<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° | æå®¢å¿«è¨Š</title><meta property="og:title" content="ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° - æå®¢å¿«è¨Š"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="http://p1.pstatp.com/large/pgc-image/1537181193465637ada828c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/46e7198.html><link rel=canonical href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/46e7198.html><meta property="article:published_time" content="2020-10-29T20:46:33+08:00"><meta property="article:modified_time" content="2020-10-29T20:46:33+08:00"><meta name=Keywords content><meta name=description content="ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•°"><meta name=author content="æå®¢å¿«è¨Š"><meta property="og:url" content="/cn/%E6%B8%B8%E6%88%8F/46e7198.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>ğŸ¤“ æå®¢å¿«è®¯ Geek Bank</a></h1><p class=description>ä¸ºä½ å¸¦æ¥æœ€å…¨çš„ç§‘æŠ€çŸ¥è¯† ğŸ§¡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>çŒœä½ å–œæ­¡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=ç§‘æŠ€>ç§‘æŠ€</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=éŠæˆ²>éŠæˆ²</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=ç§‘å­¸>ç§‘å­¸</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•°</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E6%B8%B8%E6%88%8F.html>æ¸¸æˆ</a></span></div><div class=post-content><div><h1>ä»‹ç»</h1><p>é—ä¼ ç®—æ³•ï¼Œå…¶çµæ„Ÿæ¥è‡ªæŸ¥å°”æ–¯è¾¾å°”æ–‡æå‡ºçš„è‡ªç„¶é€‰æ‹©è¿‡ç¨‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æè¿°æ¥ç†è§£è‡ªç„¶è¿‡ç¨‹åŠå…¶ä¸é—ä¼ ç®—æ³•çš„å…³ç³»:</p><p>æˆ‘ä»¬ä»å…·æœ‰æŸäº›ç‰¹å¾çš„åˆå§‹ç§ç¾¤å¼€å§‹ï¼Œå¦‚å›¾1æ‰€ç¤ºã€‚å°†åœ¨ç‰¹å®šç¯å¢ƒä¸­æµ‹è¯•è¯¥åˆå§‹ç§ç¾¤ï¼Œä»¥è§‚å¯Ÿè¯¥ç§ç¾¤ä¸­çš„ä¸ªä½“ï¼ˆçˆ¶æ¯ï¼‰åŸºäºé¢„å®šä¹‰çš„é€‚åº”æ€§æ ‡å‡†çš„è¡¨ç°ã€‚æœºå™¨å­¦ä¹ çš„é€‚åº”æ€§å¯ä»¥æ˜¯ä»»ä½•æ€§èƒ½æŒ‡æ ‡ - å‡†ç¡®åº¦ï¼Œç²¾ç¡®åº¦ï¼Œå¬å›ç‡ï¼ŒF1åˆ†æ•°ï¼Œç­‰ç­‰ã€‚æ ¹æ®é€‚åº”åº¦å€¼ï¼Œæˆ‘ä»¬é€‰æ‹©è¡¨ç°æœ€ä½³çš„çˆ¶æ¯ï¼ˆâ€œé€‚è€…ç”Ÿå­˜â€ï¼‰ï¼Œä½œä¸ºå¹¸å­˜çš„ç§ç¾¤ï¼ˆå›¾2ï¼‰ã€‚</p><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p1.pstatp.com/large/pgc-image/1537181193465637ada828c><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p3.pstatp.com/large/pgc-image/1537181197863889f074dc1><p class=pgc-img-caption></p></div><p>ç°åœ¨ï¼Œå­˜æ´»ä¸‹æ¥çš„ç¾¤ä½“ä¸­çš„çˆ¶æ¯å°†é€šè¿‡äº¤é…äº§ç”Ÿåä»£ï¼Œä½¿ç”¨ä¸¤ä¸ªæ­¥éª¤çš„ç»„åˆ:äº¤å‰/é‡ç»„å’Œçªå˜ã€‚åœ¨äº¤å‰çš„æƒ…å†µä¸‹ï¼Œäº¤é…çˆ¶æ¯çš„åŸºå› (å‚æ•°)å°†è¢«é‡æ–°ç»„åˆï¼Œäº§ç”Ÿåä»£ï¼Œæ¯ä¸ªå­©å­ä»çˆ¶æ¯åŒæ–¹é—ä¼ ä¸€äº›åŸºå› (å‚æ•°)(å›¾3)ã€‚</p><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p1.pstatp.com/large/pgc-image/15371812140993b259719a2><p class=pgc-img-caption></p></div><p>æœ€åï¼Œåœ¨çªå˜çš„æƒ…å†µä¸‹ï¼Œä¸€äº›åŸºå› (å‚æ•°)çš„å€¼å°†è¢«æ”¹å˜ä»¥ä¿æŒé—ä¼ å¤šæ ·æ€§(å›¾4)ï¼Œè¿™ä½¿å¾—è‡ªç„¶/é—ä¼ ç®—æ³•é€šå¸¸èƒ½å¤Ÿå¾—åˆ°æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚</p><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p3.pstatp.com/large/pgc-image/153718123231798411abb1c><p class=pgc-img-caption></p></div><p>å›¾5æ˜¾ç¤ºäº†ç¬¬äºŒä»£ç§ç¾¤ï¼Œè¿™å°†åŒ…æ‹¬å¹¸å­˜çš„çˆ¶æ¯å’Œå­©å­ã€‚æˆ‘ä»¬ä¿ç•™å¹¸å­˜çš„çˆ¶æ¯ï¼Œä»¥ä¾¿ä¿ç•™æœ€å¥½çš„é€‚åº”åº¦å‚æ•°ï¼Œä»¥é˜²åä»£çš„é€‚åº”åº¦å€¼æ¯”çˆ¶æ¯å·®ã€‚</p><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p3.pstatp.com/large/pgc-image/1537181247997818c31f910><p class=pgc-img-caption></p></div><h1>XGBoostçš„é—ä¼ ç®—æ³•æ¨¡å— ï¼š</h1><p>æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä¸ºXGBoostå®šåˆ¶çš„é—ä¼ ç®—æ³•æ¨¡å—ã€‚ä»¥ä¸‹æ˜¯XGboostçš„æè¿°ï¼š</p><blockquote><p>XGBoostæ˜¯ä¸€ä¸ªä¼˜åŒ–çš„åˆ†å¸ƒå¼æ¢¯åº¦å¢å¼ºåº“ï¼Œæ—¨åœ¨å®ç° é«˜æ•ˆï¼Œ çµæ´»å’Œ ä¾¿æºã€‚å®ƒåœ¨Gradient Boostingæ¡†æ¶ä¸‹å®ç°æœºå™¨å­¦ä¹ ç®—æ³• ã€‚</p></blockquote><p>è¯¥æ¨¡å—å°†å…·æœ‰éµå¾ªä»¥ä¸‹å››ä¸ªæ­¥éª¤çš„åŠŸèƒ½ï¼šï¼ˆiï¼‰åˆå§‹åŒ–ï¼Œï¼ˆiiï¼‰é€‰æ‹©ï¼Œï¼ˆiiiï¼‰äº¤å‰å’Œï¼ˆivï¼‰å˜å¼‚ï¼Œç±»ä¼¼äºä¸Šé¢è®¨è®ºçš„å†…å®¹ã€‚</p><p><strong>åˆå§‹åŒ–ï¼š</strong></p><p>ç¬¬ä¸€æ­¥æ˜¯åˆå§‹åŒ–ï¼Œå…¶ä¸­å‚æ•°éšæœºåˆå§‹åŒ–ä»¥åˆ›å»ºæ€»ä½“ã€‚å®ƒç±»ä¼¼äºå›¾1ä¸­æ‰€ç¤ºçš„ç¬¬ä¸€ä»£ç§ç¾¤ã€‚ä¸‹é¢çš„Pythonä»£ç æ˜¾ç¤ºäº†åˆå§‹åŒ–è¿‡ç¨‹ï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªåŒ…å«å‚æ•°çš„å‘é‡ã€‚åœ¨XGBoostçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€‰æ‹©äº†7ä¸ªå‚æ•°è¿›è¡Œä¼˜åŒ–ï¼šlearning_rateï¼Œn_estimatorsï¼Œmax_depthï¼Œmin_child_weightï¼Œsubsampleï¼Œcolsample_bytreeå’Œgammaã€‚å¯åœ¨æ­¤å¤„æ‰¾åˆ°è¿™äº›å‚æ•°çš„è¯¦ç»†è¯´æ˜ã€‚</p><pre>def initilialize_poplulation(numberOfParents): learningRate = np.empty([numberOfParents, 1]) nEstimators = np.empty([numberOfParents, 1], dtype = np.uint8) maxDepth = np.empty([numberOfParents, 1], dtype = np.uint8) minChildWeight = np.empty([numberOfParents, 1]) gammaValue = np.empty([numberOfParents, 1]) subSample = np.empty([numberOfParents, 1]) colSampleByTree = np.empty([numberOfParents, 1])  for i in range(numberOfParents): print(i) learningRate[i] = round(random.uniform(0.01, 1), 2) nEstimators[i] = random.randrange(10, 1500, step = 25) maxDepth[i] = int(random.randrange(1, 10, step= 1)) minChildWeight[i] = round(random.uniform(0.01, 10.0), 2) gammaValue[i] = round(random.uniform(0.01, 10.0), 2) subSample[i] = round(random.uniform(0.01, 1.0), 2) colSampleByTree[i] = round(random.uniform(0.01, 1.0), 2)  population = np.concatenate((learningRate, nEstimators, maxDepth, minChildWeight, gammaValue, subSample, colSampleByTree), axis= 1) return population</pre><p>å¦‚æœä¸Šé™è®¾ç½®ä¸ºæ— ç©·å¤§ï¼Œåˆ™å‚æ•°çš„é™åˆ¶è¦ä¹ˆåŸºäºXGBoostæ–‡æ¡£ä¸­æè¿°çš„é™åˆ¶ï¼Œè¦ä¹ˆåŸºäºåˆç†çš„çŒœæµ‹ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºæ¯ä¸ªå‚æ•°åˆ›å»ºä¸€ä¸ªç©ºæ•°ç»„ï¼Œç„¶åç”¨éšæœºå€¼å¡«å……å®ƒã€‚</p><p><strong>çˆ¶æ¯é€‰æ‹©</strong></p><p>åœ¨ç¬¬äºŒæ­¥ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆå§‹ç§ç¾¤è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹å¹¶è®¡ç®—é€‚åº”åº¦å€¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†è®¡ç®—F1å¾—åˆ†ã€‚Pythonä»£ç å¦‚ä¸‹ï¼š</p><pre>def fitness_f1score(y_true, y_pred): fitness = round((f1_score(y_true, y_pred, average='weighted')), 4) return fitness #train the data annd find fitness scoredef train_population(population, dMatrixTrain, dMatrixtest, y_test): fScore = [] for i in range(population.shape[0]): param = { 'objective':'binary:logistic', 'learning_rate': population[i][0], 'n_estimators': population[i][1],  'max_depth': int(population[i][2]),  'min_child_weight': population[i][3], 'gamma': population[i][4],  'subsample': population[i][5], 'colsample_bytree': population[i][6], 'seed': 24} num_round = 100 xgbT = xgb.train(param, dMatrixTrain, num_round) preds = xgbT.predict(dMatrixtest) preds = preds&gt;0.5 fScore.append(fitness_f1score(y_test, preds)) return fScore</pre><p>æˆ‘ä»¬å°†æ ¹æ®å®ƒä»¬çš„é€‚åº”åº¦å€¼æ¥å®šä¹‰æˆ‘ä»¬æƒ³è¦é€‰æ‹©å¤šå°‘çˆ¶æ¯å¹¶æ ¹æ®æ‰€é€‰çˆ¶æ¯åˆ›å»ºä¸€ä¸ªæ•°ç»„ã€‚Pythonå®ç°å¦‚ä¸‹ï¼š</p><pre>#select parents for matingdef new_parents_selection(population, fitness, numParents): selectedParents = np.empty((numParents, population.shape[1])) #create an array to store fittest parents  #find the top best performing parents for parentId in range(numParents): bestFitnessId = np.where(fitness == np.max(fitness)) bestFitnessId = bestFitnessId[0][0] selectedParents[parentId, :] = population[bestFitnessId, :] fitness[bestFitnessId] = -1 #set this value to negative, in case of F1-score, so this parent is not selected again return selectedParents</pre><p><strong>äº¤å‰</strong></p><p>åœ¨é—ä¼ ç®—æ³•çš„æƒ…å†µä¸‹ï¼Œæœ‰å¤šç§æ–¹æ³•å¯ä»¥å®šä¹‰äº¤å‰ï¼Œä¾‹å¦‚å•ç‚¹ï¼Œä¸¤ç‚¹å’Œkç‚¹äº¤å‰ï¼Œæœ‰åºåˆ—è¡¨çš„å‡åŒ€äº¤å‰å’Œäº¤å‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å‡åŒ€äº¤å‰ï¼Œå…¶ä¸­å­©å­çš„æ¯ä¸ªå‚æ•°å°†åŸºäºç‰¹å®šåˆ†å¸ƒä»çˆ¶æ¯ä¸­ç‹¬ç«‹åœ°é€‰æ‹©ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨numpyéšæœºå‡½æ•°çš„ â€œç¦»æ•£å‡åŒ€â€åˆ†å¸ƒã€‚Pythonä»£ç å¦‚ä¸‹ï¼š</p><pre>'''Mate these parents to create children having parameters from these parents (we are using uniform crossover method)'''def crossover_uniform(parents, childrenSize):  crossoverPointIndex = np.arange(0, np.uint8(childrenSize[1]), 1, dtype= np.uint8) #get all the index crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(childrenSize[1]/2)) # select half of the indexes randomly crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1))) #select leftover indexes  children = np.empty(childrenSize)  ''' Create child by choosing parameters from two parents selected using new_parent_selection function. The parameter values will be picked from the indexes, which were randomly selected above.  ''' for i in range(childrenSize[0]):  #find parent 1 index  parent1_index = i%parents.shape[0] #find parent 2 index parent2_index = (i+1)%parents.shape[0] #insert parameters based on random selected indexes in parent 1 children[i, crossoverPointIndex1] = parents[parent1_index, crossoverPointIndex1] #insert parameters based on random selected indexes in parent 1 children[i, crossoverPointIndex2] = parents[parent2_index, crossoverPointIndex2] return children</pre><p><strong>çªå˜</strong></p><p>æœ€åä¸€æ­¥æ˜¯é€šè¿‡éšæœºé€‰æ‹©ä¸€ä¸ªå‚æ•°å¹¶é€šè¿‡éšæœºé‡æ”¹å˜å€¼æ¥å¼•å…¥å­©å­çš„å¤šæ ·æ€§ã€‚æˆ‘ä»¬è¿˜å°†å¼•å…¥ä¸€äº›é™åˆ¶ï¼Œä»¥ä¾¿å°†æ”¹å˜çš„å€¼é™åˆ¶åœ¨ä¸€å®šèŒƒå›´å†…ã€‚è·³è¿‡è¿™äº›çº¦æŸå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯ã€‚</p><pre>def mutation(crossover, numberOfParameters): #Define minimum and maximum values allowed for each parameter  minMaxValue = np.zeros((numberOfParameters, 2))  minMaxValue[0:] = [0.01, 1.0] #min/max learning rate minMaxValue[1, :] = [10, 2000] #min/max n_estimator minMaxValue[2, :] = [1, 15] #min/max depth minMaxValue[3, :] = [0, 10.0] #min/max child_weight minMaxValue[4, :] = [0.01, 10.0] #min/max gamma minMaxValue[5, :] = [0.01, 1.0] #min/maxsubsample minMaxValue[6, :] = [0.01, 1.0] #min/maxcolsample_bytree  # Mutation changes a single gene in each offspring randomly. mutationValue = 0 parameterSelect = np.random.randint(0, 7, 1) print(parameterSelect) if parameterSelect == 0: #learning_rate mutationValue = round(np.random.uniform(-0.5, 0.5), 2) if parameterSelect == 1: #n_estimators mutationValue = np.random.randint(-200, 200, 1) if parameterSelect == 2: #max_depth mutationValue = np.random.randint(-5, 5, 1) if parameterSelect == 3: #min_child_weight mutationValue = round(np.random.uniform(5, 5), 2) if parameterSelect == 4: #gamma mutationValue = round(np.random.uniform(-2, 2), 2) if parameterSelect == 5: #subsample mutationValue = round(np.random.uniform(-0.5, 0.5), 2) if parameterSelect == 6: #colsample mutationValue = round(np.random.uniform(-0.5, 0.5), 2)  #indtroduce mutation by changing one parameter, and set to max or min if it goes out of range for idx in range(crossover.shape[0]): crossover[idx, parameterSelect] = crossover[idx, parameterSelect] + mutationValue if(crossover[idx, parameterSelect] &gt; minMaxValue[parameterSelect, 1]): crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 1] if(crossover[idx, parameterSelect] &lt; minMaxValue[parameterSelect, 0]): crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 0]  return crossover</pre><h1>å®ç°</h1><p>æˆ‘ä»¬å°†å®ç°ä¸Šé¢è®¨è®ºçš„æ¨¡å—æ¥è®­ç»ƒæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ¥è‡ªUCIæœºå™¨å­¦ä¹ åº“(https://archive.ics.uci.edu/ml/machine-learning-databases/musk/)ã€‚å®ƒå«æœ‰ä¸€ç»„102ä¸ªåˆ†å­ï¼Œå…¶ä¸­39ä¸ªè¢«äººç±»é‰´å®šä¸ºå…·æœ‰å¯ç”¨äºé¦™æ°´çš„æ°”å‘³ï¼Œ69ä¸ªæ²¡æœ‰æ‰€éœ€çš„æ°”å‘³ã€‚è¯¥æ•°æ®é›†åŒ…å«6,590ä¸ªè¿™äº›åˆ†å­çš„ä½èƒ½æ„è±¡ï¼ŒåŒ…å«166ä¸ªç‰¹å¾ã€‚ä½œä¸ºæœ¬æ•™ç¨‹çš„ç›®æ ‡ï¼Œæˆ‘ä»¬æ­£åœ¨åšæœ€å°çš„é¢„å¤„ç†æ¥ç†è§£é—ä¼ ç®—æ³•ã€‚Pythonä»£ç å¦‚ä¸‹ï¼š</p><pre># Importing the librariesimport numpy as npimport pandas as pdimport geneticXGboost #this is the module we crated aboveimport xgboost as xgb np.random.seed(723) # Importing the datasetdataset = pd.read_csv('clean2.data', header=None) X = dataset.iloc[:, 2:168].values #discard first two coloums as these are molecule's name and conformation's name y = dataset.iloc[:, 168].values #extrtact last coloum as class (1 =&gt; desired odor, 0 =&gt; undesired odor) # Splitting the dataset into the Training set and Test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 97) # Feature Scalingfrom sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test) #XGboost Classifier #model xgboost#use xgboost API nowxgDMatrix = xgb.DMatrix(X_train, y_train) #create DmatrixxgbDMatrixTest = xgb.DMatrix(X_test, y_test)</pre><p>æˆ‘ä»¬æœ‰8ä¸ªçˆ¶æ¯ï¼Œæˆ‘ä»¬é€‰æ‹©4ä¸ªæœ€é€‚åˆçš„çˆ¶æ¯è¿›è¡Œäº¤é…ã€‚æˆ‘ä»¬å°†åˆ›å»º4ä»£å¹¶ç›‘æ§é€‚åº”åº¦(f1å€¼)ã€‚åœ¨ä¸‹ä¸€ä»£ä¸­ï¼Œæœ‰ä¸€åŠçš„çˆ¶æ¯æ˜¯ä¸Šä¸€ä»£ä¸­æœ€é€‚åˆçš„ã€‚è¿™å°†ä½¿æˆ‘ä»¬ä¿æŒæœ€å¥½çš„é€‚åº”åº¦åˆ†æ•°è‡³å°‘ä¸ä¸Šä¸€ä»£ç›¸åŒï¼Œä»¥é˜²å­©å­çš„é€‚åº”åº¦åˆ†æ•°æ›´å·®ã€‚</p><pre> numberOfParents = 8 #number of parents to startnumberOfParentsMating = 4 #number of parents that will matenumberOfParameters = 7 #number of parameters that will be optimizednumberOfGenerations = 4 #number of genration that will be created #define the population size populationSize = (numberOfParents, numberOfParameters) #initialize the population with randomly generated parameterspopulation = geneticXGboost.initilialize_poplulation(numberOfParents) #define an array to store the fitness hitoryfitnessHistory = np.empty([numberOfGenerations+1, numberOfParents]) #define an array to store the value of each parameter for each parent and generationpopulationHistory = np.empty([(numberOfGenerations+1)*numberOfParents, numberOfParameters]) #insert the value of initial parameters in historypopulationHistory[0:numberOfParents, :] = population for generation in range(numberOfGenerations): print("This is number %s generation" % (generation))  #train the dataset and obtain fitness fitnessValue = geneticXGboost.train_population(population=population, dMatrixTrain=xgDMatrix, dMatrixtest=xgbDMatrixTest, y_test=y_test) fitnessHistory[generation, :] = fitnessValue  #best score in the current iteration print('Best F1 score in the this iteration = {}'.format(np.max(fitnessHistory[generation, :]))) #survival of the fittest - take the top parents, based on the fitness value and number of parents needed to be selected parents = geneticXGboost.new_parents_selection(population=population, fitness=fitnessValue, numParents=numberOfParentsMating)  #mate these parents to create children having parameters from these parents (we are using uniform crossover) children = geneticXGboost.crossover_uniform(parents=parents, childrenSize=(populationSize[0] - parents.shape[0], numberOfParameters))  #add mutation to create genetic diversity children_mutated = geneticXGboost.mutation(children, numberOfParameters)  ''' We will create new population, which will contain parents that where selected previously based on the fitness score and rest of them will be children ''' population[0:parents.shape[0], :] = parents #fittest parents population[parents.shape[0]:, :] = children_mutated #children  populationHistory[(generation+1)*numberOfParents : (generation+1)*numberOfParents+ numberOfParents , :] = population #srore parent information</pre><p>æœ€åï¼Œæˆ‘ä»¬å¾—åˆ°æœ€å¥½çš„åˆ†æ•°å’Œç›¸å…³å‚æ•°ï¼š</p><pre>#Best solution from the final iteration fitness = geneticXGboost.train_population(population=population, dMatrixTrain=xgDMatrix, dMatrixtest=xgbDMatrixTest, y_test=y_test)fitnessHistory[generation+1, :] = fitness #index of the best solutionbestFitnessIndex = np.where(fitness == np.max(fitness))[0][0] #Best fitnessprint("Best fitness is =", fitness[bestFitnessIndex]) #Best parametersprint("Best parameters are:")print('learning_rate', population[bestFitnessIndex][0])print('n_estimators', population[bestFitnessIndex][1])print('max_depth', int(population[bestFitnessIndex][2])) print('min_child_weight', population[bestFitnessIndex][3])print('gamma', population[bestFitnessIndex][4])print('subsample', population[bestFitnessIndex][5])print('colsample_bytree', population[bestFitnessIndex][6])</pre><p>ç°åœ¨è®©æˆ‘ä»¬æƒ³è±¡æ¯ä¸€ä»£ç§ç¾¤é€‚åº”åº¦çš„å˜åŒ–ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ã€‚è™½ç„¶æˆ‘ä»¬å·²ç»å¼€å§‹ä»¥é«˜å¾—åˆ†çš„F1å¾—åˆ†ï¼ˆ~0.98ï¼‰ï¼Œåœ¨ä¸¤ä¸ªçˆ¶æ¯ä¸­ï¼Œåœ¨éšæœºç”Ÿæˆçš„åˆå§‹ç§ç¾¤ä¸­ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æœ€åä¸€ä»£ä¸­è¿›ä¸€æ­¥æé«˜å®ƒã€‚åˆå§‹äººç¾¤ä¸­çˆ¶æ¯çš„æœ€ä½F1åˆ†æ•°ä¸º0.9143ï¼Œæœ€åä¸€ä»£çˆ¶æ¯ä¸­çš„ä¸€ä¸ªæœ€ä½³åˆ†æ•°ä¸º0.9947ã€‚è¿™è¡¨æ˜æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•çš„é—ä¼ ç®—æ³•å®ç°æ¥æ”¹è¿›XGBoostä¸­çš„æ€§èƒ½æŒ‡æ ‡ã€‚</p><div class=pgc-img><img alt=ä½¿ç”¨é—ä¼ ç®—æ³•åœ¨XGBoostä¸­è°ƒæ•´è¶…å‚æ•° onerror=errorimg.call(this); src=http://p9.pstatp.com/large/pgc-image/1537181359437c67d735cc4><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'é—ä¼ ','XGBoost','ä¸­è°ƒ'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=æœç´¢>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>ğŸ”</button></form></section><section class=widget><h3 class=widget-title>æœ€æ–°æ–‡ç«  âš¡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>å…¶ä»–</h3><ul class=widget-list><li><a href=TOS.html>ä½¿ç”¨æ¢æ¬¾</a></li><li><a href=CommentPolicy.html>ç•™è¨€æ”¿ç­–</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>è¯çµ¡æˆ‘å€‘</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>æå®¢å¿«è¨Š</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>