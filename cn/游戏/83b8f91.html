<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Python代码实操：详解数据清洗 | 极客快訊</title><meta property="og:title" content="Python代码实操：详解数据清洗 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="http://p9.pstatp.com/large/pgc-image/b2d2133012dd4deba7783d726b7324af"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e6%b8%b8%e6%88%8f/83b8f91.html><link rel=canonical href=https://geekbank.cf/tw/%e6%b8%b8%e6%88%8f/83b8f91.html><meta property="article:published_time" content="2020-10-29T20:48:06+08:00"><meta property="article:modified_time" content="2020-10-29T20:48:06+08:00"><meta name=Keywords content><meta name=description content="Python代码实操：详解数据清洗"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E6%B8%B8%E6%88%8F/83b8f91.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Python代码实操：详解数据清洗</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E6%B8%B8%E6%88%8F.html>游戏</a></span></div><div class=post-content><div><blockquote><p><strong>导读：</strong>此前的文章《<a class=pgc-link data-content=mp href="https://www.toutiao.com/i6711212131125035534/?group_id=6711212131125035534" target=_blank>​一文看懂数据清洗：缺失值、异常值和重复值的处理</a>》中，我们介绍了数据清洗的过程和方法，本文给出各步骤的详细代码，方便你动手操作。</p></blockquote><p>作者：宋天龙</p><p>如需转载请联系华章科技</p><div class=pgc-img><img alt=Python代码实操：详解数据清洗 onerror=errorimg.call(this); src=http://p9.pstatp.com/large/pgc-image/b2d2133012dd4deba7783d726b7324af><p class=pgc-img-caption></p></div><p>本文示例中，主要用了几个知识点：</p><ul><li>通过 pd.DataFrame 新建数据框。</li><li>通过 df.iloc[] 来选择特定的列或对象。</li><li>使用Pandas的 isnull() 判断值是否为空。</li><li>使用 all() 和 any() 判断每列是否包含至少1个为True或全部为True的情况。</li><li>使用Pandas的 dropna() 直接删除缺失值。</li><li>使用 sklearn.preprocessing 中的 Imputer 方法对缺失值进行填充和替换，支持3种填充方法。</li><li>使用Pandas的 fillna 填充缺失值，支持更多自定义的值和常用预定义方法。</li><li>通过 copy() 获得一个对象副本，常用于原始对象和复制对象同时进行操作的场景。</li><li>通过 for 循环遍历可迭代的列表值。</li><li>自定义代码实现了 Z-Score 计算公式。</li><li>通过Pandas的 duplicated() 判断重复数据记录。</li><li>通过Pandas的 drop_duplicates() 删除数据记录，可指定特定列或全部。</li></ul><h1><strong>01 缺失值处理</strong></h1><p>在缺失值的处理上，主要配合使用 sklearn.preprocessing 中的Imputer类、Pandas和Numpy。其中由于Pandas对于数据探索、分析和探查的支持较为良好，因此围绕Pandas的缺失值处理较为常用。</p><p><strong>1. 导入库</strong></p><p>该代码示例中用到Pandas、Numpy和sklearn。</p><pre>import pandas as pd 　# 导入Pandas库import numpy as np 　# 导入Numpy库from sklearn.preprocessing import Imputer 　# 导入sklearn.preprocessing中的Imputer库</pre><p><strong>2. 生成缺失数据</strong></p><pre># 生成缺失数据df = pd.DataFrame(np.random.randn(6, 4), columns=['col1', 'col2', 'col3', 'col4']) 　　　 # 生成一份数据df.iloc[1:2, 1] = np.nan 　　　　　 # 增加缺失值df.iloc[4, 3] = np.nan 　# 增加缺失值print(df)</pre><p>通过Pandas生成一个6行4列，列名分别为'col1'、'col2'、'col3'、'col4'的数据框。同时，数据框中增加两个缺失值数据。</p><p>除了示例中直接通过pd.DataFrame来直接创建数据框外，还可以使用数据框对象的 df.from_records、df.from_dict、df.from_items 来从元组记录、字典和键值对对象创建数据框，或使用 pandas.read_csv、pandas.read_table、pandas.read_clipboard 等方法读取文件或剪贴板创建数据框。该代码段执行后返回了定义含有缺失值的数据框，结果如下：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 NaN -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 NaN5 1.928313 -1.376593 -1.557721 0.289643</pre><p>提示：由于生成的数据是随机产生的，因此读者的实际结果可能与上述结果不一致。</p><p><strong>3. 判断缺失值</strong></p><pre># 查看哪些值缺失nan_all = df.isnull() # 获得所有数据框中的N值print(nan_all) # 打印输出# 查看哪些列缺失nan_col1 = df.isnull().any() # 获得含有NA的列nan_col2 = df.isnull().all() # 获得全部为NA的列print(nan_col1) # 打印输出print(nan_col2) # 打印输出</pre><p>通过 df.null() 方法找到所有数据框中的缺失值（默认缺失值是 NaN 格式），然后使用 any() 或 all() 方法来查找含有至少1个或全部缺失值的列，其中 any() 方法用来返回指定轴中的任何元素为 True，而 all() 方法用来返回指定轴的所有元素都为 True。该代码段执行后返回如下结果。</p><p>判断元素是否是缺失值（第2行第2列和第5行第4列）：</p><pre> col1 col2 col3 col40 False False False False1 False True False False2 False False False False3 False False False False4 False False False True5 False False False False</pre><p>列出至少有一个元素含有缺失值的列（该示例中为col2和col4）：</p><pre>col1 Falsecol2 Truecol3 Falsecol4 Truedtype: bool</pre><p>列出全部元素含有缺失值的列（该示例中没有）：</p><pre>col1 Falsecol2 Falsecol3 Falsecol4 Falsedtype: bool</pre><p><strong>4. 丢弃缺失值</strong></p><pre>df2 = df.dropna() # 直接丢弃含有NA的行记录print(df2) # 打印输出</pre><p>通过Pandas默认的 dropna() 方法丢弃缺失值，返回无缺失值的数据记录。该代码段执行后返回如下结果（第2行、第5行数据记录被删除）：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966912 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457125 1.928313 -1.376593 -1.557721 0.289643</pre><p><strong>5. 通过sklearn的数据预处理方法对缺失值进行处理</strong></p><pre>nan_model = Imputer(missing_values='NaN', strategy='mean', axis=0) # 建立替换规则：将值为NaN的缺失值以均值做替换nan_result = nan_model.fit_transform(df) # 应用模型规则print(nan_result) # 打印输出</pre><p>首先通过 Imputer 方法创建一个预处理对象，其中 missing_values 为默认缺失值的字符串，默认为 NaN；示例中选择缺失值替换方法是均值（默认），还可以选择使用中位数和众数进行替换，即 strategy 值设置为 median 或 most_frequent；后面的参数 axis 用来设置输入的轴，默认值为0，即使用列做计算逻辑。</p><p>然后使用预处理对象的 fit_transform 方法对 df（数据框对象）进行处理，该方法是将 fit 和 transform 组合起来使用。代码执行后返回如下结果：</p><pre>[[-0.11241503 -0.76818022 -0.08485904 0.29669147] [-1.77731513 -0.44946793 -0.16661458 -0.62875601] [-0.62946127 1.89278959 -1.85000643 0.15756702] [ 0.54486026 -1.23080434 0.836615 -0.9457117 ] [ 0.70339369 -0.76455205 -1.21437918 -0.16611331] [ 1.92831315 -1.37659263 -1.55772092 0.28964265]]</pre><p>代码中的第2行第2列和第5行第4列分别被各自列的均值替换。为了验证，我们手动计算一下各自列的均值，通过使用 df['col2'].mean() 和 df['col4'].mean() 分别获得这两列的均值为-0.4494679289032068和-0.16611331259664791，与sklearn返回的结果一致。</p><p><strong>6. 使用Pandas做缺失值处理</strong></p><pre>nan_result_pd1 = df.fillna(method='backfill') # 用后面的值替换缺失值nan_result_pd2 = df.fillna(method='bfill', limit=1) # 用后面的值替代缺失值,限制每列只能替代一个缺失值nan_result_pd3 = df.fillna(method='pad') # 用前面的值替换缺失值nan_result_pd4 = df.fillna(0) # 用0替换缺失值nan_result_pd5 = df.fillna({'col2': 1.1, 'col4': 1.2}) # 用不同值替换不同列的缺失值nan_result_pd6 = df.fillna(df.mean()['col2':'col4']) # 用各自列的平均数替换缺失值# 打印输出print(nan_result_pd1) # 打印输出print(nan_result_pd2) # 打印输出print(nan_result_pd3) # 打印输出print(nan_result_pd4) # 打印输出print(nan_result_pd5) # 打印输出print(nan_result_pd6) # 打印输出</pre><p>Pandas对缺失值的处理方法是 df.fillna()，该方法中最主要的两个参数是 value 和 method。前者通过固定（或手动指定）的值替换缺失值，后者使用Pandas提供的默认方法替换缺失值。以下是 method 支持的方法。</p><ul><li>pad 和 ffill：使用前面的值替换缺失值，示例中 nan_result_pd3 使用了 pad 方法。</li><li>backfill 和 bfill：使用后面的值替换缺失值，示例中 nan_result_pd1 和 nan_result_pd2 使用了该方法。</li><li>None：无。</li></ul><p>在示例中， nan_result_pd4、nan_result_pd5、nan_result_pd6 分别使用0、不同的值、平均数替换缺失值。需要注意的是，如果要使用不同具体值替换，需要使用 scalar、dict、Series 或 DataFrame 的格式定义。</p><p>上述代码执行后返回如下结果。</p><p>用后面的值（method='backfill'）替换缺失值：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 1.892790 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 0.2896435 1.928313 -1.376593 -1.557721 0.289643</pre><p>用后面的值（method='bfill', limit = 1）替换缺失值：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 1.892790 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 0.2896435 1.928313 -1.376593 -1.557721 0.289643</pre><p>用前面的值替换缺失值（method='pad'）：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 -0.768180 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 -0.9457125 1.928313 -1.376593 -1.557721 0.289643</pre><p>用0替换缺失值：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 0.000000 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 0.0000005 1.928313 -1.376593 -1.557721 0.289643</pre><p>手动指定两个缺失值分布为1.1和1.2：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 1.100000 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 1.2000005 1.928313 -1.376593 -1.557721 0.289643</pre><p>用平均数代替，选择各自列的均值替换缺失值：</p><pre> col1 col2 col3 col40 -0.112415 -0.768180 -0.084859 0.2966911 -1.777315 -0.449468 -0.166615 -0.6287562 -0.629461 1.892790 -1.850006 0.1575673 0.544860 -1.230804 0.836615 -0.9457124 0.703394 -0.764552 -1.214379 -0.1661135 1.928313 -1.376593 -1.557721 0.289643</pre><p>以上示例中，直接指定 method 的方法适用于大多数情况，较为简单直接；但使用 value 的方法则更为灵活，原因是可以通过函数的形式将缺失值的处理规则写好，然后直接赋值即可。限于篇幅，不对所有方法做展开讲解。</p><p>另外，如果是直接替换为特定值的应用，也可以考虑使用Pandas的 replace 功能。本示例的 df （原始数据框）可直接使用 df.replace(np.nan,0)，这种用法更加简单粗暴，但也能达到效果。当然，replace的出现是为了解决各种替换应用的，缺失值只是其中的一种应用而已。</p><p>上述过程中，主要需要考虑的关键点是缺失值的替换策略，可指定多种方法替换缺失值，具体根据实际需求而定，但大多数情况下均值、众数和中位数的方法较为常用。如果场景固定，也可以使用特定值（例如0）替换。</p><p><strong>在使用不同的缺失值策略时，需要注意以下几个问题：</strong></p><ol><li>缺失值的处理的前提是已经可以正确识别所有缺失值字段，关于识别的问题在使用Pandas读取数据时可通过设置 na_values 的值指定。但是如果数据已经读取完毕并且不希望再重新读取，那可以使用Pandas的 replace 功能将指定的字符串（或列表）替换为 NaN。更有效的是，如果数据中的缺失值太多而无法通过列表形式穷举时，replace 还支持正则表达式的写法。</li><li>当列中的数据全部为空值时，任何替换方法都将失效，任何基于中位数、众数和均值的策略都将失效。除了可以使用固定值替换外（这种情况下即使替换了该特征也没有实际参与模型的价值），最合理的方式是先将全部为缺失值的列删除，然后再做其他处理。</li><li>当列中含有极大值或极小值的 inf 或 -inf 时，会使得 mean() 这种方法失效，因为这种情况下将无法计算出均值。应对思路是使用 median 中位数做兜底策略，只要列中有数据，就一定会有中位数。</li></ol><h1><strong>02 异常值处理</strong></h1><p>有关异常值的确定有很多规则和方法，这里使用Z标准化得到的阈值作为判断标准：当标准化后的得分超过阈值则为异常。完整代码如下。</p><p>示例代码分为3个部分。</p><p><strong>1. 导入本例需要的Pandas库</strong></p><pre>import pandas as pd # 导入Pandas库</pre><p><strong>2. 生成异常数据</strong></p><pre>df = pd.DataFrame({'col1': [1, 120, 3, 5, 2, 12, 13], 'col2': [12, 17, 31, 53, 22, 32, 43]})print(df) # 打印输出</pre><p>直接通过DataFrame创建一个7行2列的数据框，打印输出结果如下：</p><pre> col1 col20 1 121 120 172 3 313 5 534 2 225 12 326 13 43</pre><p><strong>3. 为通过Z-Score方法判断异常值</strong></p><pre>df_zscore = df.copy() # 复制一个用来存储Z-score得分的数据框cols = df.columns # 获得数据框的列名for col in cols: # 循环读取每列 df_col = df[col] # 得到每列的值 z_score = (df_col - df_col.mean()) / df_col.std() # 计算每列的Z-score得分 df_zscore[col] = z_score.abs() &gt; 2.2 # 判断Z-score得分是否大于2.2，如果是则为True，否则为Falseprint(df_zscore) # 打印输出</pre><p>本过程中，先通过 df.copy() 复制一个原始数据框的副本，用来存储Z-Score标准化后的得分，再通过 df.columns 获得原始数据框的列名，接着通过循环判断每一列中的异常值。在判断逻辑中，对每一列的数据进行使用自定义的方法做Z-Score值标准化得分计算，然后与阈值2.2做比较，如果大于阈值则为异常。本段代码返回结果如下：</p><pre> col1 col20 False False1 True False2 False False3 False False4 False False5 False False6 False False</pre><p>在本示例方法中，阈值的设定是确定异常与否的关键，通常当阈值大于2.2时，就是相对异常的表现值。</p><p><strong>4. 删除带有异常值所在的记录行</strong></p><pre>df_drop_outlier = df[df_zscore['col1'] == False]print(df_drop_outlier)</pre><p>本段代码里我们直接使用了Pandas的选择功能，即只保留在 df_zscore 中异常列（col1）为 False 的列。完成后在输出的结果中可以看到，删除了 index 值为1的数据行。</p><pre> col1 col20 1 122 3 313 5 534 2 225 12 326 13 43</pre><p>上述过程中，主要需要考虑的关键点是：如何判断异常值。</p><p>对于有固定业务规则的可直接套用业务规则，而对于没有固定业务规则的，可以采用常见的数学模型进行判断：</p><ul><li>基于概率分布的模型（例如正态分布的标准差范围）</li><li>基于聚类的方法（例如KMeans）</li><li>基于密度的方法（例如LOF）</li><li>基于分类的方法（例如KNN）</li><li>基于统计的方法（例如分位数法）等。</li></ul><p><strong>异常值的定义带有较强的主观判断色彩，具体需要根据实际情况选择。</strong></p><h1><strong>03 重复值处理</strong></h1><p>有关重复值的处理代码分为4个部分。</p><p><strong>1. 导入用到的Pandas库</strong></p><pre>import pandas as pd # 导入Pandas库</pre><p><strong>2. 生成重复数据</strong></p><pre>data1, data2, data3, data4 = ['a', 3], ['b', 2], ['a', 3], ['c', 2]df = pd.DataFrame([data1, data2, data3, data4], columns=['col1', 'col2'])print(df)</pre><p>在代码中，我们在一列中直接给4个对象赋值，也可以拆分为4行分别赋值。该数据是一个4行2列数据框，数据结果如下：</p><pre> col1 col20 a 31 b 22 a 33 c 2</pre><p><strong>3. 判断重复数据</strong></p><pre>isDuplicated = df.duplicated() # 判断重复数据记录print(isDuplicated) # 打印输出</pre><p>判断数据记录是否为重复值，返回每条数据记录是否重复结果，取值为 True 或 False。判断方法为 df.duplicated()，该方法中两个主要的参数是 subset 和 keep。</p><ul><li>subset：要判断重复值的列，可以指定特定列或多个列。默认使用全部列。</li><li>keep：当重复时不标记为True的规则，可设置为第1个（first）、最后一个（last）和全部标记为True（False）。默认使用first，即第1个重复值不标记为True。</li></ul><p>结果如下：</p><pre>0 False1 False2 True3 Falsedtype: bool</pre><p><strong>4. 删除重复值</strong></p><pre>print(df.drop_duplicates()) # 删除数据记录中所有列值相同的记录print(df.drop_duplicates(['col1'])) # 删除数据记录中col1值相同的记录print(df.drop_duplicates(['col2'])) # 删除数据记录中col2值相同的记录print(df.drop_duplicates(['col1', 'col2'])) # 删除数据记录中指定列（col1/col2）值相同的记录</pre><p>该操作的核心方法是 df.drop_duplicates()，该方法的作用是基于指定的规则判断为重复值之后，删除重复值，其参数跟 df.duplicated() 完全相同。在该部分方法示例中，依次使用默认规则（全部列相同的数据记录）、col1列相同、col2列相同以及指定col1和col2完全相同4种规则进行去重。返回结果如下。</p><p>删除数据记录中所有列值相同的记录，index为2的记录行被删除：</p><pre> col1 col20 a 31 b 23 c 2</pre><p>删除数据记录中col1值相同的记录，index为2的记录行被删除：</p><pre> col1 col20 a 31 b 23 c 2</pre><p>删除数据记录中col2值相同的记录，index为2和3的记录行被删除：</p><pre> col1 col20 a 31 b 2</pre><p>删除数据记录中指定列（col1和col2）值相同的记录，index为2的记录行被删除：</p><pre> col1 col20 a 31 b 23 c 2</pre><p>提示：由于数据是通过随机数产生，因此读者操作的结果可能与上述示例的数据结果不同。</p><p>除了可以使用Pandas来做重复值判断和处理外，也可以使用Numpy中的 unique() 方法，该方法返回其参数数组中所有不同的值，并且按照从小到大的顺序排列。Python自带的内置函数 set 方法也能返回唯一元素的集合。</p><p>上述过程中，主要需要考虑的关键点是：如何对重复值进行处理。重复值的判断相对简单，而判断之后如何处理往往不是一个技术特征明显的工作，而是侧重于业务和建模需求的工作。</p><blockquote><p>关于作者：宋天龙，深大数据技术专家，触脉咨询合伙人兼副总裁，前Webtrekk中国区技术和咨询负责人（德国最大在线数据分析服务提供商）。擅长数据挖掘、建模、分析与运营，精通端到端数据价值场景设计、业务需求转换、数据结构梳理、数据建模与学习以及数据工程交付。在电子商务、零售、银行、保险等多个行业拥有丰富的数据项目工作经验。</p></blockquote><p>本文摘编自《Python数据分析与数据化运营》（第2版），经出版方授权发布。</p><div class=pgc-img><img alt=Python代码实操：详解数据清洗 onerror=errorimg.call(this); src=http://p1.pstatp.com/large/pgc-image/f7b0a792de9047f682498eecec0c78cf><p class=pgc-img-caption>延伸阅读《Python数据分析与数据化运营》（第2版）</p></div><p class=ql-align-justify><strong>推荐语：</strong>这是一本将数据分析技术与数据使用场景深度结合的著作，从实战角度讲解了如何利用Python进行数据分析和数据化运营。本书与同类书大的不同在于，并不只有纯粹的关于数据分析技术和工具的讲解，而且还与数据使用场景深度结合，在业务上真正可指导落地。此外，本书作者提供微信、邮箱等，可通过实时和离线两种方式及时为读者在线传道、受业、解惑。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Python','代码','实操'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>