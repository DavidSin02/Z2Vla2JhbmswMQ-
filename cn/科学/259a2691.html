<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 | 极客快訊</title><meta property="og:title" content="「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RUamXJaDPtgHsJ"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/259a2691.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/259a2691.html><meta property="article:published_time" content="2020-11-14T20:56:57+08:00"><meta property="article:modified_time" content="2020-11-14T20:56:57+08:00"><meta name=Keywords content><meta name=description content="「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/259a2691.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><p>词嵌入模型得到的词向量用途广泛、使用灵活，被应用于许多NLP任务中。很多NLP任务的模型，甚至是建立在词嵌入模型之上，比如机器翻译、情感分析等。然而，过往并无系统研究词向量维数怎样影响后续应用效果的工作。</p><p><strong>斯坦福Zi Yin在NeurIPS 2018的一篇论文“On the Dimensionality of Word Embedding”提供了一种快速选择维数的方法。</strong></p><p>历史使用的维数</p><p>直观而言，一方面，词向量维数不能太小，比如仅1维时，向量空间表达能力有限。另一方面，词向量维数也不能太大，否则有可能过拟合。即使不过拟合，考虑到下游任务的输入维数通常是词向量维数，这一线性增长的计算成本将使模型难以训练、调试。</p><p>最常用的词向量维数是300，因为Mikolov在他2013年那篇著名的skip-gram Word2Vec model中用到的维数是300。就实践而言，除了这样专制地选择一个维数，也可以通过搜索的办法去寻找一个维度，使得下游任务效果最好。但若搜索空间太小，如grid search的搜索空间，所得解一定是次优的。搜索空间太大，如连续每一个整数均进行词向量训练，则计算成本无法控制，且针对不同的下游任务，均需重启搜索。况且，全空间实际上是不能在有限时间被遍历的。</p><p>这些实际观察，启发作者发展一套崭新的理论去指导词向量维数的选择。下面就来说明该理论的两个基本前提。</p><p>酉变换下词向量的等价性</p><p>对于某一词向量矩阵经过酉变换得到的新矩阵，即左乘酉矩阵U（UU^T=I），我们认为它和原始词向量矩阵等价，仍然可以用作词向量。这一认识的关键在于，酉变换保持向量内积不变。而在词向量的假设中，两个词向量具体的数值不重要，而只有内积是关注的重点，因为内积表明了两个词向量对应的词之间的相似关系。既然旋转座标轴不应该改变词之间的相似关系，那么酉变换对于词向量而言就应该是一个等价变换。该文所提出的衡量词向量效果的指标，就考虑了酉变换不变性这一点。</p><p>词嵌入等价于矩阵分解</p><p>很多词嵌入模型都显示或隐式地对某个信号矩阵进行SVD分解。尤其是，skip-gram Word2Vec model 被证明等价于对PMI矩阵M的分解(Levy &Goldberg,2014)。一种等价的得到词向量算法是，首先对M做SVD分解M=UDV^T，然后将左乘矩阵U截取k维，并左乘D的前k维方阵的1/2次方，就得到词表每一项的词向量所构成的矩阵。这里的k，即为词向量维数。次方指数取1/2，是为了满足对称性需要。该文将说明，次方指数能够调节词向量模型的鲁棒性。</p><p>PIP损失（PIP loss）</p><p>PIP损失（PIP loss），即Pairwise Inner Product loss，是该文基于如上两点所提出的一种损失度量，用于评判某次训练出的词向量的好坏。它在酉变换下不变，并且是一个基于矩阵的loss。具体而言，定义PIP矩阵为词向量矩阵E和它自己转置的积，即PIP(E) = EE^T，从而可以定义两个词向量矩阵E和F之间的PIP损失（也可视为距离）为 ||PIP(E) – PIP(F)||，其中的范数是F-范数（即展平矩阵后的向量的2-范数）。</p><p>偏差-方差权衡（bias-variance trade-off）</p><p>下文将阐述本文章主要的理论结果。假设有一个真实信号矩阵M，那么基于分解M得到的d维词向量矩阵E是最优的。但实际观察到的矩阵ilde{M}=M+Z,其中加上了均值为0、方差为sigma的噪声矩阵。我们只能对ilde{M}进行分解，得到不完美的k维词向量矩阵hat{E}。相对应的算法可描述如下面几个式子：</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXJaDPtgHsJ><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RUamXJwFj6zkY7><p>我们可以利用PIP损失来度量该估计值和真值之间的误差。该文证明：</p><p>当alpha=0时，有</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXK9Iw9h5VL><p>当alpha在(0,1)时，有</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXKM5fo0Ric><p>可以看到，当维数k取得太小，会扔掉真实M谱分解的大量信号，即第一项很大；而当维数k取得太大，虽然保留了更多的原始信号，又会引入更多的随机噪声，即第一项减小时，余下的项变大。这样，最优的维数k应该是取某个中间的合适的值，以权衡偏差-方差。</p><p>鲁棒性和alpha</p><p>分析PIP损失的上界可以得知，偏差项（第一项）的指数为正（4alpha），根号内求和由最大特征值决定数量级。因此，当词向量维数k已经很大时，剩余的最大特征值也已经很小，增加k能减小的偏差是很小的。另一方面，方差项（第二项）的指数却是4alpha-2，从而当alpha小于0.5，特别的，alpha趋于0时，再增加k，这一项可能变得非常庞大，因为此时根号内求和是由最小特征值决定数量级的。<strong>从而可以得出结论，alpha越大越鲁棒</strong>。实验验证如下图。</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXKfCPJgw7H><p>特别是skip-gram Word2Vec model的alpha是0.5，恰好能保证一个亚线性增长的PIP损失上界，即这个模型能在一定程度上防过拟合，即增加维度k不会显著伤害模型表现。实际实验结果也符合上述推论，如下图。</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXSw88awR90><p>最优词向量维数</p><p>实际数据中我们无法得知真实M和噪声矩阵Z，而只观察到二者之和。该文提出可以利用统计方法来分别估计二者，用一些统计方法，可以估计噪声方差和真实信号矩阵M的各个特征值如下</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RUamXTJ4NdkgM9><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RUamXTaFsDhv9x><p>其中ilde{M}_1和ilde{M}_2是对原始矩阵ilde{M}的一个随机划分。得到估计值以后，我们可以选择与真实词向量矩阵间PIP损失最小的估计词向量矩阵的维数<strong>（注意，真实词向量矩阵是基于如上估计值得到的）。</strong></p><p>注意，用PIP损失选择最优词向量维数的优势就在于，不必再训练后续的任务，回头来判断哪个维数最优，而只需要计算矩阵间距离（PIP损失）。可以看下面一个例子。在WS353，MT771和Analogy三个任务上，使用后续任务表现来选择最优维数，其数值分别为56，102和220。可以看到，不同任务会被选择出不同的最优维数，而这些维数都落在和最优PIP损失差距为5%的区间内，即[67,218]。</p><img alt=「NeurIPS2018论文」如何确定词向量嵌入表示的维数？斯坦福提出一种快速选择方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RUamXTqDmTY0RN><p>参考文献：Zi Yin, Yuanyuan Shen. On the Dimensionality of Word Embedding. NeurIPS2018.</p><blockquote><p>AI Time第三期6月28日下午三点-五点于海淀区中关村东路搜狐大厦二楼1911（清华科技园）举行，我们邀请到了加州大学洛杉矶分校（UCLA）副教授孙怡舟、加拿大蒙特利尔学习算法研究所 (MILA)研究员唐建和中科院自动化所副研究员刘康来论道知识图谱：“知识决定智能还是智能产生知识”。</p><br></blockquote><p><strong>赶快戳下方小程序进入报名通道！</strong></p><p>学术头条已建立AI Time交流群，想进群的同学请扫描下方二维码，若群满请加学术君微信：AMiner308，记得备注：AT</p><p>[关于转载]：本文为“学术头条”原创文章。转载仅限全文转载并保留文章标题及内容，不得删改、添加内容绕开原创保护，且文章开头必须注明：转自“SciTouTiao”微信公众号。谢谢您的合作。</p><p><strong>学术头条</strong></p><p>发掘科技创新的原动力</p><p><strong>您的转发就是我们最大的动力</strong></p><p>点击阅读原文访问AMiner官网</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'NeurIPS2018','论文','确定'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>