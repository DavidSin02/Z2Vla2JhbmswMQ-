<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器不学习：深度学习训练淫技2 L1正则化和L2正则化 | 极客快訊</title><meta property="og:title" content="机器不学习：深度学习训练淫技2 L1正则化和L2正则化 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/1535372399398ea02c0c526"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/316bfb0b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/316bfb0b.html><meta property="article:published_time" content="2020-11-14T20:52:24+08:00"><meta property="article:modified_time" content="2020-11-14T20:52:24+08:00"><meta name=Keywords content><meta name=description content="机器不学习：深度学习训练淫技2 L1正则化和L2正则化"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/316bfb0b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器不学习：深度学习训练淫技2 L1正则化和L2正则化</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><p>在机器学习中，我们非常关心模型的预测能力，即模型在新数据上的表现，而不希望过拟合现象的的发生，我们通常使用正则化（regularization）技术来防止过拟合情况。正则化是机器学习中通过显式的控制模型复杂度来避免模型过拟合、确保泛化能力的一种有效方式。如果将模型原始的假设空间比作“天空”，那么天空飞翔的“鸟”就是模型可能收敛到的一个个最优解。在施加了模型正则化后，就好比将原假设空间（“天空”）缩小到一定的空间范围（“笼子”），这样一来，可能得到的最优解能搜索的假设空间也变得相对有限。有限空间自然对应复杂度不太高的模型，也自然对应了有限的模型表达能力。这就是“正则化有效防止模型过拟合的”一种直观解析。</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1535372399398ea02c0c526><p class=pgc-img-caption></p></div><p><strong>L2正则化</strong></p><p>在深度学习中，用的比较多的正则化技术是L2正则化，其形式是在原先的损失函数后边再加多一项：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15353724137567fe558f871><p class=pgc-img-caption></p></div><p>，那加上L2正则项的损失函数就可以表示为：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1535372426624094da07d48><p class=pgc-img-caption></p></div><p>，其中θ</p><p>θ就是网络层的待学习的参数，λ</p><p>λ则控制正则项的大小，较大的取值将较大程度约束模型复杂度，反之亦然。</p><p>L2约束通常对稀疏的有尖峰的权重向量施加大的惩罚，而偏好于均匀的参数。这样的效果是鼓励神经单元利用上层的所有输入，而不是部分输入。所以L2正则项加入之后，权重的绝对值大小就会整体倾向于减少，尤其不会出现特别大的值（比如噪声），即网络偏向于学习比较小的权重。所以L2正则化在深度学习中还有个名字叫做“权重衰减”（weight decay），也有一种理解这种衰减是对权值的一种惩罚，所以有些书里把L2正则化的这一项叫做惩罚项（penalty）。</p><p>我们通过一个例子形象理解一下L2正则化的作用，考虑一个只有两个参数w1和w2的模型，其损失函数曲面如下图所示。从a可以看出，最小值所在是一条线，整个曲面看起来就像是一个山脊。那么这样的山脊曲面就会对应无数个参数组合，单纯使用梯度下降法难以得到确定解。但是这样的目标函数若加上一项</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1535372459092618e014960><p class=pgc-img-caption></p></div><p>，则曲面就会变成b图的曲面，最小值所在的位置就会从一条山岭变成一个山谷了,此时我们搜索该目标函数的最小值就比先前容易了，所以L2正则化在机器学习中也叫做“岭回归”（ridge regression）。</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1535372399357aa1d9cdb7f><p class=pgc-img-caption></p></div><p><strong>L1正则化</strong></p><p>L1正则化的形式是：λ|θi|,与目标函数结合后的形式就是：L(θ)=L(θ)+λ∑in|θi|。需注意，L1 正则化除了和L2正则化一样可以约束数量级外，L1正则化还能起到使参数更加稀疏的作用，稀疏化的结果使优化后的参数一部分为0，另一部分为非零实值。非零实值的那部分参数可起到选择重要参数或特征维度的作用，同时可起到去除噪声的效果。此外，L1正则化和L2正则化可以联合使用：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153537251898831d9a0b275><p class=pgc-img-caption></p></div><p>。这种形式也被称为“Elastic网络正则化”。</p><p><strong>正则化对偏导的影响</strong></p><p>对于L2正则化：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1535372533786136b56ab07><p class=pgc-img-caption></p></div><p>，相比于未加正则化之前,权重的偏导多了一项λ/nω，偏置的偏导没变化，那么在梯度下降时ω</p><p>的更新变为：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153537239937326bf0ef4ca><p class=pgc-img-caption></p></div><p>可以看出ω的系数使得权重下降加速，因此L2正则也称weight decay(caffe中损失层的weight_decay参数与此有关)。对于随机梯度下降(对一个mini-batch中的所有x的偏导求平均)：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153537239990803f1365698><p class=pgc-img-caption></p></div><p>对于L1正则化：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1535372578420a03c4f851f><p class=pgc-img-caption></p></div><p>，梯度下降的更新为：</p><div class=pgc-img><img alt="机器不学习：深度学习训练淫技2 L1正则化和L2正则化" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15353723993642d4d58adac><p class=pgc-img-caption></p></div><p>符号函数在ω</p><p>ω大于0时为1，小于0时为-1，在ω=0时|ω|没有导数，因此可令sgn(0)=0，在0处不使用L1正则化。</p><p>L1相比于L2，有所不同：</p><ul><li>L1减少的是一个常量，L2减少的是权重的固定比例</li><li>孰快孰慢取决于权重本身的大小，权重刚大时可能L2快，较小时L1快</li><li>L1使权重稀疏，L2使权重平滑，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0</li></ul><p>实践中L2正则化通常优于L1正则化。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'正则化','机器','不学习'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>