<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器学习常用的分类器比较 | 极客快訊</title><meta property="og:title" content="机器学习常用的分类器比较 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/34161b72.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/34161b72.html><meta property="article:published_time" content="2020-10-29T21:13:00+08:00"><meta property="article:modified_time" content="2020-10-29T21:13:00+08:00"><meta name=Keywords content><meta name=description content="机器学习常用的分类器比较"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/34161b72.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器学习常用的分类器比较</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><p>传统的机器学习的监督学习分类分类和回归，分类是争对离散的数据，而回归是争对连续的数据，在数据预处理好的基础上要对数据进行预测，通常采用CV交叉验证来进行模型评价和选择。这篇文章通过连续的数据结合sklearn库对各种回归器做一比较：</p><p>1.linear regression</p><p>缺点：顾名思义，linear regression是假设数据服从线性分布的，这一假设前提也限制了该模型的准确率，因为现实中由于噪声等的存在很少有数据是严格服从线性的。</p><p>优点：基于这种假设，linear regression可以通过normal equation求闭合解的方式求得y_predict</p><p>2.logistic regression</p><p>缺点：从线性回归衍生而来，将线性的值域通过sigmoid函数压缩在（0,1）范围内，缺点同linear regression，且也是要求数据是无缺失的</p><p>优点：有两种方式求解，精确的解析解和SGD算法估计，在要求准确性时使用解析解，在要求时间效率时使用SGD 迭代</p><p>3.SVM（支持向量机 ）</p><p>缺点：计算代价比较大，SVM是将低维无序杂乱的数据通过核函数（RBF,poly，linear，sigmoid）映射到高维空间，通过超平面将其分开</p><p>优点：SVM是通过支撑面做分类的，也就是说不需要计算所有的样本，高维数据中只需去少量的样本，节省了内存</p><p>在sklearn默认配置中三种核函数的准确率大概是：RBF>poly>linear</p><p>4.Naive Bayes</p><p>缺点：这一模型适合用在文本样本上，采用了朴素贝叶斯原理假设样本间是相互独立的，因此在关联比较强的样本上效果很差</p><p>优点：也是基于其独立的假设，概率计算大大简化，节省内存和时间</p><p>5.K近邻</p><p>缺点：k需要人为设定，且该算法的复杂度很高</p><p>优点：“近朱者赤，近墨者黑”KNN是无参数训练的模型</p><p>6.决策树（DT）</p><p>缺点：在训练数据上比较耗时</p><p>优点：对数据要求度最低的模型，数据可以缺失，可以是非线性的，可以是不同的类型，，最接近人类逻辑思维的模型，可解释性好</p><p>7.集成模型（众志成城模型）</p><p>random forest：随机抽取样本形成多个分类器，通过vote，少数服从多数的方式决定最终属于多数的分类器结果，分类器之间是相互去之间关联的</p><p>gradient boost：弱弱变强，最典型的代表是adaboost（三个臭皮匠，顶个诸葛亮），弱分类器按照一定的计算方式组合形成强的分类器，分类器之间存在关联，最终分类是多个分类器组合的结果</p><p>一般地，GB>RF>DT</p><p>但是集成模型缺点在于受概率的影响，具有不确定性</p><p>以上是常用的回归分类器的比较，在知道各种分类器的优缺点之后就可以使用正确的分类器完成自己的数据处理，如下表是通过计算各类分类器的残差来对比同一任务不同分类器之间的好坏，可以看出来在sklearn默认参数的前提下，准确率排序是：集成模型>DT>SVM>KNN>Linear</p><p>分类回归器 导入python库命令 导入函数命令 残差（%）</p><p>linear regression from sklearn.linear_model import LinearRegressor lr = LinearRegressor() 5.223</p><p>SGD regression penalty L2 from sklearn.linear_model import SGDRegressor SGDR = SGDRegressor("penalty = l2") 5.780</p><p>SGD regression penalty L1 SGDR = SGDRegressor("penalty = l1") 5.765</p><p>SVR(rbf kernel) from sklearn .svm import SVR</p><p>（Penalty parameter ：C，Kernel coefficient ：gamma） SVR = SVR(kernel="rbf") 0.627</p><p>SVR(sigmoid kernel) SVR = SVR(kernel="sigmoid ") 82.507</p><p>SVR(poly kernel) SVR = SVR(kernel="poly") 20.862</p><p>SVR(linear kernel) SVR = SVR(kernel="linear") 6.451</p><p>KNN（n=5，weights=uniform） from sklearn.neighbors import KNeighborsRegressor knn = KNeighborsRegressor（n=5，weights="uniform"） 0.731</p><p>KNN（n=5，weights=distance） knn = KNeighborsRegressor（n=5，weights="distance"） 1.087</p><p>DT from sklearn.tree import DecisionTreeRegressor DT = DecisionTreeRegressor() 0.447</p><p>Random forest from sklearn.ensemble import RandomForestRegressor RF = RandomForestRegressor() 0.270</p><p>Extra Trees from sklearn.ensemble import ExtraTreesRegressor ET = ExtraTreesRegressor() 0.246</p><p>Gradient Boosting from sklearn.ensemble import GradientBoostingRegressor GB = GradientBoostingRegressor() 0.284</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'机器','学习','分类器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>