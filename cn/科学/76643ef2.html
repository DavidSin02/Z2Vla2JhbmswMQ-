<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度学习训练数据的评估与数据增强 | 极客快訊</title><meta property="og:title" content="深度学习训练数据的评估与数据增强 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/85ac7dab7c6d41b2b0725f2a70be0bec"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/76643ef2.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/76643ef2.html><meta property="article:published_time" content="2020-11-14T20:51:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:51:54+08:00"><meta name=Keywords content><meta name=description content="深度学习训练数据的评估与数据增强"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/76643ef2.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度学习训练数据的评估与数据增强</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><blockquote><p><strong>引用：</strong>Junhua Ding ; XinChuan Li ; Venkat N. Gudivada,2017 IEEE International Conference on Big Data (Big Data),11-14 Dec. 2017</p></blockquote><h1><strong>关键词</strong></h1><p>大数据; 机器学习; 神经网络; 深度学习; 卷积神经网络; 支持向量机; 衍射图像</p><h1><strong>摘要</strong></h1><p>深度学习是从大数据中提取价值的重要技术。然而，我们需要大量高质量的训练数据保证深度学习的有效性。在许多情况下，训练数据的大小不足以有效地训练深度学习分类器。数据增强是一种用于增加训练数据量的广泛采用的方法，但数据增强后数据的质量可能有问题，因此，对数据进行系统评估至关重要。此外，如果训练数据有噪声，则必须自动分离出噪声数据。在本文中，我们提出了一种深度学习分类器，用于自动将良好的训练数据与噪声数据分离。为了有效地训练深度学习分类器，我们需要转换原始训练数据以适应分类器的输入格式。我们研究了不同的数据增强方法，以从有限大小的原始训练数据生成足够数量的训练数据，通过使用不同的分类算法对分类精度进行交叉验证来评估训练数据的质量。我们还检查每个数据项的图像并比较数据集的分布。 我们通过对大规模生物医学图像的自动分类的实验研究证明了所提出的方法的有效性。 我们的方法是通用的，很容易适应其他大数据域。</p><p><strong>关键词</strong>：大数据; 机器学习; 神经网络; 深度学习; 卷积神经网络; 支持向量机; 衍射图像</p><h1>介绍</h1><p>我们需要可扩展的高性能数据处理基础架构和分析工具来从大数据中提取价值。例如，深度学习算法和GPU已被广泛用于分析大数据。数据集的规模和质量决定了从大数据中有效提取价值的难度，可用于训练算法的数据通常不够大。现在，通过将现有数据项转换为新数据的方法来进行数据扩增是一种广泛使用的实践，但是，很难确定数据扩增后是否有效。我们有必要使用转换的方法系统地评估生成的数据的质量。生成的训练数据也可能包括有错误标记数据形式的噪声。</p><p>已发表的研究表明，训练数据集中的异常和噪声可能会显著降低数据分析的性能和准确性。为了解决这些问题，我们有两种选择：设计强大的机器学习算法，可以处理嘈杂的训练数据，或通过滤波提高数据质量。</p><p>机器学习算法已被用于检测来自多个源的数据中的重复数据。数据过滤是一种通过噪声消除来提高数据质量的方法。数据发布者和订阅者可以使用域模型来过滤噪声数据。由于大数据的规模巨大，自动过滤数据至关重要。然而，朝这个方向的研究才刚刚开始出现。</p><p>在本文中，我们介绍了一种从生物医学图像数据集中分离噪声数据的系统方法，以便从大数据中提取信息。更具体地说，我们开发了一种机器学习方法，用于从数据集中分离无效和有噪声的数据。我们的方法包括使用深度学习分类器迭代地将噪声数据与常规数据分离的p-DIFC可以获得每秒近100个细胞的衍射图像。 使用p-DIFC，我们为不同类型的细胞收集了超过一百万个衍射图像。我们通过使用不同的分类算法对分类精度进行交叉验证来评估数据质量。我们还检查每个数据项的图像并比较它们的分布。</p><p>我们描述了我们提出的方法，并通过将生物细胞的衍射图像分成几个类别（包括噪声类别）来证明其有效性。 我们使用偏振衍射图像流式细胞仪（p-DIFC）获取细胞的衍射图像，其用于定量和分析单细胞的3D形态，这些特征用于精确分类细胞类型。p-DIFC每秒可以获得近100个细胞的衍射图像。 使用p-DIFC，我们为不同类型的细胞收集了超过一百万个衍射图像。</p><h1>细胞衍射图像：</h1><p>文献中已经讲述了使用机器学习对细胞衍射图像进行分类的工作。然而，p-DIFC成像可包括许多不是细胞的颗粒，例如鬼细胞体，聚集的球形颗粒（又称破裂的细胞），以及细胞碎片和小颗粒（统称为碎片）。我们将具有完整结构的活细胞称为细胞。从非细胞的颗粒获得的衍射图像也被收集到衍射图像数据集中，这些衍射图像包括噪声数据。</p><p>为了精确地对细胞进行分类，有必要将非细胞衍射图像（即，噪声）与细胞衍射图像分离。从实际角度来看，手动将噪声图像与细胞图像分离是不可行的。为了解决这个问题，我们开发了一种深度学习方法，用于衍射图像的自动分类。我们将衍射图像分为三类：细胞，破碎细胞和碎片。我们使用基于AlexNet [9]和TensorFlow框架的深度学习架构开发了分类器。我们使用细胞，破碎细胞和碎片的衍射图像训练了分类器。</p><p>原始8位灰度级p-DIFC衍射图像的尺寸是640×480像素。由于AlexNet使用大小的图像是227x227像素，我们调整原始衍射图像的大小为227x227。由于用于衍射图像的AlexNet分类器需要大量的训练图像，我们开发了一种从原始图像生成几个小衍射图像（又名增强衍射图像）的方法。通过<strong>n倍交叉验证（NFCV）</strong>和<strong>混淆矩阵</strong>来交叉检查分类精度。为了检查训练数据的质量，我们使用支持向量机（SVM）对三类衍射图像进行分类。我们先分别在原始和增强衍射图像数据集上训练分类器，然后比较分类的精度。我们还研究了小图像是否能够捕获足够的形态信息作为数据集原始图像，因此我们要求每个小图像与其原始图像不同。 此外，我们希望从同一原图生成的所有小图像都表现出不同的文本模式。最后，我们检查原始数据集和增强数据集中选定的特征值的分布，以确定它们是否一致。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/85ac7dab7c6d41b2b0725f2a70be0bec><p class=pgc-img-caption></p></div><p>图1. A. p-DIFC的光散射图 B.软件模拟衍射图像 C. p-DIFC获得的衍射图像。</p><h1>衍射图像的自动分类:</h1><p>我们首先讨论基于形态学的细胞分类，然后使用SVM和深度学习技术进行衍射图像的自动分类。</p><p><strong>A.基于形态学的细胞分类</strong></p><p>细胞通过细胞内细胞器表现出高度变化和卷曲的三维（3D）结构，以维持表型变异和功能。细胞分类对生物学和生命科学研究具有重要意义。 p-DIFC用于从单个细胞快速获取交叉极化衍射图像（p-DI）对，它采用斯托克斯矢量和穆勒矩阵来解释由于折射率，n（r，λ）或其3D形态的细胞内分布导致的散射光的偏振变化。入射光及其偏振态由斯托克斯矢量（I0，Q0，U0，V0）表示，其沿z轴传播。同样的，散射光及其偏振沿（Θs，Φs）方向表示状态向量（Is，Qs，Us，Vs），如图1所示。与非相干光获取的图像不同，p-DI 由于入射激光束引起的细胞内分子偶极子发出的相干光散射，这些对呈现出特征模式。 因此，p-DI数据提供了探测照射细胞的3D形态的数据源，其需要机器学习技术来提取形态学和分子信息。</p><p>在过去十年中，丁先生等人开发了不同的用于细胞衍射图像的快速和准确的细胞形态学分析的机器学习方法，其中包括支持向量机（SVM）和深度学习方法。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/b09f2697754b4830951c4058c344dece><p class=pgc-img-caption></p></div><p>图2.p-DIFC获得的衍射图像（a）完整结构的活细胞，（b）重影细胞体或聚集的球形颗粒，和（c）细胞碎片或小颗粒。 右上角显示每个图像的相应粒子。</p><p><strong>B.数据集</strong></p><p>一个使用p-DIFC获取的衍射图像的集合可以包括从非常规细胞获取的图像，尤其是样本中的破碎细胞和碎片。对于一些研究项目，人们只需要正常的细胞图像，然而对于其他一些研究，如细胞凋亡研究，我们只需要破碎的细胞图像。因此，有必要建立一种工具来自动分离三种类型的衍射图像。三种类型的细胞颗粒具有不同的形态结构，其在p-DIFC衍射图像中精确捕获。使用这些文本模式，生物学家可以在视觉上分离这三种类型的图像。图2显示了样品p-DIFC衍射图像及其相应的颗粒。完整结构的活细胞的衍射图像的文本图案包含许多明亮的正常斑点，一个鬼细胞体或聚集的球形颗粒则包括亮条，最后，细胞碎片或小颗粒显示出许多大的漫射斑点。</p><p>三类衍射图像的文本模式的差异足以使用机器学习算法来分离这三个类别。</p><p>我们使用p-DIFC为三类粒子获得了许多衍射图像，然后选择了数千个衍射图像作为初始数据集。对于实验研究，我们选择了总共7519个衍射图像，然后手动检查每个衍射图像并标记其类别。正常细胞被标记为细胞，破碎细胞被标记为条带，碎片被标记为碎片。初始图像数据集由2232个正常细胞，1645个破碎细胞和3642个碎片组成。衍射图像的每个类别存储在单独的目录中。我们注意到一些衍射图像可能被错误地标记，而另一些衍射图像由于视觉质量低而难以标记。</p><p><strong>C.以SVM为基础的图片分类</strong></p><p>SVM通常执行二进制分类。 为了实现多类分类，通过比较“一个与其余”或“一个与一个”来组合几个SVM分类。 我们使用LIBSVM 实现了衍射图像的分类，这是一个用于SVM的开源工具包。</p><p>衍射图像的文本模式是使用一组灰度层协作矩阵（GLCM）特征定义的。 我们总共使用了20个功能 - 其中14个是原始图像的特征，6个是扩展图像的特征。 每个特征的定义都可以在丁先生先前的工作中找到。 下面给出了为衍射图像构建SVM分类器的过程：</p><ol><li>计算训练和测试数据集中每个衍射图像的GLCM特征。</li><li>用其类别（例如其细胞类型）标记每个衍射图像，并构建由其GLCM特征值及其标记组成的特征向量。 数据集中所有衍射图像的特征向量形成特征矩阵。</li><li>使用选择的kernel和训练数据集的特征矩阵训练SVM分类器。</li><li>使用测试数据集中的衍射图像测试分类器，并使用诸如N倍交叉验证（NFCV）和混淆矩阵之类的标准验证分类性能。</li></ol><p>我们使用衍射图像数据集构建了SVM分类器。 我们为三个类别中的每一个选择了1000个衍射图像，并使用GLCM特征值和相应的类型构建了特征矩阵。 每个特征向量包括16个GLCM特征值，因为一个特征的值全部为0，而另外三个特征是在图像格式上定义的，本研究中未对其进行说明。 细胞，碎片和条带的10倍交叉验证（10FCV）的平均分类准确度分别为74.50％，81.50％和62.00％。 简化的混淆矩阵如表I所示[16]。</p><p>为了提高SVM分类器的分类精度，我们尝试了许多不同的技术，例如使用图像处理和聚类分析技术预先选择图像或者是特征选择。 我们最近的实验表明，深度学习方法极大地提高了分类准确性。</p><p><strong>D.基于机器学习的分类器</strong></p><p>衍射图像数据集由于其低分辨率和没有背景噪声的原因相对简单。 因此，我们选择了在Tensor-Flow框架中实现的AlexNet模型来构建深度学习分类器。 由于深度学习需要大量特征，因此训练数据集的大小也很大。</p><p>AlexNet使用大约120万张图像进行训练。 我们没有使用预先训练过的AlexNet，而只使用了它的网络架构。 我们只收集了7519个原始衍射图像，这些图像不足以训练AlexNet。因此，我们使用数据增强方法来生成更大的训练数据集。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fa3da08cd3c745b0b8e456dea95b0383><p class=pgc-img-caption></p></div><p><strong>E.数据增强</strong></p><p>单元的原始衍射图像的尺寸是640×490。它足够大，可以分成几个大小为227x227像素的小图像，这是AlexNet输入图像的尺寸。精心选择的子图像可以具有足够的信息来代表整个图像。衍射图像还可以包括大的黑色背景，其对于分类是无用的。因此，需要一种用于产生小图像的严格方法。该性质可以通过图7中所示的衍射图像进一步证实，其通过使用DDA（光散射模拟程序）模拟散射体的光散射而产生。</p><p><strong>F.裁剪图像</strong></p><p>如前所述，AlexNet接受输入图像的尺寸为227x227像素，而原始衍射图像的尺寸是640×480像素。因此，小图像约为原始图像尺寸的1/5。此外，由于衍射图像可能包含显著的黑色区域，因此文本图案的中心（例如亮斑点或条带）可能不是图像的中心。我们需要找到文本模式区域的中心来执行裁剪，裁剪通常是图像中最亮的区域。</p><p>使用5x5像素窗口，裁剪程序计算窗口的平均亮度。然后，它将窗口逐步滑动几个像素以覆盖整个图像，以确定具有最大平均亮度的窗口。例如，8位分辨率图像的亮度范围是从0到255，将平均亮度最大的窗口设置为裁剪小图像的中心。如果多个窗口具有最大的平均亮度，则选择距离边界最远的窗口作为中心。首先从中心周围的原始图像中裁剪出一个小图像，然后通过从中心向任意方向的某些像素滑动窗口来裁剪更小的图像，如图3所示。</p><p><strong>G.池化图像</strong></p><p>裁剪技术不适用于整个图像都对分类至关重要的情况。在这种情况下，从局部区域提取的局部特征不足以表示从整个图像中提取的全局特征。从有限数量的原始图像产生训练数据需要不同的技术。我们尝试了一种用于生成大量训练数据的池化技术。使用池化将原始衍射图像下采样为小图像。可以从具有不同池化配置的原始图像生成多个小图像。此外，可以使用不同的池函数（如最大池或平均池）生成小图像。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c14c71cff58641a78a996369feff0366><p class=pgc-img-caption></p></div><p>图4.衍射图像及其池化图像（a）细胞，（b）碎片，（c）破碎的细胞，（d）是（a）池化后的细胞，（e）是（b）池化后的碎片，和（f）是（c）池化后的破碎细胞。</p><p>我们已经尝试了三种池功能，包括平均池，最大池和最小池。 但是，数据集仅使用相同的池功能。 三个不同数据集的实验结果将在下一节中讨论。</p><p><strong>H.实验结果</strong></p><p>所有实验均在相同的原始细胞衍射图像，破碎细胞和碎片上进行。 三个图像类别存储在三个不同的文件夹中，然后对每个图像应用裁剪或池化，以生成每个类别约100,000个小图像并为其标记。 小图像根据其标签/类别存储在三个文件夹中。 8FCV和混淆矩阵用于验证分类结果。 我们已经进行了许多实验来检查和验证分类精度，但我们将仅描述本节中的重要结果。</p><p>1）裁剪图像的实验结果：8FCV显示正常细胞的平均分类准确度为99.36％，碎片为97.74％，断裂细胞为99.81％。图5显示了4组的混淆矩阵。从8FCV结果来看，我们注意到基于AlexNet的分类器可以有效地对衍射图像的类别进行分类。此外，从原始图像生成的数据集足以训练分类器。</p><p>2）使用池化图像的实验结果：基于使用平均池化生成的数据集的分类的8FCV结果显示碎片和条带的平均分类精度略高于通过裁剪建立的数据集。然而，细胞的平均分类准确度要低得多，为85.7％ vs 94.22％。如表II所示，近10％的细胞被错误地分类为碎片，只有4.5％的细胞被错误地分类为条带。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e35c047a84574c7ea20f7ab5a530f051><p class=pgc-img-caption></p></div><h1>评估数据增强的质量</h1><p>在本节中，我们将讨论如何使用裁剪或池化技术系统地评估从原始衍射图像生成的数据集的质量。 我们使用代表性，准确性和多样性来评估数据集。 代表性意味着数据集包括原始数据集中的所有信息，并且它可以表示用于训练机器学习分类器的原始数据集。 准确度是指生成的数据项无法与原始源区分开的事实。 多样性意味着增强数据集应该可以用于不普遍的特征。 对于衍射图像案例的研究中，我们首先研究了小尺寸衍射图像是否可以使用基于SVM算法对衍射图像进行分类，实现与原始图像相似的精度。然后我们检查了小图像的文本模式，以确保小图像可以捕获足够的形态信息作为其原始图像。最后，我们比较了增强数据集和原始图像数据集的特征值的分布。</p><p>A.检查SVM分类器的分类准确性</p><p>B.检查衍射图像中的文本模式</p><p>C.检查数据集中的特征图像</p><p>我们的实验表明，任何小的衍射图像都可以准确地表示其原始衍射图像的分类。深度学习分类器总是将小图像分类为与源衍射图像相同的类别，这是一件好事，但与此同时，有必要检查小图像对培训效果的贡献。如果来自原始图像的小图像具有相同的特征值，则这些图像对于训练是多余的。因此，有必要检查这些小图像区域的特征值有多接近。我们在最后一个全连接层上收集输出，其中包括AlexNet中的4096个特征，然后我们比较两个输入衍射图像之间的特征值。虽然找到两个特征向量之间的差异并不困难，但计算两个特征向量之间的差异是相当具有挑战性的，因为每个特征都不是简单的标量参数。因此，我们使用不同的方法来评估小衍射图像。由于文本模式对于衍射图像的分类是必不可少的，我们可以检查两个图像之间的<strong>GLCM</strong>特征值的差异。如果小图像的GLCM特征值与其原始图像不同，我们还需要检查小图像的数据集的分布以及原始图像的数据集的分布。如果由相同原始图像产生的小衍射图像的GLCM特征值不同，则小图像的数据集的GLCM特征的分布与原始图像的数据集的GLCM特征的分布一致。我们相信小图像的数据集很好地代表了原始图像，并有助于训练的泛化。</p><p>1）比较衍射图像的GLCM特征值：我们首先计算每个衍射图像的GLCM特征值，并将小图像与其原始图像组合在一起。然后我们比较了一组中所有图像的每个GLCM特征。如果两个图像具有至少一个GLCM特征不同，则认为这两个图像不同。表V显示了6个GLCM特征中合并的小图像及其原始图像的部分比较结果。 Img 1至Img 5是来自原始图像Img 0的合并图像。我们检查了每组图像，没有在每组中找到两个相同的图像。</p><p>2）比较数据集的GLCM特征分布：我们为属于同一类型的所有原始图像创建了GLCM特征的分布。然后，我们为从原始图像生成的一组小图像创建了相同的分布。我们比较了两个分布，看看分布是否一致。图9展示了原始衍射图像数据的GLCM特征与从原始衍射图像数据合并的小衍射图像之一的正态分布的比较。</p><p>我们使用归一化的特征值（即最小-最大归一化），均值和标准差创建了正态分布，并且基于概率质量函数绘制了曲线。很难看出这两个分布并不完全相同。但是，它们都是正常分布的。使用相同的分布检查不同的GLCM特征和不同的组图像，我们发现原始图像的数据集与合并的数据集或原始图像中的裁剪图像之间的分布模式是一致的。因此，我们得出结论，池化和裁剪对于衍射图像的数据增强都是有效的。</p><div class=pgc-img><img alt=深度学习训练数据的评估与数据增强 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e6c4fe15315a423c91ce5fca0a692545><p class=pgc-img-caption></p></div><p>图9 比较原始图像的数据集的GLCM和从原始图像合并的小图像的数据集特征值的分布。</p><h1><strong>总结</strong></h1><p>训练深度学习模型通常需要大量高质量的训练数据，然而大量训练数据可能包括噪声数据。因此，有必要将噪声数据与训练数据分开。在本文中，我们提出了一种深度学习方法，用于将训练数据自动分类为不同类别的数据，其中一种是噪声类别。在许多情况下，需要将原始训练数据转换为满足深度学习模型的输入大小要求，在其他情况下，由于原始数据的大小不足，因此需要通过数据增强来获取新数据。我们讨论了不同的数据增强方法。我们还通过交叉验证评估了培训数据的质量。</p><p>为了证明所提出的数据增强方法有效，我们对大规模衍射图像的自动分类进行了全面的实验研究。从该实验研究中收集的建议方法和经验可用于数据增强和其他领域的大数据评估。</p><h1>参考文献</h1><p>[1]J. Gao, C. Xie, and C. Tao, “Big data validation and quality assurance</p><p>– issuses, challenges, and needs,” in <em>2016 IEEE Symposium on Service- Oriented System Engineering (SOSE)</em>, March 2016, pp. 433–441.</p><p>[2]J. Ding, D. Zhang, and X. Hu, “An application of metamorphic testing for testing scientiﬁc software,” in <em>1st Intl. workshop on metamorphic testing with ICSE</em>, Austin, TX, May 2016.</p><p>[3] J. Ding, X. Kang, X. H. Hu, and V. Gudivada, “Building a deep learning classiﬁer for enhancing a biomedical big data service,” in <em>2017 IEEE Intl. Conf. on Services Computing</em>, Honolulu, HI, June 2017.</p><p>[4] J. Ding, J. Wang, X. Kang, and X. Hu, “Building an svm classiﬁer for automated selection of big data,” in <em>2017 IEEE International Congress on Big Data</em>, Honolulu, HI, 2017.</p><h1><strong>致谢</strong></h1><p>此文由南京大学软件学院2016级本科生何天行翻译转述。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'数据','学习','训练'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>