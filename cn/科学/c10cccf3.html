<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码） | 极客快訊</title><meta property="og:title" content="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/07ba2801bb4a4fcba38ad8ba8d575696"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c10cccf3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c10cccf3.html><meta property="article:published_time" content="2020-11-14T20:58:34+08:00"><meta property="article:modified_time" content="2020-11-14T20:58:34+08:00"><meta name=Keywords content><meta name=description content="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/c10cccf3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><p>采用TensorFlow 实现一个全连接的深度神经往，拟合正弦函数。</p><p>正弦函数的公式：y = sin(x)</p><p>下面具体操作是在本地 Jupyter Notebook 环境中完成的，对Jupyter Notebook 不熟悉的同学，可以参考下面的链接。</p><p><a class=pgc-link data-content=mp href="https://www.toutiao.com/i6713091746764423692/?group_id=6713091746764423692" target=_blank>Windows下的Jupyter Notebook 安装与自定义启动（图文详解）</a></p><p><a class=pgc-link data-content=mp href="https://www.toutiao.com/i6705855555849683469/?group_id=6705855555849683469" target=_blank>Jupyter Notebook神器-免费体验来自微软的Azure Notebook</a></p><div class=tt-column-card data-content='{"new_thumb_url": "http://sf1-ttcdn-tos.pstatp.com/img/pgc-image/1554257239510c388d75d26", "title": "TensorFlow\u6df1\u5ea6\u5b66\u4e60\u5b9e\u8df5", "distribution_user_id": 1593359982664708, "price": 147, "column_id": "6675492781865042180", "share_price": 35.28, "author_description": "AI\u706b\u7bad\u8425", "thumb_url": "http://p2.pstatp.com/large/pgc-image/1554257239510c388d75d26", "sold": 38}'></div><h1><strong>1. 需要构建的TensorFlow网络结构</strong></h1><p>下面要构建的模拟正弦函数的神经网络，包含3个隐藏层，每个隐藏层16个隐藏节点，单变量输入，单变量输出，各层的激活函数都采用 sigmoid函数，需要构建的网络结构如下图所示。</p><div class=pgc-img><img alt="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/07ba2801bb4a4fcba38ad8ba8d575696><p class=pgc-img-caption></p></div><h1><strong>2. 绘制标准的sin曲线</strong></h1><p>下面实现绘制标准的正弦函数，之后标准的正弦函数和模拟结果都采用 pylab.plot 画到图上，方便做对比。</p><div class=pgc-img><img alt="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d2034f39eb4244c8a9dbd3ec89b2702a><p class=pgc-img-caption></p></div><p><strong>具体代码：</strong></p><p>导入相应的Python包和模块。</p><blockquote><p>import tensorflow as tf</p><p>import math</p><p>import numpy as np</p><p>import matplotlib.pyplot as plt</p><p>import pylab</p></blockquote><p>定义draw_sin_line() 函数，该函数用来绘制标准的sin曲线。</p><blockquote><p>def draw_sin_line():</p><p>'''</p><p>绘制标准的sin曲线</p><p>'''</p><p>x = np.arange(0, 2*np.pi, 0.01)</p><p>x = x.reshape((len(x), 1))</p><p>y = np.sin(x)</p><p>pylab.plot(x, y, label='标准的sin曲线')</p><p>plt.axhline(linewidth=1, color='r')</p><p>plt.axvline(x=np.pi, linestyle='--', linewidth=1, color='g')</p></blockquote><p>pylab将所有的功能函数（pyplot状态机函数，大部分是 numpy里面的函数）全部导入其单独的命名空间内。为什么要这样做，是因为这样可以很好地与ipython（或者类似的IDE，比如pycharm）实现很好的交互模式。</p><p>上面调用 pylab的plot函数绘制曲线，pylab是python下挺不错的一个画图模块，使用也非常简单。</p><p>plt.axhline()函数，绘制平行于x轴的水平参考线。</p><p>plt.axvline()函数，绘制平行于y轴的垂直参考线。</p><h1><strong>3. 创建训练样本</strong></h1><p>定义 get_train_data() 函数，返回一个训练样本(train_x, train_y)，其中 train_x 是随机的自变量，train_y 是train_x 的sin函数值。</p><p><strong>具体代码如下：</strong></p><blockquote><p>def get_train_data():</p><p>'''</p><p>返回一个训练样本(train_x, train_y)</p><p>其中 train_x 是随机的自变量，train_y 是train_x 的sin函数值</p><p>'''</p><p>train_x = np.random.uniform(0.0, 2*np.pi, (1))</p><p>train_y = np.sin(train_x)</p><p>return train_x, train_y</p></blockquote><p>函数原型： numpy.random.uniform(low,high,size)</p><p>功能：从一个均匀分布[low,high)中随机采样，注意定义域是左闭右开，即包含low，不包含high.</p><p>参数介绍:</p><p>low: 采样下界，float类型，默认值为0；</p><p>high: 采样上界，float类型，默认值为1；</p><p>size: 输出样本数目，为int或元组(tuple)类型，例如，size=(m,n,k), 则输出m*n*k个样本，缺省时输出1个值。</p><p>返回值：ndarray类型，其形状和参数size中描述一致。</p><h1><strong>4. 定义推理函数inference</strong></h1><p>构建TensorFlow 网络结构的逻辑在 inference() 函数中实现。</p><p>其中，构建了3个隐藏层，每个隐藏层16个节点，连接节点的参数 weight 和 bias的初始化是均值为0、方差为1的随机初始化，每个隐藏层的单位采用 tf.sigmoid() 作为激活函数，输出层中没有增加 sigmoid函数，这是因为前面的几层非线性变换已经提取好了足够充分的特征，使用这些特征已经可以让模型用最后一个线性分类函数来分类。</p><p>具体代码如下：</p><blockquote><p>def inference(input_data):</p><p>'''</p><p>定义前向计算的网络结构</p><p>args: 输入x的值，单个值</p><p>'''</p><p>with tf.variable_scope('hidden1'):</p><p># 第一个隐藏层，采用16个隐藏节点</p><p>weights = tf.get_variable("weight", [1, 16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>biases = tf.get_variable("bias", [1, 16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>hidden1 = tf.sigmoid(tf.multiply(input_data, weights) + biases)</p><p>with tf.variable_scope('hidden2'):</p><p># 第二个隐藏层，采用16个隐藏节点</p><p>weights = tf.get_varaible("weight", [16, 16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>biases = tf.get_variable("bias", [16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>mul = tf.matmul(hidden1, weights)</p><p>hidden2 = tf.sigmoid(mul + biases)</p><p>with tf.variable_scope('hidden3'):</p><p># 第三个隐藏层，采用16个隐藏节点</p><p>weights = tf.get_varaible("weight", [16, 16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>biases = tf.get_variable("bias", [16], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>mul = tf.matmul(hidden2, weights)</p><p>hidden3 = tf.sigmoid(mul + biases)</p><p>with tf.variable_scope('output_layer'):</p><p># 输出层</p><p>weights = tf.get_varaible("weight", [16, 1], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>biases = tf.get_variable("bias", [1], tf.float32, initializer=tf.random_normal_initializer(0.0, 1))</p><p>output = tf.matmul(hidden3, weights) + biases</p><p>return output</p></blockquote><p>如果变量存在，函数tf.get_variable( ) 会返回现有的变量。如果变量不存在，会根据给定形状和初始值创建变量。</p><p>初始器（initializer）= tf.random_normal_initializer(0.0, 1) 是其中一种内置的初始器。</p><h1><strong>5. 定义训练函数</strong></h1><p>使用TensorFlow 实现神经网络时，需要定义网络结构、参数、数据的输入和输出、采用的损失函数和优化方法。</p><p>最繁琐的训练中的反向传播、自动求导和参数更新等操作由TensorFlow 负责实现。</p><p><strong>具体代码如下，代码中有详细的注释：</strong></p><blockquote><p># 通过梯度下降将损失最小化</p><p>def train():</p><p># 学习率</p><p>learning_rate = 0.01</p><p>x = tf.placeholder(tf.float32)</p><p>y = tf.placeholder(tf.float32)</p><p># 基于训练好的模型推理，获取推理结果</p><p>net_out = inference(x)</p><p># 定义损失函数的op</p><p>loss_op = tf.square(net_out - y)</p><p># 采用随机梯度下降的优化函数</p><p>opt = tf.train.GradientDescentOptimizer(learning_rate)</p><p># 定义训练操作</p><p>train_op = opt.minimize(loss_op)</p><p># 变量初始化</p><p>init = tf.global_variables_initializer()</p><p>with tf.Session() as sess:</p><p># 执行变量的初始化操作</p><p>sess.run(init)</p><p>print("开始训练 ...")</p><p>for i in range(100001):</p><p># 获取训练数据</p><p>train_x, train_y = get_train_data()</p><p>sess.run(train_op, feed_dict={x: train_x, y: train_y})</p><p># 定时输出当前的状态</p><p>if i % 10000 == 0:</p><p>times = int(i/10000)</p><p># 每执行10000次训练后，测试一下结果，测试结果用 pylab.plot()函数在界面上绘制出来</p><p>test_x_ndarray = np.arange(0, 2 * np.pi, 0.01)</p><p>test_y_ndarray = np.zeros([len(test_x_ndarray)])</p><p>ind = 0</p><p>for test_x in test_x_ndarray:</p><p>test_y = sess.run(net_out, feed_dict={x: test_x, y: 1})</p><p># 对数组中指定的索引值指向的元素替换成指定的值</p><p>np.put(test_y_ndarray, ind, test_y)</p><p>ind += 1</p><p># 先绘制标准的正弦函数的曲线</p><p># 再用虚线绘制出模拟正弦函数的曲线</p><p>draw_sin_line()</p><p>pylab.plot(test_x_ndarray, test_y_ndarray, '--', label = str(times) + ' times')</p><p>pylab.legend(loc='upper right')</p><p>pylab.show()</p><p>print("=== DONE ===")</p></blockquote><p>从输入数据到神经网络，到输出预测值，采用预测值和标准值的差的平方作为损失函数，然后将得到的损失函数的操作 loss_op 传给随机梯度下降优化方法 tf.train.GradientDescentOptimizer，从而得到最后训练操作 train_op。</p><p>在会话的run 方法中，传入训练数据，每一次执行 train_op，就会根据输入的训练样本做一次前向计算、一次反向传播和一次参数更新。</p><p>每训练10000个样本，就将标准的正弦函数和模拟结果采用 pylab.plot()函数绘制出来做对比，其中用实线表示标准的正弦函数，虚线表示模拟的正弦函数（也就是基于神经网络推理的结果）。</p><h1><strong>6. 开始验证训练函数</strong></h1><p>执行 train() 函数，就开始训练并验证。</p><p>第一次的参数是随机初始化的，模拟出来的正弦函数和标准的正弦函数完全不一样。</p><div class=pgc-img><img alt="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c74f1f4fd94c4bada38e5844a412513a><p class=pgc-img-caption></p></div><p>神经网络模型经过训练 10000次之后，测试结果如下。此时，模拟曲线（虚线）开始向实线靠近了。</p><div class=pgc-img><img alt="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0413a84c975c40a6b2dabc0865c7b812><p class=pgc-img-caption></p></div><p>下面是训练到 10000x10次之后，结果如下。此时，模拟曲线基本上和标准的正弦曲线重合了。</p><div class=pgc-img><img alt="TensorFlow 训练深度神经网络拟合正弦函数的详细过程（含代码）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fc45228a6421489e86b0b4968610672f><p class=pgc-img-caption></p></div><div class=tt-column-card data-content='{"new_thumb_url": "http://sf1-ttcdn-tos.pstatp.com/img/mosaic-legacy/fe3f00002562ef2bf82e", "title": "\u6bcf\u5929\u4e94\u5206\u949f\u73a9\u8f6cpython\u57fa\u7840\u7f16\u7a0b", "distribution_user_id": 1593359982664708, "price": 16.6, "column_id": "1626154665784323", "share_price": 5.31, "author_description": "\u5e7b\u98ce\u7684AI\u4e4b\u8def", "thumb_url": "http://p10.pstatp.com/large/mosaic-legacy/fe3f00002562ef2bf82e", "sold": 413}'></div><p>如果觉得拟合度还不够，还可以继续训练。这样，就实现了用深度神经网络模拟正弦函数在0-2Pi的曲线。</p><blockquote><p>参考文章：</p><p>《TensorFlow入门与实战》-罗冬日</p></blockquote></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'TensorFlow','训练','神经'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>