<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器学习与线性代数 - 特殊矩阵 | 极客快訊</title><meta property="og:title" content="机器学习与线性代数 - 特殊矩阵 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/e9b67653bc8f44999d1b863010f5dc6a"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/c31f9da4.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/c31f9da4.html><meta property="article:published_time" content="2020-11-14T20:52:19+08:00"><meta property="article:modified_time" content="2020-11-14T20:52:19+08:00"><meta name=Keywords content><meta name=description content="机器学习与线性代数 - 特殊矩阵"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/c31f9da4.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器学习与线性代数 - 特殊矩阵</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e9b67653bc8f44999d1b863010f5dc6a><p class=pgc-img-caption></p></div><p>在线性代数中，有一些特殊的矩阵具有易于分析和操作的特性。它们的特征向量可能具有特定的特征值或特殊关系。还有一些方法可以将一个矩阵分解成这些“更简单”的矩阵。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/88e7b256aa854aef9b74a2dd393696ea><p class=pgc-img-caption></p></div><p>操作复杂性的降低提高了可伸缩性。然而，即使这些矩阵都是特殊的，它们也不是罕见的。在机器学习和许多应用程序中，我们经常需要处理它们。</p><h1>对角矩阵</h1><p>对角矩阵S使所有非对角元素等于零。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/42ddbe5ba73a40cea24c7f2764c5288e><p class=pgc-img-caption></p></div><p>许多分解方法都有一个分解后的矩阵是对角矩阵。由于矩阵只包含对角元素，我们有时用向量来表示它。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/46cf6082aadd4ef2ae1bc67c9f4415b7><p class=pgc-img-caption></p></div><p>一般矩阵的逆不容易计算。但是求对角矩阵的逆很简单。我们可以用1/m替换对角线元素。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0fa764305ea64824a20e6eab0747b9aa><p class=pgc-img-caption></p></div><p>如果其中一个矩阵是对角的，矩阵乘法就简单多了。但是当任何对角元素等于0或者对角矩阵不是方形的时候，它的逆就不存在。但是，在一些方法中，伪逆矩阵（keep the inverse of 0 as 0）可以用作替代。</p><h1>正交矩阵</h1><p>正交矩阵Q是满足下列要求的方形矩阵</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cfb6b64543144036ba111f55cdf1113f><p class=pgc-img-caption></p></div><p>Q中的所有列（v 1 ，...，v 6 ，...）都是正交的，即对于i≠j，vᵢᵀvⱼ= 0，vᵢ都是单位向量。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ff642f1eab3c4096b5473382ceb5f769><p class=pgc-img-caption></p></div><p>这听起来像是一个严格的要求但是对于一些矩阵，比如对称矩阵，我们可以选择特征向量在分解过程中是正交的。</p><p>以下矩阵是正交的。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5870bf0ea2a545de9345731046d4be4f><p class=pgc-img-caption></p></div><p>像对角矩阵一样，它的逆也很容易计算 - 正交矩阵的逆是它的转置。这是正交矩阵非常方便的一个关键原因。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7862fee2daa540bd82196f8a7e99578c><p class=pgc-img-caption></p></div><p>证明：</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9f33b5006ed447c998d7b1cc366cfe8c><p class=pgc-img-caption></p></div><p>如果我们用正交矩阵乘以x, x中的误差不会被放大。这种行为对于保持数值稳定性是非常理想的。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2df28519b1754fd095f7df49c128a3fd><p class=pgc-img-caption></p></div><h1>对称矩阵</h1><p>如果矩阵的转置等于自身，则矩阵是对称的。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b57cc8a388d94e41a7b02ca2b5ee5a30><p class=pgc-img-caption></p></div><p>例如，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/63f62502ecc5423b8a3029ce758c6c4f><p class=pgc-img-caption></p></div><p>对称矩阵是线性代数和机器学习中最重要的矩阵之一。在机器学习(ML),我们经常使用矩阵保存<em>f(vᵢ , vⱼ)</em>。这些函数通常是对称的，f(x, y) = f(y, x)，因此对应的矩阵是对称的。例如在机器学习中，f可以测量数据点之间的特征距离，或者计算特征的协方差。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1be1daf1d95d459f94c0787b8522e9ca><p class=pgc-img-caption></p></div><p><strong>对称矩阵属性</strong></p><p>对称矩阵S是n×n方形矩阵。</p><ul><li>它的逆也是对称的。</li><li>S的所有特征值都是实数(不是复数)。</li><li>即使重复的特征值，我们也可以选择S的 n个本征向量为正交。</li><li>可以通过将矩阵A与其转置 - AᵀA或AAᵀ（通常AᵀA ≠ AAᵀ）相乘来形成对称矩阵。在机器学习中，以零为中心的协方差矩阵就是这种形式。</li></ul><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f81622d73884449694a846dc37f99c5b><p class=pgc-img-caption></p></div><ul><li>如果 A的列是线性无关的，则 AᵀA是可逆的。</li><li>每个对称矩阵小号可以进行对角化（因式分解）与Q由正交的特征向量形成vᵢ的小号和Λ是对角矩阵保持所有的特征值。</li><li>每个对称矩阵S可以被对角化（分解），其中Q由S的正交特征向量vi形成，Λ是对角矩阵的所有特征值。</li></ul><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e9b71241273a4cbb8f6b532a83f50c70><p class=pgc-img-caption></p></div><p>上面的等式可以改写为</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/064f899b41c141ac9097a34599c6899e><p class=pgc-img-caption></p></div><p>其中v是单位向量。因此，特征值项λᵢ主导了上述每个项的重要性。事实上，如果它太小，我们可以完全放弃相应的项λᵢvᵢvᵢᵀ。</p><p>该分解特性和“ S具有n个正交特征向量”是对称矩阵的两个重要特性。</p><p><strong>正交特征向量</strong></p><p>特征向量不是唯一的。但通常，我们可以“选择”一组特征向量来满足某些特定条件。如前所述，对称矩阵的特征向量可以选择为正交。如果S是对称矩阵，则其特征值λ和μ满足以下条件。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ae31324c671346c5873a848064f25f53><p class=pgc-img-caption></p></div><p>证明</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3a4207c1dcaf46eba70d33c652a9b9e8><p class=pgc-img-caption></p></div><p>从这种情况来看，如果λ和μ具有不同的值，则等效性迫使内积为零。因此，x和y是正交的，并且很容易将它们归一化为具有单位长度 - 正交。这证明了如果它们的相应特征值不同，我们可以选择S的特征向量是正交的。即使有重复的特征值，对于对称矩阵仍然如此。</p><p>证明 - 第2部分（可选）</p><p>对于n×n对称矩阵，我们总能找到n个独立的正交特征向量。最大的特征值是</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1bbd8cdc868149cc9cb7ed8045b1f438><p class=pgc-img-caption></p></div><p>为了求最大值，我们令r(x)的导数为0。经过一些处理，得到</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9a38c298094543a7b9b2160e2f8dd71d><p class=pgc-img-caption></p></div><p>即，当x是特征向量且特征值最大时，r(x)的比值最大。通过归纳，我们可以推导出我们可以用正交于前一个的特征向量找到下一个最高的特征值。这只是证明的高级描述。</p><p><strong>谱定理（Spectral theorem）</strong></p><p>让我们总结一下。每个n×n对称矩阵S具有n个实特征值λᵢ，其中有n个正交特征向量vᵢ。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/af3454afb0994f67af4f0ed0ff4d088a><p class=pgc-img-caption></p></div><p>这些特征值可以形成对角矩阵Λ as <em>diag(λ)</em>。我们还可以将特征向量vᵢ连接到V，即，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2cce874663314eebb614de7101472edc><p class=pgc-img-caption></p></div><p>我们将V重命名为Q.因为Q是正交的，所以它是可逆的并且Qᵀ= Q-1。因此，对称矩阵S可以分解为</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e18556bcdb7b44619c1e14a0a5a0ac77><p class=pgc-img-caption></p></div><p>这是谱定理。因为找到转置比逆转更容易，所以在线性代数中非常需要对称矩阵。</p><h1>正定矩阵</h1><p>正定矩阵具有所有正特征值。它是对称的。这听起来很不寻常，但现实生活中的许多矩阵都是肯定的。下面的术语计算具有状态x的系统的能量（<strong>energy</strong>）。如果S是正定的，它保证能量保持为正，除非x为零。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/c2a762a334084608a7a38bc3acc3ad8f><p class=pgc-img-caption></p></div><p>在许多应用中，我们假设能量是正的，因此，相应的S应该是正定的。</p><p>测试正定性有许多等效条件。如果以下任何测试为真，则对称矩阵S为正定的：</p><p>1.所有特征值> 0，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/ceaa342ae7934b1a91b4bf4481b08d3a><p class=pgc-img-caption></p></div><p>2.所有左上角的行列式> 0，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/06730bf168f44356a3071c0591a71a8b><p class=pgc-img-caption></p></div><p>3.所有pivots > 0，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d091021e7942461c8e4ebb6bad2fa1a9><p class=pgc-img-caption></p></div><p>4.能量（<strong>energy</strong>）> 0，除了x = 0，</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9acf855cfcef4f17abe8ae4bdbafff46><p class=pgc-img-caption></p></div><p>5. S可以由一个列向量无关的矩阵a构成。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/87324c00559e4d94a3490ccc891ab3c7><p class=pgc-img-caption></p></div><p>验证所有特征值是正的需要很多工作。因此，条件2或3是更常见的测试。例如，正pivots 意味着正特征值（反之亦然）。另一方面，如果我们通过上述测试之一证明矩阵是正定的，我们保证它拥有上述所有属性。</p><p>证明</p><p>在本节中，我们将证明上面的一些属性。如果S是正定的，则​​所有λ都是正的。因此，相应状态x的计算能量为正（x = 0除外）。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/78ae61e032b84afd8ff3cf8f19b75610><p class=pgc-img-caption></p></div><p>如果S由AᵀA组成，则S在能量测试下为正。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6170d620117d41109a3976726c7ad1e1><p class=pgc-img-caption></p></div><p>除了正定，我们还有半正定，负定和半负定。半正定用“≥”替换上面的所有“>”条件（例如，它的特征值是大于或等于0 ），负定和半负定与正定和半正定相反。</p><p><strong>Minimum</strong></p><p>在微积分中，我们将f的一阶导数设置为零以找到其临界点。然而，这样的点可以是最大值，最小值或鞍点。许多机器学习模型以二次形式xAᵀx表示其成本函数。知道这个函数是否是凸函数是很重要的。因为如果它是凸的，我们知道局部最小值也是全局最小值。如果A是正定的，则​​二次函数是凸的。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5922f677ff7a4829a50aa5d9ab89c56b><p class=pgc-img-caption></p></div><p>对于任何函数f，我们计算下面的Hessian矩阵。如果A是正定的，则​​相应的点是局部最小值。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e47a885905464820a28e34c4805a2d97><p class=pgc-img-caption></p></div><h1>协方差矩阵</h1><p>在机器学习中，我们非常有兴趣找到特征之间的相关性。下图显示了重量和高度之间的正相关关系。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e4f0bb8d32dc472b8148bbe9a4687c6e><p class=pgc-img-caption></p></div><p>在机器学习中，我们用协方差矩阵Σ建模关系。</p><div class=pgc-img><img alt="机器学习与线性代数 - 特殊矩阵" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/ce566368de72452ebd6b73a7c6cd727b><p class=pgc-img-caption></p></div><p>协方差矩阵是半正定的。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'机器','学习','性代数'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>