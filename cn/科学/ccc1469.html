<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>最详细的回归算法介绍，一遍就能看懂 | 极客快訊</title><meta property="og:title" content="最详细的回归算法介绍，一遍就能看懂 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/2e50a35979274f80963d07fca7d71962"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ccc1469.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ccc1469.html><meta property="article:published_time" content="2020-10-29T21:03:59+08:00"><meta property="article:modified_time" content="2020-10-29T21:03:59+08:00"><meta name=Keywords content><meta name=description content="最详细的回归算法介绍，一遍就能看懂"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/ccc1469.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>最详细的回归算法介绍，一遍就能看懂</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right><strong>Regression：Case Study</strong></h1><blockquote><p><strong>回归</strong>-案例研究</p></blockquote><h1 class=pgc-h-arrow-right><strong>问题的导入：预测宝可梦的CP值</strong></h1><p>Estimating the Combat Power(CP) of a pokemon after evolution</p><p>我们期望根据已有的宝可梦进化前后的信息，来预测某只宝可梦进化后的cp值的大小</p><h1 class=pgc-h-arrow-right><strong>确定Senario、Task和Model</strong></h1><h1 class=pgc-h-arrow-right><strong>Senario</strong></h1><p>首先根据已有的data来确定Senario，我们拥有宝可梦进化前后cp值的这样一笔数据，input是进化前的宝可梦(包括它的各种属性)，output是进化后的宝可梦的cp值；因此我们的data是labeled，使用的Senario是<strong>Supervised Learning</strong></p><h1 class=pgc-h-arrow-right><strong>Task</strong></h1><p>然后根据我们想要function的输出类型来确定Task，我们预期得到的是宝可梦进化后的cp值，是一个scalar，因此使用的Task是<strong>Regression</strong></p><h1 class=pgc-h-arrow-right><strong>Model</strong></h1><p>关于Model，选择很多，这里采用的是<strong>Non-linear Model</strong></p><h1 class=pgc-h-arrow-right><strong>设定具体参数</strong></h1><p>： 表示一只宝可梦，用下标表示该宝可梦的某种属性</p><p>：表示该宝可梦进化前的cp值</p><p>： 表示该宝可梦是属于哪一种物种，比如妙瓜种子、皮卡丘...</p><p>：表示该宝可梦的hp值即生命值是多少</p><p>： 代表该宝可梦的重重量</p><p>： 代表该宝可梦的高度</p><p>： 表示我们要找的function</p><p>： 表示function的output，即宝可梦进化后的cp值，是一个scalar</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2e50a35979274f80963d07fca7d71962><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Regression的具体过程</strong></h1><h1 class=pgc-h-arrow-right><strong>回顾一下machine Learning的三个步骤：</strong></h1><ul><li>定义一个model即function set</li><li>定义一个goodness of function损失函数去评估该function的好坏</li><li>找一个最好的function</li></ul><h1 class=pgc-h-arrow-right><strong>Step1：Model (function set)</strong></h1><p>如何选择一个function的模型呢？毕竟只有确定了模型才能调参。这里没有明确的思路，只能凭经验去一种种地试</p><h1 class=pgc-h-arrow-right><strong>Linear Model 线性模型</strong></h1><p><br></p><p>y代表进化后的cp值，代表进化前的cp值，w和b代表未知参数，可以是任何数值</p><p>根据不同的w和b，可以确定不同的无穷无尽的function，而这个抽象出来的式子就叫做model，是以上这些具体化的function的集合，即function set</p><p>实际上这是一种<strong>Linear Model</strong>，但只考虑了宝可梦进化前的cp值，因而我们可以将其扩展为：</p><p>====</p><p><strong>x~i~</strong>： an attribute of input X ( x~i~ is also called <strong>feature</strong>，即特征值)</p><p><strong>w~i~</strong>：weight of x~i~</p><p><strong>b</strong>： bias</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/0be689ebf4bd4d768b704a55184b57ce><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Step2：Goodness of Function</strong></h1><h1 class=pgc-h-arrow-right><strong>参数说明</strong></h1><p>：用上标来表示一个完整的object的编号，表示第i只宝可梦(下标表示该object中的component)</p><p>：用表示一个实际观察到的object输出，上标为i表示是第i个object</p><p>注：由于regression的输出值是scalar，因此里面并没有component，只是一个简单的数值；但是未来如果考虑structured Learning的时候，我们output的object可能是有structured的，所以我们还是会需要用上标下标来表示一个完整的output的object和它包含的component</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a48823e17c9d4d54a5559d525e74fb5e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Loss function 损失函数</strong></h1><p>为了衡量function set中的某个function的好坏，我们需要一个评估函数，即==Loss function==，损失函数，简称L；loss function是一个function的function</p><p>input：a function；</p><p>output：how bad/good it is</p><p>由于，即f是由b和w决定的，因此input f就等价于input这个f里的b和w，因此==Loss function实际上是在衡量一组参数的好坏==</p><p>之前提到的model是由我们自主选择的，这里的loss function也是，最常用的方法就是采用类似于方差和的形式来衡量参数的好坏，即预测值与真值差的平方和；这里真正的数值减估测数值的平方，叫做估测误差，Estimation error，将10个估测误差合起来就是loss function</p><p>如果越大，说明该function表现得越不好；越小，说明该function表现得越好</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/39db633b8d734ac59552210ae969cb86><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Loss function可视化</strong></h1><p>下图中是loss function的可视化，该图中的每一个点都代表一组(w,b)，也就是对应着一个function；而该点的颜色对应着的loss function的结果L(w,b)，它表示该点对应function的表现有多糟糕，颜色越偏红色代表Loss的数值越大，这个function的表现越不好，越偏蓝色代表Loss的数值越小，这个function的表现越好</p><p>比如图中用红色箭头标注的点就代表了b=-180 , w=-2对应的function，即，该点所在的颜色偏向于红色区域，因此这个function的loss比较大，表现并不好</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dab907ece660492dae7bc120fc4e4d55><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Step3：Pick the Best Function</strong></h1><p>我们已经确定了loss function，他可以衡量我们的model里面每一个function的好坏，接下来我们要做的事情就是，从这个function set里面，挑选一个最好的function</p><p>挑选最好的function这一件事情，写成formulation/equation的样子如下：</p><p>，或者是</p><p>也就是那个使最小的或，就是我们要找的或(有点像极大似然估计的思想)</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d935e98f61aa461da623227a35d78c96><p class=pgc-img-caption></p></div><p>利用线性代数的知识，可以解得这个closed-form solution，但这里采用的是一种更为普遍的方法——==gradient descent(梯度下降法)==</p><h1 class=pgc-h-arrow-right><strong>Gradient Descent 梯度下降</strong></h1><p>上面的例子比较简单，用线性代数的知识就可以解；但是对于更普遍的问题来说，gradient descent的厉害之处在于，只要是可微分的，gradient descent都可以拿来处理这个，找到表现比较好的parameters</p><h1 class=pgc-h-arrow-right><strong>单个参数的问题</strong></h1><p>以只带单个参数w的Loss Function L(w)为例，首先保证是<strong>可微</strong>的</p><p>我们的目标就是找到这个使Loss最小的，实际上就是寻找切线L斜率为0的global minima最小值点(注意，存在一些local minima极小值点，其斜率也是0) 有一个暴力的方法是，穷举所有的w值，去找到使loss最小的，但是这样做是没有效率的；而gradient descent就是用来解决这个效率问题的 * 首先随机选取一个初始的点 (当然也不一定要随机选取，如果有办法可以得到比较接近的表现得比较好的当初始点，可以有效地提高查找的效率) * 计算在的位置的微分，即，几何意义就是切线的斜率 * 如果切线斜率是negative负的，那么就应该使w变大，即往右踏一步；如果切线斜率是positive正的，那么就应该使w变小，即往左踏一步，每一步的步长step size就是w的改变量 w的改变量step size的大小取决于两件事 * 一是现在的微分值有多大，微分值越大代表现在在一个越陡峭的地方，那它要移动的距离就越大，反之就越小； * 二是一个常数项η，被称为==learning rate==，即学习率，它决定了每次踏出的step size不只取决于现在的斜率，还取决于一个事先就定好的数值，如果learning rate比较大，那每踏出一步的时候，参数w更新的幅度就比较大，反之参数更新的幅度就比较小 如果learning rate设置的大一些，那机器学习的速度就会比较快；但是learning rate如果太大，可能就会跳过最合适的global minima的点 * 因此每次参数更新的大小是 η，为了满足斜率为负时w变大，斜率为正时w变小，应当使原来的w减去更新的数值，即 ηηηη</p><p>此时对应的斜率为0，我们找到了一个极小值local minima，这就出现了一个问题，当微分为0的时候，参数就会一直卡在这个点上没有办法再更新了，因此通过gradient descent找出来的solution其实并不是最佳解global minima</p><p>但幸运的是，在linear regression上，是没有local minima的，因此可以使用这个方法</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a9544f6007e842268d07beb6a7830616><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>两个参数的问题</strong></h1><p>今天要解决的关于宝可梦的问题，是含有two parameters的问题，即</p><p>当然，它本质上处理单个参数的问题是一样的</p><ul><li>首先，也是随机选取两个初始值，和</li><li>然后分别计算这个点上，L对w和b的偏微分，即 和</li><li>更新参数，当迭代跳出时，对应着极小值点 ηηηηηη</li></ul><p>实际上，L 的gradient就是微积分中的那个梯度的概念，即</p><p>可视化效果如下：(三维座标显示在二维图像中，loss的值用颜色来表示)</p><p>横座标是b，纵座标是w，颜色代表loss的值，越偏蓝色表示loss越小，越偏红色表示loss越大</p><p><strong>每次计算得到的梯度gradient，即由和组成的vector向量，就是该等高线的法线方向(对应图中红色箭头的方向)；而ηη的作用就是让原先的朝着gradient的方向即等高线法线方向前进，其中η(learning rate)的作用是每次更新的跨度(对应图中红色箭头的长度)；经过多次迭代，最终gradient达到极小值点</strong></p><p>注：这里两个方向的η(learning rate)必须保持一致，这样每次更新座标的step size是等比例缩放的，保证座标前进的方向始终和梯度下降的方向一致；否则座标前进的方向将会发生偏移</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/16fae44b0b8b48aba2e229c199502ef1><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Gradient Descent的缺点</strong></h1><p>gradient descent有一个令人担心的地方，也就是我之前一直提到的，它每次迭代完毕，寻找到的梯度为0的点必然是极小值点，local minima；却不一定是最小值点，global minima</p><p>这会造成一个问题是说，如果loss function长得比较坑坑洼洼(极小值点比较多)，而每次初始化的取值又是随机的，这会造成每次gradient descent停下来的位置都可能是不同的极小值点；而且当遇到梯度比较平缓(gradient≈0)的时候，gradient descent也可能会效率低下甚至可能会stuck卡住；也就是说通过这个方法得到的结果，是看人品的(滑稽</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/48f6de48cfd1404982c0a3aedf6ed257><p class=pgc-img-caption></p></div><p>但是！在==linear regression==里，loss function实际上是<strong>convex</strong>的，是一个<strong>凸函数</strong>，是没有local optimal局部最优解的，他只有一个global minima，visualize出来的图像就是从里到外一圈一圈包围起来的椭圆形的等高线(就像前面的等高线图)，因此随便选一个起始点，根据gradient descent最终找出来的，都会是同一组参数</p><h1 class=pgc-h-arrow-right><strong>回到pokemon的问题上来</strong></h1><h1 class=pgc-h-arrow-right><strong>偏微分的计算</strong></h1><p>现在我们来求具体的L对w和b的偏微分</p><h1 class=pgc-h-arrow-right><strong>How's the results?</strong></h1><p>根据gradient descent，我们得到的中最好的参数是b=-188.4, w=2.7</p><p>我们需要有一套评估系统来评价我们得到的最后这个function和实际值的误差error的大小；这里我们将training data里每一只宝可梦 进化后的实际cp值与预测值之差的绝对值叫做，而这些误差之和Average Error on Training Data为</p><blockquote><p>What we really care about is the error on new data (testing data)</p></blockquote><p>当然我们真正关心的是generalization的case，也就是用这个model去估测新抓到的pokemon，误差会有多少，这也就是所谓的testing data的误差；于是又抓了10只新的pokemon，算出来的Average Error on Testing Data为；可见training data里得到的误差一般是要比testing data要小，这也符合常识</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5ea0648401af4498b73b8c09344b6287><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>How can we do better?</strong></h1><p>我们有没有办法做得更好呢？这时就需要我们重新去设计model；如果仔细观察一下上图的data，就会发现在原先的cp值比较大和比较小的地方，预测值是相当不准的</p><p>实际上，从结果来看，最终的function可能不是一条直线，可能是稍微更复杂一点的曲线</p><h1 class=pgc-h-arrow-right><strong>考虑的model</strong></h1><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/894a1ec831d247eab2e0d9061b0e3481><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>考虑的model</strong></h1><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/92431444e70d4738bc2a2a0b65f748c7><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>考虑的model</strong></h1><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/51cfd92268c24aeaa61ee3fc69d87452><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>考虑的model</strong></h1><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f87980536ab64366b8e86ce510de8e92><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>5个model的对比</strong></h1><p>这5个model的training data的表现：随着的高次项的增加，对应的average error会不断地减小；实际上这件事情非常容易解释，实际上低次的式子是高次的式子的特殊情况(令高次项对应的为0，高次式就转化成低次式)</p><p>也就是说，在gradient descent可以找到best function的前提下(多次式为Non-linear model，存在local optimal局部最优解，gradient descent不一定能找到global minima)，function所包含的项的次数越高，越复杂，error在training data上的表现就会越来越小；但是，我们关心的不是model在training data上的error表现，而是model在testing data上的error表现</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a61e15e9166f4c3f97d7a99251500e55><p class=pgc-img-caption></p></div><p>在training data上，model越复杂，error就会越低；但是在testing data上，model复杂到一定程度之后，error非但不会减小，反而会暴增，在该例中，从含有项的model开始往后的model，testing data上的error出现了大幅增长的现象，通常被称为<strong>overfitting过拟合</strong></p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db973842ede74a4090c02ada49ee0293><p class=pgc-img-caption></p></div><p>因此model不是越复杂越好，而是选择一个最适合的model，在本例中，包含的式子是最适合的model</p><h1 class=pgc-h-arrow-right><strong>进一步讨论其他参数</strong></h1><h1 class=pgc-h-arrow-right><strong>物种的影响</strong></h1><p>之前我们的model只考虑了宝可梦进化前的cp值，这显然是不对的，除了cp值外，还受到物种的影响</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/733204af7c8b486e86f4452feab38c1c><p class=pgc-img-caption></p></div><p>因此我们重新设计model：</p><p>也就是根据不同的物种，设计不同的linear model(这里)，那如何将上面的四个if语句合并成一个linear model呢？</p><p>这里引入δ条件表达式的概念，当条件表达式为true，则δ为1；当条件表达式为false，则δ为0，因此可以通过下图的方式，将4个if语句转化成同一个linear model</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3dd6a9867bba441fb1ebedd50bf20c4d><p class=pgc-img-caption></p></div><p>有了上面这个model以后，我们分别得到了在training data和testing data上测试的结果：</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5922564fd3904523bc2717d9b466a436><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>Hp值、height值、weight值的影响</strong></h1><p>考虑所有可能有影响的参数，设计出这个最复杂的model：</p><p>算出的training error=1.9，但是，testing error=102.3！<strong>这么复杂的model很大概率会发生overfitting</strong>(按照我的理解，overfitting实际上是我们多使用了一些input的变量或是变量的高次项使曲线跟training data拟合的更好，但不幸的是这些项并不是实际情况下被使用的，于是这个model在testing data上会表现得很糟糕)，overfitting就相当于是那个范围更大的韦恩图，它包含了更多的函数更大的范围，代价就是在准确度上表现得更糟糕</p><h1 class=pgc-h-arrow-right><strong>regularization解决overfitting(L2正则化解决过拟合问题)</strong></h1><blockquote><p>regularization可以使曲线变得更加smooth，training data上的error变大，但是 testing data上的error变小。有关regularization的具体原理说明详见下一部分</p></blockquote><p>原来的loss function只考虑了prediction的error，即；而regularization则是在原来的loss function的基础上加上了一项，就是把这个model里面所有的的平方和用λ加权(其中i代表遍历n个training data，j代表遍历model的每一项)</p><p>也就是说，<strong>我们期待参数越小甚至接近于0的function，为什么呢？</strong></p><p>因为参数值接近0的function，是比较平滑的；所谓的平滑的意思是，当今天的输入有变化的时候，output对输入的变化是比较不敏感的</p><p>举例来说，对这个model，当input变化，output的变化就是，也就是说，如果越小越接近0的话，输出对输入就越不sensitive敏感，我们的function就是一个越平滑的function；说到这里你会发现，我们之前没有把bias——b这个参数考虑进去的原因是<strong>bias的大小跟function的平滑程度是没有关系的</strong>，bias值的大小只是把function上下移动而已</p><p><strong>那为什么我们喜欢比较平滑的function呢？</strong></p><p>如果我们有一个比较平滑的function，由于输出对输入是不敏感的，测试的时候，一些noises噪声对这个平滑的function的影响就会比较小，而给我们一个比较好的结果</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/50179a1b041c4acc95431b85814fd100><p class=pgc-img-caption></p></div><p><strong>注：这里的λ需要我们手动去调整以取得最好的值</strong></p><p>λ值越大代表考虑smooth的那个regularization那一项的影响力越大，我们找到的function就越平滑</p><p>观察下图可知，当我们的λ越大的时候，在training data上得到的error其实是越大的，但是这件事情是非常合理的，因为当λ越大的时候，我们就越倾向于考虑w的值而越少考虑error的大小；但是有趣的是，虽然在training data上得到的error越大，但是在testing data上得到的error可能会是比较小的</p><p>下图中，当λ从0到100变大的时候，training error不断变大，testing error反而不断变小；但是当λ太大的时候(>100)，在testing data上的error就会越来越大</p><p>==我们喜欢比较平滑的function，因为它对noise不那么sensitive；但是我们又不喜欢太平滑的function，因为它就失去了对data拟合的能力；而function的平滑程度，就需要通过调整λ来决定==，就像下图中，当λ=100时，在testing data上的error最小，因此我们选择λ=100</p><p>注：这里的error指的是</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d6b8c198833c42b8895e5c0f5c51507a><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>conclusion总结</strong></h1><h1 class=pgc-h-arrow-right><strong>关于pokemon的cp值预测的流程总结：</strong></h1><ul><li>根据已有的data特点(labeled data，包含宝可梦及进化后的cp值)，确定使用supervised learning监督学习</li><li>根据output的特点(输出的是scalar数值)，确定使用regression回归(linear or non-linear)</li><li>考虑包括进化前cp值、species、hp等各方面变量属性以及高次项的影响，我们的model可以采用这些input的一次项和二次型之和的形式，如： 而为了保证function的平滑性，loss function应使用regularization，即，注意bias——参数b对function平滑性无影响，因此不额外再次计入loss function(y的表达式里已包含w、b)</li><li>利用gradient descent对regularization版本的loss function进行梯度下降迭代处理，每次迭代都减去L对该参数的微分与learning rate之积，假设所有参数合成一个vector：，那么每次梯度下降的表达式如下： 梯度 当梯度稳定不变时，即为0时，gradient descent便停止，此时如果采用的model是linear的，那么vector必然落于global minima处(凸函数)；如果采用的model是Non-linear的，vector可能会落于local minima处(此时需要采取其他办法获取最佳的function) 假定我们已经通过各种方法到达了global minima的地方，此时的vector：所确定的那个唯一的function就是在该λ下的最佳，即loss最小</li><li>这里λ的最佳数值是需要通过我们不断调整来获取的，因此令λ等于0，10，100，1000，...不断使用gradient descent或其他算法得到最佳的parameters：，并计算出这组参数确定的function——对training data和testing data上的error值，直到找到那个使testing data的error最小的λ，(这里一开始λ=0，就是没有使用regularization时的loss function) 注：引入评价的error机制，令error=，分别计算该对training data和testing data(more important)的大小 先设定λ->确定loss function->找到使loss最小的->确定function->计算error->重新设定新的λ重复上述步骤->使testing data上的error最小的λ所对应的所对应的function就是我们能够找到的最佳的function</li></ul><h1 class=pgc-h-arrow-right><strong>本章节总结：</strong></h1><ul><li>Pokémon: Original CP and species almost decide the CP after evolution</li><li>There are probably other hidden factors</li><li>Gradient descent More theory and tips in the following lectures</li><li>Overfitting and Regularization</li><li>We finally get average error = 11.1 on the testing data</li><li>How about new data? Larger error? Lower error?(larger->need validation)</li><li>Next lecture: Where does the error come from? More theory about overfitting and regularizationThe concept of validation(用来解决new data的error高于11.1的问题)</li></ul><h1 class=pgc-h-arrow-right><strong>附：Regularization(L1 L2 正则化解决overfitting)</strong></h1><blockquote><p>Regularization -> redefine the loss function</p></blockquote><p>关于overfitting的问题，很大程度上是由于曲线为了更好地拟合training data的数据，而引入了更多的高次项，使得曲线更加“蜿蜒曲折”，反而导致了对testing data的误差更大</p><p>回过头来思考，我们之前衡量model中某个function的好坏所使用的loss function，仅引入了真实值和预测值差值的平方和这一个衡量标准；我们想要避免overfitting过拟合的问题，就要使得高次项对曲线形状的影响尽可能小，因此我们要在loss function里引入高次项(非线性部分)的衡量标准，也就是将高次项的系数也加权放进loss function中，这样可以使得训练出来的model既满足预测值和真实值的误差小，又满足高次项的系数尽可能小而使曲线的形状比较稳定集中</p><p>以下图为例，如果loss function仅考虑了这一误差衡量标准，那么拟合出来的曲线就是红色虚线部分(过拟合)，而过拟合就是所谓的model对training data过度自信, 非常完美的拟合上了这些数据, 如果具备过拟合的能力, 那么这个方程就可能是一个比较复杂的非线性方程 , 正是因为这里的和使得这条虚线能够被弯来弯去, 所以整个模型就会特别努力地去学习作用在和上的c、d参数. <strong>但是在这个例子里，我们期望模型要学到的却是这条蓝色的曲线. 因为它能更有效地概括数据</strong>.而且只需要一个就能表达出数据的规律.</p><p>或者是说, 蓝色的线最开始时, 和红色线同样也有c、d两个参数, 可是最终学出来时, c 和 d 都学成了0, 虽然蓝色方程的误差要比红色大, 但是概括起数据来还是蓝色好</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4d1e3ffb089849d3a7bb50b3c3ad3d08><p class=pgc-img-caption></p></div><p>这也是我们通常采用的方法，我们不可能一开始就否定高次项而直接只采用低次线性表达式的model，因为有时候真实数据的确是符合高次项非线性曲线的分布的；而如果一开始直接采用高次非线性表达式的model，就很有可能造成overfitting，在曲线偏折的地方与真实数据的误差非常大。我们的目标应该是这样的：</p><p><strong>在无法确定真实数据分布的情况下，我们尽可能去改变loss function的评价标准</strong></p><ul><li><strong>我们的model的表达式要尽可能的复杂，包含尽可能多的参数和尽可能多的高次非线性项；</strong></li><li><strong>但是我们的loss function又有能力去控制这条曲线的参数和形状，使之不会出现overfitting过拟合的现象；</strong></li><li><strong>在真实数据满足高次非线性曲线分布的时候，loss function控制训练出来的高次项的系数比较大，使得到的曲线比较弯折起伏；</strong></li><li><strong>在真实数据满足低次线性分布的时候，loss function控制训练出来的高次项的系数比较小甚至等于0，使得到的曲线接近linear分布</strong></li></ul><p>那我们如何保证能学出来这样的参数呢? 这就是 L1 L2 正规化出现的原因.</p><p>之前的loss function仅考虑了这一误差衡量标准，而<strong>L1 L2正规化</strong>就是在这个loss function的后面多加了一个东西，即model中跟高次项系数有关的表达式；</p><ul><li>L1正规化即加上λ这一项，loss function变成，即n个training data里的数据的真实值与预测值差值的平方和加上λ权重下的model表达式中所有项系数的绝对值之和</li><li>L2正规化即加上这一项，loss function变成，即n个training data里的数据的真实值与预测值差值的平方和加上λ权重下的model表达式中所有项系数的平方和</li></ul><p>相对来说，L2要更稳定一些，L1的结果则不那么稳定，如果用p表示正规化程度，上面两式可总结如下：</p><div class=pgc-img><img alt=最详细的回归算法介绍，一遍就能看懂 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c01ed3db56324036a6acc29c32ea7c8e><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'详细','介绍','能看懂'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>