<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>聚类（二）：聚类性能评估、肘部法则、轮廓系数 | 极客快訊</title><meta property="og:title" content="聚类（二）：聚类性能评估、肘部法则、轮廓系数 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/05a2c3fcf29f4a5783bd2579b953a7e3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d2dd4ef.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d2dd4ef.html><meta property="article:published_time" content="2020-10-29T20:55:19+08:00"><meta property="article:modified_time" content="2020-10-29T20:55:19+08:00"><meta name=Keywords content><meta name=description content="聚类（二）：聚类性能评估、肘部法则、轮廓系数"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/d2dd4ef.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>聚类（二）：聚类性能评估、肘部法则、轮廓系数</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><h1>一、聚类K的选择规则</h1><p><strong>1.1 肘部法则–Elbow Method</strong></p><p>我们知道k-means是以最小化样本与质点平方误差作为目标函数，将每个簇的质点与簇内样本点的平方距离误差和称为畸变程度(distortions)，那么，对于一个簇，它的畸变程度越低，代表簇内成员越紧密，畸变程度越高，代表簇内结构越松散。 畸变程度会随着类别的增加而降低，但对于有一定区分度的数据，在达到某个临界点时畸变程度会得到极大改善，之后缓慢下降，这个临界点就可以考虑为聚类性能较好的点。 基于这个指标，我们可以重复训练多个k-means模型，选取不同的k值，来得到相对合适的聚类类别（簇内误方差(SSE)）</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/05a2c3fcf29f4a5783bd2579b953a7e3><p class=pgc-img-caption></p></div><p>如上图所示，在k=3时，畸变程度得到大幅改善，可以考虑选取k=3作为聚类数量，附简单代码：</p><pre>from sklearn.cluster import KMeansmodel = KMeans(n_clusters=k)model.fit(vector_points)md = model.inertia_ / vector_points.shape[0]</pre><p><strong>1.2 轮廓系数–Silhouette Coefficient</strong></p><p>对于一个聚类任务，我们希望得到的类别簇中，簇内尽量紧密，簇间尽量远离，轮廓系数便是类的密集与分散程度的评价指标，公式表达如下</p><p>s=(b−a)/max(a,b)</p><p>a簇样本到彼此间距离的均值</p><p>b代表样本到除自身所在簇外的最近簇的样本的均值</p><p>s取值在[-1, 1]之间。</p><p>如果s接近1，代表样本所在簇合理，若s接近-1代表s更应该分到其他簇中。 同样，利用上述指标，训练多个模型，对比选取合适的聚类类别：</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f31bda41517a426db1140ae2ad19b5af><p class=pgc-img-caption></p></div><p>图， 当k=3时，轮廓系数最大，代表此时聚类的效果相对合理，简单代码如下：</p><pre>from sklearn.cluster import KMeansfrom sklearn.metrics import silhouette_scoremodel = KMeans(n_clusters=k)model.fit(vector_points)s = silhouette_score(vector_points, model.labels_)</pre><h1>二、聚类性能评估</h1><p>说到聚类性能比较好，就是说同一簇的样本尽可能的相似，不同簇的样本尽可能不同，即是说聚类结果簇内相似度（intra-cluster similarity）高，而簇间相似度（inter-cluster similarity）低。</p><p>有监督的分类算法的评价指标通常是accuracy, precision, recall, etc；由于聚类算法是无监督的学习算法，评价指标则没有那么简单了。因为聚类算法得到的类别实际上不能说明任何问题，除非这些类别的分布和样本的真实类别分布相似，或者聚类的结果满足某种假设，即同一类别中样本间的相似性高于不同类别间样本的相似性。聚类模型的评价指标如下：</p><p><strong>2.1 外部评估（external evaluation）</strong></p><p>将结果与某个“参考模型”（reference model）进行比较。</p><p><strong>2.1.1 Adjusted Rand Index(兰德指数)</strong></p><p>ARI的优点:</p><p>随机均匀的标签分布的ARI值接近0，这点与raw Rand Index和 V-measure指标不同;</p><p>ARI值的范围是[-1,1]，负的结果都是较差的，说明标签是独立分布的，相似分布；ARI结果是正的，1是最佳结果，说明两种标签的分布完全一致;</p><p>不用对聚类结果做任何假设，可以用来比较任意聚类算法的聚类结果间的相似性。</p><p>ARI的缺点：</p><p>ARI指标需要事先知道样本的真实标签，这和有监督学习的先决条件是一样的。然而ARI也可以作为一个通用的指标，用来评估不同的聚类模型的性能。</p><p>数学公式：</p><p>如果C是真实类别，K是聚类结果，我们定义a和b分别是：</p><p>a: 在C和K中都是同一类别的样本对数</p><p>b: 在C和K中都是不同类别的样本对数</p><p>raw Rand Index 的公式如下</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/996e0487cdc14c97a0e671cda9d1105d><p class=pgc-img-caption></p></div><p><strong>2.1.2 Entropy 熵</strong></p><p>对于一个聚类i，首先计算。指的是聚类 i 中的成员（member）属于类（class）j 的概率，。其中是在聚类 i 中所有成员的个数，是聚类 i 中的成员属于类 j 的个数。每个聚类的entropy可以表示为，其中L是类（class）的个数。整个聚类划分的entropy为，其中K是聚类（cluster）的数目，m是整个聚类划分所涉及到的成员个数。</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/f562e9afc4b347b7a87e8f2d3377974c><p class=pgc-img-caption></p></div><p><strong>2.1.3 purity（纯度）</strong></p><p>使用上述Entropy中的定义，我们将聚类 i 的purity定义为。整个聚类划分的purity为，其中K是聚类（cluster）的数目，m是整个聚类划分所涉及到的成员个数。</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f704fb5e02634573baaac39763f9a407><p class=pgc-img-caption></p></div><pre>def purity(cluster, labels, k, label_set): p = np.zeros((k, len(label_set))) purity = 0 for i in range(len(cluster)): p[int(cluster[i]), label_set.index(labels[i])] += 1 purity = sum(np.max(p, axis=1))/len(labels) return purity</pre><p><strong>2.1.4 Accuracy（AC）</strong></p><p>Accuracy, （Accuracy 里可以包含了precision, recall, f-measure.），AC是目前最流行的聚类评价指标。在很多文献里面，都将AC作为聚类结果的评价指标。</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1d88e1ef72f84a7ebe6f15f12b473180><p class=pgc-img-caption></p></div><p>map(pi) 是一个排列映射函数，将聚类得到的标签映射到与之等价的真实标签，聚类标签与真实标签之间是1-1映射(不一定是满的)。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a0010d3752684e51a022568f0899db15><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><ul><li>CA计算 聚类正确的百分比</li><li>CA越大证明聚类效果越好</li></ul><pre>def f_score(cluster, labels, label_set): TP, TN, FP, FN = 0, 0, 0, 0 n = len(labels) # a lookup table for i in range(n): if i not in cluster: continue for j in range(i + 1, n): if j not in cluster: continue same_label = (labels[i] == labels[j]) same_cluster = (cluster[i] == cluster[j]) if same_cluster: if same_label: TP += 1 else: FP += 1 elif same_label: FN += 1 else: TN += 1 precision = TP / (TP + FP) recall = TP / (TP + FN) fscore = 2 * precision * recall / (precision + recall) return fscore, precision, recall, TP + FP + FN + TN</pre><p>在二分类中：</p><p>TP(true positive):分类正确，把原本属于正类的样本分成正类。</p><p>TN(true negative):分类正确，把原本属于负类的样本分成负类。</p><p>FP(false positive):分类错误，把原本属于负类的错分成了正类。</p><p>FN(false negative):分类错误，把原本属于正类的错分成了负类。</p><p><strong>2.2 内部评估（internal evaluation）</strong></p><p>直接考虑聚类结果而不利用任何参考模型。</p><p><strong>2.2.1 Silhouette coefficient（轮廓系数）</strong></p><p>轮廓系数–Silhouette Coefficient 1.2 已讲。</p><p><strong>2.2.2 Calinski-Harabaz（CH）</strong></p><p>CH也适用于实际类别信息未知的情况，以下以K-means为例，给定聚类数目K</p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b1599c601cd642bc883311d9788269f9><p class=pgc-img-caption></p></div><p><strong>2.3 其它内部评估方法（others）</strong></p><p><strong>2.3.1 Davies-Bouldin Index（DBI）</strong></p><ul><li>σi：本簇中到其它所有样本点的距离的平均；</li><li>cici ：簇的中心；</li><li>d(ci,cj)：样本间距。</li></ul><p class=ql-align-center><br></p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2c3d4711337c44b8bc6cce3864bf836f><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>DBI越小越好。</p><p><strong>2.3.2 Dunn Index（DI）</strong></p><ul><li>d(i,j) ：样本间距；</li><li>d′(k) ：本簇内样本对间的最远距离</li></ul><p class=ql-align-center><br></p><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1ce4e346e7e740d2913d4d8aafce36c1><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>DI越大越好。</p><h1><strong>私信我:“学习”，可免费领取更多相关学习资料 （免费的哦）。</strong></h1><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/21ad754f28304ab0b4cc63a0dc947488><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=聚类（二）：聚类性能评估、肘部法则、轮廓系数 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeaecfd2093146548d72450fd9f3bbdc><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'聚类','评估','法则'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>