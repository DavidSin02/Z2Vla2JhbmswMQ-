<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 | 极客快訊</title><meta property="og:title" content="UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/5fda894b77ee46a68a8ff9d418e3c32b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/d53fb59.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/d53fb59.html><meta property="article:published_time" content="2020-10-29T21:03:32+08:00"><meta property="article:modified_time" content="2020-10-29T21:03:32+08:00"><meta name=Keywords content><meta name=description content="UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/d53fb59.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征</h1><p><strong>题目：</strong></p><p>UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation</p><p><strong>作者：</strong></p><p>Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, Jianming Liang</p><p><strong>来源：</strong></p><p>Computer Vision and Pattern Recognition</p><p>Journal of IEEE Transactions on Medical Imaging</p><p>(Submitted on 11 Dec 2019 (v1), last revised 28 Jan 2020 (this version, v2))</p><p><strong>文档链接：</strong></p><p>https://arxiv.org/pdf/1912.05074v2.pdf</p><p><strong>代码链接：</strong></p><p>https://github.com/MrGiovanni/UNetPlusPlus</p><p><br></p><h1 class=pgc-h-arrow-right>摘要</h1><p>目前最先进的医学图像分割模型是U-Net和全卷积网络(FCN)的变种。尽管这些模型取得了成功，但它们有两个局限性:(1)它们的最优深度先天未知，需要大量的架构搜索，或者对不同深度的模型进行低效的集成;(2)它们的跳跃连接强加了一种不必要的限制融合方案，强制只在编码器和解码器子网的相同尺度的特征映射上进行聚合。为了克服这两个局限性，我们提出了一种新的用于语义和实例分割的神经网络结构——UNet++，具体如下:(1)使用不同深度的u - net高效集成来减轻未知网络深度，这些U-Nets部分共享一个编码器，同时使用深度监督进行联合学习;(2)重新设计skip连接，在解码器子网络上聚合不同语义尺度的特征，形成高度灵活的特征融合方案;(3)设计一种剪枝方案，加快UNet++的推理速度。我们评估UNet + +使用六种不同的医学图像分割的数据集,覆盖多个成像技术如计算机断层扫描(CT)、磁共振成像(MRI),和电子显微镜(EM),并证明(1)UNet + +持续优于基线模型语义分割的任务在不同的数据集和骨干架构;(2) UNet++增强了可变大小对象的分割质量——相对于固定深度U-Net的改进;(3) Mask RCNN++ (Mask R-CNN with UNet++ design)在实例分割任务上优于原始的Mask R-CNN;(4)修剪后的UNet++模型实现了显著的加速，而性能仅略有下降。我们的实现和预培训的模型可以在https://github.com/MrGiovanni/UNetPlusPlus上找到</p><p><br></p><h1 class=pgc-h-arrow-right>英文原文</h1><p>The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects -- an improvement over the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus</p><h1 class=pgc-h-arrow-right><strong>要点</strong></h1><p><br></p><p><strong>本文的贡献：</strong></p><p>（1）我们在UNet++中引入了一个内置的不同深度的U-Net集合，从而提高了不同大小对象的分割性能，比固定深度的U-Net有了改进(参见II-B部分)。</p><p>（2)我们在UNet++中重新设计了skip连接，在解码器中实现了灵活的feature fusion，这比U-Net中只需要融合相同比例的feature map的限制性skip连接有了改进(见II-B部分)。</p><p>(3) Mask RCNN++ (Mask R-CNN with UNet++ design)在实例分割任务上优于原始的Mask R-CNN;</p><p>(4)修剪后的UNet++模型实现了显著的加速，而性能仅略有下降。我们的实现和预培训的模型可以在https://github.com/MrGiovanni/UNetPlusPlus上找到，这比单独培训相同架构的孤立的u - net有更好的性能(见第四节- d和第五节- c)。</p><p>（5)我们证明了UNet++可扩展到多个骨干编码器，并进一步证明其适用于各种医学成像模式，包括CT、MRI和电子显微镜(见IV-A节和IV-B节)。</p><p><br></p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5fda894b77ee46a68a8ff9d418e3c32b><p class=pgc-img-caption></p></div><p>图1展示了UNet++是如何从最初的UNet发展而来的。</p><p>在接下来的部分中，我们将首先跟踪这一演变过程，从而激发对UNet++的需求，然后解释其技术和实现细节。</p><p><br></p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/12d2e2c7740a4adc9e88fc9d4af0bc7a><p class=pgc-img-caption></p></div><p>图2显示了在不同复杂度的修剪架构中，分割分支的选择是如何产生结果的。具体来说，从X 0,4中提取分割结果不会导致剪枝，而从X0,1中提取分割结果会导致网络的最大剪枝。</p><p><br></p><h1 class=pgc-h-arrow-right>实验</h1><p><br></p><p><strong>数据集:</strong></p><p>（1）电子显微镜(EM):数据集由EM分割挑战[30]提供，作为ISBI 2012的一部分。该数据集包含30张果蝇初生幼体腹神经索(VNC)的连续切片透射电镜图像(512512像素)。参照图3中的例子</p><p><br></p><p>（2）Cell:使用Cell-CT成像系统[31]获取数据集。两个训练有素的专家手动分割收集的图像，因此数据集中的每个图像都带有两个二进制单元掩码。</p><p>(3)Nuclei:数据集由数据科学提供Bowl 2018年分割挑战，包括670个来自不同模式的分割核图像(brightfield vs. fluorescence)。</p><p>(4)脑瘤:数据集由BraTS 2013[32]，[34]提供。为了减少与其他方法的比较，模型使用20个高级别(HG)和10个低级别(LG)的Flair、T1、T1c和T2扫描所有患者的MR图像，共得到66348个切片。</p><p>（5）肝脏:数据集由MICCAI 2017 LiTS Challenge提供，包含331个CT扫描，我们将其分为训练(100例患者)、验证(15例患者)和测试(15例患者)亚组。</p><p>（6）肺结节:数据集由肺图像数据库联盟(LIDCIDRI)[33]提供，包括7个学术中心和8个医学影像公司收集的1018例病例。确定并排除了六例地面真相问题。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a5dc5a6bda2a4c27a820cfaf5b6ef0c6><p class=pgc-img-caption></p></div><p><br></p><p><strong>实验结果：</strong></p><p>表3：更宽版本的U-Net和V-Net被设计成具有与UNet++和VNet++相当数量的参数。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f122cec7477f4f149362d3b52b85a297><p class=pgc-img-caption></p></div><p>表4：对U-Net、宽U-Net、UNet+(我们的中间建议)和UNet++(我们的最终建议)的语义分割结果使用IoU(平均s.d. %)测量。UNet+和UNet++均在有和无深度监督(DS)的情况下进行评估。我们对U-Net[5]和其他20个独立试验进行了独立的两个样本t检验，并在差异有统计学意义时用红色高亮框标出(p &lt;0.05)。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3b75209de6d64f938f8f5b17497bfc84><p class=pgc-img-caption></p></div><p><br></p><p>图4：U-Net、UNet+、UNet+在神经结构、细胞、细胞核、脑肿瘤、肝脏切分等领域的最新研究进展。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5dde4388fd254ee18569b1c8bec77fe0><p class=pgc-img-caption></p></div><p>表5：重新设计的跳过连接提高了语义和实例分割的原子核分割的任务。我们使用Mask R-CNN进行实例分割，使用U-Net进行语义分割。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/307ce0a008784deb823750f0326e92f9><p class=pgc-img-caption></p></div><p><br></p><p>图8:脑肿瘤图像中沿顶部最跳跃连接的早期、中期和晚期的特征图的可视化和比较。这里，点箭头表示U-Net和UNet+中的简单跳跃连接，而破折号箭头表示UNet++中引入的密集连接。</p><div class=pgc-img><img alt=UNet++：重新设计跳跃连接，利用图像分割中的多尺度特征 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2f7a6942c67a419fb011a74e2e355bef><p class=pgc-img-caption></p></div><p><br></p><h1 class=pgc-h-arrow-right>结论</h1><p>我们提出了一个新的架构，名为UNet++，以更准确的图像分割。我们的UNet++性能的提高归功于它的嵌套结构和重新设计的跳跃连接，旨在解决U-Net的两个关键挑战:1)优化架构的未知深度和2)跳跃连接的不必要的限制性设计。我们使用了六种不同的生物医学成像应用程序对UNet++进行了评估，并在语义分割和实例分割的元框架的各种最先进的主干上展示了一致的性能改进。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'特征','UNet','++'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>