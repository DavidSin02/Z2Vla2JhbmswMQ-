<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度学习-学习率衰减策略 | 极客快訊</title><meta property="og:title" content="深度学习-学习率衰减策略 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/51d0468cc1184f3fbf9062d872199b81"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/e587649.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/e587649.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/e587649.html><meta property="article:published_time" content="2020-10-29T21:02:15+08:00"><meta property="article:modified_time" content="2020-10-29T21:02:15+08:00"><meta name=Keywords content><meta name=description content="深度学习-学习率衰减策略"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/e587649.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度学习-学习率衰减策略</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><p>梯度下降算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些</strong>，使得网络更好的收敛到最优解。下图展示了随着迭代的进行动态调整学习率的4种策略曲线：</p><div class=pgc-img><img alt=深度学习-学习率衰减策略 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/51d0468cc1184f3fbf9062d872199b81><p class=pgc-img-caption></p></div><p>上述4种策略为自己根据资料整理得到的衰减类型：指数衰减、固定步长的衰减、多步长衰、余弦退火衰减。下面逐一介绍其性质，及pytorch对应的使用方式，需要注意学习率衰减策略很大程度上是<strong>依赖于经验与具体问题的</strong>，不能照搬参数。</p><p><br></p><p><strong>1、指数衰减</strong></p><p>学习率按照指数的形式衰减是比较常用的策略，我们首先需要确定需要针对哪个优化器执行学习率动态调整策略，也就是首先定义一个优化器：</p><pre><code>optimizer_ExpLR = torch.optim.SGD(net.parameters(), lr=0.1)</code></pre><p>定义好优化器以后，就可以给这个优化器绑定一个指数衰减学习率控制器：</p><pre><code>ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer_ExpLR, gamma=0.98)</code></pre><p>其中<strong>参数gamma表示衰减的底数，选择不同的gamma值可以获得幅度不同的衰减曲线</strong>，如下：</p><div class=pgc-img><img alt=深度学习-学习率衰减策略 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/02fd32d722b24ed0abd51654aa9d81e1><p class=pgc-img-caption></p></div><p><br></p><p><strong>2、固定步长衰减</strong></p><p>有时我们希望学习率每隔一定步数（或者epoch）就减少为原来的gamma分之一，使用固定步长衰减依旧先定义优化器，再给优化器绑定StepLR对象：</p><pre><code>optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=0.1)StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=0.65)</code></pre><p>其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整，下面对比了不同gamma值下的学习率变化情况：</p><div class=pgc-img><img alt=深度学习-学习率衰减策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c752cbef7c6d4387928ab97f55ed134e><p class=pgc-img-caption></p></div><p><br></p><p><strong>3、多步长衰减</strong></p><p>上述固定步长的衰减的虽然能够按照固定的区间长度进行学习率更新<strong>，但是有时我们希望不同的区间采用不同的更新频率，或者是有的区间更新学习率，有的区间不更新学习率</strong>，这就需要使用MultiStepLR来实现动态区间长度控制：</p><pre><code>optimizer_MultiStepLR = torch.optim.SGD(net.parameters(), lr=0.1)torch.optim.lr_scheduler.MultiStepLR(optimizer_MultiStepLR,                    milestones=[200, 300, 320, 340, 200], gamma=0.8)</code></pre><p>其中milestones参数为表示学习率更新的起止区间，在区间[0. 200]内学习率不更新，而在[200, 300]、[300, 320].....[340, 400]的右侧值都进行一次更新；gamma参数表示学习率衰减为上次的gamma分之一。其图示如下：</p><div class=pgc-img><img alt=深度学习-学习率衰减策略 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/44488c40fdc144d2aa8a25bb5c06f2ca><p class=pgc-img-caption></p></div><p>从图中可以看出，学习率在区间[200， 400]内快速的下降，这就是milestones参数所控制的，在milestones以外的区间学习率始终保持不变。</p><p><br></p><p><strong>4、余弦退火衰减</strong></p><p>严格的说，余弦退火策略不应该算是学习率衰减策略，因为它使得学习率按照周期变化，其定义方式如下：</p><pre><code>optimizer_CosineLR = torch.optim.SGD(net.parameters(), lr=0.1)CosineLR = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_CosineLR, T_max=150, eta_min=0)</code></pre><p>其包含的参数和余弦知识一致，参数T_max表示余弦函数周期；eta_min表示学习率的最小值，默认它是0表示学习率至少为正值。确定一个余弦函数需要知道最值和周期，其中周期就是T_max，最值是初试学习率。下图展示了不同周期下的余弦学习率更新曲线：</p><div class=pgc-img><img alt=深度学习-学习率衰减策略 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/13981821c06d4e04bc1b89e98447ab7b><p class=pgc-img-caption></p></div><p><br></p><p><strong>5、上述4种学习率动态更新策略的说明</strong></p><p>4个负责学习率调整的类：StepLR、ExponentialLR、MultiStepLR和CosineAnnealingLR，其完整对学习率的更新都是在其step()函数被调用以后完成的，这个step表达的含义可以是一次迭代，当然更多情况下应该是一个epoch以后进行一次scheduler.step()，这根据具体问题来确定。此外，根据pytorch官网上给出的说明，scheduler.step()函数的调用应该在训练代码以后：</p><pre><code>scheduler = ...&gt;&gt;&gt; for epoch in range(100):&gt;&gt;&gt;     train(...)&gt;&gt;&gt;     validate(...)&gt;&gt;&gt;     scheduler.step()</code></pre><p>本文来源：知乎</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'学习','学习率','衰减'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>