<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>理解凸性:为什么梯度下降适用于线性回归 | 极客快訊</title><meta property="og:title" content="理解凸性:为什么梯度下降适用于线性回归 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/9eda7c3599bd4983babdbc0edd64044c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/ec9167e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/ec9167e.html><meta property="article:published_time" content="2020-10-29T20:55:38+08:00"><meta property="article:modified_time" content="2020-10-29T20:55:38+08:00"><meta name=Keywords content><meta name=description content="理解凸性:为什么梯度下降适用于线性回归"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/ec9167e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>理解凸性:为什么梯度下降适用于线性回归</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><p>在机器学习中我们总会遇到线性回归问题，但是为什么我们可以用梯度下降算法来求解线性回归成本函数呢？凸性理论可以让我们更容易理解这个问题。</p><h1 class=pgc-h-arrow-right>凸性</h1><p>首先，通过凸集和凸函数定义凸度。凸集的定义如下:</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9eda7c3599bd4983babdbc0edd64044c><p class=pgc-img-caption></p></div><p>在二维中，我们可以将凸集视为一个形状，无论您用什么线连接集中的两个点，都不会在集外。</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/be14dc2b815140dbbf351628459fc98f><p class=pgc-img-caption>（左）凸集，（中）非凸集，（右）凸集</p></div><p>凸集的定义正好体现在凸函数的定义中，如下所示：</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a53f22a6df8e47729ee4f32710636a13><p class=pgc-img-caption></p></div><p>你可以直观地把凸函数想象成这样的函数:如果你画一条从(x,f(x))到(y,f(y))的直线，那么凸函数的图像就会在这条直线的下方。下面是三个例子，我们应用这个直觉来确定函数是否是凸的。</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/edbe443661144544ae4ef6fda5fd9a42><p class=pgc-img-caption>（左）具有唯一优化器的凸函数，（中）非凸函数，（右）具有多个优化器的凸函数</p></div><p>我们可以看到中间的图不是凸的，因为当我们绘制连接图上两个点的线段时，有一些点（x，f（x））大于f（x）上对应的点。</p><p>左边和右边的图形都是凸的。不管你在这些图上画什么线段，这个线段总是在函数图的上面或者等于函数图。</p><p>现在我们对凸集和凸函数有了一些直觉和理解，让我们转向线性回归，看看凸性在哪里起作用。</p><h1 class=pgc-h-arrow-right>线性回归回顾</h1><p>假设在n维空间中有m个数据样本。每个样本都有n个映射到单个输出值的特性。我们可以访问输入和输出数据，但是我们想弄清楚输入数据和输出数据之间是否存在线性关系。这就是线性回归模型的用处。该模型的形式为:</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4880e614c6734ba2922976bb5eb0b94c><p class=pgc-img-caption></p></div><p>现在，我们确定最佳线性模型的方法是求解模型的系数，使我们的估计输出值与实际输出值之间的误差最小化。我们可以用线性最小二乘法来实现。因此，我们的成本函数如下:</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e507faa108a144b4a69b6581c349eb45><p class=pgc-img-caption></p></div><p>我们称这个函数为“成本”函数，因为我们计算的是估算值与实际值之间的总误差或成本。由于线性最小二乘问题是一个二次函数，我们可以用解析的方法最小化这个成本函数。然而，对于大型机器学习数据集，使用一种称为梯度下降的迭代方法来寻找最佳系数通常计算速度更快。如何使用梯度下降来最小化成本函数的详细说明如下:</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/025df8f11a74460f86816af19edb83ec><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>成本函数的凸性</h1><p>现在我们来看一些凸优化理论。如上所示，梯度下降法被应用于寻找成本函数的全局最小值。但是我们怎么知道存在一个全局最小值呢?当最小化函数时，凸函数可确保如果存在最小值，则它将是全局最小值。前面我们看到二次函数是凸函数。因为我们知道线性最小二乘问题是二次函数，所以我们也知道它是一个凸函数。</p><p>二次函数（例如线性最小二乘问题）是强凸的。这意味着该函数具有唯一的最小值，而该最小值是全局最小值。因此，当我们应用梯度下降算法时，我们可以确信它将收敛于正确的最小值。如果我们试图最小化的函数是非凸的，则梯度下降可能会收敛于局部最小值而不是全局最小值。这就是为什么使用非凸函数要困难得多。这很重要，因为许多机器学习模型（最著名的是神经网络）是非凸的。您可以看一个示例，梯度下降以最简单的形式没有找到全局最小化器。</p><div class=pgc-img><img alt=理解凸性:为什么梯度下降适用于线性回归 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1a67811e997e4f41a6bc035aeddf93d0><p class=pgc-img-caption>在非凸函数上收敛到局部最小值的梯度下降的示例</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'凸性','什么','适用'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>