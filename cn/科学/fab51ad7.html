<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>基于全局数据集合结构的近邻搜索：极大极小信息传递算法 | 极客快訊</title><meta property="og:title" content="基于全局数据集合结构的近邻搜索：极大极小信息传递算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/3f2400000803d5728be1"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%a6/fab51ad7.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%a6/fab51ad7.html><meta property="article:published_time" content="2020-11-14T20:53:56+08:00"><meta property="article:modified_time" content="2020-11-14T20:53:56+08:00"><meta name=Keywords content><meta name=description content="基于全局数据集合结构的近邻搜索：极大极小信息传递算法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E5%AD%A6/fab51ad7.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>基于全局数据集合结构的近邻搜索：极大极小信息传递算法</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E5%AD%A6.html>科学</a></span></div><div class=post-content><div><p class=正文><strong>Neighbor Search with Global Geometry:A Minimax Message Passing Algorithm</strong></p><p class=正文><strong>人脸识别简介：</strong></p><p class=正文>人脸识别技术是基于人的脸部特征，对输入的人脸图象或者视频流 . 首先判断其是否存在人脸 , 如果存在人脸，则进一步的给出每个脸的位置、大小和各个主要面部器官的位置信息。并依据这些信息，进一步提取每个人脸中所蕴涵的身份特征，并将其与已知的人脸进行对比，从而识别每个人脸的身份。</p><p class=正文>　　广义的人脸识别实际包括构建的一系列相关技术，包括人脸图像采集、人脸定位、人脸识别预处理、身份确认以及身份查找等；而狭义的人脸识别特指通过人脸进行身份确认或者身份查找的技术或系统。</p><p class=正文>人脸识别技术中被广泛采用的区域特征分析算法，它融合了计算机图像处理技术与生物统计学原理于一体，利用计算机图像处理技术从视频中提取人像特征点，利用生物统计学的原理进行分析建立数学模型,即人脸特征模板。利用已建成的人脸特征模板与被测者的人的面像进行特征分析，根据分析的结果来给出一个相似值。通过这个值即可确定是否为同一人。</p><p class=正文>基本算法：1.基于人脸特征点的识别算法（Feature-based recognition algorithms）。</p><p class=正文>2.基于整幅人脸图像的识别算法（Appearance-based recognition algorithms）。</p><p class=正文>3.基于模板的识别算法（Template-based recognition algorithms）。</p><p class=正文>4.利用神经网络进行识别的算法（Recognition algorithms using neural network）。</p><p class=正文>5.利用线性回归进行识别的算法。</p><p class=正文>6.利用稀疏表示进行识别的算法。</p><p class=正文>我的课题是利用最小最大距离进行人脸识别的算法（ Neighbor with Global Geometry：A Minimax Message Passing Algorithm ）</p><p class=正文><strong>核心算法：</strong></p><p class=正文>1. <strong>k-Nearest Neighbor algorithm（k邻近算法）</strong></p><p class=正文>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN方法虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。</p><p class=正文>具体来说就是在N个已知样本中，找出X的k个近邻。设这N个样本中，来自</p><p>类的样本有</p><p>个，来自</p><p>类的有</p><p>个，&amp;hellip;，来自</p><p>类的有</p><p>个，若</p><p>分别是k个近邻中属于</p><p>类的样本数，则我们可以定义判别函数为：</p><p></p><p class=正文>决策规则为：若</p><p></p><p class=正文>则决策</p><p>。</p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3f2400000803d5728be1></p><p class=正文>上图中，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。</p><p class=正文>2. <strong>minimum spanning tree（最小生成树）</strong></p><p class=正文>在一给定的 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 ），而 w(u, v) 代表此的权重，若存在 T 为 E 的（即 ）且为，使得 w(T) 最小，则此 T 为 G 的最小生成树。</p><p class=正文>许多应用问题都是一个求无向连通图的最小生成树问题。例如：在设计电子线路时，常常要把数个元件的引脚连接在一起，使其电位相同。要是n个引脚互相连通，可以使用n-1条连接线，每条连接线连接两个引脚。在各种连接方案中，通常希望找出连接线最小的接法。</p><p class=正文>可以把这一接线问题模型化为一个无向连通图G=（V,E），其中V是引脚集合，E是每对引脚之间可能互联的集合。对图中每一条边 ，都有一个权值 ， 表示 u 和 v 的代价（需要接线数目）。我们希望找出一个无回路的子集 ,它连接了所有的顶点，且其权值之和：</p><p class=正文>为最小。因为T无回路且连接所有的顶点，所以它必然是一棵树，称为生成树（spanning tree），因为它&amp;ldquo;生成&amp;rdquo;了图G。把确定树T的问题称为最小生成树。</p><p class=正文>3. <strong>欧氏距离</strong></p><p class=正文>度量定义中，点 x = (x1,...,xn) 和 y = (y1,...,yn) 之间的距离为：</p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/3ecf00002d509c1bdc9d></p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3ecf00002d522bfb1978> 的自然长度，即该点到原点的距离为</p><p class=正文>. <img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3ece000037c0d1313aa6></p><p class=正文>它是一个纯数值。在欧几里得度量下，两点之间最短。</p><p class=正文>欧氏距离变换在中的应用范围很广泛，尤其对于图像的骨架提取，是一个很好的参照。</p><p class=正文><strong>论文分析：</strong></p><p class=正文>对于人脸识别来讲，我们需要将人脸的正面图片转换成为矩阵，通过数字矩阵来表征人脸，每张人脸图片都是一个1024*1的矩阵，在不同的光照和位置的环境下，每个人一共有10张不同的图片，即1024*10矩阵。一共40个人，则会有一个1024*400矩阵。我们要做的工作就是给定一个这40个中的一个人的人脸数据，对人脸数据进行鉴别分类，最后确定这张人脸是哪个人。</p><p class=正文>具体来讲，我们都会用kNN算法进行分类，用欧氏距离计算出测试样本到训练样本的距离，并对最近的距离进行排列，对k取值，例如取5，那么分析前5个中哪一类占比重大，如果一类有3个，那么将把测试样本归入1类中。</p><p class=正文>但是，利用欧氏距离进行kNN分类存在问题，尤其是在基于全局数据几何结构的邻近搜索中，见下图：</p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3ecf00002d54c04ec4c0></p><p class=正文>对于(a)图来讲，用欧式距离结果是正确的，可以把黑星分类正确，但是对于(b)图来讲，用欧式距离会把黑星分类给蓝色的叉号一类，造成分类错误。对于(c)图，绿线以上的黑点会分类到红圈中，绿线以下的黑点会分类到蓝叉中。由此会发现欧式距离来对具有几何结构的数据进行分类会造成严重的误差。然而，欧式距离更适用于具有球形分布结构的数据，人脸数据一般不满足这一条件，最大最小距离（minimax distance）基于数据的流型结构，是一种更适合人脸的度量方法。</p><p class=正文>下面介绍用构造最小生成树来计算距离然后进行分类。用最小生成树得到一棵权值之和最小的树，由最小生成树的性质可知，从一个点到任何一个端点的路径是唯一的，那么我们定义每一个训练样本点a到测试样本点b的距离d为：d等于从a到b路径上所有点的两点之间的最大值。然后记录下来这个距离，那么每个训练样本到测试样本点的距离都计算并保存起来，为了达到更加精确减小误差，我们在距离d的基础上加上（λ*欧式距离），得到最终的距离，根据kNN算法，对这些距离排序，根据k的取值不同，最后得到哪个类标所占的比重更大，就把测试样本分类过去。</p><p class=正文>几点需要注意的，1.要把所有的测试样本和训练样本加到一起来生成MST。2.把测试样本加进去一起生成树的原因是能够较为准确的反应几何流线型。</p><p class=正文>结果的分析就是，例如，我们从400个样本中选取200个特征脸数据当做测试样本，另外200张脸当做训练样本，因为我们已知测试样本属于的类标，根据分类结果的样本类标分析结果，如果180个样本相符合，那么正确率就是180/200*100%=90%。</p><p class=正文><strong>算法设计：</strong></p><p class=正文>1. 对1024*400的人脸数据建立全连接，即每张人脸数据到其他人脸数据的欧式距离，构造一个全连接。</p><p class=正文>2. 生成最小生成树MST。</p><p class=正文>3. 计算测试样本到训练样本的距离（A=MMD+0.01*ED;MMD是最小生成树计算得到的两点之间的距离，ED是两点之间的欧式距离，加上欧式距离是因为太多点之间点的距离是相等的，使得最终距离之间产生区分）。</p><p class=正文>4. 从生成的距离矩阵中提取测试离样本，然后对每一个测试样本到所有训练样本的距离进行排序，用kNN算法取前k个距离最近的训练样本，比较所占比例最大的训练样本类，将测试样本分类到训练样本类中。</p><p class=正文>5. 最终根据测试样本分类正确的数目比上测试样本的总量得到精度accuracy。</p><p class=正文><strong>精确度分析：</strong></p><p class=正文>影响精确度（accuracy）有以下几个方面：①样本维度。②λ的取值大小。③k的选取。</p><p class=正文>④测试样本和训练样本的比例（label_train的设置）。⑤精确度的平均次数n。</p><p class=正文>结果如下：</p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/3ece000037c19624f897></p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/3ecd0002d4ed5c5d6ede></p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3ece000037c5cd976743></p><p class=正文><img alt=基于全局数据集合结构的近邻搜索：极大极小信息传递算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3ecf00002d58286ce2c9></p><p class=正文>从上面表格的分析数据我们可以看出：</p><p class=正文>1. 精确度的平均次数n对精确度基本上没有影响。</p><p class=正文>2. 训练样本和测试样本的比例取值对精确地影响较大，精确度随着训练样本比例的下降而降低，就是说训练样本比重大，测试样本比重小时，精度比较大；反之亦然。</p><p class=正文>3． A=MMD+λ*ED中的λ取值的大小对精确度也没有太大的影响。</p><p class=正文>4. 维度改变和k值改变对精确度的影响较大，维数不同精确度差别很大，就测试的三个1024*400，191*213,88*400样本中，191*213的样本精确度比较高；而在同一个样本下，精确度是随着k的增长而降低的，当然k近邻算法中k的选择是公认的难题，姑且就取k=3。</p><p class=正文><strong>算法精度优势分析</strong></p><p class=正文>根据上述的分析，我们取样本data_test_JAFFE（191*213），k=3, λ=0.01,label_train比例为0.01/0.99 , n=20,最终得到的精确度是：accuracy=98.63。达到了较高的精度要求！</p><p class=正文>为了证明这种算法的优越性，我们和只用欧式距离进行kNN分类的算法的精度进行比较，在其他条件不变的情况下，得到精度为：95.30。很明显98.63>95.30，体现了基于最小生成树的kNN分类算法在进行人脸识别时的优越性!</p><p class=正文><strong>参考文献：</strong></p><p class=正文>1.算法导论（原书第二版）<em>Thomas H.Cormen / Charles E.Leiserson / Ronald L.Rivest /Clifford Stein </em>潘金贵 等译 出 版 社： 出版时间： 2006-9-1</p><p class=正文>2.模式识别（第二版） 边肇祺 张学工等编着 出版社：清华大学出版社 出版时间：2010-8</p><p class=正文>3.MATLAB宝典 作者：陈杰　 ： 　出版时间： 2007</p><p class=正文>4.Neighbor with Global Geometry：A Minimax Message Passing Algorithm .ICML 2007. ssssKye-Hyeon Kim Seungjin Choi Department of Computer Science,Pohang University of Science and Technology,San 31 Hyoja-dong,Nam-gu,Pohang 790-784,Korea.</p><p class=正文><strong>收获心得</strong></p><p class=正文>1. 本次实习体验了两周的科研生活，提高了英文论文阅读以及利用互联网搜索相关文献的能力，从课题中对最小生成树算法和k近邻算法有了更加深刻的认识和体会，提升了matlab的程序编写的能力，熟悉了PPT的制作方法，认识到了模式识别在研究领域的重要意义。</p><p class=正文>2.编写算法的代码尽可能的精简，尽量的高效，因为在数据量很大的情况下，即是是多一次循环也会浪费很多时间。</p><p class=正文>3.张青富教授关于多目标跟踪识别的讲座，高性能计算的讲座，机器学习的讲座开拓了视野，激发了兴趣，印象比较深刻的是缑老师的&amp;ldquo;关于机器学习在互联网应用上的研究&amp;rdquo;的讲座，让我认识到了机器学习在未来互联网生活中的价值，并坚定了我深入学习理论的信念。</p><p class=正文>4.感谢计院和电院的领导和老师们让我有这次机会参加暑期学校学习的机会，让我收获很多；另外还要感谢我的指导老师王晓东博士，耐心细致的指导帮助我圆满的完成了课题；最后还要感谢我周围的同学的帮助，让我体会到了团队的力量。</p><p class=正文><strong>附录（代码）：</strong></p><p class=正文><strong>建立全连接：</strong></p><p class=正文>function g_mst=make_PV(W_pca_data)</p><p class=正文>[D,N]=size(W_pca_data);</p><p class=正文>g_mst=zeros(N*(N-1)/2,3); g_mst1=zeros(N*(N-1)/2,3); n=0;</p><p class=正文>for i=1:N-1</p><p class=正文>for j=i+1:N</p><p class=正文>n=n+1;</p><p class=正文>g_mst(n,:)=[i,j,norm(W_pca_data(:,i)-W_pca_data(:,j))]; g_mst1(n,:)=[i,j,norm(W_pca_data(:,i)-W_pca_data(:,j))];</p><p class=正文>end</p><p class=正文>end</p><p class=正文><strong>最小生成树矩阵g_mst：</strong></p><p class=正文>% function [g_mst,gT]=Kruskal_MST(g_mst)</p><p class=正文>function g_mst=Kruskal_MST(g_mst)</p><p class=正文>tic</p><p class=正文>[Y,I]=sort(g_mst(:,3),'ascend');</p><p class=正文>g_mst=g_mst(I,:);</p><p class=正文>g_mst=[g_mst,zeros(size(g_mst,1),1)];</p><p class=正文>% g_mst=[g_mst(1,1) g_mst(1,1) 0 1;g_mst];</p><p class=正文>g_mst=[-1 -1 0 0;g_mst];</p><p class=正文>i=0;</p><p class=正文>iter=1;</p><p class=正文>for n=2:size(g_mst,1)</p><p class=正文>iter=iter+1;</p><p class=正文>I=find(g_mst(iter,1)==g_mst(1:iter-1,1));</p><p class=正文>if isempty(I)</p><p class=正文>I=find(g_mst(iter,1)==g_mst(1:iter-1,2));</p><p class=正文>end</p><p class=正文>if isempty(I)</p><p class=正文>a=0;</p><p class=正文>else</p><p class=正文>a=g_mst(I(1),4);</p><p class=正文>end</p><p class=正文>I=find(g_mst(iter,2)==g_mst(1:iter-1,1));</p><p class=正文>if isempty(I)</p><p class=正文>I=find(g_mst(iter,2)==g_mst(1:iter-1,2));</p><p class=正文>end</p><p class=正文>if isempty(I)</p><p class=正文>b=0;</p><p class=正文>else</p><p class=正文>b=g_mst(I(1),4);</p><p class=正文>end</p><p class=正文>if (a==0) && (b==0)</p><p class=正文>i=i+1;</p><p class=正文>g_mst(iter,4)=i;</p><p class=正文>elseif (a~=0) && (b==0)</p><p class=正文>g_mst(iter,4)=a;</p><p class=正文>elseif (a==0) && (b~=0)</p><p class=正文>g_mst(iter,4)=b;</p><p class=正文>elseif (a~=0) && (b~=0)</p><p class=正文>if a>b</p><p class=正文>I=(g_mst(1:iter-1,4)==a);</p><p class=正文>g_mst(I,4)=b;</p><p class=正文>g_mst(iter,4)=b;</p><p class=正文>elseif b>a</p><p class=正文>I=(g_mst(1:iter-1,4)==b);</p><p class=正文>g_mst(I,4)=a;</p><p class=正文>g_mst(iter,4)=a;</p><p class=正文>else</p><p class=正文>g_mst=[g_mst(1:iter-1,:);g_mst(iter+1:end,:)];</p><p class=正文>iter=iter-1;</p><p class=正文>end</p><p class=正文>end</p><p class=正文>end</p><p class=正文>% g_mst1=g_mst(2:end,:);</p><p class=正文>if max(g_mst(:,4))~=1</p><p class=正文>disp('Graph is not connected');</p><p class=正文>end</p><p class=正文>g_mst=g_mst(2:end,1:3);</p><p class=正文>% gT=zeros(size(g_mst,1)+1);</p><p class=正文>% for i=1:size(g_mst,1)</p><p class=正文>% a=g_mst(i,1);</p><p class=正文>% b=g_mst(i,2);</p><p class=正文>% gT(a,b)=1;</p><p class=正文>% gT(b,a)=1;</p><p class=正文>% end</p><p class=正文>toc</p><p class=正文><strong>计算最大最小距离矩阵MMD：</strong>function MMD=minimax_distance(g_mst)</p><p class=正文>MMD=zeros(size(g_mst,1)+1);</p><p class=正文>for i=1:size(g_mst,1)+1</p><p class=正文>MMD(:,i)=single_minimax_distance(g_mst,i);</p><p class=正文>%MMD(:,i)=single_minimax_distance(g_mst,i);</p><p class=正文>end</p><p class=正文>function V=single_minimax_distance(g_mst,n)</p><p class=正文>Omega=n;</p><p class=正文>V=zeros(size(g_mst,1)+1,1);</p><p class=正文>A=[n 0];</p><p class=正文>while length(Omega)&lt;=size(g_mst,1)</p><p class=正文>[A,V]=nextpoints(A,Omega,g_mst,V);</p><p class=正文>Omega=[Omega; A(:,1)];</p><p class=正文>end</p><p class=正文>function [B,V]=nextpoints(A,Omega,g_mst,V)</p><p class=正文>B=[];</p><p class=正文>for i=1:size(A,1)</p><p class=正文>I= g_mst(:,1)==A(i,1);</p><p class=正文>b=g_mst(I,2:3);</p><p class=正文>for j=1:size(b,1)</p><p class=正文>if ~sum(Omega==b(j,1))</p><p class=正文>B=[B; [b(j,1) max(A(i,2),b(j,2))]];</p><p class=正文>V(fix(B(end,1)))=max(A(i,2),b(j,2));</p><p class=正文>end</p><p class=正文>end</p><p class=正文>% disp('!!!')</p><p class=正文>I= g_mst(:,2)==A(i,1);</p><p class=正文>b=g_mst(I,[1 3]);</p><p class=正文>for j=1:size(b,1)</p><p class=正文>if ~sum(Omega==b(j,1))</p><p class=正文>B=[B; [b(j,1) max(A(i,2),b(j,2))]];</p><p class=正文>V(fix(B(end,1)))=max(A(i,2),b(j,2));</p><p class=正文>end</p><p class=正文>end</p><p class=正文>% disp('!!!')</p><p class=正文>end</p><p class=正文><strong>计算欧式距离矩阵ED：</strong></p><p class=正文>function ED=Euclidean_distance(ORL_data)</p><p class=正文>[D,N]=size(ORL_data);</p><p class=正文>ED=zeros(N,N);</p><p class=正文>for i=1:N-1</p><p class=正文>for j=i+1:N</p><p class=正文>ED(i,j)=norm(ORL_data(:,i)-ORL_data(:,j));</p><p class=正文>ED(j,i)=ED(i,j);</p><p class=正文>end</p><p class=正文>end</p><p class=正文><strong>生成最终最大最小距离矩阵Ａ：</strong></p><p class=正文>function A=makeA(W_pca_data)</p><p class=正文>g_mst=make_PV(W_pca_data);</p><p class=正文>g_mst=Kruskal_MST(g_mst);</p><p class=正文>MMD=minimax_distance(g_mst);</p><p class=正文>ED=Euclidean_distance(W_pca_data);</p><p class=正文>A=MMD+0.01*ED;</p><p class=正文><strong>N次平均取平均值得到最终精度accuracy：</strong></p><p class=正文>function accuracy=ntimes_MMD(n,A,label,k)</p><p class=正文>accuracy=0;</p><p class=正文>for i=1:n</p><p class=正文>label_train=rand(1,size(A,2))>0.4;</p><p class=正文>accuracy1=Mytest(A,label,label_train,k);</p><p class=正文>accuracy=accuracy+accuracy1;</p><p class=正文>end</p><p class=正文>accuracy=accuracy/n;</p><p>� EMBED Equation.DSMT4 ���</p><p>� EMBED Equation.DSMT4 ���</p><p>� EMBED Equation.DSMT4 ���</p><p>� EMBED Equation.DSMT4 ���</p><p></p><p></p><p></p><p></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'数据','结构','极大极'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>