<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） | 极客快訊</title><meta property="og:title" content="Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/e11e69f643584941aaa2b71ee6ed3d7f"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/04486eba.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/04486eba.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/04486eba.html><meta property="article:published_time" content="2020-11-14T21:07:40+08:00"><meta property="article:modified_time" content="2020-11-14T21:07:40+08:00"><meta name=Keywords content><meta name=description content="Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆）"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/04486eba.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>前言</strong></p><p>本文的文字及图片来源于网络,仅供学习、交流使用,不具有任何商业用途,版权归原作者所有,如有问题请及时联系我们以作处理。</p><p>作者： python小爬虫</p><p>PS：如有需要Python学习资料的小伙伴可以加点击下方链接自行获取</p><p>http://note.youdao.com/noteshare?id=3054cce4add8a909e784ad934f956cef</p><ol start=0><li>效果图，其中涉及一些真名我就打码了，还有qq号我也打码了，见谅</li><li>分析登陆的元素，下图一目了然，怎么获取这个登陆元素应该都知道了</li><li>代码奉上</li></ol><pre>url = 'https://qun.qq.com/'# 构建谷歌驱动器browser = webdriver.Chrome()# 请求urlbrowser.get(url)# 模拟登陆，首先找到登陆的id，并点击browser.find_element_by_css_selector('#headerInfo p a').click()</pre><ol start=4><li>点击之后出现这么一个框框（这个框框可把我折磨的阿）原因是这样的，寻常的获取这个框框是不能获取到的</li></ol><p>5.先看看这个框所在的位置，这个框框竟然在另一个html代码里面，也就是说在浏览器看的时候，出现了两个html标签，老实说，我是第一次看到这种情况的，奈何我的html也不好，连入门都算不上，没办法，我就去百度了，果然黄天不负有心人，说是因为iframe这个标签可以再放html代码，所以就是这种情况了</p><div class=pgc-img><img alt=Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e11e69f643584941aaa2b71ee6ed3d7f><p class=pgc-img-caption></p></div><ol start=5><li>既然知道了是怎么一回事之后，那就可以继续操作了，首先我们先找到iframe这个标签，然后获取它的src属性，这个链接就是这个框框登陆的链接了，如果不获取这个iframe标签的src属性，那么我们使用selenium是获取不到这个框框的元素的。</li></ol><pre># 点击之后会弹出一个登陆框，这时候我们用显示等待来等待这个登陆框加载出来WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CSS_SELECTOR, '#loginWin iframe') ))print('登陆框已加载')# 登陆框加载之后，我们发现整个登陆框其实就是另一个网网页# 如果在原网页操作这个登陆框的话，是不能操作的# 所以我们只需要提取iframe标签的src属性，然后再去访问这个url即可实现# 自动登陆# 找到iframe标签并获取srciframe_url = browser.find_element_by_css_selector('#loginWin iframe').get_attribute('src')# 再访问这个urlbrowser.get(iframe_url)# 找到快捷登陆的头像并点击# 首先用显示等待这个头像已经加载完成WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.ID, 'qlogin_list') ))browser.find_element_by_css_selector('#qlogin_list a').click()print('登陆成功')</pre><ol start=7><li>登陆成功之后我们需要的是群管理，是ul标签的第四个li标签，通过xpath获取</li></ol><pre># 登陆成功之后，我们就找到群管理的标签并点击,首先等待这个元素加载完成WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.XPATH, './/ul[@id="headerNav"]/li[4]') ))browser.find_element_by_xpath('.//ul[@id="headerNav"]/li[4]').click()</pre><p>8.点击群管理之后，进入群管理界面，我们需要的是成员管理</p><div class=pgc-img><img alt=Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b688405faac9489497041e3306a49af4><p class=pgc-img-caption></p></div><pre># 点击之后，我们找到成员管理标签并点击WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'color-tit') ))browser.find_element_by_class_name('color-tit').click()</pre><p>9.点击成员管理之后会重新新建一个窗口，这个时候就会出现句柄，我们需要将当然窗口的句柄切换到新打开的这个界面，不然的话，是获取不到新打开界面的信息的，注释已经写了</p><div class=pgc-img><img alt=Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/20c6aa3808de4890b2a16d4c9f0b6c51><p class=pgc-img-caption></p></div><pre># 打印全部窗口句柄# print(browser.window_handles)# 打印当前窗口句柄# print(browser.current_window_handle)# 注意这里点击成员管理之后会自动跳转到一个新窗口打开这个页面# 所以我们需要将窗口句柄切换到这个新窗口browser.switch_to.window(browser.window_handles[1])# 解释一下browser.switch_to.window是获取当前一共有几个窗口# 这里是2个# browser.switch_to.window这个是指定当前游标切换到哪个窗口# 其实也可以这么写# all_window = browser.switch_to.window返回的是一个列表# browser.switch_to.window(all_window[1])# 效果是一样的</pre><p>10.我们需要的是我加入的群信息</p><div class=pgc-img><img alt=Python爬虫使用selenium爬取群成员信息（全自动实现自动登陆） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/12409e6a5bb442b485e7bfe9e67b6f83><p class=pgc-img-caption></p></div><pre># 切换句柄之后，我们显示等待窗口出来 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'my-all-group') ) ) # 筛选出我加入的群标签 lis = browser.find_elements_by_xpath('.//div[@class="my-all-group"]/ul[2]/li')</pre><p>11.遍历列表，取出信息</p><pre># 遍历num= 0while True: if num == len(lis): break try: # 按顺序选择群并获取信息 # 先点击该群获取成员信息 lis[num].click() # 显示等待信息加载完成 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'list') ) ) # 获取该群当前有多少人，后面翻页需要 groupMemberNum = eval(browser.find_element_by_id('groupMemberNum').text) # 每一次翻页都会刷新21条信息，所以写个循环 # 这里加1是因为假如一个群有36人，那么count=1，如果循环的话就不会翻页了 # 也就是只能抓到一页的数据，大家可以自己想想其中的流程就知道了 count = groupMemberNum // 21 + 1 # 这里我只爬取每个群的一部分，如果想爬取全部成员信息 # 请注释下面的if语句 if count &gt; 2: count = 1 # 每次循环都进行翻页 # while count: # count -= 1 # # browser.execute_script('document.documentElement.scrollTop=100000') # time.sleep(2) time.sleep(2) # 开始获取成员信息 trs = browser.find_elements_by_class_name('mb') if trs: # 遍历 for tr in trs: tds = tr.find_elements_by_tag_name('td')[2:] if len(tds) == 8: # qq网名 qq_name = tds[0].text # 群名称 group_name = tds[1].text # qq号 qq_number = tds[2].text # 性别 gender = tds[3].text # qq年龄 qq_year = tds[4].text # 入群时间 join_time = tds[5].text # 等级（积分） level = None # 最后发言时间 end_time = tds[6].text # 声明一个字典存储数据 data_dict = {} data_dict['qq_name'] = qq_name data_dict['group_name'] = group_name data_dict['qq_number'] = qq_number data_dict['gender'] = gender data_dict['qq_year'] = qq_year data_dict['join_time'] = join_time data_dict['level'] = level data_dict['end_time'] = end_time print(data_dict) elif len(tds) == 9: # qq网名 qq_name = tds[0].text # 群名称 group_name = tds[1].text # qq号 qq_number = tds[2].text # 性别 gender = tds[3].text # qq年龄 qq_year = tds[4].text # 入群时间 join_time = tds[5].text # 等级（积分） level = tds[6].text # 最后发言时间 end_time = tds[7].text # 声明一个字典存储数据 data_dict = {} data_dict['qq_name'] = qq_name data_dict['group_name'] = group_name data_dict['qq_number'] = qq_number data_dict['gender'] = gender data_dict['qq_year'] = qq_year data_dict['join_time'] = join_time data_dict['level'] = level data_dict['end_time'] = end_time data_list.append(data_dict) print(data_dict) browser.find_element_by_id('changeGroup').click() time.sleep(3) WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'ui-dialog') ) ) lis = browser.find_elements_by_xpath('.//div[@class="my-all-group"]/ul[2]/li') num += 1 except Exception as e: lis = browser.find_elements_by_xpath('.//div[@class="my-all-group"]/ul[2]/li') num += 1 continue</pre><p><strong>完整代码附上</strong></p><pre># 导入需要的包# 爬取qq群的成员信息from selenium import webdriverfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.common.by import Byimport timeimport jsonimport csv# 开始登陆def login_spider(): url = 'https://qun.qq.com/' # 构建谷歌驱动器 browser = webdriver.Chrome() # 请求url browser.get(url) # 模拟登陆，首先找到登陆的id，并点击 browser.find_element_by_css_selector('#headerInfo p a').click() # 点击之后会弹出一个登陆框，这时候我们用显示等待来等待这个登陆框加载出来 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CSS_SELECTOR, '#loginWin iframe') ) ) print('登陆框已加载') # 登陆框加载之后，我们发现整个登陆框其实就是另一个网网页 # 如果在原网页操作这个登陆框的话，是不能操作的 # 所以我们只需要提取iframe标签的src属性，然后再去访问这个url即可实现 # 自动登陆 # 找到iframe标签并获取是如此熟悉 iframe_url = browser.find_element_by_css_selector('#loginWin iframe').get_attribute('src') # 再访问这个url browser.get(iframe_url) # 找到快捷登陆的头像并点击 # 首先用显示等待这个头像已经加载完成 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.ID, 'qlogin_list') ) ) browser.find_element_by_css_selector('#qlogin_list a').click() print('登陆成功') return browser# 切换句柄操作def switch_spider(browser): # 登陆成功之后，我们就找到群管理的标签并点击,首先等待这个元素加载完成 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.XPATH, './/ul[@id="headerNav"]/li[4]') ) ) browser.find_element_by_xpath('.//ul[@id="headerNav"]/li[4]').click() # 点击之后，我们找到成员管理标签并点击 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'color-tit') ) ) browser.find_element_by_class_name('color-tit').click() # 打印全部窗口句柄 # print(browser.window_handles) # 打印当前窗口句柄 # print(browser.current_window_handle) # 注意这里点击成员管理之后会自动跳转到一个新窗口打开这个页面 # 所以我们需要将窗口句柄切换到这个新窗口 browser.switch_to.window(browser.window_handles[1]) # 解释一下browser.switch_to.window是获取当前一共有几个窗口 # 这里是2个 # browser.switch_to.window这个是指定当前游标切换到哪个窗口 # 其实也可以这么写 # all_window = browser.switch_to.window返回的是一个列表 # browser.switch_to.window(all_window[1]) # 效果是一样的 return browser# 开始采集数据def start_spider(browser): # 声明一个列表存储字典 data_list = [] # 切换句柄之后，我们显示等待窗口出来 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'my-all-group') ) ) # 筛选出我加入的群标签 lis = browser.find_elements_by_xpath('.//div[@class="my-all-group"]/ul[2]/li') # 遍历 num = 0 while True: try: # 按顺序选择群并获取信息 # 先点击该群获取成员信息 lis[num].click() # 显示等待信息加载完成 WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'list') ) ) # 获取该群当前有多少人，后面翻页需要 groupMemberNum = eval(browser.find_element_by_id('groupMemberNum').text) # 每一次翻页都会刷新21条信息，所以写个循环 # 这里加1是因为假如一个群有36人，那么count=1，如果循环的话就不会翻页了 # 也就是只能抓到一页的数据，大家可以自己想想其中的流程就知道了 count = groupMemberNum // 21 + 1 # 这里我只爬取每个群的一部分，如果想爬取全部成员信息 # 请注释下面的if语句 if count &gt; 5: count = 5 # 每次循环都进行翻页 while count: count -= 1 browser.execute_script('document.documentElement.scrollTop=100000') time.sleep(2) time.sleep(3) # 开始获取成员信息 trs = browser.find_elements_by_class_name('mb') if trs: # 遍历 for tr in trs: tds = tr.find_elements_by_tag_name('td')[2:] if len(tds) == 8: # qq网名 qq_name = tds[0].text # 群名称 group_name = tds[1].text # qq号 qq_number = tds[2].text # 性别 gender = tds[3].text # qq年龄 qq_year = tds[4].text # 入群时间 join_time = tds[5].text # 等级（积分） level = None # 最后发言时间 end_time = tds[6].text # 声明一个字典存储数据 data_dict = {} data_dict['qq_name'] = qq_name data_dict['group_name'] = group_name data_dict['qq_number'] = qq_number data_dict['gender'] = gender data_dict['qq_year'] = qq_year data_dict['join_time'] = join_time data_dict['level'] = level data_dict['end_time'] = end_time print(data_dict) elif len(tds) == 9: # qq网名 qq_name = tds[0].text # 群名称 group_name = tds[1].text # qq号 qq_number = tds[2].text # 性别 gender = tds[3].text # qq年龄 qq_year = tds[4].text # 入群时间 join_time = tds[5].text # 等级（积分） level = tds[6].text # 最后发言时间 end_time = tds[7].text # 声明一个字典存储数据 data_dict = {} data_dict['qq_name'] = qq_name data_dict['group_name'] = group_name data_dict['qq_number'] = qq_number data_dict['gender'] = gender data_dict['qq_year'] = qq_year data_dict['join_time'] = join_time data_dict['level'] = level data_dict['end_time'] = end_time data_list.append(data_dict) print(data_dict) browser.find_element_by_id('changeGroup').click() time.sleep(3) WebDriverWait(browser, 1000).until( EC.presence_of_all_elements_located( (By.CLASS_NAME, 'ui-dialog') ) ) lis = browser.find_elements_by_xpath('.//div[@class="my-all-group"]/ul[2]/li') num += 1 except Exception as e: continue return data_listdef main(): browser = login_spider() browser = switch_spider(browser) data_list = start_spider(browser) # 将数据写入json文件 with open('data_json.json', 'a+', encoding='utf-8') as f: json.dump(data_list, f) print('json文件写入完成') # 这里的编码格式不要写错了，不然会出现乱码，因为群里面的大神名字贼骚 with open('data_csv.csv', 'w', encoding='utf-8-sig', newline='') as f: # 表头 title = data_list[0].keys() # 声明writer writer = csv.DictWriter(f, title) # 写入表头 writer.writeheader() # 批量写入数据 writer.writerows(data_list) print('csv文件写入完成')if __name__ == '__main__': main()</pre></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Python','爬虫','selenium'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>