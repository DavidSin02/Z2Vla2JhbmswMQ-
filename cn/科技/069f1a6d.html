<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 | 极客快訊</title><meta property="og:title" content="哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/S44t6ohazkQ74"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><meta property="article:published_time" content="2020-10-29T21:10:44+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:44+08:00"><meta name=Keywords content><meta name=description content="哈工大提出基于光流估计与光照不一致监督的人脸正向化模型"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/069f1a6d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>哈工大提出基于光流估计与光照不一致监督的人脸正向化模型</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S44t6ohazkQ74><p>今天解读的是一篇已被ECCV 2020接收的论文，在这篇论文中，来自哈工大的作者们针对之前方法忽略对侧脸-正脸图像对之间光照情况不一致的考虑，引入了一个光照保留损失，实现了图像中光照信息和人脸身份信息的特征解藕，同时使用光流估计在特征层面得到了侧脸-正脸之间的特征对应关系，作为一个强有力的正向化监督信号，进而生成了更加逼真的正面人脸，同时也保留了更多的细节信息，实验结果表明，本文方法达到了SOTA效果。</p><p>论文：《Learning Flow-based Feature Warping for Face Frontalization with Illumination Inconsistent Supervision》。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oDvGr8eBQi><p>论文链接：https://arxiv.org/pdf/2008.06843</p><p>代码链接：https://github.com/csyxwei/FFWM</p><p><strong toutiao-origin=span>1 动机</strong></p><p>目前针对人脸正向化问题，较为流行的方法是通过大量的侧脸-正脸图像对（profile-frontal pairs）训练一个GAN网络，但是此类方法都忽略了侧脸-正脸之间存在光照不一致的现象，光照不一致主要是由拍摄角度（拍摄现场使用固定的照明设备）造成的，尤其是侧脸角度达到±90°时，光照的明暗差异非常明显，下图为Multi-PIE数据集中不同角度的人脸。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oDvoHwcth1E><p>之前的方法直接最小化生成人脸与ground-truth正面人脸的像素级损失，会迫使网络同时学习对姿态和光照的转换，对光照的转换在一定程度上会干扰前者，本文针对该问题，在正向化过程中保留了输入侧脸的光照信息，使模型更加专注于姿态转换的学习，从而得到了更好的生成效果。</p><p><strong toutiao-origin=span>2 方法</strong></p><p>人脸正向化本质上是人脸图像的旋转变化，本文使用光流场来构建侧脸-正脸之间的特征对应关系，光流估计网络使用FlowNetSD[1]，正向光流场（Forward Flow Field）表征侧脸到正脸的特征转换，反向光流场（Reverse Flow Field）表征正脸到侧脸的特征转换。然后将得到的两个光流场分别应用到光照保留模块（Illumination Preserving Module）和注意力特征转换模块（Warp Attention Module）。</p><p><strong>光照保留模块</strong></p><p>光照保留模块主要负责将人脸图像中的光照信息与代表人脸身份的细节信息进行特征解藕。光照保留模块分为两个支路，其中光照保留支路（Illumination preserving pathway）保证生成的正面图像与输入的侧脸图像在光照情况上一致，而光照适应支路（Illumination adaption pathway）尽可能的保证学习到与ground-truth图像一致的身份细节特征。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oDweEdHAaf1><p>由于光照条件很难量化到特征空间中，所以作者直接在图像空间对生成前后图像的光照情况进行约束，如上图Illumination Preserving Module中首先通过反向光流场将模型生成的正向人脸</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oDxCgxeWxv><p>转换到侧脸视角，然后对和输入侧脸</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFYr4zE0XFm><p>计算光照保留损失。</p><p>在光照适应支路中，考虑到生成图像与ground-truth图像</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFaLCPvtRSJ><p>的光照条件不一致，直接对它们进行约束可能会消除前面光照保留支路的效果，所以使用guided filter[2]对ground-truth图像做光照条件的迁移得到</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFbFvYPU96><p>，保证两幅正面图像有同样的光照条件，然后对其计算细节特征损失即可。</p><p></p><h1 toutiao-origin=h3>注意力特征转换模块</h1><p>该模块主要实现侧脸到正脸的特征转换，使用正向光流场可以得到非常精确的像素对应关系，但是由于人脸自身旋转带来的自遮挡现象，使得侧脸图像会有一部分信息丢失，进而也就无法得到完整的像素对应关系，针对这个问题，作者根据人脸对称先验对得到的特征图进行水平翻转，再通过一个注意力模块进行特征融合，消除翻转特征带来的信息混乱。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oFba4jmMffF><p><strong toutiao-origin=span>3 损失函数</strong></p><p><strong>多尺度像素级损失</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oFcMBfJGmYS><p>为了保证生成图像与ground-truth图像的内容一致性，本文仿照TP-GAN[3]，CAPG-GAN[4]加入了多尺度像素级损失，本文设置了三个尺度，分别为32x32、64x64和128x128。由于ground-truth图像与生成正面图像的光照情况不同，所以计算该损失之前需要进行光照迁移。</p><p><strong>感知损失</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oGNS29wii2><p>为了缓解像素级损失带来的生成图像较为模糊的问题，本文加入了VGG-19的感知损失，为了使感知损失作用到人脸图像中的关键区域，这里重点关注了眼睛、鼻子和嘴巴部分。</p><p><strong>对抗损失</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGPT1w10KYw><p>上式为标准的图像对抗损失，促使生成器生成更加逼真的人脸图像。</p><p><strong>光照保留损失</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGPwfq0hM5><p>上式为本文比较核心的多尺度光照保留损失，其中S代表的多尺度与上面的多尺度像素级损失一致，本质上是对输入侧脸与经过反向光流场生成的侧脸图像计算L1距离。</p><p><strong>身份特征保留损失</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGQrFyhO9eD><p>人脸正向化需要保证正向化过程中尽可能的保留与输出侧脸相同的身份信息，所以本文也加入了身份特征的保留损失，分别对LightCNN-29[5]最后一个池化层和全连接层的特征向量计算L1距离。</p><p><strong>优化：</strong></p><p>最后将上述各项损失整合起来得到总优化目标，即以下损失项的加权和。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oGS4DCzN0T8><p><strong toutiao-origin=span>4 实验与结果</strong></p><p>本文数据集使用了Multi-PIE数据集和LFW数据集，前者是目前比较流行的受限条件下多角度人脸数据集，后者为非受限条件下的人脸数据集。</p><p><strong>定性实验</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oH4W51QCX7G><p>本文分别与4种人脸正向化方法进行了对比，可以看到其他方法得到的生成图像的光照情况与最左侧的输入侧脸的光照情况有很大差异，同时在脸部轮廓和其他细节区域与真实图像也有明显的差异，本文方法首先保证生成图像的光照情况与原图一致，使模型能够更加明确的执行正向化。</p><p>上图为在Multi-PIE数据集上的生成效果，下图为在LFW数据集的效果。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oH65Ea2siPf><p><strong>定量实验</strong></p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oH7Q4Oe2AyR><p>为了体现人脸正向化模型对人脸识别性能的提升以及本文方法的优越性，作者将本文方法作为人脸识别的一个预处理过程，首先对所有侧脸执行正向化操作，其后将生成正脸图像输入到LightCNN中计算得到特征向量，使用余弦距离作为相似性度量计算得到Rank-1识别准确率，可以看到本文方法在大于75度的极端角度情况下可以达到SOTA效果。</p><img alt=哈工大提出基于光流估计与光照不一致监督的人脸正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oH8l8YyyWfv><p>为了展示本文方法在受限场景和非受限场景中都可以得到很好的效果，作者在LFW数据集上计算了ACC和AUC指标，都达到了SOTA效果。</p><p><strong toutiao-origin=span>5 总结</strong></p><p>在这篇论文中，作者以侧脸-正脸图像对中光照条件不一致为切入点，通过光照保留模块对人脸关键信息与光照信息进行解藕，然后使用双向的光流场对两种视角人脸特征对应关系进行拟合，再通过注意力特征转换模块消除掉一些与人脸关键特征无关的信息，进而实现精确的人脸正向化。实验结果表明，本文的方法不仅能够生成较为逼真的正面人脸，同时也可以解决大角度的人脸识别问题。</p><p>参考引用</p><p>[1] Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox, T.: Flownet 2.0: Evolution of optical flow estimation with deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2462–2470 (2017)</p><p>[2] He, K., Sun, J., Tang, X.: Guided image filtering. In: Proceedings of the European Conference on Computer Vision. pp. 1–14. Springer (2010)</p><p>[3] Huang, R., Zhang, S., Li, T., He, R.: Beyond face rotation: Global and local per- ception gan for photorealistic and identity preserving frontal view synthesis. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 2439– 2448 (2017)</p><p>[4] Hu,Y.,Wu,X.,Yu,B.,He,R.,Sun,Z.:Pose-guidedphotorealisticfacerotation.In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8398–8406 (2018)</p><p>[5] Wu, X., He, R., Sun, Z., Tan, T.: A light cnn for deep face representation with noisy labels. IEEE Transactions on Information Forensics and Security 13(11),2884–2896 (2018)</p><p><strong toutiao-origin=span>[博文视点赠书福利]</strong></p><p>AI科技评论联合博文视点赠送周志华教授“森林树”十五本，在“周志华教授与他的森林书”一文留言区留言，谈一谈你和集成学习有关的学习、竞赛等经历。</p><p>AI 科技评论将会在留言区选出15名读者，每人送出《集成学习：基础与算法》一本。</p><p><strong toutiao-origin=span>活动规则：</strong></p><p>1. 在“周志华教授与他的森林书”一文留言区留言，留言点赞最高的前 15 位读者将获得赠书。获得赠书的读者请联系 AI 科技评论客服（aitechreview）。</p><p>2. 留言内容会有筛选，例如“选我上去”等内容将不会被筛选，亦不会中奖。</p><p>3. 本活动时间为2020年8月23日 - 2020年8月30日（23:00），活动推送内仅允许中奖一次<strong toutiao-origin=span>。</strong></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'哈工大','光流','估计'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>