<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍 | 极客快訊</title><meta property="og:title" content="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/6c3f0004669244ec2591"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><meta property="article:published_time" content="2020-10-29T21:10:03+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:03+08:00"><meta name=Keywords content><meta name=description content="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/1521fcda.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>【2018 新智元 AI 技术峰会倒计时 18 天】</strong></p><p><strong>诺贝尔奖唯一计算机领域评委亲临，峰会首批嘉宾阵容公布</strong></p><p>早鸟票已经售罄，现正式进入全额票阶段。 即将于北京举办的<strong> 2018 年中国 AI 开年盛典——2018 新智元 AI 技术峰会</strong>上，我们邀请到了德国总理默克尔的科学顾问、诺贝尔奖唯一计算机领域评委、工业 4.0 教父、世界顶级自然语言处理专家 Wolfgang Wahlste 教授。Wahlster 教授将亲临 329 峰会现场分享欧洲对人工智能科技发展和 AI 产业化的思考。想现场一睹诺奖评委的风采，点击抢票链接，马上参会！</p><p><strong>抢票链接：<span>http://www.huodongxing.com/event/8426451122400</span></strong></p><hr><p><strong>新智元专栏</strong></p><p>来源：阿里巴巴语音交互智能团队</p><p>作者：毕梦霄，卢恒，张仕良，雷鸣，鄢志杰</p><p>会议：ICASSP-2018</p><p><strong>【新智元导读】</strong>阿里巴巴语音交互智能团队提出一种基于深度前馈序列记忆网络的语音合成系统。该系统在达到与基于双向长短时记忆单元的语音合成系统一致的主观听感的同时，模型大小只有后者的四分之一，且合成速度是后者的四倍，非常适合于对内存占用和计算效率非常敏感的端上产品环境。该研究已入选语音顶会ICASSP会议Oral论文，本文带来详细解读。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6c3f0004669244ec2591></p><h1>研究背景</h1><p>语音合成系统主要分为两类，<strong>拼接合成系统</strong>和<strong>参数合成系统</strong>。其中参数合成系统在引入了神经网络作为模型之后，合成质量和自然度都获得了长足的进步。另一方面，物联网设备（例如智能音箱和智能电视）的大量普及也对在设备上部署的参数合成系统提出了计算资源的限制和实时率的要求。<strong>本工作引入的深度前馈序列记忆网络可以在保持合成质量的同时，有效降低计算量，提高合成速度。</strong></p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6c3e00056702b5d97099></p><p>我们使用基于<strong>双向长短时记忆单元（BLSTM）</strong>的统计参数语音合成系统作为基线系统。与其他现代统计参数语音合成系统相似，我们提出的<strong>基于深度前馈序列记忆网络（DFSMN）</strong>的统计参数语音合成系统也是由3个主要部分组成，<strong>声音合成器（vocoder），前端模块和后端模块</strong>，如上图所示。我们使用开源工具WORLD作为我们的声音合成器，用来在模型训练时从原始语音波形中提取频谱信息、基频的对数、频带周期特征（BAP）和清浊音标记，也用来在语音合成时完成从声学参数到实际声音的转换。前端模块用来对输入的文本进行正则化和词法分析，我们把这些语言学特征编码后作为神经网络训练的输入。后端模块用来建立从输入的语言学特征到声学参数的映射，在我们的系统中，我们使用DFSMN作为后端模块。</p><h1>深度前馈序列记忆网络</h1><p>紧凑前馈序列记忆网络（cFSMN）作为标准的前馈序列记忆网络（FSMN）的改进版本，在网络结构中引入了低秩矩阵分解，这种改进简化了FSMN，减少了模型的参数量，并加速了模型的训练和预测过程。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed30000e0710d626233></p><p>上图给出了cFSMN的结构的图示。对于神经网络的每一个cFSMN层，计算过程可表示成以下步骤①经过一个线性映射，把上一层的输出映射到一个低维向量②记忆模块执行计算，计算当前帧之前和之后的若干帧和当前帧的低维向量的逐维加权和③把该加权和再经过一个仿射变换和一个非线性函数，得到当前层的输出。三个步骤可依次表示成如下公式。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed2000333b826771ba7></p><p>与循环神经网络（RNNs，包括BLSTM）类似，通过调整记忆模块的阶数，cFSMN有能力捕捉序列的长程信息。另一方面，cFSMN可以直接通过反向传播算法（BP）进行训练，与必须使用沿时间反向传播算法（BPTT）进行训练的RNNs相比，训练cFSMN速度更快，且较不容易受到梯度消失的影响。</p><p>对cFSMN进一步改进，我们得到了深度前馈序列记忆网络（DFSMN）。DFSMN利用了在各类深度神经网络中被广泛使用的跳跃连接（skip-connections）技术，使得执行反向传播算法的时候，梯度可以绕过非线性变换，即使堆叠了更多DFSMN层，网络也能快速且正确地收敛。对于DFSMN模型，增加深度的好处有两个方面。一方面，更深的网络一般来说具有更强的表征能力，另一方面，增加深度可以间接地增大DFSMN模型预测当前帧的输出时可以利用的上下文长度，这在直观上非常有利于捕捉序列的长程信息。具体来说，我们把跳跃连接添加到了相邻两层的记忆模块之间，如下面公式所示。由于DFSMN各层的记忆模块的维数相同，跳跃连接可由恒等变换实现。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ed2000333b9bd9e193e></p><p>我们可以认为DFSMN是一种非常灵活的模型。当输入序列很短，或者对预测延时要求较高的时候，可以使用较小的记忆模块阶数，在这种情况下只有当前帧附近帧的信息被用来预测当前帧的输出。而如果输入序列很长，或者在预测延时不是那么重要的场景中，可以使用较大的记忆模块阶数，那么序列的长程信息就能被有效利用和建模，从而有利于提高模型的性能。</p><p>除了阶数之外，我们为DFSMN的记忆模块增加了另一个超参数，步长（stride），用来表示记忆模块提取过去或未来帧的信息时，跳过多少相邻的帧。这是有依据的，因为与语音识别任务相比，语音合成任务相邻帧之间的重合部分甚至更多。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed2000333ba548e6e34></p><p>上文已经提到，除了直接增加各层的记忆模块的阶数之外，增加模型的深度也能间接增加预测当前帧的输出时模型可以利用的上下文的长度，上图给出了一个例子。</p><h1>实验</h1><p>在实验阶段，我们使用的是一个由男性朗读的中文小说数据集。我们把数据集划分成两部分，其中训练集包括38600句朗读（大约为83小时），验证集包括1400句朗读（大约为3小时）。所有的语音数据采样率都为16k赫兹，每帧帧长为25毫秒，帧移为5毫秒。我们使用WORLD声音合成器逐帧提取声学参数，包括60维梅尔倒谱系数，3维基频的对数，11维BAP特征以及1维清浊音标记。我们使用上述四组特征作为神经网络训练的四个目标，进行多目标训练。前端模块提取出的语言学特征，共计754维，作为神经网络训练的输入。</p><p>我们对比的基线系统是基于一个强大的BLSTM模型，该模型由底层的1个全连接层和上层的3个BLSTM层组成，其中全连接层包含2048个单元，BLSTM层包含2048个记忆单元。该模型通过沿时间反向传播算法（BPTT）训练，而我们的DFSMN模型通过标准的反向传播算法（BP）训练。包括基线系统在内，我们的模型均通过逐块模型更新过滤算法（BMUF）在2块GPU上训练。我们使用多目标帧级别均方误差（MSE）作为训练目标。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ed30000e072c8706c56></p><p>所有的DFSMN模型均由底层的若干DFSMN层和上的2个全连接层组成，每个DFSMN层包含2048个结点和512个投影结点，而每个全连接层包含2048个结点。在上图中，第三列表示该模型由几层DFSMN层和几层全连接层组成，第四列表示该模型DFSMN层的记忆模块的阶数和步长。由于这是FSMN这一类模型首次应用在语音合成任务中，因此我们的实验从一个深度浅且阶数小的模型，即模型A开始（注意只有模型A的步长为1，因为我们发现步长为2始终稍好于步长为1的相应模型）。从系统A到系统D，我们在固定DFSMN层数为3的同时逐渐增加阶数。从系统D到系统F，我们在固定阶数和步长为10,10,2,2的同时逐渐增加层数。从系统F到系统I，我们固定DFSMN层数为10并再次逐渐增加阶数。在上述一系列实验中，随着DFSMN模型深度和阶数的增加，客观指标逐渐降低（越低越好），这一趋势非常明显，且系统H的客观指标超过了BLSTM基线。</p><p><img alt="ICASSP Oral 论文：阿里提出低计算量语音合成系统，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6c3f000466932ac41f31></p><p>另一方面，我们也做了平均主观得分（MOS）测试（越高越好），测试结果如上图所示。主观测试是通过付费众包平台，由40个母语为中文的测试人员完成的。在主观测试中，每个系统生成了20句集外合成语音，每句合成语音由10个不同的测试人员独立评价。在平均主观得分的测试结果表明，从系统A到系统E，主观听感自然度逐渐提高，且系统E达到了与BLSTM基线系统一致的水平。但是，尽管后续系统客观指标持续提高，主观指标只是在系统E得分的上下波动，没有进一步提高。</p><h1>结论</h1><p>根据上述主客观测试，我们得到的结论是，历史和未来信息各捕捉120帧（600毫秒）是语音合成声学模型建模所需要的上下文长度的上限，更多的上下文信息对合成结果没有直接帮助。与BLSTM基线系统相比，我们提出的DFSMN系统可以在获得与基线系统一致的主观听感的同时，模型大小只有基线系统的1/4，预测速度则是基线系统的4倍，这使得该系统非常适合于对内存占用和计算效率要求很高的端上产品环境，例如在各类物联网设备上部署。</p><p>原文链接：https://arxiv.org/abs/1802.09194</p><p><strong>【加入社群】</strong></p><p>新智元 AI 技术 + 产业社群招募中，欢迎对 AI 技术 + 产业落地感兴趣的同学，加小助手微信号: aiera2015_1 入群；通过审核后我们将邀请进群，加入社群后务必修改群备注（姓名 - 公司 - 职位；专业群审核较严，敬请谅解）。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'合成系','ICASSP','Oral'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>