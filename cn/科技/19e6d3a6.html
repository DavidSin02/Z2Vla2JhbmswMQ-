<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>开发者必读｜如何通过TensorFlow构建计算图正则化模型 | 极客快訊</title><meta property="og:title" content="开发者必读｜如何通过TensorFlow构建计算图正则化模型 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/35714dcd6a3a4b7a90f017da2caac6c2"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/19e6d3a6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/19e6d3a6.html><meta property="article:published_time" content="2020-11-14T21:02:26+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:26+08:00"><meta name=Keywords content><meta name=description content="开发者必读｜如何通过TensorFlow构建计算图正则化模型"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/19e6d3a6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>开发者必读｜如何通过TensorFlow构建计算图正则化模型</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt=开发者必读｜如何通过TensorFlow构建计算图正则化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/35714dcd6a3a4b7a90f017da2caac6c2><p class=pgc-img-caption></p></div><p class=pgc-end-literature>文 / Google Research 软件工程师 Arjun Gopalan</p><p class=pgc-end-literature>编辑 / Google Research TensorFlow 技术推广工程师 Robert Crowe</p><p class=pgc-end-literature><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">简介</span></strong></p><p><span style="color:#3369e8;--tt-darkmode-color: #3369E8">神经架构学习</span> (Neural Structured Learning，NSL) 是 TensorFlow 中的一个框架，可以利用结构化信号来训练神经网络。这种框架接受 (i) 显式计算图或 (ii) 隐式计算图，处理结构化输入，并在模型训练过程中动态生成<strong>邻接点</strong> (Neighbors)。显式计算图的 NSL 通常用于<strong>基于神经网络的图学习</strong> (Neural Graph Learning)，而隐式计算图的 NSL 通常用于 对抗学习。这两种技术均以 NSL 框架中的正则化形式实现。所以，它们只对训练工作流有影响，而工作流的模型保持不变。我们将在本文中探讨如何在 TFX 中使用 NSL 框架实现<strong>计算图正则化</strong> (Graph Regularization )。</p><pre><code>神经架构学习https://tensorflow.google.cn/neural_structured_learning</code></pre><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">使用 NSL 构建计算图正则化模型的高级工作流包含以下步骤：</span></p><ol start=1><li><span style="color:#4f4f4f;--tt-darkmode-color: #979797">如果没有可用的计算图，则需要先构建一个计算图。</span></li><li><span style="color:#4f4f4f;--tt-darkmode-color: #979797">使用计算图和输入样本特征扩充训练数据。</span></li><li><span style="color:#4f4f4f;--tt-darkmode-color: #979797">使用扩充的训练数据对给定模型进行计算图正则化。</span></li></ol><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">这些步骤不会立即映射到现有的 </span><span style="color:#3369e8;--tt-darkmode-color: #3369E8">TFX</span> (TensorFlow Extended) 流水线组件上。但是，TFX 支持<span style="color:#3369e8;--tt-darkmode-color: #3369E8">自定义组件</span>，允许用户在其 TFX 流水线中实现自定义处理。如需了解 TFX 中的自定义组件，请参阅<u><span style="color:#3369e8;--tt-darkmode-color: #3369E8">这篇文章</span></u>。</p><pre><code>TFXhttps://tensorflow.google.cn/tfx/guide#tfx_standard_components自定义组件https://tensorflow.google.cn/tfx/guide/understanding_custom_components</code></pre><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">为了在 TFX 中创建一个包含上述步骤的计算图正则化模型，我们将利用扩展自定义 TFX 组件。</span></p><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">为展示如何使用 NSL，我们构建了一个示例 TFX 流水线，对 </span><span style="color:#3369e8;--tt-darkmode-color: #3369E8">IMDB 数据集</span>进行情感分类。我们提供了一个基于 <span style="color:#3369e8;--tt-darkmode-color: #3369E8">Colab 的教程</span>，演示了如何使用 NSL 与原生 TensorFlow 来完成这项任务，我们以此作为示例 TFX 流水线的基础。</p><pre><code>IMDB 数据集https://tensorflow.google.cn/datasets/catalog/imdb_reviewsColab 教程https://tensorflow.google.cn/neural_structured_learning/tutorials/graph_keras_lstm_imdb</code></pre><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">自定义 TFX 组件的计算图正则化</span></strong></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">为了在 TFX 中构建一个计算图正则化的 NSL 模型来完成这项任务，我们将使用</span><span style="color:#3369e8;--tt-darkmode-color: #3369E8">自定义 Python 函数</span>方法自定义三个组件。以下是使用这些自定义组件实现我们示例的 TFX 流水线示意图。为了简洁起见，我们省略了通常在 Trainer 之后的组件，例如 Evaluator、 Pusher 等。</p><pre><code>自定义 Python 函数https://tensorflow.google.cn/tfx/guide/custom_function_component</code></pre><div class=pgc-img><img alt=开发者必读｜如何通过TensorFlow构建计算图正则化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0ce730f709d047e0a3fbaf989cd5dde0><p class=pgc-img-caption>图 1：TFX 流水线示例：使用计算图正则化进行文本分类</p></div><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">在此图中，仅有自定义组件（粉色）与</span><strong><span style="color:#4f4f4f;--tt-darkmode-color: #979797">计算图正则化的 Trainer </span></strong><span style="color:#4f4f4f;--tt-darkmode-color: #979797">组件具备 NSL 相关逻辑。值得注意的是，此处展示的自定义组件仅作例证，还可以通过其他方式构建类似功能的流水线。接下来，我们进一步详细描述各个自定义组件，并展示相应的代码段。</span></p><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">IdentifyExamples</span></strong></p><p>此自定义组件为每个训练样本分配一个唯一的 ID，将每个训练样本与其在计算图中相应的邻接点关联起来。</p><pre><code>@componentdef IdentifyExamples(    orig_examples: InputArtifact[Examples],    identified_examples: OutputArtifact[Examples],    id_feature_name: Parameter[str],    component_name: Parameter[str]  ) -&gt; None:  # Compute the input and output URIs.  ...  # For each input split, update the TF.Examples to include a unique ID.  with beam.Pipeline() as pipeline:    (pipeline     | 'ReadExamples' &gt;&gt; beam.io.ReadFromTFRecord(         os.path.join(input_dir, '*'),         coder=beam.coders.coders.ProtoCoder(tf.train.Example))     | 'AddUniqueId' &gt;&gt; beam.Map(make_example_with_unique_id, id_feature_name)     | 'WriteIdentifiedExamples' &gt;&gt; beam.io.WriteToTFRecord(         file_path_prefix=os.path.join(output_dir, 'data_tfrecord'),         coder=beam.coders.coders.ProtoCoder(tf.train.Example),         file_name_suffix='.gz'))  identified_examples.split_names = orig_examples.split_names  return</code></pre><p><br></p><p><span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">make_example_with_unique_id() </span>函数可以更新给定样本，将包含唯一 ID 的额外特征包括在内。</p><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">SynthesizeGraph</span></strong></p><p>如上所述，在 IMDB 数据集中，没有提供显式计算图作为输入。因此，在演示计算图正则化之前，我们将构建一个计算图。在此示例中，我们使用一个预训练的文本嵌入向量模型将电影评论中的原始文本转换为嵌入向量，然后通过生成的嵌入向量构建计算图。</p><p><br></p><p><strong>SynthesizeGraph</strong> 自定义组件负责处理计算图构建，请注意，它定义了一个新的 <span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">Artifact</span>，名为 <span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">SynthesizedGraph</span>，作为此自定义组件的输出。</p><pre><code>"""Custom Artifact type"""class SynthesizedGraph(tfx.types.artifact.Artifact):  """Output artifact of the SynthesizeGraph component"""  TYPE_NAME = 'SynthesizedGraphPath'  PROPERTIES = {      'span': standard_artifacts.SPAN_PROPERTY,      'split_names': standard_artifacts.SPLIT_NAMES_PROPERTY,  }@componentdef SynthesizeGraph(    identified_examples: InputArtifact[Examples],    synthesized_graph: OutputArtifact[SynthesizedGraph],    similarity_threshold: Parameter[float],    component_name: Parameter[str]  ) -&gt; None:  # Compute the input and output URIs  ...  # We build a graph only based on the 'train' split which includes both  # labeled and unlabeled examples.  create_embeddings(train_input_examples_uri, output_graph_uri)  build_graph(output_graph_uri, similarity_threshold)  synthesized_graph.split_names = artifact_utils.encode_split_names(      splits=['train'])  return</code></pre><p><br></p><p><span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">create_embeddings()</span> 函数通过 <span style="color:#3369e8;--tt-darkmode-color: #3369E8">TensorFlow Hub</span> 上的一些预训练模型将电影评论中的文本转换为相应的嵌入向量。<span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">build_graph() </span>函数调用 NSL 中的 build_graph()API。</p><pre><code>TensorFlow Hubhttps://tensorflow.google.cn/hubbuild_graph() https://tensorflow.google.cn/neural_structured_learning/api_docs/python/nsl/tools/build_graph</code></pre><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">GraphAugmentation</span></strong></p><p>此自定义组件的目的在于将样本特征（电影评论中的文本）与通过嵌入向量构建的计算图结合起来，生成一个扩充的训练数据集。由此得出的训练样本也将包括其相应邻接点的特征。</p><pre><code>@componentdef GraphAugmentation(    identified_examples: InputArtifact[Examples],    synthesized_graph: InputArtifact[SynthesizedGraph],    augmented_examples: OutputArtifact[Examples],    num_neighbors: Parameter[int],    component_name: Parameter[str]  ) -&gt; None:  # Compute the input and output URIs  ...  # Separate out the labeled and unlabeled examples from the 'train' split.  train_path, unsup_path = split_train_and_unsup(train_input_uri)   # Augment training data with neighbor features.  nsl.tools.pack_nbrs(    train_path, unsup_path, graph_path, output_path, add_undirected_edges=True,    max_nbrs=num_neighbors  )  # Copy the 'test' examples from input to output without modification.  ...  augmented_examples.split_names = identified_examples.split_names  return</code></pre><p><br></p><p><span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">split_train_and_unsup()</span> 函数将输入样本拆分成带标签和无标签的样本，pack_nbrs() NSL API 创建扩充的训练数据集。</p><pre><code>pack_nbrs()https://tensorflow.google.cn/neural_structured_learning/api_docs/python/nsl/tools/pack_nbrs</code></pre><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">计算图正则化的 Trainer</span></strong></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">我们目前所有的自定义组件都已实现，TFX 流水线的 </span><span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">Trainer</span><span style="color:#4f4f4f;--tt-darkmode-color: #979797"> 组件中增加了其他 NSL 相关的内容。下方展示了一个计算图正则化 </span><span style="color:#ff6f00;--tt-darkmode-color: #FF6F00">Trainer</span><span style="color:#4f4f4f;--tt-darkmode-color: #979797"> 组件的简化视图。</span></p><pre><code>...  estimator = tf.estimator.Estimator(       model_fn=feed_forward_model_fn, config=run_config, params=HPARAMS)  # Create a graph regularization config.  graph_reg_config = nsl.configs.make_graph_reg_config(      max_neighbors=HPARAMS.num_neighbors,      multiplier=HPARAMS.graph_regularization_multiplier,      distance_type=HPARAMS.distance_type,      sum_over_axis=-1)  # Invoke the Graph Regularization Estimator wrapper to incorporate  # graph-based regularization for training.  graph_nsl_estimator = nsl.estimator.add_graph_regularization(      estimator,      embedding_fn,      optimizer_fn=optimizer_fn,      graph_reg_config=graph_reg_config) ...</code></pre><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">如您所见，创建了基础模型后（本例中指一个前馈神经网络），就可以通过调用 NSL 封装容器 API 将其直接转换为计算图正则化模型。</span></p><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">一切就这么简单。现在，我们已补充完在 TFX 中构建计算图正则化 NSL 模型所需的步骤。</span><span style="color:#3369e8;--tt-darkmode-color: #3369E8">此处</span>提供了一个基于 Colab 的教程，在 TFX 中端到端地演示这个示例。不妨尝试一下，并可根据您的需要进行自定义。</p><pre><code>此处https://tensorflow.google.cn/tfx/tutorials/tfx/neural_structured_learning</code></pre><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">对抗学习</span></strong></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">如前文简介中所述，神经架构学习的另一个方面是对抗学习，即不使用计算图中的显式邻接点来进行正则化，而是动态、对抗性地创建隐式邻接点来迷惑模型。</span></p><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">因此，使用对抗样本进行正则化是提高模型鲁棒性的有效方式。使用神经架构学习的对抗学习可以轻松集成到 TFX 流水线中。无需任何自定义组件，只需要更新 Trainer 组件即可在神经架构学习中调用对抗正则化封装容器 API。</span></p><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">总结</span></strong></p><p>我们演示了如何利用自定义组件在 TFX 中使用神经架构学习构建计算图正则化模型。当然，也可以用其他方式构建计算图，或者按照另外的方式来构建整体流水线。</p><p><br></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">我们希望这个示例能够为您构建自己的神经架构学习工作流提供帮助。</span></p><p><br></p><p><strong><span style="color:#f79430;--tt-darkmode-color: #F2912F">相关链接</span></strong></p><p><span style="color:#4f4f4f;--tt-darkmode-color: #979797">有关神经架构学习的更多信息，请查阅以下资源：</span></p><pre><code>TFX 中的 NSL Colab 教程https://tensorflow.google.cn/tfx/tutorials/tfx/neural_structured_learningNSL 网站https://tensorflow.google.cn/neural_structured_learningNSL GitHubhttps://github.com/tensorflow/neural-structured-learning更多 NSL 教程与视频https://github.com/tensorflow/neural-structured-learning#videos-and-colab-tutorials</code></pre><p><br>致谢：<br>我们特此鸣谢 Google 神经架构学习团队、TFX 团队以及 Aurélien Geron 的支持与贡献。</p><p><br></p><p><span style="color:#999;--tt-darkmode-color: #999999">转载自：谷歌开发者官方账号【TensorFlow】</span></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'开发者','必读','通过'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>