<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ICLR 2020会议的16篇最佳深度学习论文 | 极客快訊</title><meta property="og:title" content="ICLR 2020会议的16篇最佳深度学习论文 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/afa88e3a9b9a4c76904856ed340b09bd"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><meta property="article:published_time" content="2020-11-14T20:59:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:59:54+08:00"><meta name=Keywords content><meta name=description content="ICLR 2020会议的16篇最佳深度学习论文"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/1c6b0390.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ICLR 2020会议的16篇最佳深度学习论文</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>作者：Kamil Kaczmarek</p><p>编译：ronghuaiyang</p></blockquote><h1 class=pgc-h-arrow-right>导读</h1><blockquote><p>给大家介绍一下今年的ICLR上的最佳16篇深度学习论文。</p></blockquote><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/afa88e3a9b9a4c76904856ed340b09bd><p class=pgc-img-caption></p></div><p>上周，我很荣幸地参加了学习表现国际会议(<strong>ICLR</strong>)，这是一个致力于深度学习各方面研究的活动。最初，会议本应在埃塞俄比亚首Addis Ababa召开，但由于新型冠状病毒大流行，会议变成了虚拟会议。把活动搬到网上对组织者来说是一个挑战，但是我认为效果非常令人满意！</p><p>1300多名演讲者和5600名与会者证明，虚拟形式更容易为公众所接受，但与此同时，会议保持了互动和参与。从许多有趣的演讲中，我决定选择16个，这些演讲既有影响力又发人深省。以下是来自ICLR的最佳深度学习论文。</p><p>1. On Robustness of Neural Ordinary Differential Equations</p><p>2. Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</p><p>3. Target-Embedding Autoencoders for Supervised Representation Learning</p><p>4. Understanding and Robustifying Differentiable Architecture Search</p><p>5. Comparing Rewinding and Fine-tuning in Neural Network Pruning</p><p>6. Neural Arithmetic Units</p><p>7.The Break-Even Point on Optimization Trajectories of Deep Neural Networks</p><p>8. Hoppity: Learning Graph Transformations To Detect And Fix Bugs In Programs</p><p>9. Selection via Proxy: Efficient Data Selection for Deep Learning</p><p>10. And the Bit Goes Down: Revisiting the Quantization of Neural Networks</p><p>11. A Signal Propagation Perspective for Pruning Neural Networks at Initialization</p><p>12. Deep Semi-Supervised Anomaly Detection</p><p>13. Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells</p><p>14. Federated Learning with Matched Averaging</p><p>15. Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation</p><p>16. Network Deconvolution</p><h1 class=pgc-h-arrow-right>最佳深度学习论文</h1><h1 class=pgc-h-arrow-right>1. On Robustness of Neural Ordinary Differential Equations</h1><p>深入研究了神经常微分方程或神经网络的鲁棒性。使用它作为构建更健壮的网络的基础。</p><p>论文：https://openreview.net/forum?id=B1e9Y2NYvS</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/718626394c604c3c81d0e23fef0e7467><p class=pgc-img-caption></p></div><p>ODENet的结构，神经ODE块作为一个保维非线性映射。</p><p><br></p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89422efceb9b4d4a87b60855957db0ea><p class=pgc-img-caption>第一作者：Hanshu YAN</p></div><h1 class=pgc-h-arrow-right>2. Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</h1><p>证明梯度裁剪可加速非光滑非凸函数的梯度下降。</p><p>论文：https://openreview.net/forum?id=BJgnXpVYwS</p><p>代码：https://github.com/JingzhaoZhang/why-clipping-accelerates</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/47f43a659a0f478c97516100c0e294f3><p class=pgc-img-caption></p></div><p>PTB数据集上AWD-LSTM (Merity et al.， 2018)训练轨迹上的对数尺度上的梯度范数vs局部梯度Lipschitz常数。颜色条表示在训练过程中迭代的次数。</p><p>第一作者：Jingzhao Zhang</p><h1 class=pgc-h-arrow-right>3. Target-Embedding Autoencoders for Supervised Representation Learning</h1><p>新的，通用目标嵌入自动编码器或者说TEA监督预测框架。作者给出了理论和经验的考虑。</p><p>论文：https://openreview.net/forum?id=BygXFkSYDH</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fe98360282c941bd9a21892a122c8969><p class=pgc-img-caption></p></div><p>(a)特征嵌入和(b)目标嵌入自动编码器。实线对应于(主要)预测任务，虚线为(辅助)重建任务。两者都涉及到共享组件。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f35e87e4d85e495f8b88a9de2c13104d><p class=pgc-img-caption>第一作者：Daniel Jarrett</p></div><hr><h1 class=pgc-h-arrow-right>4. Understanding and Robustifying Differentiable Architecture Search</h1><p>通过分析验证损失的海塞矩阵的特征值，研究了DARTS（可微结构搜索）的失效模式，并在此基础上提出了相应的对策。</p><p>论文：https://openreview.net/forum?id=H1gDNyrKDS</p><p>代码：https://github.com/automl/RobustDARTS</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2039a9b892a34d098340ec96cc6c5889><p class=pgc-img-caption></p></div><p>在Space1到Space4上，DARTS发现的差的网格标准。对于所有的空间，DARTS选择的大多是无参数的操作(跳过连接)，甚至是有害的噪声操作。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2109be19c24b4553831dd05614d8a763><p class=pgc-img-caption>第一作者: Arber Zela</p></div><h1 class=pgc-h-arrow-right>5. Comparing Rewinding and Fine-tuning in Neural Network Pruning</h1><p>在修剪神经网络时，不需要在修剪后进行微调，而是将权值或学习率策略倒回到它们在训练时的值，然后再从那里进行再训练，以达到更高的准确性。</p><p>论文：https://openreview.net/forum?id=S1gSj0NKvB</p><p>代码：https://github.com/lottery-ticket/rewinding-iclr20-public</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9f6bb35df3be440ca14ac95aff170fef><p class=pgc-img-caption></p></div><p>通过一次修剪获得再训练时间的最佳可达到的精度。</p><p>![Alex Renda](The Best Deep Learning Papers from the ICLR 2020 Conference.assets/5-Alex-Renda.jpg)</p><p>第一作者：Alex Renda</p><h1 class=pgc-h-arrow-right>6. Neural Arithmetic Units</h1><p>神经网络虽然能够逼近复杂的函数，但在精确的算术运算方面却很差。这项任务对深度学习研究者来说是一个长期的挑战。在这里，我们介绍了新的神经加法单元(NAU)和神经乘法单元(NMU)，它们能够执行精确的加法/减法(NAU)和向量子集乘法(MNU)。</p><p>论文：https://openreview.net/forum?id=H1gNOeHKPS</p><p>代码：https://github.com/AndreasMadsen/stable-nalu</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0e52d8202e0748a79595cb753bd87eb2><p class=pgc-img-caption></p></div><p>NMU的可视化，其中权值(Wi,j)控制门控的值1(identity)或xi，然后显式地乘上每个中间结果以形成zj。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5cc6fe467484430c8b22826c7d17dffb><p class=pgc-img-caption>第一作者：Andreas Madsen</p></div><h1 class=pgc-h-arrow-right>7. The Break-Even Point on Optimization Trajectories of Deep Neural Networks</h1><p>在深度神经网络训练的早期阶段，存在一个决定整个优化轨迹性质的“均衡点”。</p><p>论文：https://openreview.net/forum?id=r1g87C4KwB</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c301763e03164206808e1aea78cb9347><p class=pgc-img-caption></p></div><p>早期训练轨迹的可视化，CIFAR-10(之前训练精度达到65%)的一个简单的CNN模型优化使用SGD学习率η= 0.01(红色)和η= 0.001(蓝色)。训练轨迹上的每个模型(显示为一个点)通过使用UMAP将其测试预测嵌入到一个二维空间中来表示。背景颜色表示梯度K (λ1K, 左)的协方差归一化频谱和训练精度(右)。对于小的η，达到我们所说的收支平衡点后，对于同样的训练精度(右)，轨迹是引向一个地区，这个区域具有更大λ1K(左)的特点。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9327c69274844fcda51560cad9b12b36><p class=pgc-img-caption>第一作者：Stanisław Jastrzębski</p></div><h1 class=pgc-h-arrow-right>8. Hoppity: Learning Graph Transformations To Detect And Fix Bugs In Programs</h1><p>一种基于学习的方法，用于检测和修复Javascript中的bug。</p><p>论文：https://openreview.net/forum?id=SJeqs6EFvB</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4459c89a76e14d81b459f4edc99a02a0><p class=pgc-img-caption></p></div><p>演示现有方法的局限性的示例程序包括基于规则的静态分析器和基于神经的错误预测器。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/da61e13ee3504e23a50bb65e209f78e1><p class=pgc-img-caption>第一作者：Elizabeth Dinella</p></div><h1 class=pgc-h-arrow-right>9. Selection via Proxy: Efficient Data Selection for Deep Learning</h1><p>通过使用一个更小的代理模型来执行数据选择，我们可以显著提高深度学习中数据选择的计算效率。</p><p>论文：https://openreview.net/forum?id=HJg2b0VYDr</p><p>代码：https://github.com/stanford-futuredata/selection-via-proxy</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ef50a3353baa48f0ab3fcfaa7c3db31d><p class=pgc-img-caption></p></div><p>SVP应用于主动学习(左)和核心集选择(右)。在主动学习中，我们遵循了相同的迭代过程，即训练和选择标记为传统方法的点，但是用计算成本更低的代理模型代替了目标模型。对于核心集的选择，我们学习了使用代理模型对数据进行特征表示，并使用它选择点来训练更大、更精确的模型。在这两种情况下，我们发现代理和目标模型具有较高的rank-order相关性，导致相似的选择和下游结果。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f5c162dafe7b439f917b3f57f4aae2a4><p class=pgc-img-caption>第一作者：Cody Coleman</p></div><h1 class=pgc-h-arrow-right>10. And the Bit Goes Down: Revisiting the Quantization of Neural Networks</h1><p>采用结构化量化技术对卷积神经网络进行压缩，实现更好的域内重构。</p><p>论文：https://openreview.net/forum?id=rJehVyrKwH</p><p>代码：https://drive.google.com/file/d/12QK7onizf2ArpEBK706ly8bNfiM9cPzp/view?usp=sharing</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f61e01cbff104a5f95ec6467e0840c16><p class=pgc-img-caption></p></div><p>图解我们的方法。我们近似一个二元分类器ϕ，通过量化权重把图像标记为狗或猫。标准方法：使用标准目标函数来量化 ϕstandard，(1)提升分类器ϕ，试图在整个输入空间上近似ϕ，因此对于域内的输入可能表现很差。我们的方法：用我们的目标函数量化ϕ(2)提升分类器ϕbactivations，使之对于域内输入表现良好。在输入空间的图像由ϕactivations正确分类，但ϕstandard不正确。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/212f0b06c22d45c4a2eb541b8684a2b3><p class=pgc-img-caption>第一作者：Pierre Stock</p></div><h1 class=pgc-h-arrow-right>11. A Signal Propagation Perspective for Pruning Neural Networks at Initialization</h1><p>我们正式描述了初始化时有效剪枝的初始化条件，并分析了得到的剪枝网络的信号传播特性，提出了一种增强剪枝网络可训练性和剪枝效果的方法。</p><p>论文：https://openreview.net/forum?id=HJeTo2VFwH</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/697650339b1d4c34868606e33a8f1ba8><p class=pgc-img-caption></p></div><p>(左)layerwise稀疏模式c∈{0,1} 100×100获得剪枝水平为κ¯= {10 . .90}%的效果。这里，黑色(0)/白色(1)像素为修剪/保留参数，(右)各层参数的连接灵敏度(CS)所有网络初始化γ=1.0。与线性情况不同，tanh网络的稀疏模式在不同层上是不均匀的。当进行高等级剪枝的时候(例如，κ¯= 90%)，这成为关键，导致学习能力差，只有几个参数留在后面的层。这是由连接灵敏度图所解释的，图中显示，对于非线性网络参数，后一层的连接灵敏度低于前一层。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8c8f688ad5854592990b8d238c15677c><p class=pgc-img-caption>第一作者：Namhoon Lee</p></div><h1 class=pgc-h-arrow-right>12. Deep Semi-Supervised Anomaly Detection</h1><p>我们介绍了Deep SAD，一种用于一般性的半监督异常检测的深度方法，特别利用了异常的标记。</p><p>论文：https://openreview.net/forum?id=HkgH0TEYwH</p><p>代码：https://github.com/lukasruff/Deep-SAD-PyTorch</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/77ac66f84a874001a548b79a3270395d><p class=pgc-img-caption></p></div><p>半监督异常检测的需要：训练数据(如(a)所示)由(大部分正常)未标记数据(灰色)和少数标记正常样本(蓝色)和标注的异常样本(橙色)组成。图(b) - (f)显示了测试时各种学习模式的决策边界，以及出现的新异常(每个图的左下角)。我们的半监督AD方法利用了所有的训练数据：未标记的样本，标记的正常样本，以及标记的异常样本。这在单类别学习和分类之间取得了平衡。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4560aa38f37649a2939d76078c55a4bc><p class=pgc-img-caption>第一作者：Lukas Ruffs</p></div><h1 class=pgc-h-arrow-right>13. Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells</h1><p>我们提出了一个名为Space2vec的表示学习模型来编码位置的绝对位置和空间关系。</p><p>论文：https://openreview.net/forum?id=rJljdh4KDH</p><p>代码：https://github.com/gengchenmai/space2vec</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/21ce777c666840e39dbf53dcc552393c><p class=pgc-img-caption></p></div><p>具有非常不同特征的联合建模分布的挑战。(a)(b)拉斯维加斯的POI位置(红点)以及Space2Vec预测了女装(使用聚类分布)和教育(使用均匀分布)的条件似然。(b)中的黑色区域表明市中心区域的其他类型的POIs比教育多。(c)相对于wrap， Space2Vec具有最大和最小改进的POI类型的Ripley的K曲线(Mac Aodha et al.， 2019)。每条曲线表示以某一类型的点为中心的某一半径内某一类型点的点的个数(d)用POI密度重新规格化的Ripley’s K曲线，并以对数刻度表示。为了高效地实现多尺度表示，Space2Vec将64个尺度(波长从50米到40k米不等)的网格单元编码作为深度模型的第一层，并以无监督的方式与POI数据进行训练。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c05f4dcda8ec474db91184af921cb4ec><p class=pgc-img-caption>第一作者：Gengchen Mai</p></div><hr><h1 class=pgc-h-arrow-right>14. Federated Learning with Matched Averaging</h1><p>使用分层匹配来实现联邦学习的高效交流。</p><p>论文：https://openreview.net/forum?id=BkluqlSFDS</p><p>代码：https://github.com/IBM/FedMA</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2963131d54644d17b9954c259f63b021><p class=pgc-img-caption></p></div><p>在MNIST上进行有限次数的LeNet联邦学习方法的比较，在CIFAR-10数据集上训练VGG-9，LSTM在莎士比亚数据集上训练:(a)同构数据(b)异构数据</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a0c99d611b77474f98f68414f5e5b448><p class=pgc-img-caption>第一作者：Hongyi Wang</p></div><h1 class=pgc-h-arrow-right>15. Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation</h1><p>深度神经网络优化编译的增强学习和自适应采样。</p><p>论文：https://openreview.net/forum?id=rygG4AVFvH</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/789c8dd2270542fcb33f128909cc0e01><p class=pgc-img-caption>我们的模型编译工作流的概要，突出显示的是这项工作的范围。</p></div><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0eff0a416beb46cfa98e8ec55cf588ab><p class=pgc-img-caption>第一作者：Byung Hoon Ahn</p></div><h1 class=pgc-h-arrow-right>16. Network Deconvolution</h1><p>为了更好地训练卷积网络，我们提出了一种类似于动物视觉系统的网络反卷积方法。</p><p>论文：https://openreview.net/forum?id=rkeu30EtvS</p><p>代码：https://github.com/yechengxi/deconvolution</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/99ae6dd72fbd45bfae87065cc4a2931b><p class=pgc-img-caption></p></div><p>使用相关滤波器(例如高斯核)对这个真实世界的图像进行卷积，将相关性添加到生成的图像中，这使得目标识别更加困难。去除这种模糊的过程称为反卷积。但是，如果我们看到的真实世界的图像本身是某种未知的相关滤波器的结果，这使得识别更加困难呢？我们提出的网络反卷积操作可以去除底层图像特征之间的关联，使得神经网络能够更好地执行。</p><div class=pgc-img><img alt="ICLR 2020会议的16篇最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fe4aabcd69274f12bf2a8747e9a6754f><p class=pgc-img-caption>第一作者：Chengxi Ye</p></div><h1 class=pgc-h-arrow-right>总结</h1><p>ICLR的深度和广度相当鼓舞人心。在这里，我只介绍了“深度学习”主题的冰山一角。然而，这一分析表明，有一些是很受欢迎的领域，特别是：</p><ol start=1><li>深度学习(本文涵盖)</li><li>强化学习</li><li>生成模型</li><li>自然语言处理/理解</li></ol><p>为了更全面地概述ICLR的顶级论文，我们正在撰写一系列文章，每一篇都集中在上面提到的一个主题上。</p><p>英文原文：https://neptune.ai/blog/iclr-2020-deep-learning</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'ICLR','2020','会议'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>