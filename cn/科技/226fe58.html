<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>反向传播解析 | 极客快訊</title><meta property="og:title" content="反向传播解析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/15388229214070eac6af6f2"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/226fe58.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/226fe58.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/226fe58.html><meta property="article:published_time" content="2020-10-29T21:05:34+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:34+08:00"><meta name=Keywords content><meta name=description content="反向传播解析"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/226fe58.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>反向传播解析</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>反向传播是训练人工神经网络，特别是深度神经网络的常用方法。需要反向传播来计算梯度，我们需要调整权重矩阵的权重。通过计算损失函数的梯度来调整神经网络的神经元（即节点）的权重。为此目的，使用梯度下降优化算法。它也被称为误差的反向传播。</p><p>一个比喻可能会有帮助:想象你自己被放在一座山中，不一定是在山顶，在晚上被大雾包围。让我们进一步想象这座山在一个岛上，你想达到海平面。</p><ul><li>你必须往下走，但你几乎看不到任何东西，可能只有几米。你的任务是找到你的路，但是你看不到路。你可以用梯度下降法。这意味着你正在检查你当前位置的陡度。你将沿着最陡的下降方向前进。</li><li>你只走了几步，然后又停下来重新定位自己。这意味着您正在再次应用前面描述的过程，即您正在寻找最陡的下降。</li></ul><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15388229214070eac6af6f2><p class=pgc-img-caption></p></div><p>这样下去，你将到达一个没有进一步下降的位置，每个方向都向上。你可能已达到最低处（全局最低），但你也可能陷入一个盆地。</p><p>总之，如果在这个理论岛上随机放置很多次，你会发现向下到海平面的方法。这就是我们训练神经网络时要做的。</p><h1>实际的反向传播程序</h1><p>假设我们从一个简单的（线性）神经网络开始：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15388229420504295d39391><p class=pgc-img-caption></p></div><p>使用与权重关联的以下示例值：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1538822956223d20665e237><p class=pgc-img-caption></p></div><p>我们有标签，即每个输出值o的目标值或期望值t。误差是目标和实际输出之间的差异：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1538822971743532b3602f6><p class=pgc-img-caption></p></div><p>我们稍后将使用平方误差函数，因为它具有更好的算法特性。</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1538822991207fd14302718><p class=pgc-img-caption></p></div><p>我们将看一下输出值o1o1，它取决于值w11w11，w21w21，w31w31和w41w41。假设计算值（o1o1）为0.92，期望值（t1t1）为1.在这种情况下，误差是</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1538823008158c23c788aa6><p class=pgc-img-caption></p></div><p>根据此误差，我们必须相应地更改传入值的权重。我们有四个权重，所以我们可以均匀地分散误差。然而，根据权重值，按比例进行比较更有意义。这意味着我们可以计算w11w11中误差e1e1的分数：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1538823025281ce89084a25><p class=pgc-img-caption></p></div><p>这意味着在我们的示例中：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1538823040500ad34e47381><p class=pgc-img-caption></p></div><p>隐藏和输出层之间的权重矩阵中的总误差如下所示：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15388230553328d7f79e169><p class=pgc-img-caption></p></div><p>左矩阵中的分母始终相同。这是一个缩放因子。我们可以删除它，以便计算变得更简单：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15388230710221a780e725f><p class=pgc-img-caption></p></div><p>该示例已经证明了线性神经网络的基本场景的反向传播。</p><p>现在让我们回顾一下在线神经网络的反向传播（即具有激活函数）。</p><p>误差函数的推导描述了斜率。当我们希望下降时，推导描述了当权重w改变时误差E如何变化：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1538823089230d580a58e4c><p class=pgc-img-caption></p></div><p>好吧，假设在所有输出节点ojoj（j = 1，... nj = 1，... n）上的误差函数E，其中n是输出节点的数量是：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153882310489133e68968f6><p class=pgc-img-caption></p></div><p>我们可以在推导中加入这个</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1538823118790c4ec8f7f5c><p class=pgc-img-caption></p></div><p>我们可以彼此独立地计算每个输出节点的误差，并且我们除去了总和。这是节点j的误差，例如：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1538823139532b4b2dd1fab><p class=pgc-img-caption></p></div><p>应用链式法则，我们在微积分中学过的微分，在上一项中，来简化</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1538823169390a4654ea793><p class=pgc-img-caption></p></div><p>假设一个Sigmoid激活函数，其微分很简单:</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1538823184329d465ff1b97><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153882319820969910081b1><p class=pgc-img-caption></p></div><p>基本神经网络训练数学:</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15388232137816f0c6db4b2><p class=pgc-img-caption></p></div><p>****</p><p>综上所述：</p><div class=pgc-img><img alt=反向传播解析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1538823227833ec4db19840><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'传播','反向','解析'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>