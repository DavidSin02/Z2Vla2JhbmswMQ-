<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Lucene集成IK Analyzer中文分词器 | 极客快訊</title><meta property="og:title" content="Lucene集成IK Analyzer中文分词器 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/bb5b16ad480f4e5f817c222f9699112b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="Lucene集成IK Analyzer中文分词器"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/2281a34.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Lucene集成IK Analyzer中文分词器</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>IK Analyzer</h1><p>IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始， IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。</p><p><strong>IK Analyzer 2012特性:</strong></p><ul><li>1.采用了特有的“正向迭代最细粒度切分算法“，支持细粒度和智能分词两种切分模式；</li><li>2.在系统环境：Core2 i7 3.4G双核，4G内存，window 7 64位， Sun JDK 1.6_29 64位 普通pc环境测试，IK2012具有160万字/秒（3000KB/S）的高速处理能力。</li><li>3.2012版本的智能分词模式支持简单的分词排歧义处理和数量词合并输出。</li><li>4.采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符</li><li>5.优化的词典存储，更小的内存占用。支持用户词典扩展定义。特别的，在2012版本，词典支持中文，英文，数字混合词语。</li></ul><p>地址：https://code.google.com/archive/p/ik-analyzer/</p><h1 class=pgc-h-arrow-right>与Lucene集成</h1><p>IK分词器最先作为lucence上使用而开发，主要用于对中文的分词，后来发展成独立的分词组件，目前只提供到lucence 4.0版本的支持，我们在使用4.0以后的版本的时候需要简单的集成一下。</p><p>IK需要集成一因为lucence4.0后，Analyer的createComponents方法的参数改变了。</p><p>1.添加依赖：</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;com.janeluo&lt;/groupId&gt;    &lt;artifactId&gt;ikanalyzer&lt;/artifactId&gt;    &lt;version&gt;2012_u6&lt;/version&gt;        &lt;exclusions&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-core&lt;/artifactId&gt;       &lt;/exclusion&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;       &lt;/exclusion&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt;       &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--lucene-queryparser 查询分析器模块 --&gt;    &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;    &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;    &lt;version&gt;7.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>2.因为lucence4.0后，Analyer的createComponents方法的参数改变了。</p><pre><code>protected abstract Analyzer.TokenStreamComponents createComponents(String var1);</code></pre><p>需要将org.apache.lucene.analysis的类IKAnalyzer，IKTokenizer拷贝修改：</p><pre><code>import org.apache.lucene.analysis.Analyzer;public class IKAnalyzer4Lucene7 extends Analyzer {	private boolean useSmart = false;	public IKAnalyzer4Lucene7() {		this(false);	}	public IKAnalyzer4Lucene7(boolean useSmart) {		super();		this.useSmart = useSmart;	}	public boolean isUseSmart() {		return useSmart;	}	public void setUseSmart(boolean useSmart) {		this.useSmart = useSmart;	}	@Override	protected TokenStreamComponents createComponents(String fieldName) {		IKTokenizer4Lucene7 tk = new IKTokenizer4Lucene7(this.useSmart);		return new TokenStreamComponents(tk);	}}</code></pre><pre><code>import java.io.IOException;import org.apache.lucene.analysis.Tokenizer;import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;import org.apache.lucene.analysis.tokenattributes.TypeAttribute;import org.wltea.analyzer.core.IKSegmenter;import org.wltea.analyzer.core.Lexeme;public class IKTokenizer4Lucene7 extends Tokenizer {	// IK分词器实现	private IKSegmenter _IKImplement;	// 词元文本属性	private final CharTermAttribute termAtt;	// 词元位移属性	private final OffsetAttribute offsetAtt;	// 词元分类属性（该属性分类参考org.wltea.analyzer.core.Lexeme中的分类常量）	private final TypeAttribute typeAtt;	// 记录最后一个词元的结束位置	private int endPosition;	/**	 * @param in	 * @param useSmart	 */	public IKTokenizer4Lucene7(boolean useSmart) {		super();		offsetAtt = addAttribute(OffsetAttribute.class);		termAtt = addAttribute(CharTermAttribute.class);		typeAtt = addAttribute(TypeAttribute.class);		_IKImplement = new IKSegmenter(input, useSmart);	}	/*	 * (non-Javadoc)	 * 	 * @see org.apache.lucene.analysis.TokenStream#incrementToken()	 */	@Override	public boolean incrementToken() throws IOException {		// 清除所有的词元属性		clearAttributes();		Lexeme nextLexeme = _IKImplement.next();		if (nextLexeme != null) {			// 将Lexeme转成Attributes			// 设置词元文本			termAtt.append(nextLexeme.getLexemeText());			// 设置词元长度			termAtt.setLength(nextLexeme.getLength());			// 设置词元位移			offsetAtt.setOffset(nextLexeme.getBeginPosition(),					nextLexeme.getEndPosition());			// 记录分词的最后位置			endPosition = nextLexeme.getEndPosition();			// 记录词元分类			typeAtt.setType(nextLexeme.getLexemeTypeString());			// 返会true告知还有下个词元			return true;		}		// 返会false告知词元输出完毕		return false;	}	/*	 * (non-Javadoc)	 * 	 * @see org.apache.lucene.analysis.Tokenizer#reset(java.io.Reader)	 */	@Override	public void reset() throws IOException {		super.reset();		_IKImplement.reset(input);	}	@Override	public final void end() {		// set final offset		int finalOffset = correctOffset(this.endPosition);		offsetAtt.setOffset(finalOffset, finalOffset);	}}</code></pre><p>Ik中默认的停用词很少，我们往往需要扩展它。可从网址： https://github.com/cseryp/stopwords 下载一份比较全的停用词。</p><p>Ik中停用词的扩展步骤：</p><p>1、在类目录下创建IK的配置文件：IKAnalyzer.cfg.xml</p><p>2、在配置文件中增加配置扩展停用词文件的节点：</p><p>&lt;entry key=“ext_stopwords”>my_ext_stopword.dic&lt;/entry></p><p>如有多个，以“;”间隔</p><p>3、在类目录下创建我们的扩展停用词文件 my_ext_stopword.dic</p><p>4、编辑该文件加入停用词，一行一个</p><p>扩展 IKAnalyzer的词典：</p><p>每年都有很多的新词产生，往分词器的词典中添加新词的步骤：</p><p>1、在类目录下IK的配置文件：IKAnalyzer.cfg.xml 中增加配置扩展词文件的节点：</p><p>&lt;entry key="ext_dict">ext.dic&lt;/entry></p><p>如有多个，以“;”间隔</p><p>2、在类目录下创建扩展词文件 ext.dic</p><p>4、编辑该文件加入新词，一行一个</p><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;  &lt;properties&gt;  	&lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;	&lt;!--用户可以在这里配置自己的扩展字典 --&gt;	&lt;entry key="ext_dict"&gt;ext.dic&lt;/entry&gt; 		&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;	&lt;entry key="ext_stopwords"&gt;my_ext_stopword.dic&lt;/entry&gt;&lt;/properties&gt;</code></pre><p><strong>ext_dict：</strong>字典，新词：比如奥利给</p><p><strong>ext_stopwords</strong>：停用词：的，地，这</p><p>测试代码：</p><pre><code>public class IkAnalyzerTestDemo {   private static void doToken(TokenStream ts) throws IOException {      ts.reset();      CharTermAttribute cta = ts.getAttribute(CharTermAttribute.class);      while (ts.incrementToken()) {         System.out.print(cta.toString() + "|");      }      System.out.println();      ts.end();      ts.close();   }   public static void main(String[] args) throws IOException {      String etext = "Don't be afraid of any difficulty we encounter. Smile at it. " +            "The best way to eliminate fear is to face fear. Persistence is the victory. Come on, Ollie!";      String chineseText = "我们遇到什么困难，也不要怕，微笑着面对它，消除恐惧的最好方法就是面对恐惧，坚持才是胜利，加油，奥利给！ ";      // IKAnalyzer 细粒度切分      try (Analyzer ik = new IKAnalyzer4Lucene7();) {         TokenStream ts = ik.tokenStream("content", etext);         System.out.println("IKAnalyzer中文分词器 细粒度切分，英文分词效果：");         doToken(ts);         ts = ik.tokenStream("content", chineseText);         System.out.println("IKAnalyzer中文分词器 细粒度切分，中文分词效果：");         doToken(ts);      }      // IKAnalyzer 智能切分      try (Analyzer ik = new IKAnalyzer4Lucene7(true);) {         TokenStream ts = ik.tokenStream("content", etext);         System.out.println("IKAnalyzer中文分词器 智能切分，英文分词效果：");         doToken(ts);         ts = ik.tokenStream("content", chineseText);         System.out.println("IKAnalyzer中文分词器 智能切分，中文分词效果：");         doToken(ts);      }   }}</code></pre><div class=pgc-img><img alt="Lucene集成IK Analyzer中文分词器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bb5b16ad480f4e5f817c222f9699112b><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Lucene','IK','Analyzer'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>