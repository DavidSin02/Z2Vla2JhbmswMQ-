<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>基于PPF方式改进的物体检测与位姿估计算法 | 极客快訊</title><meta property="og:title" content="基于PPF方式改进的物体检测与位姿估计算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/2cce084686cc4c038af85f34ad395de3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/27b945d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/27b945d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/27b945d.html><meta property="article:published_time" content="2020-10-29T20:53:36+08:00"><meta property="article:modified_time" content="2020-10-29T20:53:36+08:00"><meta name=Keywords content><meta name=description content="基于PPF方式改进的物体检测与位姿估计算法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/27b945d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>基于PPF方式改进的物体检测与位姿估计算法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote class=pgc-blockquote-abstract><p>作者：仲夏夜之星</p><p>来源：公众号<a class=tteditor-mention data-concern-id data-id data-name=3D视觉工坊 data-uid=78756497532>@3D视觉工坊</a></p></blockquote><p><strong>论文标题：</strong>Point Pair Features Based Object Detection and Pose Estimation Revisited<br></p><p><strong>下载方式</strong>：在公众号「3D视觉工坊」，后台回复「PPF物体检测」，即可直接下载。</p><p><strong>摘要</strong>：本文基于原始点对特征对于三维目标识别与位姿估计提出了一种改进的通道，该方法采用自相似点对表示三维目标对象，然后在简化的位姿参数空间上使用高效的霍夫投票方案将该模型与三维场景匹配，将目标检测与粗到细的分割相结合，其中每个分割都要进行不相交的姿态估计，在匹配过程中，采用加权霍夫投票和位姿参数插值恢复。最后，对所有生成的假设位姿进行排序，本文认为这种组合通道同时提高了检测率和降低了复杂性，同时提高了结果姿态的准确性，由于这种增强的位姿检索，我们的验证不需要ICP，从而达到更好的速度和准确性。</p><h1 class=pgc-h-arrow-right><strong>一 本文方法</strong></h1><p>本文建模和匹配框架遵循Drost.et al[1],贡献在于一个增强的模式表示，以及引入分割进入投票和快速假设验证。</p><h1 class=pgc-h-arrow-right><strong>1.1模型表示</strong></h1><h1 class=pgc-h-arrow-right><strong>1.1.1表面特征</strong></h1><p>对于物体表面的两个点、，其点对特征可以定义为</p><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2cce084686cc4c038af85f34ad395de3><p class=pgc-img-caption></p></div><p>其中表示两个表面点的距离，表示两个向量之间的角度</p><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/83843deeb340405095ae2b9b3e59b3b7><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>1.1.2计算模型法线</strong></h1><p>本文使用的特征大多都使用了法线，但总存在一些不太准确的估计，针对该问题，协方差矩阵的特征分解更好地解决了此问题。但由于平面斑块不能很好地表示局部结构的邻域，因此一阶方法不能准确地表示三维模型。一种更好的方法是使用二阶项，其中凹凸性也可以建模。尽管在线阶段计算二阶近似代价很高，但在离线阶段使用它们是安全的。因此，目标是找到一个二阶多项式的参数，近似邻近点的高度场，给定一个局部参考系，形式上，给定集合的点, MLS通过在局部k邻域中拟合一个m阶曲面并将这个点投影到这个曲面上进行操作，拟合本质上是多项式表面参数的一种标准加权最小二乘估计，这是由权重函数决定的，点被投影到二阶曲面上。对所有的点重复这个过程，从而得到一个具有良好定义法线的平滑点集。</p><h1 class=pgc-h-arrow-right><strong>1.1.3模型点权重</strong></h1><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8affb76821b749f48e310f894b71c150><p class=pgc-img-caption></p></div><p>给定一个半球Ω,集合在一个表面上的点与正常n可以通过计算获得可见度函数的积分，V是一个狄拉克函数，定义为1如果p在w的方向被遮挡，否则为0，这个积分通过从几个角度渲染模型和积累每个顶点的可见性来逼近。然后将余弦加权平均值报告为顶点方向的遮挡值。基于，本文建议对哈希表的条目进行权衡。因此，给定哈希表容器，我们的权重只是和的标准化几何平均值。</p><h1 class=pgc-h-arrow-right><strong>1.1.4全局描述</strong></h1><p>根据提取出来的PPF，实现了全局描述作为一个映射特性空间到空间的哈希表点对。为了做到这一点，距离和角度是和的采样步长分别为。然后将这些量化的特性用作哈希表的键。点对特性映射到相同的部分中并组合在一起放在同一bin里。为了降低计算复杂度，在下采样在这个阶段，要将所有的点整合到一起其至少为距离，本文使用泊松函数磁盘采样算法。</p><h1 class=pgc-h-arrow-right><strong>1.2在线匹配</strong></h1><h1 class=pgc-h-arrow-right><strong>1.2.1投票机制</strong></h1><p>对于固定的场景点对，我们寻求最优模型对应计算匹配和六自由度位姿。本文采用一种类似于广义霍夫变换的投票机制，投票可以直接在6DOF位姿空间上进行，Drost等提出了一种有效的方案,利用局部座标将投票空间缩减为2D。只要找到一个模型对，对应于一个场景对，就建立一个中间座标系，其中和通过物体围绕法线旋转来对齐。预先计算了该模型的平面旋转角曲线，在线计算了场景点的类似曲线。通过简单的减法求出了平面绕x轴的旋转角，即:.</p><h1 class=pgc-h-arrow-right><strong>1.2.2位姿聚类</strong></h1><p>对于投票后的位姿进行排序，作为对不相交的部分集群进行投票的结果，每个场景参考获得一个姿势候选。这些候选位姿分别为每个片段分组。一个聚集聚类加上良好的姿态平均方案被认为是合理准确的。最初，候选姿势按票数计算被排序。最高的投票创造了第一个集群，只创建一个新的姿态集群，如果候选姿态明显偏离现有的簇。当一个姿态被添加到集群中时，集群平均值将被更新 聚类分数增加,得到新的候选位姿。所描述的聚类需要一个姿态平均步骤，访问每个候选姿势一次。为了准确起见， 使用旋转矩阵是禁止的，因为它们不能直接平均。</p><h1 class=pgc-h-arrow-right><strong>1.2.3假设检验</strong></h1><p>本文方法为每个对象生成一组假设，具有合理的位姿精度。然而，如此庞大的假设集需要一个有效的验证方案和典型的策略，如Hinterstoister et al.[2]，要么将ICP放入回路，然而，对于本文方法，姿态精度不用ICP来进行精调，为了验证所收集的假设并对其进行排序，将可见空间按照如下投影误差函数分为3个类别:杂波(离群点)、遮挡物和模型上的点:</p><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0ebcd4305fb34b9cad84a30a058176f7><p class=pgc-img-caption></p></div><p>其中选择模型的投影点M对应像素p，给定一个摄像机矩阵K和假设h的姿态参数，对给定的有效点p进行分类为：</p><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3c02d969e6f14b6196d707cb61f15ade><p class=pgc-img-caption></p></div><p>然后，给定假设的分数为：</p><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/efb255154996425fb5d2a5635f4f1919><p class=pgc-img-caption></p></div><p>模型点的数量的有效区域的投影，阈值和依赖于传感器，由于传感器没有获得缺失点，阈值被放宽。这个度量有利于更少的遮挡和更少的杂乱匹配，拥有更多法线一致的模型点。然而，实验中，发现使用过滤后的聚类增加了假设下降姿势的机会，而这只有在很少被验证错过的情况下才会发生。</p><h1 class=pgc-h-arrow-right><strong>二实验</strong></h1><h1 class=pgc-h-arrow-right><strong>2.1 模拟合成实验</strong></h1><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9ae182277a3645328a3c416e36aa7ef7><p class=pgc-img-caption></p></div><p><strong>图1投票策略的比较</strong></p><h1 class=pgc-h-arrow-right><strong>2.2真实场景</strong></h1><div class=pgc-img><img alt=基于PPF方式改进的物体检测与位姿估计算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5d3346a86109464185f53461f37ffdd1><p class=pgc-img-caption></p></div><p>图2 定性结果</p><p>a)本文数据中的检测结果，在远程Kinect扫描中存在小物体</p><p>b)对ACCV3D数据集的位姿估计结果</p><h1 class=pgc-h-arrow-right><strong>参考文献</strong></h1><p>[1] M. Alexa, J. Behr, D. Cohen-Or, S. Fleishman, D. Levin, and C. T. Silva. Computing and rendering point set surfaces .Visualization and Computer Graphics, IEEE Transactions on,9(1):3–15, 2003.</p><p>[2] S. Hinterstoisser, V. Lepetit, S. Ilic, S. Holzer, G. Bradski,K.Konolige, and N. Navab. Model based training, detection and pose estimation of texture-less 3d objects in heavily cluttered scenes. In Computer Vision–ACCV 2012, pages 548–562. Springer, 2013.</p><p>本文仅做学术分享，如有侵权，请联系删文。</p><p><strong>下载1</strong></p><p>在「3D视觉工坊」公众号后台回复：<strong>3D视觉，</strong>即可下载 3D视觉相关资料干货，涉及相机标定、三维重建、立体视觉、SLAM、深度学习、点云后处理、多视图几何等方向。</p><p><br></p><p><strong>下载2</strong></p><p>在「3D视觉工坊」公众号后台回复：<strong>3D视觉github资源汇总，</strong>即可下载包括<strong>结构光、标定源码、缺陷检测源码、深度估计与深度补全源码、点云处理相关源码、立体匹配源码、单目、双目3D检测、基于点云的3D检测、6D姿态估计汇总</strong>等。</p><p><br></p><p><strong>下载3</strong></p><p>在「3D视觉工坊」公众号后台回复：<strong>相机标定，</strong>即可下载独家<strong>相机标定</strong>学习课件与视频网址；后台回复：<strong>立体匹配，</strong>即可下载独家<strong>立体匹配</strong>学习课件与视频网址。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'PPF','改进','物体'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>