<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>使用Detectron2分6步进行目标检测 | 极客快訊</title><meta property="og:title" content="使用Detectron2分6步进行目标检测 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/513895be4d6b4fcca97f9a59bdb13013"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/295e41c5.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/295e41c5.html><meta property="article:published_time" content="2020-10-29T21:11:33+08:00"><meta property="article:modified_time" content="2020-10-29T21:11:33+08:00"><meta name=Keywords content><meta name=description content="使用Detectron2分6步进行目标检测"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/295e41c5.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>使用Detectron2分6步进行目标检测</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>让我们看看如何在涉及文本识别的自定义数据集上使用FAIR（Facebook AI Research）的Detectron 2进行实例检测。</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/513895be4d6b4fcca97f9a59bdb13013><p class=pgc-img-caption></p></div><p>你是否尝试过使用你自己选择的自定义数据集从头开始训练对象检测模型？</p><p>如果是的话，你就会知道这个过程有多乏味。如果我们选择基于区域建议的方法，如更快的R-CNN，或者我们也可以使用SSD和YOLO等一次性检测器算法，我们需要从使用特征金字塔网络和区域建议网络来构建模型。</p><p>如果我们想从头开始实现的话，它们中的任何一个都有点复杂。我们需要一个框架，在这个框架中，我们可以使用最先进的模型，例如Fast，Faster和Mask R-CNN。然而，重要的是我们需要从头开始构建一个模型，以理解其背后的数学原理。</p><p>如果我们想使用自定义数据集快速训练对象检测模型，Detectron 2就可以提供帮助。Detectron 2库的模型库中存在的所有模型都在COCO Dataset上进行了预训练。我们只需要在预先训练的模型上微调我们的自定义数据集。</p><p>Detectron 2完全重写了2018年发布的第一款Detectron。其前身是在Caffe2上编写的，Caffe2是一个深度学习框架，也得到了Facebook的支持。Caffe2和Detectron现在都不推荐使用。Caffe2现在是PyTorch的一部分，它的继承者Detectron 2完全是在PyTorch上编写的。</p><p>Detectron2旨在通过提供快速的训练并解决公司从研究到生产的过程中面临的问题，来促进机器学习的发展。</p><p>以下是Detectron 2提供的各种类型的目标检测模型。</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0a3bdc941a9143f084a31e06e29b3347><p class=pgc-img-caption></p></div><p>让我们直接研究<strong>实例检测</strong>。</p><p>实例检测是指对象的分类和定位，并带有边界框。在本文中，我们将使用Detectron 2的模型库中的Faster RCNN模型来识别图像中的文本语言。</p><p>请注意，我们将语言限制为2种。</p><p>我们识别北印度语和英语文本，并为其他语言提供了一个名为“Others”的类。</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/96ab2d624d30405a983c8a5614f62db5><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7c576e0e4fb447148538b6b522298897><p class=pgc-img-caption></p></div><p>我们将实现一个以这种方式输出的模型。</p><p>让我们开始吧！</p><p>使用Detectron 2，可以使用七个步骤对任何自定义数据集执行对象检测。所有这些步骤都可以在此Google Colab Notebook 中轻松找到，你可以立即运行！</p><p>使用Google Colab进行这项工作很容易，因为我们可以使用GPU进行更快的训练。</p><h1 class=pgc-h-arrow-right>步骤1：安装Detectron 2</h1><p>首先安装一些依赖项，例如Torch Vision和COCO API，然后检查CUDA是否可用。CUDA有助于跟踪当前选择的GPU。然后安装Detectron2。</p><pre><code># install dependencies: !pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html!pip install cython pyyaml==5.1!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'import torch, torchvisionprint(torch.__version__, torch.cuda.is_available())!gcc --version# install detectron2:!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html</code></pre><h1 class=pgc-h-arrow-right>步骤2：准备和注册数据集</h1><p>导入一些必要的程序包。</p><pre><code># You may need to restart your runtime prior to this, to let your installation take effectimport detectron2from detectron2.utils.logger import setup_loggersetup_logger()# import some common librariesimport numpy as npimport cv2import randomfrom google.colab.patches import cv2_imshow# import some common detectron2 utilitiesfrom detectron2 import model_zoofrom detectron2.engine import DefaultPredictorfrom detectron2.config import get_cfgfrom detectron2.utils.visualizer import Visualizerfrom detectron2.data import MetadataCatalog</code></pre><p>内置数据集中列出了detectron2具有内置支持的数据集。如果要使用自定义数据集，同时还要重用detectron2的数据加载器，则需要注册数据集（即，告诉detectron2如何获取数据集）。</p><ul><li>内置数据集: https://detectron2.readthedocs.io/tutorials/builtin_datasets.html</li></ul><p>我们使用具有三个类别的文本检测数据集：</p><ol start=1><li>英语</li><li>印地语</li><li>其他</li></ol><p>我们将从在COCO数据集上预先训练的现有模型训练文本检测模型，该模型可在detectron2的模型库中使用。</p><p>如果你有兴趣了解从原始数据集格式到Detectron 2接受的格式的转换，请查看：</p><ul><li>https://colab.research.google.com/drive/1q-gwQteO79r8sX59oYnHYCNtP9zXWFPN?usp=sharing</li></ul><p>如何将数据输入模型？输入数据要求属于某些格式，如YOLO格式、PASCAL VOC格式、COCO格式等。Detectron2接受COCO格式的数据集。数据集的COCO格式由一个JSON文件组成，该文件包含图像的所有细节，如大小、注释（即边界框座标）、与其边界框对应的标签等。例如，</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4f519c0db68c4240a147afab720e1ea7><p class=pgc-img-caption></p></div><p>这是一个JSON格式的图像。边界框表示有不同类型的格式。它必须是Detectron2的structures.BoxMode成员。这样的格式有5种。但目前，它支持 BoxMode.XYXY_ABS, BoxMode.XYWH_ABS.</p><p>我们使用第二种格式。（X，Y）表示边界框的一个座标，W，H表示该框的宽度和高度。category_id 指的是边界框所属的类别。</p><p>然后，我们需要注册我们的数据集。</p><pre><code>import jsonfrom detectron2.structures import BoxModedef get_board_dicts(imgdir):    json_file = imgdir+"/dataset.json" #Fetch the json file    with open(json_file) as f:        dataset_dicts = json.load(f)    for i in dataset_dicts:        filename = i["file_name"]         i["file_name"] = imgdir+"/"+filename         for j in i["annotations"]:            j["bbox_mode"] = BoxMode.XYWH_ABS #Setting the required Box Mode            j["category_id"] = int(j["category_id"])    return dataset_dictsfrom detectron2.data import DatasetCatalog, MetadataCatalog#Registering the Datasetfor d in ["train", "val"]:    DatasetCatalog.register("boardetect_" + d, lambda d=d: get_board_dicts("Text_Detection_Dataset_COCO_Format/" + d))    MetadataCatalog.get("boardetect_" + d).set(thing_classes=["HINDI","ENGLISH","OTHER"])board_metadata = MetadataCatalog.get("boardetect_train")</code></pre><p>为了验证数据加载是否正确，让我们可视化训练集中随机选择的样本的标注。</p><h1 class=pgc-h-arrow-right>步骤3：可视化训练集</h1><p>我们将从数据集的train文件夹中随机选择3张图片，并查看边界框的外观。</p><pre><code>#Visualizing the Train Datasetdataset_dicts = get_board_dicts("Text_Detection_Dataset_COCO_Format/train")#Randomly choosing 3 images from the Setfor d in random.sample(dataset_dicts, 3):    img = cv2.imread(d["file_name"])    visualizer = Visualizer(img[:, :, ::-1], metadata=board_metadata)    vis = visualizer.draw_dataset_dict(d)    cv2_imshow(vis.get_image()[:, :, ::-1])</code></pre><p>输出看起来是这样的，</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1397cb41120a43eca34bdf617756532a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cebd8d94f49c4f34921571a1ccca26f9><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e1a19c4626a3422b8b905953625109ec><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>第四步：训练模型</h1><p>我们向前迈进了一大步。这是我们给出配置和设置模型准备接受训练的步骤。从技术上讲，我们只是在数据集上微调我们的模型，因为模型已经在COCO数据集上进行了预训练。</p><p>在Detectron2的模型库里有大量的模型可用于目标检测。在这里，我们使用faster_rcnn_R_50_FPN_3x。</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/85f0d3e542bf451581c069f1f224b888><p class=pgc-img-caption></p></div><p>这里有一个主干网（这里是Resnet），用于从图像中提取特征，然后是一个区域建议网络，用于提出区域建议，以及一个用于收紧边界框的框头部。</p><p>你可以在我的前一篇文章中读到更多关于R-CNN如何更快工作的文章。</p><ul><li>https://towardsdatascience.com/understanding-fast-r-cnn-and-faster-r-cnn-for-object-detection-adbb55653d97</li></ul><p>让我们为训练设置配置。</p><pre><code>from detectron2.engine import DefaultTrainerfrom detectron2.config import get_cfgimport oscfg = get_cfg()cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")) #Get the basic model configuration from the model zoo #Passing the Train and Validation setscfg.DATASETS.TRAIN = ("boardetect_train",)cfg.DATASETS.TEST = ("boardetect_val",)# Number of data loading threadscfg.DATALOADER.NUM_WORKERS = 4cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo# Number of images per batch across all machines.cfg.SOLVER.IMS_PER_BATCH = 4cfg.SOLVER.BASE_LR = 0.0125  # pick a good LearningRatecfg.SOLVER.MAX_ITER = 1500  #No. of iterations   cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 # No. of classes = [HINDI, ENGLISH, OTHER]cfg.TEST.EVAL_PERIOD = 500 # No. of iterations after which the Validation Set is evaluated. os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)trainer = CocoTrainer(cfg) trainer.resume_or_load(resume=False)trainer.train()</code></pre><p>我不认为这是最好的配置。当然，其他配置的精确度也会提高。毕竟，这取决于选择正确的超参数。</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c6b711c29a634356a89cf4017ddaaca3><p class=pgc-img-caption></p></div><p>注意，这里我们还计算验证集中每500次迭代的精确度。</p><h1 class=pgc-h-arrow-right>第五步：使用训练好的模型进行推理</h1><p>现在是时候通过在验证集上测试模型来推断结果了。</p><p>成功完成训练后，输出文件夹保存在本地存储器中，其中存储最终权重。你可以保存此文件夹，以便将来根据此模型进行推断。</p><pre><code>from detectron2.utils.visualizer import ColorMode#Use the final weights generated after successful training for inference  cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set the testing threshold for this model#Pass the validation datasetcfg.DATASETS.TEST = ("boardetect_val", )predictor = DefaultPredictor(cfg)dataset_dicts = get_board_dicts("Text_Detection_Dataset_COCO_Format/val")for d in random.sample(dataset_dicts, 3):        im = cv2.imread(d["file_name"])    outputs = predictor(im)    v = Visualizer(im[:, :, ::-1],                   metadata=board_metadata,                    scale=0.8,                   instance_mode=ColorMode.IMAGE       )    v = v.draw_instance_predictions(outputs["instances"].to("cpu")) #Passing the predictions to CPU from the GPU    cv2_imshow(v.get_image()[:, :, ::-1])</code></pre><p>结果：</p><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/193610679e814e399d7e5975d30d7bfd><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8bc92f52d8e84d54a7b4a895d16d6204><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>第6步：评估训练模型</h1><p>通常，模型的评估遵循COCO评估标准。用平均精度（mAP）来评价模型的性能。</p><p>这是一篇关于mAP的文章：https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/</p><pre><code>#import the COCO Evaluator to use the COCO Metricsfrom detectron2.evaluation import COCOEvaluator, inference_on_datasetfrom detectron2.data import build_detection_test_loader#Call the COCO Evaluator function and pass the Validation Datasetevaluator = COCOEvaluator("boardetect_val", cfg, False, output_dir="/output/")val_loader = build_detection_test_loader(cfg, "boardetect_val")#Use the created predicted model in the previous stepinference_on_dataset(predictor.model, val_loader, evaluator)</code></pre><div class=pgc-img><img alt=使用Detectron2分6步进行目标检测 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/97ea9c51779046ffa29cb532570a4fd7><p class=pgc-img-caption></p></div><p>对于0.5的IoU，我们获得约79.4％的准确度，这还不错。可以通过稍微调整参数并增加迭代次数来增加。但请密切注意训练过程，因为该模型可能会过拟合。</p><p>如果你需要从保存的模型中进行推断，请浏览：https://colab.research.google.com/drive/1d0kXs-TE7_3CXldJNs1WsEshXf8Gw_5n?usp=sharing</p><h1 class=pgc-h-arrow-right>结论</h1><p>在本文中，我重点介绍了使用Detectron 2的自定义数据集进行目标检测的过程，而不是着重于获得更高的准确性。</p><p>尽管这似乎是一个非常简单的过程，但在Detectron 2的库中还有很多值得探索的地方。我们有大量的优化参数，可以进一步调整以获得更高的准确性，这完全取决于一个人的自定义数据集。</p><p>你可以从我的Github存储库下载 notebook，然后尝试在Google Colab或Jupyter Notebooks上运行它。</p><ul><li>https://github.com/aakarsh7599/Text-Detection-using-Detectron2</li></ul></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Detectron2','进行','目标'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>