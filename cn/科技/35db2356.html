<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>大数据深度学习的新利器: 快速神经网络训练:P-network | 极客快訊</title><meta property="og:title" content="大数据深度学习的新利器: 快速神经网络训练:P-network - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/d172925963f2465aa131058c05cd72f9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/35db2356.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/35db2356.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/35db2356.html><meta property="article:published_time" content="2020-11-14T21:06:51+08:00"><meta property="article:modified_time" content="2020-11-14T21:06:51+08:00"><meta name=Keywords content><meta name=description content="大数据深度学习的新利器: 快速神经网络训练:P-network"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/35db2356.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>大数据深度学习的新利器: 快速神经网络训练:P-network</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d172925963f2465aa131058c05cd72f9><p class=pgc-img-caption></p></div><p>微信公众号：法思诺创新</p><p>ID：Fasinno-Academy</p><p><br></p><p><strong>文丨</strong>Boris Zlotin</p><p>国际TRIZ学会创始人(TRIZ五级大师)</p><p><strong>文丨</strong>Ivan Nehrishnyi, Sr</p><p><strong>文丨</strong>Ivan Nehrishnyi, Jr</p><p><strong>文丨</strong>Vladimir Proseanic</p><p><strong>文丨</strong>姜台林 博士</p><p>法思诺创新学院 院长</p><p>国际TRIZ学会副主席 (TRIZ五级大师)</p><p>国际设计思考学会联合创始人 (DT大师)</p><p><strong>编辑</strong>丨illa</p><p>本文乃是介绍一种新型的人工神经网络的基本架构-渐进式人工神经网络（PANN/P-network）及其新的训练算法。与已知的人工神经网络和训练方法相比，P-network体系结构及其算法的结合使用提供了更高效的训练速度本文也针对对P-network和现有网络进行了测试比较。</p><h1 class=pgc-h-center-line>P-network的理论基础</h1><p><br></p><p>人工神经网络（ANN）于1969年在学术上被称为通用逼近设备[1]。</p><p>于此同时，学者也揭示了ANN的主要限制。众所周知，ANN中的每个突触具有一个突触权重。神经网络训练是通过对训练图像进行权重的计算和校正来实现的。对于每一个接下来的训练图像，必须再次校正相同的权重。因此，训练是通过大量的迭代进行的。随着训练量的增加，训练时间则呈现倍数的增长。</p><p></p><p>在参考文献[2]和[3]中，提出了一种新的神经网络设计方法，它不同于现有的神经网络，它的特点是每个神经突触都有多个校正权重，校正权重由一个特殊的装置(分配器)根据输入信号的值进行选择。</p><p><br></p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/106bb8282b8442cfb0f50aa4bcff658c><p class=pgc-img-caption></p></div><p>图1展示了一个众所周知的人工形式神经元，它包括一个求和装置和一个启动装置，图2展示了一个新的人工神经元，称为p神经元。在p神经元中，来自输入设备的信号被发送到分配器，分配器估算信号的值，将它引用到一个值区间中，并相应地为这个信号分配一个校正权重。</p><p>图2显示，一个值与值间隔3对应的信号应选择校正权值d3。</p><p></p><p>一个新的神经网络有一个经典的神经结构，p神经元被用来代替正式的神经元。图3展示了具有经典形式神经元的ANN，图4展示了具有本研究所提出的p神经元的p- network。</p><p></p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/618255e12ce444b988cad5348d281249><p class=pgc-img-caption></p></div><p><strong></strong></p><h1 class=pgc-h-center-line>P-network的训练</h1><p>如图4所示，P-network训练与经典ANN的训练有着显著性的差异。由于每个突触存在多个校正权重，因此不同的输入信号会启动不同的权重。相同值的输入信号启动相同的权重。</p><p><br></p><p>P-network的训练包括以下步骤</p><p><br></p><p><strong>1. 输入信号被发送到分配器</strong></p><p>分配器根据输入信号的值启动突触处的权重,通过其他输入信号，突触上的其他权重被启动,同时这些权重的值将发送到与突触相连的神经元。</p><p></p><p><strong>2. 神经元的输出信号是由神经元接收到的校正权值的总和所给定的</strong></p><p>∑n= i,d,nWi,d,n</p><p>注释：</p><p>∑n-神经元输入信号；</p><p>i -校正权输入指针，确定信号输入;</p><p>d -校正权值区间指针，确定给定信号的值区间;</p><p>n -校正权神经元指数，确定接收到信号的神经元;</p><p>W i,d,n-校正重量值；</p><p></p><p><strong>3.将接收到的神经元输出信号与预先设定的理想输出信号进行比较，生成校正信号，用于校正权重的分组校正。</strong>其中，组校正是与给定神经元相关的启动校正权重的修正，每个权重都改变为相同的值或乘以相同的系数。</p><p></p><p>以下是组校正信号的形成和使用的两种典型的非限制性变式:</p><p></p><p>变式#1 -根据理想输出信号与得到的输出信号总和之间的差值，形成和应用校正信号，如下所示：</p><p></p><p>根据公式计算各校正权重贡献到神经元n的相等校正值∆n:</p><p>∆n = (On - ∑n) / S</p><p></p><p>注释：</p><p>On -与神经元输出总和相对应的理想输出信号∑n;</p><p>S -连接到神经元n的突触数。</p><p></p><p>变式2-基于所需输出信号与获得的输出总和之比的校正信号的形成和应用如下：</p><p></p><p>根据公式计算各校正权重反映到神经元n的相等校正值∆n:</p><p></p><p>∆n = On / ∑n</p><p></p><p><strong>4.矫正所有连接到给定神经元的权值。</strong>根据第一个变式,Δn被添加到当前的重量值。在第二个变式, 当前重量乘以Δn价值。这就消除了给定神经元当前图像的训练误差。换句话说，不是传统的梯度下降法神经网络需要大量的迭代，P-network在一步中提供了对权重的根本校正。</p><p><strong>5.重复步骤2到5，这样就完成了第一个训练阶段。</strong>可以通过其与下一阶段图像的训练来校正在第一阶段图像进行网络训练期间获得的校正后的权重, 如果在第一个训练阶段后没有达到预期的精度，可以再进行几个阶段的训练。</p><p>P-network计算重量修正的简单方法不需要迭代过程，提供了一个快速的完成训练阶段。对整个训练误差量的所有主动权重进行一步校正，大大减少了训练所需的时间间隔。</p><p></p><h1 class=pgc-h-center-line>P-network的软件实现</h1><p>本文的P-network已经使用面向对象语言(OOL)以软件形式实现。图5表示统一建模语言（UML）中P-network的软件实现:</p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4a10abda1dd44204a23edd67f7106d77><p class=pgc-img-caption></p></div><p><br></p><p>图5中的UML模型显示了生成的软件对象及其关系，以及这些对象的功能和参数。更详细的步骤如图6 - 12所示，包括:</p><ul><li>Fig.6 - P-network形成的一般顺序;</li><li>Fig.7 -分析过程，为P-network的形成准备必要的资料;</li><li>Fig.8 -输入信号处理，使P-network能够在其训练和操作期间与输入数据进行交互;</li><li>Fig.9 -神经元单元的形成，包括具有矫正权重的神经元和突触，提供P-network训练和操作;</li><li>Fig.10 -创建正确的突触权重。</li></ul><p></p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f13efc343a8842c8afc34943ac0dadec><p class=pgc-img-caption></p></div><p></p><p>在这个过程中，形成了以下几类对象:</p><ul><li>P-network</li><li>输入信号;</li><li>神经元单元;</li><li>神经突触.</li></ul><p></p><p>形成的神经元单元包括:·</p><ul><li>神经突触类的对象数组；</li><li>神经元: 一个变量，在培训过程中提供了”加”的功能；</li><li>计算器: 一个变量，其中包含了预期总和的值，并在其中进行训练校正的算。</li></ul><p>神经元单元提供网络培训，包括：</p><ul><li>神经元总和的形成；</li><li>预期价值的分配；</li><li>更正的计算；</li><li>在校正权重中引入校正的功能。</li></ul><p></p><p>形成的对象类突触包括：</p><ul><li>校正权重；</li><li>指向与突触相关的输入的指示。</li></ul><p>突触类提供以下功能：</p><ul><li>开始校正;</li><li>因子乘以权重；</li><li>权重校正。</li></ul><p>形成的对象输入信号类包括：</p><ul><li>指向与给定输入连接的突触的指示数组；</li><li>在输入信号的值所在的位置可变；</li><li>潜在的最小和最大输入信号值；</li><li>间隔数；</li><li>间隔的宽度。</li></ul><p></p><p>输入信号类提供以下功能：</p><ul><li>网络结构的形成，包括：-在输入和突触之间添加和删除连结；-给定输入的突触间隔数的分配。</li><li>分配最小和最大输入信号的参数值；</li><li>对网络运营的贡献：-设置输入信号；-设置校正系数。</li></ul><p></p><p>形成的对象类P-network包括对象类数组:</p><ul><li>神经元单元;</li><li>输入信号。</li></ul><p></p><p>P-network类提供了以下功能:</p><ul><li>指定类输入信号中的对象数量;</li><li>指定类神经元单元中的对象数量;</li><li>提供对象神经元单元的功能和输入信号的组请求。</li></ul><p></p><p>在培训过程中形成操作循环，其中:</p><ul><li>神经元的输出就形成了它在周期开始之前等于零。对所有参与给定神经元单元的突触进行综述，其中每个突触:-分配器根据输入信号形成一组校正因子。-所有到达这个突触的重量都被检查，每一个重量都执行以下操作:-乘法的重量值对应的系数Сi, d n;-乘法的结果加到神经元的输出和上。</li><li>计算校正值∆n;</li><li>乘法的结果修正价值系数∆n, Сid n计算(∆n×Сi, d, n);</li><li>对所有参与给定神经元单元的突触进行综述，其中每个突触:对所有传入突触的权重进行复核，每个权重由相应的修正值改变。</li></ul><p></p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ebf5b98679324a4b9119f6df05cc8d67><p class=pgc-img-caption></p></div><p>图11 -单个神经单元的详细训练过程</p><p>图12 - P-network训练的一般流程</p><h1 class=pgc-h-center-line>测试结果</h1><p>本研究也根据上述算法构建的P-network在Python中进行测试。</p><p>对基于高级谷歌Tensor Flow技术的深度学习神经网络(DNN)与P-network进行了比较。基于标准统计IRIS检验的比较结果如下:</p><ul><li>训练误差:P-network的表现可与DNN的最佳结果相媲美;</li><li>训练速度:P-network速度至少是DNN的3000倍。</li><li>测试结果如下面的屏幕截图所示：</li></ul><p></p><div class=pgc-img><img alt="大数据深度学习的新利器: 快速神经网络训练:P-network" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fa2d88cef3a7484cbb0bf7ee9e2df446><p class=pgc-img-caption></p></div><p></p><p>可以看出，在同样的精度下，P-network的训练速度为1 ms，而DNN为22141 ms。测试比较结果是在以下的系统设备中进行:</p><p></p><h1 class=pgc-h-center-line>结 论</h1><p>这些测试通过消除迭代计算的需要，证实了从根本上加速网络培训的理论预期。他们还发现了额外的好处:</p><p></p><p>在预先定义的准确性要求下，网络训练周期的数量急剧减少。在某些情况下，整个训练在2-3个周期内完成，在某些情况下，会在几十个周期内完成，这进一步减少了训练时间。</p><p>P-network不需要传统神经网络所需要的启动函数，删除此功能进一步提高了训练速度。</p><p>P-network和所提出的训练方法可以显著加速各种专用神经网络的运行，例如霍普菲尔德和科荷伦神经网络，波尔兹曼机器和自适应网络。该网络及其训练方法可用于识别，聚类和分类，预测，关联信息搜索等，并可实时增加部分网络训练。</p><p></p><p>此外，P-network应用也可以:</p><ul><li>通过使用基于P-network的计算块和缓存内存系统，提高计算机的计算能力。</li><li>节省计算资源，减少能源消耗。</li><li>创建高性能、快速和可靠的大型数据库。</li></ul><p><br></p><p><strong>参考文献：</strong></p><p>1. Marvin Minsky and Seymour Papert “Perceptrons: an introduction to computational geometry”, Cambridge, MA: MIT Press., 1969.</p><p>2. D. Pescianschi, A. Boudichevskaia, B. Zlotin, and V. Proseanic, “Analog and Digital Modeling of a Scalable Neural Network,” CSREA Press, US 2015.</p><p>3. Patent US 9390373.</p><p>4. Patent US 9619749.</p><p>5. Patent application US 20170177998 A1.</p><p>6. International patent application PCT/US2015/19236, 06-Mar-2015.</p><p>7. International patent application PCT/US2017/36758, 09-JUN-2017.</p><p><br></p><p>本文由法思诺创新原创，欢迎关注，创新有你一路同行！</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'大数据','学习','神经'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>