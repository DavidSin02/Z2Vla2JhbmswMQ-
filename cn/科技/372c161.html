<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>用于图像降噪的卷积自编码器 | 极客快訊</title><meta property="og:title" content="用于图像降噪的卷积自编码器 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/449c17c702f54ceca0b90a4ddcc4a0bb"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><meta property="article:published_time" content="2020-10-29T21:05:26+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:26+08:00"><meta name=Keywords content><meta name=description content="用于图像降噪的卷积自编码器"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/372c161.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>用于图像降噪的卷积自编码器</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/449c17c702f54ceca0b90a4ddcc4a0bb><p class=pgc-img-caption></p></div><p>这篇文章的目的是介绍关于利用自动编码器实现图像降噪的内容。</p><p>在神经网络世界中，对图像数据进行建模需要特殊的方法。其中最著名的是卷积神经网络(CNN或ConvNet)或称为卷积自编码器。并非所有的读者都了解图像数据，那么我先简要介绍图像数据(如果你对这方面已经很清楚了，可以跳过)。然后，我会介绍标准神经网络。这个标准神经网络用于图像数据，比较简单。这解释了处理图像数据时为什么首选的是卷积自编码器。最重要的是，我将演示卷积自编码器如何减少图像噪声。这篇文章将用上Keras模块和MNIST数据。Keras用Python编写，并且能够在TensorFlow上运行，是高级的神经网络API。</p><h1 class=pgc-h-decimal data-index=01>了解图像数据</h1><p>如图(A)所示，图像由“像素”组成。在黑白图像中，每个像素由0到255之间的数字表示。如今大多数图像使用24位彩色或更高的颜色。一幅RGB彩色图像表示一个像素的颜色由红色、绿色和蓝色组成，这三种颜色各自的像素值从0到255。RGB色彩生成器(如下所示)表明，RGB色彩系统利用红绿蓝，组合成各种颜色。因此，一个像素由含三个值的RGB(102、255、102)构成，其色号为＃66ff66。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/195b9ccf0c544c479d8db9e4394a6a22><p class=pgc-img-caption></p></div><p>宽800像素，高600像素的图像具有800 x 600 = 480,000像素，即0.48兆像素(“兆像素”等于100万像素)。分辨率为1024×768的图像是一个由1,024列和768行构成的网格，共有1,024×768 = 0.78兆像素。</p><p><br></p><h1 class=pgc-h-decimal data-index=02>MNIST</h1><p>MNIST数据库是一个大型的手写数字数据库，通常用于训练各种图像处理系统。Keras的训练数据集具备60,000条记录，而测试数据集则包含了10,000条记录。每条记录共有28 x 28个像素。</p><pre><code>from keras.layers import Input, Densefrom keras.models import Modelfrom keras.datasets import mnistimport numpy as np(x_train, _), (x_test, _) = mnist.load_data()</code></pre><p>它们看起来怎么样？我们用绘图库及其图像功能imshow()展示前十条记录。</p><pre><code>import matplotlib.pyplot as pltn = 10  # 显示的记录数plt.figure(figsize=(20, 4))for i in range(n):    # 显示原始图片    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ec254e1e581044bca7b1428f4abb30b0><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=03>图像数据的堆叠，用于训练</h1><p>如果要让神经网络框架适用于模型训练，我们可以在一列中堆叠所有28 x 28 = 784个值。第一条记录的堆叠列如下所示(使用x_train[1].reshape(1,784))：</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2e7def5cde704a7096ff484ddcf476c0><p class=pgc-img-caption></p></div><p>然后，我们可以使用标准的神经网络训练模型，如图(B)所示。数值为784的每个值都是输入层中的一个节点。且慢！堆叠数据会丢失很多信息吗？答案是肯定的。图像中的空间关系被忽略了。这使得大量的信息丢失。那么，我们接着看卷积自编码器如何保留空间信息。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/21d723e025554871897ffaa6776dbb5d><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=04>为什么图像数据首选卷积自编码器？</h1><p>可以看到，数据切片和数据堆叠会导致信息大量丢失。卷积自编码器放弃堆叠数据，使图像数据输入时保持其空间信息不变，并在卷积层中以温和的方式提取信息。图(D)演示了将平面2D图像先提取到一个厚的正方体(Conv1)，再提取到一个长方体(Conv2)和另一个长度更长的长方体(Conv3)。此过程旨在保留数据中的空间关系。这是自动编码器的编码过程。中间部分是一个完全连接的自动编码器，其隐藏层仅由10个神经元组成。然后就是解码过程。三个立方体将会展平，最后变成2D平面图像。图(D)的编码器和解码器是对称的。实际上，编码器和解码器不要求对称。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a98f303752284817979d2b053c5c2397><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=05>卷积自编码器如何工作？</h1><p>上面的数据析取似乎很神奇。数据析取究竟是如何进行的？这包括以下三层：卷积层，线性整流层和池化层。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3a2e2517a152487fa23d404fa1b2f177><p class=pgc-img-caption></p></div><p><strong>1. 卷积层</strong></p><p>卷积步骤会生成很多小块，称为特征图或特征，如图(E)的绿色、红色或深蓝色的正方形。这些正方形保留了输入图像中像素之间的关系。如图(F)所示，每个特征扫描原始图像。这一产生分值的过程称为卷积。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a71367f093564fc19f673f9b730e6d5e><p class=pgc-img-caption></p></div><p>扫描完原始图像后，每个特征都会生成高分值和低分值的滤波图像，如图(G)所示。如果匹配完美，那块正方形的得分就高。如果匹配度低或不匹配，则得分低或为零。例如，原始图像有四个区域与红色方块完全匹配，那么这四个区域的得分都很高。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/53ebff749bcb427ca54aace48d69eae1><p class=pgc-img-caption></p></div><p>过滤器越多，模型可以提取的特征就越多。但是，特征越多，训练时间也就越长。因此，最好还是选择最少的过滤器提取特征。</p><p><strong>1.1 填充</strong></p><p>特征如何确定匹配项？一种超参数是填充，有两种选择：(i)用零填充原始图像以符合该特征，或(ii)删除原始图像中不符的部分并保留有效部分。</p><p><strong>1.2步长</strong></p><p>卷积层的另一个参数：步长。步长是输入矩阵上移动的像素个数。当步长为1时，过滤器一次移动1个像素。在Keras代码中，我们将其视为超参数。</p><p><strong>2.线性整流步骤</strong></p><p>线性整流单位(ReLU)的步骤与典型的神经网络相同。它将所有的负值校正为零，确保数学运算正确。</p><p><strong>3.最大池化层</strong></p><p>池化会缩小图像尺寸。在图(H)中，一个2 x 2的窗口(称为池的大小)扫描每个滤波图像，并将该2 x 2窗口的最大值划分给新图像中大小为1 x 1的正方形。如图(H)所示，第一个2 x 2窗口的最大值分数高(用红色表示)，因此高分划分给1 x 1正方形。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/42a6b7719785484680fc439b44ad1194><p class=pgc-img-caption></p></div><p>除了采用最大值之外，其他不常用的池化方法还包括“平均池化”(取平均值)或“总和池化”(总和)。</p><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2a20f1a81aa47d89cec2aab83058352><p class=pgc-img-caption></p></div><p>池化后，会生成新的更小的滤波图像。现在我们拆分这个滤波图像，然后堆叠为一列，如图(J)所示。</p><h1 class=pgc-h-decimal data-index=06>Keras模型</h1><p>以上三层是卷积神经网络的构建块。Keras具有以下两个功能：</p><p>• Conv2D(filters, kernelsize, activation = 'reLu', strides=1)：核尺寸(kernelsize)是2D卷积窗口的高度和宽度。图(E)使用的是2×2正方形，所以例子中核尺寸将为(2,2)。步长是输入矩阵上移动的像素个数。我们一次将滤镜移动了1个像素，所以步长为1。</p><p>• MaxPooling2D(pool_size=(2,2))：在图(H)中，我们使用2×2窗口作为池的大小。因此，我们将在以下代码中使用(2,2)。</p><p>你可以在卷积自编码器中构建许多卷积层。在图(E)中，在编码部分有三层，分别标记为Conv1，Conv2和Conv3。因此，我们要进行相应的构建。</p><p>• 下面的代码input_img = Input(shape=(28,28,1)表明输入的2D图像为28 x 28。</p><p>• 然后，它构建了Conv1，Conv2和Conv3。</p><p>• 请注意，Conv1在Conv2内部，而Conv2在Conv3内部。</p><p>• 要是过滤器无法适应输入图像，填充将指定下一步该做什么。padding='valid'表示过滤器不符合，图像的一部分将被丢弃；padding='same'用零填充图片以适应图片。</p><pre><code>from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2Dfrom keras.models import Model# 编码过程input_img = Input(shape=(28, 28, 1))  ############# 编码 ############## Conv1 #x = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)x = MaxPooling2D(pool_size = (2, 2), padding='same')(x)# Conv2 #x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)x = MaxPooling2D(pool_size = (2, 2), padding='same')(x) # Conv 3 #x = Conv2D(filters = 8, (3, 3), activation='relu', padding='same')(x)encoded = MaxPooling2D(pool_size = (2, 2), padding='same')(x)# 注意:# padding 是一个超参数，值'valid' or 'same'. # "valid" 意味不需要填充 # "same" 填充输入，使输出具有与原始输入相同的长度。 </code></pre><p>然后，解码过程继续。因此，下面解码部分已全部完成编码和解码过程。</p><pre><code>############# 解码 ############## DeConv1x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)x = UpSampling2D((2, 2))(x)# DeConv2x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)x = UpSampling2D((2, 2))(x)# Deconv3x = Conv2D(16, (3, 3), activation='relu')(x)x = UpSampling2D((2, 2))(x)decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)</code></pre><p>该Keras API需要模型和优化方法的声明：</p><p>•• Model (inputs= inputimg,outputs= decoded)：在解码给定输入数据inputimg的情况下，模型包括计算输出所需的所有层。compile(optimizer='adadelta',loss='binary_crossentropy')：优化程序会像渐变梯度一样执行优化操作。最常见的是随机梯度下降(SGD)，自适应梯度(Adagrad)和Adadelta(Adadelta是Adagrad的扩展)。有关详细信息，请参见Keras优化器文档。损失函数可以查找Keras损失文档。</p><pre><code># 声明模型autoencoder = Model(input_img, decoded)autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')</code></pre><p>下面，我使用xtrain作为输入和输出来训练模型。batchsize是样本量和epochs是迭代的次数。我指定shuffle=True打乱训练数据。</p><pre><code># 训练模型autoencoder.fit(x_train, x_train,                epochs=100,                batch_size=128,                shuffle=True,                validation_data=(x_test, x_test)               )</code></pre><p>我们可以打印出前十张原始图像和相同十张图像的预测。</p><pre><code>decoded_imgs = autoencoder.predict(x_test)n = 10plt.figure(figsize=(20, 4))for i in range(n):    # 显示原始图像    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)    # 显示重构后的图像    ax = plt.subplot(2, n, i+1+n)    plt.imshow(decoded_imgs[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d078b828049d41ea94dfc597618b2048><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=07>如何构建图像降噪卷积自编码器？</h1><p>图像降噪的想法是训练一个模型，输入噪声数据，并输出它们各自清晰的数据。这是与上述模型的唯一区别。首先让我们向数据添加噪音。</p><pre><code>noise_factor = 0.4x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) x_train_noisy = np.clip(x_train_noisy, 0., 1.)x_test_noisy = np.clip(x_test_noisy, 0., 1.)</code></pre><p>前十张噪声图像如下所示：</p><pre><code>n = 10plt.figure(figsize=(20, 2))for i in range(n):    ax = plt.subplot(1, n, i+1)    plt.imshow(x_test_noisy[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ff15067ea85349fa8000e246a8333ed3><p class=pgc-img-caption></p></div><p>然后，我们训练模型时将输入噪声数据，输出干净的数据。</p><pre><code>autoencoder.fit(x_train_noisy, x_train,                epochs=100,                batch_size=128,                shuffle=True,                validation_data=(x_test_noisy, x_test)               )</code></pre><p>最后，我们打印出前十个噪点图像以及相应的降噪图像。</p><pre><code>decoded_imgs = autoencoder.predict(x_test)n = 10plt.figure(figsize=(20, 4))for i in range(n):    # 显示原始图像    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test_noisy[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)    # 显示重构后的图像    ax = plt.subplot(2, n, i+1+n)    plt.imshow(decoded_imgs[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用于图像降噪的卷积自编码器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d6bde239b4cc4b5ba7860153e712b46b><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=08>是否可以使用任何经过训练的CNN代码吗？</h1><p>可以的。如果你有兴趣学习代码，Keras提供了几个经过预训练的CNN，包括Xception，VGG16，VGG19，ResNet50，InceptionV3，InceptionResNetV2，MobileNet，DenseNet，NASNet和MobileNetV2。值得一提的是，你可以出于研究目的付钱或下载此大型图像数据库ImageNet。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'卷积','自编','码器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>