<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>异地多活场景下，如何进行数据同步？ | 极客快訊</title><meta property="og:title" content="异地多活场景下，如何进行数据同步？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/95de6966f5de42068d11a412cbe1888f"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/39032e8.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/39032e8.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/39032e8.html><meta property="article:published_time" content="2020-10-29T20:58:13+08:00"><meta property="article:modified_time" content="2020-10-29T20:58:13+08:00"><meta name=Keywords content><meta name=description content="异地多活场景下，如何进行数据同步？"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/39032e8.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>异地多活场景下，如何进行数据同步？</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>文章来源：https://dwz.cn/Xmghvn4n</p><p>作者：田守枝</p></blockquote><p>在当今互联网行业，大多数人互联网从业者对"单元化"、"异地多活"这些词汇已经耳熟能详。而<strong>数据同步</strong>是异地多活的基础，所有具备数据存储能力的组件如：数据库、缓存、MQ等，数据都可以进行同步，形成一个庞大而复杂的数据同步拓扑。</p><p>本文将先从概念上介绍单元化、异地多活、就近访问等基本概念。之后，将以数据库为例，讲解在数据同步的情况下，如何解决数据回环、数据冲突、数据重复等典型问题。</p><h1 class=pgc-h-arrow-right>1 什么是单元化</h1><p>如果仅仅从"单元化”这个词汇的角度来说，我们可以理解为将数据划分到多个单元进行存储。"单元"是一个抽象的概念，通常与数据中心(IDC)概念相关，一个单元可以包含多个IDC，也可以只包含一个IDC。本文假设一个单元只对应一个IDC。</p><p>考虑一开始只有一个IDC的情况，所有用户的数据都会写入同一份底层存储中，如下图所示：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/95de6966f5de42068d11a412cbe1888f><p class=pgc-img-caption></p></div><p>这种架构是大多数据中小型互联网公司采用的方案，存在以下几个问题：</p><p><strong>1 不同地区的用户体验不同。</strong>一个IDC必然只能部署在一个地区，例如部署在北京，那么北京的用户访问将会得到快速响应；但是对于上海的用户，访问延迟一般就会大一点，上海到北京的一个RTT可能有20ms左右。</p><p><strong>2 容灾问题。</strong>这里容灾不是单台机器故障，而是指机房断电，自然灾害，或者光纤被挖断等重大灾害。一旦出现这种问题，将无法正常为用户提供访问，甚至出现数据丢失的情况。这并不是不可能，例如：2015年，支付宝杭州某数据中心的光缆就被挖断过；2018年9月，云栖大会上，蚂蚁金服当场把杭州两个数据中心的网线剪断。</p><p>为了解决这些问题，我们可以将服务部署到多个不同的IDC中，不同IDC之间的数据互相进行同步。如下图：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/06331b66dce046d7ace3ba9da22215e5><p class=pgc-img-caption></p></div><p>通过这种方式，我们可以解决单机房遇到的问题：</p><p><strong>1 用户体验。</strong>不同的用户可以选择离自己最近的机房进行访问</p><p><strong>2 容灾问题。</strong>当一个机房挂了之后，我们可以将这个机房用户的流量调度到另外一个正常的机房，由于不同机房之间的数据是实时同步的，用户流量调度过去后，也可以正常访问数据 (故障发生那一刻的少部分数据可能会丢失)。</p><p>需要注意的是，关于容灾，存在一个容灾级别的划分，例如：单机故障，机架(rack)故障，机房故障，城市级故障等。我们这里只讨论机房故障和城市故障。</p><ul class=list-paddingleft-2><li><strong>机房容灾 :</strong> 上面的案例中，我们使用了2个IDC，但是2个IDC并不能具备机房容灾能力。至少需要3个IDC，例如，一些基于多数派协议的一致性组件，如zookeeper，redis、etcd、consul等，需要得到大部分节点的同意。例如我们部署了3个节点，在只有2个机房的情况下， 必然是一个机房部署2个节点，一个机房部署一个节点。当部署了2个节点的机房挂了之后，只剩下一个节点，无法形成多数派。在3机房的情况下，每个机房部署一个节点，任意一个机房挂了，还剩2个节点，还是可以形成多数派。这也就是我们常说的"两地三中心”。</li><li><strong>城市级容灾：</strong>在发生重大自然灾害的情况下，可能整个城市的机房都无法访问。一些组件，例如蚂蚁的ocean base，为了达到城市级容灾的能力，使用的是"三地五中心"的方案。这种情况下，3个城市分别拥有2、2、1个机房。当整个城市发生灾难时，其他两个城市依然至少可以保证有3个机房依然是存活的，同样可以形成多数派。</li></ul><p>小结：如果仅仅是考虑不同地区的用户数据就近写入距离最近的IDC，这是纯粹意义上的”单元化”。不同单元的之间数据实时进行同步，相互备份对方的数据，才能做到真正意义上"异地多活”。实现单元化，技术层面我们要解决的事情很多，例如：流量调度，即如何让用户就近访问附近的IDC；数据互通，如何实现不同机房之间数据的相互同步。流量调度不在本文的讨论范畴内，数据同步是本文讲解的重点。</p><h1 class=pgc-h-arrow-right>2 如何实现数据同步</h1><p>需要同步的组件有很多，例如数据库，缓存等，这里以多个Mysql集群之间的数据同步为例进行讲解，实际上缓存的同步思路也是类似。<br></p><h1 class=pgc-h-arrow-right>2.1 基础知识</h1><p>为了了解如何对不同mysql的数据相互进行同步，我们先了解一下mysql主从复制的基本架构，如下图所示：<br></p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1b71423c4f914448af842e5786c03c86><p class=pgc-img-caption></p></div><p>通常一个mysql集群有一主多从构成。用户的数据都是写入主库Master，Master将数据写入到本地二进制日志binary log中。从库Slave启动一个IO线程(I/O Thread)从主从同步binlog，写入到本地的relay log中，同时slave还会启动一个SQL Thread，读取本地的relay log，写入到本地，从而实现数据同步。</p><p>基于这个背景知识，我们就可以考虑自己编写一个组件，其作用类似与mysql slave，也是去主库上拉取binlog，只不过binlog不是保存到本地，而是将binlog转换成sql插入到目标mysql集群中，实现数据的同步。</p><p>这并非是一件不可能完成的事，MySQL官网上已经提供好所有你自己编写一个mysql slave 同步binlog所需的相关背景知识，访问这个链接：https://dev.mysql.com/doc/internals/en/client-server-protocol.html，你将可以看到mysql 客户端与服务端的通信协议。下图红色框中展示了Mysql主从复制的相关协议：</p><p></p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/78a2ce2da4f4419f935e3464ae073ede><p class=pgc-img-caption></p></div><p>当然，笔者的目的并不是希望读者真正的按照这里的介绍尝试编写一个mysql 的slave，只是想告诉读者，模拟mysql slave拉取binlog并非是一件很神奇的事，只要你的网络基础知识够扎实，完全可以做到。然而，这是一个庞大而复杂的工作。以一人之力，要完成这个工作，需要占用你大量的时间。好在，现在已经有很多开源的组件，已经实现了按照这个协议可以模拟成一个mysql的slave，拉取binlog。例如：</p><ul class=list-paddingleft-2><li>阿里巴巴开源的canal</li><li>美团开源的puma</li><li>linkedin开源的databus ...<br></li></ul><p>你可以利用这些组件来完成数据同步，而不必重复造轮子。假设你采用了上面某个开源组件进行同步，需要明白的是这个组件都要完成最基本的2件事：从源库拉取binlog并进行解析，笔者把这部分功能称之为<strong>binlog syncer</strong>；将获取到的binlog转换成SQL插入目标库，这个功能称之为<strong>sql writer</strong>。</p><p>为什么划分成两块独立的功能？因为binlog订阅解析的实际应用场景并不仅仅是数据同步，如下图：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9bcb6fb9c2a74f9f8703a76d5666b990><p class=pgc-img-caption></p></div><p>如图所示，我们可以通过binlog来做很多事，如：</p><ul class=list-paddingleft-2><li>实时更新搜索引擎，如es中的索引信息</li><li>实时更新redis中的缓存<br></li><li>发送到kafka供下游消费，由业务方自定义业务逻辑处理等<br></li><li>...<br></li></ul><p>因此，通常我们把binlog syncer单独作为一个模块，其只负责解析从数据库中拉取并解析binlog，并在内存中缓存(或持久化存储)。另外，binlog syncer另外提一个sdk，业务方通过这个sdk从binlog syncer中获取解析后的binlog信息，然后完成自己的特定业务逻辑处理。</p><p>显然，在数据同步的场景下，我们可以基于这个sdk，编写一个组件专门用于将binlog转换为sql，插入目标库，实现数据同步，如下图所示：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b2a1f179f68b4967b760bf56575252dd><p class=pgc-img-caption></p></div><p>北京用户的数据不断写入离自己最近的机房的DB，通过binlog syncer订阅这个库binlog，然后下游的binlog writer将binlog转换成SQL，插入到目标库。上海用户类似，只不过方向相反，不再赘述。通过这种方式，我们可以实时的将两个库的数据同步到对端。当然事情并非这么简单，我们有一些重要的事情需要考虑。</p><h1 class=pgc-h-arrow-right>2.2 如何获取全量+增量数据？</h1><p>通常，mysql不会保存所有的历史binlog。原因在于，对于一条记录，可能我们会更新多次，这依然是一条记录，但是针对每一次更新操作，都会产生一条binlog记录，这样就会存在大量的binlog，很快会将磁盘占满。因此DBA通常会通过一些配置项，来定时清理binlog，只保留最近一段时间内的binlog。<br></p><p>例如，官方版的mysql提供了expire_logs_days配置项，可以设置保存binlog的天数，笔者这里设置为0，表示默认不清空，如果将这个值设置大于0，则只会保存指定的天数。</p><p>另外一些mysql 的分支，如percona server，还可以指定保留binlog文件的个数。我们可以通过show binary logs来查看当前mysql存在多少个binlog文件，如下图：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4379b4c8d7184aec9b0f09459a4ea34a><p class=pgc-img-caption></p></div><p>通常，如果binlog如果从来没被清理过，那么binlog文件名字后缀通常是000001，如果不是这个值，则说明可能已经被清理过。当然，这也不是绝对，例如执行"reset master”命令，可以将所有的binlog清空，然后从000001重新开始计数。</p><p>Whatever! 我们知道了，binlog可能不会一直保留，所以直接同步binlog，可能只能获取到部分数据。因此，通常的策略是，由DBA先dump一份源库的完整数据快照，增量部分，再通过binlog订阅解析进行同步。</p><p><strong>2.2 如何解决重复插入</strong></p><p>考虑以下情况下，源库中的一条记录没有唯一索引。对于这个记录的binlog，通过sql writer将binlog转换成sql插入目标库时，抛出了异常，此时我们并不知道知道是否插入成功了，则需要进行重试。如果之前已经是插入目标库成功，只是目标库响应时网络超时(socket timeout)了，导致的异常，这个时候重试插入，就会存在多条记录，造成数据不一致。<br></p><p>因此，通常，在数据同步时，通常会限制记录必须有要有主键或者唯一索引。</p><p><strong>2.3 如何解决唯一索引冲突</strong></p><p>由于两边的库都存在数据插入，如果都使用了同一个唯一索引，那么在同步到对端时，将会产生唯一索引冲突。对于这种情况，通常建议是使用一个全局唯一的分布式ID生成器来生成唯一索引，保证不会产生冲突。<br></p><p>另外，如果真的产生冲突了，同步组件应该将冲突的记录保存下来，以便之后的问题排查。</p><p>2.4 对于DDL语句如何处理</p><p>如果数据库表中已经有大量数据，例如千万级别、或者上亿，这个时候对于这个表的DDL变更，将会变得非常慢，可能会需要几分钟甚至更长时间，而DDL操作是会锁表的，这必然会对业务造成极大的影响。</p><p>因此，同步组件通常会对DDL语句进行过滤，不进行同步。DBA在不同的数据库集群上，通过一些在线DDL工具(如gh-ost)，进行表结构变更。</p><p>2.5 如何解决数据回环问题</p><p>数据回环问题，是数据同步过程中，最重要的问题。我们针对INSERT、UPDATE、DELETE三个操作来分别进行说明：</p><p><strong>INSERT操作</strong></p><p>假设在A库插入数据，A库产生binlog，之后同步到B库，B库同样也会产生binlog。由于是双向同步，这条记录，又会被重新同步回A库。由于A库应存在这条记录了，产生冲突。</p><p><strong>UPDATE操作</strong></p><p>先考虑针对A库某条记录R只有一次更新的情况，将R更新成R1，之后R1这个binlog会被同步到B库，B库又将R1同步会A库。对于这种情况下，A库将不会产生binlog。因为A库记录当前是R1，B库同步回来的还是R1，意味着值没有变。</p><p>在一个更新操作并没有改变某条记录值的情况下，mysql是不会产生binlog，相当于同步终止。下图演示了当更新的值没有变时，mysql实际上不会做任何操作：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fd588174f05d49678cdccd72e8dae7e0><p class=pgc-img-caption></p></div><p>上图演示了，数据中原本有一条记录(1,"tianshouzhi”)，之后执行一个update语句，将id=1的记录的name值再次更新为”tianshouzhi”，意味着值并没有变更。这个时候，我们看到mysql 返回的影响的记录函数为0，也就是说，并不会产生真是的更新操作。</p><p>然而，这并不意味UPDATE 操作没有问题，事实上，其比INSERT更加危险。考虑A库的记录R被连续更新了2次，第一次更新成R1，第二次被更新成R2；这两条记录变更信息都被同步到B库，B也产生了R1和R2。由于B的数据也在往A同步，B的R1会被先同步到A，而A现在的值是R2，由于值不一样，将会被更新成R1，并产生新的binlog；此时B的R2再同步会A，发现A的值是R1，又更新成R2，也产生binlog。由于B同步回A的操作，让A又产生了新的binlog，A又要同步到B，如此反复，陷入无限循环中。</p><p><strong>DELETE操作</strong></p><p>同样存在先后顺序问题。例如先插入一条记录，再删除。B在A删除后，又将插入的数据同步回A，接着再将A的删除操作也同步回A，每次都会产生binlog，陷入无限回环。</p><p>关于数据回环问题，笔者有着血的教训，曾经因为笔者的误操作，将一个库的数据同步到了自身，最终也导致无限循环，原因分析与上述提到的UPDATE、DELETE操作类似，读者可自行思考。</p><p>针对上述数据同步到过程中可能会存在的数据回环问题，最终会导致数据无限循环，因此我们必须要解决这个问题。由于存在多种解决方案，我们将在稍后统一进行讲解。</p><p><strong>2.6 数据同步架构设计</strong></p><p>现在，让我们先把思路先从解决数据同步的具体细节问题转回来，从更高的层面讲解数据同步的架构应该如何设计。稍后的内容中，我们将讲解各种避免数据回环的各种解决方案。</p><p>前面的架构中，只涉及到2个DB的数据同步，如果有多个DB数据需要相互同步的情况下，架构将会变得非常复杂。例如：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/61e86d273d894307b0ed4897d65e093a><p class=pgc-img-caption></p></div><p>这个图演示的是四个DB之间数据需要相互同步，这种拓扑结构非常复杂。为了解决这种问题，我们可以将数据写入到一个数据中转站，例如MQ中进行保存，如下：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f39d16586fa446ea853f5b83788bae45><p class=pgc-img-caption></p></div><p>我们在不同的机房各部署一套MQ集群，这个机房的binlog syncer将需要同步的DB binlog数据写入MQ对应的Topic中。对端机房如果需要同步这个数据，只需要通过binlog writer订阅这个topic，消费topic中的binlog数据，插入到目标库中即可。一些MQ支持consumer group的概念，不同的consumer group的消费位置offset相互隔离，从而达到一份数据，同时供多个消费者进行订阅的能力。</p><p>当然，一些binlog订阅解析组件，可能实现了类似于MQ的功能，此时，则不需要独立部署MQ。</p><p>那么MQ应该选择什么呢？别问，问就是Kafka，具体原因问厮大。</p><p><br></p><p><strong>3 数据据回环问题解决方案</strong></p><p>数据回环问题有多种解决方案，通过排除法，一一进行讲解。</p><p><strong>3.1 同步操作不生成binlog</strong></p><p>在mysql中，我们可以设置session变量，来控制当前会话上的更新操作，不产生binlog。这样当往目标库插入数据时，由于不产生binlog，也就不会被同步会源库了。为了演示这个效果，笔者清空了本机上的所有binlog(执行reset master)，现在如下图所示：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7a0e52272c7b49c9bbd7b431abeeee4f><p class=pgc-img-caption></p></div><p>忽略这两个binlog event，binlog文件格式最开始就是这两个event。</p><p>接着，笔者执行set sql_log_bin=0，然后插入一条语句，最后可以看到的确没有产生新的binlog事件：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1d64fe1984104ff1a26713c23fbbde50><p class=pgc-img-caption></p></div><p>通过这种方式，貌似可以解决数据回环问题。目标库不产生binlog，就不会被同步会源库。但是，答案是否定的。我们是往目标库的master插入数据，如果不产生binlog，目标库的slave也无法同步数据，主从数据不一致。所以，需要排除这种方案。</p><p>提示：如果恢复set sql_log_bin=1，插入语句是会产生binlog，读者可以自行模拟。</p><p><strong>3.2 控制binlog同步方向</strong></p><p>既然不产生binlog不能解决问题。那么换一种思路，可以产生binlog。当把一个binlog转换成sql时，插入某个库之前，我们先判断这条记录是不是原本就是这个库产生的，如果是，那么就抛弃，也可以避免回环问题。</p><p>现在问题就变为，如何给binlog加个标记，表示其实那个mysql集群产生的。这也有几种方案，下面一一讲述。</p><p><strong>3.2.1 ROW模式下的SQL</strong></p><p>mysql主从同步，binlog复制一般有3种模式。STATEMENT，ROW，MIXED。默认情况下，STATEMENT模式只记录SQL语句，ROW模式只记录字段变更前后的值，MIXED模式是二者混合。binlog同步一般使用的都是ROW模式，高版本Mysql主从同步默认也是ROW模式。</p><p>我们想采取的方案是，在执行的SQL之前加上一段特殊标记，表示这个SQL的来源。例如</p><pre>/*IDC1:DB1*/insert into users(name) values("tianbowen")</pre><p>其中/*IDC1:DB1*/是一个注释，表示这个SQL原始在是IDC1的DB1中产生的。之后，在同步的时候，解析出SQL中的IDC信息，就能判断出是不是自己产生的数据。</p><p>然而，ROW模式下，默认只记录变更前后的值，不记录SQL。所以，我们要通过一个开关，让Mysql在ROW模式下也记录INSERT、UPDATE、DELETE的SQL语句。具体做法是，在mysql的配置文件中，添加以下配置：</p><pre>binlog_rows_query_log_events =1</pre><p>这个配置可以让mysql在binlog中产生ROWS_QUERY_LOG_EVENT类型的binlog事件，其记录的就是执行的SQL。</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3d8219993a88478faeebe5ccb0eb1b67><p class=pgc-img-caption></p></div><p>通过这种方式，我们就记录下的一个binlog最初是由哪一个集群产生的，之后在同步的时候，sql writer判断目标机房和当前binlog中包含的机房相同，则抛弃这条数据，从而避免回环。</p><p>这种思路，功能上没问题，但是在实践中，确非常麻烦。首先，让业务对执行的每条sql都加上一个这样的标识，几乎不可能。另外，如果忘记加了，就不知道数据的来源了。如果采用这种方案，可以考虑在数据库访问层中间件层面添加支持在sql之前增加/*..*/的功能，统一对业务屏蔽。即使这样，也不完美，不能保证所有的sql都通过中间件来来写入，例如DBA的一些日常运维操作，或者手工通过mysql命令行来操作数据库时，肯定会存在没有添加机房信息的情况。</p><p>总的来说，这个方案不是那么完美。<br></p><p>3.2.2 通过附加表</p><p>这种方案目前很多知名互联网公司在使用。大致思路是，在db中都加一张额外的表，例如叫direction，记录一个binlog产生的源集群的信息。例如</p><pre>CREATE TABLE `direction` ( `idc` varchar(255) not null, `db_cluster` varchar(255) not null,) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4</pre><p>idc字段用于记录某条记录原始产生的IDC，db_cluster用于记录原始产生的数据库集群(注意这里要使用集群的名称，不能是server_id，因为可能会发生主从切换)。<br></p><p>假设用户在IDC1的库A插入的一条记录(也可以在事务中插入多条记录，单条记录，即使不开启事务，mysql默认也会开启事务)：</p><pre>BEGIN;insert into users(name) values("tianshouzhi”);COMMIT;</pre><p>那么A库数据binlog通过sql writer同步到目标库B时，sql writer可以提前对事务中的信息可以进行一些修改，，如下所示：</p><pre>BEGIN;#往目标库同步时，首先额外插入一条记录，表示这个事务中的数据都是A产生的。insert into direction(idc,db_cluster) values("IDC1”,"DB_A”)#插入原来的记录信息insert into users(name) values("tianshouzhi”);COMMIT;</pre><p>之后B库的数据往A同步时，就可以根据binlog中的第一条记录的信息，判断这个记录原本就是A产生的，进行抛弃，通过这种方式来避免回环。这种方案已经已经过很多的公司的实际验证。<br></p><p>3.2.3 通过GTID</p><p>Mysql 5.6引入了GTID(全局事务id)的概念，极大的简化的DBA的运维。在数据同步的场景下，GTID依然也可以发挥极大的威力。</p><p>GTID 由2个部分组成：</p><pre>server_uuid:transaction_id</pre><p>其中server_uuid是mysql随机生成的，全局唯一。transaction_id事务id，默认情况下每次插入一个事务，transaction_id自增1。注意，这里并不会对GTID进行全面的介绍，仅说明其在数据同步的场景下，如何避免回环、数据重复插入的问题。</p><p>GTID提供了一个会话级变量gtid_next，指示如何产生下一个GTID。可能的取值如下:</p><ul class=list-paddingleft-2><li>AUTOMATIC: 自动生成下一个GTID，实现上是分配一个当前实例上尚未执行过的序号最小的GTID。</li><li>ANONYMOUS: 设置后执行事务不会产生GTID，显式指定的GTID。<br></li></ul><p>默认情况下，是AUTOMATIC，也就是自动生成的，例如我们执行sql：</p><pre>insert into users(name) values("tianbowen”); 产生的binlog信息如下：20BBA7C4-FAB0-4C2A-B1BB-D84ABFC5DB39可以看到，GTID会在每个事务(Query-&gt;...-&gt;Xid)之前，设置这个事务下一次要使用到的GTID。从源库订阅binlog的时候，由于这个GTID也可以被解析到，之后在往目标库同步数据的时候，我们可以显示的的指定这个GTID，不让目标自动生成。也就是说，往目标库，同步数据时，变成了2条SQL：</pre><p>产生的binlog信息如下：</p><div class=pgc-img><img alt=异地多活场景下，如何进行数据同步？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/eedcde4df9cc42558ff1d00cee3756cb><p class=pgc-img-caption></p></div><p>可以看到，GTID会在每个事务(Query->...->Xid)之前，设置这个事务下一次要使用到的GTID。</p><p>从源库订阅binlog的时候，由于这个GTID也可以被解析到，之后在往目标库同步数据的时候，我们可以显示的的指定这个GTID，不让目标自动生成。也就是说，往目标库，同步数据时，变成了2条SQL：</p><pre>SET GTID_NEXT= '09530823-4f7d-11e9-b569-00163e121964:1’insert into users(name) values("tianbowen")</pre><p>由于我们显示指定了GTID，目标库就会使用这个GTID当做当前事务ID，不会自动生成。同样，这个操作也会在目标库产生binlog信息，需要同步回源库。再往源库同步时，我们按照相同的方式，先设置GTID，在执行解析binlog后得到的SQL，还是上面的内容</p><pre>SET GTID_NEXT= '09530823-4f7d-11e9-b569-00163e121964:1'insert into users(name) values("tianbowen")</pre><p><strong>由于这个GTID在源库中已经存在了，插入记录将会被忽略，演示如下：</strong></p><pre>mysql&gt; SET GTID_NEXT= '09530823-4f7d-11e9-b569-00163e121964:1';Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into users(name) values("tianbowen");Query OK, 0 rows affected (0.01 sec) #注意这里，影响的记录行数为0</pre><p>注意这里，对于一条insert语句，其影响的记录函数居然为0，也就会插入并没有产生记录，也就不会产生binlog，避免了循环问题。</p><p>如何做到的呢？mysql会记录自己执行过的所有GTID，当判断一个GTID已经执行过，就会忽略。通过如下sql查看：</p><pre>mysql&gt; show global variables like "gtid_executed";+---------------+------------------------------------------+| Variable_name | Value |+---------------+------------------------------------------+| gtid_executed | 09530823-4f7d-11e9-b569-00163e121964:1-5 |+---------------+------------------------------------------+</pre><p>上述value部分，冒号":"前面的是server_uuid，冒号后面的1-5，是一个范围，表示已经执行过1，2，3，4，5这个几个transaction_id。这里就能解释了，在GTID模式的情况下，为什么前面的插入语句影响的记录函数为0了。</p><p>显然，GTID除了可以帮助我们避免数据回环问题，还可以帮助我们解决数据重复插入的问题，对于一条没有主键或者唯一索引的记录，即使重复插入也没有，只要GTID已经执行过，之后的重复插入都会忽略。</p><p>当然，我们还可以做得更加细致，不需要每次都往目标库设置GTID_NEXT，这毕竟是一次网络通信。sql writer在往目标库插入数据之前，先判断目标库的server_uuid是不是和当前binlog事务信息携带的server_uuid相同，如果相同，则可以直接丢弃。查看目标库的gtid，可以通过以下sql执行：</p><pre>mysql&gt; show variables like "server_uuid";+---------------+--------------------------------------+| Variable_name | Value |+---------------+--------------------------------------+| server_uuid | 09530823-4f7d-11e9-b569-00163e121964 |+---------------+--------------------------------------+</pre><p>GTID应该算是一个终极的数据回环解决方案，mysql原生自带，比添加一个辅助表的方式更轻量，开销也更低。需要注意的是，这倒并不是一定说GTID的方案就比辅助表好，因为辅助表可以添加机房等额外信息。在一些场景下，如果下游需要知道这条记录原始产生的机房，还是需要使用辅助表。</p><p><strong>4 开源组件介绍canal/otter</strong></p><p>前面深入讲解了单元化场景下数据同步的基础知识。读者可能比较感兴趣的是，哪些开源组件在这些方面做的比较好。笔者建议的首选，是canal/otter组合。</p><p>canal的作用就是类似于前面所述的binlog syncer，拉取解析binlog。otter是canal的客户端，专门用于进行数据同步，类似于前文所讲解的sql writer。并且，canal的最新版本已经实现了GTID。</p><p><br></p><blockquote><p>我目前是在职Java开发，如果你现在正在了解Java技术，想要学好Java，渴望成为一名Java开发工程师，在入门学习Java的过程当中缺乏基础的入门视频教程，你可以关注并私信我：01。我这里有一套最新的Java基础JavaSE的精讲视频教程，这套视频教程是我在年初的时候，根据市场技术栈需求录制的，非常的系统完整。</p></blockquote></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'异地','活场','景下'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>