<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>超全的最新的人脸识别特征点定位方法 | 极客快訊</title><meta property="og:title" content="超全的最新的人脸识别特征点定位方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/3c790001f19132c60dbf"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3bf9405f.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3bf9405f.html><meta property="article:published_time" content="2020-11-14T21:03:55+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:55+08:00"><meta name=Keywords content><meta name=description content="超全的最新的人脸识别特征点定位方法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/3bf9405f.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>超全的最新的人脸识别特征点定位方法</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>1.2 人脸特征点定位方法综述</h1><p>目前为止，国内外学者们已经提出了人脸特征点定位的方法[3]，依据定位所需要的基本信息的类型，人脸特征点定位的方法可以大致分为以下六类：(1)灰度信息的方法；(2)先验规则的方法；(3)几何形状的方法；(4)统计模型的方法；(5)小波的方法；(6)3D 方法。</p><p><img alt=超全的最新的人脸识别特征点定位方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/3c790001f19132c60dbf></p><h1>1.2.1 基于灰度信息的方法</h1><p>几何投影法：几何投影方法是利用人脸特征灰度与其他部分的差异，先统计出不同方向上的灰度值和，根据和的变化找出特定的变化点，然后利用投影灰度值基于统计的方法将不同方向上的变化点位置相结合，找到人脸特征点的位置。投影的方法计算量较低，但当姿态变化较大或者背景较复杂时容易失效。</p><p>谷分析：图像中亮度比周围像点暗的区域就称作谷，通过亮度比较的方法，就可以对人脸的各个关键部位如眼睛、眉毛、鼻子、嘴巴等相对较暗的区域进行定位。虽然其受光照影响比较大，但考虑到计算量低的优势也在定位方法中常见。</p><h1>1.2.1先验规则的方法</h1><p><img alt=超全的最新的人脸识别特征点定位方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/3c790001f21d31289cfd></p><p>根据人脸特征的一般特点总结出一些经验规则就称作基于先验规则的方法。人脸图像有一些明显的基本特征，比如人脸的长度比例，满足&amp;ldquo;三庭五眼&amp;rdquo;，脸部区域的双眼、鼻子和嘴巴等脸部特征处的亮度一般低于其周边区域；两眼间的对称以及眼睛与鼻子的三角分布规律，都是人脸识别的重要根据。此方法虽然简单，但是远远不能满足复杂的人脸结构的正确定位，于是该方法一般只用于粗定位，精定位还要结合其他的方法来实现。</p><p>镶嵌图法：我们可以用一组相同大小的方格去划分图像，每个方格的灰度取格中各像素灰度的均值，根据一定的规则确定哪些可能是人脸的方格区域，将确定的可能存在人脸的方格的变长减半，重新构建镶嵌图，重复第一步的工作，找到眼睛，鼻子，嘴巴等脸部特征所在的位置，然后对这两次得到的脸部区域二值化，利用边缘检测最终精确定位各个特征的位置。</p><p>二值化定位：得到图像的直方图，选择合适的阀值将图像二值化，二值化后区域的相对位置和面积形状等几何信息就可以用来确定瞳孔的位置，再通过眼睛与其他特征点的位置关系和几何关系等对其他的人脸特征点进行定位。显然该方法受光照和图像质量等的影响较大。</p><p>广义对称法：显然，在人脸图像中，眼睛眼、眉毛、鼻子等都具有较强的点对称性。为我们通过定义广义对称变换来描述点对称性，通过考察人眼中心点的强对称性和脸部特征的几何分布来对人脸的特征点进行定位，该方法仅仅利用了各点的对称性，计算量很大，而且也会因为光照表情等影响产生大量的候选点，大大影响到定位精度。</p><h1>1.2.3 基于几何形状的方法</h1><p><img alt=超全的最新的人脸识别特征点定位方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/3c780004443a0599502a></p><p>Shake 算法：该方法利用一条由几个控制点组成的闭合曲线，再利用一个进行匹配的能量函数来作为评价标准，当不断迭代最后使得能量函数最小化时就定位到人脸特征点。Snake是主动的，总是最小化能量函数，因此表现出一种动态特性。但是由于人脸的多样性和复杂性以及图像中的噪声等复杂因素的影响，在使用刚性模型分割人脸轮廓时遇到了很大的困难。另外，Snake模型也没有利用关于对象的知识，所以过于灵活，很难做到精确的特征点提取。</p><p>可变形模板方法：把眼睛特征为有两条抛物线（上下眼睑）和一个圆（虹膜）构成的几何图形，通过优化的方法来调整其参数以达到最佳的匹配，嘴巴、下巴等也可以采用类似的几何图形建模。但是，固定的几何图形并不能很好地建模实际上会千差万别的眼睛形状，而光照、姿态和表情的变化更使得采用这种固定的简单数学模型难以适应这些复杂的变化，因此很难实现鲁棒的特征提取。优化速度慢、容易陷入局部极小也阻止了该算法的进一步发展。</p><p>基于点分布模型算法:ASM和AAM都是基于点分布模型（Point Distribution Model，PDM）的算法在PDM中，外形相似的特定类别物体，比如人脸、人手的形状通过若干关键的特征点的座标串接成原始形状向量。对训练集中的所有形状向量进行对齐操作后，对它们进行PCA分析建模，保留的主成分形成最终的形状模型，形状模型的参数反映了形状的主要可变化模式，ASM搜索则首先通过局部纹理模型匹配得到各个特征点的更佳的位置，经过相似变换对齐后，通过统计形状模型对其进行约束，而后再进行局部纹理模型的匹配，形成一个迭代过程，以期形状模型最终匹配到输入的形状模式上去。在ASM中，仅使用了特证点局部纹理特证作为启发式信息，没有使用全局的纹理约束，实践中发现ASM很容易陷入局部极小。</p><p>而在AAM中，则采用了形状和纹理二者融合的统计约束，即所谓的统计表观模型。AAM搜索借鉴了基于合成的分析技术的思想，通过模型参数的优化调整使得模型能够不断逼近实际输入模式，模型参数的更新则放弃了ASM中的局部纹理搜索过程，仅使用一个线性预测模型根据当前模型和输入模式之间的差别来预测和更新模型参数。AAM尽管利用了全局纹理，但却抛弃了局部纹理匹配过程，因此会在一定程度上降低关键特证点配准的精度，而且其线性预测模型也有较大的局限性，在初始位置偏离目标位置过大时，则很难收敛到正确位置。</p><h1>1.2.4 基于统计模型的方法</h1><p><img alt=超全的最新的人脸识别特征点定位方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/3c790001f38ee92ab3a3></p><p>肤色唇色分割法:该方法是使用统计方法建立起人脸特征的色彩模型，定位时遍历候选区域，根据被测点的色彩与模型的匹配度筛选出候选的人脸特征点。该方法主要是对人脸面部特征的色彩信息进行研究，构造人脸特征的色彩模型，利用人脸肤色的色彩信息进行特征点定位。基于色彩信息实现简单，但容易受环境的影响，定位的可靠性不高。</p><p>特征脸法:该方法利用K-L变换将表征人脸的高维向量映射到由若干个特征向量（也称Eigenface特征脸）张成的子空间中，先用主成分分析模型重构被检区域，求出重构图与原图之间的距离，当距离小于一定阈值时，即被认定为候选区域。该方法的缺点是针对不同脸型要分别建模，搜索时采用金字塔策略，算法复杂度高。另外，主成分分析着重优化和解析图像，而没有着重于特征点的定位。</p><p>支持向量机:支持向量机（Support Vector Machines，SVM）是Vapnik等提出的基于风险最小化原理的统计学习理论，用于分类与回归问题。将SVM 方法用于脸部特征检测，使用了方形扫描窗口，将眉毛与眼睛作为一个整体作为定位的对象，从而减少了眉毛对定位的干扰。Jefrey Huang则采用该方法来检测眼睛。但是由于训练需要求解计算复杂度极高的二次规划问题，内存需求量大，其次是训练样本个数较大时，会得到大量的支持向量，使分类器计算量过高。</p><p>模板匹配法:模板匹配法是较早用于面部特征点定位的方法之一，也是使用范围较广的一种。这是由于模板匹配法具有比较直观、易于构造等优点。在对图像进行预处理的基础上产生特征的候选区域，之后通过一个具有几何约束（五官模板的相关量）的模板对特征加以定位。Sako等人采用彩色直方图方法分割脸部区域和嘴唇区域，并根据眼睛的结构和灰度信息特点预先构造了眼睛模板，利用此模板进行搜索以确定眼睛的位置匹配的过程是利用事先建立的面部特征的模板在候选窗口逐点滑动进行特征匹配定位。模板匹配需要考虑面部特征的尺寸缩放、方向旋转等变化，所以计算量很大，并且由于光照的不均匀变化往往引起模板匹配的失败，所以基于模板匹配的人脸检测方法较适合于人脸尺寸、方向、光照等有一定的约束条件或者先前已确定的情况。该方法虽然速度较慢，但正确率较高。</p><p>人工神经网络:人工神经网络（ANN）在模式识别中有着广泛的应用，特别适合研究非线性问题。完整的人脸图像受个体差异、眼睛状态和目标对象姿态等变化的影响较大，而子特征点（包括左右眼角和上下眼眶顶点）附近区域相对稳定，根据这一特点，Waite 等以各子特征点附近的灰度图像为输入，分别建立神经网络。检测时，先用各个神经网络对目标区域进行遍历搜索，再结合先验知识对搜索结果进行筛选和结合。这个算法训练过程比较简单，有较强的鲁棒性。但缺点是区分度不足。</p><p>贝叶斯概率网络方法:Kin 和 Cipolla 使用一个 3 层的概率网络来对脸型建模，其网络结构如图1。他们在搜索中采用了自底向上的搜索策略，结合使用高斯滤波器和边缘检测算法找出双眉、鼻和嘴的候选点（对应于网络中的第1层），据邻近候选点之间的相对关系两两配对为水平或垂直组合（对应于网络中的第2层），并进一步归入脸部的上、下、左、右 4 个区域（对应于网络中的第3层），从而筛去虚警点。</p><h1>1.2.5 基于小波的方法</h1><p>弹性图匹配法:该方法是面部关键特证定位的另一个重要算法，该方法将人脸面部关键特证点的属性及其他们之间的位置关系通过一个属性图进行描述，图的顶点对关键特征点的局部纹理建模（通过Gabor特征），图的边则反映了特征点之间的距离等位置关系。对新输入的图像，其特征点则通过基于相位预测的位移估计结合图匹配技术来定位。通过属性图的形变，一方面匹配顶点处的Gabor局部特征，另一方面匹配全局几何结构特征。尽管弹性图匹配可以达到较高的定位精度，但速度较慢。</p><p>DWN（Gabor小波网络）:Kr&amp;uuml;ger等将Gabor小波引入图像处理领域，使用一组同源派生的Gabor小波函数取代RBF神经网络的基函数，通过训练，可以将目标图像分解为若干个小波函数的线性组合。GWN 的训练中同时对相关权值和小波函数本身的参数作优化，这使得GWN模型可以用很小数量的小波函数实现对目标对象的解析和重构。Feris使用两层的GWN树模型来定位脸部特征，两层GWN分别用于表征全脸和各个脸部特征。在训练中，他们为每幅训练图建立一个GWN树模型，并标定出各脸部特征的位置，存入人脸库中。实际搜索的时候，他们首先通过全脸比对从库中找出与目标图像最接近的一个模型，然后以该模型的标定位置为搜索起点，在小范围内，通过与该模型中相应的脸部特征信息的比对求出脸部特征的精确位置。</p><h1>1.2.6 3D方法</h1><p>光流向量化技术:光流指的是灰度值图案在整个图像范围内的运动。首先，在每个点对各自的灰度值计算位移向量；然后计算一个连续的向量场，该向量场能充分地再现光流。两个步骤的执行都需要某些限制性假设，而结果也做不到完全无误差。然而，可以获得重要的时域信息，无论是由有利位置产生的连续变化，还是单个物体的不连续变化。因为变化的连续与否并不重要。无论怎样都应该清楚，孤立地考虑单幅图像是没有意义的。检测对象必须是至少包括两幅连续图像的图像序列。</p><p>采用光流迭代的方法建立输入人脸与参考人脸之间的稠密的像素级对应关系；Beymer等人提出的基于光流的向量化技术，是计算不同人脸图像之间的密集对应的一个典型算法。在此方法中，2D的形状由测试图像和参考图像之间的光流域来描述。由于此算法很大精度的限制，因此在实际应用中很难精确求解。也存在计算复杂、计算速度慢的问题。</p><p>3D形变模型:迄今为止，最成功的姿态和光照不变的人脸识别是3D变形模型方法。该方法通过主成分分析对人脸的3D形状和纹理分别进行统计建模。在此基础上建立了包含形状、纹理统计参数、Phone模型参数、光照参数、摄像机内外参数、绘制参数等在内的复杂成像模型，最终采用基于合成的分析技术通过优化算法估计这些参数，得到输入人脸的3D形状和纹理统计参数用于最终的分类识别。遗憾的是，该方法需要求解一个涉及几百个参数的复杂连续优化问题，迭代优化过程耗费了大量的计算时间，对3D形状、纹理、成像参数等形成的形变模型参数进行优化，使得合成的模型图像最佳匹配输入图像，从而得到人脸3D形状和纹理.</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'超全','脸识别','特征点'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>