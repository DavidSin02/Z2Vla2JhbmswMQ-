<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>必读 | ICLR 2020大会最佳深度学习论文 | 极客快訊</title><meta property="og:title" content="必读 | ICLR 2020大会最佳深度学习论文 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/23b6cc0be3e34a158e87dda097dbff16"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c250658.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c250658.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c250658.html><meta property="article:published_time" content="2020-11-14T20:59:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:59:54+08:00"><meta name=Keywords content><meta name=description content="必读 | ICLR 2020大会最佳深度学习论文"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/3c250658.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>必读 | ICLR 2020大会最佳深度学习论文</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>一年一度的ICLR刚刚结束，本届共有2594篇投稿，687 篇被接收。其中：48篇 oral 108篇，spotlights 531篇， poster 录取率为 26.5%，相比去年的 31.4% 略有降低。</p><p><br></p><p>值得关注的是，受疫情影响，今年的ICLR大会转到了线上举行，成为了首个完全线上举行的人工智能领域顶会，并且参会人数暴增了一倍。</p><p><br></p><p>深度学习一直是ICLR投稿的热点，近日，国外一研究者精选了10篇深度学习领域的论文，供大家研读：</p><p><br></p><p>1. On Robustness of Neural Ordinary Differential Equations</p><p><br></p><p>简而言之，是对神经常微分方程或NeuralODE的鲁棒性的深入研究。将其用作构建更强大网络的基础。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=B1e9Y2NYvS</p><p><br></p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/23b6cc0be3e34a158e87dda097dbff16><p class=pgc-img-caption></p></div><p>ODENet的体系结构，神经ODE块用作保维非线性映射。</p><p><br></p><p>2.Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</p><p><br></p><p>可证明的是，对于非平滑的非凸函数，渐变修剪可加速梯度下降。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=BJgnXpVYwS</p><p><br></p><p>代码：</p><p>https://github.com/JingzhaoZhang/why-clipping-accelerates</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f0bdfb6b3b3b40bd8eb44ced75fb7b2c><p class=pgc-img-caption></p></div><p>沿PTB数据集上AWD-LSTM的训练轨迹的对数刻度上的梯度范数与局部梯度Lipschitz常数。颜色条指示训练期间的迭代次数。</p><p><br></p><p>3.Target-Embedding Autoencoders for Supervised Representation Learning</p><p><br></p><p>目标嵌入自动编码器或TEA的新通用框架，用于监督预测。作者给出了理论和经验上的考虑。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=BygXFkSYDH</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a3754cef2e6542dab5fab4d42eb4576a><p class=pgc-img-caption></p></div><p>（a）特征嵌入和（b）目标嵌入自动编码器。实线对应于（主要）预测任务；（辅助）重建任务的虚线。共享的组件都参与其中。</p><p><br></p><p>4.Understanding and Robustifying Differentiable Architecture Search</p><p><br></p><p>通过查看架构的验证损失的Hessian特征值来研究DARTS（可区分架构搜索）的失败模式，并在分析的基础上提出稳健性。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=H1gDNyrKDS</p><p><br></p><p>代码：</p><p>https://github.com/automl/RobustDARTS</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/033d906ff7064025b91055739999aadd><p class=pgc-img-caption></p></div><p>标准DARTS的不良细胞在空间S1-S4上找到。对于所有空间，DARTS大多选择无参数操作（跳过连接），甚至选择有害的Noise操作。图中显示的是CIFAR-10上的正常细胞。</p><p><br></p><p>5.Comparing Rewinding and Fine-tuning in Neural Network Pruning</p><p><br></p><p>除了在修剪后进行微调外，还可以在训练中更早地将权重或学习率调度到它们的值，然后从那里进行再训练，以在修剪神经网络时获得更高的准确性。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=S1gSj0NKvB</p><p><br></p><p>代码：</p><p>https://github.com/lottery-ticket/rewinding-iclr20-public</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e5fa227fd5ff493994a5c606faeea8a5><p class=pgc-img-caption></p></div><p>通过一次修剪即可在再训练时间内实现最佳的精度。</p><p><br></p><p>6.Neural Arithmetic Units</p><p><br></p><p>神经网络虽然能够逼近复杂函数，但是在精确的算术运算中却很差。对于深度学习研究人员而言，这项任务是一项长期的挑战。在这里，介绍了新颖的神经加法单元（NAU）和神经乘法单元（NMU），它们能够执行精确的加法/减法（NAU）并乘以向量的子集（MNU）。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=H1gNOeHKPS</p><p><br></p><p>代码：</p><p>https://github.com/AndreasMadsen/stable-nalu</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0cf895c2281f4a73bd82a2e938df73f2><p class=pgc-img-caption></p></div><p>NMU的可视化，其中权重（W i，j）控制1（同一性）或x i之间的门控，然后将每个中间结果显式相乘以形成z j。</p><p><br></p><p>7.The Break-Even Point on Optimization Trajectories of Deep Neural Networks</p><p><br></p><p>在深度神经网络训练的早期阶段，存在一个“收支平衡点”，它确定了整个优化轨迹的属性。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=r1g87C4KwB</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b97be0c9478f4d68b1dd97f8295d1441><p class=pgc-img-caption></p></div><p>使用CGD优化的简单CNN模型在CIFAR-10上训练轨迹的早期部分（在达到65％的训练准确度之前）的可视化，学习率η= 0.01（红色）和η= 0.001（蓝色）。训练轨迹上的每个模型（显示为一个点）由使用UMAP嵌入到二维空间中的测试预测表示。背景颜色表示梯度K的协方差的光谱范数（λ 1 ķ，左）和训练精度（右）。对于较低η，达到我们所说的盈亏平衡点后，轨迹向着特点是较大的λ区域转向1 ķ对于相同的训练精度。</p><p><br></p><p>8. Hoppity: Learning Graph Transformations To Detect And Fix Bugs In Programs</p><p><br></p><p>一种基于学习的方法，用于检测和修复Javascript中的错误。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=SJeqs6EFvB</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d1bcc1ac96a44a329d1c92675429a3f5><p class=pgc-img-caption></p></div><p>示例程序说明了现有方法的局限性，包括基于规则的静态分析器和基于神经的错误预测器。</p><p><br></p><p>9.Selection via Proxy: Efficient Data Selection for Deep Learning</p><p><br></p><p>通过使用更小的代理模型执行数据选择，可以显著提高深度学习中数据选择的计算效率。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=HJg2b0VYDr</p><p><br></p><p>代码：</p><p>https://github.com/stanford-futuredata/selection-via-proxy</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3de8212f5ca843d09c4e245784cd0720><p class=pgc-img-caption></p></div><p>SVP应用于主动学习（左）和核心集选择（右）。在主动学习中，遵循与传统方法相同的训练和选择标记点的迭代过程，但是将目标模型替换为便宜的计算代理模型。对于核心集选择，使用代理模型学习了数据的特征表示，并使用它来选择点以训练更大，更准确的模型。在这两种情况下，发现代理模型和目标模型具有较高的等级相关性，从而导致相似的选择和下游结果。</p><p><br></p><p>10.And the Bit Goes Down: Revisiting the Quantization of Neural Networks</p><p><br></p><p>使用旨在更好地进行域内重构的结构化量化技术来压缩卷积神经网络。</p><p><br></p><p>论文：</p><p>https://openreview.net/forum?id=rJehVyrKwH</p><p><br></p><p>代码：</p><p>https://drive.google.com/file/d/12QK7onizf2ArpEBK706ly8bNfiM9cPzp/view?usp=sharing</p><div class=pgc-img><img alt="必读 | ICLR 2020大会最佳深度学习论文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3ad1b30cb79b40e3bf3ceba885d12f1e><p class=pgc-img-caption></p></div><p>我们的方法的说明。我们近似一个二元分类器ϕ，通过量化其权重将图像标记为狗或猫。标准方法：使用标准目标函数（1）量化s会产生分类器ϕb standard，该standard试图在整个输入空间上近似ϕ，因此对于域内输入可能表现不佳。我们的方法：用目标函数（2）量化s可以促进分类器ϕb activations，该activations对于域内输入表现良好。位于输入空间的阴影区域的图像被正确地分类φ activations但是φ standard的结果错误。</p><p><br></p><p>原文链接：</p><p>https://neptune.ai/blog/iclr-2020-deep-learning</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'必读','ICLR','2020'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>