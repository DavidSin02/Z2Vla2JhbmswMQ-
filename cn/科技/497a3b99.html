<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>如何通过向量化78倍速加快您的机器学习算法 | 极客快訊</title><meta property="og:title" content="如何通过向量化78倍速加快您的机器学习算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/93c0d0abac9c43bf9b93270e56632f53"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/497a3b99.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/497a3b99.html><meta property="article:published_time" content="2020-10-29T21:09:42+08:00"><meta property="article:modified_time" content="2020-10-29T21:09:42+08:00"><meta name=Keywords content><meta name=description content="如何通过向量化78倍速加快您的机器学习算法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/497a3b99.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>如何通过向量化78倍速加快您的机器学习算法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/93c0d0abac9c43bf9b93270e56632f53><p class=pgc-img-caption></p></div><p>给定一个方程式，我们将逐步了解如何才能不仅在速度上获得x78倍的效率更高的代码，而且仅使用3行代码！ 让我们开始吧……</p><h1 class=pgc-h-arrow-right>介绍</h1><p>作为一种解释型语言，Python for loop本质上比C语言慢。 这对于编程语言是一个很大的瓶颈，因为深度学习和机器学习算法严重依赖于矩阵运算，而矩阵运算是通过for循环执行的。</p><p>这就是开发人员开发软件包的原因，例如numpy，他们在numpy数组上提供矢量化操作。 这意味着它将通常在Python中完成的for循环下推到C级，这要快得多。</p><p>Python + C级速度=天堂</p><h1 class=pgc-h-arrow-right>问题</h1><p>（如果您对EM算法有疑问，可以跳过解释部分）</p><p>我们想对无监督学习任务使用期望最大化（EM）算法（例如，在MNIST数据集中识别手写数字），并且我们的数据是二进制的（例如二进制图像）。 一种自然的方法是将我们的数据建模为伯努利混合模型。 伯努利分布的加权和，每个分布都有自己的标量权重π和自己的均值向量μ并表示数据的群集（例如，如果我们的数据是数字2、3和4的图像，并且我们使用3伯努利进行建模 它们中，一个伯努利将是数字2，另一个是数字4，依此类推）。 总的来说，这使得前者成为向量，而后者成为矩阵。</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0250d4e675b349c4b5e9602f3aa6f4f3><p class=pgc-img-caption>Bernoulli mixture model (1)</p></div><p><br></p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/84c426282f814aa7a4305e2d029c9bcd><p class=pgc-img-caption>Distribution of one observation x given the cluster k (2)</p></div><p>令N =观测数，D =一个观测的维数，K =聚类数。 因为对于我们的问题很重要，所以我们拥有的随机变量的类型为：</p><ul><li>X； 我们的数据是一个NxD矩阵（N个图像数量，D个维数→5张28 * 28的图像将形成5x784矩阵X）</li><li>π； 向量K，代表每个分布的权重的标量。（例如，三个伯努利可以具有π= [0.2，0.75，0.05]加权向量）</li><li>μ； 每个群集的平均KxD矩阵。（一个图像的维数为D = 28 * 28 = 784，其中每个图像代表一个像素值。取属于同一群集的图像的每个像素的平均值，例如数字2 ，我们得出的平均向量为784。因此，μ将是KxD的矩阵）</li></ul><p>在E步中，我们对潜在变量后验的期望值或所谓的责任特别感兴趣。</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f3bee7cdb8a341588fd6b25eae49493f><p class=pgc-img-caption>E-step of EM algorithm (3)</p></div><p><br></p><p>γ实际上返回属于聚类k的观测值（图像）n的期望值。 γ是NxK矩阵； 对于每个观察，我们分配属于每个聚类的概率。 具有最大值的一个就是我们分配给的那个。</p><p>为什么我要告诉所有这些？</p><blockquote class=pgc-blockquote-abstract><p>"向量化中最重要的事情是了解变量的维度。"</p></blockquote><p>责任的计算是我们要向量化的一项</p><p>总结：</p><ul><li>X：NxD矩阵</li><li>π：1xK向量</li><li>μ：KxD矩阵</li><li>γ：NxK矩阵</li></ul><h1 class=pgc-h-arrow-right>管道</h1><p>我们将创建一个函数E_step来运行计算上面的表达式并使用以下代码对其进行测试</p><pre><code>observations = [5, 10, 20, 50, 100, 200, 500, 1000]for n in observations:    X_test = bin_train_data[:n]    D_test, K_test = X_test.shape[1], 10    mu_test = np.random.uniform(low=.25, high=.75,                                 size=(K_test,D_test))    pi_test = np.ones(K_test) / K_test    t0 = time.time()    gamma_test = E_step_1(X_test, mu_test, pi_test)    runtime = time.time() - t0    assert gamma_test.shape == (n, K_test)</code></pre><p><br></p><p>随意先尝试一下！</p><h1 class=pgc-h-arrow-right>尝试№1</h1><p>第一次尝试时，我们将使用for循环编写所有内容； 在矢量/矩阵运算中，仅标量。</p><p>通过查看方程式，我们可以看到存在3个循环。 每个示例N一个，每个群集K一个，每个对象D每个维一个，我们将按此顺序循环。 因此，我们将一次用一个元素填充矩阵γ。</p><pre><code>def E_step(X, mu, pi):    N, D = X.shape    K = pi.shape[0]    gamma = np.zeros((N, K))    for n in range(N):        for k in range(K):            m = 1            for i in range(D):                m *= mu[k][i]**X[n][i] * (1-mu[k][i])**(1-X[n][i])            gamma[n][k] = m * pi[k]        gamma[n] /= gamma[n].sum()    return gamma</code></pre><p><br></p><p>下图显示了我们的结果。</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0c5c7121e08749e381ea230cea4fcb4b><p class=pgc-img-caption></p></div><p>我们肯定可以做得更好！</p><h1 class=pgc-h-arrow-right>尝试№2</h1><p>最好从内部循环开始，然后逐步发展到外部循环。 而这正是我们要做的！</p><p>我们要摆脱for循环D。 因此，每个依赖于D的项现在都应成为向量。 在此for循环中，我们有两个变量； μ和x（请参阅等式（2））。 因此x和μ→向量。 问题; 它是μ** x，是另一个矢量的幂的矢量，很难计算。 如果我们能解决这个问题……</p><p>有一个函数可以将幂运算转换为乘法。 是的，是对数！ 因此，让我们对表达式取对数，然后得出结果的指数！</p><blockquote class=pgc-blockquote-abstract><p>首选对数概率运算，因为它们提供数值稳定性</p></blockquote><p>即使在我们的情况下它没有任何影响，但是每次使用日志时，请在表达式内部使用常量epsilon以保持稳定性（使用-inf时不要为零）。</p><p>因此，我们将不得不逐元素矢量相乘。 简单 ;）</p><pre><code>def E_step(X, mu, pi):    N, D = X.shape    K = pi.shape[0]    gamma = np.zeros((N, K))    for n in range(N):        for k in range(K):            log_gamma = np.log(pi[k]) + (X[n] * np.log(mu[k]) \                        + (1 - X[n])*np.log(1 - mu[k])).sum()            gamma[n][k] = np.exp(log_gamma)        gamma[n] /= gamma[n].sum()    return gamma</code></pre><p><br></p><p>我们的结果是……</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8a6de31a269a4589bb5d89765fa0f923><p class=pgc-img-caption></p></div><p>那是巨大的胜利！ 与Algor.1相比，x轴看起来更像1！ 但是，我们可以做得更好;）</p><h1 class=pgc-h-arrow-right>尝试№3</h1><p>一次循环一圈：K圈！</p><p>在矢量化过程中，我们正在朝以下方向发展：</p><blockquote class=pgc-blockquote-abstract><p>标量→向量→矩阵</p></blockquote><p>随着我们用numpy数组替换越来越多的循环，越来越多的代码将在C→更快更干净的代码上运行。</p><p>我们采用之前的实现，并且想要删除K for循环。 因此，每个依赖于K的标量都将变成一个向量，而每个向量都将变成一个矩阵。 这意味着X将保持不变，而μ将变成矩阵，而π和γ将成为向量。 注意最后一个； 随着γ字段的逐行传播，我们表达式的结果现在必须是向量！ 因此，μ和X的运算必须产生1xK向量，快速指示符是（i）它们必须与向量π相加，这也是1xK（ii）结果是矩阵γ的一行，也是1xK 向量。</p><p>得出的结果是：</p><pre><code>def E_step(X, mu, pi):    N, D = X.shape    K = pi.shape[0]    gamma = np.zeros((N, K))    for n in range(N):        log_gamma = np.log(pi) + np.log(mu) @ X[n] \                    + np.log(1 - mu) @ (1 - X[n])        gamma[n] = np.exp(log_gamma)        gamma[n] /= gamma[n].sum()    return gamma</code></pre><p><br></p><p>结果是：</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/aae9a14862c34954a2d6fe782e837905><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/953153bf9d09448596b62aa09dab7960><p class=pgc-img-caption></p></div><p>惊人！ 在n = 1000的情况下，我们成功完成了一半的时间！ 与Algor.1确实没有可比性。 但是，我们可以做得更好吗？</p><h1 class=pgc-h-arrow-right>尝试№4</h1><p>我们还有一个循环。 我们可以有一个无Python的计算循环吗？ N，你的时间到了！</p><p>在将矩阵*向量运算转换为矩阵@矩阵运算时，我们需要采用前者的转置矩阵（@是常规矩阵乘法）。 请记住，现在我们的输出必须是整个γ矩阵。 我认为到现在为止，您对它的运行方式有了想法；）。</p><p>所以我们的代码是</p><pre><code>def E_step(X, mu, pi):    gamma = np.exp(np.log(pi) + X @ np.log(mu.T) \            + (1 - X) @ np.log(1 - mu.T))        gamma /= gamma.sum(axis=1)[:, np.newaxis]    return gamma</code></pre><p><br></p><p>没有一个循环！ 该代码看起来很优雅，只有三行！ 现在要获得结果，鼓掌吧…</p><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f86e4351f21345b1a0803c7dcbc04069><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=如何通过向量化78倍速加快您的机器学习算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c677ed42d89143a6a40bf134e9d1e84b><p class=pgc-img-caption></p></div><p>就是这样，再也无法得到任何改善！ 对于n = 1000，我们仅使用三行代码就从11.688→0.012的运行时开始运行！</p><h1 class=pgc-h-arrow-right>摘要</h1><p>因此，当您要对表达式进行向量化时，您需要做什么：</p><ul><li>了解矩阵的尺寸。</li><li>笔和纸：写下公式，从求和到求和，然后将其转换为等效的矩阵运算。 总是要考虑任何表达式必须返回的维数； 观察邻居求和操作，因为它们的维数相同</li><li>逐个循环，逐步：标量→向量→矩阵</li><li>取对数并确保引入归一化常数epsilon</li><li>对方法的向量化版本进行编码，并进行光泽：D</li></ul><p>(本文翻译自Ioannis Gatopoulos的文章《Vectorization: How to speed up your Machine Learning algorithm by x78》</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'倍速','通过','78'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>