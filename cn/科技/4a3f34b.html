<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器学习 | 关于参数模型与非参数模型研究 | 极客快訊</title><meta property="og:title" content="机器学习 | 关于参数模型与非参数模型研究 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/68b4f4157bf646db9ce418d00bef8ec8"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><meta property="article:published_time" content="2020-10-29T20:59:30+08:00"><meta property="article:modified_time" content="2020-10-29T20:59:30+08:00"><meta name=Keywords content><meta name=description content="机器学习 | 关于参数模型与非参数模型研究"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/4a3f34b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器学习 | 关于参数模型与非参数模型研究</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>关注并标星<strong>索信达</strong></p><p>每天打卡阅读</p><p>更快走进金融人工智能世界</p><p>━━━━━━</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/68b4f4157bf646db9ce418d00bef8ec8><p class=pgc-img-caption></p></div><p>我们是索信达集团旗下的金融人工智能实验室团队，微信公众号（datamargin)将不定期推送原创AI科学文章。我们的作品都是由实战经验丰富的AI科学技术人员或资深顾问精心准备，志在分享结合实际业务的理论应用和心得体会。</p><p><strong>文 | 索 信 达 Yvonne Yang</strong></p><p><strong>引言</strong></p><p>在大数据时代，我们常常面临成万上亿的数据，伴随着的是高维度的变量，当今很多学术和技术领域都致力于解决针对大数据的模型构造，例如神经网络、深度学习。但对于金融和商业领域，变量是如何影响响应变量的（可解释性）、模型是否可靠等因素尤为重要，特别是当我们的数据集只包含了屈指可数的几个变量，那么特征变量的选取应更严谨，变量与响应变量间关系的量化也是重要的指标，此时可以运用更为精细的模型探索方法。广义线性模型和广义加性模型分别由线性模型和加性模型推广而来，能更广泛地应用于不同分布的数据，并辅以似然比检验逐步优化模型。本文将从参数模型和非参数模型的角度，以广义线性模型和广义加性模型为例，配以相应的案例，对模型探索以及优化方法进行简要介绍。<strong>1. 参数回归模型1.1 传统线性模型</strong></p><p>统计学中，参数模型是一类可以通过结构化表达式和参数集表示的模型。为确定两种或两种以上变量之间的定量关系，我们希望通过手中已有的数据去“拟合”出一个“线性方程”，众所周知的经典线性回归模型（Linear Regression Model）就属于参数模型,</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/59585a91590e4e128d2e03881714bf5d><p class=pgc-img-caption></p></div><p>它要求响应变量y是实值的且连续的，用于我们通常所说的“回归问题”。</p><p><strong>1.2 广义线性模型</strong></p><p><strong>1.2.1 模型介绍</strong></p><p>日常生活中的许多问题的数据形式并不符合“连续”这个要求，并且面临很多“分类问题“，即该把某对象预测为属于哪一类，这时传统的线性回归模型便显得约束过于强而导致应用范围的狭窄。此外，对于一些较为特殊的分布，如偏态分布和常为重尾分布的金融数据，该如何选择模型呢？广义线性模型（Generalized Linear Model）应运而生，它将线性回归的思想推广到探索多种形式的响应变量和回归变量之间的关系。其向量形式为：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d75fae472b4349e1ba97f70ea8aed677><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/099d91661383417790d7aca519fe8f1e><p class=pgc-img-caption></p></div><p>被称为连接函数（link function），满足平滑（简单来说，图像光滑）且可逆（反函数存在的函数是可逆的）的条件，</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5067e9e4e6bf4b74a980a16bcb1700f0><p class=pgc-img-caption></p></div><p>为给定样本下Y的分布。</p><p>可以看到，当y为连续变量并且我们选择</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/416fff4d8ae7440aa4393a3666aad2e1><p class=pgc-img-caption></p></div><p>作为y|x 的分布，连接函数取恒等函数</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f88fc77c3a0d44758c714a4d0855a900><p class=pgc-img-caption></p></div><p>时，它恰好是传统的线性回归模型；逻辑回归也是其特例，连接函数为</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6fa859fb3f08426bb0fdf214d03190c7><p class=pgc-img-caption></p></div><p>；而当y为离散值且选择分布为</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5b75f0ad01124bc39478a6de6944b68e><p class=pgc-img-caption></p></div><p>，连接函数为</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/8cac69e4ef9d4fc7bd8e4dd6c5963fed><p class=pgc-img-caption></p></div><p>时，模型变为：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/47617290b8b14ba1b182f696e9d38d49><p class=pgc-img-caption></p></div><p>恰好是泊松回归模型。可以见得，以上常见模型都是广义线性模型的一种特殊形式，广义线性模型通过连接函数将模型变得更灵活而具有普适性。</p><p><strong>1.2.2 分布选择</strong></p><p>分布的选择依赖于给定样本中y值的分布，y的分布观察可利用直方图和核密度估计（kernel density estimator）。特别的，对于均值与方差相差甚远的离散响应变量y，选择Poisson分布不再是一个明智的选择（因为服从Poisson分布的随机变量均值与方差应相等），因此可尝试用负二项分布。</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dd7ae6f1780647c296c91e21785a60e1><p class=pgc-img-caption></p></div><p>图1. 几种常见分布</p><p><strong>1.2.3 连接函数</strong></p><p>对于连接函数的选择，此处引入指数族分布的概念：概率密度函数（p.d.f.）或者概率质量函数（p.m.f.）能化成如下形式的分布，被称为指数族分布，</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/58d167c30de640b398999f55ac5d1e3a><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1c197a86bc514632bacc99f5c612b2e6><p class=pgc-img-caption></p></div><p>是自然参数，</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/48d7d62131f148919cf068a3bd56df21><p class=pgc-img-caption></p></div><p>是尺度参数，且满足条件：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5a5571e38d1746c2acf3fd2dffa5bf81><p class=pgc-img-caption></p></div><p>以下给出一些常见的指数族分布及其标准连接函数（canonical link function）：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5aeea9113ece47d0af6dc765fc9fc40e><p class=pgc-img-caption></p></div><p>为简化得到系数</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db16078c6bd649b1932e2b8812f60ee8><p class=pgc-img-caption></p></div><p>的数学计算，通常我们选择标准连接函数，特别地，对于要求y值大于0的响应变量，可以选择连接函数</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2cb2ae1b56e74705addda4901907669f><p class=pgc-img-caption></p></div><p>，以保证预测值仍然满足大于0。</p><p><strong>1.2.4 模型优化之似然比检验</strong></p><p>对于参数不显著的项(例如X1)，说明其对于目标变量的影响不显著，可是去掉之后模型是否显著变好，有时用肉眼无法甄别，此时可借助似然比检验。我们希望检验一个更“小”的模型是否可行，此处假设设定为 ：</p><p>原假设：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d75c111823eb4e5a861711f33315a9b6><p class=pgc-img-caption></p></div><p>备择假设：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2a4d0e961684486a98548fec297c699><p class=pgc-img-caption></p></div><p>若</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/526a194d832d4a9ebf713e0f7bb554c4><p class=pgc-img-caption></p></div><p>，p值小于显著性水平时，拒绝原假设，认为X1去掉模型效果将显著变差。<strong>1.3 示例</strong></p><p>例如在一个案例中（数据来自：https://www.kaggle.com/mirichoi0218/insurance），我们要探索保险公司给付的保费（charges）与年龄、性别、bmi、地区、抽烟习惯、小孩数量之间的函数关系，目标变量charges为连续变量，下图为核密度估计曲线，发现其近似Gamma分布，因此可选择Gamma分布与其标准连接函数</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5ec3cf9894604ea9a024e8419ff9f9b0><p class=pgc-img-caption></p></div><p>.</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/64928b28c4b9427fa7542bee0caa61b0><p class=pgc-img-caption></p></div><p>图2: 目标变量charges分布</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e5f467c37fae4667b4a233f12a29d568><p class=pgc-img-caption></p></div><p>图3: gamma分布图（来自：Wikipedia）</p><p>对于上图中的数据集，当模型优化至此步，发现不显著项（p值大于0.05）大部分与region（地域）有关（如左图所示）。去掉region这一项后，重新拟合模型，在参数显著性上有所提升，然而AIC略微上升（如右图所示）：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/937f567d69c448599ebe5bd7a96c5cd3><p class=pgc-img-caption></p></div><p>图4: 模型结果输出-优化前（左）优化后（右）</p><p>看起来小小牺牲AIC能换来参数显著性的提高，那么把地域特征去除真的能达到优化模型的效果吗？我们希望检验一个更“小”的模型是否可行，当显著性水平设为</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/52baaf7ba7c84bd2a3384b28af8185d2><p class=pgc-img-caption></p></div><p>时，根据如下输出结果，p值为0.3989，不拒绝原假设，认为“地区（region）”可从模型中移除，至此模型优化结束。似然比检验能更客观地告诉我们某一特征能否从模型中移除。</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db96ba17f46d4a1a93c55762073aba5c><p class=pgc-img-caption></p></div><p>图5: 似然比检验结果</p><p><strong>2.非参数回归模型</strong></p><p><strong>2.1 非参数模型</strong></p><p>参数模型与非参数模型的区别在于：参数模型预先设定了模型的形式，后通过最小化score function求得参数，而非参数模型不对随机变量预先假设任何模型形式，预测器的构建都依赖于数据，可以自由地从数据中学习出模型，具有极大的灵活性。在构造目标函数时，非参的方法寻找合适的训练数据，同时保留一些对数据的泛化能力， 因此，这些非参方法能够拟合大多数的函数形式。例如K近邻算法就是典型的非参模型，对于一个新的数据实例x，该算法寻找离x最邻近的K个样本，以“多数取胜”策略来确定x的类别。</p><p>受限于先验模型的形式，参数模型有时无法全面地捕捉到数据样本的特征，且有时模型形式难以预先确定。对于回归问题而言，常用的非参数回归方法有局部多项式回归（polynomial regression）和样条回归（spline regression）。对于p个变量的回归问题，非参数方法能得到最终的回归方程</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4fc6621eb4d249c4a286c424c867feab><p class=pgc-img-caption></p></div><p>，或向量表示为</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/221a5a8d32934051bffe72fa35650da0><p class=pgc-img-caption></p></div><p>.</p><p><strong>2.2 从加性模型到广义加性模型</strong></p><p>非参数回归的模型形式自由，完全由数据驱动，适应力强，但也有显著的缺点，例如“高维诅咒”：当维数较高时，前述的两种非参数回归方法开始变得不稳定且收敛减慢，同时最终的回归方程解释性和可视化能力弱。解决维度问题的一种方法是利用加性模型（Additive Model）：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/077cf918906e4b95aeffe3654039a18a><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a38c55c87f8a4ba4beda9d4e6a19cec6><p class=pgc-img-caption></p></div><p>为单变量非参数方程。该方法相当于将1个p维变量的方程转换成了p个单变量方程。</p><p>相似地，通过连接函数</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9b5c4b31bb904e86b3c1291faa535d1e><p class=pgc-img-caption></p></div><p>，可推广到广义加性模型（Generalized additive model）：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ee68aaad2e394be1a41c722bbad40673><p class=pgc-img-caption></p></div><p><strong>2.3 示例</strong></p><p>采用广义加性模型，能克服非参数模型常有的解释性弱和可视化能力差的问题，可以研究单个变量的非参数项。例如探究房价与10个变量的关系，采用样条函数平滑每一个变量，变量显著性如下图所示：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9988fa2c8d764881a129dcfb4c834a95><p class=pgc-img-caption></p></div><p>图6：GAM模型拟合结果</p><p>通过绘制部分预测图，可以探索单个变量的效应，其中每幅图横轴为单一变量取值，纵轴为对应的</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/51190758ed2e414284379a07c58f0508><p class=pgc-img-caption></p></div><p>：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3a4acaf1490546cfa0378c1952d70a8a><p class=pgc-img-caption></p></div><p>图7: 部分预测图</p><p><strong>3. 半参数模型</strong></p><p><strong>3.1 模型介绍</strong></p><p>在非参数模型模型优化的过程中，有些变量呈现出强烈的线性性，对该变量</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/78ef7f89abb34a68b19818e20f6ea185><p class=pgc-img-caption></p></div><p>应用线性项</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/63c59424fd114a0b8ba4320b56553fa5><p class=pgc-img-caption></p></div><p>替代非线性项放入模型中。此时得到的是“半参数模型”，它同时含有线性项和非线性项，作为非参数模型和参数模型之间的一类模型，半参数模型既继承了非参数模型的灵活性,又继承了参数模型的可解释性，可以进一步改善非参数模型的缺陷。半参数模型常具有以下的形式：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/40422354572845f9b0972f44bcbf803b><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e1766912bcba4a2ab255233077d36559><p class=pgc-img-caption></p></div><p>为线性项 ，</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0efd2a73032a4a12b6661e2c1a20af0e><p class=pgc-img-caption></p></div><p>为非线性项。</p><p><strong>3.2 示例</strong></p><p>在2.3示例中，非参数模型拟合后发现x5和x9的非参数项不够显著，进一步观察部分预测图发现变量x5对模型响应变量没有贡献（因为其纵轴刻度始终都在0附近），变量x8和x9表现出线性性（因为其部分预测图近似直线），而其他变量表现出非线性性。据此移除变量x5，并将x8和x9的项替换为线性项，优化得到一个半参模型，所有项都是显著的，结果如下所示：</p><div class=pgc-img><img alt="机器学习 | 关于参数模型与非参数模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4f31df53c85d45a69dc35a937f81827e><p class=pgc-img-caption></p></div><p>图8: 优化后参数显著性</p><p><strong>4. 小结</strong></p><p>传统的参数模型(如线性回归)只能处理一些简单的变量间呈现特定关系的数据，当面临的问题更复杂的时候，变量关系说不清道不明，参数模型不一定能达到目标效果。非参数模型可以规避上述问题，具有更好的灵活性，并可通过广义加性模型获得更好的性能。此外，半参数模型是介于参数模型和非参数模型之间的一类，常由非参模型优化得来，兼具灵活性和可解释性。</p><p>对于样本量足够大而变量数量不大的数据集，或者对一些需要追踪指标变化原因的场景，这些统计模型及其优化方法或许能派上用场。其通过分布选择与连接函数推广到更具有普适性的模型，并能利用统计方法去检测变量的选择是否具有合理性。无论是广义线性模型和广义加性模型，都能学习到一个既定的模型，通过变量参数或者部分预测图去发现变量如何影响响应变量，同时对于新的数据集可以产生相应的预测值。</p><p>注：本文使用的分析工具为R语言， 有兴趣的读者可自行了解。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'参数','模型','机器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>