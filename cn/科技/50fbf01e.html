<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>一文看懂四种基本的神经网络架构 | 极客快訊</title><meta property="og:title" content="一文看懂四种基本的神经网络架构 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/2af16cac7e3f4219a00d306ce278b7e5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50fbf01e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50fbf01e.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="一文看懂四种基本的神经网络架构"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/50fbf01e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>一文看懂四种基本的神经网络架构</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>刚刚入门神经网络，往往会对众多的神经网络架构感到困惑，神经网络看起来复杂多样，但是这么多架构无非也就是三类，前馈神经网络，循环网络，对称连接网络，本文将介绍四种常见的神经网络，分别是CNN，RNN，DBN，GAN。通过这四种基本的神经网络架构，我们来对神经网络进行一定的了解。</p><p><strong><span>什么是神经网络</span></strong></p><p>神经网络是机器学习中的一种模型，是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。</p><p>一般来说，神经网络的架构可以分为三类：</p><p><strong>前馈神经网络：</strong></p><p>这是实际应用中最常见的神经网络类型。第一层是输入，最后一层是输出。如果有多个隐藏层，我们称之为“深度”神经网络。他们计算出一系列改变样本相似性的变换。各层神经元的活动是前一层活动的非线性函数。</p><p><strong>循环网络：</strong></p><p>循环网络在他们的连接图中定向了循环，这意味着你可以按照箭头回到你开始的地方。他们可以有复杂的动态，使其很难训练。他们更具有生物真实性。</p><p>循环网络的目的使用来处理序列数据。在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。</p><p>循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。</p><p><strong>对称连接网络：</strong></p><p>对称连接网络有点像循环网络，但是单元之间的连接是对称的（它们在两个方向上权重相同）。比起循环网络，对称连接网络更容易分析。这个网络中有更多的限制，因为它们遵守能量函数定律。没有隐藏单元的对称连接网络被称为“Hopfield 网络”。有隐藏单元的对称连接的网络被称为玻尔兹曼机。</p><p><strong><span>感知机</span></strong></p><p>其实之前的帖子讲过一些关于感知机的内容，这里再复述一下。</p><p>首先还是这张图</p><p>这是一个M-P神经元</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2af16cac7e3f4219a00d306ce278b7e5></div></div></p><p>一个神经元有n个输入，每一个输入对应一个权值w，神经元内会对输入与权重做乘法后求和，求和的结果与偏置做差，最终将结果放入激活函数中，由激活函数给出最后的输出，输出往往是二进制的，0 状态代表抑制，1 状态代表激活。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c657c4511f144f95b222c8aabbed76c3></div></div></p><p>感知机可以分为单层感知机，多层感知机。</p><p>我们这里主要讨论的是单层感知机。</p><p>而感知机由两层神经网络组成，输入层接收外界输入信号后传递给输出层，输出层是 M-P神经元，</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/24c8dbb1fc2f48858c7ceffb33de33c7></div></div></p><p>可以把感知机看作是 n 维实例空间中的超平面决策面，对于超平面一侧的样本，感知器输出 1，对于另一侧的实例输出 0，这个决策超平面方程是 w⋅x=0。 那些可以被某一个超平面分割的正反样例集合称为线性可分(linearly separable)样例集合，它们就可以使用图中的感知机表示。</p><p>与、或、非问题都是线性可分的问题，使用一个有两输入的感知机能容易地表示，而异或并不是一个线性可分的问题，所以使用单层感知机是不行的，这时候就要使用多层感知机来解决疑惑问题了。</p><p><strong><span>如果我们要训练一个感知机，应该怎么办呢？</span></strong></p><p>我们会从随机的权值开始，反复地应用这个感知机到每个训练样例，只要它误分类样例就修改感知机的权值。重复这个过程，直到感知机正确分类所有的样例。每一步根据感知机训练法则来修改权值，也就是修改与输入 xi 对应的权 wi，法则如下：</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2f780d1009d644a4a8a0cec2b210c017></div></div></p><p>这里 t 是当前训练样例的目标输出，o 是感知机的输出，η 是一个正的常数称为学习速率。学习速率的作用是缓和每一步调整权的程度，它通常被设为一个小的数值（例如 0.1），而且有时会使其随着权调整次数的增加而衰减。</p><p>多层感知机，或者说是多层神经网络无非就是在输入层与输出层之间加了多个隐藏层而已，后续的CNN，DBN等神经网络只不过是将重新设计了每一层的类型。感知机可以说是神经网络的基础，后续更为复杂的神经网络都离不开最简单的感知机的模型，</p><p><strong><span>卷积神经网络 CNN</span></strong></p><p>谈到机器学习，我们往往还会跟上一个词语，叫做模式识别，但是真实环境中的模式识别往往会出现各种问题。比如：</p><p>图像分割：真实场景中总是掺杂着其它物体。很难判断哪些部分属于同一个对象。对象的某些部分可以隐藏在其他对象的后面。</p><p>物体光照：像素的强度被光照强烈影响。</p><p>图像变形：物体可以以各种非仿射方式变形。例如，手写也可以有一个大的圆圈或只是一个尖头。</p><p>情景支持：物体所属类别通常由它们的使用方式来定义。例如，椅子是为了让人们坐在上面而设计的，因此它们具有各种各样的物理形状。</p><p>卷积神经网络与普通神经网络的区别在于，卷积神经网络包含了一个由卷积层和子采样层构成的特征抽取器。在卷积神经网络的卷积层中，一个神经元只与部分邻层神经元连接。在CNN的一个卷积层中，通常包含若干个特征平面(featureMap)，每个特征平面由一些矩形排列的的神经元组成，同一特征平面的神经元共享权值，这里共享的权值就是卷积核。卷积核一般以随机小数矩阵的形式初始化，在网络的训练过程中卷积核将学习得到合理的权值。共享权值（卷积核）带来的直接好处是减少网络各层之间的连接，同时又降低了过拟合的风险。子采样也叫做池化（pooling），通常有均值子采样（mean pooling）和最大值子采样（max pooling）两种形式。子采样可以看作一种特殊的卷积过程。卷积和子采样大大简化了模型复杂度，减少了模型的参数。</p><p>卷积神经网络由三部分构成。第一部分是输入层。第二部分由n个卷积层和池化层的组合组成。第三部分由一个全连结的多层感知机分类器构成。</p><p>这里举AlexNet为例：</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cf60476a76d740ac88b80a774fc53843></div></div></p><p>·输入：224×224大小的图片，3通道</p><p>·第一层卷积：11×11大小的卷积核96个，每个GPU上48个。</p><p>·第一层max-pooling：2×2的核。</p><p>·第二层卷积：5×5卷积核256个，每个GPU上128个。</p><p>·第二层max-pooling：2×2的核。</p><p>·第三层卷积：与上一层是全连接，3*3的卷积核384个。分到两个GPU上个192个。</p><p>·第四层卷积：3×3的卷积核384个，两个GPU各192个。该层与上一层连接没有经过pooling层。</p><p>·第五层卷积：3×3的卷积核256个，两个GPU上个128个。</p><p>·第五层max-pooling：2×2的核。</p><p>·第一层全连接：4096维，将第五层max-pooling的输出连接成为一个一维向量，作为该层的输入。</p><p>·第二层全连接：4096维</p><p>·Softmax层：输出为1000，输出的每一维都是图片属于该类别的概率。</p><p>卷积神经网络在模式识别领域有着重要应用，当然这里只是对卷积神经网络做了最简单的讲解，卷积神经网络中仍然有很多知识，比如局部感受野，权值共享，多卷积核等内容，后续有机会再进行讲解。</p><p><strong><span>循环神经网络（递归神经网络） RNN</span></strong></p><p>传统的神经网络对于很多问题难以处理，比如你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNN之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。理论上，RNN能够对任何长度的序列数据进行处理。</p><p>这是一个简单的RNN的结构，可以看到隐藏层自己是可以跟自己进行连接的。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/382da319ae10415b90f8e7fe03561f56></div></div></p><p>那么RNN为什么隐藏层能够看到上一刻的隐藏层的输出呢，其实我们把这个网络展开来开就很清晰了。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d48fd00441af4cb59914edd813a480e0></div></div></p><p>这个网络在t时刻接收到输入Xt之后，隐藏层的值是St,输出值是Ot,关键一点是，的值不仅仅取决于Xt，还取决于St-1。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f4b51e68bbf14849a70661e21ea7a675></div></div></p><p>式1是输出层的计算公式，输出层是一个全连接层，也就是它的每个节点都和隐藏层的每个节点相连。V是输出层的权重矩阵，g是激活函数。式2是隐藏层的计算公式，它是循环层。U是输入x的权重矩阵，W是上一次的值St-1作为这一次的输入的权重矩阵，f是激活函数。</p><p>从上面的公式我们可以看出，循环层和全连接层的区别就是循环层多了一个权重矩阵 W。</p><p>如果反复把式2带入到式1，我们将得到：</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/264f1a7203c34968ab7ff869fdd7e0f2></div></div></p><p>从上面可以看出，循环神经网络的输出值，是受前面历次输入值Xt、Xt-1、Xt-2、X-3、X-4…影响的，这就是为什么循环神经网络可以往前看任意多个输入值的原因。</p><p><strong><span>深度信念网络 DBN</span></strong></p><p>在讲DBN之前，我们需要对DBN的基本组成单位有一定的了解，那就是RBM，受限玻尔兹曼机。</p><p>首先什么是玻尔兹曼机？</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/42883be8e85d48de8cb0a1684ff63f37></div></div></p><p>如图所示为一个玻尔兹曼机，其蓝色节点为隐层，白色节点为输入层。</p><p>玻尔兹曼机和递归神经网络相比，区别体现在以下几点：</p><p>1、递归神经网络本质是学习一个函数，因此有输入和输出层的概念，而玻尔兹曼机的用处在于学习一组数据的“内在表示”，因此其没有输出层的概念。</p><p>2、递归神经网络各节点链接为有向环，而玻尔兹曼机各节点连接成无向完全图。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b4db1917c5a54ff78f3a6cfebffc784e></div></div></p><p><strong><span>而受限玻尔兹曼机是什么呢？</span></strong></p><p>最简单的来说就是加入了限制，这个限制就是将完全图变成了二分图。即由一个显层和一个隐层构成，显层与隐层的神经元之间为双向全连接。</p><p>h表示隐藏层，v表示显层</p><p>在RBM中，任意两个相连的神经元之间有一个权值w表示其连接强度，每个神经元自身有一个偏置系数b（对显层神经元）和c（对隐层神经元）来表示其自身权重。</p><p>具体的公式推导在这里就不展示了</p><p>DBN是一个概率生成模型，与传统的判别模型的神经网络相对，生成模型是建立一个观察数据和标签之间的联合分布，对P(Observation|Label)和 P(Label|Observation)都做了评估，而判别模型仅仅而已评估了后者，也就是P(Label|Observation)。</p><p>DBN由多个限制玻尔兹曼机（Restricted Boltzmann Machines）层组成，一个典型的神经网络类型如图所示。这些网络被“限制”为一个可视层和一个隐层，层间存在连接，但层内的单元间不存在连接。隐层单元被训练去捕捉在可视层表现出来的高阶数据的相关性。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/45daadcce59b4cc199407a2383d60854></div></div></p><p><strong><span>生成对抗网络 GAN</span></strong></p><p>生成对抗网络其实在之前的帖子中做过讲解，这里在说明一下。</p><p>生成对抗网络的目标在于生成，我们传统的网络结构往往都是判别模型，即判断一个样本的真实性。而生成模型能够根据所提供的样本生成类似的新样本，注意这些样本是由计算机学习而来的。</p><p>GAN一般由两个网络组成，生成模型网络，判别模型网络。</p><p>生成模型 G 捕捉样本数据的分布，用服从某一分布（均匀分布，高斯分布等）的噪声 z 生成一个类似真实训练数据的样本，追求效果是越像真实样本越好；判别模型 D 是一个二分类器，估计一个样本来自于训练数据（而非生成数据）的概率，如果样本来自于真实的训练数据，D 输出大概率，否则，D 输出小概率。</p><p>举个例子：生成网络 G 好比假币制造团伙，专门制造假币，判别网络 D 好比警察，专门检测使用的货币是真币还是假币，G 的目标是想方设法生成和真币一样的货币，使得 D 判别不出来，D 的目标是想方设法检测出来 G 生成的假币。</p><p><strong>传统的判别网络：</strong></p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dc0a5af28217440e8da992d6726c051a></div></div></p><p><strong>生成对抗网络：</strong></p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ac951494615f4db9b7f696f0ac8572b7></div></div></p><p>在训练的过程中固定一方，更新另一方的网络权重，交替迭代，在这个过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到一个动态的平衡（纳什均衡），此时生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%。</p><p>下面展示一个cDCGAN的例子（前面帖子中写过的）</p><p><strong>生成网络</strong></p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a422fc0d89e445b69e36c4c256a7bd49></div></div></p><p><strong>判别网络</strong></p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b10d84879f00424c83ec24cc720b3d58></div></div></p><p>最终结果，使用MNIST作为初始样本，通过学习后生成的数字，可以看到学习的效果还是不错的。</p><p><div class="pgc-image pgc-card-fixWidth"><div class="pgc-img-wrapper ttcore-relative"><img alt=一文看懂四种基本的神经网络架构 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/06dc244024894ba39782107865e4c29e></div></div></p><p><strong><span>小结</span></strong></p><p>本文非常简单的介绍了四种神经网络的架构，CNN，RNN，DBN，GAN。当然也仅仅是简单的介绍，并没有深层次讲解其内涵。这四种神经网络的架构十分常见，应用也十分广泛。当然关于神经网络的知识，不可能几篇帖子就讲解完，这里知识讲解一些基础知识，帮助大家快速入（zhuang）门（bi）。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'四种','神经','网络架构'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>