<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>AI也有偏见：你在机器“眼里”是好人还是坏蛋？ | 极客快訊</title><meta property="og:title" content="AI也有偏见：你在机器“眼里”是好人还是坏蛋？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RfDgA10IBHJqK9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51723e35.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51723e35.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51723e35.html><meta property="article:published_time" content="2020-11-14T21:08:18+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:18+08:00"><meta name=Keywords content><meta name=description content="AI也有偏见：你在机器“眼里”是好人还是坏蛋？"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/51723e35.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>AI也有偏见：你在机器“眼里”是好人还是坏蛋？</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote class=pgc-blockquote-abstract toutiao-origin=blockquote><p>人工智能是从人类身上学习的，而人类是有偏见的生物。</p></blockquote><img alt=AI也有偏见：你在机器“眼里”是好人还是坏蛋？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RfDgA10IBHJqK9><p>近日，麻省理工的博士生在两项独立研究中发现，虽然机器擅长识别人工智能生成的文本，但是很难分辨其中的真假。原因在于训练机器识别假新闻的数据库中充满了人类的偏见，因此，训练而成的人工智能也不可避免地带上了刻板印象。</p><p>人类偏见是人工智能界普遍存在的沉疴。ImageNetRoulette数字艺术项目通过使用AI分析描述用户上传的图片，揭示出了这一严峻问题。本期全媒派独家编译《纽约时报》对ImageNetRoulette项目的评论，为你呈现人工智能背后的“隐形偏见”。</p><p>一天清晨，当网友Tabong Kima正在刷推特时，他看到了一个名为#ImageNetRoulette的实时热搜。</p><p>在这个热搜里，用户们把自拍上传到某个网站上，然后由人工智能来分析和描述它所看到的每一张脸。ImageNetRoulette就是一家这样的网站，它把某位男性定义为“孤儿”，或是“不吸烟者”，如果是戴着眼镜的，则可能被贴上“书呆子、白痴、怪胎”的标签。</p><img alt=AI也有偏见：你在机器“眼里”是好人还是坏蛋？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RfDgA1M3U98aAH><p>一位Twitter网友上传了自己的照片，被AI识别为“强奸犯嫌疑人”（Rape Suspect），标签位于照片左上角</p><p>在Kima看到的推特信息中，这些标签有的准确，有的奇怪，有的离谱，但都是为了搞笑，于是他也加入了。但结果却让这个24岁的非裔美国人很不开心——他上传了一张自己的微笑照片，然后网站给他贴上了“不法分子”和“罪犯”的标签。</p><p>“可能是我不懂幽默吧，”他发了一条推特，“但我没觉得这有什么有趣的。”</p><p>注：截至发稿，该网站imagenet-roulette.paglen.com已经下线，现跳转到www.excavating.ai。后者网页上发布了一篇由原项目创始人撰写的文章《挖掘人工智能：机器学习训练集中的图像政治》</p><img alt=AI也有偏见：你在机器“眼里”是好人还是坏蛋？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RfDgA1d4OsTsP4><p></p><h1 toutiao-origin=h2>人工智能背后：偏见、种族、厌女症</h1><p>事实上，Kima的反应正是这家网站想看到的。ImageNetRoulette是一个数字艺术项目，在人工智能迅速改变个人生活的当下，<strong>这个项目旨在揭露某些古怪的、无根据的、冒犯的行为，它们正在蔓延到人工智能技术中</strong>，包括被互联网公司、公安部门和其他政府机构广泛使用的面部识别服务。</p><p>面部识别和其他AI技术都是通过分析海量数据来学习技能，而这些数据来自过去的网站和学术项目，不可避免地包含多年来未被注意到的细微偏差和其他缺陷。这也是美国艺术家Trevor Paglen和微软研究员Kate Crawford发起ImageNetRoulette项目的原因——他们希望更深层次地揭露这个问题。</p><p>“我们希望揭露偏见、种族主义和厌女症如何从一个系统转移到另一个系统，”Paglen在电话采访中说：“<strong>重点在于让人们理解幕后的操作，看到我们（的信息）一直以来是如何被处理和分类的</strong>。”</p><p>作为本周米兰Fondazione Prada博物馆展览的一部分，这个网站主要关注的是知名的大型可视化数据库ImageNet。2007年，以李飞飞为首的研究人员开始讨论ImageNet项目，它在“深度学习”的兴起中发挥了重要的作用，这种技术使机器能够识别包括人脸在内的图像。</p><p>“Training Humans”摄影展在米兰Fondazione Prada博物馆揭幕，展示人工智能系统如何通过训练来观看并给这个世界分类。</p><p>ImageNet汇集了从互联网上提取的1400多万张照片，它探索了一种训练AI系统并评估其准确性的办法。通过分析各种各样不同的图像，例如：花、狗、汽车，这些系统可以学习如何识别它们。</p><p>在关于人工智能的讨论中，鲜少被提及的一点是，ImageNet也包含了数千人的照片，每一张都被归入某一类。有些标签直截了当，如“啦啦队”、“电焊工”和“童子军”；有些则带有明显的感情色彩，例如“失败者、无望成功的人、不成功的人”和“奴隶、荡妇、邋遢女人、流氓”。</p><p>Paglen和Crawford发起了应用这些标签的ImageNetRoulette项目，<strong>以展示观点、偏见甚至冒犯性的看法如何影响人工智能</strong>，不论这些标签看起来是否无害。</p><p></p><h1 toutiao-origin=h2>偏见的蔓延</h1><p>ImageNet的标签被成千上万的匿名者使用，他们大多数来自美国，被斯坦福的团队雇佣。通过Amazon Mechanical Turk的众包服务，他们每给一张照片贴标签就能赚几分钱，每小时要浏览数百个标签。在这个过程中，偏见就被纳入了数据库，尽管我们不可能知道这些贴标签的人本身是否带有这样的偏见。</p><p>但他们定义了“失败者”、<strong>“荡妇”和“罪犯”</strong>应该长什么样。</p><p>这些标签最早来自另一个庞大的数据集，WordNet，是普林斯顿大学研究人员开发的一种机器可读的语义词典。然而，该词典包含了这些煽动性的标签，斯坦福大学ImageNet的研究者们可能还没有意识到这项研究出现了问题。</p><p>人工智能通常以庞大的数据集为基础进行训练，而即使是它的创造者们也并不能完全理解这些数据集。“<strong>人工智能总是以超大规模运作，这会带来一些后果</strong>，”Liz O’Sullivan说道。他曾在人工智能初创公司Clarifai负责数据标签的监督工作，现在是民权和私人组织“技术监督计划”（STOP,全称为Surveillance Techonology Oversight Project）的成员，这个组织的目标是提高人们对人工智能系统问题的意识。</p><p>ImageNet数据中的许多标签都是十分极端的。但是，同样的问题也可能发生在看似“无害”的标签上。毕竟，即使是“男人”和“女人”的定义，也有待商榷。</p><p>“给女性（无论是否成年）的照片贴标签时，可能不包括性别酷儿（nonbinary，即自我认为非二元性别的人士）或短发女性，”O’ Sullivan表示，“于是，AI模型里就只有长发女性。”</p><p>近几个月来，研究者们发现诸如亚马逊、微软和IBM等公司提供的面部识别服务，都有对女性和有色人种持有偏见。通过IamgeNetRoulette项目，Paglen和Crawford希望能引起人们对这个问题的重视，而他们也的确做到了。随着这个项目在推特等网站上走红，ImageNetRoulette项目近期每小时产生的标签数超过10万个。</p><p>“我们完全没想到，它会以这样的方式走红，”Crawford与Paglen说道，“它让我们看到人们对这件事的真正看法，并且真正参与其中。”</p><p></p><h1 toutiao-origin=h2>热潮之后，隐忧重重</h1><p>对有些人来说，这只是个玩笑。但另外一些人，例如Kima，则能懂得Crawford和Paglen的用意。“他们做得很好，<strong>并不是说我以前没有意识到这个问题，但他们把问题揭露出来了</strong>”，Kima说道。</p><p>然而，Paglen和Crawford认为，问题也许比人们想象得更加严重。</p><p>ImageNet只是众多数据集中的一个。这些数据集被科技巨头、初创公司和学术实验室重复使用，训练出各种形式的人工智能。这些数据库中的任何纰漏，都有可能已经开始蔓延。</p><p>如今，许多公司和研究者都在试图消除这些弊端。为了应对偏见，微软和IBM升级了面部识别服务。今年一月，Paglen和Crawofrod初次探讨ImageNet中的奇怪标签时，斯坦福大学的研究者们禁止了该数据集中所有人脸图像的下载。现在，他们表示将删除更多的人脸图像。</p><p>斯坦福大学的研究团队向《纽约时报》发表了一份声明，他们的长期目标是“解决数据集和算法中的公平性、问责制度和透明度问题。”</p><p>但对Paglen来说，一个更大的隐忧正在逼近——<strong>人工智能是从人类身上学习的，而人类是有偏见的生物。</strong></p><p><strong>“我们对图像的贴标签方式是我们世界观的产物，”他说，“任何一种分类系统都会反映出分类者的价值观。”</strong></p><p>作者：全媒派，公众号：全媒派（ID：quanmeipai）</p><p>本文由 @全媒派 原创发布于人人都是产品经理。未经许可，禁止转载</p><p>题图来自Unsplash，基于CC0协议</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'AI','偏见','机器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>