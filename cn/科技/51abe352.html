<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>视觉交通仿真研究：自动驾驶中的模型，评估和应用 | 极客快訊</title><meta property="og:title" content="视觉交通仿真研究：自动驾驶中的模型，评估和应用 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/12df25dc0418499f8f6eb033f4074160"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><meta property="article:published_time" content="2020-11-14T21:02:04+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:04+08:00"><meta name=Keywords content><meta name=description content="视觉交通仿真研究：自动驾驶中的模型，评估和应用"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/51abe352.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>视觉交通仿真研究：自动驾驶中的模型，评估和应用</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>来源：自动驾驶测试验证技术创新论坛</strong></p><p style=text-align:justify><br></p><p style=text-align:justify><strong>1引言</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>近年来，视觉流量吸引了许多研究社区的关注，包括但不限于计算机游戏，城市可视化，城市规划和自动驾驶。在虚拟现实，游戏和动画中，城市场景必不可少，这些场景不可避免地涉及到大量的车辆行驶。为了控制单个车辆的运动，一种简单的解决方案是使用关键帧方法。但是，在大型交通场景中使用关键帧方法模拟交通拥堵，频繁变道和行人与车辆的交互作用，不仅需要复杂的设计和动画师的反复调整，而且所产生的车辆运动也很少符合物理定律。因此，有效地模拟大规模流量已成为计算机图形学中越来越必要的主题。此外，由于道路网络可视化工具（如OpenStreetMap，ESRI和Google Maps）的普及，将实时交通流纳入虚拟道路网络已变得至关重要。然而，很难访问车辆的实际轨迹并将其实时地整合到虚拟应用程序中。这些趋势激发了对数据驱动的流量模拟[WSLL15]的研究努力。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了上述在动画和可视化中的应用之外，交通模拟在交通研究中还具有广泛的应用。交通仿真软件包，例如VISSIM [PTV11]，TSIS [TSI18]和PARAMICS [PAR18]，是研究人员研究交通网络性能的有效工具。基于虚拟现实的驾驶培训计划通过产生现实的交通环境[VRd18，LWX * 18]帮助新驾驶员提高了驾驶技能。交通模拟还可以用作生成各种交通条件以训练和测试自动驾驶车辆的有效工具[SAMR18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>此外，车辆交通量的增加和复杂道路网络导致了许多与交通有关的问题，例如交通拥堵，事件管理，信号控制和网络设计优化。使用基于分析模型的传统工具很难解决这些问题[SHVDWVW16]。因此，已经尝试使用先进的计算技术对交通的建模，模拟和可视化进行许多研究工作，以分析交通管理的交通状况[PBH12，WLY * 13，WYL * 14]或协助城市发展中的交通重建[ GDGAVU14]。</p><p style=text-align:justify><br></p><p style=text-align:justify>交通模拟的主要重点是回答以下问题：给定道路网络，行为模型和初始车辆状态，交通将如何演变？关于交通流的建模和仿真，有大量的数学描述，可以大致分为宏观模型[SWML10]，微观模型[SJ12]和介观模型[SWL11]。尽管宏观方法将车辆的收集视为连续流动，但微观方法却在周围车辆的影响下为每个车辆的动力学建模。相比之下，介观模型结合了微观模型和宏观模型的优势，可以模拟不同细节级别的流量。另外，道路网络的生成和表示也是交通仿真中的一个基本问题。</p><p style=text-align:justify><br></p><p style=text-align:justify>尽管前面提到的交通模型可以有效地捕获高层交通状况，但是所得的模拟结果通常与街道上的真实交通情况并不相似。随着先进的传感硬件和计算机视觉技术的发展，以视频，LiDAR和GPS传感器形式的经验性交通流数据集变得越来越可用。这种现象产生了数据驱动的交通动画技术。示例工作包括从现有道路传感器[SVDBLM11，WSL13，LWL17]获取的时空数据重构交通流，从有限的轨迹样本[CDR * 18]合成新的交通流以及通过从交通监控数据集中学习行为模式和个人特征[CSJ13，BMWD16]。</p><p style=text-align:justify><br></p><p style=text-align:justify>尽管在交通模拟和动画方面取得了重大进展，但迄今为止，如何衡量模拟交通的真实性仍未得到充分探索。此外，在基于模型的交通仿真和数据驱动的动画方法中，始终要关注基于仿真交通与现实交通之间的相似性进行模型验证。为了解决这些问题，当前的方法包括使用主观用户评估并将客观评估指标纳入度量[CDX * 18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>通过各种交通模拟和动画技术的虚拟交通也已应用于自动驾驶培训。自动驾驶有可能改变我们的交通系统。但是，最近的测试失败强调了在模拟环境中对这些自动化机器的培训，然后再将其部署到现实世界中[BNP * 18，LWL19，LPZ * 19]。</p><p style=text-align:justify><br></p><p style=text-align:justify>当前，通常在虚拟环境[WEG * 00，DRC * 17，apo18]中使用具有预定行为的单个干扰道路用户（例如，车辆，行人或自行车）来测试自动驾驶车辆的性能。在模拟的交通流中进行训练，并在各种道路使用者之间进行丰富的交互，自动驾驶汽车可以潜在地获得处理复杂城市环境中复杂交通状况的能力。此外，交通模拟和动画还可以受益于为自动驾驶汽车开发的基于学习的运动计划和决策算法。具体来说，随着收集的驾驶数据集数量的增加，由此产生的精确交通仿真可以从更准确的交通语义上丰富自动驾驶汽车的运动计划和决策。</p><p style=text-align:justify><br></p><p style=text-align:justify>为了实现安全的无人驾驶，需要具有逼真的交通流量和复杂交通状况的高保真驾驶模拟器。这样的模拟器可以以有效且可再现的方式产生关键的训练环境。由于交通模拟在自动驾驶研究中变得至关重要，因此在本次调查中，我们将特别从三个方面描述自动驾驶的最新发展：数据采集，运动计划和测试模拟。</p><p style=text-align:justify><br></p><p style=text-align:justify>组织。本调查的其余部分安排如下。第2节介绍了三类基于模型的交通模拟方法，并为道路网络的过程建模和几何表示提供了不同的代表性方法。第3节概述了基于不同数据采集方法的各种数据驱动动画技术。第4节研究了动画方法的验证和生成的虚拟流量的评估。第5节介绍了最近在数据采集，运动计划以及将虚拟交通用于自动驾驶研究方面的工作。最后，第6节和第7节在总结本调查的基础上，讨论了现有研究的当前状态以及我们对未来研究方向的看法。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2基于模型的交通模拟</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通模拟中的一个重要组成部分是描绘各个细节级别的车辆运动。交通流建模和仿真的早期研究可以追溯到1950年代，当时分别提出了宏观交通模型和微观交通模型[Pip53，LW55]。经过多年的发展，交通模拟技术有三种通用类型[VWKVLVH15，FSS18]（如图2所示），即宏观（2.1节），微观（2.2节）和中观（2.3节）。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/12df25dc0418499f8f6eb033f4074160><p class=pgc-img-caption></p></div><p style=text-align:center>图1</p><p style=text-align:justify><br></p><p style=text-align:justify>通过各种交通模拟和动画方法生成的交通流：（a）Chao等人在高速公路网络上的综合交通流。[CDR * 18]，（b）来自沈和金的信号交叉路口的密集交通场景[SJ12]，（c）使用来自Wilkie等人的道路传感器数据重建虚拟交通流。[WSL13]，（d）使用Li等人的GPS数据重建的城市规模交通。[LWL17]，以及（e）用于自动驾驶测试的异构交通仿真[CJH * 19]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0d559a8841e5449e9e242d010c239785><p class=pgc-img-caption></p></div><p style=text-align:center>图2</p><p style=text-align:justify><br></p><p style=text-align:justify>本次调查介绍了交通模拟和动画组件的架构。首先，传统交通模拟和动画的组成部分：道路网络生成（第2.4节）；交通数据获取（第3.1节）；基于模型的仿真（第2节）；数据驱动的动画（第3.2节）; 以及验证和评估（第4节）。第二，自动驾驶研究的组成部分：自动驾驶培训数据集（第5.1节）；运动计划和决策方法。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89cbce8e99f449d9b226b7606c30f8f7><p class=pgc-img-caption></p></div><p style=text-align:center>图3</p><p style=text-align:center><br></p><p style=text-align:justify>基于模型模拟的详细程度对基于模型的交通模拟方法进行分类。在这里，LWR和ARZ分别指的是Lighthill.Whitham.Richards [LW55，Ric56]和Aw.Rascle.Zhang [AR00，Zha02]提出的两种流行的宏观交通模型。</p><p style=text-align:justify><br></p><p style=text-align:justify>交通流量可以被视为人群流量的一种：流量中的车辆具有相似的目标和行为规则，在保持个人驾驶特性的同时与邻居互动。在计算机图形学中，人群模拟一直是重要的研究领域，支持对集体行为和动力学的研究[PAB08，ZCC * 10]。可以通过宏观方式（以牺牲单个个体的实际运动为代价对人群进行整体建模）[NGCL09]或微观方式（将群体作为个体个体的运动集合进行建模）来实现人群模拟[WLP16] 。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.1宏观方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>宏观方法也称为连续体方法，它以较低的详细程度描述车辆的行为和相互作用：交通流由速度，流量，密度等方面的连续体表示。宏观方法主要用于在道路上进行有效的交通模拟大型道路网络，着重于再现以集体量（例如流量密度和交通流量）衡量的综合行为。</p><p style=text-align:justify><br></p><p style=text-align:justify>Lighthill和Whitham [LW55]和Richards [Ric56]开发了一种早期的一阶宏观模型，称为LWR模型。他们的模型假设交通流率仅取决于描述交通密度关系的交通密度。</p><p style=text-align:justify><br></p><p style=text-align:justify>该模型基于一维可压缩气体动力学与单车道上交通流演变之间的相似性，建立了用于对交通流进行建模的非线性标量守恒定律。本质上，LWR模型描述了具有低分辨率细节的大规模交通流的运动。它的局限性之一是无法在非平衡条件下（例如走走停停的波浪）模拟车辆的运动。</p><p style=text-align:justify><br></p><p style=text-align:justify>后来，Payne [Pay71]和Whitham [Whi74]提出了一个连续的二阶交通流模型，该模型被称为Payne-Whitham（PW）模型。尽管一阶模型假定存在固定的平衡状态，但是二阶模型引入了一个第二个微分方程来描述交通速度动力学。作为限制，PW模型可能会引入负速度，并且从车辆动力学生成的信息传播的速度可能快于车速，这意味着驾驶员可能会受到其后续车辆的影响。Aw and Rascle [AR00]和Zhang [Zha02]提出了对PW模型的修改，以消除其非物理行为。具体来说，Aw和Rascle [AR00]引入了压力项，以确保没有任何信息能比汽车的速度更快地传播。张[Zha02]，类似地，提出了对PW模型的动量方程的修改，以处理向后传播的交通。生成的模型称为Aw-Rascle-Zhang（ARZ）模型，自[Ras02，GP06，LMHS07，MR07]以来已进行了深入研究。Mammar等。[MLS09]表明，ARZ模型在数值上比LWR模型更适合现实世界的数据。</p><p style=text-align:justify><br></p><p style=text-align:justify>为了产生详细的3D动画和交通流的可视化，Sewall等人。[SWML10]提出了一种连续交通仿真模型，用于在大型道路网络上生成现实的交通流。他们通过引入新的车道变换模型并为每辆车使用离散表示，使单车道ARZ模型适应多车道交通。如图4所示，通过将每个车道离散化为多个像元来模拟交通流。为了更新每个像元的状态，将空间离散化的有限体积方法[LeV02]与Riemann求解器结合使用来求解ARZ方程。为了模拟车道合并和换道行为，Sewall等人。通过将车辆表示为“小车”，将连续动力学与离散的车信息结合起来。这些“回转”是由潜在的连续流驱动的。</p><p style=text-align:center><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c1cf3ee36c6f40d980426e8419d19be7><p class=pgc-img-caption></p></div><p style=text-align:center>图4</p><p style=text-align:center><br></p><p style=text-align:justify>宏观交通仿真方法的插图[SWML10]。每个泳道分为离散的单元格。在给定的时间步长，通过求解ARZ方程更新每个像元的状态，然后使用这些解决方案更新每个车道中每个车辆的状态。</p><p style=text-align:justify><br></p><p style=text-align:justify>总之，宏观交通模型是模拟大规模交通的有效工具。但是，此类技术仅限于高速公路网络，因此不适合模拟由单个汽车之间的丰富交互组成的街道级交通。此外，由于这些模型没有对车辆的车道合并行为进行建模，因此它们无法处理车道转换过程中的密度传递。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.2微观方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>微观模型可产生高细节的车辆运动：每辆车辆都被视为满足某些控制规则的离散主体。已经针对特定的城市交通模拟开发了许多微观模型，这归因于它们在建模代理的异构行为，各种道路拓扑以及周围车辆之间的相互作用方面的灵活性。</p><p style=text-align:justify><br></p><p style=text-align:justify>微观模型的早期例子包括细胞自动机模型[NS92]和跟车模型[Pip53，HG63]。元胞自动机模型中车辆的运动由预先指定的时间，空间和状态变量中的演化规则描述。具体而言，将道路离散为多个单元，然后模型确定车辆何时从当前单元移至下一个单元。由于其简单性，元胞自动机模型的计算效率很高，并且可以在大型道路网络[KSSS04]上模拟大量车辆。但是，由于其离散性，生成的虚拟流量只能重现有限数量的真实流量行为。</p><p style=text-align:justify><br></p><p style=text-align:justify>相比之下，由Pipes [Pip53]和Reuschel [Reu50]首次引入的跟车模型可以以计算为代价生成逼真的驾驶行为和详细的车辆特性。他们假设交通流由分散的微粒[SZ14]组成，并对汽车之间的详细交互进行建模。这些模型通过基于刺激响应框架的连续时间微分方程表示每辆汽车的位置和速度：urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0001，其中刺激与领先车辆的位置和速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>在过去的几十年中，通过对主题车辆对其前部车辆的响应进行建模，已经开发了许多跟车模型的变体和扩展。最佳速度模型（OVM）[BHN * 95]和智能驾驶模型（IDM）[TH02]是两个著名的例子。在OVM模型中，假定目标车辆保持其最佳速度。它的加速度取决于它的速度和前车的最佳速度之间的差。在IDM模型中，车辆的加速度或减速度是根据其当前速度以及相对于其前部车辆的相对速度和位置来计算的。车辆特定的参数使IDM模型能够模拟各种车辆类型和驾驶方式。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了模拟单车道上的交通流外，还研究了多车道模拟[SN03，Dav04，THG05，HNT07]。一个示例是修改后的最佳速度模型[Dav04]，该模型用于模拟双车道高速公路和带匝道的单车道高速公路上的交通。另一个示例是两车道交通模型[THG05]，该模型用于模拟交通横向影响。</p><p style=text-align:justify><br></p><p style=text-align:justify>为了生成详细的交通模拟，Shen和Jin [SJ12]提出了一种增强的IDM以及连续的换道技术。他们的技术可以产生顺畅的加/减速策略和灵活的变道行为的交通流。该模型修改了原始IDM模型，使其更适合信号化城市道路网。具体而言，加速过程分为描述驾驶员意图达到其期望速度的自由道路加速项和描述驾驶员保持与其附近车辆的安全距离的意图的减速项。通过添加激活控制控制部分来修改减速项，该激活控制控制部分用于对停止的车辆产生更平稳的反应。此外，该模型将城市道路上的换车行为分为两种情况：自由车道变更和命令式车道变更，并为这两种情况提供了灵活的连续模型。</p><p style=text-align:justify><br></p><p style=text-align:justify>自由行车道经常在相对自由的道路条件下发生。此行为由Kesting等人的双通道MOBIL模型建模。[KTH07]。当目标车辆由于某些强制性因素（例如到达车道尽头或在十字路口转弯）而需要换道动作时，将应用强制性换道，而目标车辆与其前导车辆之间的间隙可能不足以免费变道（图5）。陆等人。[LCX * 14]扩展了全速差模型[JWZ01]，以处理乡村交通模拟中的近车制动情况。后来，Lu等。还在交通仿真中引入了个性模型[LWX * 14]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/849ef27cc8a74b9ebfcfd13bc2dc2922><p class=pgc-img-caption></p></div><p style=text-align:center>图5</p><p style=text-align:center><br></p><p style=text-align:justify>车辆必须更改其车道的情况[SJ12]：（a）到达当前车道的尽头，（b）事故车辆出现在当前车道的前面，并且（c）引导标志出现在交叉路口。</p><p style=text-align:justify><br></p><p style=text-align:justify>与模拟车道（标志性或多个）上的交通相比，模拟交叉路口的交通更为困难。Doniec等。[DMPE08]通过将交叉路口交通视为多主体协调任务，提出了一种用于交通模拟的多主体行为模型。具体来说，首先，每辆车都会感知周围的交通并做出决定；其次，引入了一种预测算法来生成仿真车辆的预测能力。Wang等。[WXZ * 18]引入了影子流量的概念，用于在流量模拟中以统一的方式对流量异常进行建模。Chao等。[CDJ15]设计了一个基于规则的流程，以在混合交通模拟中对车辆与人的交互进行建模。</p><p style=text-align:justify><br></p><p style=text-align:justify>总之，由于微观交通模型旨在描述特定的车辆行为，因此它们可用于模拟连续车道和交叉路口的交通。瓶颈通常是计算成本，尤其是在需要大规模仿真时。</p><p style=text-align:justify><br></p><p style=text-align:justify>2.2.1混合方法</p><p style=text-align:justify><br></p><p style=text-align:justify>尽管连续方法（即宏观模型）优于大型交通模拟和基于代理的技术（即微观模型）优於单个车辆的建模，Sewall等人。[SWL11]结合了这两种类型的方法，并提出了一种混合方法。他们的方法使用基于代理的模型来模拟感兴趣区域中的流量，而其余区域使用连续体模型来模拟流量（请参见图6）。通过在两种建模方法之间自动动态切换，他们的方法可以根据用户的喜好在不同详细程度下模拟流量。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/996af7e0366340948c502cda13ca5854><p class=pgc-img-caption></p></div><p style=text-align:center>图6</p><p style=text-align:justify><br></p><p style=text-align:justify>混合交通仿真方法[SWL11]的说明。黄色边界框内的流量使用基于代理的技术进行模拟，而其余流量使用连续性技术进行模拟。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.3介观方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>介观模型是宏观和微观方法之间的中间方法。介观模型的核心思想是使用概率分布函数[HB01c]以聚合的方式描述交通流动态，同时代表单个驾驶员的行为。介观模型可分为三类：聚类模型，车距分布模型和气体动力学模型[FSS18]。集群模型通过描述具有相同属性的车辆组来表示交通流的动态[KMLK02，MKL05]。车距分布模型集中在时间车距的统计属性上。在介观方法中，最著名的模型是气体动力学模型，其中绘制了气体动力学和交通动力学之间的类比。[PA60，THH99，HHST01，HB01a]。</p><p style=text-align:justify><br></p><p style=text-align:justify>在运输工程中，气体动力学模型通常不用于模拟，但在推导其他连续体模型时仍保持其作用[Hel01]。例如，Hoogendoorn和Bovy [HB00，HB01b]基于气体动力学模型推导了一个多类多车道连续流交通模型。气体动力学模型也是许多宏观模型的基础，例如自适应巡航控制策略[DNP15]。动力学理论还被用来推导出车辆交通的数学模型[FT13]，其中放宽了对车辆连续分布的空间位置和速度的假设。在计算机图形学中，由于大量未知参数以及复杂的微分或积分项，介观模型很少用于交通仿真中，这限制了仿真和动画效果。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.4道路网的产生</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通模拟是车辆与道路网络之间相互作用的一种形式。基础道路网络的获取和建模是重要但具有挑战性的方面。现实世界道路网络的数字表示已越来越多，但是这些数据通常不能直接用于模拟交通。基于宏观和微观建模方法的交通模拟是在形成车道的道路网络上进行的。道路网络包含许多功能，例如车道，交叉路口，合并区域和坡道。已经提出了许多方法用于道路网络的过程建模和几何表示。</p><p style=text-align:justify><br></p><p style=text-align:justify>教区等。[PM06]提出了一个名为CityEngine [cit18]的系统，它使用基于L系统的程序方法来生成道路网络（图7a）。以地图图像为输入，该系统可以生成一组高速公路和街道，将土地分为很多部分，并为各个分配区的建筑物构建适当的几何形状。后来，许多研究人员改进了基于CityEngine [CEW * 08，BN08，GPMG10]的道路网络生成模型。例如，Sun等。[SYBG02]提出了基于模板的道路网络生成模型。具有更大的灵活性，用户可以使用Chen等人的自动道路网络生成模型直接编辑道路网络。[CEW * 08]。最近，西田等人。[NGDA16]展示了一种交互式道路设计系统，该系统使用了从示例道路网络中提取的补丁和统计信息。哈特曼等。[HWWK17]提出了一种基于示例的方法，用于使用生成对抗网络（GAN）来综合道路网络。他们使用二进制图像表示道路网补丁。因为这些方法是为构建虚拟场景而设计的，所以它们通常无法为交通仿真提供必要的信息，例如车道到车道的连接和邻接。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2270e83a07604a3fb4865fe8f261ff44><p class=pgc-img-caption></p></div><p style=text-align:center>图7</p><p style=text-align:justify><br></p><p style=text-align:justify>使用（a）CityEngine [cit18]和（b）Wilkie等人的技术创建的道路网络。[WSL12]。</p><p style=text-align:justify><br></p><p style=text-align:justify>提出了几种用于交通仿真的道路建模技术。Yang和Koutsopoulos [YK96]使用节点，链接，路段和车道来描述道路网络的语义。他们的模型已经整合到交通仿真软件MITSIM [BAKY02]中。在此模型中，路段表示一组具有相同几何折线的车道，而链接则表示路段的集合。矢量数据存储在段的数据结构中。所存储的信息包括分段弧的起点/终点和曲率。节点用于描述相交。在此，必须将节点作为输入数据提供给模型，并且仅用于描述链接是否已连接。不考虑交叉点每个方向上的链接之间的冲突关系。在VISSIM [PTV11]中，采用交通仿真软件，链接和连接器来描述道路网络的拓扑结构，这有助于呈现具有更复杂几何形状的道路。但是，VISSIM中的道路网络仅由连续的路段组成，因此很难处理交叉路口不同方向之间的冲突。同样，其他道路网络表示模型[Par03，BC05，SWL11，SJ12]也已可用。最近，Cura等人。[CPP18]使用真实的地理信息系统（GIS）数据生成了一个连贯的街道网络模型，其中包含拓扑交通信息，路面和街道对象。该系统可以提供车道和车道互连作为交通模拟所需的基本几何信息。但是，他们使用车道作为基本单位来定义和组织道路网络，而忽略了道路网络的矢量数据。值得一提的是，为了促进不同驾驶模拟器之间的数据交换，提出了一种名为OpenDRIVE [DG06]的开放数据格式，以标准化逻辑道路描述。</p><p style=text-align:justify><br></p><p style=text-align:justify>为了改善车辆运动的可视化，Wilkie等人。[WSL12]提出了一种新颖的道路网络模型（图7b），用于将低详细信息GIS数据自动转换为高详细功能道路网络进行仿真。可以使用此模型生成以车道为中心的拓扑结构和弧形道路表示。该模型基于车道定义了一个交叉点。在模拟中，交叉路口通过交通信号和预定的移动优先级进行管理。生成的道路网络库[WSLL15]可在http://gamma.cs.unc.edu/RoadLib/中找到。该模型激发了更多基于车道的仿真技术，例如Mao等。[MWDW15]在Frenet框架下基于道路轴对车道进行建模，以简化复杂的交通模拟。</p><p style=text-align:justify><br></p><p style=text-align:justify>值得一提的是，取决于应用程序，不同详细级别的交通模拟需要有关基础道路网络的不同信息。通常，宏观交通模拟需要较少的路网细节-主要是需要几何信息，以便可以对交通流的密度和速度的传播进行建模。相比之下，微观交通模拟会输出单个车辆的详细运动，因此通常需要有关路网的更多信息。这些信息包括车道（而不是道路）分离和连接，交通信号逻辑，交叉路口和坡道的移动优先级等。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3数据驱动的交通模拟</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>在本节中，我们探讨了现实交通数据的获取（第3.1节）以及用于交通重建和综合的各种数据驱动方法（第3.2节）。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3.1交通数据采集</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通传感器有几种形式[LBH * 10，Led08]。仅举几个例子，一个固定的传感器是感应环路检测器，通常放置在高速公路和主要道路上，以记录每辆经过的车辆的属性。另一个固定传感器是摄像机，它也用于监视流量。除了固定传感器之外，移动传感器也无处不在：手机和GPS设备用于记录车辆的速度及其位置。</p><p style=text-align:justify><br></p><p style=text-align:justify>自从1960年代初推出[AKH * 12，KMGK06]以来，感应环路检测器已成为使用最多的传感器。它可以检测车辆的通过或到达某个点，例如，接近交通信号灯或高速公路交通。绝缘的导电回路安装在人行道中。通过或停在检测区域内的车辆会降低环路的电感。然后，电子单元将该事件感测为频率降低，并向控制器发送脉冲以表示车辆通过或存在。该道路传感器通常可以跟踪通过时间，车道ID和车辆速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>摄像机作为道路传感器，也已得到广泛部署。一个示例是下一代仿真（NGSIM）程序[NGS18]，其中沿道路安装了摄像头，以每秒10帧的速度捕获交通数据。结果数据集包含详细的车辆轨迹。表1列出了四种流行的NGSIM数据集，包括道路长度，道路类型，记录时间和车辆数量。图8显示了在美国101高速公路上收集数据的示例：八个同步摄像机安装在与高速公路相邻的36层建筑物的顶部，记录通过研究区域的车辆。为了处理捕获的大量数据，开发了NGSIM-VIDEO [NGS18]以从图像中自动提取车辆轨迹。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9cb671ebd7d64d6fb53a542486981349><p class=pgc-img-caption></p></div><p style=text-align:center>图8</p><p style=text-align:center><br></p><p style=text-align:justify>在美国101号高速公路上安装了8个摄像机。右图显示了安装在俯瞰高速公路的建筑物顶部的摄像机。</p><p style=text-align:justify><br></p><p style=text-align:justify>表1.四个选定的NGSIM数据集[NGS18]</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1a14532716044445a4f1ed4b1d2fed7b><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:justify>尽管传统的通过道路传感器收集交通数据的方法通常比较昂贵，但诸如GPS报告之类的移动数据已变得越来越可用，并已用于估算城市范围内的交通状况[AA06，LNWL17]。出租车和共享乘车服务（例如Uber和Lyft）系统地为其车队配备了这些设备。汽车的位置，速度和方向等属性将发送到中央处理中心。处理后，有用的信息（例如交通状况和替代路线）将广播给道路上的驾驶员[TEBH98]。当前公共可用的GPS数据集包括Mobile Century [HWH * 10]，T-Drive [tdr19]，GeoLife [geo19]和Uber Movement [ube17]。尽管很有前途，除了固有噪声外，GPS数据通常还包含较低的采样率，这意味着两个连续点之间的时间差可能很大（例如，大于60 s），并且表现出时空稀疏性，这意味着数据可能稀疏。某些时间段和区域。因此，为了在重建交通动态中使用GPS数据，需要几个处理步骤[LNWL17，LJCL18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了单车数据之外，还付出了很多努力来收集互联车辆的交通数据[HL08，RMR14]。例如，安全试点模型部署（SPMD）计划于2012年在美国密歇根州的安阿伯市启动。大约3000辆汽车配备了GPS天线和DSRC（专用短程通信）设备。每辆车向附近的车辆和路边单位广播基本安全消息，包括其位置和速度。这些联网车辆数据为改善智能交通系统应用以及详细的多车道交通模拟和动画提供了机会。由于此类数据可以以较高的频率（例如10 Hz [BS15]）进行采样，这可能会导致存储和通信系统的可观成本，因此通常通过下采样但信息保留的技术[MOH * 14，LLP19]。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3.2交通重建与综合</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>Van Den Berg等人首先介绍了创建与现实世界条件相对应的交通量的数字表示形式。[SVDBLM11]。在他们的工作中，从交通传感器提供的时空数据重建并可视化连续的交通流。如图9所示，传感器（A，B和C点）以200–400 m的间隔放置在道路上。对于特定车辆i，传感器A提供元组urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0002作为数据输入，其中urn：x-wiley：01677055：media：cgf13803：cgf13803-math- 0003分别是通过时间，车道id和车辆i的速度（对于点B和C类似）。任务是计算在给定时间，给定速度和给定速度下开始和到达给定车道的道路上车辆i的轨迹（图9中的蓝色曲线）。该方法首先离散化可能的状态时空，并将车辆的运动限制为预先计算的路线图。然后，它为路线图中的每辆车搜索一条最佳轨迹，该轨迹使换道次数和加速/减速量最小化，并使其与其他车辆的距离最大化，从而获得平稳逼真的运动。对于多辆车辆，基于优先级的多机器人路径规划算法[VDBO07]用于计算车辆的轨迹。但是，基于优先级的多主体路由规划算法非常耗时，随着搜索空间中离散化分辨率的提高，这种方法很快变得难以处理。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b0cf77aedf1844f48a0080b7f126e0fd><p class=pgc-img-caption></p></div><p style=text-align:center>图9</p><p style=text-align:justify><br></p><p style=text-align:justify>根据从公路传感器获取的时空数据重建交通的插图。对于车辆i，传感器提供向量urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0004作为数据输入，其中urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0005是分别经过A点时（与B点和C点类似），通过时间，车道ID和车辆i的速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>出于通过道路传感器测量值重建交通流量的相同目标，Wilkie等人。[WSL13]引入了一种实时技术，该技术通过将稀疏传感器测量的宏观状态估计与基于代理的交通模拟系统集成在一起，来重构单个车辆的真实运动。如图10所示，此方法具有交通状态估计阶段的功能，其中使用卡尔曼平滑器（EnKS）[Eve03]和连续交通模拟器的集合来创建整个道路网络上速度和密度场的估计。然后，将状态估计值用于驱动基于代理的交通模拟模型，以产生各个车辆的详细运动。最后，输出是与传感器测量的原始交通信号一致的2D交通流。与Sewall等人的交通重建工作相比。[SVDBLM11]，此方法显示了更高的灵活性和更低的计算成本。但是，除了各个车辆的匹配之外，该估计方法在本质上是宏观的。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2019fbbf876b4c35a9b71e0f5a20c003><p class=pgc-img-caption></p></div><p style=text-align:center>图10</p><p style=text-align:justify><br></p><p style=text-align:justify>管道的交通流量重建算法[WSL13]。该算法集成了一个有效的状态估计方法，该方法使用Ensemble Kalman滤波器和连续交通仿真来有效地重构交通。使用基于代理的交通模拟可以直观显示结果，从而为单个车辆产生逼真的运动。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Li等人。[LWL17]提出了一种从GPS数据重建城市规模交通的方法。为了解决数据覆盖范围不足的问题，此方法以GIS地图和GPS数据为输入，并使用两阶段过程来重构城市规模的交通。在初始交通重建的第一阶段，使用统计学习结合优化，地图匹配和行程时间估算技术，从稀疏的GPS数据中重建并逐步完善各个路段的流量条件。在动态数据完成的第二阶段，引入了基于元模型的仿真优化以有效地完善第一阶段的重建结果，同时还引入了微观模拟器，可以在数据覆盖范围不足的区域动态内插丢失的数据。为了确保重建的交通正确，该方法针对第一阶段的城市边界（交通）约束和重建的交通流量进一步优化了模拟。这是通过基于元模型的公式所计算出的交通流量的误差近似值来实现的。</p><p style=text-align:justify><br></p><p style=text-align:justify>尽管上述流量重构技术专用于在相同情况下使用稀疏输入数据预测完整的流量，但是还有其他数据驱动的流量合成方法，旨在从有限的流量轨迹样本中生成新的流量。Chao等。[CDR * 18]使用一组有限的车辆轨迹作为输入样本，通过纹理合成和交通行为规则的融合来合成新的车辆轨迹。示例（输入）车辆轨迹集包含有关车道数量和流量密度的各种交通流量段。如图11所示，通过将交通流的时空信息作为2D纹理，可以将新交通流的生成公式化为纹理合成过程，这可以通过最小化新开发的交通纹理能量度量来有效解决。具体来说，交通纹理中的每个纹素在特定帧处编码车辆的状态，包括其速度，位置以及与其相邻车辆的动态关系。交通纹理能量度量测量合成交通流与给定交通流样本之间的相似性。通过在输入交通流量样本中找到最匹配的纹理元素，可以确定合成交通流量中的每辆车速度。合成的输出不仅可以捕获输入交通流的时空动态，还可以确保交通特征，例如车辆之间的安全距离和换道规则。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b937e65adc154927839e408ebd4fca93><p class=pgc-img-caption></p></div><p style=text-align:center>图11</p><p style=text-align:justify><br></p><p style=text-align:justify>一组两车道轨迹[CDR * 18]的纹理比喻。从概念上讲，轨迹集的时空信息可以看作是2D纹理，并且每个交通纹理元素都可以在特定帧上编码车辆的状态，包括其运动信息以及与相邻车辆的位置关系。</p><p style=text-align:justify><br></p><p style=text-align:justify>研究人员还没有使用基于从道路传感器获取的数据来重建虚拟交通，也没有从现有的轨迹数据中合成新的交通流，而是使用机器学习算法来学习车辆的详细运动特性，包括纵向的加速/减速以及车道。变更过程。Chao等。[CSJ13]提出了一种基于视频的方法，用于从交通动画视频中学习驾驶员的特定驾驶特性。这种方法将对每个车辆的独特驾驶习惯的估计公式化为寻找微观驾驶模型的最佳参数集的问题，这可以使用自适应遗传算法解决。获悉的特征可用于在给定视频中高精度地重现交通流，也可应用于任何基于代理的交通模拟系统。Bi等。[BMWD16]从车辆轨迹数据中学习变道特性。如图12所示，此方法首先从预先收集的车辆轨迹数据集中提取与换道任务最相关的特征。然后，将提取的特征用于对变道决策过程进行建模，并估计变道执行过程。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a01a9b09fdb94762b7e1807a62679d4e><p class=pgc-img-caption></p></div><p style=text-align:center>图12</p><p style=text-align:justify><br></p><p style=text-align:justify>数据驱动车道变换模型[BMWD16]的管道插图。预处理步骤从预先收集的交通数据集中提取最相关的功能。然后，决策模块可以推断目标车辆是否应执行车道变换以及应更改为目标车道/间隙。最后，执行模块计算所涉及车辆的详细轨迹，以完成换道任务。</p><p style=text-align:justify><br></p><p style=text-align:justify>上述工作的重点是模拟高速公路或大型城市网络上的车辆。最近，Bi等人。[BMWD19]提出了一个基于深度学习的交叉路口交通仿真框架。为了描述对车辆与环境相互作用的视觉感知，建立了一个称为网格图的网格座标系统，以对与行人混合的异构车辆之间的相互作用进行编码。如图13所示，在网格地图上滑动具有五个通道的窗口可以为每个车辆生成一个环境矩阵。环境矩阵捕获车辆和车辆周围的行人的速度和位置。除了环境矩阵外，还基于收集到的交叉路口数据集采用车辆身份来描述当前的车辆状态。然后，使用卷积神经网络和递归神经网络来学习交叉路口的车辆轨迹模式。除了模拟交叉路口交通外，它还可通过为车辆提供新的目的地和驾驶环境来更改现有的交叉路口交通动画。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/af62414c83f444d78c6c5f523627422f><p class=pgc-img-caption></p></div><p style=text-align:center>图13</p><p style=text-align:justify><br></p><p style=text-align:justify>交叉路口交通仿真中的环境矩阵图[BMWD19]。对于车辆A，使用大小为31×31的窗口描述周围区域。一个包含五个通道的环境矩阵（urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0006）。urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0007（或urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0008）可视化车辆B和C的速度。urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0009表示行人和骑自行车的人数。Φ和χ分别表示车辆A可行驶的区域和从无人机的角度看的可见区域。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>4验证与评估</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>广义上讲，可以执行两种类型的虚拟流量评估：视觉和统计[TK04]。在视觉验证中，并排显示实际流量和模拟流量的图形表示，以确定它们是否可以区分[SVDBLM11，CSJ13]。在Chao等人的工作中。[CDR * 18]，研究人员通过三种不同方法对生成的流量进行成对比较，进行了用户研究[KS40] ：( 1）真实性（即NGSIM流量数据），（2）基于纹理的建议流量合成方法[CDR * 18]和（3）IDM模型[SJ12]的最新发展之一。对于每个测试场景，分别使用上述三种不同方法生成三种不同的交通流动画。如图14（a）所示，要求参与者在两个动画剪辑对中选择更真实的一个。此外，如果参与者无法确定哪个剪辑更具视觉吸引力，则可以选择“不确定”选项。为了平衡视觉刺激的顺序，根据威廉姆斯设计的拉丁方[Wil49]显示配对。此用户研究的实验结果如图14（b）所示。除了计算票数外，研究人员还执行了单样本t检验和配对样本t检验，并计算了相应的p值以量化投票结果的统计显著性。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/53bac5e9c37e40d49ef65d26b6af46c1><p class=pgc-img-caption></p></div><p style=text-align:center>图14<br></p><p style=text-align:justify>驾驶员视野研究（a）和实验结果（b）的快照[CDR * 18]。左侧的黑框和右侧的白框表示参与者使用相应方法对结果进行投票的总次数。中间的灰色框表示“不确定的选择”（即，在感知上等效）。符号*表示根据具有urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0010的两尾独立一样本t检验得出的统计显著性。</p><p style=text-align:justify><br></p><p style=text-align:justify>由于主观用户研究不可避免地耗时且容易出错，因此通过定量和客观措施进行的统计验证不仅可以用于测量各种模拟交通流的真实性，而且可以以一致的方式客观地比较不同交通模拟模型的性能。对于交通模拟和动画技术，由于交通的随机性，通常不执行直接轨迹比较。取而代之的是比较平均速度和流量随时间变化的情况（例如，Sewall等人的图15 [SWL11]）。在更详细的级别上，还使用了特定的运动参数（包括速度，加速度和车辆间隙）来验证交通模拟技术的有效性[CSJ13，BMWD16]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/425669a0ff4245ed8dbe27f341f020f8><p class=pgc-img-caption></p></div><p style=text-align:center>图15</p><p style=text-align:center><br></p><p style=text-align:justify>基于代理的（微观）模拟，连续体（宏观）模拟，我们的混合模拟技术和101号高速公路上的实际NGSIM数据之间的比较。这些图显示了以15s为间隔记录的密度，速度和通量，这些时间间隔集中在显示的时间高速公路尽头的传感器（从起点开始urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0011）[SWL11]。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Chao等人。[CDX * 18]引入了一种通用的，基于字典的学习方法，以定量和客观地测量交通轨迹数据的保真度。首先，从预先收集的地面交通数据离线构建表征现实交通行为常见模式的交通模式字典。中间学习错误设置为基于字典的流量表示的基准。借助构建的字典，可以通过将输入（模拟）流量的基于字典的重构误差与基准字典误差进行比较，来评估输入（模拟）流量的真实性。如图17所示，此方法包括四个阶段：（1）提取时空交通流特征；（2）从现实交通数据中学习字典（即构建交通模式字典），（3）基于字典的任何输入交通流量数据的重建，以及（4）基于重建误差的定量度量的计算。该评估指标可以稳固地应用于任何模拟交通流量。图16显示了几种不同交通数据的评估结果。保真度分数的范围设置为[0..10]。如果模拟的流量更接近真实（训练）流量数据集，则保真度得分将具有较小的值，反之亦然。</p><p style=text-align:center><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5596430e9af24ff396ed8bba279e14a0><p class=pgc-img-caption></p></div><p style=text-align:center>图16</p><p style=text-align:center><br></p><p style=text-align:justify>IDM模型[SJ12]使用三个不同的参数集（（b）–（d））生成的三个虚拟流量之间的保真度度量比较。模拟器的初始流量状态设置为与实际流量（a）相同的值。使用白色圆圈突出显示了模拟流量与真实世界地面真实情况之间的差异。对于基于字典的保真度评估，度量值越小表示虚拟流量的保真度越高[CDX * 18]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/31379edfb232496d96232fa98440c890><p class=pgc-img-caption></p></div><p style=text-align:center>图17</p><p style=text-align:justify><br></p><p style=text-align:justify>虚拟流量的基于字典的保真度度量的管道[CDX * 18]。蓝色框显示了系统的待评估输入，其中包含实际流量数据集和模拟数据。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5在自动驾驶中的应用</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>无人驾驶汽车具有释放人们驾驶汽车的潜力，从而提高了他们在旅途中的生产率，提高了当前交通运输系统的安全性和效率，并将交通运输转化为随时随地可供任何人使用的公用事业。在本节中，我们将描述自动驾驶的最新发展，包括自动驾驶训练数据的收集（第5.1节），基于深度学习的运动计划方法（第5.2节）和自动驾驶模拟（第5.3节）。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.1自动驾驶数据集</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>收集第3.1节中提到的交通数据集，以进行交通流重建和虚拟交通动画。这些数据集对于建立自动驾驶系统可能没有用。知道训练数据对于自动驾驶至关重要，因此，我们以不同交通状况下的第一眼视频，LiDAR数据和GPS信息的形式调查了现有的驾驶数据集（如下所述）。这些数据集促进了自动驾驶系统的开发和各种驾驶行为的学习。</p><p style=text-align:justify><br></p><p style=text-align:justify>Jain等。[JKR * 15]从10位驾驶员那里收集了1180英里自然高速公路和城市驾驶行为的多样化数据集。记录了汽车内外的视频片段，GPS报告和速度测量结果。</p><p style=text-align:justify><br></p><p style=text-align:justify>comma.ai [SH16]数据集是一个公共数据集，其中包含约7.25小时的高速公路行驶数据。数据集已分为11个视频剪辑。发行的视频分辨率为160×320。还记录了来自多个传感器的速度，转向角，GPS报告，陀螺仪和IMU。</p><p style=text-align:justify><br></p><p style=text-align:justify>伯克利DeepDrive视频数据集（BDDV）[GKB * 16]由真实的驾驶视频和GPS / IMU数据组成。记录了各种驾驶情况，例如美国几个主要城市的城市，高速公路，城镇和农村地区。BDDV包含超过1万小时的仪表板摄像机视频流。</p><p style=text-align:justify><br></p><p style=text-align:justify>LiDAR视频数据集（LiVi Set）[CWL * 18]包括来自Velodyne激光扫描仪的大规模高质量点云和来自仪表板相机的图像。Velodyne激光扫描仪在水平360度和垂直−30.67至+10.67度的角度收集点云。点云数据的总量约为1TB。密度约为每秒70万个点。通过仪表板摄像机录制了约15G的视频剪辑。记录软件工具包远程连接到车辆控制器，以便从车载传感器获取速度。该数据集涵盖各种交通状况，包括主干道，主要道路，山区道路，学区和特殊的旅游路线。</p><p style=text-align:justify><br></p><p style=text-align:justify>本田研究所的驾驶数据集（HDD）[RCMS18]包括旧金山湾区的104个小时的驾驶数据。包括各种交通场景。经过后期处理的数据集的总大小约为150GB和104个视频小时。</p><p style=text-align:justify><br></p><p style=text-align:justify>Drive360 [HDVG18]包含来自八个环视摄像机的60小时驾驶视频。通过车辆的CAN总线记录了低水平的驾驶操作（例如转向角和速度控制）。数据具有高时间分辨率，360度视野覆盖，逐帧同步和各种路况。</p><p style=text-align:justify><br></p><p style=text-align:justify>其他一些没有驾驶行为的数据集也可能有助于自动驾驶中的视觉语义理解和基于视觉的控制。使用Foru高分辨率摄像机，Velodyne激光扫描仪和定位系统记录KITTI数据集[GLSU13，GLU12]。该数据集包含289个立体和光流图像对，urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0012长度的立体视觉测距序列，以及在杂乱环境中捕获的200k以上3D对象注释。该数据集用于立体，光流，视觉测距/ SLAM（同时定位和制图）和3D对象检测的任务。</p><p style=text-align:justify><br></p><p style=text-align:justify>Cityscape数据集[COR * 16]包含记录在50个城市街道上的大量不同的立体声视频序列。这些图像中总共有5000张具有高质量的像素级注释。20,000张其他图像带有粗略注释。数据集捕获了不同季节的不同街道场景。</p><p style=text-align:justify><br></p><p style=text-align:justify>牛津RobotCar数据集[MPLN17]包含1000多公里的行驶数据，其中包括从六个摄像头收集的近2000万张图像，以及来自多种天气条件（包括大雨，临近，直射阳光和大雪）的LIDAR和GPS数据。由于此数据集的记录时间跨度为一年，因此某些道路和建筑物可能会发生变化。Udacity [Uda]的另一个数据集包括通过CAN总线进行的低级驾驶操作。</p><p style=text-align:justify><br></p><p style=text-align:justify>城市环境的基于视觉的语义分割对于自动驾驶至关重要。已经提出了各种数据集[RSM * 16，TKWU17，WU18]，包括语义分割的各种合成驾驶或街道场景，有助于语义理解和基于视觉的控制。表2显示了不同的自动驾驶数据集的详细比较。</p><p style=text-align:justify><br></p><p style=text-align:justify>表2.各种自动驾驶数据集的比较。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3229002bdbc84f2aa9696b23c256df09><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7d607b3ba3e247b69da6017b54b4d8cd><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:justify>值得注意的是，自动驾驶数据集也可以有助于交通模拟和动画。具体而言，首先，可以使用车辆轨迹来校准交通仿真模型；其次，大规模交通数据集可以丰富数据驱动的交通综合方法。第三，虚拟流量的评估可以受益于各种现实流量数据集。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.2运动计划和决策</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>运动计划和决策对于自主代理在其环境中导航至关重要。在本节中，我们回顾了几种基于学习的自动驾驶汽车和其他智能代理的运动计划方法和决策算法。我们建议感兴趣的读者阅读其他评论文章，包括[KQCD15，PČY* 16，SAMR18]，以供进一步阅读。</p><p style=text-align:justify><br></p><p style=text-align:justify>Pomerleau [Pom89]引入了ALVINN（神经网络中的自主陆地车辆），该技术开创了端到端自主导航方法。ALVINN将来自摄像机和激光测距仪的图像用作导航车辆的输入。Chen et al并没有采用介导的感知来推动决策者的行为和使用回归方法来反映行为。[CSKX15]映射了基于图像的直接感知驾驶中的几种收费指标。基于带有标签的赛车视频游戏TORCS的屏幕截图，可以训练深度卷积神经网络（CNN）。该方法已在车载智能手机视频和KITTI数据集[GLSU13]中进行了测试。</p><p style=text-align:justify><br></p><p style=text-align:justify>随着各种获取的交通数据集和高级计算设备的发展，多年来，已经开发了更多的用于自动驾驶的端到端深度学习框架。Bojarski等。[BDTD * 16]使用CNN（称为PilotNet [BYC * 17]）从前置摄像头获取原始像素作为输入，以产生转向行为。该框架功能强大，无需手动分解和语义抽象即可实现道路跟踪。Gurghian等。[GKB * 16]提出了端到端的深层CNN，可直接估算车辆的车道位置。输入图像来自侧面安装的向下摄像头，与带前置摄像头的图像相比，该图像提供了更好的视图，可进行车道标记。</p><p style=text-align:justify><br></p><p style=text-align:justify>后来，徐等人。[XGYD17]使用基于大规模众包车辆动作数据的FCN-LSTM框架来学习通用车辆动作。这种方法采用了一种新的范例来从未校准的源中学习模型。训练后，它可以产生离散的动作（例如，笔直，停止，左转和右转）或连续的动作（例如，车道跟随和转向控制）来导航自动驾驶车辆。Chen等人的工作并非基于交通视频数据学习自动驾驶模型。[CWL * 18]证明了诸如LiDAR点云和视频记录之类的额外信息对于自动驾驶很有用。</p><p style=text-align:justify><br></p><p style=text-align:justify>伦茨等。[LDLK17]专注于高速公路入口处的车辆运动。他们使用部分可观察的马尔可夫决策过程训练了一个深层神经网络来预测车辆运动。Kuefler等。[KMWK17]采用“生成对抗模拟学习”来学习驾驶行为。这种方法克服了级联错误的问题，并且可以产生逼真的驾驶行为。Hecker等。[HDVG18]通过将来自周围360度全景摄像机的信息集成到路线规划器中，学习了一种新颖的端到端驾驶模型。此方法中使用的网络将传感器输出直接映射到低级驾驶操作，包括转向角和速度。金等。[KRD * 18]通过引入扎实的内省式解释模型，为自动驾驶引入了一种端到端，可解释的驾驶方法。该模型由两部分组成：第一部分是基于CNN的视觉注意机制，该机制将图像映射到驾驶行为，第二部分是基于注意的视频到文本模型，用于对模型动作进行文字说明。杨等。[YLWX18]利用在CARLA和TORCS中收集的虚拟交通数据来预测车辆行为，称为DU-drive（图18）。Maqueda等。[MLG * 18]提出了一种深度神经网络方法来预测车辆的转向角。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/df24bd5e6e164d4ab2c017996ae12cd9><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:center>图18</p><p style=text-align:justify><br></p><p style=text-align:justify>DU-Drive [YLWX18]的体系结构。该模型与条件GAN密切相关。生成器网络G将真实图像转换为虚拟图像，通过预测器网络P从中预测车辆命令。鉴别器网络D将伪虚拟图像与真实虚拟图像区分开。对抗目标和预测目标都驱动生成器G产生可产生最佳预测结果的虚拟表示。</p><p style=text-align:justify><br></p><p style=text-align:justify>近年来，强化学习也已经适应自动驾驶。Abbeel等。[ADNT08]提出了一种有效的算法，可在全球导航和生成车辆轨迹的本地计划之间进行折衷。银等。[SBS13]为自动导航系统提出了适当的耦合成本函数，以平衡不同的偏好，包括应该在哪里驾驶以及如何驾驶汽车。Lillicrap等。[LHP * 15]采用深层的Q学习算法，以实施行为准则，无模型的系统，该系统学习一种策略来引导车辆在模拟驾驶环境中保持在赛道上。Kuderer等。[KGB15]提出了一种基于特征的逆强化学习方法，用于学习自动驾驶的各个驾驶方式。沃尔夫等。[WHW * 17]提出了一个深度Q网络，用于在3D物理模拟中操纵车辆。在这种方法中，车辆的目标是跟随车道完成任意路线上的圈速，基于动作的奖励功能是由在实际单词增强学习场景中的潜力所激发的。潘等人。[PYWL17]使用新颖的现实翻译网络在虚拟环境中训练自动驾驶模型，然后在现实环境中使用它。在此虚拟现实增强学习框架中，来自虚拟环境的图像首先被分割为场景解析表示，然后转换为合成图像。梁等。[LWYX18]提出了一种通用的可控模仿强化学习方法，以缓解大型连续动作空间的低探索效率。基于直接来自CARLA模拟器的视觉输入，可以实现高成功率的自动驾驶。</p><p style=text-align:justify><br></p><p style=text-align:justify>为了在复杂的交通环境中高效安全地驾驶车辆，自动驾驶汽车需要预测周围车辆的运动。车辆和行人之间的相互作用应准确表示[LVL14]。轨迹预测的任务可以分为几类：基于物理的，基于机动的和交互感知的模型。此外，已经完成了大量基于深度学习的工作，用于人类轨迹预测[AGR * 16，VMO18，GJFF * 18，MA18，SKS * 19，XPG18，HST * 18]。在这里，我们将注意力集中在使用深度神经网络的车辆轨迹预测上。</p><p style=text-align:justify><br></p><p style=text-align:justify>李等人。[LCV * 17]提出了一个深度随机IOC RNN编码器-解码器框架，以预测动态场景中交互主体的未来距离，该距离可以在驾驶场景中产生准确的车辆轨迹。金等。[KKK * 17]提出了一种基于LSTM的概率车辆轨迹预测方法，该方法使用占用栅格图来表征驾驶环境。Deo和Trivedi [DT18]采用卷积社交池网络来预测高速公路上的车辆轨迹。整个网络包括LSTM编码器，卷积社交池层和基于机动的解码器。具体来说，它首先使用LSTM编码器基于轨道历史记录来学习车辆动力学。然后，它使用卷积社交池层来捕获所有车辆轨迹的相互依赖关系，最后，它训练基于机动的LSTM解码器来预测未来车辆轨迹的分布。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.3自动驾驶仿真</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>尽管机器学习方法的发展极大地促进了自动驾驶中的运动计划和决策制定，但现实世界的数据量仍然不足以覆盖许多复杂的交通场景，因此限制了自动驾驶系统学习各种驾驶策略的能力，而且重要的是，在危险情况下的恢复行动。出于安全考虑，这使得无人驾驶汽车始终采用最保守，最无效率的决策。据报道，自动驾驶汽车已造成一些致命事故。这些观察结果刺激了高保真驾驶模拟器的发展，它可以作为替代和有效的工具，为训练自动驾驶汽车提供各种交通状况。此外，模拟器可以在自动驾驶汽车部署到现实世界之前对其进行全面而彻底的安全测试[ARB * 15，APPI11，LF09]。</p><p style=text-align:justify><br></p><p style=text-align:justify>实际上，自自动驾驶研究的早期以来，仿真已用于训练驾驶模型[Pom89]。后来，赛车模拟器已用于评估各种驾驶方法。例如，Chen等。[CSKX15]使用TORCS [WEG * 00]评估提出的用于自动驾驶的直接感知模型。最近，研究人员[RVRK16，JRBM * 17，RHK17]利用侠盗猎车手V（GTA V）来得出自动驾驶策略，从而获得与可手动绘制的真实世界图像得出的控制策略相当的性能。</p><p style=text-align:justify><br></p><p style=text-align:justify>CARLA [DRC * 17]作为一种开放源代码模拟器，已经被开发来支持自动驾驶城市驾驶模型的开发，培训和验证。该仿真平台支持灵活设置传感器套件，并提供可用于训练驾驶策略的信号。信号包括GPS座标，速度，加速度/减速度以及有关碰撞的详细数据。可以指定各种环境因素，包括天气和一天中的时间（图19）。通过这些设置，CARLA已用于研究许多自动驾驶方法的性能，包括经典的模块化方法，通过模仿学习的端到端训练模型以及通过强化学习的端到端训练模型。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=视觉交通仿真研究：自动驾驶中的模型，评估和应用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/486c71afd9ae49b79446a137dd58e0c5><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:center>图19</p><p style=text-align:justify><br></p><p style=text-align:justify>CARLA Simulator [DRC * 17]中的街道交通，在三种天气情况下以第三人称视角显示。从左上方顺时针方向：晴天，白天下雨，下雨后不久的白天和晴朗的日落。</p><p style=text-align:justify><br></p><p style=text-align:justify>最佳等。[BNP * 18]介绍了AutonoVi‐Sim，这是一个用于自动驾驶数据生成和驾驶策略测试的高保真模拟平台。AutonoVi‐Sim是高级可扩展模块的集合。与CARLA相似，它还支持车辆传感器系统的规范以及日间时间和天气条件的变化，以及非车辆参与者（如骑自行车的人和行人）的活动。</p><p style=text-align:justify><br></p><p style=text-align:justify>此外，最近的几个项目寻求构建仿真平台来训练端到端驾驶系统，并提供丰富的虚拟交通场景，以测试自动驾驶。一个示例项目是Apollo [apo18]，其中包含了来自实际流量和虚拟流量的大量驾驶数据。Apollo的目标是为自动驾驶系统的开发创建强大的虚拟闭环：从算法到评估，再到更新算法。阿波罗（Apollo）的局限性在于，虚拟路况数据是使用特定且定义明确的障碍物和交通信号手动创建的，这些障碍物和交通信号不如实际交通情况现实且复杂。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Li等人。[LPZ * 19]开发了一个模拟框架AADS，它可以通过模拟交通流量来增强真实图像，以生成逼真的图像。利用来自LiDAR和摄像头的数据，该框架可以将基于实际车辆轨迹的模拟交通流组合到后台。可以将合成图像更改为不同的视点，并对其进行充分注释，以准备用于自动驾驶系统的开发和测试。该框架旨在克服手动开发虚拟环境的负担以及使用虚拟图像训练自动驾驶汽车的性能下降。</p><p style=text-align:justify><br></p><p style=text-align:justify>Li等人开发的另一个框架。ADAPS [LWL19]则采用了不同的观点-能够从事故中学习自动驾驶。该框架包含两个仿真平台。第一个模拟平台以3D运行，用于测试学习的策略并模拟事故。第二个仿真平台以2D模式运行，用于分析第一个仿真平台中发生的事故，并通过提供替代的安全轨迹来解决事故。然后，根据安全轨迹生成大量带注释的数据，以训练和更新控制策略。与以前的技术（例如DAGGER [RGB11]）相比，ADAPS还代表了一种更有效的在线学习机制，该技术可以大大减少得出鲁棒控制策略所需的迭代次数。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>6讨论</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>在本节中，我们讨论了潜在的未来研究方向。</p><p style=text-align:justify><br></p><p style=text-align:justify>首先，交通仿真模型应该能够对尽可能多的复杂交通行为进行建模，同时保持计算效率。但是，对于现有的微观交通模型，车辆的每种行为（例如加速/减速和换道）都可以单独建模和控制。此外，微观交通模型更侧重于车辆的前向运动，这在某种程度上受到局限，从而忽略了换道行为和一般的车辆横向运动。此外，由于根据汽车遵循规则，车辆的运动主要受其领先车辆的影响，因此所得的模拟很少会涉及视场中的其他车辆来计算加速度/减速度。为了模拟更现实的交通流，有必要开发一个统一的，可扩展的模拟框架，以应对丰富的车辆行为，包括加速/减速，停留在车道，改变车道以及与非车辆交通参与者（例如行人和骑自行车的人）互动。</p><p style=text-align:justify><br></p><p style=text-align:justify>其次，尽管进行了许多成功的演示，但当前的数据驱动交通动画方法无法处理车辆与其他移动物体（例如行人）之间的平凡互动。主要原因之一是要同时获取车辆，行人和环境因素的大规模时空数据是一项艰巨的任务。对于交通重建，通常在计算中分别使用公路传感器和GPS数据（两种交通数据）。同时，交通重建的准确性受到可用数据的限制。因此，结合各种数据源，例如道路传感器，视频流和GPS轨迹，有可能提高重建精度。</p><p style=text-align:justify><br></p><p style=text-align:justify>第三，关于虚拟流量保真度的评估，基于字典的度量标准[CDX * 18]提供了可行的解决方案。但是，作为数据驱动方法的常见问题，交通数据的质量和组成对所生成的字典具有直接而实质的影响，因此会影响评估结果。此外，该框架还提取了每辆车的加速度，速度，相对速度和与前车的间隙距离，以描述车辆的瞬时状态。为了更好地捕获用于字典学习的交通模式，还应考虑并提取交通流量的更多功能，包括车辆运动学约束，道路限制和驾驶员特征。对于宏观交通仿真，有必要开发保真度度量标准，以总的方式衡量交通流量，包括流量密度和速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>最后，对于自动驾驶，解决自动驾驶车辆与其他道路使用者之间的相互作用仍然是一个挑战。现有的模拟器认为两方之间的相互影响较小。举个例子，在Apollo模拟平台[apo18]和[BNP * 18]的工作中，两种模拟都实现了两种非车辆交通参与者：行人和骑自行车的人。但是，这些非车辆代理的行为是预先定义的，因此它们无法实时响应车辆。此外，尽管在CARLA [DRC * 17]中引入了动态行人，但车辆和行人之间的交互仍以简单，预先指定的方式处理：行人将在行进前检查附近是否有车辆，然后继续行进无需进一步检查。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>7结论</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>自将近60年以来，用于建模和模拟交通流的方法已经取得了长足的进步。在计算机图形学中，近十年来提出了各种基于交通流模型的交通模拟技术。此外，随着传感技术的进步，已提出了许多数据驱动的方法来开发交通动画和模拟。来自各种传感器的交通数据量的增加也可以有助于自动驾驶算法的开发和测试。</p><p style=text-align:justify><br></p><p style=text-align:justify>在本报告中，我们调查了主要的交通模拟和动画技术，重点是但不限于从计算机图形学角度进行的讨论。这些方法的子集专注于基于宏观，微观和介观流动模型模拟交通流。其他方法利用收集的交通数据来重建交通，合成新的交通流或了解各种交通模式的特征。还讨论了虚拟流量的各种评估和验证技术。</p><p style=text-align:justify><br></p><p style=text-align:justify>作为重要的应用，还介绍了使用交通模拟的自动驾驶技术的最新发展。特别是，我们专注于为自动驾驶开发创建的数据驱动方法，运动计划技术，决策算法和模拟器。我们还探讨了一些研究挑战和未来方向。</p><p style=text-align:justify><br></p><p style=text-align:justify>总之，交通模拟和动画将继续发展和进步。许多令人兴奋的应用程序和新颖的方法仍有待探索和开发。在自动驾驶研究方面，我们相信本次调查中讨论的各种模型和应用将在未来几年内激发有趣的研究主题。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'视觉','自动','驾驶中'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>