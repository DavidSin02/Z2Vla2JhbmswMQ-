<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>爬虫平台Crawlab核心原理--自动提取字段算法 | 极客快訊</title><meta property="og:title" content="爬虫平台Crawlab核心原理--自动提取字段算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5524e89.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5524e89.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5524e89.html><meta property="article:published_time" content="2020-10-29T20:59:31+08:00"><meta property="article:modified_time" content="2020-10-29T20:59:31+08:00"><meta name=Keywords content><meta name=description content="爬虫平台Crawlab核心原理--自动提取字段算法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/5524e89.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>爬虫平台Crawlab核心原理--自动提取字段算法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>⚠注意: 可配置爬虫现在仅在Python版本（v0.2.1-v0.2.4）可用，在最新版本Golang版本（v0.3.0）还暂时不可用，后续会加上，请关注近期更新</strong></p><p>背景</p><p>实际的大型爬虫开发项目中，爬虫工程师会被要求抓取监控几十上百个网站。一般来说这些网站的结构大同小异，不同的主要是被抓取项的提取规则。传统方式是让爬虫工程师写一个通用框架，然后将各网站的提取规则做成可配置的，然后将配置工作交给更初级的工程师或外包出去。这样做将爬虫开发流水线化，提高了部分生产效率。但是，配置的工作还是一个苦力活儿，还是非常消耗人力。因此，<strong>自动提取字段</strong>应运而生。</p><p>自动提取字段是Crawlab在中在基础上开发的新功能。它让用户不用做任何繁琐的提取规则配置，就可以自动提取出可能的要抓取的列表项，做到真正的“一键抓取”，顺利的话，开发一个网站的爬虫可以半分钟内完成。市面上有利用机器学习的方法来实现自动抓取要提取的抓取规则，有一些可以做到精准提取，但遗憾的是平台要收取高额的费用，个人开发者或小型公司一般承担不起。</p><p>Crawlab的自动提取字段是根据人为抓取的模式来模拟的，因此不用经过任何训练就可以使用。而且，Crawlab的自动提取字段功能不会向用户收取费用，因为Crawlab本身就是免费的。</p><p>算法介绍</p><p>算法的核心来自于人的行为本身，通过查找网页中看起来像列表的元素来定位列表及抓取项。一般我们查找列表项是怎样的一个过程呢？有人说：这还不容易吗，一看就知道那个是各列表呀！兄弟，拜托… 咱们是在程序的角度谈这个的，它只理解HTML、CSS、JS这些代码，并不像你那样智能。</p><p>我们识别一个列表，首先要看它是不是有很多类似的子项；其次，这些列表通常来说看起来比较“复杂”，含有很多看得见的元素；最后，我们还要关注分页，分页按钮一般叫做“下一页”、“下页”、“Next”、“Next Page”等等。</p><p>用程序可以理解的语言，我们把以上规则总结如下：</p><p><strong>列表项</strong></p><p><strong>列表子项</strong></p><p><strong>分页</strong></p><p>这样，我们就设计好了自动提取列表项、列表子项、分页的规则。剩下的就是写代码了。我知道这样的设计过于简单，也过于理想，没有考虑到一些特殊情况。后面我们将通过在一些知名网站上测试看看我们的算法表现如何。</p><p>算法实现</p><p>算法实现很简单。为了更好的操作HTML标签，我们选择了库作为HTML的操作库。是python的一个解析库，支持HTML和XML的解析，支持XPath、CSS解析方式，而且解析效率非常高。</p><p>自上而下的遍历语法是。是，而会从根节点自上而下遍历各个元素，直到遍历完所有元素。它是一个。</p><p>构造解析树</p><p>在获取到页面的HTML之后，我们需要调用中的方法构造解析树。代码很简单如下，其中为的</p><p>这段带代码在方法里。源码请见。</p><p>辅助函数</p><p>在开始构建算法之前，我们需要实现一些辅助函数。所有函数是封装在类中的，所以写法与类方法一样。</p><pre></pre><p>获取列表项</p><p>下是核心中的核心！同学们请集中注意力。</p><p>们来编写获取列表项的代码。以下是获得列表标签候选列表的代码。看起来稍稍有些复杂，但其实逻辑很简单：对于每一个节点，我们获得所有子节点（一级），过滤出高于阈值（默认10）的节点，然后过滤出节点的子标签类别唯一的节点。这样候选列表就得到了。</p><p>接下来我们将从候选列表中筛选出包含最多文本子节点的节点。听起来有些拗口，打个比方：一个电商网站的列表子项，也就是产品项，一定是有许多例如价格、产品名、卖家等信息的，因此会包含很多文本节点。我们就是通过这种方式过滤掉文本信息不多的列表（例如菜单列表、类别列表等等），得到最终的列表。在代码里我们存为。</p><pre></pre><p>，我们将生成列表项的CSS选择器。以下代码实现的逻辑主要就是根据上面得到的目标标签根据其或属性来生成CSS选择器。</p><p>找到目标列表项之后，我们需要做的就是将它下面的文本标签和超链接标签提取出来。代码如下，就不细讲了。感兴趣的读者可以看来理解。</p><pre></pre><p>的代码很简单，实现也很容易，就不多说了，大家感兴趣的可以看</p><p>我们就实现了提取列表项以及列表子项的算法。</p><p>用方法</p><p>要用自动提取字段，首先得安装Crawlab。如何安装请查看。</p><p>rawlab安装完毕运行起来后，得创建一个<strong>可配置爬虫</strong>，详细步骤请参考。</p><p>完毕后，我们来到创建好的可配置爬虫的爬虫详情的<strong>配置</strong>标签，输入<strong>开始URL</strong>，点击<strong>提取字段</strong>按钮，Crawlab将从开始URL中提取列表字段。</p><p>来，点击预览看看这些字段是否为有效字段，可以适当增删改。可以的话点击运行，爬虫就开始爬数据了。</p><p>，你需要做的就是这几步，其余的交给Crawlab来做就可以了。</p><p>结果</p><p>本文在对排名前10的电商网站上进行了测试，仅有3个网站不能识别（分别是因为“动态内容”、“列表没有id/class”、“lxml定位元素问题”），成功率为70%。读者们可以尝试用Crawlab自动提取字段功能对你们自己感兴趣的网站进行测试，看看是否符合预期。结果的详细列表如下。</p><p>awlab的算法当然还需要改进，例如考虑动态内容和列表没有id/class等定位点的时候。也欢迎各位前来试用，甚至贡献该项目。</p><p><strong>ithub</strong>:</p><p>您觉得Crawlab对您的日常开发或公司有帮助，请加作者微信拉入开发交流群，大家一起交流关于Crawlab的使用和开发。</p><p>&lt;/p</p><p><strong>本篇文章由一文多发平台ArtiPub自动发布</strong>. https://github.com/crawlab-team/artipub</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'爬虫平','Crawlab','--'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>