<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器学习：神经网络学习之多层前馈神经网络（二） | 极客快訊</title><meta property="og:title" content="机器学习：神经网络学习之多层前馈神经网络（二） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/dfic-imagehandler/2d53a815-ab09-4da3-94a2-5b6843366e3a"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/556321d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/556321d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/556321d.html><meta property="article:published_time" content="2020-10-29T21:05:34+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:34+08:00"><meta name=Keywords content><meta name=description content="机器学习：神经网络学习之多层前馈神经网络（二）"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/556321d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器学习：神经网络学习之多层前馈神经网络（二）</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>现实任务中使用神经网络时，大多是在使用BP算法进行训练。BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，比如递归神经网络。同样地，BP算法也不是完美的，可能会面临各种问题。</p><div class=pgc-img><img alt=机器学习：神经网络学习之多层前馈神经网络（二） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/dfic-imagehandler/2d53a815-ab09-4da3-94a2-5b6843366e3a><p class=pgc-img-caption></p></div><h1>结构学习问题</h1><p>多层前馈神经网络包括：输入层、输出层、一个或多个隐含层。输入层神经元的个数由输入的数据维度（连续属性）和编码方法（离散属性）确定；输出层神经元的个数由待分类的类别数目和编码方法确定。</p><p>只需要一个包含足够多神经元的隐含层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数。</p><p>如何确定隐含层神经元的个数仍然是个悬而未决问题。实际应用中通常是根据经验来确定或者靠“试错法”来调整。</p><h1>初始化问题</h1><p>在BP算法中，连接权和偏置在网络学习之前，都需要将其初始化为不同的小随机数。“不同”保证网络可以学习；“小随机数”可以防止其值过大而提前进入饱和状态，达到局部极小值。</p><p>解决办法：重新初始化。</p><h1>步长设置问题</h1><p>BP网络的收敛是基于无穷小的修改量，学习率控制着算法每一轮迭代中的更新步长。</p><p>步长太小，收敛速度就会过慢。步长太大，又可能会导致网络的不稳定，甚至瘫痪。因此，需要自适应步长，让步长随着网络的训练而不断变化。</p><h1>权值和阈值的更新问题</h1><p>基本的BP算法采用的是样例更新，即每处理一个训练样例就更新一次权值和阈值。样例更新的缺陷：参数更新频繁，不同样例可能抵消，需要迭代的次数较多。另外，训练样例的输入顺序对训练结果有较大影响，它更“偏爱”较后输入的样例。而给训练样例安排一个适当的顺序，又是非常困难的。</p><p>解决的方法就是采用周期更新，即每处理一遍所有的训练样例才更新一次权值和阈值。但在很多实际任务中，周期更新的累计误差下降到一定程度后，进一步下降会非常缓慢，这时样例更新往往会获得较好的解，尤其当训练集非常大时效果更明显。</p><h1>过拟合问题</h1><p>神经网络由于强大的表示能力，通常遭遇过拟合。具体表现为：训练误差持续降低，但测试误差却可能上升。</p><p>缓解过拟合的策略包括早停和正规化。早停就是在训练过程中，若训练误差降低，但验证误差升高，则停止训练；正则化就是误差目标函数中增加一项描述网络复杂程度的部分，比如连接权值和阈值的平方和。</p><div class=pgc-img><img alt=机器学习：神经网络学习之多层前馈神经网络（二） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/dfic-imagehandler/245c8224-a520-447d-a99e-e2ef1e0ab359><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'学习','神经','网络'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../cn/%E7%A7%91%E6%8A%80/9f3924a.html alt=机器学习：神经网络学习之多层前馈神经网络（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a0a4cd0f7d9244a6a12da3c0af6893a5 style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E6%8A%80/9f3924a.html title=机器学习：神经网络学习之多层前馈神经网络（一）>机器学习：神经网络学习之多层前馈神经网络（一）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>