<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析 | 极客快訊</title><meta property="og:title" content="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/bee309a50ea64a2ea56fbd698279eff2"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/55686102.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/55686102.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/55686102.html><meta property="article:published_time" content="2020-11-14T21:04:01+08:00"><meta property="article:modified_time" content="2020-11-14T21:04:01+08:00"><meta name=Keywords content><meta name=description content="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/55686102.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1><strong>InfluxDB 的存储机制解析</strong></h1><p>本文介绍了InfluxDB对于时序数据的存储/索引的设计。由于InfluxDB的集群版已在0.12版就不再开源，因此如无特殊说明，本文的介绍对象都是指 InfluxDB 单机版</p><p><strong>1. InfluxDB 的存储引擎演进</strong></p><p>尽管InfluxDB自发布以来历时三年多，其存储引擎的技术架构已经做过几次重大的改动, 以下将简要介绍一下InfluxDB的存储引擎演进的过程。</p><p>1.1 演进简史</p><ul><li>版本0.9.0之前</li></ul><pre>**基于 LevelDB的LSMTree方案**</pre><ul><li>版本0.9.0～0.9.4</li></ul><pre>**基于BoltDB的mmap COW B+tree方案**</pre><ul><li>版本0.9.5～1.2</li></ul><pre>**基于自研的 WAL + TSMFile 方案**（TSMFile方案是0.9.6版本正式启用，0.9.5只是提供了原型）</pre><ul><li>版本1.3～至今</li></ul><pre>**基于自研的 WAL + TSMFile + TSIFile 方案**</pre><p>1.2 演进的考量</p><p>InfluxDB的存储引擎先后尝试过包括LevelDB, BoltDB在内的多种方案。但是对于InfluxDB的下述诉求终不能完美地支持：</p><ul><li>时序数据在降采样后会存在大批量的数据删除</li></ul><pre>=&gt; *LevelDB的LSMTree删除代价过高*</pre><ul><li>单机环境存放大量数据时不能占用过多文件句柄</li></ul><pre>=&gt; *LevelDB会随着时间增长产生大量小文件*</pre><ul><li>数据存储需要热备份</li></ul><pre>=&gt; *LevelDB只能冷备*</pre><ul><li>大数据场景下写吞吐量要跟得上</li></ul><pre>=&gt; *BoltDB的B+tree写操作吞吐量成瓶颈*</pre><ul><li>存储需具备良好的压缩性能</li></ul><pre>=&gt; *BoltDB不支持压缩*</pre><p>此外，出于技术栈的一致性以及部署的简易性考虑（面向容器部署），InfluxDB团队希望存储引擎 与 其上层的TSDB引擎一样都是用GO编写，因此潜在的RocksDB选项被排除</p><p>基于上述痛点，InfluxDB团队决定自己做一个存储引擎的实现。</p><p><strong>2 InfluxDB的数据模型</strong></p><p>在解析InfluxDB的存储引擎之前，先回顾一下InfluxDB中的数据模型。</p><p>在InfluxDB中，时序数据支持多值模型，它的一条典型的时间点数据如下所示：</p><p>图 1</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/bee309a50ea64a2ea56fbd698279eff2><p class=pgc-img-caption></p></div><ul><li>measurement:</li></ul><pre>指标对象，也即一个数据源对象。每个measurement可以拥有一个或多个指标值，也即下文所述的**field**。在实际运用中，可以把一个现实中被检测的对象（如：“cpu”）定义为一个measurement</pre><ul><li>tags:</li></ul><pre>概念等同于大多数时序数据库中的tags, 通常通过tags可以唯一标示数据源。每个tag的key和value必须都是字符串。</pre><ul><li>field:</li></ul><pre>数据源记录的具体指标值。每一种指标被称作一个“field”，指标值就是 “field”对应的“value”</pre><ul><li>timestamp:</li></ul><pre>数据的时间戳。在InfluxDB中，理论上时间戳可以精确到 **纳秒**（ns）级别</pre><p>此外，在InfluxDB中，measurement的概念之上还有一个对标传统DBMS的 Database 的概念，逻辑上每个Database下面可以有多个measurement。在单机版的InfluxDB实现中，每个Database实际对应了一个文件系统的 目录。</p><p>2.1 Serieskey的概念</p><p>InfluxDB中的SeriesKey的概念就是通常在时序数据库领域被称为 时间线 的概念, 一个SeriesKey在内存中的表示即为下述字符串(逗号和空格被转义)的 字节数组(github.com/influxdata/influxdb/model#MakeKey())</p><blockquote><p>{measurement名}{tagK1}={tagV1},{tagK2}={tagV2},...</p></blockquote><p>其中，SeriesKey的长度不能超过 65535 字节</p><p>2.2 支持的Field类型</p><p>InfluxDB的Field值支持以下数据类型:</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/83ac562ef8d3418e8efec8e5c9b88170><p class=pgc-img-caption></p></div><p>在InfluxDB中，Field的数据类型在以下范围内必须保持不变，否则写数据时会报错 类型冲突。</p><blockquote><p>同一Serieskey + 同一field + 同一shard</p></blockquote><p>2.3 Shard的概念</p><p>在InfluxDB中， 能且只能 对一个Database指定一个 Retention Policy (简称:RP)。通过RP可以对指定的Database中保存的时序数据的留存时间(duration)进行设置。而 Shard 的概念就是由duration衍生而来。一旦一个Database的duration确定后, 那么在该Database的时序数据将会在这个duration范围内进一步按时间进行分片从而时数据分成以一个一个的shard为单位进行保存。</p><p>shard分片的时间 与 duration之间的关系如下</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/321e854e6ebf4504aedefce7370ef432><p class=pgc-img-caption></p></div><p>新建的Database在未显式指定RC的情况下，默认的RC为 数据的Duration为永久，Shard分片时间为7天</p><p>注: 在闭源的集群版Influxdb中，用户可以通过RC规则指定数据在基于时间分片的基础上再按SeriesKey为单位进行进一步分片</p><p><strong>3. InfluxDB的存储引擎分析</strong></p><p>时序数据库的存储引擎主要需满足以下三个主要场景的性能需求</p><ol><li>大批量的时序数据写入的高性能</li><li>直接根据时间线(即Influxdb中的 Serieskey )在指定时间戳范围内扫描数据的高性能</li><li>间接通过measurement和部分tag查询指定时间戳范围内所有满足条件的时序数据的高性能</li></ol><p>InfluxDB在结合了1.2所述考量的基础上推出了他们的解决方案，即下面要介绍的 WAL + TSMFile + TSIFile的方案</p><p>3.1 WAL解析</p><p>InfluxDB写入时序数据时为了确保数据完整性和可用性，与大部分数据库产品一样，都是会先写WAL,再写入缓存，最后刷盘。对于InfluxDB而言，写入时序数据的主要流程如同下图所示：</p><p>图 2</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad3705a14c3549c8b4b23db4f1700018><p class=pgc-img-caption></p></div><p>InfluxDB对于时间线数据和时序数据本身分开，分别写入不同的WAL中，其结构如下所示：</p><p>索引数据的WAL</p><p>由于InfluxDB支持对Measurement，TagKey，TagValue的删除操作，当然随着时序数据的不断写入，自然也包括 增加新的时间线，因此索引数据的WAL会区分当前所做的操作具体是什么，它的WAL的结构如下图所示</p><p>图 3</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/40d2d262e4504794b5fbcd54a475b723><p class=pgc-img-caption></p></div><p>时序数据的WAL</p><p>由于InfluxDB对于时序数据的写操作永远只有单纯写入，因此它的Entry不需要区分操作种类，直接记录写入的数据即可</p><p>图 4</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a8b4a1aa22f54bab888ed1bd9e716d6e><p class=pgc-img-caption></p></div><p>3.2 TSMFile解析</p><p>TSMFile是InfluxDB对于时序数据的存储方案。在文件系统层面，每一个TSMFile对应了一个 Shard。</p><p>TSMFile的存储结构如下图所示:</p><p>图 5</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b8bfdb87ab4c42da99fba55ae37483c5><p class=pgc-img-caption></p></div><p>其特点是在一个TSMFile中将 时序数据（i.e Timestamp + Field value）保存在数据区；将Serieskey 和 Field Name的信息保存在索引区，通过一个基于 Serieskey + Fieldkey构建的形似B+tree的文件内索引快速定位时序数据所在的 数据块</p><p>注： 在当前版本中，单个TSMFile的最大长度为2GB，超过时即使是同一个Shard，也会继续新开一个TSMFile保存数据。本文的介绍出于简单化考虑，以下内容不考虑同一个Shard的TSMFile分裂的场景</p><ul><li>索引块的构成</li></ul><pre>上文的索引块的构成，如下所示：*图 6*</pre><ul><li><br></li></ul><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0a56782314bd47e198b53d73eef41925><p class=pgc-img-caption></p></div><ul><li><br></li></ul><pre>其中 **索引条目** 在InfluxDB的源码中被称为`directIndex`。在TSMFile中，索引块是按照 Serieskey + Fieldkey **排序** 后组织在一起的。明白了TSMFile的索引区的构成，就可以很自然地理解InfluxDB如何高性能地在TSMFile扫描时序数据了：1. 根据用户指定的时间线（Serieskey）以及Field名 在 **索引区** 利用二分查找找到指定的Serieskey+FieldKey所处的 **索引数据块**2. 根据用户指定的时间戳范围在 **索引数据块** 中查找数据落在哪个（*或哪几个*）**索引条目**3. 将找到的 **索引条目** 对应的 **时序数据块** 加载到内存中进行进一步的Scan*注：上述的1，2，3只是简单化地介绍了查询机制，实际的实现中还有类似扫描的时间范围跨索引块等一系列复杂场景*&lt;br&gt;</pre><ul><li>时序数据的存储</li><li>在图 2中介绍了时序数据块的结构：即同一个 Serieskey + Fieldkey 的 所有时间戳 - Field值对被拆分开，分成两个区：Timestamps区和Value区分别进行存储。它的目的是：实际存储时可以分别对时间戳和Field值按不同的压缩算法进行存储以减少时序数据块的大小</li><li>采用的压缩算法如下所示：</li><li class=ql-indent-1>Timestamp： <a class=pgc-link href=http://www.vldb.org/pvldb/vol8/p1816-teller.pdf target=_blank>Delta-of-delta encoding</a></li><li>Field Value：由於单个数据块的Field Value必然数据类型相同，因此可以集中按数据类型采用不同的压缩算法</li><li class=ql-indent-2>Float类: <a class=pgc-link href=http://www.vldb.org/pvldb/vol8/p1816-teller.pdf target=_blank>Gorrila's Float Commpression</a></li><li class=ql-indent-2>Integer类型: Delta Encoding + Zigzag Conversion + RLE / Simple8b / None</li><li class=ql-indent-2>String类型: <a class=pgc-link href=https://github.com/golang/snappy target=_blank>Snappy Compression</a></li><li class=ql-indent-1>Boolean类型: Bit packing</li><li>做查询时，当利用TSMFile的索引找到文件中的时序数据块时，将数据块载入内存并对Timestamp以及Field Value进行解压缩后以便继续后续的查询操作。</li></ul><p>3.3 TSIFile解析</p><p>有了TSMFile，第3章开头所说的三个主要场景中的场景1和场景2都可以得到很好的解决。但是如果查询时用户并没有按预期按照Serieskey来指定查询条件，而是指定了更加复杂的条件，该如何确保它的查询性能？通常情况下，这个问题的解决方案是依赖倒排索引(Inverted Index)。</p><p>InfluxDB的倒排索引依赖于下述两个数据结构</p><ul><li>map&lt;SeriesID, SeriesKey></li><li>map&lt;tagkey, map&lt;tagvalue, List&lt;SeriesID>>></li></ul><p>它们在内存中展现如下：</p><p>图 7</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c9d39faccc664b6da92b4bb590441dcd><p class=pgc-img-caption></p></div><p>图 8</p><div class=pgc-img><img alt="时序数据库连载系列: 时序数据库一哥InfluxDB之存储机制解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/55d1ce28c4204183a85fb05b370b5b84><p class=pgc-img-caption></p></div><p>但是在实际生产环境中，由于用户的时间线规模会变得很大，因此会造成倒排索引使用的内存过多，所以后来InfluxDB又引入了 TSIFile</p><p>TSIFile的整体存储机制与TSMFile相似，也是以 Shard 为单位生成一个TSIFile。具体的存储格式就在此不赘述了。</p><p><strong>4. 总结</strong></p><p>以上就是对InfluxDB的存储机制的粗浅解析，由于目前所见的只有单机版的InfluxDB，所以尚不知道集群版的InfluxDB在存储方面有哪些不同。但是，即便是这单机版的存储机制，也对我们设计时序数据库有着重要的参考意义。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'时序','数据库','连载'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../cn/%E7%A7%91%E6%8A%80/2aa8e0f7.html alt=时序数据库连载系列：时序数据库那些事 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/125534ddebc242d5ad4694adcd1602aa style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E6%8A%80/2aa8e0f7.html title=时序数据库连载系列：时序数据库那些事>时序数据库连载系列：时序数据库那些事</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>