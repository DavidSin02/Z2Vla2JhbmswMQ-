<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>自然语言处理入门：简单，快速和深入 | 极客快訊</title><meta property="og:title" content="自然语言处理入门：简单，快速和深入 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/e8a2f1a7e8df45669983281db34d6099"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6033abd.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6033abd.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6033abd.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="自然语言处理入门：简单，快速和深入"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/6033abd.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>自然语言处理入门：简单，快速和深入</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e8a2f1a7e8df45669983281db34d6099><p class=pgc-img-caption></p></div><p><strong>什么是自然语言处理（NLP）？</strong></p><p>简单来说，我们可以说，NLP意味着处理和分析文本数据。</p><p><em>技术定义：</em></p><blockquote><p><strong>自然语言处理是计算机科学，信息工程和人工智能的子领域，涉及计算机和人类语言之间的交互，特别是如何对计算机进行编程以处理和分析大量自然语言数据。</strong></p></blockquote><p><strong>NLP有什么用？或者我们为什么需要NLP？</strong></p><p>在互联网时代，生成的大多数数据都是原始文本格式，实际上是非结构化数据。除非进行处理和分析，否则此数据无用。我们使用NLP技术将“数据转换为信息”。使用NLP我们可以深入了解数据，我们也可以根据数据结果采取行动。</p><p>一些使用NLP的应用程序：</p><p><em>情感分析</em>：分析文本是正面还是负面，</p><p><em>自动摘要：</em>总结数据的含义，</p><p><em>文本分类：</em>将数据组织成预定义的类别。</p><p>为了理解NLP实际上做了什么，我们将制作一个关于情绪分析的示例项目，以检查给定的评论是积极的还是消极的。</p><p>例：</p><p>这个食物非常好吃。<em>（正面陈述）</em></p><p>这个食物不好吃。<em>（否定声明）</em></p><p><strong>先决条件：</strong></p><p>用Python编程（基础知识）</p><p>机器学习的基础知识</p><p>朴素贝叶斯 - 机器学习算法</p><p>Getting hand's dirty<strong>：</strong></p><p>NLP可以使用机器学习和深度学习来完成。</p><p>首先，我们需要安装自然语言处理工具包（<strong>nltk</strong>）。 https://www.nltk.org/install.html</p><pre>import ntlknltk.download()</pre><p>在应用任何NLP /机器学习算法之前，我们需要清理文本，我们需要以适当的格式进行，以便可以对其应用处理和分析功能。</p><p><strong>导入数据集： -</strong></p><p>可以在superdatascience.com上<em>找到最简单的情绪分析数据集</em>。仅包含1000个数据集另外还有“Review”和“likes”。</p><blockquote><p><strong>注意：<em> </em></strong><em>下载文件中的代码与本文中的代码不同，因此不要直接运行代码，否则可能会导致意外行为。</em></p></blockquote><p>由于数据集非常小，我们无法进行探索性数据分析。但是，如果数据集很大并且具有许多功能（列），我们需要探索和分析哪些数据需要进行分析，哪些数据可以跳过。</p><p><strong>文本整理步骤： -</strong></p><ol><li>删除重复项</li><li>删除标点符号</li><li>删除数字，字母数字</li></ol><p>我们需要删除重复的条目，因为它们可能会影响我们的准确性，同时预测输出（因为我们的数据集太小而且列数较少，所以很难找到和删除重复）。此外，标点符号在评论中没有太多意义，因此可以将其删除。数字和字母数字也可以删除，其他无用的也可以删除，我们只是分析它是积极的还是消极的。</p><p>我们可以使用正则表达式来删除标点符号，或者我们可以使用一些内置库。</p><p><strong>文本预处理步骤： -</strong></p><ol><li>标记</li><li>移除停用词</li><li>词干提取</li><li>词形还原</li></ol><p><strong>标记：</strong>在分析中，我们更重视某些具有意义的单词并删除无意义的单词（停用词）。所以，我们必须处理文字而不是完整的句子<strong>。</strong>因此，最好将数据划分为较小的块。将数据，文本划分为较小的块（或符号）的过程称为标记。使用标记，我们可以更多地重视单词而不是句子。通过这种方式，我们可以通过查看特定单词轻松检查评论是正面还是负面。</p><p><strong>移除停用词：</strong>在一个句子中，有许多额外的单词。示例：<strong>is，and，are，</strong>等等。这些单词不会对句子添加任何含义。所以，我们可以删除它们。</p><p>将所有单词设为小写将有助于识别和删除相同的单词，这将有助于我们减少<strong>Bag of Words</strong>中的<strong>任何其他方法</strong>。</p><p><strong>词干提取：</strong>现在我们有单独的单词来执行分析，但有些单词具有相同的基础/根词。因此，我们可以合并它们或将它们作为单个单词，因为我们不希望增加要分析的数据的大小。词干将单词转换为其根形式。例如： <strong><em>sing, singing, singer belongs to the root word'sing'</em></strong>。所以，最好保留一个单词'sing'并删除剩下的单词。有时来自Stemmer的输出词没有意义。示例<strong>calves - > calv</strong>（Stemming方法实际上尝试删除后缀或替换后缀）。有3种常用的词干分析器，它们的比较如下：</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/43f61556fdb043f0ad4c50770339c795><p class=pgc-img-caption>不同词干的比较</p></div><p>我们可以在这里观察到，PorterStemmer最不严格，Lancaster最严格且速度非常快。Snowball stemmer在速度和严格性之间是一个很好的平衡。</p><p><strong>词形还原：</strong>就像词干提取一样，词形还原也会将单词转换为基本形式，只是它更先进。一个lemmatizer使用它的KnowledgeBase将单词转换为它的根形式。示例：<strong>Calves - > Calf</strong>（Noun Lemmatizer输出）。这里的lemmatizer不会删除后缀。下面是Noun Lemmatizer和Verd Lemmatizer之间的比较。您可以使用它们中的任何一个，但在整个代码中保持相同。</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e71277cb8b874da288366bf0f129e134><p class=pgc-img-caption></p></div><p>它使用一个名为WordNet的知识库。由于知识的原因，词形还原甚至可以转换具有不同拼写的词，但是词干提取不能解决，例如将“ <strong>came</strong> ” 转换为“ <strong>come</strong> ”。stemmers的输出可能毫无意义，但是lemmatizer的输出总是有意义的。</p><p><strong>词干提取或词形还原或两者</strong>：这一切都取决于数据集以及如何分析它。如果我们可以使用试错法，因为每个数据集都不相同，这样会更好。经过几次试验后，我们将清楚使用什么，词干提取或词形还原或两者兼而有之。</p><p>从我们的数据集中，我采取了极端的评论案例，其中有些人写了疯狂的评论，拼写错误，故意拼写错误来表达情感。现在检查哪个更好的词干提取或词形还原。</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/796f1d25957b43469e9b38106d8c6668><p class=pgc-img-caption>stemmers的输出</p></div><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/91c0c3b493424f1e862c60ae71bdf268><p class=pgc-img-caption>lemmatizer的输出</p></div><p>正如你所看到的，从试验中我发现<strong>SnowbalStemmer</strong>比其他 stemmers效果更好，甚至比lemmatizer更好。我会选择SnowballStemmer，但如果在完整的情绪分析结束时我的准确度不如预期，我可能会尝试不同的方法。</p><blockquote><p>机器学习不是关于模型的工作效率，而是模型的准确性。因此，我们不会在第一次尝试中获得最准确的结果，我们需要一次又一次地优化我们的方法。</p></blockquote><p>现在我们已经完成了文本的清理，预处理，我们需要分析和处理文本，为此，我们需要如下所述的策略和模型。</p><p><strong>分析文本的策略/模型：</strong></p><ol><li>Bag of Words</li><li>TF-IDF（术语频率*反文档频率）</li><li>Word2Vec</li><li>Average Word2Vec</li><li>TF-IDF weighted word2Vec</li></ol><p>我将仅解释这部分中的Bag of Words方法。</p><p>Bag of Words<strong>：</strong></p><p>我们的计算机无法直接对纯文本数据执行操作。因此，我们需要将数据转换为计算机可以理解的形式。计算机理解数字和数学的语言。我们需要将数据转换为称为<strong>vector</strong>的东西。并且可以在矢量上容易地执行数学运算。</p><p><strong>Vector</strong>只是一个尺寸为'n'的单维数组。</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f3aa19f1dbb24da1896808d070e1eb33><p class=pgc-img-caption></p></div><p>大小为n = 5的vector</p><p>矩阵是矢量的集合。一旦我们将评论转换为vector，我们就可以利用线性代数的力量来正确分析评论。<strong>两个相似矢量之间的距离将小于两个不相似矢量之间的距离</strong>。可以将矢量彼此进行比较，并且可以在彼此附近绘制/表示相似的矢量，并且可以在2D或3D或nD空间中彼此绘制/表示不相似的矢量。我们可以在n维空间中使用直线或平面来分离正负点组。通过这种方式，我们可以区分积极评论和负面评论。</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/86d47fd0ac084797a5bf988e0bed7df9><p class=pgc-img-caption></p></div><p>假设我们得到了d维空间中评论的向量表示，如上图所示。我们可以使用' <strong>w'（垂直于或垂直于平面）</strong>在d维空间中使用平面来分离它们<strong>。</strong>现在发现<strong>'w'</strong>是一个复杂的理论<strong>。因此，我们可以假设'w'方向上的矢量点可以被分类为正，而在'w'的相反方向上，即w ^ T（w-Transpose）是负的。</strong></p><p>审查也称为<strong>文件</strong>。评论或文档的集合称为<strong>语料库</strong>。</p><p>假设我们有3个预处理的评论（我们也将标记加入到单个句子中）</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/64bcbd749d9d424889aaf8689b44fd73><p class=pgc-img-caption>现在我们可以说我们有一个语料库</p></div><p>该<strong>文字包</strong>策略，在数据集中的所有评论转化为向量。因此，对于每次审核，都会有一个单独的向量。向量存储评论中每个单词的计数。Vector实际上将包含语料库中的所有单词。</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/754e6bb983c544d280f65c0f4929521f><p class=pgc-img-caption>语料库的实际向量和矩阵表示</p></div><p>正如模型的名称所示，“ <strong>Bag of words”，</strong>它创建了一个包（向量），其中包含文档中每个评论的单词数。您可以看到此矩阵是<strong>稀疏矩阵</strong>（包含大多数元素为零）。如果不进行预处理，矩阵会更稀疏，而且单词也会增加，从而降低效率，降低准确性。此外，通过使用小写字母，我们避免在向量中添加额外的条目。示例：<strong>如果没有小写，</strong> “ <strong>Food”</strong>和“<strong>food”将是向量中的单独条目/特征。</strong></p><p><strong>代码</strong>（单词包）：我们将使用CountVectorizer将我们的评论转换为向量。CountVectorizer可在Sci-Kit学习库（sklearn）中使用。</p><p>接下来的步骤是机器学习的基本步骤：</p><ol><li>将数据拆分为训练集和测试集。</li><li>将机器学习算法拟合到训练集。（这里我们将使用<strong>朴素贝叶斯机器学习算法</strong>）</li><li>预测测试集结果。</li><li>检查模型的准确性。</li></ol><p>朴素贝叶斯分类器假设向量中的一个特征独立于其他特征。因此，它认为每个特征将独立地有助于评估预测正面或负面的概率，而在特征之间没有任何相关性。</p><p>我们可以看到该模型的准确率为<strong>74％</strong>，这也不错。看一下我们观察到的混淆矩阵：</p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/422930dc94be4686ac1fc9a7c5bb700c><p class=pgc-img-caption></p></div><p>我们可以看到<strong>41条评论是假阳性，即它们是假的，但预测为真。</strong></p><p>发生这种情况是因为在删除停用词时，我们也删除了<strong>“not”。</strong>删除<strong>“not”</strong>可以完全改变评论的含义。</p><p>例：</p><ol><li>This place is not good. (original review)</li></ol><p>2. place good (removing stop words, meaning changes completely)</p><p><strong>uni-gram，bi-grams和 n-grams的概念</strong></p><p>为了处理上述情况，<strong>误报，我们需要一次处理多个单词。</strong></p><p>Uni-gram意味着一个单词。使用CountVectorizer将审阅转换为向量时，默认情况下我们使用uni-gram方法。它将单个单词转换为向量中的一个要素。</p><p>我们也可以使用bi-gram（2个单词）或tri-gram（3个单词）来处理像<strong>''not good'（bi-gram）</strong>，<strong>'not not tasty'这样的</strong>单词<strong>（tri-gram）。</strong>使用上述三元组是非常罕见的情况。</p><p>示例：评论 - <strong>Place is not that good as compared to others。</strong><em>（预处理后，不包括删除字）</em></p><div class=pgc-img><img alt=自然语言处理入门：简单，快速和深入 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d5444691434b4343961782310bdbf458><p class=pgc-img-caption></p></div><p>注意：现在，由于我们将在评论中使用“ <strong>not”</strong>，因此应避免删除<strong>“not”之</strong>类<strong>的</strong>停用词<strong>。</strong></p><p>我使用了 bi-gram 和 tri-gram，但是随着我增加n-gram范围，我的准确度不断提高，而不是获得更好的结果。对于tri-gram，我得到了<strong>73.5％</strong>的准确度<strong>（降低了0.5％）。但这可能是因为我避免删除“not”之类的停用词。使用自定义停用词可能不起作用。</strong></p><p><strong>结论：</strong></p><p><strong>对于NLP来说，Bag of Words非常原始的方法。我们看到删除停用词会降低我们的准确度，同时使用n-gram可能会增加，但我们还需要避免删除像“not”这样的停用词来构建n-gram。我们无法逐个手动删除停用词。因此，需要采取不同的方法。也许“TF-IDF”可能会提供更好的结果或任何其他机器学习方法或深度学习方法。</strong></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'语言','处理','入门'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>