<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>接近人类智能！一文读懂计算机视觉中的深度域适应 | 极客快訊</title><meta property="og:title" content="接近人类智能！一文读懂计算机视觉中的深度域适应 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/ea1685b1eae94732b5e0e6b8ee0a4856"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/617cb8a.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/617cb8a.html><meta property="article:published_time" content="2020-10-29T21:08:15+08:00"><meta property="article:modified_time" content="2020-10-29T21:08:15+08:00"><meta name=Keywords content><meta name=description content="接近人类智能！一文读懂计算机视觉中的深度域适应"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/617cb8a.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>接近人类智能！一文读懂计算机视觉中的深度域适应</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote>全文共<strong>4378</strong>字，预计学习时长<strong>8</strong>分钟</blockquote><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/ea1685b1eae94732b5e0e6b8ee0a4856><p class=pgc-img-caption>图片来源：pexels.com/@omarhouc</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>在过去十年里，人们在计算机视觉领域取得了巨大进步。这一进展主要归功于卷积神经网络（CNNs）。如果使用高质量带有注释的训练数据进行训练，卷积神经网络可以进行非常精确的预测。例如，在分类设置中，通常可以使用其中一种标准化网络体系架构（ResNet，VGG等），并使用数据集对其进行训练，其结果可能表现优异。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>另一方面，如果你没有为其特定问题提供庞大的手动注释数据集，卷积神经网络还能够通过迁移学习，利用其他为解决类似问题而训练过的网络。在这种情况下，你可以采用在大型数据集上预先训练的网络，并使用自己的小型注释数据集调整某些上层模块。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>两种方法都设定训练数据（无论其大小）代表了潜在分布。但是，如果测试时输入的数据与训练数据有明显的不同，那么可能就无法很好地执行模型。例如，假设一名自动驾驶汽车工程师，想要对汽车摄像头拍摄的图像进行分割，以便了解前方的情况（包括建筑物、树木、其他车辆、行人、交通信号灯等）。这名工程师可以为他在纽约市的数据集提供良好的人工生成的注释，并使用这些注释训练大型网络。如果在曼哈顿的街道上测试其自动驾驶汽车，那么系统能运转良好。而如果之后在巴黎测试相同的系统，好像突然间就会出现问题。汽车无法再检测到交通信号灯，每辆汽车看起来差异巨大（巴黎没有黄色出租车），街道看上去也不是笔直的。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>在这些情况下，模型的表现不佳，其原因在于问题域已发生了更改。在这种特殊情况下，在任务域（即分类）保持不变时，数据输入的域发生了变化。在其他情况下，人们可能想要使用来自同一域的数据（针对相同的潜在分布）来完成新任务。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>同样，输入域和任务域可能同时存在差异。在这些案例中，领域适应能给人带来帮助。领域适应是机器学习的子学科，处理在不同（但相关的）目标分布的背景下使用在信息源分布上训练的模型。一般而言，领域适应使用一个或多个源域中的标记数据来解决目标域中的新任务。因此，源域和目标域之间的相关性水平通常决定了领域适应的成功程度。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>目前有多种领域适应方法。在“浅层”（非深度）领域适应中，通常会用两种方法：重新测量源样本并对重新测量重的样本进行训练，并尝试学习共享空间以配合源数据集和目标数据集的分布。虽然这些技术也可以在深度学习的背景下进行应用，但深度神经网络（DNNs）所学的深度特征通常会产生更多可进行迁移的标志（通常在较浅层中学习可转移度高的特征，而较高层中的可转移性急剧下降）。在深度域适应中，我们尝试使用深度神经网络的这个属性。</p><p class=ql-align-justify><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2f16d4955c294ac1b1f857d1a63e3a28><p class=pgc-img-caption></p></div><h1 class=ql-align-center><strong>域适应类别</strong></h1><p class=ql-align-justify><br></p><p class=ql-align-justify>以下总结主要基于Wang等人的综述论文，以及威尔逊等人的综述。在该文章中，作者根据任务的复杂程度，将标记/未标记数据量以及输入特征空间的差异，对不同类型的领域适应进行区分。他们明确域适应的定义问题，在于任务空间相同，而仅在输入域散度中存在差异。基于该定义，域适应即可以是同构的（输入特征空间相同，但具有不同的数据分布），也可以是异构的（特征空间及其维度均有不同）。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>域适应也可以在一个步骤（一步式域适应）中发生，或者通过多个步骤发生，遍历过程中的一个或多个域（多步式域适应）。在这篇文章中，笔者将只讨论一步式领域适应，因为这是最常见的领域适应类型。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>基于从目标域中获得的数据，领域适应可以进一步分类为监督式（确实有来自目标域的标记数据，然而对于训练整个模型来说太小了），半监督式（同时拥有标记数据和未标记数据）和无监督式（没有来自目标域的任何标记数据）。</p><p class=ql-align-justify><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2f16d4955c294ac1b1f857d1a63e3a28><p class=pgc-img-caption></p></div><h1 class=ql-align-center><strong>任务相关性</strong></h1><p class=ql-align-justify><br></p><p class=ql-align-justify>如何确定在源域中训练的模型是否能够适应目标域？事实证明，这个问题并不容易解答，任务相关性仍然是人们积极研究的话题。如果人们使用相同的特征来做出决定，可以定义这两个任务是相似的。另外一种可能性是，如果它们的参数向量（即分类边界）相似，则可以定义这两个任务也是相似的（参考Xue等人的论文）。另一方面，大卫·本等人认为，如果通过使用一组转换值F，可以从固定的概率分布中生成两个任务的数据，则这两个任务和F是相关的。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>尽管有这些理论思考，但实际上，读者可能需要在自己的数据集上尝试领域适应，以查看是否可以通过使用源任务中的模型，帮助完成目标任务。一般而言，可以通过简单的推理来确定任务相关性，例如，在不同视角或不同照明条件下观察图像，或是在医学领域中，不同设备下观察图像等。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>一步式领域适应的技术和应用</p><p class=ql-align-justify><br></p><p class=ql-align-justify>一步式域适应有三种基本技术：</p><p class=ql-align-justify>· 基于差异的域适应；</p><p class=ql-align-justify>· 使用生成模型（GANs）或使用域混淆损失进行对抗式的域适应，以及</p><p class=ql-align-justify>· 使用栈式自动编码器（SAE）或生成模型重建域适应。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>基于分歧的域适应</p><p class=ql-align-justify><br></p><p class=ql-align-justify>基于发散的域适应通过最小化源和目标数据分布之间的一些发散标准来工作，从而实现域不变特征表示。如果找到这样的特征表示，则分类器便能够同时在两个域上执行良好。当然，首先需要假设存在这样的表示，才能反过来假设任务以某种方式相关。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>四种最常用的散度式度量分别是最大均值差异（MMD）、相关性对齐（CORAL）、对比域差异（CCD）和Wasserstein度量。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>最大均值差异是一种假设检验，通过比较特征的平均值并将其映射到再生核希尔伯特空间（RKHS）后，检验两个样本是否来自同一分布。如果平均值不同，则分布也可能不同。一般通过使用内核嵌入技巧，并使用高斯核比较样本来完成检验。可以这么说，如果两个分布相同，则来自每个分布的样本之间的平均（平均值）相似性，应该等于来自两个分布的混合样本之间的平均相似性。Rozantsev等人的文章中，就在领域适应中使用了最大均值差异。在本文中，双流架构使用的权重不会共享，但通过使用分类，正则化和域差异（MMD）损失的组合，会产生相似的特征表示。如下图所示。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/61a9beca8f12448db7b1f0ef6c8162ff><p class=pgc-img-caption>Rozantsev等人的双流架构</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>因此，该设置可以是监督式的，半监督式的或甚至是无监督式的（目标域中没有分类丢失）。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>CORAL（link）类似于MMD，但它尝试均衡源分布和目标分布的二阶统计量（统计），而不是使用线性变换的均值。Sun等人撰写的文章，通过使用源和目标协方差矩阵之间的Frobenius范数构造可区分的CORAL损失，在深度学习的背景下使用CORAL。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>以MMD为基础，CCD也能利用标签分布查看条件分布。这可以确保联合域特征仍然保留标签的预测性。最小化CCD可最大限度地减少类内差异，同时最大化类间差异，这需要源域和目标域的标签。为了摆脱这种束缚，Kang等人建议，在迭代过程中使用聚类来预估缺失的目标标签，该迭代过程能联合优化目标标签和特征表示。因此，通过聚类能找到目标标签，最小化CCD，从而适应这些特征。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>最后，通过考虑最优传输问题及其相应距离——Wasserstein距离，来均衡源域和目标域中的特征分布和标签分布。这是在DeepJDOT（Damodaran等人）中提出的。作者建议通过最佳运输模型，来最小化联合深层特征表示与标签之间的差异。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>基于对抗的域适应</p><p class=ql-align-justify><br></p><p class=ql-align-justify>该技术试图通过使用对抗训练来实现域适应。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>一种方法是使用生成式对抗网络（GAN）生成以某种方式与源域相关的合成目标数据（例如通过保留标签）。然后将这些合成数据用于训练目标模型。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>为实现这一点，CoGAN模型 CoGAN model试图通过对源分布和目标分布使用两对生成器/鉴别器，分享生成器和鉴别器的一些权重以学习域不变特征空间。通过这种方式，可以生成标记的目标数据，该数据能够进一步用于诸如分类的任务中。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/65dc0e54615749beabad6c58c648cdaa><p class=pgc-img-caption>CoGAN架构，来源Liu等人</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>在另一个装置中，Yoo等人尝试通过使用两个鉴别器来学习源/目标转换器网络：一个用于确保目标数据是真实的，另一个用于保证源域和目标域之间的相关性。因此，生成器以源数据作为条件。此方法仅需要目标域中的未标记数据。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>除了用于当前任务的分类损失之外，如果人们用到所谓的域混淆损失，也可以完全摆脱生成器，并一次性执行域适应。域混淆损失类似于GAN中的鉴别器，因为它试图匹配源域和目标域的分布，以便“混淆”高级分类层。有关这种网络最著名的例子，可能是Ganin等人的深度重建分类网络（DANN）。该网络由两个损失组成，即分类丢失和域混淆丢失。它包含一个梯度反转层以匹配特征分布。通过最小化源样本的分类损失和所有样本的域混淆损失（同时最大化特征提取的域混淆损失），这确保了样本对于分类器而言是无法相互区分的。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b86e5d82b8034392bf34b1ba19a86bcd><p class=pgc-img-caption>领域对抗式神经网络架构， 来源Ganin等人</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>基于重建的域适应</p><p class=ql-align-justify><br></p><p class=ql-align-justify>此方法使用辅助重建任务为每个域创建共享表示。例如，深度重建分类网络（DRCN）试图同时解决这两个任务：（i）源数据的分类，以及（ii）重建未标记的目标数据。这确保了网络学习不仅可以正确地进行区分，还可以保留有关目标数据的信息。在本文中，作者还提到重建管道学习，将源图像转换为类似于目标数据集的图像，这表明两者都学习了一个共同的表示。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cac8e2f8cd38480d890fddabd0240c0b><p class=pgc-img-caption>深度重建分类网络架构，来源Ghifaryet al.</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>使用CycleGANs是另一种可能性。Cycle GAN的灵感来自机器翻译中的双重学习概念。该概念同时训练两个相反的语言翻译器（A-B，B-A）。循环中的反馈信号由相应的语言模型和双语互译质量评估（BLEU）分数组成。使用im2im框架的图像同样能做到。在一篇文章的介绍中，网络学习从一个图像域到另一个图像域的映射，而不使用任何配对的图像样本。这是通过同时训练两个GAN，分别在两个域中生成图像。为确保一致性，引入使用循环一致性损失。这确保了一个域到另一个域的转换与返回，能生成与输入大致相同的图像。因此，两个配对网络的损失是两个鉴别器的GAN损失和周期一致性损失的总和。</p><p class=ql-align-justify><br></p><p class=ql-align-justify>最后，生成式对抗网络还可以通过调节来自另一个域的图像上的输入，来用于编码器 - 解码器设置。在Isola等人的论文中，通过调节鉴别器的输入和发生器的输出，条件性GANs能用来将图像从一个域转换到另一个域。简单的编码器 - 解码器架构，或者能跳过连接的U-Net架构都能实现这一点。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7a834989f32944bc89b972e13fc46149><p class=pgc-img-caption>从条件生成式对抗网络而来的几个结果，来源Isola等人</p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>深度域适应让人们将源任务上的特定深度神经网络上所学习的知识，传递给新的相关目标任务。深度域适应已成功应用于图像分类或风格转移等任务。在某种意义上，根据新的特定计算机视觉任务所需的训练数据量，深度域适应的功能表现更接近于人类智能。因此，笔者认为这一领域的进展，对于计算机视觉整个领域而言至关重要，笔者希望，深度域适应最终能引领人们在视觉任务中重用有效而简单的知识。</p><div class=pgc-img><img alt=接近人类智能！一文读懂计算机视觉中的深度域适应 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6cf33ea0fcda4042bd6ac4dc7a4341af><p class=pgc-img-caption></p></div><p>留言 点赞 关注</p><p>我们一起分享AI学习与发展的干货</p><p>欢迎关注全平台AI垂类自媒体 “读芯术”</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'人类','计算','机视觉'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>