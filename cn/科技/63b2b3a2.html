<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>浅谈图像风格迁移Style Transfer（二） | 极客快訊</title><meta property="og:title" content="浅谈图像风格迁移Style Transfer（二） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/53f60003fdfb3bdfb858"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/63b2b3a2.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/63b2b3a2.html><meta property="article:published_time" content="2020-11-14T21:03:55+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:55+08:00"><meta name=Keywords content><meta name=description content="浅谈图像风格迁移Style Transfer（二）"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/63b2b3a2.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>浅谈图像风格迁移Style Transfer（二）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/53f60003fdfb3bdfb858></p><h1>加快style stransfer</h1><p>在浅谈图像风格迁移Style Transfer（一） 中主要写了 Neural style以及fast neural style。 本篇讨论的一个主要的问题是解决在提取隐藏层的patch上耗费大部分时间问题。</p><p>下面介绍的论文都秉承<strong>任意风格图一次前向直接出结果</strong></p><p><strong>A Learned representation for artistic style</strong></p><p>这个在ICLR 2017发表的文章，核心思想：<strong>many styles probably share some degree of computation</strong>.就是说，虽然我们可以用fast neural style根据很多不同的style训练不同的模型，但是这些模型的所有卷积层的权值都是一样的！</p><p>看原文比较容易：</p><p><code>we found a very surprising fact about the role of normalization in style transfer networks:</code></p><p><code>to model a style, it is sufficient to specialize scaling and shifting parameters after normalization to each specific style.</code></p><p><code>In other words, all convolutional weights of a style transfer network can be shared across many styles,</code></p><p><code>and it is sufficient to tune parameters for an affine transformation after normalization for each style.</code></p><p>他们把这个方法称为<code>condition instance normalization</code></p><p>z=γs(x−μσ)+βs</p><p>我们只要根据不同的style选择不同的参数γs和βs就行。这样的话，一次前向，就能生成N幅不同style的图像。这种方法只能生成指定数量的预先训练的style，还不能说是任意的。</p><p><strong>Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</strong></p><p>论文</p><p>这篇的话主要的思想是:加入了 adaptive instance normalization(AdaIN)层，主要是让生成图像特征与画的特征在 <strong>均值和方差</strong>上进行尽量相似。其实就是换了一种约束。原版的neural style是用二阶统计信息（协方差，用Gram矩阵）来进行匹配风格，但是也有用其他的，比如MRF loss（ombining markov random fields and convolutional neural networks for image synthesis.）， Adversarial loss(C. Li and M. Wand. Precomputed real-time texture synthesis with markovian generative adversarial networks. In ECCV,2016), 梯度直方图（P. Wilmot, E. Risser, and C. Barnes. Stable and controllable neural texture synthesis and style transfer using histogram losses. arXiv preprint arXiv:1701.08893 , 2017）， MMD损失（P. Wilmot, E. Risser, and C. Barnes. Stable and controllable neural texture synthesis and style transfer using histogram losses. arXiv preprint arXiv:1701.08893, 2017）等等吧。然后貌似均值和方差没有人用啊，所以他们就用了。</p><p>先说一下，Instance Normalization不同于不同的BN，它是每个例子的每个通道进行normalization的。</p><p>μnc(x)=1HW∑h=1H∑w=1Wxnchw</p><p>上篇说的CIN（condition Instance Normalization）</p><p>CIN(x;s)=γs(x−μ(x)σ(x))+βs</p><p><strong>他们学的是每种style图的这两个参数。但是这种仿射参数其实可以由style图的本身的统计信息来替代。</strong></p><p>所以如果我们把这两个仿射系数去掉，用style图像的方差和均值替代，那么就可以将CIN转换成任意风格的图像。</p><p>AdaIN(x,y)=σ(y)(x−μ(x)σ(x))+μ(y)</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/568500002a090fed4611></p><p>然而我个人觉得这种效果很差啊，生成的风格图呈现出很严重的“块状”效果。</p><p>代码：https://github.com/xunhuang1995/AdaIN-style</p><h1></h1><p>让style transfer更加的visual-pleasing</p><p><strong>Controlling Perceptual Factors in Neural Style Transfer</strong></p><p>这篇主要是从三个方面着手</p><p><strong>1. 颜色控制</strong></p><p>在以前的风格转换中，生成图的颜色都会最终变成style图的颜色，但是很多时候我们并不希望这样。其中一种方法是，将RGB转换成YIQ，只在Y上进行风格转换，因为I和Q通道主要是保存了颜色信息。</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/56810000c9c0b1ce8011></p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/56800003cd28b1e66b38></p><p><strong>2. 空间控制</strong></p><p>主要是加入R个引导通道。</p><p>唯一的区别是</p><p><strong>Frl(x)[:,i]=Trl∘Fl(x)[:,i]</strong></p><p>原版的是这样的，可以看到下面的生成图片，天空有一部分变成墙壁了。这是因为协方差来衡量一个分布存在不稳定性。（在 Risser E, Wilmot P, Barnes C. Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses[J]. 2017. 有提到这一点。）</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/567f00044372e2d9a0b8></p><p>如果加入了空间控制，那么</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/567f00044373d3423d26></p><p>如果再加上style II，那么得到如下，可以看到被style II所stransfer只有天空部分。</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/567f000443707e003d12></p><p>复现代码：https://github.com/leongatys/NeuralImageSynthesis</p><p><strong>Deep Photo Style Transfer（个人很喜欢）</strong></p><p>从最初的CNN做style transfer一年多，style transfer出来的都是“画”，并不是照片。直到17年3月份，Cornell和Adobe的这篇论文。</p><p>可以看到，这种风格转换可以使得生成图几乎看不出任何“画”的细节，如同照片一样。所谓“画”就是包含局部的扭曲，<strong>这篇论文成功抑制了这种扭曲，将style transfer变成颜色域的仿射变换。</strong></p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/567f00044376a7cbf4f6></p><p>可以看到，比如第四行，最右侧被子颜色成功变成第二幅的，而前两种方法都没法很好的进行颜色转换，并且前两种方法扭曲明显，比如墙壁的垂直边缘扭曲很明显，而这篇论文的方法就几乎没有这种现象。</p><p>他们还比较了其他一些”spatially-variant color transfer”的方法。效果明显更好。</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/568500002a0d796a747a></p><p>他们主要在传统损失函数中加入了一个”Photorealism regularization”项。由于是local color stransfer，所以他们采用 Matting Laplacian of Levin的方法，这种方法将灰度模板用RGB通道的局部仿射组合来表示。所以</p><p><strong>Lm=∑c=13Vc[O]TMIVv[O]</strong></p><p>其中，Vc[O]表示第c个通道的输出的向量化(Nx1)。关键点在于这个MI，这个值只和输出有关，Mi是NxN的。</p><p>此外，由于Gram矩阵自身是计算整幅图的协方差，并不是局部的，所以就先根据输入图像生成多个masks，然后将该图像标上一系列标签（天空、楼房、水等等），然后把这些模板作为额外通道直接concatenate上去就行。</p><p><strong>Lls+=∑c=1C12N2l,c∑ij(Gl,c[O]−Gl,c[S])2ij</strong></p><p><strong>Fl,c[O]=Fl[O]Ml,c[I]</strong></p><p><strong>Fl,c[S]=Fl[S]Ml,c[S]</strong></p><p>可以看到我们需要分别给C图和S图进行分割，还是挺麻烦的。</p><p>最终公式：</p><p><strong>Ltotal=∑l=1LαlLlc+Γ∑l=1LβlLls++λLm</strong></p><p>代码：https://github.com/luanfujun/deep-photo-styletransfer</p><p>顺带说一句，3月份公开的论文，现在才过了2个月不到，竟然已经差不多8800多颗star了。。大家挺喜欢这个工作的。。</p><h1></h1><p>其他方面</p><h1></h1><p>Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses</p><p>他们发现Gram矩阵用于style transfer的不稳定性，即两种完全不同的分布其Gram矩阵可能是一样的。</p><p>从而提出加入直方图信息来强化约束。用于纹理生成时可以生成更加符合参考图的纹理。</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/56810000c9c721153c9d></p><h1></h1><p>SON OF ZORN’S LEMMA TARGETED STYLE TRANSFER USING INSTANCE-AWARE SEMENTIC SEGMENTATION</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/568500002a0a2be8830f></p><p>以前都是整幅图stransfer的，然后他们想只对一幅图的单个物体进行stransfer，比如下面这幅图是电视剧Son of Zorn的剧照，设定是一个卡通人物生活在真实世界。他们还说这种技术可能在增强现实起作用，比如Pokemon go.</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/56820000c15e0e5c1f82></p><hr><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/568400003d5ad04df524></p><h1></h1><p>通过GAN的风格转换</p><p>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks（个人很喜欢）</p><p><img alt="浅谈图像风格迁移Style Transfer（二）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/56800003cd2ca32d77c1></p><p>这个就是一个对偶学习的思想。现在这种论文N多啊。比如discoGAN之类的。这个没什么好说的。</p><p>代码：Torch版本（论文原版）：https://github.com/junyanz/CycleGAN</p><p>Pytorch版本（仍旧是作者实现的）:https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'浅谈图','风格','迁移'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../cn/%E7%A7%91%E6%8A%80/cf9af8ca.html alt="浅谈图像风格迁移Style Transfer（一）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/53f60003fdfb3bdfb858 style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E6%8A%80/cf9af8ca.html title="浅谈图像风格迁移Style Transfer（一）">浅谈图像风格迁移Style Transfer（一）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>