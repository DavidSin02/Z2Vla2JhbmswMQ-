<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>使用机器学习的手写数字识别 | 极客快訊</title><meta property="og:title" content="使用机器学习的手写数字识别 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6cc52e2b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6cc52e2b.html><meta property="article:published_time" content="2020-11-14T21:05:10+08:00"><meta property="article:modified_time" content="2020-11-14T21:05:10+08:00"><meta name=Keywords content><meta name=description content="使用机器学习的手写数字识别"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/6cc52e2b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>使用机器学习的手写数字识别</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>机器学习和深度学习在计算机技术和人工智能中发挥着重要作用。通过深度学习和机器学习，可以减少识别，学习，预测和更多领域的人力。本文介绍了从著名的MNIST数据集识别手写数字（0到9），比较KNN，PSVM，NN和卷积神经网络等分类器的性能，准确性，时间，灵敏度，正产生率和特异性，使用不同的参数与分类器。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b><p class=pgc-img-caption>来自MNIST数据集的样本数字</p></div><p>无论是机器学习和深度学习的初学者还是已经练习多年的专家，手写数字识别仍然会获得非常广泛的关注。开发这样的系统包括用于理解手写数字的图像并将其分类为10位数（0-9）的机器。MNIST数据库中的手写数字在近年来已经在社区中广为人知，因为使用不同的分类器和参数以及预处理技术降低错误率，从线性分类器（1层NN）的12％错误率到达到0.23％的误差具有35个卷积神经网络层次的速率。本文的范围是比较不同分类器与不同的参数，并尝试实现近人类的性能。</p><p><strong>数字识别系统</strong></p><p>数字识别系统是一台机器的工作，用于训练自己或识别来自不同来源的数字，如电子邮件，银行支票，纸张，图像等，以及在不同的真实场景中，用于在计算机平板电脑或系统上进行在线手写识别，识别车辆号码板块，处理银行支票金额，手工填写的表格中的数字条目（比如 - 税表）等</p><p><strong>手写数字的问题</strong></p><p>手写数字并不总是具有相同的大小，宽度，方向和边距，因为它们与人的写作方式不同，因此一般的问题是由于数字之间的相似性（例如1和7）对数字进行分类， 5和6,3和8,2和5,2和7等等。当许多人用各种不同的笔迹书写一个数字时，这个问题就越多。最后，不同个体的笔迹的独特性和多样性也影响数字的形成和外观。</p><p><strong>MNIST数据集</strong></p><p>从MNIST数据集提供的样本总共有70,000个图像的手写数字，其包括训练集中的60,000个示例和测试集中的10,000个示例，两者都具有来自10位数（0到9）的标记图像。这是来自MNIST的一小部分，其中尺寸被标准化以适合20 * 20像素的盒子而不改变长宽比。手写数字是28 * 28灰度级图像形式的图像，表示图像以及第一列，作为每个图像的标签（0到9）。同样选择测试集的情况为10,000个图像，标签为0到9。</p><p><strong>Yann Lecun，Corinna Cortes</strong>和<strong>Christopher Burges</strong>开发了这个MNIST数据集，用于评估和改进手写数字分类问题的机器学习模型。MNIST数据集是从NIST的特殊数据集开发的，其中包括特殊数据库3（美国人口普查局员工）和特殊数据库1（高中学生），其中包含手写数字的二进制图像。早期的SD-3（特殊数据库-3）被认为是训练和SD-1（特殊数据库-1）作为测试集，具有更容易识别的SD-3级别。因此，为了在不同的学习分类器中保持挑战性，NIST数据集被混淆了。MNIST的划分来自SD-3的30,000个样本和来自SD-1的30,000个样本，其中约250个人参与。来自SD-3和剩余5个的5,000个样本，来自SD-1的000个样本形成不同的测试集。数字图像取自各种扫描数字，标准化大小并都已经居中对齐。这使其成为评估模型的优秀数据集，并允许机器学习的抱负者专注于深度学习和机器学习，而只需很少的数据清理。</p><p>谈到与标准MNIST相似的更新或更多修改版本，2017年出现了EMNIST或扩展MNIST，其中训练集中的2,40,000个图像的样本以及测试集中的40,000个图像的增量由手写的数字组成。</p><p><strong>数据集中的可用文件</strong></p><p>因此，在深入探讨本主题之前，最好的方法是熟悉所提供的数据集。以下几点与训练和测试集以及图像和标签文件集相同 -</p><ol><li>像素按行排列，从0到255不等，与RGB颜色代码一样。</li><li>背景为白色（RGB值为0），前景为黑色（RGB值为255）。</li><li>数字标签从0到9分类。</li></ol><p><strong>有4个训练和测试文件：</strong></p><p>1.训练集图像文件（train-images-idx3-ubyte） -</p><p>2.训练集标签文件（train-labels-idx1-ubyte） -</p><p>3.测试集图像文件（t10k-images-idx3-ubyte） -</p><p>4.测试集标签文件（t10k-labels-idx1-ubyte） -</p><p><strong>更好地理解数据集</strong></p><p>MNIST数据集以IDX格式提供。这种IDX文件格式是一种简单的格式，在使用不同数值类型的向量和高维矩阵进行操作时非常方便。从文件格式的description列中的数字开始。我们可以将其定义为整数值（比如MSB优先），其中前2个字节总是为零。这给了我们以下信息：</p><ol><li>0000（2个字节）通知文件的开头。</li><li>08告诉我们第三个字节是无符号字节类型。</li><li>第4个字节0​​3告诉我们矩阵有三个维度，01只用一个维度。</li></ol><p>第3个字节表示数据是整数、浮点数、短整数、长整数还是无符号类型。第4个字节表示向量或矩阵的维数，即行和列的数量。如果它等于1，则它是一个向量，否则它是一个矩阵。items变量的数量也首先被读作MSB。</p><p><strong>从IDX更改为更简单的CSV</strong></p><p>由于我们的数据集以IDX格式提供，我们可以通过算法将数据集更改为CSV格式，我们可以用CSV实现MNIST数据集格式。</p><p><strong>为了更好地理解CSV：</strong></p><ol><li>第一列或值是“标签”，即手写应该分类的实际真实数字，例如“7”或“9”。这是分类器渴望分类的正确解决方案。</li><li>剩余值或所有逗号分隔值是手写数字的像素值强度，从0到255不等。图像的大小为28乘28，因此标签的值为784（28 * 28） 。</li></ol><p><strong>分类器</strong></p><p>在本节中，我们将讨论机器学习和深度学习的各种算法，以便进行预测和准确性。机器学习中的分类器 -</p><p><strong>KNN（K nearest neighbors（K最近邻））</strong></p><p>KNN是用于分类和回归问题的非参数方法或分类器。这是延迟或晚期学习分类算法，其中所有计算都被导出直到分类的最后阶段，以及这是基于实例的学习算法，其中近似是在局部进行的。最简单和最容易实现，没有明确的训练阶段，并且算法不执行任何训练数据的泛化。</p><p><strong>什么时候用？</strong>直接解决方案是当这些是类之间的非线性决策边界时，或者当数据量足够大时。输入特征本质上可以是定性的和定量的。而输出要素可以是分类值，这些值是数据中看到的典型类。</p><p><strong>KNN</strong>使用K个最近邻的多数选择来解释分类值，其中K的值可以不同，因此在改变K的值时，选择的数值也可以变化。</p><p><strong>假设</strong></p><ol><li>作为非参数，该算法不对基础数据假设做出任何假设。</li><li>根据数据选择参数K.</li><li>需要距离度量来定义任意两个数据点之间的接近度。该距离可以从欧几里德距离，马哈拉诺比斯距离，汉明距离等计算得出。</li></ol><p><strong>算法</strong></p><ol><li>计算测试数据点和所有标记数据点之间的距离度量。</li><li>按照距离度量的递增顺序对标记的数据点进行排序。</li><li>选择前K个标记的数据点并查看类标签。</li><li>查找大多数这些K标记数据点具有的类标签，并将其分配给测试数据点。</li></ol><p><strong>需要考虑的事项 -</strong></p><ol><li>参数选择 - K的最佳选择取决于数据。较大的K值降低了噪声对分类的影响，但使得无类别之间的决策边界不同。较小的K值往往受到噪声的影响，并且类之间有明显的分离。</li><li>存在噪声</li><li>特征选择和缩放 - 减少不相关的特征非常重要。当特征数量太大并且怀疑是高度冗余时，将需要提取特征。如果仔细选择这些功能，那么预计分类会更好。</li><li>维度的灾难</li></ol><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a376afabe9a744bb81b15f889dc3c949><p class=pgc-img-caption>案例1（K = 3）和案例2（K = 5）</p></div><p>为了更好地理解，让我们看看K的不同值。在案例1中，K的值为3。然后，测试数据点的类在红色和蓝色的类中将是红色。对于情况2中的K = 5，则预测的类将是来自KNN算法的蓝色。因此，为了改变K的值，测试数据点的输出也可以变化。所以有必要明智地选择K的值。K的较大值可以降低整体噪声，但不能保证精确度。</p><p><strong>距离函数</strong></p><p>KNN使用的不同距离函数是</p><ol><li>Euclidean function</li><li>Manhattan function</li><li>Minkowski</li><li>Hamming distance</li><li>Mahalanobis distance</li></ol><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c6c47b55dac845dcae9b7315453eca5e><p class=pgc-img-caption>KNN中的距离函数</p></div><p><strong>执行KNN的命令</strong></p><p>我们可以改变分类器的参数并观察分类器提取的变化，并比较使用不同参数和超参数的效果和效率。</p><blockquote><p><em>class</em> sklearn.neighbors。 <strong>KNeighborsClassifier</strong>（ <em>n_neighbors = 5</em>， <em>weights ='uniform'</em>， <em>algorithm ='auto'</em>，<em>leaf_size = 30</em>， <em>p = 2</em>， <em>metric ='minkowski'</em>， <em>metric_params = None</em>， <em>n_jobs = 1</em>， <em>** kwargs</em>）</p></blockquote><p><strong>SVM（支持向量机）</strong></p><p>SVM属于监督学习的范畴，具有分类奖励和回归问题。通常，SVM绘制最佳超平面，其分类为不同的类别。在二维空间中，首先，我们绘制对应于因变量的自变量的数据点。然后，从查看超平面或任何线性或非线性平面开始分类过程，将两个类别区分开来。</p><p><strong>算法</strong></p><p>首先要理解，在二进制分类的情况下：</p><ol><li>确定正确的超平面，更好地分离这两个类。</li><li>查找最近数据点（任何类别）和超平面之间的最大距离，距离测量为边距。因此，寻找具有最大边距的超平面。具有较高边距的超平面更加稳健，而低边距因错误分类而发生变化。</li><li>SVM准确选择分类器以最大化边距。</li><li>SVM对分类器具有鲁棒性，并且具有忽略异常值并尝试寻找具有最大余量的超平面的功能。</li></ol><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5880e0799b884143bc50cb039f401b48><p class=pgc-img-caption>SVM在分类两个类（红色和蓝色）</p></div><p><strong>调整参数</strong></p><p>1.核（Kernel）：线性代数在线性SVM中转换超平面学习中起作用。</p><blockquote><p><strong>F（x）= B（0）+ sum（ai *（X，Xi））</strong></p></blockquote><p>2.线性内核（Linear kernel）：点积是内核，显示为K（x，xi）= sum（x * xi），内核是新数据点和支持向量超平面之间的相似性或距离度量。<strong>核心技巧是通过多项式和指数技巧计算的更高维度的分离线。</strong></p><p>3.多项式内核（Polynomial kernel）：与内核相同但指定了一个度。如果d = 1，则转换为线性内核。</p><blockquote><p><strong>K（x，xi）= 1 + sum（x * xi）^ d。</strong></p></blockquote><p>4.径向内核（Radial kernel）：更复杂的内核是径向内核。</p><blockquote><p><strong>K（x，xi）= exp（-gamma * sum（（x-xi²））</strong></p></blockquote><p>在算法中指定伽马（γ）的情况下，伽马的良好考虑值取为0.1，其中伽玛在0和1之间不同。当径向核在特征空间内创建复杂区域时，形成二维中的闭合多边形。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f36052da16b84c5a8b043bd6659e650a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fc40539d98fb48509dc0c228fe88efdb><p class=pgc-img-caption></p></div><p>5.Margin：Margin应保持两边等距离。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0bedbd0b9843488b9ed78ef5acbfb747><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89ed952ae58d42469115181be538fd67><p class=pgc-img-caption></p></div><p><strong>计算命令</strong></p><blockquote><p><em>class</em> sklearn.svm。 <strong>SVC</strong>（ <em>C = 1.0</em>， <em>内核='rbf'</em>， <em>度数= 3</em>， <em>gamma ='auto'</em>， <em>coef0 = 0.0</em>， <em>收缩=真</em>， <em>概率=假</em>， <em>tol = 0.001</em>， <em>cache_size = 200</em>， <em>class_weight =无</em>， <em>详细=假</em>， <em>max_iter = -1</em>， <em>decision_function_shape =' ovr '</em>，<em>random_state = None</em>）</p></blockquote><p><strong>NN（神经网络）</strong></p><p>神经网络模仿我们大脑的工作方式。它们在计算能力不断提高的时代出现了很多。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/284da049da6447ac9eccdf924bfa85b1><p class=pgc-img-caption>具有输入，输出和隐藏层的神经网络</p></div><p>深度学习的概念源于人工神经网络的研究，神经网络是与多层连接的网络。这些图层由节点组成。节点只是一种感知，它接受输入执行一些计算，然后通过节点的激活函数，以显示信号进展通过网络进行上下文分类。</p><p><strong>算法</strong></p><ol><li>随机初始化权重（并不是将它们保持为零）</li><li>实现向前传播以实现<em>hθ</em>（<em>x</em>（<em>i</em>））。</li><li>计算成本</li><li>评估反向传播以计算偏导数并使用梯度检查来确认反向传播正常工作。然后禁用梯度检查。</li><li>使用梯度下降或任何内置优化函数来最小化具有θ权重的成本函数。</li></ol><p><strong>结合</strong></p><p>选择神经网络的布局，包括每层中的多个隐藏单元以及总层数</p><ol><li>特征Xi的尺寸等于输入单元的数量。</li><li>输出单元的数量是类的数量。</li><li>每层隐藏单元的数量通常越多越好（必须与计算成本平衡，因为它随着更多隐藏单元而增加）。</li><li>默认值：1个隐藏层，如果隐藏层多于1个，则每个隐藏层中的单元数相同。</li></ol><p><strong>分类器命令</strong></p><p>MLP代表多层感知器，在这里我们使用带有MLPClassifier的sklearn以及不同的参数。</p><blockquote><p><em>class sklearn.neural_network。</em> <strong><em>MLPClassifier</em></strong> <em>（hidden_​​layer_sizes =（100，），activation ='relu'，solver ='adam'，alpha = 0.0001，batch_size ='auto'，learning_rate ='constant'，learning_rate_init = 0.001，power_t = 0.5，max_iter = 200，shuffle = True，random_state = None，tol = 0.0001，verbose = False，warm_start = False，momentum = 0.9，nesterovs_momentum = True，early_stopping = False，validation_fraction = 0.1，beta_1 = 0.9，beta_2 = 0.999，epsilon = 1e-08）</em></p></blockquote><p><strong>CNN（卷积神经网络）</strong></p><p>现在让我们来讨论卷积神经网络，CNN近来已成名。CNN是深度前馈人工神经网络的一部分，可以在不同的图像和视频识别，推荐系统和自然语言处理应用中执行各种任务，比其他分类器具有更好的时间和精度。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a35bf51b6e5e4b2aabaad71216b8967e><p class=pgc-img-caption>CNN中神经元的排列</p></div><p>随着Facebook使用神经网络进行自动标记算法，谷歌搜索亚马逊的照片搜索产品推荐，Pinterest用于家庭饲料个性化，Instagram用于搜索基础设施，CNN的使用已经普及。图像分类或对象识别是一个问题，即将图像作为参数传递并预测条件是否满足（是猫还是狗），或图像的概率或最令人满意的条件。我们能够快速识别模式，从以前的信息和知识中概括出来。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b7b7a52e34d247a7bb59a5678b40e460><p class=pgc-img-caption>我们看到的与系统看到的</p></div><p><strong>输入和输出</strong></p><p>当计算机或系统拍摄图像时，它只会看到一组像素值。假设480 * 480 * 3，其中480 * 480是大小，3是指RGB值。这些数字中的每一个都被赋值为0到255，作为该点的像素强度。关键点在于，基于将图像作为输入，计算机系统预测并作出输出以用于描述图像是所述或某个类的概率（对于类1为0.90，对于类2为0.96，对于类3为0.4）。</p><p><strong>算法</strong></p><p>要查看系统预测的执行步骤，我们可以将算法定义为 -</p><ol><li>将图像分解为小图像切片 - 与滑动窗口类似，我们可以在整个大图像上传递滑动窗口，并将每个结果保存为单独的，作为一个大图像片段作为小图片图块。</li><li>将每个小块数据送入较小尺寸的神经网络 - 我们很少用相同的值初始化参数，如果不是这样，那么我们将该数据标记为有用。</li><li>将每个小块数据的结果保存到一个新数组中 - 我们不想错放原始文件的索引。因此，我们将结果放在与原始图像相同排列的网格中。</li><li>下采样 - 为了减小新数组的大小，最大池化使用下采样。</li></ol><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/27fb67ad154e454088f4252f2e23df3a><p class=pgc-img-caption>MNIST数据集中的CNN架构</p></div><p><strong>卷积神经网络层</strong></p><p>这些层的多次出现表明我们的网络有多深，这种形成被称为深度神经网络。</p><ol><li>输入：原始像素值作为输入提供。</li><li>卷积层：输入层转换神经元层的结果。需要指定要使用的滤波器。每个滤波器只能是一个5 * 5的窗口，可以滑动输入数据并获得最大强度的像素。</li><li>线性整流单元[ReLU]层：对作为图像的数据提供激活函数。在反向传播的情况下，使用ReLU函数来防止像素值的变化。</li><li>池化层：沿着维度（宽度，高度）在体积中执行下采样操作。</li><li>完全连接的图层：聚焦评分等级，并找到输入数字的最高分数。</li></ol><p>随着我们在层中越来越深入，复杂性增加了很多。但值得一提的是，准确度可能会提高，但时间消耗也会增加。</p><p><strong>绩效措施</strong></p><p>在机器学习和深度学习中，分类器的性能或效率由各种特征显示，这些特征告诉特定分类器的工作情况。</p><p><strong>混淆矩阵</strong></p><p>这也与误差矩阵相同，通过混淆矩阵可以很容易地证明我们的分类器做出的预测百分比是正确的，并且分类器难以预测实际分类。为了显示混淆矩阵，最好以表格的形式进行练习。为了为我们的数字创建一个混淆矩阵，我们将面对10个类别，即10行和10列，其中每个数字都将与其他数字进行比较，我们可以很容易地显示我们的分类器预测错误的地方以及它预测正确的地方以及它预测的总次数</p><p><strong>使用的术语是</strong></p><ol><li><strong>TP</strong> = True positive</li><li><strong>TN </strong>= True negative</li><li><strong>FP</strong> = False positive</li><li><strong>FN</strong> = False negative</li></ol><p><strong>TP</strong>模型预测为正的正样本，<strong>TN</strong>模型预测为负的负样本，<strong>FP</strong>模型预测为正的负样本，<strong>FN</strong>模型预测为负的正样本。</p><p><strong>准确性</strong></p><p>分类器的总体有效性，最好地从总数中定义真实结果的准确性或部分（意味着具有真实的肯定和真实的负面）。</p><blockquote><p>精度=（TP + TN）/ N，其中N是TP，TN，FN，FP的总和。</p></blockquote><p>准确度可以达到的最大值是1.当分类器对两个组进行精确分类时（即FP = 0和FN = 0），会发生这种情况。请记住，<strong>True positive</strong>的总数是TP + FN。<strong>True negative</strong>总数是TN + FP。</p><p><strong>敏感性</strong></p><p>敏感性可以定义为分类器识别阳性标记的有效性。这也称为召回。</p><blockquote><p>Sensitivity=（TP）/（TP + FN）</p></blockquote><p><strong>特异性</strong></p><p>这被定义为分类器正确识别阴性标记的有效性。</p><blockquote><p>Specificity=（TN）/（FP + TN）</p></blockquote><p>灵敏度和特异性都在0和1之间，每个都是理想值。我们将平衡准确度计算为平均敏感性和特异性。</p><p><strong>普遍性</strong></p><p>那么，在我们的样本中，“是”条件实际发生的频率是多少？</p><blockquote><p>Prevalence=（TP + FN）/ N.</p></blockquote><p>N是所有条件的总和，即TP，FN，FP，TN。</p><p>正预测值</p><blockquote><p>Positive_predicted_value =（Sensitivity*Prevalence）/（（Sensitivity*Prevalence）+（1-Specificity）*（1-Prevalence））</p></blockquote><p>负预测值</p><blockquote><p>Negative_predicted_values =Specificity*（1 - Prevalence）/（（（1-Sensitivity）*Prevalence）+（Specificity*（1 - Prevalence）））</p></blockquote><p>检测率</p><p>检测率是真实阳性除以条件总数。</p><blockquote><p>DR = TP / N.</p></blockquote><p>预期的准确性</p><p>也被视为条件中的随机机会</p><blockquote><p>Expected_accuracy =（（TP + FN）*（TP + FP）+（FP + TN）*（FN + TN））/ N</p></blockquote><p>其中N是所有条件的总和，即TP，FN，FP和TN。</p><p>Kappa统计</p><p>Kappa统计量（或值）是将观察到的准确度与预期准确度（比如随机机会）进行比较的度量。</p><blockquote><p>Kappa =（观察到的准确度 - expected_accuracy）/（1 - expected_accuracy）</p></blockquote><p>分类器有很多性能指标可以显示它在这些统计情况下的表现。分类器预测的速度也提高了整体性能，我们对快速分类器进行了分类。通过这些示例，首先保留描述不可见数据集的预测中的错误细分。</p><p><strong>结果</strong></p><p>用于研究目的，或将分类器应用于实际场景问题。识别的准确性和速度被认为是更好的衡量标准。现在逐一谈论不同的分类器。</p><p>总体比较结果</p><p>显示训练集中使用的不同分类器之间的准确性，时间，特异性，敏感性和其他参数比较。</p><div class=pgc-img><img alt=使用机器学习的手写数字识别 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/bae38362a7fd4767bfb521233e334c92><p class=pgc-img-caption>训练和测试数据的分类器比较</p></div><p><strong>结论和未来的工作</strong></p><p>由于使用机器学习算法如KNN，SVM，神经网络以及不同的参数和特征缩放矢量，我们还看到了分类器之间在精度和时序的最重要特征方面的不同比较。准确性可以根据训练和测试数据的分割而改变，如果提供训练和测试数据的数量，这可以进一步改进。如果数据量增加，总有机会提高准确性。每个分类器都有自己的准确性和时间消耗。我们还可以包括这样的事实：如果CPU的功率变为GPU，则分类器可以以更好的准确性和更少的时间执行，并且可以观察到更好的结果。</p><p>分类器的性能可以根据正确识别条件的能力（灵敏度），真实结果的比例（准确性），分类程序中的阳性结果数量作为假阳性（阳性预测）和排除能力来衡量。条件正确（特异性）。在这里，我们看到了与机器学习和深度学习的分类器的简要比较。</p><p>到目前为止，深度学习算法在手写数字识别的应用中表现更好。</p><p><strong>未来的研究</strong>可能会考虑使用卷积网络的架构，该架构在MNIST数据库上给出最好的结果，并且所提出的识别系统在手写数字上实现。这样的系统可以设计用于手写字符识别，对象识别，图像分割，手写识别，文本语言识别，未来研究也可以考虑在线数字识别系统的硬件实现，具有更高的性能和效率，实时测试结果的实时结果场景。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'机器','学习','数字识别'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>