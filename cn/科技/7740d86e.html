<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>学习NLP的第10天——文章关键词提取：词频统计 | 极客快訊</title><meta property="og:title" content="学习NLP的第10天——文章关键词提取：词频统计 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7740d86e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7740d86e.html><meta property="article:published_time" content="2020-10-29T21:09:48+08:00"><meta property="article:modified_time" content="2020-10-29T21:09:48+08:00"><meta name=Keywords content><meta name=description content="学习NLP的第10天——文章关键词提取：词频统计"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/7740d86e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>学习NLP的第10天——文章关键词提取：词频统计</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>关键词提取是词语颗粒度的信息抽取的一种重要的需求，即提取文章中重要的词语。</p><p>关键词提取的常用方法包括词频统计、TF-IDF和TextRank等。</p><p>其中，词频和TextRank属於单文档算法，即只需一篇文章即可提取出其中的关键词；而TF-IDF则属于多文档宣发，需要其他文档的辅助来提取当前文章的关键词。</p><hr><h1 class=pgc-h-arrow-right>词频统计的Python实现</h1><p>词频统计的逻辑是：在一篇文章中，越重要的关键词往往会在文章中反复出现；因为为了解释关键词，作者经常会反复地提及它们。所以通过统计文章中各个词语的出现频率，即可初步地获得关键词。</p><p>但是因为齐夫定律，文章中出现频率最高的往往并不是长度较长的关键词，而是标点符号和助词等，因此在词频统计之前还需要先进行停用词过滤。</p><blockquote><p>齐夫定律：一个单词的词频与它的词频排名成反比。</p></blockquote><p>由此，词频统计的流程通常是中文分词、停用词过滤、词频统计。依据以上逻辑，我在Python中实现以下词频统计。（以《红楼梦·桃花行》节选为例）</p><pre><code>from pyhanlp import HanLPfrom pyhanlp import JClassdef load_from_words(*words):    &#34;&#34;&#34;    从词汇构造双数组trie树    :param words: 一系列词语    :return:    &#34;&#34;&#34;    map = JClass(&#39;java.util.TreeMap&#39;)()  # 创建TreeMap实例    for word in words:        map[word] = word    return JClass(&#39;com.hankcs.hanlp.collection.trie.DoubleArrayTrie&#39;)(map)def remove_stopwords_termlist(termlist, trie):    return [term.word for term in termlist if not trie.containsKey(term.word)]if __name__ == &#34;__main__&#34;:    # 《红楼梦·桃花行》节选    article = &#34;桃花帘外东风软，桃花帘内晨妆懒。帘外桃花帘内人，人与桃花隔不远。&#34;    # 停用词表(诗中包含的哈工大停用词表的停用词)    trie = load_from_words(&#34;，&#34;, &#34;。&#34;, &#34;与&#34;)    # 中文分词+停用词过滤    termlist = HanLP.segment(article)    termlist = remove_stopwords_termlist(termlist, trie)  # 分词结果去除停用词    print(&#34;分词结果:&#34;, termlist)    # 词频统计    word_frequency = dict()    for word in termlist:        if word not in word_frequency:            word_frequency[word] = 0        word_frequency[word] += 1    word_frequency_sorted = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)  # 词频排序    for i in range(5):        print(word_frequency_sorted[i][0], &#34;词频:&#34;, word_frequency_sorted[i][1])</code></pre><p class=pgc-end-literature>其中load_from_words和remove_stopwords_termlist在之前（<a class=pgc-link data-content=mp href="https://www.toutiao.com/i6798427877848121864/?group_id=6798427877848121864" rel="noopener noreferrer" target=_blank>第7天</a>）的学习中已经掌握。</p><p><strong>运行结果</strong></p><pre><code>分词结果: [&#39;桃花&#39;, &#39;帘&#39;, &#39;外&#39;, &#39;东风&#39;, &#39;软&#39;, &#39;桃花&#39;, &#39;帘&#39;, &#39;内&#39;, &#39;晨妆&#39;, &#39;懒&#39;, &#39;帘&#39;, &#39;外&#39;, &#39;桃花&#39;, &#39;帘&#39;, &#39;内&#39;, &#39;人&#39;, &#39;人&#39;, &#39;桃花&#39;, &#39;隔&#39;, &#39;不远&#39;]桃花 词频: 4帘 词频: 4外 词频: 2内 词频: 2人 词频: 2</code></pre><h1 class=pgc-h-arrow-right>基于HanLP实现的词频统计</h1><p>HanLP中封装了TermFrequencyCounter类用来统计文档的词频，接着我们使用这个类实现词频统计。</p><pre><code>from pyhanlp import *TermFrequency = JClass(&#39;com.hankcs.hanlp.corpus.occurrence.TermFrequency&#39;)TermFrequencyCounter = JClass(&#39;com.hankcs.hanlp.mining.word.TermFrequencyCounter&#39;)if __name__ == &#39;__main__&#39;:    counter = TermFrequencyCounter()    counter.add(&#34;桃花帘外东风软，桃花帘内晨妆懒。帘外桃花帘内人，人与桃花隔不远。&#34;)  # 第1个文档    counter.add(&#34;东风有意揭帘栊，花欲窥人帘不卷。桃花帘外开仍旧，帘中人比桃花瘦。&#34;)  # 第2个文档    print(&#34;2篇文章的词频前5名:&#34;, counter.top(5))    #  根据词频提取关键词    print(&#34;第1篇文章的词频前5名:&#34;, TermFrequencyCounter.getKeywordList(&#34;桃花帘外东风软，桃花帘内晨妆懒。帘外桃花帘内人，人与桃花隔不远。&#34;, 5))</code></pre><p><strong>运行结果</strong></p><pre><code>2篇文章的词频前5名: [帘=8, 桃花=6, 外=3, 东风=2, 隔=1]第1篇文章的词频前5名: [桃花, 帘, 外, 隔, 软]</code></pre><p>可以看到，整体结果是相近的，HanLP去除了更多的停用词，包括“人”、“内”以及标点符号等。</p><hr><p>用词频提取关键词存在一个缺陷，就是即使使用过滤停用词以后，高频词也并与关键词完全等价。例如在分析一个明星的相关新闻时，明星名字的出现频率可能是最高的，但是在我们希望找到每一篇文章各自的特点，而不是文章的共性，此时，我们就需要引入TF-IDF等关键词提取方法。</p><p class=pgc-end-literature>学习参考文献：《自然语言处理入门》(何晗)：9.2.1</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'学习','NLP','10'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>