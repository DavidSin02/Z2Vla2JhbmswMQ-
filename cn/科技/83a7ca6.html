<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>利用基于几何关系的扩增技术从OCT图像进行病理视网膜区域分割 | 极客快訊</title><meta property="og:title" content="利用基于几何关系的扩增技术从OCT图像进行病理视网膜区域分割 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/2f831479a2984dd6ab30d7c6614b2131"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/83a7ca6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/83a7ca6.html><meta property="article:published_time" content="2020-10-29T20:51:37+08:00"><meta property="article:modified_time" content="2020-10-29T20:51:37+08:00"><meta name=Keywords content><meta name=description content="利用基于几何关系的扩增技术从OCT图像进行病理视网膜区域分割"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/83a7ca6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>利用基于几何关系的扩增技术从OCT图像进行病理视网膜区域分割</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><br></p><div class=pgc-img><img alt=利用基于几何关系的扩增技术从OCT图像进行病理视网膜区域分割 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2f831479a2984dd6ab30d7c6614b2131><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">大型数据集的像素级手动注释需要高度的专业知识，而且非常耗时。传统的数据扩增由于不能完全代表训练集的基本分布，因此在对不同来源的图像进行测试时，影响了模型的鲁棒性。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">虽然深度学习方法展示了医学图像分析任务的最新成果，但其鲁棒性取决于不同训练数据集的可用性，学习不同的疾病属性，如外观和形状特征。用于分割的大规模数据集注释需要图像像素标记，这非常耗时，并且涉及到高度的临床专业知识。这个问题对于病理图像来说尤其严重，对于发病率较低的疾病，很难获得不同的图像，因此需要进行数据扩增。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">传统的扩增方法（如图像旋转或变形）的好处有限，因为它们不能完全代表训练集的潜在信息分布，并且对参数选择敏感。最近的研究提出通过使用合成数据来扩增和增加训练样本的多样性来解决这个问题。然而，这些方法并没有很好地解决一些困难。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">由 Amy Zhao 等人提出的一种基于学习的配准方法，将图像配准到图集中，利用相应的变形场对分割掩模进行变形，得到新的图像数据。但这种方法要面对以下问题：1）由于配准误差会传播到后续阶段，不准确的配准会对数据生成过程产生不利影响；2）对于正常人的图谱，由于外观或形状的变化，很难从病患的图集中注册图像。这与视网膜光学相干断层成像（OCT）图像中的层分割特别相关，在 OCT 图像中，正常和患病病例的层形状有很大的差异。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">使用生成性对抗网络（GAN）进行数据扩增的方法在医学图像分类方面取得了一定的成功。然而，由于它们不能模拟不同器官之间的几何关系，而且大多数扩增方法不能区分正常和病变样本，因此它们对分割的相关性有限。因此，需要考虑不同解剖区域之间的几何关系的扩增方法，并为病变和正常病例生成不同的图像。当前扩增方法的另一个局限性是它们没有以原则性的方式纳入多样性。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">文章提出了一种改进的基于 GAN 的医学图像合成方法，通过联合编码几何和形状的内在关系。潜在空间变量采样可以从基本图像中生成不同的图像，并提高了鲁棒性。基于改进的数据扩增在深度学习系统中产生更好分割性能的前提下，假设通过考虑解剖结构的形状和几何结构之间的内在关系，可以改进合成图像的生成。在本文中，我们提出了一个几何感知形状生成对抗网络（GeoGAN），该网络学习生成所需解剖结构的可信图像（例如视网膜 OCT 图像），同时保留几何和形状之间的学习关系，作出了以下贡献：</span></p><ol start=1><li><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">与标准数据扩增相比，结合几何信息有助于生成真实和定性不同的医学图像和形状。其他的方法并没有把这种解剖部位之间的几何关系结合起来。</span></li><li><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在类标签上使用不确定抽样和条件形状生成来引入掩码生成过程中的多样性。与以往的方法相比，在不同阶段尝试多样化，并引入了辅助分类器，以提高生成图像的质量和准确性。</span></li></ol><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">本文使用的数据扩增方法：1）建立多个分割标签之间的几何关系；2）保留原始图像的疾病类别标签，以学习疾病特定的外观和形状特征；3）通过不确定性采样，在图像生成过程中引入多样性。利用图像集和分割掩模对发生器进行训练，鉴别器提供反馈以提高发生器的输出。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">此方法的主要目的是学习解剖区域的轮廓和其他特定的形状信息，从一个基本图像及其相应的人工掩模生成一个新的图像和分割标签映射。空间变换网络（STN）将基础遮罩转换为具有不同位置、比例和方向属性的新形状；发生器通过输入和输出掩码的期望标记向量输出仿射变换矩阵；鉴别器数据决定输出图像是否保留所需的标签，它的任务是确保生成的掩模和图像是真实的。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">对不同数据扩增方法进行比较，实验共分为以下步骤：1）将数据集分成训练（60%）、验证（20%）和测试（20%）的集合，这样任何患者的图像都只有一个集合。2） 使用训练图像来训练图像生成器。3） 从验证集生成形状，并在生成的图像上训练 UNet 分割网络。4） 使用训练过的 UNet 分割测试图像。5） 对不同的数据扩增方法重复上述步骤。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">比较结果表明，当应用于视网膜 OCT 图像的病理区域分割时，所得到的扩增数据集优于标准数据扩增和其他竞争性方法。对于形状，分类和采样项之间的协同作用可以改进分割，此方法可用于其他医学成像模式，而无需对工作流程进行重大更改。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">尽管这种方法有很好的性能，但是当图像采集过程的固有特性导致基础图像有噪声时，以及当流体区域与其他层有很大重叠时，会发生失效情况。虽然这种情况不太常见，但在医学领域可能是至关重要的，因此还需要提升此方法在各种医学成像模式上的稳健性。</span></p><h1 class=pgc-h-arrow-right>致谢</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">本论文由 iSE 实验室 2021 级学生叶宇晖转述。</span></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'几何关','增技术','OCT'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>