<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU | 极客快訊</title><meta property="og:title" content="深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/cc64e1221edd467183ee229ac9a79dc5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8930726.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8930726.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8930726.html><meta property="article:published_time" content="2020-10-29T20:50:03+08:00"><meta property="article:modified_time" content="2020-10-29T20:50:03+08:00"><meta name=Keywords content><meta name=description content="深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/8930726.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>目标检测任务的损失函数由Classificition Loss和Bounding Box Regeression Loss两部分构成。本文介绍目标检测任务中近几年来Bounding Box Regression Loss Function的演进过程，其演进路线是Smooth L1 Loss IoU Loss GIoU Loss DIoU Loss CIoU Loss，本文按照此路线进行讲解。</p><p><br></p><h1 class=pgc-h-arrow-right><strong>1. Smooth L1 Loss</strong></h1><p><br></p><ul><li>本方法由微软rgb大神提出，Fast RCNN论文提出该方法</li></ul><p>1.1 假设x为预测框和真实框之间的数值差异，常用的L1和L2 Loss定义为：</p><p><br></p><p><br>1.2 上述的3个损失函数对x的导数分别为：</p><p><br></p><p>从损失函数对x的导数可知： 损失函数对x的导数为常数，在训练后期，x很小时，如果learning rate 不变，损失函数会在稳定值附近波动，很难收敛到更高的精度。 损失函数对x的导数在x值很大时，其导数也非常大，在训练初期不稳定。 <strong>完美的避开了 和 损失的缺点。</strong></p><p><br></p><p>1.3 实际目标检测框回归任务中的损失loss为：</p><p><br></p><p>其中 表示GT 的框座标， 表示预测的框座标，即分别求4个点的loss，然后相加作为Bounding Box Regression Loss。</p><p><br></p><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cc64e1221edd467183ee229ac9a79dc5><p class=pgc-img-caption></p></div><p>三种loss的曲线图如图所示，可以看到Smooth L1相比L1的曲线更加的Smooth</p><p><strong>缺点：</strong></p><p><br></p><ul><li>上面的三种Loss用于计算目标检测的Bounding Box Loss时，独立的求出4个点的Loss，然后进行相加得到最终的Bounding Box Loss，这种做法的假设是4个点是相互独立的，实际是有一定相关性的</li><li><strong>实际评价框检测的指标是使用IOU，这两者是不等价的，多个检测框可能有相同大小的</strong> <strong>Loss，但IOU可能差异很大，为了解决这个问题就引入了IOU LOSS。</strong></li></ul><h1 class=pgc-h-arrow-right><strong>2. IoU Loss</strong></h1><p><br></p><ul><li>本文由旷视提出，发表于2016 ACM</li></ul><p><br></p><p><strong>2.1 通过4个座标点独立回归Building boxes的缺点：</strong></p><p><br></p><ul><li>检测评价的方式是使用IoU,而实际回归座标框的时候是使用4个座标点，如下图所示，是不等价的；L1或者L2 Loss相同的框，其IoU 不是唯一的</li><li><strong>通过4个点回归座标框的方式是假设4个座标点是相互独立的，没有考虑其相关性，实际4个座标点具有一定的相关性</strong></li><li>基于L1和L2的距离的loss对于尺度不具有不变性</li></ul><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dcccfd6fb9474c449fbb880cf4523abb><p class=pgc-img-caption></p></div><p>图(a)中的三组框具有相同的L2 Loss，但其IoU差异很大；图（b）中的三组框具有相同的L1 Loss,但IoU 同样差异很大，说明L1,L2这些Loss用于回归任务时，不能等价于最后用于评测检测的IoU.</p><p><br></p><p>2.2 基于此提出IoU Loss,其将4个点构成的box看成一个整体进行回归：</p><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d414c5ea57754fdf9082fab07391a98a><p class=pgc-img-caption></p></div><p>上图中的红色点表示目标检测网络结构中Head部分上的点（i,j），绿色的框表示Ground truth框, 蓝色的框表示Prediction的框，IoU loss的定义如上，先求出2个框的IoU，然后再求个-ln(IoU)，实际很多是直接定义为IoU Loss = 1-IoU</p><p><br></p><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/40cf4d6ee985499b9348a52e598610f4><p class=pgc-img-caption></p></div><p>IoU Loss 前项推理时的算法实现方式</p><p><br></p><p><strong>附录：</strong></p><p><br></p><p>论文链接：https://arxiv.org/pdf/1608.01471.pdf</p><p><br></p><h1 class=pgc-h-arrow-right><strong>3 GIoU Loss</strong></h1><p><br></p><ul><li>本文由斯坦福学者提出，发表于CVPR2019</li></ul><p><strong>3.1 IoU Loss 有2个缺点：</strong></p><p><br></p><ul><li>当预测框和目标框不相交时，IoU(A,B)=0时，不能反映A,B距离的远近，此时损失函数不可导，IoU Loss 无法优化两个框不相交的情况。</li><li>假设预测框和目标框的大小都确定，只要两个框的相交值是确定的，其IoU值是相同时，IoU值不能反映两个框是如何相交的。</li></ul><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4aaaa7a85cfb4b608896ce69e9e2ebc4><p class=pgc-img-caption></p></div><p>如上图所示，三种不同相对位置的框拥有相同的IoU=0.33值，但是拥有不同的GIoU=0.33，0.24，-0.1。当框的对齐方向更好一些时GIoU的值会更高一些。</p><p><br></p><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b1e0cb46e1dc4bb59897ae2481acf868><p class=pgc-img-caption></p></div><p>GIoU的实现方式如上，其中C为A和B的外接矩形。用C减去A和B的并集除以C得到一个数值，然后再用框A和B的IoU减去这个数值即可得到GIoU的值。</p><p><br></p><p><strong>GIoU的性质</strong></p><p><br></p><ul><li>GIoU和IoU一样，可以作为一种距离的衡量方式，</li><li>GIoU具有尺度不变性</li><li>对于 ,有 且 ,因此 当 时，两者相同都等于1，此时 等于1</li><li>当 和 不相交时，</li></ul><p><strong>附录</strong></p><p><br></p><p>论文链接：https://arxiv.org/abs/1902.09630</p><p><br></p><p>github链接：https://github.com/generalized-iou/g-darknet</p><p><br></p><p>参考链接：目标检测算法之CVPR2019 GIoU Loss（https://mp.weixin.qq.com/s/CNVgrIkv8hVyLRhMuQ40EA）</p><p><br></p><p><strong>实现结论和启发：</strong></p><p><br></p><p>本文提出了GIoU Loss，最终单阶段检测器YOLO v1涨了2个点，两阶段检测器涨点相对较少（RPN的box比较多，两个框未相交的数量相对较少）</p><p><br></p><h1 class=pgc-h-arrow-right><strong>4. DIoU Loss</strong></h1><p><br></p><ul><li>本文发表在AAAI 2020</li></ul><p><strong>GIoU Loss不足</strong></p><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/32eb8e6ec0a44659ba2ca3c7861a5bb4><p class=pgc-img-caption></p></div><p>当目标框完全包裹预测框的时候，IoU和GIoU的值都一样，此时GIoU退化为IoU, 无法区分其相对位置关系；此时作者提出的DIoU因为加入了中心点归一化距离，所以可以更好地优化此类问题。</p><p><br></p><p><strong>启发点:</strong></p><p><br></p><p>基于IoU和GIoU存在的问题，作者提出了两个问题：</p><p><br></p><ul><li>第一：直接最小化预测框与目标框之间的归一化距离是否可行，以达到更快的收敛速度。</li><li>第二：如何使回归在与目标框有重叠甚至包含时更准确、更快。</li></ul><p><br></p><p>好的目标框回归损失应该考虑三个重要的几何因素：<strong>重叠面积，中心点距离，长宽比。</strong>基于问题一，作者提出了DIoU Loss,相对于GIoU Loss收敛速度更快，该Loss考虑了<strong>重叠面积和中心点距离</strong>，但没有考虑到长宽比；针对问题二，作者提出了CIoU Loss，<strong>其收敛的精度更高</strong>，以上三个因素都考虑到了。</p><p><br></p><p><strong>Distance-IoU Loss</strong></p><p><br></p><ul><li>通常基于IoU-based的loss可以定义为 ，其中 定义为预测框 和目标框 的惩罚项。</li><li>DIoU中的惩罚项表示为 ，其中 和 分别表示 和 的中心点， 表示欧式距离， 表示 和 的最小外界矩形的对角线距离，如下图所示。<strong>可以将DIoU替换IoU用于NMS算法当中，也即论文提出的DIoU-NMS,实验结果表明有一定的提升。</strong></li><li>DIoU Loss function定义为：</li></ul><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3fbde3623d524a65bd58634780f0eb15><p class=pgc-img-caption></p></div><p>上图中绿色框为目标框，黑色框为预测框，灰色框为两者的最小外界矩形框，d表示目标框和真实框的中心点距离，c表示最小外界矩形框的距离。</p><p><strong>DIoU的性质：</strong></p><p><br></p><ul><li>尺度不变性</li><li>当两个框完全重合时， ,当2个框不相交时</li><li>DIoU Loss可以直接优化2个框直接的距离，比GIoU Loss收敛速度更快</li><li>对于目标框包裹预测框的这种情况，DIoU Loss可以收敛的很快，而GIoU Loss此时退化为IoU Loss收敛速度较慢</li></ul><h1 class=pgc-h-arrow-right><strong>5. CIoU Loss</strong></h1><p><br></p><p><strong>Complete-loU Loss</strong></p><p><br></p><ul><li>CIoU的惩罚项是在DIoU的惩罚项基础上加了一个影响因子 ，这个因子把预测框长宽比拟合目标框的长宽比考虑进去。 ，其中 是用于做trade-off的参数， ， 是用来衡量长宽比一致性的参数，定义为</li><li>CIoU Loss function的定义为</li></ul><h3 class=pgc-h-arrow-right>DIoU和CIoU的提升效果</h3><div class=pgc-img><img alt=深度学习——目标检测回归损失：SmoothL1/IoU/GIoU/DIoU/CIoU onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/820bf175818b4385bafdd25e4885193a><p class=pgc-img-caption></p></div><p>上表中左边是用5种不同Boudning Box Regression Loss Function的对比，右边是以IoU和GIoU来计算的2种Evaluation的结果；GIoU相对IoU会有2.49点提升，DIoU相对IoU会有3.29点提升，CIoU会有大概5.67点提升，CIoU结合DIoU-NMS使用效果最好，大概会有5.91点提升。</p><h3 class=pgc-h-arrow-right><strong>结论：</strong></h3><p>DIoU Loss和CIoU Loss优化了GIoU Loss的不足，实验证明效果有进一步提升，代码已开源，非常推荐工程上去尝试。</p><h3 class=pgc-h-arrow-right><strong>附录：</strong></h3><p>论文地址：https://arxiv.org/pdf/1911.08287.pdf</p><p><br></p><p>github地址：https://github.com/Zzh-tju/DIoU-darknet</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'学习','目标','检测'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>