<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>教程：采用梯度下降算法实现线性回归！ | 极客快訊</title><meta property="og:title" content="教程：采用梯度下降算法实现线性回归！ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/1537162000876f4501fb1c4"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8d93e49d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8d93e49d.html><meta property="article:published_time" content="2020-11-14T21:07:33+08:00"><meta property="article:modified_time" content="2020-11-14T21:07:33+08:00"><meta name=Keywords content><meta name=description content="教程：采用梯度下降算法实现线性回归！"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/8d93e49d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>教程：采用梯度下降算法实现线性回归！</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>点击上方关注，All in AI中国</strong></p><p>作者：Adarsh Menon</p><p>在这个教程中，你可以了解梯度下降算法将如何工作，并在python中从头开始实现。首先我们看一下线性回归是什么，然后定义损失函数。我们学习了梯度下降算法的工作原理，最后我们将在给定的数据集上实现它，并进行预测。</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537162000876f4501fb1c4><p class=pgc-img-caption>在每次迭代时更新m和c的值以获得最优解</p></div><p><strong>线性回归</strong></p><p>在统计学中，线性回归是一种线性方法，用于对因变量与一个或多个自变量之间的关系进行建模。设X为自变量，Y为因变量。我们将在这两个变量之间定义一个线性关系，如下所示：</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537162001009d0878ecc72><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153716200111975dfbd95fe><p class=pgc-img-caption></p></div><p>这是你在高中学习的线性方程。m是直线的斜率，c是y截距。如今我们将使用这个方程用给定的数据集训练我们的模型，并预测任何给定X值的Y值。我们今天的挑战是确定m和c的值，使得对应于这些值的线是最佳拟合直线或给出最小误差。</p><p><strong>损失函数</strong></p><p>损失是我们预测的m和c值的误差。我们的目标是最小化这个误差，以获得最准确的m和c值。</p><p>我们将使用均方误差函数来计算损失。这个函数有三个步骤：</p><ol><li>对于给定x，找到实际y和预测y值之间的差值（y＝mx+c）。</li><li>把这个差值进行平方。</li><li>找出X中每个值的平方均值。</li></ol><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537162001284c5883247dd><p class=pgc-img-caption>均方误差方程</p></div><p>这是yi实际值，ȳ i是预测值。让我们替换ȳ i的值：</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537162001413e22f1c1352><p class=pgc-img-caption>替换 ȳ i的值</p></div><p>所以我们将误差平方并找出均值。因此，名称均方误差。现在我们已经定义了损失函数，让我们进入有趣的部分 - 最小化它，并找到m和c。</p><p><strong>梯度下降算法</strong></p><p>梯度下降是寻找函数最小值的迭代优化算法。这里的函数是我们的损失函数。</p><p>了解梯度下降</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537162001650948f9e6864><p class=pgc-img-caption>说明梯度下降算法的工作原理</p></div><p>想象一个山谷和一个没有方向感的人想要到达山谷的底部。当斜坡陡峭时，他沿着斜坡走下坡时，步幅较大，当斜坡不那么陡峭时，步幅较小。他根据自己目前的位置决定下一个位置，并在他到达山谷底部时停下来，这是他的目标。</p><p>让我们尝试将梯度下降算法应用于m和c，并逐步逼近它：</p><p>1.最初让m = 0和c = 0。设L是我们的学习率。这可以控制m值随每一步的变化程度。 L可以是0.0001的这样小的数值，以获得良好的准确性。</p><p>2.计算损失函数相对于m的偏导数，并插入其中x，y，m和c的当前值，得到导数值D。</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15371620017497db52ab25e><p class=pgc-img-caption></p></div><p>关于m的导数</p><p>Dc 是相对于m的偏导数的值。类似地，我们找到关于c，Dc的偏导数：</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153716200188111e1111a3e><p class=pgc-img-caption></p></div><p>关于c的导数</p><p>3.现在我们使用以下等式更新m和c的当前值：</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537162002003b43e09b597><p class=pgc-img-caption></p></div><p>4.我们重复这个过程，直到我们的损失函数是一个非常小的值或理想情况下为0（这意味着0误差或100％准确度）。我们现在剩下的m和c的值将是最佳值。</p><p>现在回到我们的类比，m可以被认为是图中人员的当前位置。D等于斜率的陡度，L是他移动的速度。现在我们使用上面的等式计算的m的新值将是他的下一个位置，并且L×D将是步幅的大小。当斜率更陡（D更大）时，他需要迈出更大的步幅，当它更陡（D更小）时，他迈出更小的步幅。最后他到达山谷的底部，相当于我们的损失= 0。</p><p>现在有了m和c的最佳值，我们的模型已经准备好进行预测了。</p><p><strong>实施模型</strong></p><p>现在让我们将上面的所有内容转换为代码并查看我们的模型！</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15371620025985fe264fd52><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537162002707217e66032e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537162002839ca1c174f52><p class=pgc-img-caption></p></div><p>梯度下降算法是机器学习中最简单、应用最广泛的算法之一，主要是因为它可以应用于任何函数来优化它。学习它为掌握机器学习奠定了基础。你可以在这里找到数据集和代码：</p><p>https//github.com/chasinginfinity/ml-from-scratch/tree/master/02%20Linear%20Regression%20using%20Gradient%20Descent</p><div class=pgc-img><img alt=教程：采用梯度下降算法实现线性回归！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537163559113369188d8e5><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'采用','实现','线性'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>