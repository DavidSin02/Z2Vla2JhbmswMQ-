<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>视频分类/行为识别研究综述，从数据集到方法 | 极客快訊</title><meta property="og:title" content="视频分类/行为识别研究综述，从数据集到方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/f8492465503747d18ce4a78a021d63e6"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8e333c0.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8e333c0.html><meta property="article:published_time" content="2020-10-29T20:51:33+08:00"><meta property="article:modified_time" content="2020-10-29T20:51:33+08:00"><meta name=Keywords content><meta name=description content="视频分类/行为识别研究综述，从数据集到方法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/8e333c0.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>视频分类/行为识别研究综述，从数据集到方法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f8492465503747d18ce4a78a021d63e6><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5cf94ca6d7754c19880e49ad4e10405f><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/127a403eb629411c82d5fc2df5079c37><p class=pgc-img-caption></p></div><p>文章发布于公号【数智物语】 （ID：decision_engine），关注公号不错过每一篇干货。</p><blockquote><p>来源 | 有三AI（id：yanyousan_ai）</p><p>作者 | 言有三</p></blockquote><p>视频分类/行为识别是计算机视觉领域中非常有挑战性的课题，因为其不仅仅要分析目标体的空间信息，还要分析时间维度上的信息，如何更好的提取出空间-时间特征是问题的关键。本文总结了该领域的技术进展和相关数据集，技术进展从传统特征法到深度学习中的3DCNN，LSTM，Two-Stream等。</p><p><strong>01</strong></p><p><strong>视频分类/行为识别问题</strong></p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/45a1806f1065499dbc6831f269b4eb41><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>首先我们要明确这是一个什么问题，基于视频的行为识别包括两个主要问题，即行为定位和行为识别。行为定位即找到有行为的视频片段，与2D图像的目标定位任务相似。而行为识别即对该视频片段的行为进行分类识别，与2D图像的分类任务相似。</p><p>本文聚焦的是行为识别，即对整个视频输入序列进行视频分类，一般都是经过裁剪后的视频切片。接下来从数据集的发展，传统方法，深度学习方法几个方向进行总结。</p><p><strong>02</strong></p><p><strong>视频分类/行为分析重要数据集</strong></p><p>深度学习任务的提升往往伴随着数据集的发展，视频分类/行为识别相关的数据集非常多，这里先给大家介绍在论文评测中最常见的3个数据集。</p><p><strong>2.1 HMDB-51</strong></p><p>HMDB-51共51个类别，6766个短视频。数据集地址：http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#dataset，发布于2011年。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/63d4514981784bdfb888f86b50887981><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>数据来源非常广泛，包括电影，一些现有的公开数据集，YouTube视频等。从中选择了51个类别，每一个类别包含101个以上视频。</p><p>分为5大类：</p><p>1. 常见的面部动作(smile，laugh，chew，talk)</p><p>2. 复杂的面部动作(smoke，eat，drink)</p><p>3. 常见的肢体动作(climb，dive，jump)</p><p>4. 复杂的肢体动作(brush hair，catch，draw sword)</p><p>5. 多人交互肢体动作(hug，kiss，shake hands)</p><p>下面是其中一些维度的统计，包括姿态，相机运动等。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/42047269341a47e790d11e90bb8f70cb><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>51个类别的展示如下：</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6ebbaf3a9c4347d68665b73165069c8c><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3f0ff92ebf6548088fc0eff1b7e6854f><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p><strong>2.2 UCF-101</strong></p><p>UCF-101共101个类别，13320个短视频。数据集地址：https://www.crcv.ucf.edu/research/data-sets/human-actions/ucf101/，发布于2012年。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5926f6d1c13143df8d6c48bbad559d14><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>UCF-101是目前动作类别数、样本数最多的数据集之一，包含5大类动作：人与物体互动、人体动作、人与人互动、乐器演奏、体育运动。总共包括在自然环境下101种人类动作，每一类由25个人做动作，每个人做4-7组，视频大小为320×240。正因为类别众多加上在动作的采集上具有非常大的多样性，如相机运行、外观变化、姿态变化、物体比例变化、背景变化等等，所以也成为了当前难度最高的动作类数据集挑战之一。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0e9f677432334eca97117eaa70d47dd8><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>各个类别的分布如上，相对还是比较均匀的，UCF-101是视频分类/行为识别方法必须评测的标准。</p><p><strong>2.3 Kinetics-700 dataset</strong></p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d3a30170679142cd943fc0ed3b6299f3><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>Kinetics-700 dataset被用于ActivityNet比赛，包含约650000个视频，700个类别。数据集地址：https://deepmind.com/research/open-source/open-source-datasets/kinetics/，发布于2019年。</p><p>ActivityNet比赛始于2016的CVPR，是与ImageNet齐名的在视频理解方面最重要的比赛。在这个比赛下的Task A–Trimmed Action Recognition比赛是一个视频分类比赛，2019年的比赛使用kinetics-700数据集，在此之前还有2017年的kinetics-400和2018年的kinetics-600。</p><p>数据集是Google的deepmind团队提供，每个类别至少600个视频以上，每段视频持续10秒左右，标注一个唯一的类别。行为主要分为三大类：人与物互动，比如演奏乐器；人人互动，比如握手、拥抱；运动等。即person、person-person、person-object。</p><p>除了以上数据集，比较重要的还有Sports-1M，YouTube-8M等，篇幅所限，就不一一描述，大家可以参考文献[1]。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5ad81ec22998440c8b76fa58fd7023c4><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p><strong>03</strong></p><p><strong>传统有监督特征提取方法</strong></p><p>传统的方法通过提取关键点的特征来对视频进行描述，以时空关键点，密集轨迹方法等为代表。</p><p><strong>3.1 时空关键点(space-time interest points)</strong></p><p>基于时空关键点的核心思想是：视频图像中的关键点通常是在时空维度上发生强烈变化的数据，这些数据反应了目标运动的重要信息[2]。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e6eb4361ea9d44efa6c626a36deb721c><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>比如一个人挥舞手掌，手掌一定会在前后帧中发生最大移动，其周围图像数据发生变化最大。而这个人的身体其他部位却变化很小，数据几乎保持不变。如果能将这个变化数据提取出来，并且进一步分析其位置信息，那么可以用于区分其他动作。</p><p>时空关键点的提取方法是对空间关键点方法的扩展，空间关键点的提取则是基于多尺度的图像表达，这里的时空关键点就是将2D Harris角点的检测方法拓展到了3D，具体求解方法非常复杂读者需要自行了解，篇幅问题就不讲述了。</p><p>得到了这些点之后，基于点的一次到四次偏导数，组合成一个34维的特征向量，使用k-means对这些特征向量进行了聚类。</p><p>除了harris，经典的2D描述子SIFT被拓展到3D空间[3]，示意图如下：</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ba07cf75e0034d8b9abcaec97aafd55d><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>上图从左至右分别展示了2D SIFT特征，多个时间片的2D SIFT特征，以及3D SIFT特征，后两者的区别在于计算区域的不同，3D SIFT的每一个关键点包含3个值，幅度和两个角度。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/588f85a6870a4a9f9046f4391820f111><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>统计关键点时空周围的梯度直方图就可以形成特征描述子，然后对所有的特征描述子进行k-means聚类，划分类别，形成词汇“word”。所有不同word就构成了一个vocabulary，每个视频就可以通过出现在这个vocabulary中词汇的数量来进行描述，最后训练一个SVM或者感知器来进行动作识别。</p><p><strong>3.2 密集轨迹(dense-trajectories)[4]</strong></p><p>时空关键点是编码时空座标中的视频信息，而轨迹法iDT(improved Dense Trajectories)是另一种非常经典的方法，它追踪给定座标图像沿时间的变化。</p><p>iDT算法包含三个步骤：密集采样特征点，特征轨迹跟踪和基于轨迹的特征提取。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/293fa828b52b4d409835996651a7bc8b><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>密集采样是对不同尺度下的图像进行规则采样，不过真正被用于跟踪等不是所有点，因为平滑区域的点没有跟踪意义，通过计算每个像素点自相关矩阵的特征值，并设置阈值去除低于阈值的特征点来实现这个选择。</p><p>对轨迹的追踪是通过光流，首先计算图像光流速率(ut, vt)，然后通过这个速率来描述图像运动轨迹：</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b47a69e232de4c629af4f46bb430eb24><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>wt是密集光流场，M是中值滤波器，得到的一系列点形成了一个轨迹。由于轨迹会随着时间漂移，可能会从初始位置移动到很远的地方。所以论文对轨迹追踪距离做了限制，首先将帧数限制在L内，而且轨迹空间范围限制在WxW范围，如果被追踪点不在这个范围，就重新采样进行追踪，这样可以保证轨迹的密度不会稀疏。</p><p>除了轨迹形状特征，还提取了HOG，HOF(histogram of flow)以及MBH(motion boundary histogram)等特征。其中HOG特征计算的是灰度图像梯度的直方图，HOF计算的是光流的直方图，MBH计算的是光流梯度的直方图，也可以理解为在光流图像上计算的HOG特征，它反应了不同像素之间的相对运动。</p><p>以HOG特征为例，在一个长度为L的轨迹的各帧图像上取特征点周围大小为N×N的区域，将其在空间和时间上进行划分。假如空间划分为2*2，时间划分为3份，bins为8，则HOG特征维度为2*2*3*8=96，HOF特征和MBH特征计算类似。</p><p>提取出HOG等信息后，接下来具体的分类与上面基于时空关键点的方法类似，不再赘述。</p><p><strong>04</strong></p><p><strong>深度学习方法</strong></p><p>当前基于CNN的方法不需要手动提取特征，性能已经完全超越传统方法，以3D卷积，RNN/LSTM时序模型，双流法等模型为代表。</p><p><strong>4.1 3D卷积[5]</strong></p><p>视频相对于图像多出了一个维度，而3D卷积正好可以用于处理这个维度，因此也非常适合视频分类任务，缺点是计算量比较大，下图展示了一个简单的3D模型。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/8826af4203264d749257908e7045b2d3><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p><strong>4.2 RNN/LSTM[6]</strong></p><p>视频和语音信号都是时序信号，而RNN和LSTM正是处理时序信号的模型。如下图所示，通过CNN对每一个视频帧提取特征，使用LSTM建模时序关系。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9d822b17de7649acb13cadad1bef7c1b><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p><strong>4.3 双流法(two-stream)[7]</strong></p><p>双流法包含两个通道，一个是RGB图像通道，用于建模空间信息。一个是光流通道，用于建模时序信息。两者联合训练，并进行信息融合。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c4a9a56a1f0c44e1bff699bc6e6d23e0><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p>双流模型是视频分类中非常重要的一类模型，在特征的融合方式，光流的提取等方向都有非常多的研究。</p><p><strong>05</strong></p><p><strong>总结</strong></p><p>虽然在UCF-101数据集上评测指标已经达到了98.5%，但是视频的分类目前远没有图像分类成熟，面临着巨大的类内方差，相机运动和背景干扰，数据不足等难题。</p><p>除了要解决以上难题外，有以下几个重要方向是值得研究的。</p><p>1. 多模态信息融合。即不只是采用图像信息，还可以融合语音等信息。</p><p>2. 多标签视频分类。与多标签图像分类类似，现实生活中的视频可能有多个标签。</p><p>3. 行为定位。一段视频中的行为有开始和结束，如何定位到真正有效的片段是之后的视频分类的重要前提。</p><p>参考文献</p><p>[1] Kong Y, Fu Y. Human action recognition and prediction: A survey[J]. arXiv preprint arXiv:1806.11230, 2018.</p><p>[2] Laptev I. On space-time interest points[J]. International journal of computer vision, 2005, 64(2-3): 107-123.</p><p>[3] Scovanner P, Ali S, Shah M. A 3-dimensional sift descriptor and its application to action recognition[C]//Proceedings of the 15th ACM international conference on Multimedia. ACM, 2007: 357-360.</p><p>[4] Wang H, Kläser A, Schmid C, et al. Dense trajectories and motion boundary descriptors for action recognition[J]. International journal of computer vision, 2013, 103(1): 60-79.</p><p>[5] Ji S, Xu W, Yang M, et al. 3D convolutional neural networks for human action recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2012, 35(1): 221-231.</p><p>[6] Donahue J, Anne Hendricks L, Guadarrama S, et al. Long-term recurrent convolutional networks for visual recognition and description[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 2625-2634.</p><p>[7] Simonyan K, Zisserman A. Two-stream convolutional networks for action recognition in videos[C]//Advances in neural information processing systems. 2014: 568-576.</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bca3a792f54f451486006baa5f13187a><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-center><br></p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5fe02161319a438db4a2cb7aabe02476><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-center>星标我，每天多一点智慧</p><div class=pgc-img><img alt=视频分类/行为识别研究综述，从数据集到方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e569b55579884ffeb16d4e73baf238ab><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'视频','分类','行为'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>