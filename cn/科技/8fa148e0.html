<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>基于CDC技术的ElasticSearch索引同步机制 | 极客快訊</title><meta property="og:title" content="基于CDC技术的ElasticSearch索引同步机制 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/SDAIrbpCGdpuDg"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8fa148e0.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8fa148e0.html><meta property="article:published_time" content="2020-10-29T21:09:58+08:00"><meta property="article:modified_time" content="2020-10-29T21:09:58+08:00"><meta name=Keywords content><meta name=description content="基于CDC技术的ElasticSearch索引同步机制"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/8fa148e0.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>基于CDC技术的ElasticSearch索引同步机制</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>Flink 从入门到精通 系列文章</p><p></p><h1 toutiao-origin=h3>概述</h1><p>ElasticSearch作为一个基于Lucene的搜索引擎被广泛应用于各种应用系统，比如电商、新闻类、咨询类网站。在使用ElasticSearch开发应用的过程中，一个非常重要的过程是将数据导入到ElasticSearch索引中建立文档。在一开始系统规模比较小时，我们可以使用logstash来同步索引。logstash的好处是开方量少，只要进行编写简单的索引模板和同步sql，就能快速搭建索引同步程序。但是随着应用数据规模的变大，索引变化变得非常频繁。logstash的缺点也随着暴露，包括：</p><p>（1）不支持删除，只能通过修改字段属性软删除，随着应用使用时间的增长，ElasticSearch中会留存大量的无用数据，拖慢搜索速度。（2）sql分页效率低，sql查询慢。logstash的分页逻辑是先有一个大的子查询，然后再从子查询中分页获取数据，因此效率低下，当数据库数据量大时，一个分页查询就需要几百秒。同步几千万数据可能需要1天时间。</p><p>因此我们决定放弃使用logstash，而改用使用canal来搭建基于CDC技术的ElasticSearch索引同步机制。</p><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>系统架构设计</strong></h1><img alt=基于CDC技术的ElasticSearch索引同步机制 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/SDAIrbpCGdpuDg><p>如图所示，索引同步系统由几个部分组成，下面分点介绍。</p><p>（1）数据库</p><p>原始数据数据库</p><p>（2）Canal</p><p>Canal是阿里云开源的MySql数据库增量数据订阅和消费工具。它的实现原理是将自己伪装为一个MySQL slave，向MySql ma ster发送dump协议；MySQL master收到dump请求，开始推送binary log给slave，canal解析binary log对象。</p><p>（3）Canal Client</p><p>Canal Client是自己实现的程序，通过从Canal Server中获取经过Canal解析之后的数据库binlog日志，做相应的业务逻辑处理。在本文介绍的基于CDC的索引同步系统中，Canal Client订阅搜索相关的数据库表的binlog日志，如果跟数据搜索相关的数据发生变化时，就向Rabbit发一条消息，表明数据发生变化了，通知同步Worker从MySQL同步数据到ES。</p><p>（4）RabbitMQ</p><p>消息队列，也可以选用Kafaka等其他消息队列，根据具体业务确定。</p><p>（5）索引同步Worker</p><p>Worker从消息队列中消费数据，根据消息从MySQL获取相应的数据并同步到ElasticSearch中。</p><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>Canal Client实现</strong></h1><p>Canal Client从Canal Server中获取binlog日志，并根据业务需求进行处理。以下通过一些关键代码介绍Canal Client的实现。</p><p>（1）在pom中添加Canal client的依赖。</p><pre><code>&lt;dependency&gt;<br>&lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt;<br>&lt;artifactId&gt;canal.client&lt;/artifactId&gt;<br>&lt;version&gt;1.1.0&lt;/version&gt;<br>&lt;/dependency&gt;<br></code></pre><p>（2）初始化Canal连接</p><p>CanalConfig包含了Canal的配置信息。CanalConnector为canal-client包中的类，我们通过这个类来连接server，获取binlog，关闭server。该服务基于SpringBoot。因此init会在CanalClientInitializer bean被创建时被调用，preDestory会在服务关闭，CanClientInitializer被销毁时被调用。</p><pre><code>@Component<br>@Slf4j<br>public class CanalClientInitializer {<br><br><br>CanalConfig canalConfig;<br><br>CanalConnector connector;<br><br>CanalDataProcessor canalDataProcessor;<br><br><br>public CanalClientInitializer(@Autowired CanalConfig canalConfig, @Autowired CanalDataProcessor canalDataProcessor) {<br>this.canalConfig = canalConfig;<br>this.canalDataProcessor = canalDataProcessor;<br>}<br><br><br>@PostConstruct<br>public void init throws InterruptedException {<br>connector = CanalConnectors.newSingleConnector(new InetSocketAddress(canalConfig.getIp, canalConfig.getPort), canalConfig.getDestination, "", "");<br>//建立连接<br>connector.connect;<br>//订阅相关的表<br>connector.subscribe(canalConfig.getSyncTable);<br>canalDataProcessor.process(connector);<br>}<br><br><br>@PreDestroy<br>public void<strong class=highlight-text toutiao-origin=span>preDestroy</strong> {<br>log.info("stop the canal client");<br>canalDataProcessor.stopProcess;<br>}<br><br>}<br></code></pre><p>（3）CanalDataProcessor获取并处理binlog</p><pre><code>@Component<br>@Slf4j<br>public class CanalDataProcessor {<br><br><br>boolean isRunning;<br><br>RabbitTemplate rabbitTemplate;<br><br>TableChangeProcessor tableChangeProcessor;<br><br>public CanalDataProcessor(@Autowired RabbitTemplate rabbitTemplate, @Autowired TableChangeProcessor processor) {<br>this.rabbitTemplate = rabbitTemplate;<br>this.tableChangeProcessor = processor;<br>}<br><br>@Async<br>public void process(CanalConnector connector) throws InterruptedException {<br>isRunning = true;<br>while (isRunning) {<br>try {<br>//获取消息<br>Message message = connector.getWithoutAck(100, 10L, TimeUnit.SECONDS);<br>//业务处理逻辑<br>processMessage(message);<br>//消息被成功执行，向Canal Server发送ack消息通知server该message已经被处理完成<br>connector.ack(message.getId);<br>} catch (Exception e) {<br>log.error("wtf", e);<br>//当消息没被成功处理完成时进行回滚，下次能够重新获取该Message<br>connector.rollback;<br>Thread.sleep(1000);<br>}<br>}<br>connector.disconnect;<br>}<br><br><br>public void<strong class=highlight-text toutiao-origin=span>stopProcess</strong> {<br>isRunning = false;<br>}<br><br><br>private void processMessage(Message message) {<br>for(Entry entry : message.getEntries) {<br>try {<br>tableChangeProcessor.process(entry);<br>} catch (Exception e) {<br>log.error("wtf", e);<br>continue;<br>}<br>}<br>}<br>}<br></code></pre><p>（4）TableChangeProcessor</p><p>TableChangeProcessor中为具体的业务逻辑，处理Message，获取跟搜索相关的数据变化，发送相应的消息到消息队列中。注意点 （1）忽略搜索无关的数据字段变化，避免不必要的索引更新，降低服务器压力。如Products表中有一个product_weight表示商品重量发生了变化，但其实商品重量跟搜索无关，那就不要关心这个变化。</p><p>（2）对于搜索中不会出现的数据，不要写入到ES中，比如电商商品中的下架商品，另外，如果商品被下架，则要进行监听通知索引同步Worker从es中删除索引文档。这样能够降低ES中总的索引文档数量，提升搜索效率。</p><p>（3）要考虑Rabbit挂掉或者队列写满，消息无法写入的情况；首先应该在Rabbit发送消息时添加重试，其次应该在重试几次还是失败的情况下抛出异常，canal消息流回滚，下次还是能够获取到这个数据变化的Canal消息，避免数据变动的丢失。</p><p>（4）注意目前Canal只支持单Client。如果要实现高可用，则需要依赖于ZooKeeper，一个Client作为工作Client，其余Client作为冷备，当工作Client挂掉时，冷备Client监听到ZooKeeper数据变化，抢占锁成为工作Client。</p><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>Canal Worker实现</strong></h1><p>索引同步Worker从消息队列中获取Canal Client发送的跟搜索相关的数据库变化消息。举个例子，比如商品表中跟搜索相关的字段发生了变化，Canal Client会发送以下一条数据：</p><pre><code>{<br>"change_id": "694212527059369984",<br>"change_type": 1, //商品发生变化<br>"change_time": "1600741397"<br>}<br></code></pre><p>在Worker中监听队列消息：</p><pre><code>@Component<br>@Slf4j<br>public class ProductChangeQueueListener {<br><br>@Autowired<br>@Qualifier("snake")<br>ObjectMapper om;<br><br>@Autowired<br>ChangeEventHandlerFactory changeEventHandlerFactory;<br><br>@RabbitListener(queues = RabbitConfig.PRODUCT_QUEUE_NAME, containerFactory = "customRabbitListenerContainerFactory")<br>public void onChange(Message message) {<br><br>ChangeEvent event = parse(message);<br>if(event == ) {<br>return;<br>}<br><br>changeEventHandlerFactory.handle(event);<br>}<br><br>private ChangeEvent parse(Message message) {<br>ChangeEvent event = ;<br>try {<br>event = om.readValue(new String(message.getBody), ChangeEvent.class);<br>} catch (Exception e) {<br>log.error("同步失败，解析失败", e);<br>}<br>return event;<br>}<br><br><br>}<br></code></pre><p>ChangeEventHandlerFactory为事件处理器的工厂类。以下为一个事件处理器的实现。它监听changeType为CHANGE_TYPE_OUT_PRODUCT的事件，从数据库中获取到变动的数据，构建ES的IndexRequest，并将Request存入到RequestBulkBuffer中，等待批量同步到ES中。有些同学可能会有疑问，为何不直接从Canal中获取数据，主要原因是Canal中只包含了单表数据，但是索引文档可能包含了多表的数据，因此还需要从MySQL获取数据。如果索引文档中只包含单表数据，可以考虑在ChangeEvent中包含修改之后的数据，索引同步Woker就不用再从MySql中再获取一遍数据，提升Worker工作效率。</p><pre><code>@Component<br>@Slf4j<br>public class OutProductEventHandler implements ChangeEventHandler {<br><br>@Autowired<br>ProductDao productDao;<br><br>@Autowired<br>RequestBulkBuffer buffer;<br><br><br>@Autowired<br>OutProductChangeRequestBuilder builder;<br><br>@Override<br>@Retryable<br>public boolean handle(ChangeEvent changeEvent) {<br>if (!match(changeEvent)) {<br>return false;<br>}<br><br>Tuple dataTuple = productDao.getProductWithStore(changeEvent.getChangeId);<br>if (dataTuple == ) {<br>return true;<br>}<br>Product product = dataTuple.get(QProduct.product);<br>Store store = dataTuple.get(QStore.store);<br><br>IndexRequest request = ;<br>try {<br>request = builder.convertToUpdateQuery(getTimestampNow, product, store);<br>} catch (Exception e) {<br>log.error("wtf", e);<br>}<br>if (request == ) {<br>return true;<br>}<br>buffer.add(request);<br>return true;<br><br>}<br><br>@Override<br>public boolean match(ChangeEvent changeEvent) {<br>return ChangeEvent.CHANGE_TYPE_OUT_PRODUCT == changeEvent.getChangeType;<br>}<br>}<br></code></pre><p>在上面的OutProductEventHandler类中，我们并不直接在该类中使用RestHighLevelClient将文档更新到ES索引，而是将IndexRequest暂存到RequestBulkBuffer中。RestBulkBuffer使用CircularFifoBuffer作为存储数据结构。</p><pre><code>@Component<br>public class RequestBulkBuffer {<br><br>CircularFifoBuffer buffer;<br><br>public RequestBulkBuffer(CircularFifoBuffer buffer) {<br>this.buffer = buffer;<br>}<br><br><br>public void add(DocWriteRequest&lt;?&gt; request) {<br>buffer.add(request);<br>}<br><br>}<br></code></pre><p>CircularFifoBuffer是一个经过改造的环形队列实现。允许多线程写，在我们这个应用场景中只支持也只需支持单线程读->处理->移除处理完的数据。当环形队列缓存满时，借助于semaphore，写入线程将会被阻塞，在后面的Worker如何防止数据丢失中，我们来阐述为什么要这么做。</p><pre><code>/**<br>* 允许多线程写<br>* 只允许单线程-&gt;读-&gt;处理-&gt;移除<br>*/<br>public class CircularFifoBuffer {<br><br>private Logger logger = LoggerFactory.getLogger(CircularFifoBuffer.class.getName);<br><br><br>private transient Object elements;<br><br>private transient int start = 0;<br>private transient int end = 0;<br><br>private transient boolean full = false;<br><br>private final int maxElements;<br><br>private ReentrantLock addLock;<br><br>private Semaphore semaphore;<br><br>public CircularFifoBuffer(int size) {<br>if (size &lt;= 0) {<br>throw new IllegalArgumentException("The size must be greater than 0");<br>}<br>elements = new Object[size];<br>maxElements = elements.length;<br>addLock = new ReentrantLock;<br>semaphore = new Semaphore(size);<br>}<br><br><br>public int<strong class=highlight-text toutiao-origin=span>size</strong> {<br>int size = 0;<br><br>if (end &lt; start) {<br>size = maxElements - start + end;<br>} else if (end == start) {<br>size = (full ? maxElements : 0);<br>} else {<br>size = end - start;<br>}<br><br>return size;<br>}<br><br>public boolean<strong class=highlight-text toutiao-origin=span>isEmpty</strong> {<br>return size == 0;<br>}<br><br>public boolean<strong class=highlight-text toutiao-origin=span>isFull</strong> {<br>return size == maxElements;<br>}<br><br>public int<strong class=highlight-text toutiao-origin=span>maxSize</strong> {<br>return maxElements;<br>}<br><br>public void<strong class=highlight-text toutiao-origin=span>clear</strong> {<br>full = false;<br>start = 0;<br>end = 0;<br>Arrays.fill(elements, );<br>}<br><br>public boolean add(Object element) {<br>if ( == element) {<br>throw new PointerException("Attempted to add object to buffer");<br>}<br><br>addLock.lock;<br>try {<br>semaphore.acquire;<br>} catch (Exception e) {<br>logger.error("RingBuffer", "线程退出，添加失败");<br>return false;<br>}<br><br>elements[end++] = element;<br><br><br>if (end &gt;= maxElements) {<br>end = 0;<br>}<br><br>if (end == start) {<br>full = true;<br>}<br><br>addLock.unlock;<br><br>return true;<br><br>}<br><br>public Object<strong class=highlight-text toutiao-origin=span>get</strong> {<br>if (isEmpty) {<br>return ;<br>}<br><br>return elements[start];<br>}<br><br><br>public Object<strong class=highlight-text toutiao-origin=span>remove</strong> {<br>if (isEmpty) {<br>return ;<br>}<br><br>Object element = elements[start];<br>if( != element) {<br>elements[start++] = ;<br>if (start &gt;= maxElements) {<br>start = 0;<br>}<br>full = false;<br>semaphore.release;<br>}<br>return element;<br>}<br><br><br>/**<br>* @param size the max size of elements will return<br>*/<br>public Object get(int size) {<br>int queueSize = size;<br>if (queueSize == 0) { //empty<br>return new Object[0];<br>}<br>int realFetchSize = queueSize &gt;= size ? size : queueSize;<br>if (end &gt; start) {<br>return Arrays.copyOfRange(elements, start, start + realFetchSize);<br>} else {<br>if (maxElements - start &gt;= realFetchSize) {<br>return Arrays.copyOfRange(elements, start, start + realFetchSize);<br>} else {<br>return ArrayUtils.addAll(<br>Arrays.copyOfRange(elements, start, maxElements),<br>Arrays.copyOfRange(elements, 0, realFetchSize - (maxElements - start))<br>);<br>}<br>}<br>}<br><br><br>public Object<strong class=highlight-text toutiao-origin=span>getAll</strong> {<br>return get(size);<br>}<br><br><br><br>public Object remove(int size) {<br>if(isEmpty) {<br>return new Object[0];<br>}<br>int queueSize = size;<br>int realFetchSize = queueSize &gt;= size ? size : queueSize;<br>Object  retArr = new Object[realFetchSize];<br>for(int i=0;i&lt;realFetchSize;i++) {<br>retArr[i] = remove;<br>}<br><br>return retArr;<br>}<br><br>}<br></code></pre><p>下面这个类为缓存的消费者，它循环从buffer中获取一定数据的数据，并使用RestHighLevelClient将数据批量同步到ES。在Worker启动时，会创建一个线程调用startConsume，在服务关闭时该线程结束。</p><pre><code>@Slf4j<br>public class RequestBulkConsumer {<br>private static final int DEFAULT_BULK_SIZE = 2000;<br><br>private CircularFifoBuffer buffer;<br>private EsBulkRequestService service;<br><br>private boolean isRunning = false;<br>private int bulkSize = DEFAULT_BULK_SIZE;<br><br>public RequestBulkConsumer(CircularFifoBuffer buffer, RestHighLevelClient client) {<br>this.buffer = buffer;<br>this.service = new EsBulkRequestService(client);<br>}<br><br>public void setBulkSize(int size) {<br>this.bulkSize = size;<br>}<br><br>public int<strong class=highlight-text toutiao-origin=span>getBulkSize</strong> {<br>return bulkSize;<br>}<br><br>public boolean<strong class=highlight-text toutiao-origin=span>isRunning</strong> {<br>return isRunning;<br>}<br><br><br>public void<strong class=highlight-text toutiao-origin=span>startConsume</strong> {<br>if(isRunning) {<br>return;<br>}<br>isRunning = true;<br>while(true) {<br>if(!isRunning) {<br>break;<br>}<br><br>Object  items = buffer.get(bulkSize);<br>if(items.length == 0) {<br>try {<br>Thread.sleep(1000);<br>} catch (InterruptedException e) {<br>break;<br>}<br>} else {<br>List&lt;DocWriteRequest&lt;?&gt;&gt; requests = convert(items);<br>try {<br>BulkResponse response = service.request(requests);<br>processResponse(response);<br>buffer.remove(items.length);<br>if (items.length &lt; bulkSize) {<br>Thread.sleep(3000);<br>}<br>} catch (InterruptedException e) {<br>break;<br>} catch (IOException e) {<br>log.error("wtf", e);<br>} catch (Exception e) {<br>log.error("wtf", e);<br>buffer.remove(items.length);<br>}<br>}<br>}<br>}<br><br><br>private List&lt;DocWriteRequest&lt;?&gt;&gt; convert(Object [] items) {<br>return Stream.of(items)<br>.map(i -&gt; {<br>if(i instanceof DocWriteRequest) {<br>return (DocWriteRequest&lt;?&gt;) i;<br>} else {<br>return ;<br>}<br>})<br>.filter(Objects::non)<br>.collect(Collectors.toList);<br>}<br><br>public void<strong class=highlight-text toutiao-origin=span>stop</strong> {<br>isRunning = false;<br>}<br><br><br>private void processResponse(BulkResponse bulkResponse) {<br>BulkItemResponse  itemResponseArr = bulkResponse.getItems;<br>for(BulkItemResponse resp : itemResponseArr) {<br>DocWriteResponse docWriteResponse = resp.getResponse;<br>if(docWriteResponse instanceof IndexResponse) {<br>IndexResponse indexResponse = (IndexResponse) docWriteResponse;<br>if(indexResponse.getResult != Result.CREATED &amp;&amp; indexResponse.getResult != Result.UPDATED) {<br>if(indexResponse.status == RestStatus.CONFLICT) {<br>continue;<br>} else {<br>log.error("索引更新失败: {}, {}", indexResponse.getId, resp.getFailureMessage);<br>}<br>}<br>} else if(docWriteResponse instanceof DeleteResponse) {<br>DeleteResponse deleteResponse = (DeleteResponse) docWriteResponse;<br>if(deleteResponse.getResult != Result.DELETED) {<br>log.error("索引删除失败: {}, {}", deleteResponse.getId, resp.getFailureMessage);<br>}<br>}<br>}<br>}<br>}<br><br></code></pre><p>以下为Worker的主要几个类的代码。在索引同步系统中，高可用并不是最重要的，因为我们的搜索本身是一个准实时系统，只需要保证最终一致性就可以了，我们主要需要避免的是数据变更的丢失。以下说明在Worker中是如何避免数据丢失的。</p><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>避免数据丢失</strong></h1><p>（1）如果Rabbit挂掉，没关系，Canal Client那边在Rabbit挂掉期间无法消费binlog，会等待Rabbit重启之后再处理数据变化。Worker只要能做到Rabbit重启之后重连就行。</p><p>（2）如果MySQL挂掉，则Worker无法从数据库中获取数据，则消息处理失败，消息会堆积在Rabbit中。等MySQL重新上线之后，消息重新开始处理，数据也不会丢失。</p><p>（3）如果ES挂掉，则批量处理线程消费buffer中的数据时会失败，buffer会被生产者填满，由于CircularFifoBuffer在被填满时使用了信号量阻塞生产者线程，消息又会被堆积在Rabbit中，等待ES重新上线之后，消息重新开始处理，数据也不会丢失。</p><p>（4）如果Rabbit队列被写满，emmm，设置好在内存被占满时将消息写入硬盘然后搞一个大一点的硬盘吧，Rabbit默认应该就是这么做的。然后做好预警，当消息达到一定量时抓紧处理，一般来说可能性不是很大。</p><p>（5）版本冲突，如果商品表中某一条数据如商品A在同一秒内变化了两次，消息队列中有连续两条消息，又由于这两条消息可能在两个线程中被消费，由于网络，计算机性能等原因，先变的数据后被写入ES中，导致ES中数据和MySql数据不一致。因此我们在更新索引时使用ES的外部版本号。使用从MySQL中取数据时的时间戳作为版本号，只有当时间戳比当前版本号大或相等时才能变更文档，否则ES会报版本冲突错误。</p><pre><code> private IndexRequest convertToUpdateQuery(Long timestamp, OutStoreProduct outStoreProduct) throws JsonProcessingException {<br>IndexRequest indexRequest = new IndexRequest(indexName, "doc", outStoreProduct.getId);<br>if(StringUtils.isEmpty(outStoreProduct.getTooEbaoProductId)) {<br>log.error("商品 {} 的ebaoProductId为空，无法同步", outStoreProduct.getId);<br>return ;<br>}<br>indexRequest.source(om.writeValueAsString(outStoreProduct), XContentType.JSON)<br>.versionType(VersionType.EXTERNAL_GTE)<br>.version(timestamp)<br>.routing(outStoreProduct.getTooEbaoProductId);<br>return indexRequest;<br>}<br></code></pre><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>关于全量同步</strong></h1><p>以上只是实现了增量同步，在索引初始化时，我们需要做全量同步操作，将数据从数据库初始化到ES索引中。我们可以在Worker中写一个接口，该接口实现逻辑分批将数据同步任务发到消息队列中，其它worker收到消息后完成对应任务。比如我们可以发布每一个门店的数据同步任务，worker每收到一个消息，同步一个门店的数据。</p><p></p><h1 toutiao-origin=h3><strong toutiao-origin=h1>总结</strong></h1><p>综上，本系统是一个近实时的能够保证ES和MySQL数据一致性的高效索引同步系统。</p><blockquote><p>作者：Tango2100 链接：https://juejin.im/post/6875591758802059278</p></blockquote><pre><br><div><img alt=基于CDC技术的ElasticSearch索引同步机制 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RdIEj9hARSR1DD></div><br><div><ul><li><p>基于 Apache Flink 的实时监控告警系统</p></li><li><p>关于数据中台的深度思考与总结（干干货）</p></li><li><p>日志收集Agent，阴暗潮湿的地底世界</p></li><li><p>2020 继续踏踏实实的做好自己</p></li></ul></div></pre><img alt=基于CDC技术的ElasticSearch索引同步机制 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S0FUMtl41NrEMK><img alt=基于CDC技术的ElasticSearch索引同步机制 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S0FUNTDJBxRdKz><pre><div><div><div><div><div><p>公众号(<strong class=highlight-text toutiao-origin=span>zhisheng</strong>)里回复 面经、ClickHouse、ES、Flink、<strong class=highlight-text toutiao-origin=span>Spring、Java、Kafka、监控 </strong>等关键字可以查看更多关键字对应的文章。</p></div></div></div></div></div></pre><pre><div><div><div><div><div><div><div><div><div><div><div><div><div><div><p><strong toutiao-origin=span>👇</strong></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></pre></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'CDC','技术','ElasticSearch'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>