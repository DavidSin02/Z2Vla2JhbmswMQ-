<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>吴恩达深度学习笔记(89)-迁移学习（Transfer Learning） | 极客快訊</title><meta property="og:title" content="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/d934f6fbf66144dca95cbb6ce8223d62"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9819f021.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9819f021.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9819f021.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/9819f021.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>迁移学习（Transfer Learning）</h1><p>如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。</p><p>计算机视觉的研究社区非常喜欢把许多数据集上传到网上，如果你听说过，比如<strong>ImageNet</strong>，或者<strong>MS_COCO</strong>，或者<strong>Pascal类</strong>型的数据集，这些都是不同数据集的名字，它们都是由大家上传到网络的，并且有大量的计算机视觉研究者已经用这些数据集训练过他们的算法了。</p><p>有时候这些训练过程需要花费好几周，并且需要很多的GPU，其它人已经做过了，并且经历了非常痛苦的寻最优过程，这就意味着你可以下载花费了别人好几周甚至几个月而做出来的开源的权重参数，把它当作一个很好的初始化用在你自己的神经网络上。<strong>用迁移学习把公共的数据集的知识迁移到你自己的问题上，让我们看一下怎么做。</strong></p><h1>来个栗子</h1><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d934f6fbf66144dca95cbb6ce8223d62><p class=pgc-img-caption></p></div><p>举个例子，假如说你要建立一个猫咪检测器，用来检测你自己的宠物猫。</p><p>比如网络上的Tigger，是一个常见的猫的名字，Misty也是比较常见的猫名字。</p><p>假如你的两只猫叫Tigger和Misty，还有一种情况是，两者都不是。所以你现在有一个三分类问题，图片里是Tigger还是Misty，或者都不是，我们忽略两只猫同时出现在一张图片里的情况。现在你可能没有Tigger或者Misty的大量的图片，所以你的训练集会很小，你该怎么办呢？</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d89e302b3e2b439a8aeac31bc763172a><p class=pgc-img-caption></p></div><p>我建议你从网上下载一些神经网络开源的实现，不仅<strong>把代码下载下来，也把权重下载下来</strong>。</p><p>有许多训练好的网络，你都可以下载。举个例子，ImageNet数据集，它有1000个不同的类别，因此这个网络会有一个Softmax单元，它可以输出1000个可能类别之一。</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c5f18a2361a749d184ae04c1f40ab2eb><p class=pgc-img-caption></p></div><p>你可以<strong>去掉上图中的这个Softmax层，创建你自己的Softmax单元，用来输出Tigger、Misty和neither三个类别</strong>。</p><p>就网络而言，我建议你把所有的层看作是冻结的，你冻结网络中所有层的参数，你只需要训练和你的Softmax层有关的参数。这个Softmax层有三种可能的输出，Tigger、Misty或者都不是。</p><p>通过使用其他人预训练的权重，你很可能得到很好的性能，即使只有一个小的数据集。幸运的是，大多数深度学习框架都支持这种操作，事实上，取决于用的框架，它也许会有trainableParameter=0这样的参数，对于这些前面的层，你可能会设置这个参数。</p><p>为了不训练这些权重，有时也会有freeze=1这样的参数。不同的深度学习编程框架有不同的方式，允许你指定是否训练特定层的权重。在这个例子中，你只需要训练softmax层的权重，把前面这些层的权重都冻结。</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6a553e14f0594887a7078eba650185f0><p class=pgc-img-caption></p></div><p><strong>另一个技巧</strong>，也许对一些情况有用，由于前面的层都冻结了，相当于一个固定的函数，不需要改变。因为你不需要改变它，也不训练它，取输入图像X，然后把它<strong>映射到这层（softmax的前一层）的激活函数</strong>。</p><p>所以这个能加速训练的技巧就是，如果我们先计算这一层（紫色箭头标记），<strong>计算特征或者激活值，然后把它们存到硬盘里</strong>。你所做的就是用这个固定的函数，在这个神经网络的前半部分（softmax层之前的所有层视为一个固定映射），取任意输入图像X，然后计算它的某个特征向量，这样你训练的就是一个很浅的softmax模型，用这个特征向量来做预测。</p><p>对你的计算有用的一步就是对你的训练集中所有样本的这一层的激活值进行预计算，然后存储到硬盘里，然后在此之上训练softmax分类器。所以，存储到硬盘或者说预计算方法的优点就是，你不需要每次遍历训练集再重新计算这个激活值了。</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f0d389774421415fba2b4c72ab9a5da2><p class=pgc-img-caption></p></div><p>因此如果你的任务只有一个很小的数据集，你可以这样做。</p><p>要有一个更大的训练集怎么办呢？</p><p>根据经验，如果你有一个更大的标定的数据集，也许你有大量的Tigger和Misty的照片，还有两者都不是的，这种情况，你应该冻结更少的层，比如只把上图中前面括起来的这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元，Tigger、Misty或者两者都不是三个类别。有很多方式可以实现，你可以取后面几层的权重，用作初始化，然后从这里开始梯度下降。</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3757757700af4db68fb4321d7f65d0c3><p class=pgc-img-caption></p></div><p>或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的softmax输出层，这些方法值得一试。但是有一个规律，如果你有越来越多的数据，你需要冻结的层数越少，你能够训练的层数就越多。这个理念就是，如果你有一个更大的数据集，也许有足够多的数据，那么不要单单训练一个softmax单元，而是考虑训练中等大小的网络，包含你最终要用的网络的后面几层。</p><div class=pgc-img><img alt="吴恩达深度学习笔记(89)-迁移学习（Transfer Learning）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1b817e19c0064c2fad3f9b873a9f528f><p class=pgc-img-caption></p></div><p>最后，如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这、所有的权重当作初始化，然后训练整个网络。再次注意，如果这是一个1000节点的softmax，而你只有三个输出，你需要你自己的softmax输出层来输出你要的标签。</p><p>如果你有越多的标定的数据，或者越多的Tigger、Misty或者两者都不是的图片，你可以训练越多的层。极端情况下，你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。</p><p>这就是卷积网络训练中的迁移学习，事实上，网上的公开数据集非常庞大，并且你下载的其他人已经训练好几周的权重，已经从数据中学习了很多了，你会发现，对于很多计算机视觉的应用，如果你下载其他人的开源的权重，并用作你问题的初始化，你会做的更好。</p><p>在所有不同学科中，在所有深度学习不同的应用中，我认为计算机视觉是一个你经常用到迁移学习的领域，除非你有非常非常大的数据集，你可以从头开始训练所有的东西。总之，迁移学习是非常值得你考虑的，除非你有一个极其大的数据集和非常大的计算量预算来从头训练你的网络。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'学习','吴恩达','笔记'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../cn/%E7%A7%91%E6%8A%80/3605c009.html alt="吴恩达深度学习笔记(67)-迁移学习（Transfer learning)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f00ccb946c7a451aa25adba4b28799e5 style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E6%8A%80/3605c009.html title="吴恩达深度学习笔记(67)-迁移学习（Transfer learning)">吴恩达深度学习笔记(67)-迁移学习（Transfer learning)</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>