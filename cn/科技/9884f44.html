<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>变量系数对机器学习（ML）回归模型精度的影响分析 | 极客快訊</title><meta property="og:title" content="变量系数对机器学习（ML）回归模型精度的影响分析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/6faaa884abc3438681dcb4217d580cd5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9884f44.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9884f44.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9884f44.html><meta property="article:published_time" content="2020-10-29T20:58:14+08:00"><meta property="article:modified_time" content="2020-10-29T20:58:14+08:00"><meta name=Keywords content><meta name=description content="变量系数对机器学习（ML）回归模型精度的影响分析"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/9884f44.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>变量系数对机器学习（ML）回归模型精度的影响分析</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6faaa884abc3438681dcb4217d580cd5><p class=pgc-img-caption></p></div><p>R平方（R²），均方误差（MSE），平均绝对误差（MAE）和均方根误差（RMSE）是衡量连续变量准确度的最常用指标。在这篇文章中，我们将观察变量系数（CoV）对MAE，MSE，R²和Accuracy 的影响。我们将相同的线性回归应用于4个不同的数据，这些数据具有不同系数的变量，以解释MSE，MAE，R²和Accuracy 如何以及为何发生变化。首先，当我们保持MSE和MAE固定时，我们将通过变量系数的变化观察R²和Accuracy 。其次，在保持R 2和Accuracy 固定的同时，我们将观察MSE和MAE随变量系数的变化。</p><h1>导入Python库：</h1><pre>import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom itertools import countfrom sklearn import metricsimport statsmodels.api as smfrom sklearn.linear_model import LinearRegression%matplotlib inline</pre><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/674851c4ff8848eeb98fa5e2cb45e91c><p class=pgc-img-caption></p></div><h1>1.恒定MSE和增加R²</h1><p>我们将创建具有不同系数变量的4个不同数据（D1，D2，D3，D4）。首先，我们保持对D1，D2，D3和D4的MSE和MAE固定，而D1，D2，D3和D4的变量系数值分别为0.1,0.5,1,10。</p><blockquote><p>Data1（D1） = 0.1 + 0.1 * X_1 + 0.1 * X_2 + 0.1 * X_3 +（Random Error）</p></blockquote><p>虽然常数和变量系数（CoV）是0.1，但我们将添加具有误差系数（CoE）= 0.1的随机误差。我们将看到CoE = 0.1 / CoV = 0.1速率对Accuracy 和R²的影响。</p><blockquote><p>Data2（D2） = 0.5 + 0.5 * X_1 + 0.5 * X_2 + 0.5 * X_3 +（Random Error）</p></blockquote><p>当常数和CoV为0.5时，我们将添加CoE = 0.1的随机误差。观察Accuracy 和R²对CoE = 0.1 / CoV = 0.5的影响。</p><blockquote><p>Data3（D3） = 1 + 1 * X_1 + 1 * X_2 + 1 * X_3 +（Random Error）</p></blockquote><p>当常数和系数为1时，我们将添加CoE = 0.1的随机误差。</p><blockquote><p>Data4（D4） = 10 + 10 * X1 + 10 * X2 + 10 * X3 +（RandomError）</p></blockquote><pre>input_dim = 3output_dim = 1size = 1000total_size = size * input_dimrand_state = np.random.RandomState(42)X = np.array([rand_state.rand() for i in range(total_size)], dtype=np.float32)X = X.reshape(-1, input_dim)#coefficientscoeff=[] alfa=[0.1, 0.5, 1, 10] for i in alfa:coeff.append(np.array([1*i, 1*i, 1*i], dtype=np.float32))noise = 0.1*rand_state.normal(0,1,size)Y=[]for i in range(0, len(coeff)):Y.append((X.dot(coeff[i]) + alfa[i] + noise).reshape(-1, output_dim))train_size = int(0.7*size)X_train=[]X_test=[]Y_train=[]Y_test=[]LR=[]Y_test_pred=[]for i in range(0, len(coeff)): X_train.append(X[:train_size]) X_test.append(X[train_size:]) Y_train.append(Y[i][:train_size]) Y_test.append(Y[i][train_size:]) LR.append(LinearRegression().fit(X_train[i], Y_train[i])) Y_test_pred.append(LR[i].predict(X_test[i]))Y_test_=[]Y_test_pred_=[]new=[]for i in range(0, len(coeff)): Y_test_.append(pd.DataFrame(Y_test[i])) Y_test_pred_.append(pd.DataFrame(Y_test_pred[i])) new.append(pd.concat([Y_test_[i], Y_test_pred_[i]], axis=1, join='inner')) new[i].columns = ['actual', 'Predict']#for loop to calculate accuracyAcr=[]Accuracy=[]for i in range(0,len(coeff)): Acr.append(new[i].iloc[0:301,].min(axis=1)/new[i].iloc[0:301,].max(axis=1)) Accuracy.append(np.mean(Acr[i]))D_MSE=[]D_MAE=[]D_R2=[]D_EVS=[]D_Accuracy=[]#calculate the metricsfor i in range (0, len(coeff)): D_MSE.append(metrics.mean_squared_error(Y_test_[i],Y_test_pred_[i])) D_MAE.append((metrics.mean_absolute_error(Y_test_[i],Y_test_pred_[i]))) D_R2.append((metrics.r2_score(Y_test_[i],Y_test_pred_[i]))) D_EVS.append((metrics.explained_variance_score(Y_test_[i],Y_test_pred_[i]))) D_Accuracy.append(Accuracy[i])</pre><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a55a8f4acfe8402dba3988cb474031aa><p class=pgc-img-caption></p></div><p>现在我们将比较指标，Python代码如下：</p><pre>data = [['MSE',D_MSE[0], D_MSE[1], D_MSE[2], D_MSE[3]],['MAE',D_MAE[0], D_MAE[1], D_MAE[2], D_MAE[3]], ['R^2',D_R2[0], D_R2[1], D_R2[2], D_R2[3]], ['ACR', D_Accuracy[0], D_Accuracy[1], D_Accuracy[2], D_Accuracy[3]]]df = pd.DataFrame(data,columns=['Metric','D1', 'D2', 'D3', 'D4'])print (np.round(df,3))####################with sns.axes_style("darkgrid", {"axes.facecolor": "0.8"}): sns.set_context("poster") sns.factorplot(data=np.round(df, 3), kind="point", col="Metric", color='purple')</pre><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a523ff9218a1403e881e9c9a1295a266><p class=pgc-img-caption></p></div><p>度量表：</p><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fe7c1b5bab5c4fb8bc459fa5fdfac1c7><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/265a53c8c61c4841a5aa02a6957fc7f2><p class=pgc-img-caption></p></div><p>我们保持D1，D2，D3和D4的误差固定，而D1，D2，D3和D4的CoV值分别为0.1,0.5,1,10。我们对D1应用了0.1 / 0.1（CoE / CoV） rate，对D4应用了0.1 / 10（CoE / CoV） rate。我们已经获得了恒定MSE和MAE，因为对于所有D1，D2，D3和D4保持固定的error rates为0.1。另一方面，对于D1到D4，CoE / CoV rate 从1变为0.01。结果表明，CoE / CoV rate 与accuracy的影响成正比。由于CoE / CoV rate 的直接比例影响，R²和accuracy从D1增加到D4。</p><h1>2.恒定R²和增加MSE</h1><p>在这部分中，我们将再次创建4个不同的数据（D1，D2，D3，D4）。对于D1，D2，D3，D4，我们将CoE / CoV rate 应用为1。 对于D1，D2，D3和D4，CoE和CoV值分别为0.1,1,10,100。</p><blockquote><p>Data1（D1） = 0.1 + 0.1 * X_1 + 0.1 * X_2 + 0.1 * X_3 +（Random Error）</p></blockquote><p>当常数和CoV值为0.1时，将添加te CoE = 0.1的随机误差。</p><blockquote><p>Data2（D2） = 1 + 1 * X_1 + 1 * X_2 + 1 * X_3 +（Random Error）</p></blockquote><p>当常数和CoV值为1时，我们将添加CoE = 1的随机错误。</p><blockquote><p>Data3（D3） = 10 + 10 * X_1 + 10 * X_2 + 10 * X_3 +（Random Error）</p></blockquote><p>当常数和CoV值为10时，我们将添加CoE = 10的随机错误。</p><blockquote><p>Data4（D4） = 100 + 100 * X_1 + 100 * X_2 + 100 * X_3 +（Random Error）</p></blockquote><p>当常数和CoV值为100时，我们将添加CoE = 100的随机错误。</p><pre>input_dim = 3output_dim = 1size = 1000total_size = size * input_dimrand_state = np.random.RandomState(42)X = np.array([rand_state.rand() for i in range(total_size)], dtype=np.float32)X = X.reshape(-1, input_dim)#coefficientscoeff=[] alfa=[0.1, 1, 10, 100] noise=[]for i in alfa:coeff.append(np.array([1*i, 1*i, 1*i], dtype=np.float32))alfa=[0.1, 1, 10, 100] noise=[]rand_state = np.random.RandomState(42)for i in alfa:noise.append(i*rand_state.normal(0,1,size))input_dim = 3output_dim = 1size = 1000total_size = size * input_dimrand_state = np.random.RandomState(42)X = np.array([rand_state.rand() for i in range(total_size)], dtype=np.float32)X = X.reshape(-1, input_dim)#coefficientscoeff=[] alfa=[0.1, 1, 10, 100] noise=[]for i in alfa:coeff.append(np.array([1*i, 1*i, 1*i], dtype=np.float32))for i in alfa: rand_state = np.random.RandomState(42) noise.append(rand_state.normal(0,1,size)*i)Y=[]for i in range(0, len(coeff)):Y.append((X.dot(coeff[i]) + alfa[i] + noise[i]).reshape(-1, output_dim))train_size = int(0.7*size)X_train=[]X_test=[]Y_train=[]Y_test=[]LR=[]Y_test_pred=[]X_train_with_const=[]for i in range(0, len(coeff)): X_train.append(X[:train_size]) X_test.append(X[train_size:]) Y_train.append(Y[i][:train_size]) Y_test.append(Y[i][train_size:]) X_train_with_const.append(sm.add_constant(X_train[i]) ) LR.append(LinearRegression().fit(X_train[i], Y_train[i])) Y_test_pred.append(LR[i].predict(X_test[i]))Y_test_=[]Y_test_pred_=[]new=[]for i in range(0, len(coeff)): Y_test_.append(pd.DataFrame(Y_test[i])) Y_test_pred_.append(pd.DataFrame(Y_test_pred[i])) new.append(pd.concat([Y_test_[i], Y_test_pred_[i]], axis=1, join='inner')) new[i].columns = ['actual', 'Predict']#for loop to calculate accuracyAcr=[]Accuracy=[]for i in range(0,len(coeff)): Acr.append(new[i].iloc[0:301,].min(axis=1)/new[i].iloc[0:301,].max(axis=1)) Accuracy.append(np.mean(Acr[i]))D_MSE=[]D_MAE=[]D_R2=[]D_EVS=[]D_Accuracy=[]#calculate the metricsfor i in range (0, len(coeff)): D_MSE.append(metrics.mean_squared_error(Y_test_[i],Y_test_pred_[i])) D_MAE.append((metrics.mean_absolute_error(Y_test_[i],Y_test_pred_[i]))) D_R2.append((metrics.r2_score(Y_test_[i],Y_test_pred_[i]))) D_EVS.append((metrics.explained_variance_score(Y_test_[i],Y_test_pred_[i]))) D_Accuracy.append(Accuracy[i])data = [['MSE',D_MSE[0], D_MSE[1], D_MSE[2], D_MSE[3]],['MAE',D_MAE[0], D_MAE[1], D_MAE[2], D_MAE[3]], ['R^2',D_R2[0], D_R2[1], D_R2[2], D_R2[3]], ['ACR', D_Accuracy[0], D_Accuracy[1], D_Accuracy[2], D_Accuracy[3]]]df = pd.DataFrame(data,columns=['Metric','D1', 'D2', 'D3', 'D4'])print (np.round(df,3))####################with sns.axes_style("darkgrid", {"axes.facecolor": "0.8"}): sns.set_context("poster") sns.factorplot(data=np.round(df, 3), kind="point", col="Metric", color='purple')</pre><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/603a7043749a419e85df2e965203fb7e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b6522988791440e481159c06854d0e0d><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7b63fa3615974c538b79643efa68ba60><p class=pgc-img-caption></p></div><pre>with sns.axes_style("darkgrid"): sns.set_context("poster") MSE=sns.factorplot(data=np.round(df.iloc[0:1, 1:5], 3), kind="point", color='purple') MSE.set_axis_labels("Data", "MSE") MAE=sns.factorplot(data=np.round(df.iloc[0:1, 1:5], 3), kind="point", color='purple') MAE.set_axis_labels("Data", "MAE") R2=sns.factorplot(data=np.round(df.iloc[2:3, 1:5], 3), kind="point", color='purple') R2.set_axis_labels("Data", "$R^2$") ACR=sns.factorplot(data=np.round(df.iloc[3:4, 1:5], 3), kind="point", color='purple') ACR.set_axis_labels("Data", "Accuracy")</pre><div class=pgc-img><img alt=变量系数对机器学习（ML）回归模型精度的影响分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/938217f6f07043a0a11cbbc8ecf5e40c><p class=pgc-img-caption></p></div><p>从图中可以看出，当MSE和MAE增加R²且Accuracy 恒定时。我们将D1，D2，D3和D4的CoE / CoV rate应用为1。随着随机误差的CoE值增加，由于D1，D2，D3和D4的相同CoE / CoV = 1，R 2和Accuracy 没有改变。</p><h1>3.结论</h1><p>已经对Metrics进行了详细的分析，以观察变量系数对机器学习（ML）回归模型精度的影响。通过将机器学习线性回归模型应用于D1，MSE = 0.09和Accuracy = 73％。相同的机器学习线性回归模型已应用于D4，MSE = 9405和accuracy= 73％。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'变量','数对','机器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>