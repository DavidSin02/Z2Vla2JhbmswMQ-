<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>单目视觉深度估计测距的前生今世 | 极客快訊</title><meta property="og:title" content="单目视觉深度估计测距的前生今世 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/b0360f4d73104a549efe60c54479f1d5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/99b6e932.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/99b6e932.html><meta property="article:published_time" content="2020-11-14T21:03:55+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:55+08:00"><meta name=Keywords content><meta name=description content="单目视觉深度估计测距的前生今世"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/99b6e932.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>单目视觉深度估计测距的前生今世</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p>最近通过深度学习直接从单目摄像头的图像预测/估计深度图的方法成为一个应用的热点，惹来不少争议。</p></blockquote><hr><p>深度学习直接通过大数据的训练得到/调整一个深度NN模型的参数，在当今计算能力日新月异的平台（GPU/FPGA/ASIC/Muli-core）上实现了计算机视觉/语音识别/自然语言处理（NLP）等领域一些应用的突破。但是专家们还是对今后深度学习的发展有些期待和展望，比如</p><ul><li class=ql-align-justify>非监督学习方法的引入减轻大数据标注的负担，比如GAN；</li><li class=ql-align-justify>NN模型的压缩和精简以普及深度学习在移动终端甚至物联网终端的广泛应用；</li><li class=ql-align-justify>还有深度学习能够更多的引入人类知识和简单可靠的推理，以减少“暴力“学习的误差和错误，比如贝叶斯理论，知识图谱，逻辑推理，符号学习，多任务联合训练和迁移学习等等。</li></ul><p>这里从单目深度估计在计算机视觉中的发展历程，特别是最近在采用深度学习NN模型的实验中，总结一下如何通过深度学习求解传统视觉问题，并从中发现可借鉴的地方。</p><hr><p>深度估计问题在计算机视觉领域属于3-D重建的一部分，即Shape from X。这个X包括stereo, multiple view stereo, silhouette, motion (SfM, SLAM), focusing, hazing, shading, occlusion, texture, vanishing points, ...前面5个都是多图像的输入，从空间几何，时域变换和焦距变化的关系推导深度距离。剩下的都是单目的输入。</p><p>如果把图像模糊度建模，下图是图像边缘模糊的响应模型，那么单目图像也能估算深度，即shape from defocusing。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b0360f4d73104a549efe60c54479f1d5><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/be154b0cf5a1430b926bd935cf067636><p class=pgc-img-caption></p></div><p>另外一个现象是大气散射 (Atmosphere scattering ) 造成的霾 (haze)提供了深度信息，即depth from haze，一般有天空被拍摄下来的图像，通过散射模型能够推断像素深度。这里给出的是图像亮度C和深度z之间计算的公式：C0是没有散射情况下的图像亮度值，S是天空的图像亮度值。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7a762ca83f8747e6afda527c9377bd3f><p class=pgc-img-caption></p></div><p>以上两个任务可认为是deconvolution问题，blind或者non-blind。</p><p>物体表面阴影的变化可以提供深度的信息，利用图像亮度和其中物体表面的形状之间的关系，即Shape from shading。和SFM一样，这是一个病态问题，需要附加约束条件，如物体表面的特性。SFS一般假设四种表面模型：纯Lambertian，纯镜面，混合和更复杂的模型。大部分情况下都是Lambertian，即均匀照明的表面从任何一个方向观察其亮度不变。其目标函数是一个积分，求解的算法比较复杂，类似有限元之类。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/867708d367bf4f009fa2c6ad766b9a71><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/63e45ff5c52b4e61b4db6e22678a405a><p class=pgc-img-caption></p></div><p>纹理的变形提供了该纹理表面形状的线索。下图是一个示意流程图：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/839cc005aa1148dea9609a87a898e9f7><p class=pgc-img-caption></p></div><p>中间第三图是表面法向图，第四个才是深度图。纹理分割是必备的基础（估计是很难的一部分），此外求解这个shape from texture的优化问题，必须加上几个纹理元素（textels）约束条件：homogeneity，isotropy，stationary。</p><p>遮挡（occlusion）也是深度的一个线索，曲率（curvature）是其中的一个体现，即shape from curvature。isophote这个词指一种封闭的物体外轮廓，一般通过对图像灰度设门限可以得到，而它的曲率用来推导对应该门限的深度，见下图所示。门限在【0，255】范围变化就能得到最终叠加平均的深度图。分割仍然是一个求解遮挡的基础，要知道当时分割算法是计算机视觉很头疼的难题，俗称“chicken-and-egg"。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/79de25feaca3417b97a351ef1db93b63><p class=pgc-img-caption></p></div><p>最后再说消失点，即某平面的一组平行线在透视投影下会聚的点。那么，它相应的平面就能得到深度图，如下图所示，在人工（特别室内）环境下可以推导深度图，沿着平行线的平面，靠近消失点的赋予大的深度值。该方法叫depth from geometrical perspective。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/f56c5487789e4e32ae15be8a19da0866><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7f55ad7d5f2443baba4ecf8668d23a19><p class=pgc-img-caption></p></div><hr><p>顺便提一下，在3维电视热的时期（2008-2010年左右）大家希望把以前拍摄的单目视频变成立体视频，给3-D电视提供更多的内容，包括3-D显示技术的普及（比如红绿眼镜）大家也想在家里share一些3-D的UGC。这个技术被称为2D-to-3D，通过深度图估计和虚拟立体视觉假设可以生成立体视频，其绘制技术称为DIBR，如下图：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3d9f1955cf2747d3a3b88a844b09864a><p class=pgc-img-caption></p></div><p>以上是典型的传统计算机视觉，需要加约束求解病态的优化问题。下面谈谈机器学习如何解决这个视觉问题：</p><p>最早看到用机器学习的方法是基于MRF的，把各种约束关系放在模型的data term和connectivity term求解。这是我看到Andrew Ng在计算机视觉方面的第一篇论文，发表在NIPS 2005年，当时他刚刚在斯坦福大学建立自己的研究组。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c7dc7acf95af46ed9e65b8af49caed44><p class=pgc-img-caption></p></div><p>如果采用图像分割得到的super-pixels，可以得到更平滑的结果，该系统叫做Make3D。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2e876d73bdcc410498215ef6f77e97d1><p class=pgc-img-caption></p></div><p>值得一提的是，当时CMU的博士生Derek Hoiem也在研究如何从单目图像中提取出景物的3-D结构，只是他采用机器学习方法在图像分割基础上做了一个简单的语义分割，即“ground”, “sky”, 和 “vertical”标注像素，然后采用简单的平面billboard做纹理映射后变成“pop-up”的3-D景物：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/34aef776279f4303a36eaf9d005905b5><p class=pgc-img-caption></p></div><p>还有一种方法是把深度图估计变成一个搜索问题，即假设相似图像具有相似深度图：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/64bad9345f1d404991c13cbea27c0689><p class=pgc-img-caption></p></div><p>针对视频，可以利用optic flow做motion segmentation，那么修正上面的方法得到：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><p>另外一种改进是利用dictionary learning优化整个搜索过程：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8adfb07acf134c6e92234678a78c1a51><p class=pgc-img-caption></p></div><hr><p>下面我们看看深度学习是如何做的。</p><p>首先就是“暴力”方法直接喂数据训练模型：2篇论文</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6ec01b1ffacc4626bf193c28d9b52887><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><p>有些方法开始考虑传统方法的结合，比如CRF：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><p>随后，双目立体视觉的空间约束被用作无监督学习单目的深度估计：三篇论文</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/19de6d07dc78470fab452f1ef2db3abb><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a7498b00738c498386db2fa580477009><p class=pgc-img-caption></p></div><p>自然地采用帧间运动为单目视频的深度估计提供帮助，实际上是双任务联合训练的例子：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d77cd3c06380445984a936ad428b7fae><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eeae528114cf47369cf820b13fae5b79><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/11058d6f3a3d4811b66363745f208783><p class=pgc-img-caption></p></div><p>这是结合表面法向图的联合训练例子：GeoNet，Geometric Neural Network</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1297955da2ac4c86b3a61c0a718ac25d><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/60e3a9cd46bb4646b6ef35842ebc25d7><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8406f37171b14053b39b271437c231c7><p class=pgc-img-caption></p></div><p>结合view synthesis也是利用几何约束和成像特性的工作：之前已经有文章直接通过Deep3D模型做单目到双目的合成，这里的工作只是最终结果是深度估计而不是图像。</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/3bebf399ab514b53825c476546e96db4><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2c172e539eb4066ad4196902429a447><p class=pgc-img-caption></p></div><p>这是结合运动和边缘信息的联合训练例子：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/84edffa0407c41628c133c3e70e00f55><p class=pgc-img-caption></p></div><p>这个工作延续了以前利用分割提高深度估计的想法，只是假设上attention机制：</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9cfbcac2656742b9bd267b6558c050d5><p class=pgc-img-caption></p></div><p>谷歌最近的工作延续了camera motion的结合，同时加上了其中物体各自运动的信息：可以认为是将optic flow分成了camera ego motion和object motion的工作，和加入语义分割有类似的思路吧，文章发表在AAAI‘19.</p><div class=pgc-img><img alt=单目视觉深度估计测距的前生今世 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dee139cd580b4a1aa43c8be14bf75dea><p class=pgc-img-caption></p></div><p>总之，深度学习在这个计算机视觉的传统问题上一开始是暴力的数据学习方法，慢慢地加入了传统方法的约束和先验知识，一定程度上缓解了数据标注的压力（pixel级别的ground truth是个挑战性的工作，structured light带来的数据多半是室内的，激光雷达的数据也存在“黑洞”现象），同时设计新的loss function同时多任务联合训练都能提升模型算法的性能。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'单目','视觉','估计测'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>