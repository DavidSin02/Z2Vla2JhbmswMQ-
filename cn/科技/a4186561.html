<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>汇总自然语言处理技术领域的主要研究方向 | 极客快訊</title><meta property="og:title" content="汇总自然语言处理技术领域的主要研究方向 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/e32135a30d4b43b98c0ad7ae1ffae80c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a4186561.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a4186561.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a4186561.html><meta property="article:published_time" content="2020-11-14T21:00:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:19+08:00"><meta name=Keywords content><meta name=description content="汇总自然语言处理技术领域的主要研究方向"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/a4186561.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>汇总自然语言处理技术领域的主要研究方向</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>NLP自然语音处理在整个人工智能体系中属于基础服务层，很多NLPer可能会有点困惑，面对着一堆的模型数学公式，如何能发挥实际功效，跟实际应用场景结合起来，这里</p><p style=text-align:start>转发一篇NLP的应用体系的框架介绍：</p><p style=text-align:start>https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/2b1VLDDDJ3BHwcrQdaszXA</p><p style=text-align:start><br></p><p><strong>1 文本向量化 </strong>【NLP】一文汇总自然语言处理主要研究方向<strong>1 文本向量化</strong></p><p style=text-align:start>文本的向量化可谓是NLP进入深度学习时代的标志。所谓文本的向量化（embedding），就是将文本用一定维度的向量来表示，也可以理解为文本的数值化。通过embedding，文本的语义、句法等特征得以表征，便于下游模型的处理。</p><p style=text-align:start>例如，“人/如果/没有/梦想/，/跟/咸鱼/还有/什么/差别”，向机器学习模型直接输入字符串显然是不明智的，不便于模型进行计算和文本之间的比较。那么，我们需要一种方式来表示一个文本，这种文本表示方式要能够便于进行文本之间的比较，计算等。最容易想到的，就是对文本进行向量化的表示。例如，根据语料库的分词结果，建立一个词典，每个词用一个向量来表示，这样就可以将文本向量化了。</p><div class=pgc-img><img alt=汇总自然语言处理技术领域的主要研究方向 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e32135a30d4b43b98c0ad7ae1ffae80c><p class=pgc-img-caption></p></div><p style=text-align:start>词的向量化，最早尝试是词袋模型，后来证明，词袋模型无法表征词序特征，并且会带来维度灾难；Yoshua Bengio在2003年《A Neural Probabilistic Language Model》一文中提出了一种神经网络的方法，用于语言模型的计算，<strong>词向量作为副产品</strong>后来却引起了业界的关注。2008年Collobert和Weston展示了<strong>第一个</strong>能有效利用预训练词嵌入的研究工作，他们提出的神经网络架构，构成了当前很多方法的基础。这一项研究工作还率先将词嵌入作为 NLP 任务的高效工具。不过词嵌入真正走向NLP主流还是Mikolov 等人在 2013 年做出的研究《Distributed Representations of Words and Phrases and their Compositionality》。Mikolov 等研究者在这篇论文中提出了连续词袋模型CBOW和 Skip-Gram 模型，通过引入负采样等可行性的措施，这两种方法都能<strong>学习高质量</strong>的词向量。基于此，ELMO提出了一种相同词能够根据语境生成不同词向量的模型。高质量的词向量的获得，结合LSTM、CNN等神经网络抽取器，使得NER，文本分类以及信息抽取等任务获得了长足的进步。<br>此外，基于词向量的思想，从2018年开始，NLP中预训练模型开始流行，BERT、GPT、ALBERT以及XLNET等模型不断刷榜。</p><p style=text-align:start>笔者曾经写过的词向量即预训练语言模型相关的文章有：</p><p style=text-align:start><u>【NLP-词向量】词向量的由来及本质</u></p><p style=text-align:start><u>【NLP-词向量】从模型结构到损失函数详解word2vec</u></p><p style=text-align:start><u>【NLP】 聊聊NLP中的attention机制</u></p><p style=text-align:start><u>【NLP】 理解NLP中网红特征抽取器Tranformer</u></p><p style=text-align:start><u>【NLP】 深入浅出解析BERT原理及其表征的内容</u></p><p style=text-align:start><u>【NLP】GPT：第一个引入Transformer的预训练模型</u></p><p style=text-align:start><u>【NLP】XLnet：GPT和BERT的合体，博采众长，所以更强</u></p><p style=text-align:start><strong>2 序列标注任务</strong></p><p style=text-align:start>序列标注任务是NLP里非常基础和重要的任务，例如分词、NER等都属于序列标注任务，包括一些预测span的阅读理解任务也可归于此列。</p><p style=text-align:start><br></p><p style=text-align:start>分词通常是中文自然语言处理的第一步（随着深度学习模型表征能力越来越强，慢慢证明，分词未必是必要的）；NER是非常重要和基础的信息抽取任务，在非常多的场景中都需要用到，例如聊天机器人中的槽位抽取、文本结构化过程中的实体抽取等等。</p><div class=pgc-img><img alt=汇总自然语言处理技术领域的主要研究方向 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/fd608c3228cb4443a75a5204e70bc977><p class=pgc-img-caption>隐马尔科夫模型</p></div><p style=text-align:start>早期的序列标注任务，例如分词，NER等主要是用HMM、CRF等机器学习模型；随着深度学习的兴起，LSTM+CRF变成序列标注任务的主流方法；当然，因为LSTM的若干缺点，不少NLP的从业者坚持使用CNN，因而基于膨胀卷积的序列标注模型得以提出。随着transformer的提出，利用BERT等预训练模型做NER这类任务开始变得流行，特别是抽取一些相对较长和复杂的实体，例如地址等。需要特别提出的是，有些情况下，正则匹配也是实体抽取的一种有效手段，可作为补充，例如时间实体等。<br>笔者曾经写过的序列标注相关的文章有：</p><p style=text-align:start><u>【NLP-NER】什么是命名实体识别？</u></p><p style=text-align:start><u>【NLP-NER】命名实体识别中最常用的两种深度学习模型</u></p><p style=text-align:start><u>【NLP-NER】如何使用BERT来做命名实体识别</u></p><p style=text-align:start><u>【NLP实战系列】Tensorflow命名实体识别实战</u></p><p style=text-align:start><u>【每周NLP论文推荐】 NLP中命名实体识别从机器学习到深度学习的代表性研究</u></p><p style=text-align:start><strong>3 文本分类</strong></p><p style=text-align:start>文本分类是一个不难理解的概念，即通过计算机对输入文本进行分类，例如判断“你真是个帅哥啊”这句话是褒义还是贬义。文本分类的应用场景很多，例如情感分类、机器人中的意图识别等。<br>听上去，分类问题似乎是个不难解决的问题，实际上文本分类有它的难度。当类别非常多或者类别与类别之间差异很小时，文本分类就开始变得困难；再者，有时需要考虑额外特征才能分类正确，例如常常需要根据说话者语气，才能判断“你真是个帅哥啊”这句话是讽刺还是真心的赞美。</p><p style=text-align:start>早期有一些基于传统机器学习的文本分类，例如基于某种词语特征的的贝叶斯模型，SVM分类器等。随着深度学习的发展，LSTM+softmax/CNN+softmax模型变成了一种非常流行的文本分类架构，基于此Fasttext、textCNN等便捷高效的开源文本分类工具也开始流行。此外，结合Attention等技巧与概念能够一定程度的提高模型的效果。文本分类还有另外一种模式，即通过将文本向量化，再通过聚类获得类别，NLTK等开源NLP工具都有便捷的Doc2vec API。如果觉得效果不好，可以试试BERT的【CLS】向量。此外，还可以增加TF-IDF模块，构建更有表达能力的DocVec。</p><p style=text-align:start><br></p><p style=text-align:start>笔者曾经写过的文本分类相关的文章有：</p><p style=text-align:start><u>【NLP实战系列】朴素贝叶斯文本分类实战</u></p><p style=text-align:start><u>【NLP实战】基于ALBERT的文本相似度计算</u></p><p style=text-align:start><strong>4 信息提取任务</strong></p><p style=text-align:start>信息提取(IE)的目标是将文本信息转化为结构化信息，起初用于定位自然语言文档中的特定信息。广泛的看，信息提取其实是一个非常宽泛的概念，从文本提出感兴趣的内容就可以称为信息提取。在NLP中常常用实体抽取、关系抽取以及事件抽取等手段进行信息抽取。实体抽取是序列标记问题，上面已经介绍过，关系抽取以及事件抽取则通常转化为分类的任务。关系抽取常常需要先确认subject以及object。所以，关系抽取任务常常伴随着实体抽取的要求。</p><p style=text-align:start><strong>文本摘要自动抽取（自动摘要，标题生成）</strong>是文本信息抽取的主要任务之一，也是自然语言处理 NLP(Nature Language Process)领域的主要研究方向，它是指利用计算机自动从文本中抽取重要信息，形成摘要的方式表达原文。根据对信息的抽取方式的不同，可将文本自动摘要抽取技术分为两大类:抽取式(extractive)文本摘要生成方式和理解式(abstractive)文本摘要生成方式。抽取式文本摘要生成方法统计文本中各个句子的权重，根据权值进行排序选取重要的句子作为文本摘要，是本次调研的着力点。</p><p style=text-align:start>早期，信息提取多使用正则和传统的机器学习方法。随着深度学习的快速发展，信息提取技术也开始迅速发展。实体抽取与关系抽取从Pipline的方式进化到end-to-end的方式。使用的特征抽取器也逐步进化，从LSTM/CNN到transformer。需要特别提出的是，BERT在信息抽取方面表现出色，基于BERT和阅读理解任务来做信息抽取，是一种非常别致的方式。</p><p style=text-align:start><br></p><p style=text-align:start>笔者曾经写过的信息抽取相关的文章有：</p><p style=text-align:start><u>【文本信息抽取与结构化】目前NLP领域最有应用价值的子任务之一</u></p><p style=text-align:start><u>【文本信息抽取与结构化】详聊文本的结构化【上】</u></p><p style=text-align:start><u>【文本信息抽取与结构化】详聊文本的结构化【下】</u></p><p style=text-align:start><u>【文本信息抽取与结构化】详聊如何用BERT实现关系抽取</u></p><p style=text-align:start><u>【每周NLP论文推荐】 掌握实体关系抽取必读的文章</u></p><p style=text-align:start><strong>5 场景任务</strong></p><p style=text-align:start>此外，NLP还有一些复杂的应用场景，他们可能是多种NLP技术的应用和综合，例如聊天机器人、知识图谱、文本搜索以及文本推荐系统等。</p><ol start=1><li>搜索是NLP技术最早得到大规模应用的技术，例如百度搜索、知乎话题搜索以及各大互联网公司的query搜索技术，都涉及到语义匹配或文本分类技术。此外，大型的搜索引擎，知识图谱的搭建是必须的。</li></ol><p style=text-align:start>2. 推荐系统在一定层面来说是跟搜索场景相反的。搜索是基于用户的意图，在文本库中寻找匹配项；推荐则相反，通常基于积累的用户信息，给用户推荐可能感兴趣的内容。推荐系统常常涉及用户画像、标签定义等过程，需要一定程度的依赖NLP技术。</p><p style=text-align:start>3. 聊天机器人是目前NLP技术应用最多的场景，基于NLP技术构建一个能够替代客服、销售、办公文员是这一任务的终极目标。目前，聊天机器人已经以各种形态出现在人们面前，有站在银行门口迎接顾客的迎宾机器人，有放在卧室床头的智能音箱，有呆在各个APP首页的助手机器人等等。在聊天机器人中，运用了文本分类、语义匹配、对话管理、实体识别等大量的NLP技术。要做好是一件难度大、超复杂的任务。</p><p style=text-align:start>4. 知识图谱是AI时代一个非常重要基础设施，大规模结构化的知识网络的搭建，能够重塑很多的智能场景。</p><p style=text-align:start>关于搜索和推荐系统我们会在后面的系列文章中进行介绍，关于知识图谱和聊天机器人我们已经写了大量的文章进行介绍，感兴趣的同学可以看看，：</p><p style=text-align:start><u>【NLP-ChatBot】我们熟悉的聊天机器人都有哪几类？</u></p><p style=text-align:start><u>【NLP-ChatBot】搜索引擎的最终形态之问答系统（FAQ）详述</u></p><p style=text-align:start><u>【NLP-ChatBot】能干活的聊天机器人-对话系统概述</u></p><p style=text-align:start><u>【每周NLP论文推荐】 对话管理中的标志性论文介绍</u></p><p style=text-align:start><u>【每周NLP论文推荐】 开发聊天机器人必读的重要论文</u></p><p style=text-align:start><u>【知识图谱】人工智能技术最重要基础设施之一，知识图谱你该学习的东西</u></p><p style=text-align:start><u>【知识图谱】知识表示：知识图谱如何表示结构化的知识？</u></p><p style=text-align:start><u>【知识图谱】如何构建知识体系：知识图谱搭建的第一步</u></p><p style=text-align:start><u>【知识图谱】获取到知识后，如何进行存储和便捷的检索？</u></p><p style=text-align:start><u>【知识图谱】知识推理，知识图谱里最“人工智能”的一段</u></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'语言处','理技术','领域'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>