<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>机器学习总结（基础）：偏差和方差、iid、分布 | 极客快訊</title><meta property="og:title" content="机器学习总结（基础）：偏差和方差、iid、分布 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a55cbbea.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a55cbbea.html><meta property="article:published_time" content="2020-11-14T21:05:42+08:00"><meta property="article:modified_time" content="2020-11-14T21:05:42+08:00"><meta name=Keywords content><meta name=description content="机器学习总结（基础）：偏差和方差、iid、分布"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/a55cbbea.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>机器学习总结（基础）：偏差和方差、iid、分布</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e><p class=pgc-img-caption></p></div><h1><strong>偏差和方差</strong></h1><p>在监督机器学习中，我们为训练数据提供标签以构建f（x）机器学习模型。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/203ea61fe1984b1e93c210752552d84f><p class=pgc-img-caption></p></div><p>均方误差由方差和偏差组成。由于噪声与机器学习模型无关，并且在训练机器学习模型时不可减少，因此我们可以从讨论中忽略它。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/7c6f9b0ea20441d190e2d4d69404b70d><p class=pgc-img-caption></p></div><p>方差是对采样数据变化敏感的误差。如果机器学习训练数据集太小，则复杂模型容易过度拟合。一旦发生这种情况，如果对不同的训练数据进行采样，模型预测可能会发生显著变化。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/3db226eae51348739207bfb0f8d3ab4f><p class=pgc-img-caption></p></div><p>在N 1-D的训练数据输入下，我们可以用一个N阶多项式完美地拟合一个机器学习模型。下面的红色矩形区域过度拟合，如果ground truth更接近线性方程，则会导致错误的预测。如果最后2个数据点不包含在训练数据集中，或者在红色矩形区域内采样更多的数据点，预测结果将会不同。简而言之，如果机器学习模型是复杂的，并且没有足够的数据来拟合它，那么训练的方差就会很大。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ab61bcd39c134cc6b536d2e2e772dba5><p class=pgc-img-caption></p></div><p>另一方面，当模型不够复杂，无法做出准确预测时，就会出现偏差。如果x的ground truth在下面的圆心附近，偏差会将答案朝一个特定的方向移动，而方差则会将预测散布在ground truth周围。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e9435d21d52a4c448688fb53660287d0><p class=pgc-img-caption></p></div><p>下面是模型复杂性的演示。随着复杂度的提高，它会更好地拟合训练数据，直到过拟合。此时，训练误差继续减小。但是当我们使用不用于训练的数据点来验证机器学习模型时，验证误差很大，并且随着迭代次数的增加而增加。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9a3f534471fc4af8b01cb4c47f53f258><p class=pgc-img-caption></p></div><p>下图总结了模型复杂性、偏差和方差之间的关系。减小方差的方法是增加训练数据集的大小，降低模型的复杂度或增加正则化。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b93132d050494b2cbc5f7c6a883d72f4><p class=pgc-img-caption></p></div><h1><strong>独立同分布（iid）</strong></h1><p>在许多机器学习（ML）问题中，我们假设数据点来自相同的数据分布，并且观测值不影响其他观测值。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/019c71fdc42d4768a5925ddc18a567bf><p class=pgc-img-caption></p></div><p>这是一个简单的概念，许多机器学习（ML）和深度学习（DL）算法的成功很大程度上取决于它。当数据点和训练批次接近i.i.d时，模型训练更加稳定。</p><p>当我们掷100次骰子时，每个数据点都来自相同的分布。当掷骰子的时候，结果是独立于之前的结果的，因此掷骰子是i.i.d。但是，如果我们从一副纸牌中抽取而不进行替换，采样分布就会发生变化，因此不是i.i.d。这样的假设可以在很多情况下简化我们的数学运算。例如，最大似然估计(MLE)中的联合分布可以简化为独立事件的乘法。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/48b3e41ee2a943718bf4e7b341c58a35><p class=pgc-img-caption></p></div><p>这很关键。通过将模型分解为可管理的独立子组件，我们可以显著降低复杂性</p><p><strong>协变量偏移</strong></p><p>然而，如果我们有一个用骰子训练的模型，如果我们在推理时间内的输入具有不同的分布，那么预测将是错误的，比如庄家切换到一个有偏差的骰子。这就是协变量偏移。最近，有一篇关于在医学领域使用深度学习的报告。虽然深度学习（DL）预测的准确性似乎很高，但在其他医院却显示出不一致的结果。结果发现，一些模型被从少数医院收集的数据过度拟合。当该模型适用于移动设备使用频率较高的地区时，准确度会下降。这是一个协变量偏移问题！</p><p>在一些机器学习（ML）或深度学习（DL）问题中，状态可能是高度相关的。时间序列模型的相关性更高。如果我们在优化这些模型时使用梯度下降法，则i.i.d.假设不成立，相应的训练可能非常不稳定。</p><h1><strong>分布</strong></h1><p>在这一节中，我们将讨论高斯分布、伽马分布、β分布、狄里克莱分布等分布，不同的分布有不同的参数和不同的形状，用于不同的目的。找到合适的模型可以大大简化计算</p><p><strong>期望</strong></p><p>对于连续随机变量，f（x）的期望值为</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/490857c6fc3449d4a088694f0e022527><p class=pgc-img-caption></p></div><p>对于离散随机变量，它是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2dda0f1beea94d1eb2f47021cf58d361><p class=pgc-img-caption></p></div><p><strong>方差和协方差</strong></p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/c63ace8b2c634e12b8047537034a7925><p class=pgc-img-caption></p></div><p>对于连续随机变量，它是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/70dcbb1758f04afca54e28757dc8cb87><p class=pgc-img-caption></p></div><p>协方差表明两个变量是正相关还是负相关。如果它为零，则它们是无关的。</p><p>方差可以表示为下面的等式</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/11fedbcb70e64dbbb2f7b6485e26b34f><p class=pgc-img-caption></p></div><p>这种形式化对于许多证明是很方便的，包括找到 MLE估计的偏差和方差。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/477e5505e43d4cf99e7f7fb5086976d7><p class=pgc-img-caption></p></div><p>X＆Y的协方差是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c4fc753c25d54e6786fa39e676d3f7ba><p class=pgc-img-caption></p></div><p><strong>样本方差</strong></p><p>样本方差是通过采样m个数据点来估计总体方差的方法。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2839701e1d944b77b143f8861ae849e0><p class=pgc-img-caption></p></div><p>但是，采样数据的平均值与数据本身相关。因此，（xᵢ-μ）²将小于总体的数量。为了弥补这一点，我们需要将其除以m-1而不是m（证明）。但是对于样本均值，我们只需要将总和除以m，估计是无偏的。</p><p><strong>相关性</strong></p><p>协方差显示变量之间的关系，但不能很好地量化变量。每个变量可以是不同的比例（或单位）。相关性对协方差进行归一化，使得每个变量对应于相同的比例。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cc0e7736823e4207a9e2dc72eaf3401b><p class=pgc-img-caption></p></div><p><strong>高斯分布/正态分布</strong></p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e6427912ea094442918911191d7b14ac><p class=pgc-img-caption></p></div><p>在高斯分布中，68%的数据在1σ内，95%的数据在2σ内。标准正态分布为μ=0和σ=1。</p><p><strong>多元高斯分布</strong></p><p>多元高斯分布使用高斯模型模拟多变量分布。下图是双变量高斯分布，涉及两个随机变量。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/887975ae66ec4861988e5b22c370a458><p class=pgc-img-caption></p></div><p>多元高斯分布定义为</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5f6c2ab2dc29482d91b0797652dd5d73><p class=pgc-img-caption></p></div><p>其中Σ是协方差矩阵。 该矩阵中的每个元素记录两个随机变量的相关性。我们可以通过下面的来进行采样多元高斯分布</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e5b0f9375cd84e80a722daa15a96bda4><p class=pgc-img-caption></p></div><p>协方差矩阵可以用相关性表示。这是一个二元高斯分布的例子。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4525c56e4f0d42448e2211257ed11198><p class=pgc-img-caption></p></div><p><strong>中心极限定理</strong></p><p>考虑掷骰子，如果骰子是公平的，则掷出的值均匀分布。让我们多次掷骰子并平均结果。我们多次重复实验并收集所有汇总结果。当我们绘制这些结果时，我们将认识到结果是高斯分布的。中心极限定理说：</p><blockquote><p>大量相同分布的随机变量的和倾向于高斯分布。</p></blockquote><p>即我们可以有许多独立的随机变量，比如说每个变量代表一个抛出的结果。当我们将它们加在一起并将其归一化（平均值）时，经过多次试验后的归一化结果往往是高斯分布。该定理推广到自变量的任何分布。因此，无论骰子是公平的，有偏的还是任何数据分布，归一化结果都是高斯分布的。这意味着单个变量可能具有不同的数据分布，但我们可以使用高斯分布来模拟其聚合结果。</p><p>如果随机变量已经是高斯分布，且方差为σ²，则归一化结果将是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8445999473f049818421dd3c247890c8><p class=pgc-img-caption></p></div><p>即聚合结果的方差随着较大样本量的平均值而下降。两个高斯分布变量的和或差也是高斯分布的。</p><p><strong>伯努利分布</strong></p><p>伯努利分布是具有两种可能结果的事件的离散分布，一个具有概率φ而另一个具有1-φ。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/662afe36fe7444a1b0360fd53527a48a><p class=pgc-img-caption></p></div><p>分布也可以写成：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/033ef3af3ed6479aa19eb69aa5fa31a4><p class=pgc-img-caption></p></div><p><strong>二项分布</strong></p><p>二项分布是独立伯努利试验的综合结果。例如，我们掷硬币n次，然后模拟有x次反面的机会。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2c34653aa3154da589bba4afc8bccc6b><p class=pgc-img-caption></p></div><p>其中p是反面的概率。二项分布的均值和方差是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3edea97fd0364fb5a33a2735d89d5f82><p class=pgc-img-caption></p></div><p>伯努利分布中θ的方差是：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/33a5225e7d174170a4337974e1b63ea4><p class=pgc-img-caption></p></div><p><strong>分类分布</strong></p><p>伯努利分布仅有两种可能的结果。在分类分布中，我们有K个可能的结果，概率为p 1，p 2 p 3，...和pk，所有这些概率加起来为1。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/8340531d01d3461abfe95af43d580f7c><p class=pgc-img-caption></p></div><p><strong>多项式分布</strong></p><p>多项式分布是二项分布的推广。它有k个可能的结果。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2787f88eb8df4f2dbad6990ec564572a><p class=pgc-img-caption></p></div><p>假设这些结果分别与概率p 1，p 2，...和pk相关。我们收集大小为n的样本，xᵢ表示结果i的计数。联合概率是</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a88c9277d8884aea89ca95556795d848><p class=pgc-img-caption></p></div><p>在贝叶斯推理中，我们经常通过Beta分布对此概率进行建模（稍后讨论）。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b9bccc44ff784473a716700dae8bbafc><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/968a96af8e83453d9d7d3c2786ffde6f><p class=pgc-img-caption></p></div><p><strong>Beta分布</strong></p><p>Beta分布的定义与二项分布非常相似。beta分布定义为：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c9b0f58b0f864f0484ee0a4176b020d3><p class=pgc-img-caption></p></div><p>B是归一化因子</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/24dcdeaf475a4ec7b57dd51f0b25ba84><p class=pgc-img-caption></p></div><p>它对下面的分子进行归一化，因此计算结果f是概率分布。如果我们将f（x）除以所有可能的x，它等于1。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6920d411eabc4e4cb9b52f099e8c0d83><p class=pgc-img-caption></p></div><p>当a = b = 1时，f（x）对于所有x都是常数，因此，分布是均匀分布的。Beta分布中的两个参数a和b极大地改变了分布的形状。如下所示，Beta分布可以模拟许多形状的分布，包括U形和均匀分布。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c4bbf714733c40e48cfa6fc25fec2f2f><p class=pgc-img-caption></p></div><p>二项分布具有与Beta分布类似的形式（红色下划线）。因此，很容易同时操作二项分布和Beta分布。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2bc15dd0e41047b7bb84249a055c4497><p class=pgc-img-caption></p></div><p>此外，可以训练上述Beta分布中的θ以在二项分布中对参数p进行建模。Beta分布可以被认为是对分布上的分布进行建模。简而言之，我们可以通过调整a和b来使用Beta分布来学习二项分布的p。简而言之，Beta分布模拟了二项分布的p的所有可能值及其确定性。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/41615a5fa7014c45b8a77b40eb4e34ce><p class=pgc-img-caption></p></div><p>如前所述，后者通常是难以处理的。但是，如果我们能用特殊的分布对似然和先验进行建模，我们可以用解析的方法很容易地解决后验问题。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/de863f21c8294096993e9112de091d19><p class=pgc-img-caption></p></div><p>我们将在贝叶斯推理中进一步阐述它。但作为预览，后验非常简单：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/99ed071145644023908698416cc18e27><p class=pgc-img-caption></p></div><p>Beta分布的均值和方差为：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5065183c14ab4c248f9074ea164643d4><p class=pgc-img-caption></p></div><p>其中ψ是Digamma函数：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a186d8ede79544cc96088d440dc10148><p class=pgc-img-caption></p></div><p>给定观测数据，我们可以利用上述方程逆向设计模型参数。</p><p><strong>Dirichlet分布</strong></p><p>如果Beta分布是二项分布，则Dirichlet分布是多项式分布。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b80cbdf6e1a24396af794e6d378057d1><p class=pgc-img-caption></p></div><p>Dirichlet分布</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f0fd4b25cca74102a940df6d84ac0742><p class=pgc-img-caption></p></div><p>其中α是Dirichlet分布的参数。它控制分布的形状。由于θ有3个分量，α也由3个值组成，因此我们可以很容易地控制θ的分布形状。Dirichlet分布定义为：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4e69c9edef4a42819e83adc0d119eee1><p class=pgc-img-caption></p></div><p>我们可以看到Dirichlet分布与下面的多项式分布之间有着密切的相似性。这就是为什么通过调整α的值来使用它来学习多项式分布是一个很好的选择。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e4c5dbec78394f14b503cd04e4400e37><p class=pgc-img-caption></p></div><p>在视觉上，θ1，θ2，θ3的可能值位于三角形平面上，以强制执行这些值总和为1的约束。对于K变量，所有采样值都位于（K -1）-simplex内。即所有K变量总和为1。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/71cbc8108e0f48bea5007ee49e895755><p class=pgc-img-caption></p></div><p>下图显示了K = 1和K = 3的一些可能的形状（不同的αᵢ)。如图所示，它可以表示均匀分布，单峰形状和多个模态形状。Dirichlet分布允许我们模拟不同形状的概率分布(给定θ1，θ2，θ3，...总是加1)。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d75fa5314b8147a983a5ae0326a40d0c><p class=pgc-img-caption></p></div><p>要理解α与形状之间的关系，首先让我们总结一下它的一些属性。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/93daa35841b949d59753682f499bdb82><p class=pgc-img-caption></p></div><p>当所有αᵢ都相等时,E（θ ₁）=E（θ ₂）=E（θ ₃），即要使θ ₁，θ ₂，θ ₃均匀分布，我们可以设置所有αᵢ等于1。如果我们想要一个特定的类型，我们使相应的αᵢ远大于1并且也远高于其他αⱼ（假设αⱼ≥1）。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5336ec4bc04c48a4896ffb8d52c4adf3><p class=pgc-img-caption></p></div><p>当θᵢ接近0时，p（θᵢ）将接近无穷大，即θᵢ等于0的概率很高。</p><p>让所有αᵢ相等，并将其命名为α。这是Dirichlet分布的一种特殊情况，称为对称Dirichlet分布。α不是向量，而是用标量来建模。如下所示，随着我们增加α，我们将非常稀疏的分布变为均匀分布。当α很小时，单个样本中的大多数值xᵢ为零。随着它的增加，分布变得均匀。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1d582c53dc7644ad9b07341e789f25f1><p class=pgc-img-caption></p></div><p>dirichlet分布的参数可以重新表示为α和n（α’ᵢ → α nᵢ）的乘积，其中α是称为浓度参数（稀疏性度量）的标量，n是称为其元素总和为1的基度量的向量。</p><p><strong>泊松分布</strong></p><p>泊松分布模拟在固定时间间隔内发生的给定数量事件的概率。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5f9e596c78564f279d57ae772b427d4f><p class=pgc-img-caption></p></div><p>当事件数量与持续时间尺度相比相对较小时，事件在特定持续时间内发生x次的概率为：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/3a65350f1eb346918a1f994fe90f2ac4><p class=pgc-img-caption></p></div><p>这是不同λ的概率质量函数。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a673d9a232ea401bac0fbe846919ac2a><p class=pgc-img-caption></p></div><p>泊松过程是事件以恒定平均速率独立地和连续地发生的方法。</p><p>在泊松过程中，</p><ul><li>您知道平均事件发生率。</li><li>事件是随机的，彼此独立。事件的发生不会影响另一个事件的发生。</li><li>等待时间的分布是无记忆的。无论你等待多久都没关系，未来的分布仍然是一样的，即</li></ul><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cb8709fe9fa948b28ea147050a9445fd><p class=pgc-img-caption></p></div><p><strong>指数和拉普拉斯分布</strong></p><p>指数分布是泊松过程中下一个事件发生之前等待时间的概率分布。该等待时间被建模为具有指数分布的随机变量。如前所述，等待时间的这种分配是无记忆的。即使在过去20分钟内没有发生任何事件，PDF也是一样的。下图显示了分布的形状和数学定义。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a1a053e65b7d4c14b79a066a9506ea57><p class=pgc-img-caption></p></div><p>对于λ= 0.1，等待超过15的机会是0.22。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e0f01286a4134dfdbeb284658ba7c31b><p class=pgc-img-caption></p></div><p>拉普拉斯分布也称为双指数分布，可以认为是两个背靠背粘合在一起的指数分布。</p><p><strong>Gamma分布</strong></p><p>指数分布和卡方分布是Gamma分布的特例。Gamma分布可以被认为是k个独立的指数分布随机变量的总和。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b7bf40cb380f4841961f6a55c31df698><p class=pgc-img-caption></p></div><p>直观地说，它是第k个事件发生的等待时间的分布。这是Gamma分布的数学定义。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/14997b0a094649d9908b571d1f2eb1b6><p class=pgc-img-caption></p></div><p>Gamma分布通常使用许多不同的符号：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/98249dd86b834074882715c830f06824><p class=pgc-img-caption></p></div><p>α通常被写成k，这是第k个事件。如图所示，α控制形状。k=1是具有指数衰减形状的指数分布。随着k的增加，曲线的偏度减小。分布将与累积分布趋于平稳。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ca7ff69278024c3d9e972bc1b4a955cb><p class=pgc-img-caption></p></div><p>它看起来更接近中心极限定理所建议的正态分布。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/6af88fcaa06e4240ae68cdee6ef611ea><p class=pgc-img-caption></p></div><p>接下来，我们分别确定k=2和绘制β=1和2。如下图所示，形状保持不变。但如果我们更靠近x轴和y轴上的单位，随着β的增加，值的扩展会减小。直观地说，当事件率增加时，预期等待时间减少。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6d314195e76940cfb8a11cd34544dcc3><p class=pgc-img-caption></p></div><p>如果两条曲线具有相同的比例，则第二个图中的值范围将更窄。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f3628db51ea247fcaea38e0d3f7b51bb><p class=pgc-img-caption></p></div><p>根据α和β的值，可以看大一部分正在增长，而另一部分正在衰减。因此它可以模拟大范围的密度形状。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad31554d781847f198ae73b5cb302251><p class=pgc-img-caption></p></div><p>根据定义，如果x为负，伽马分布的密度为零。在建模实际问题时，这是一个很好的约束条件，X和高度一样，永远不能为负。这是伽马分布的不同参数图。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f645dc9095bc4a609a8a9c98500514be><p class=pgc-img-caption></p></div><p>Gamma分布的期望和方差是：</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/19a91ca05e22483cb6a34c7481e082bd><p class=pgc-img-caption></p></div><p><strong>卡方分布</strong></p><p>假设Z 1，Z 2，...和ZK是ķ个独立随机变量，每个都具有标准正态分布。我们对每个变量进行平方并将它们相加。我们多次重复这些实验，平方结果的分布称为卡方分布²，k是自由度数。以下是具有不同k值的数学定义及其分布图。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/08b680340b3b468592f80fcc716b56de><p class=pgc-img-caption></p></div><p>让我们用一个k为3的例子来说明它。在每次测试中，我们抽取3名学生。我们把它们的体重归一化，平方，然后加在一起。假设它们的体重（磅）是（165，175，145）和归一化值（0.17,0.5，-0.5）。它的平方和是0.53。我们重复运行1000次并绘制结果。它应该看起来像上面的淡蓝色曲线，k=3。</p><p>让我们绘制100个学生样本(i从1到100)并计算下面的卡方统计量。如果该值过高，则表明它在表示总体方面是一个糟糕的样本。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e3cc895296624e668e585b5d21ae0ef2><p class=pgc-img-caption></p></div><p>卡方分布是偏态的。但毫不奇怪，随着自由度的增加，分布看起来更接近正态分布。简而言之，如果样本量增加，我们应该期望分布接近正态分布。</p><p>卡方检验的另一个重要应用是对独立性的检验。</p><p>卡方分布是Gamma分布的一个特例。当α=v/2和β=1/2时，gamma（α，β）随机变量是具有v自由度的卡方随机变量。</p><p><strong>Dirac分布</strong></p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e6f496c6f74b493990f18233ae9a303f><p class=pgc-img-caption></p></div><p><strong>归一化因子</strong></p><p>许多分布可以表示为</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1c478a1265a94975a67231ea1a446009><p class=pgc-img-caption></p></div><p>其中分子是非归一化分布。在许多概率模型中，我们首先对非归一化分布进行建模，然后对所有可能的x求和，以创建归一化因子。这将我们的结果转化为概率，对于所有可能的x，p（x）总和为1 。例如，使用图模型，我们使用Graph对问题进行建模，分子是从中导出的因子。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db0f54b56b3143c0848fd747fae8dfef><p class=pgc-img-caption></p></div><p>在图模型中，这个归一化因子取决于我们如何对因子（θ）建模，因此，我们将其称为配分函数（z（θ））。一般来说，配分函数或标准化因子很难计算。在所有x上求和或积分是不容易的。</p><p>但对于众所周知的分布，我们可以首先关注计算分布参数，如μ，σ²，可以从这些参数中轻松找到归一化因子。</p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/459f21ffc8c341cd83b3abe3581ac6b8><p class=pgc-img-caption></p></div><p><strong>小结</strong></p><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9b7444a1ee054a9ba9290bed339adc1a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=机器学习总结（基础）：偏差和方差、iid、分布 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b369902b600b4c8ea49470ccdbc00233><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'机器','学习','总结'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../cn/%E7%A7%91%E6%8A%80/59b3843e.html alt=机器学习总结（基础）：指数分布、矩匹配、矩阵分解等 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/84c47890a2c44654997e63bd5cdf0c72 style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E6%8A%80/59b3843e.html title=机器学习总结（基础）：指数分布、矩匹配、矩阵分解等>机器学习总结（基础）：指数分布、矩匹配、矩阵分解等</a></li><hr><li><a href=../../cn/%E7%A7%91%E5%AD%A6/5199ece.html alt=机器学习总结（算法）：聚类、决策树、能量模型、LSTM等 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/76d31ab63a7249a5abaeec98d8891354 style=border-radius:25px></a>
<a href=../../cn/%E7%A7%91%E5%AD%A6/5199ece.html title=机器学习总结（算法）：聚类、决策树、能量模型、LSTM等>机器学习总结（算法）：聚类、决策树、能量模型、LSTM等</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>