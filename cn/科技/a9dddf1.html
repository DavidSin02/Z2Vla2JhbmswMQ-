<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>将大于内存的csv文件过滤到Pandas数据帧 | 极客快訊</title><meta property="og:title" content="将大于内存的csv文件过滤到Pandas数据帧 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/15340600359424dcb3951dc"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a9dddf1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a9dddf1.html><meta property="article:published_time" content="2020-10-29T21:06:37+08:00"><meta property="article:modified_time" content="2020-10-29T21:06:37+08:00"><meta name=Keywords content><meta name=description content="将大于内存的csv文件过滤到Pandas数据帧"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/a9dddf1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>将大于内存的csv文件过滤到Pandas数据帧</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=将大于内存的csv文件过滤到Pandas数据帧 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15340600359424dcb3951dc><p class=pgc-img-caption></p></div><p>通常，我们需要解析大型csv文件，只选择符合特定标准的行来加载dataframe。但是，对于大于内存的文件，我们不能简单地在dataframe中加载它并选择需要的文件。解决方案是用块解析csv文件，只将需要的行追加到dataframe中。在本文中，我还提供了一些工具来了解内存的一般用法。</p><p>首先，一些方法来确定我们需要的不同大小(内存、csv、dataframe)。</p><h1>查找可用的RAM：</h1><p>为此，我们需要一个名为psutil的库</p><blockquote><p>pip install psutil</p></blockquote><p>并使用以下方法获取</p><blockquote><p>import psutil</p><p>svmem = psutil.virtual_memory（）</p><p>print（svmem.available）</p></blockquote><h1>获取csv大小:</h1><p>为此，我们将使用os库。我们还可以遍历一个文件夹，如果你的数据集被分割成几个文件，我们可以得到文件的累积大小:</p><blockquote><p>import os</p><p># only one file dataset:</p><p>os.path.getsize('./dataset.csv')</p><p># same but for a folder containing several files:</p><p>total_filesize = 0</p><p>for filename in os.listdir('./dataset_folder/'):</p><p>total_filesize = total_filesize + os.path.getsize(filename)</p></blockquote><h1>获取dataframe的大小：</h1><p>以下命令返回数据帧df占用的内存大小，包括其索引。</p><blockquote><p>df.memory_usage(index=True).sum()</p></blockquote><p>另一个选择是使用sys库如下：</p><blockquote><p>import sys</p><p>sys.getsizeof(df)</p></blockquote><h1>处理csv文件</h1><p>让我们阅读csv的前几行，看看它需要多少内存。</p><blockquote><p>df_sample = pd.read_csv(‘./dataset.csv’, nrows=10)</p><p>df_sample_size = df_sample.memory_usage(index=True).sum()</p></blockquote><p>在下面的示例中，我将使用1Gb的RAM进行处理，如果我的结果dataframe变得太大而无法存储在内存中，我将在处理过程中提醒我。</p><p>为此，我们使用chunksize和iterator参数，它决定了每次迭代读取的行数:</p><blockquote><p># define a chunksize that would occupy a maximum of 1Gb</p><p># we divide by 10 because we have selected 10 lines in our df_sample</p><p># we then get the integer part of the result</p><p>my_chunk = (1000000000 / df_sample_size)/10</p><p>my_chunk = int(my_chunk//1)</p><p># create the iterator</p><p>iter_csv = pd.read_csv(</p><p>‘./dataset.csv’,</p><p>iterator=True,</p><p>chunksize=my_chunk)</p><p># concatenate according to a filter to our result dataframe</p><p>df_result = pd.concat(</p><p>[chunk[chunk['my_field']>10]</p><p>for chunk in iter_csv])</p></blockquote><p>在连接中，我们传递我们想要应用于数据的过滤器，以仅保留与此过滤器匹配的行。在此示例中，我们希望保留my_field列的值大于10的行。但是您可以使用任何经典的pandas方式过滤数据。</p><p>下面的完整代码，所以你不需要定义上面的Python代码片段：</p><blockquote><p>import psutil</p><p>import pandas as pd</p><p>import csv</p><p>svmem = psutil.virtual_memory()</p><p>print (svmem.available)</p><p>PATH = r”C:\tmp\dataset\tf_train.csv”</p><p>df_sample = pd.read_csv(PATH, nrows=10)</p><p>df_sample_size = df_sample.memory_usage(index=True).sum()</p><p>print (df_sample_size)</p><p>print (df_sample)</p><p># define a chunksize that would occupy a maximum of 1Gb</p><p># we divide by 10 because we have selected 10 lines in our df_sample</p><p>my_chunk = (1000000000 / df_sample_size)/10</p><p>my_chunk = int(my_chunk//1) # we get the integer part</p><p>print (my_chunk)</p><p># create the iterator</p><p>iter_csv = pd.read_csv(</p><p>PATH,</p><p>iterator=True,</p><p>chunksize=my_chunk)</p><p># concatenate according to a filter to our result dataframe</p><p>df_result = pd.concat(</p><p>[chunk[chunk[‘n3’]>0]</p><p>for chunk in iter_csv])</p><p>print (df_result)</p></blockquote></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'将大','内存','csv'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>