<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>极简笔记：关于变分自编码器的那点儿事 | 极客快訊</title><meta property="og:title" content="极简笔记：关于变分自编码器的那点儿事 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/153717696412479d454149b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b0dd6d1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b0dd6d1.html><meta property="article:published_time" content="2020-10-29T21:05:26+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:26+08:00"><meta name=Keywords content><meta name=description content="极简笔记：关于变分自编码器的那点儿事"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/b0dd6d1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>极简笔记：关于变分自编码器的那点儿事</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p><strong>点击上方关注，All in AI中国</strong></p></blockquote><p>作者：Yoel Zeldes</p><p>有没有想过变分自编码器（VAE）模型是如何工作的？你想知道变分自编码器（VAE）如何生成类似于其训练的数据集的新示例吗？</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153717696412479d454149b><p class=pgc-img-caption></p></div><p>阅读本文后，你将掌握对变分自编码器（VAE）内部工作原理的理论知识，并能够自己实现。</p><p>在以后的文章中，我将提供一个变分自编码器（VAE）的工作代码，这个变分自编码器（VAE）是在手写数字图像的数据集上训练的，我们将获得一些产生新数字的乐趣！</p><p><strong>生成模型</strong></p><p>VAE是一种生成模型-----它估计训练数据的概率密度函数（PDF）。如果在自然视觉图像上训练这样的模型，则应该为狮子的图像分配高概率值。另一方面，随机乱码的图像应该被分配低概率值。</p><p>VAE模型还可以从学习的概率密度函数（PDF）中采样示例，这是最酷的部分，因为它将能够生成看起来与原始数据集类似的新示例！</p><p>我将使用MNIST手写数字数据集解释VAE。模型的输入是28∙28维空间中的图像（R[28∙28]）。如果输入看起来像数字，则模型应估计高概率值。</p><p><strong>建模图像面临的挑战</strong></p><p>像素之间的相互作用是一个巨大的挑战。如果像素彼此独立，我们需要独立学习每个像素的概率密度函数（PDF），这很容易。采样也是轻而易举的，这是因为我们只是独立地对每个像素进行采样。</p><p>在数字图像中，像素之间存在明显的依赖关系。如果你看一下图像的左半边并看到4的开头，你会非常惊讶地看到右边的一半是0的结尾。但是为什么呢？...</p><p><strong>潜在的空间</strong></p><p>你知道一个数字的每个图像应该包含一个数字。R[28∙28]中的输入未明确包含该信息。但它必须驻留在某个地方......而某处是潜在的空间。</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537176964385483850af64><p class=pgc-img-caption>潜在的空间</p></div><p>你可以将潜在空间视为R[k]，其中每个向量包含绘制图像所需的k条基本信息。假设第一个维度包含数字所代表的数字，第二个维度可以是宽度。第三个是角度，等等。</p><p>我们可以把生成图像的过程看作两个步骤。首先，某人有意识地或不自觉地决定他要画的数字的所有属性。接下来，这些决策转化为笔触。</p><p>VAE尝试对此过程进行建模：给定图像x，我们希望找到至少一个能够描述它的潜在向量 - 一个包含生成x的指令的向量。我们得到了使用总概率定律来表达它。</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15371769645246b20fc7918><p class=pgc-img-caption></p></div><p>让我们关注这个方程：</p><ul><li>积分意味着我们应该在候选人的整个潜在空间中进行搜索。</li><li>对于每个候选人z，我们都会问：可以使用z的指令生成x吗？ P（x | z）足够大吗？例如，如果z对数字为7的信息进行编码，那么8的图像是不可能的。然而，1的图像可能是可能的，因为1和7看起来相似。</li><li>我们找到了一个很好的z？很好！但等一下......这个Z可能吗？ P（z）足够大吗？让我们考虑一个倒置的给定图像7。一个潜在的矢量描述一个类似的外观7，其中角度尺寸设置为180度将是一个完美的匹配。但是，z不太可能，因为通常数字不是以180度角绘制的。</li></ul><p>VAE的训练目标是最大化P（x）。我们将使用多元高斯</p><hr><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537176964619388c49e1f9><p class=pgc-img-caption></p></div><p>对P（x | z）进行建模。</p><p>f（z）将使用神经网络建模。σ是一个超参数，乘以单位矩阵I.</p><p>你应该记住，f是我们在使用训练模型生成新图像时将要使用的内容。施加高斯分布仅用于训练目的。如果我们使用σ函数（即确定性地x = f（z）），我们将无法使用梯度下降来训练模型！</p><p><strong>潜伏空间的奇迹</strong></p><p>潜在空间方法存在两个大问题：</p><ol><li>每个维度包含哪些信息？某些维度可能涉及抽象的信息，例如：样式。即使很容易解释所有维度，我们也不希望为数据集分配标签。这种方法无法扩展到新数据集。</li><li>潜在的空间可能是纠缠在一起的，即维度可能是相关的。例如，绘制得非常快的数字可能会导致角度更小和笔触更细。确定这些依赖关系很难。</li></ol><p><strong>深入学习救援</strong></p><p>事实证明，通过在标准多元高斯上应用足够复杂的函数，可以生成每个分布。</p><p>因此，我们将选择P（z）作为标准多元高斯。f由神经网络建模，因此可以分为两个阶段：</p><p>第一层将高斯映射到潜在空间上的真实分布。我们将无法解释这些维度，但这并不重要。</p><p>然后，随后的层将从潜在空间映射到P（x|z）。</p><p>那么我们如何训练这头野兽呢？</p><p>P（x）的公式是难以处理的，因此我们将使用蒙特卡罗方法对其进行近似：</p><ol><li>来自先前P（z）的样本{zi }（i=1 ... n）</li><li>使用P（x）≈（1/n）∙ΣP（x|zi）进行近似</li></ol><p>这很好！所以我们只是采样一组z，并让其反向传播！</p><p>不幸的是，由于x具有高维度，因此需要许多样本来获得合理的近似值。我的意思是，如果你对z进行采样，那么您最终会得到一个与x有关的图像的可能性有多大？顺便说一下，这解释了为什么P（x|z）必须为任何可能的图像分配正概率值的原因，否则模型将无法学习：采样的z将导致几乎肯定与x不同的图像，如果概率为0，则梯度不会传播。</p><p>那么我们如何解决这个问题呢？</p><p>我们走捷径吧！</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15371769648403a04185fdf><p class=pgc-img-caption></p></div><p>大多数采样的z都不会对P（x）做出任何贡献，它们太过分了。如果我们事先知道从哪里采样就好了......</p><p>我们可以引入Q（z|x）。将训练Q以给出可能产生x的z的高概率值。现在我们可以使用来自Q的少得多的样本来计算蒙特卡罗估计。</p><p>不幸的是，出现了一个新问题！而不是最大化</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153717696496286b1e65043><p class=pgc-img-caption></p></div><p>我们将最大化以下内容</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153717696508178402ff380><p class=pgc-img-caption></p></div><p>这两者如何相互关联？</p><p><strong>变分推理</strong></p><p>变分推理是它自己的一个主题，所以我不会在这里详细说明。我要说的是，这两个都是通过这个等式来联系的：</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153717696519295c7e59e41><p class=pgc-img-caption></p></div><p>KL是Kullback-Leibler散度，它直观地测量两种分布的相似程度。</p><p>片刻之后，你将看到我们如何才能最大化方程式的右侧。通过这样做，左侧也将最大化：</p><ul><li>P（x）将最大化。</li><li>Q（z|x）与P（z|x）的关系 - 我们不知道的真正的后验将被最小化。</li></ul><p>方程右侧背后的直觉是我们有一点紧张：</p><ol><li>一方面，我们希望最大化X如何从Z～Q解码。</li><li>另一方面，我们希望Q（z|x）（编码器）类似于先前的P（z）（多元高斯）。人们可以将这个术语视为正则化。</li></ol><p>正确选择分布，最大限度地减少KL散度很容易。我们将Q（z|x）建模为神经网络，其输出是多元高斯的参数：</p><ul><li>平均μ_Q</li><li>对角协方差矩阵Σ_Q</li></ul><p>然后KL散度变得可以解析地解决，这对我们和梯度来说是很好的。</p><p>解码器部分有点棘手。通常，我们通过使用蒙特卡罗来解决这个难以处理的事实。但是从Q采样z将不允许梯度通过Q传播，因为采样不是可微分的运算。这是有问题的，因为输出Σ_Q和μ_Q的层的权重将不会更新。</p><p><strong>重新参数化的技巧</strong></p><p>我们可以用无参数随机变量的确定性参数化变换代替Q：</p><ol><li>来自标准（无参数）高斯的样本。</li><li>将样本乘以Σ_Q的平方根。</li><li>将μ_Q添加到结果中。</li></ol><p>结果将具有等于Q的分布。现在，采样操作将来自标准高斯。因此，梯度将能够通过Σ_Q和μ_Q传播，因为它们是现在的确定性路径。</p><p>其结果是什么？该模型将能够学习如何调整Q的参数：它将集中在能够产生x的良好z上。</p><p><strong>连接点</strong></p><p>VAE模型很难掌握。我们在这里介绍了很多材料，它可能是颠覆性的。</p><p>因此，让我总结一下为实现VAE而需要掌握的所有步骤。</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15371769653579473e5e130><p class=pgc-img-caption></p></div><p>在左侧，我们有模型定义：</p><ol><li>输入图像通过编码器网络。</li><li>编码器输出分布Q（z|x）的参数。</li><li>从Q（z|x）采样潜在矢量z。如果编码器学会了很好地完成其工作，大多数的可能性是z将包含描述x的信息。</li><li>解码器将z解码为图像。</li></ol><p>在右边我们有损失：</p><ol><li>重建错误：输出应与输入类似。</li><li>Q（z|x）应与先验（多变量标准高斯）相似。</li></ol><p>为了生成新图像，你可以直接从先验分布中采样潜在向量，并将其解码为图像。</p><p>在下一篇文章中，我将为你提供VAE的工作代码。 另外，我将向你展示如何使用一个巧妙的技巧来调节潜在的矢量，以便你可以决定要为哪个数字生成图像。</p><p>这篇文章是基于我的直觉和这些来源：</p><p>·变分推理与深度学习：一种新的综合</p><p>https://pure.uva.nl/ws/files/17891313/Thesis.pdf ·变分自编码器教程</p><p>https://arxiv.org/abs/1606.05908</p><div class=pgc-img><img alt=极简笔记：关于变分自编码器的那点儿事 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15371775495527125e90fd7><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'极简','笔记','关于变'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>