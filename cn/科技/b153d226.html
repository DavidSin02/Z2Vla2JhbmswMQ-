<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>语音合成系列 - WaveRNN | 极客快訊</title><meta property="og:title" content="语音合成系列 - WaveRNN - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/6a1d4a4fab3e4e6d83123b9bb7c092a3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b153d226.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b153d226.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b153d226.html><meta property="article:published_time" content="2020-10-29T21:10:03+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:03+08:00"><meta name=Keywords content><meta name=description content="语音合成系列 - WaveRNN"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/b153d226.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>语音合成系列 - WaveRNN</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>介绍</h1><p>如何更快地进行音频合成。特别是，我会对实时地语音场景的合成感兴趣，部分原因是因为这对项目有好处，部分原因是因为它与我个人的研究目标很吻合。我找到了两个选择：</p><p><strong>Parallel Wavenet （并行wavenet）</strong></p><p>有一段时间，研究了Parallel wavenet。据推测，这可以实时地生成样本，现在已经在Google智能助理中使用。但是，我一直无法找到一个较好的，真正的实现，而且论文的细节真的很少。在GitHub上有一些项目，实现了超过6个月，还是没有完成，所以考虑到这个项目的时间限制，我自己实现它似乎不可行。此外，训练过程非常复杂，需要分别训练几个网络，然后再一起训练 - 这使得研究变得非常困难。作为最后一点，本文没有说明是否需要GPU实时运行（优化是“大规模并行”），因此可能是Google Assistant在服务器上合成声音并将其发回。</p><p><strong>WaveRNN</strong></p><p>这篇论文介绍了一种新的语音合成深度架构，称为WaveRNN。他们声称它可以在任何常见的CPU上实时运行，包括手机中的cpu。该架构本身非常简单，而且该论文对于DeepMind来说已经算是非常清晰（如果简洁）的。此外，它采用比我们一直在研究的其他方法更高分辨率的音频（true 16-bit and realtime at 24kHz，而对于Wavenet采用的是 8-bit 16 KHz）。我在Github上发现了这个部分实现。“部分”，这个实现不能实时运行。它实现了基本体系结构，但并非所有其他优化。在我的机器的CPU上，它产生大约800个样本/秒，这仍然比Wavenet或SampleRNN好。该论文中的一个优化是矩阵稀疏化（matrix sparsification），它应该相对容易实现，初步测试表明，这将使合成速度提高10倍。而且据说它听起来会更好。这似乎很有希望，所以我决定更详细地研究WaveRNN。</p><h1><strong>Speech</strong></h1><p>按照惯例，从复制已知结果开始。我通过在VTCK语音语料库中通过连接说话者编号229的所有话语来制作语音数据集。这产生了20分钟的音频文件。我在此基础上使用默认参数训练了WaveRNN，进行了108000次迭代。训练是“无条件的（unconditional）”，这意味着我没假设它会产生可理解的语音 - 只有freeform的speech-like sounds。结果在Example 1中以及来自数据集的样本。</p><p><strong>Example 1：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/p229_008.mp3</p><p>a）来自VCTK数据集的Speaker 229;</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/VCTK_108000_iters.mp3</p><p>b）WaveRNN在经过20分钟的Speaker 229训练后进行108 000次迭代合成的声音</p><p>这些实际上比我在Wavenet上的speech要好得多。同时也注意到训练融合得相对较快。即使经过几千次迭代，它听起来还是不错的，尽管有些artifacts随着训练的增加逐渐消失。Example2是仅18000次迭代后的样品，用于比较。</p><p><strong>Example 2：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/VCTK_18000_iters.mp3</p><p>WaveRNN仅经过18 000次迭代后合成的声音，对于这种小训练来说听起来非常不错。</p><p>很多我们的soundscape录音被分解成10秒的文件，开头和结尾都不太好。处理这些数据需要额外注意，以确保音频文件之间的不连续性不会被训练到模型中。为了确保我的代码是正确的，我将来自VCTK speaker 270的所有音频文件连接起来，并将结果分解为具有不好边界的10秒块。Example 3（a）是来自该数据集的样本记录，Example 3（b）是通过WaveRNN合成的，在对该数据进行102000次迭代的训练之后的结果。</p><p><strong>Example 3：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/VCTK_p270_orig.mp3</p><p>a）来自VCTK speaker p270的10秒块，开始和结束都不太好</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/VCTK_p270_102000.mp3</p><p>b）WaveRNN在对此数据进行120 000次迭代训练后合成的声音。</p><p>这里的结果非常好。该模型像以前一样融合得很好，因此确信代码是正确的。</p><h1><strong>Lakeside数据集</strong></h1><p>在得到的合成speech的结果很不错之后，我决定尝试一些熟悉的数据集 - 从2016年DCASE的Lakeside数据集开始。即使对这个特定的数据集感到有些厌倦，这也可以让我们将WaveRNN与之前在SampleRNN和Wavenent上的结果进行比较。在48,000次迭代之后，结果如Example 4中所述，与来自Lakeside数据集的样本一起呈现。</p><p><strong>Example 4：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/DCASE_Beach.mp3</p><p>a）来自DCASE 2016 Lakeside的风声</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/Beach_48000_1537462877.87.mp3</p><p>b）在DCASE 2016 Lakeside上进行48 000次迭代后，WaveRNN合成的声音。</p><p>这开始听起来像白噪声，听起来可能听起来像声音，也可能听起来不像是声音，然后过渡到麦克风上的声音，这在原始数据集中非常普遍。然而，合成声音缺乏清晰度，声音可能更像是噪声轮廓而不是声景soundscape。</p><p>所以继续训练。然而，随着训练的增加，声音变得越来越大，可能就像所有的音频样本都太嘈杂而且太接近±1。Example 5是在81000个训练周期之后听起来的样子</p><p><strong>Example 5：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/Beach_81000_1537443940.04.mp3</p><p>WaveRNN在81000次迭代后合成的声音，听起来非常震撼，就像过度曝光的照片一样。</p><p>不知道这听起来像水声，还是只是噪音。无论如何，我并没有因此而气馁，因为我注意到训练并没有以一种非常可预测的方式收敛。Figure 2通过显示WaveRNN输出的波形逐渐增加训练来说明这一点。</p><div class=pgc-img><img alt="语音合成系列 - WaveRNN" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6a1d4a4fab3e4e6d83123b9bb7c092a3><p class=pgc-img-caption></p></div><p><strong>Figure</strong> 2：WaveRNN分别在3 000,33 000,48 000,81 000次迭代后输出的波形。这表明网络没有可预测地收敛，因为波形都是完全不同的。</p><p>虽然这不是很好，因为看起来网络似乎没有学习如何很好地拟合数据，它可能会在grinding away一段时间之后达到最低限度。然而，在大约135000次迭代中，损失函数开始返回NaN，这意味着网络中某处的至少一个权重必须是NaN，这可能意味着某个地方的梯度爆炸。The blown-out sound 可能部分归因于网络中非常大的浮点数的低分辨率，在梯度爆炸形成之前。该模型确实在GRU cells上使用了一个变体，可以减轻这种影响。可以是正则化regularization/梯度削减gradient clipping，或者甚至稀疏化sparsification可能有所帮助。但是，此时，模型无法恢复，因此必须进行单独的实验。</p><h1><strong>Park 数据集</strong></h1><p>另外再尝试其他一些数据集，所以在DCASE2016的Park数据集上训练WaveRNN，其中包括在城市公园录制的52分钟音频。Example 6具有来自数据集的一些代表性录音。</p><p><strong>Example</strong> 6：来自DCASE 2016公园数据集的代表性录音。</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/park_orig_1.mp3</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/park_orig_2.mp3</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/park_orig_3.mp3</p><p>Example 7是在对该数据集进行72000次迭代训练后由WaveRNN合成的样本。</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/park_72000.mp3</p><p><strong>Example</strong> 7：在72,000次训练迭代之后由WaveRNN合成的停车声音。这是这一轮训练中最好听的结果（挑选后结果）。</p><p>这听起来相当不错 - 它捕捉鸟鸣般的声音，类似交通的声音以及原始数据中存在的一些严重声音（不知道这些声音实际上是什么）。在训练期间，在每3000次迭代后创建了一个音频样本，但是通过更多的训练，音频并没有明显好转。有时候经过更多的训练后听起来会更好，有时甚至更糟，有点随意。这可能表明学习率太高，或者可能表明梯度变得过于陡峭。为了比较，Example 8是更具代表性的样本，在81000次训练迭代后产生。</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/park_81000.mp3</p><p><strong>Example</strong> 8：在81,000次训练迭代之后由WaveRNN合成的停车声音。这是一个更具代表性（即更糟糕的声音）样本。</p><h1><strong>Night数据集</strong></h1><p>正确地说，在某些方面，这些例子在原始录音的噪音profile上过多，而foreground特征可能还不够。因此，制作了一个“干净”的无噪音数据集，通过一些非常干净的夜间声音录音作为granular合成器。对于一个8-chanel文件，我将其分解为individual channels，总共16分钟的单声道音频。我训练WaveRNN进行了15000次迭代，结果在Example 9中。</p><p><strong>Example 9：</strong></p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/night_orig_mono.mp3</p><p>a）来自原始night数据集的单个频道</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/night_15000.mp3</p><p>b）WaveRNN在对该数据集进行15000次迭代训练后合成的声音</p><p>和上面的Park数据集的示例一样，我选择了这个结果。随着越来越多的训练，似乎模型在几个不同的解决方案之间徘徊。这是其中之一，其他人只是在两个球场中的一个持续吹口哨。这再次非常清楚地表明学习率太高了。（使用的是Adam优化器，它应该在一定程度上防止这种情况，但是仍然存在全局学习率，其值对训练结果有很大影响。）在任何情况下，模型都没有获得原始的幅度轮廓。数据集。Example 10是该模型发现的其他解决方案之一，这次是在150,000（十五万）个训练周期之后。</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/night_150000.mp3</p><p><strong>Example</strong> 10：在Night数据集上训练150,000次迭代后由WaveRNN合成的声音。</p><h1><strong>Cafe数据集</strong></h1><p>不同的架构在不同的数据上表现不同，所以我想看看在DCASE 2016的Cafe数据集上WaveRNN会发生什么。结果并不好。这就是87000次迭代之后的情况。</p><p>http://cvssp.org/projects/ambisynth/pages/ambisynth/ambisynth_blogspot_com/Post_10_Wave_RNN/Cafe_87000_iters.mp3</p><p><strong>Example 11</strong>：在Cafe数据集上进行87 000次迭代后由WaveRNN合成的声音。</p><p>虽然这听起来不像咖啡馆，但听起来有点像一些数据太少的SampleRNN的Cafe模型。然而，通过持续训练，声音再次被吹灭和嘈杂，所以我在大约170 000次迭代后将其消灭。虽然这不是很好，但我认为它比Wavenet在这个数据集上的结果要好得多。话虽如此，很明显环境声音比语音更难合成，而咖啡馆Cafe似乎是一个异常难合成的数据集，因为它包括语音，嘈杂的声音和脉冲一样的声音。</p><h1><strong>结论和未来的工作</strong></h1><p>这样看下来，对这种架构的兴趣有点挫败。但是，我认为我们仍然可以采取一些措施来改善结果，尽管它们可能并不容易，因此现在暂时不会这样做，除非我想到一些非常明显的事情。话虽如此，很明显环境声音比语音更难合成，而咖啡馆似乎是一个异常艰难的数据集，因为它包括语音，嘈杂的声音和脉冲声音。</p><p>经过一番思考，再多做一些实验，我觉得这个模型听起来相当不错。我认为通过正则化regularization，梯度削波gradient clipping和一些超参数调整（例如学习率），我们应该能够获得更稳定一致的结果。</p><h1><strong>代码片段</strong></h1><p>通过使用块稀疏矩阵，使用以下的代码，估计了可以近10倍的提高速度。</p><pre>import numpy as npimport timeimport randomimport scipy.sparsehidden_size = 896block_width = 4density = 0.05 R = np.random.rand(3 * hidden_size, hidden_size)h = np.ones(hidden_size); t = time.time() for i in range(22050): h = np.matmul(R, h) h = h[0:hidden_size] print time.time() - tfor i in range(3 * hidden_size // block_width): for j in range(hidden_size // block_width): r = random.random(); if r &gt; density: for k in range(block_width): for l in range(block_width): R[(block_width*i)+k][(block_width*j)+l] = 0S = scipy.sparse.bsr_matrix(R, blocksize=(block_width,block_width))t = time.time() for i in range(22050): h = S * h h = h[0:hidden_size]print time.time() - t</pre></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'语音','WaveRNN','合成'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>