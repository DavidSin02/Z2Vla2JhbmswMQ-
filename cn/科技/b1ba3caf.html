<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>教你学Python30-支持向量机SVM基础 | 极客快訊</title><meta property="og:title" content="教你学Python30-支持向量机SVM基础 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/07db0cc84ff24bd5ae7a4632bd7f97b3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b1ba3caf.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b1ba3caf.html><meta property="article:published_time" content="2020-10-29T21:09:42+08:00"><meta property="article:modified_time" content="2020-10-29T21:09:42+08:00"><meta name=Keywords content><meta name=description content="教你学Python30-支持向量机SVM基础"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/b1ba3caf.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>教你学Python30-支持向量机SVM基础</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>​</h1><h3 class=pgc-h-arrow-right>一、前言</h3><p>对于SVM这个理论，本人感觉是非常难理解的 借鉴了很多大佬的笔记和视频 还是想以自己能理解的方式进行阐述清楚SVM是什么东西 他的具体实现 所以我尽量少点涉及公式什么的 通俗的介绍SVM</p><h3 class=pgc-h-arrow-right>二、什么是SVM</h3><p>SVM的英文全称是Support Vector Machines，我们叫它支持向量机。支持向量机是我们用于分类的一种算法。让我们以一个小故事的形式，开启我们的SVM之旅吧。</p><p>在很久以前的情人节，一位大侠要去救他的爱人，但天空中的魔鬼和他玩了一个游戏。</p><p>魔鬼在桌子上似乎有规律放了两种颜色的球，说："你用一根棍分开它们？要求：尽量在放更多球之后，仍然适用。"</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/07db0cc84ff24bd5ae7a4632bd7f97b3><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>于是大侠这样放，干的不错？</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c140f694950f44a095a11c8063811d5a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>然后魔鬼，又在桌上放了更多的球，似乎有一个球站错了阵营。显然，大侠需要对棍做出调整。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fa31c3081c04446181a65fd679864e86><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p><strong>SVM就是试图把棍放在最佳位置，好让在棍的两边有尽可能大的间隔。这个间隔就是球到棍的距离。</strong></p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5a583da11e3443129d893f6061c1ba11><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在好了，即使魔鬼放了更多的球，棍仍然是一个好的分界线。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/54ed7e9f305a45bd83d6bd9156eee3a6><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>魔鬼看到大侠已经学会了一个trick(方法、招式)，于是魔鬼给了大侠一个新的挑战。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3353c09e7ebd41f58571aaeed7db371f><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在，大侠没有棍可以很好帮他分开两种球了，现在怎么办呢？当然像所有武侠片中一样大侠桌子一拍，球飞到空中。然后，凭借大侠的轻功，大侠抓起一张纸，插到了两种球的中间。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ca6ec6913fcb43f6b8bf691aea5eec00><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在，从空中的魔鬼的角度看这些球，这些球看起来像是被一条曲线分开了。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d589d0a04c1543e58da303511ea3ca63><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>再之后，无聊的大人们，把这些球叫做data，把棍子叫做classifier(分类器也可叫做分隔超平面), 找到最大间隔的trick叫做optimization(最优化)，拍桌子叫做kernelling(核函数), 那张纸叫做hyperplane(超平面)。</p><p>更为直观地感受一下吧(需要翻墙)：https://www.youtube.com/watch?v=3liCbRZPrZA</p><p>概述一下：</p><p>当一个分类问题，数据是线性可分的，也就是用一根棍就可以将两种小球分开的时候，我们只要将棍的位置放在让小球距离棍的距离最大化的位置即可，寻找这个最大间隔的过程，就叫做最优化，这条分隔直线称为分隔超平面(separating hyperplane)。但是，现实往往是很残酷的，一般的数据是线性不可分的，也就是找不到一个棍将两种小球很好的分类。这个时候，我们就需要像大侠一样，将小球拍起，用一张纸代替小棍将小球进行分类。想要让数据飞起，我们需要的东西就是核函数(kernel)，用于切分小球的纸，就是超平面。</p><p>也许这个时候，你还是似懂非懂，没关系。根据刚才的描述，可以看出，问题是从线性可分延伸到线性不可分的。那么，我们就按照这个思路，进行原理性的剖析。</p><h3 class=pgc-h-arrow-right>三、线性SVM</h3><p>先看下线性可分的二分类问题。</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a802ea3b03b24c4ba6f0791efe2ff105><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>上图中的(a)是已有的数据，红色和蓝色分别代表两个不同的类别。数据显然是线性可分的，但是将两类数据点分开的直线显然不止一条。上图的(b)和(c)分别给出了B、C两种不同的分类方案，其中黑色实线为分界线，术语称为‘分隔超平面’。每个分隔超平面对应了一个线性分类器。虽然从分类结果上看，分类器A和分类器B的效果是相同的。但是他们的性能是有差距的，看下图：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/356302a304ac47bdac97fb416e2e9069><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>在分隔超平面不变的情况下，我又添加了一个红点。可以看到，分类器B依然能很好的分类结果，而分类器C则出现了分类错误。显然分类器B的分隔超平面放置的位置优于分类器C的分隔超平面放置的位置，SVM算法也是这么认为的，它的依据就是分类器B的分类间隔比分类器C的分类间隔大。这里涉及到第一个SVM独有的概念"分类间隔"。在保证分隔超平面方向不变且不会出现错分样本的情况下移动分隔超平面，会在原来的分隔超平面两侧找到两个极限位置（越过该位置就会产生错分现象），如虚线所示。虚线的位置由分隔超平面的方向和距离原分隔超平面最近的几个样本的位置决定。而这两条平行虚线正中间的分界线就是在保持当前分隔超平面方向不变的前提下的最优分隔超平面。两条虚线之间的垂直距离就是这个最优分隔超平面对应的分类间隔。显然每一个可能把数据集正确分开的方向都有一个最优分隔超平面（有些方向无论如何移动分隔超平面的位置也不可能将两类样本完全分开），而不同方向的最优分隔超平面的分类间隔通常是不同的，那个具有“最大间隔”的分隔超平面就是SVM要寻找的最优解。而这个真正的最优解对应的两侧虚线所穿过的样本点，就是SVM中的支持样本点，称为"支持向量"。也就是图中被虚线穿过的红点和蓝点里面有黑色标记的样本点就是SVM的支持向量。</p><p>ok到这部分我们还没有涉及到复杂的公式推导 下面我们就会涉及到一点公式推导了 我尽量用简答明理的方式来说明</p><p>我们求解这个‘分隔超平面’的过程，也就是求出线性可分数据那条分类直线的过程，然后求出最大的分类间隔，就是最优化。</p><p>一个最优化问题通常有两个基本的因素：1）目标函数，也就是你希望什么东西的什么指标达到最好；2）优化对象，你期望通过改变哪些因素来使你的目标函数达到最优。</p><p><strong>(1)"分类间隔"方程</strong></p><p>在线性SVM算法中，目标函数显然就是那个"分类间隔"，而优化对象则是分隔超平面。</p><p>我们可以看下图：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b23a112c2f7b4776ae4f2b1bf63153df><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>分隔超平面的形式可写成$w^x+b$ 我们已经知道分类间隔的大小实际上就是支持向量(虚线穿过的点)对应的样本点到分隔超平面的距离的二倍。图中d求出来就是分类间隔。</p><p>我们高中都学过，点到直线的距离距离公式如下：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d8f194bad1e743c5bfecc40f82df86ad><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在，将直线方程扩展到多维，求得我们现在的超平面方程，对公式进行如下变形：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e84f32b750a24956942ee08f5eb5e69e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>我们目的是为了找出一个分类效果好的超平面作为分类器。分类器的好坏的评定依据是分类间隔W=2d的大小，即分类间隔w越大，我们认为这个超平面的分类效果越好。此时，求解超平面的问题就变成了求解分类间隔W最大化的为题。W的最大化也就是d最大化的。</p><p>在这里我们看到两条虚线是优化的变量d的取值范围 也就是在这里我们设定直线值大于1的是红色球 小于1的是蓝色球</p><p>即：假设超平面可以完全正确地将所有样本分类，则对于任意一个样本（xi，yi）来说都有如下性质（注：这里样本的类别标签y_i用+1代表正例，-1代表反例）：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c5acc460e6a84731a584646ee8177c01><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>上述方程即给出了SVM最优化问题的约束条件。这样标记方便我们将上述方程变成如下形式：也就可以理解为所有样本点到直线$wx+b=0$的距离都大于1.</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/49e70562ec644551af440f574c3910ab><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p><strong>（2）"分隔超平面"方程</strong></p><p>我们会头疼这里的具体推倒是怎么产生的那，比如$w^x+b$分隔超平面的公式为什么写成这样 以及从二维的点到直线距离扩展为多维的是怎么扩展的那 其实是很简单的 我们来简单说下</p><p>我们都知道二维空间下一条直线的方式如下所示：$y=ax+b$</p><p>现在我们做个小小的改变，让原来的x轴变成x1，y轴变成x2：$x_2=ax_1+b$</p><p>移项得：$ax_1-x_2+b=0$</p><p>将公式向量化得：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0f3f28adde584b08ac92960dbf49263f><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>进一步向量化，用w列向量和x列向量和标量γ进一步向量化：$w^T+b=0$</p><p>其中，向量w和x分别为：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a5cc2589c0d64ab69cecfc272e511e16><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>二维空间的直线方程已经推导完成，将其推广到n维空间，就变成了超平面方程。(一个超平面，在二维空间的例子就是一个直线)但是它的公式没变，依然是：$w^T+b=0$</p><p>不同之处在于：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b6f223754f214394844913f9525f81a2><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>这样推倒之后我们可以非常直观的看出来分隔超平面这条直线和分类间隔是怎么从一维扩展到多维的了。</p><p><strong>(3)线性SVM优化问题基本描述</strong></p><p>现在整合一下思路，我们已经得到我们的目标函数：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/b779028ae75f4c81828ec4258fc170b6><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>我们的优化目标是是d最大化。我们已经说过，我们是用支持向量上的样本点求解d的最大化的问题的。那么支持向量上的样本点有什么特点呢？</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c75bee40e8064cf5b07a6a42341637a5><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>所有支持向量上的样本点，都满足如上公式。如果不赞同，请重看"分类间隔"方程推导过程。也就是这个方程绝对值都是满足等于1的。</p><p>现在我们就可以将我们的目标函数进一步化简：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0eda127768324b0ab8bd0305d1493f3c><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>因为，我们只关心支持向量上的点。随后我们求解d的最大化问题变成了||w||的最小化问题。进而||w||的最小化问题等效于</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad75b76ed72a406d96e04ff7190291d9><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>为什么要做这样的等效呢？这是为了在进行最优化的过程中对目标函数求导时比较方便，但这绝对不影响最优化问题最后的求解。我们将最终的目标函数和约束条件放在一起进行描述：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e482506c53bd4d9fa0e5cd6235610bce><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在我们的优化问题变成了如上的形式</p><p>这里n是样本点的总个数，缩写s.t.表示"Subject to"，是"服从某某条件"的意思。上述公式描述的是一个典型的不等式约束条件下的二次型函数优化问题，同时也是支持向量机的基本数学模型。</p><p>SVM就是来解决上面这个方程的优化问题。再经过拉格朗日公式和KKT条件等数学运算最后找出分类器定义中的w和b。</p><p>我这样只是把简单的SVM最基本的概念讲清楚了 对于更复杂的SVM优化问题 以及优化我们可以参照这个网址进行理解：https://cuijiahua.com/blog/2017/11/ml_8_svm_1.html</p><p>总之经过复杂的推论 拉格朗日公式和KKT条件等数学运算之后 现在我们的优化问题变成了如下的形式：</p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f7f4d461694644278e6fdee6ffd7bee7><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p><p>现在我们的优化问题变成了如上的形式。对于这个问题，我们有更高效的优化算法，即序列最小优化（SMO）算法。我们通过这个优化算法能得到α，再根据α，我们就可以求解出w和b，进而求得我们最初的目的：找到分隔超平面。</p><p>下面我们来谈谈SVM的一种高效的优化算法，序列最小化SMO算法</p><h3 class=pgc-h-arrow-right>四、序列最小化SMO算法</h3><p>对于上面提到的最优化的这个问题，我们有更高效的优化算法，即序列最小优化（SMO）算法。我们通过这个优化算法能得到α，再根据α，我们就可以求解出w和b，进而求得我们最初的目的：找到分隔超平面。</p><h3 class=pgc-h-arrow-right>序列最小优化(Sequential Minimal Optimization, SMO)</h3><ul><li>创建作者：John Platt</li><li>创建时间：1996年</li><li>SMO用途：用于训练 SVM</li><li>SMO目标：求出一系列 alpha 和 b,一旦求出 alpha，就很容易计算出权重向量 w 并得到分隔超平面。</li><li>SMO思想：是将大优化问题分解为多个小优化问题来求解的。</li><li>SMO原理：每次循环选择两个 alpha 进行优化处理，一旦找出一对合适的 alpha，那么就增大一个同时减少一个。这里指的合适必须要符合一定的条件这两个 alpha 必须要在间隔边界之外这两个 alpha 还没有进行过区间化处理或者不在边界上。</li></ul><p>SMO 伪代码大致如下：</p><pre><code>创建一个 alpha 向量并将其初始化为0向量当迭代次数小于最大迭代次数时(外循环)    对数据集中的每个数据向量(内循环)：        如果该数据向量可以被优化            随机选择另外一个数据向量            同时优化这两个向量            如果两个向量都不能被优化，退出内循环    如果所有向量都没被优化，增加迭代数目，继续下一次循环</code></pre><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><h3 class=pgc-h-arrow-right>五、编程求解线性SVM</h3><p>已经梳理完了SMO算法实现步骤，接下来按照这个思路编写代码，进行实战练习。</p><p>SVM开发流程</p><ol start=1><li>收集数据：可以使用任意方法。</li><li>准备数据：需要数值型数据。</li><li>分析数据：有助于可视化分隔超平面。</li><li>训练算法：SVM的大部分时间都源自训练，该过程主要实现两个参数的调优。</li><li>测试算法：十分简单的计算过程就可以实现。</li><li>使用算法：几乎所有分类问题都可以使用SVM，值得一提的是，SVM本身是一个二类分类器，对多类问题应用SVM需要对代码做一些修改。</li></ol><p><br></p><p>喜欢点下关注，你的关注是我写作的最大支持</p><p><br></p><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4e5b16898cf147bd9f60a0ad4cf0a122><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=教你学Python30-支持向量机SVM基础 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfb7b7ef19ea482195ec8bf365e4fc65><p class=pgc-img-caption></p></div><p>​</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Python30','SVM','基础'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>