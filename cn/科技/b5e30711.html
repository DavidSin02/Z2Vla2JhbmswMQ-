<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 | 极客快訊</title><meta property="og:title" content="Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/3b45b2142ecf4aa0880b1d53cf8bf32e"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5e30711.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5e30711.html><meta property="article:published_time" content="2020-10-29T21:09:59+08:00"><meta property="article:modified_time" content="2020-10-29T21:09:59+08:00"><meta name=Keywords content><meta name=description content="Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/b5e30711.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>前几天小编连续写了四篇关于Python选择器的文章，分别用正则表达式、BeautifulSoup、Xpath、CSS选择器分别抓取京东网的商品信息。今天小编来给大家总结一下这四个选择器，让大家更加深刻的理解和熟悉Python选择器。</p><p>一、正则表达式</p><p>正则表达式为我们提供了抓取数据的快捷方式。虽然该正则表达式更容易适应未来变化，但又存在难以构造、可读性差的问题。当在爬京东网的时候，正则表达式如下图所示：</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3b45b2142ecf4aa0880b1d53cf8bf32e><p class=pgc-img-caption></p></div><p>利用正则表达式实现对目标信息的精准采集</p><p>此外 ，我们都知道，网页时常会产生变更，导致网页中会发生一些微小的布局变化时，此时也会使得之前写好的正则表达式无法满足需求，而且还不太好调试。当需要匹配的内容有很多的时候，使用正则表达式提取目标信息会导致程序运行的速度减慢，需要消耗更多内存。</p><p>二、BeautifulSoup</p><p>BeautifulSoup是一个非常流行的 Pyhon 模块。该模块可以解析网页，并提供定位内容的便捷接口。通过'pip install beautifulsoup4'就可以实现该模块的安装了。</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/438f2c13f2394702a4da379cd1f3b0fa><p class=pgc-img-caption></p></div><p>利用美丽的汤去提取目标信息</p><p>使用 BeautifulSoup的第一步是将己下载的 HTML 内容解析为 soup文档。由 于大多 数网 页都不具备良好的HTML 格式，因此BeautifulSoup需要对实际格式进行确定。BeautifulSoup能够正确解析缺失的引号并闭合标签，此外还会添加＜html ＞和＜body＞标签使其成为完整的HTML文档。通常使用find() 和find_all()方法来定位我们需要的元素。如果你想了解BeautifulSoup全部方法和参数，可以查阅BeautifulSoup的官方文档。虽然BeautifulSoup在代码的理解上比正则表达式要复杂一些，但是其更加容易构造和理解。</p><p>三、Lxml</p><p>Lxml模块使用 C语言编写，其解析速度比 BeautiflSoup更快，而且其安装过程也更为复杂，在此小编就不赘述啦。XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e0a6fdb391464e05b2383ccea79e7e11><p class=pgc-img-caption></p></div><p>Xpath</p><p>使用 lxml 模块的第一步和BeautifulSoup一样，也是将有可能不合法的HTML 解析为 统一格式。 虽然Lxml可以正确解析属性两侧缺失的引号，并闭合标签，不过该模块没有额外添加＜html ＞和＜body＞标签 。</p><p>在线复制Xpath表达式可以很方便的复制Xpath表达式。但是通过该方法得到的Xpath表达式放在程序中一般不能用，而且长的没法看。所以Xpath表达式一般还是要自己亲自上手。</p><p>四、CSS</p><p>CSS选择器表示选择元素所使用 的模式。BeautifulSoup整合了CSS选择器的语法和自身方便使用API。在网络爬虫的开发过程中，对于熟悉CSS选择器语法的人，使用CSS选择器是个非常方便的方法。</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/38e71e723cac412c8641fe3153ee7988><p class=pgc-img-caption></p></div><p>CSS选择器</p><p>下面是一些常用的选择器示例。</p><ul><li>选择所 有标签： ＊</li><li>选择＜a＞标 签： a</li><li>选择所有class＝”link” 的元素： .l in k</li><li>选择 class＝”link” 的＜a＞标签： a.link</li><li>选择 id= " home ” 的＜a＞标签： a Jhome</li><li>选择父元素为＜a＞标签的所有＜ span＞子标签： a > span</li><li>选择＜a＞标签内部的所有＜span＞标签： a span</li><li>选择title属性为” Home ” 的所有＜a＞标签： a [title=Home]</li></ul><p>五、性能对比</p><p>lxml 和正则表达式模块都是C语言编写的，而BeautifulSoup则是纯Python 编写的。下表总结了每种抓取方法的优缺点。</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4f4aa3210dda4087b6b50841e8c3402d><p class=pgc-img-caption></p></div><p>相对困难需要注意的是。lxml在内部实现中，实际上是将CSS选择器转换为等价的Xpath选择器。</p><p>六、总结</p><p>如果你的爬虫瓶颈是下载网页，而不是抽取数据的话，那么使用较慢的方法（如BeautifulSoup） 也不成问题。如果只需抓取少量数据，并且想要避免额外依赖的话，那么正则表达式可能更加适合。不过，通常情况下，l xml是抓取数据的最好选择，这是因为该方法既快速又健壮，而正则表达式和BeautifulSoup只在某些特定场景下有用。</p><div class=pgc-img><img alt=Python网络爬虫四大选择器（正则表达式、BS4、Xpath、CSS）总结 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ed706d93222b4044894af5c8dd6c361c><p class=pgc-img-caption></p></div><p>想学习更多Python网络爬虫与数据挖掘知识，可前往专业网站：http://pdcfighting.com/</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Python','网络','爬虫'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>