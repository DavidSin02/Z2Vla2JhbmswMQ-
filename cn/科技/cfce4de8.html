<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>基于方向引导优化的视觉导航方法 | 极客快訊</title><meta property="og:title" content="基于方向引导优化的视觉导航方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/65be0007500383aa7f79"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/cfce4de8.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/cfce4de8.html><meta property="article:published_time" content="2020-10-29T21:11:06+08:00"><meta property="article:modified_time" content="2020-10-29T21:11:06+08:00"><meta name=Keywords content><meta name=description content="基于方向引导优化的视觉导航方法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/cfce4de8.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>基于方向引导优化的视觉导航方法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>姜德晶1，孙 涛1，2，秦录芳1</p><p>（1.徐州工程学院 机电工程学院，江苏 徐州221111；2.南京航空航天大学 机电学院，江苏 南京210016）</p><p>为解决主动视觉导航在复杂路况条件下精度较差的问题，提出了一种基于方向引导优化的主动视觉导航参量计算方法。首先，建立了车辆物理座标系与视觉图像座标系的变换方程，通过Canny算子对视频图像进行初步的车道边缘线和道路标志线检测；接着，基于方向引导优化有效降低了阴影、积水等杂波对检测性能的干扰，并通过阈值优化的广义Hough变换实现车道线的内外边缘及道路标志线的精确检测；最后，基于检测结果计算出用于导航的中心引导线、偏离角度、距离等参量。实验结果表明，该方法能够有效且精确地获取主动导航系统的偏移参量。</p><p>计算机视觉；主动导航；道路边缘线检测；道路标志线检测；偏移参</p><p><strong>中图分类号：</strong>TN94；TP242</p><p><strong>文献标识码：</strong>A</p><p><strong>DOI：</strong>10.16157/j.issn.0258-7998.172745</p><p><strong>中文引用格式：</strong>姜德晶，孙涛，秦录芳. 基于方向引导优化的视觉导航方法[J].电子技术应用，2018，44(2)：52-54，58.</p><p><strong>英文引用格式：</strong>Jiang Dejing，Sun Tao，Qin Lufang. Direction guided optimization based vision navigation method[J]. Application of Electronic Technique，2018，44(2)：52-54，58.</p><p><strong>0 引言</strong></p><p>基于计算机视觉技术的视觉导航技术是人工智能领域的研究重点和热点<sup>[1]</sup>。同传统的卫星定位（GPS）导航技术相比，基于视觉的导航方法具有实现方式灵活、性价比高、实时性好、导航快速精确等优点<sup>[2-3]</sup>。但是，现有的视觉导航系统多数都是基于固定摄像机的限定视角导航方法，这类导航系统只能适用于在直线行驶或者小弯度行驶情况，一旦出现大弯度转弯，道路会偏离摄像机视场，导致路径导航线丢失、导航失效<sup>[4-5]</sup>。为改善这种视角范围的局限，传统解决方法主要是将固定的摄像机改为广角镜头摄像机，增大视场范围<sup>[6]</sup>，但是广角摄像机的图像畸变严重，对图像前期的处理精度和速度的要求严格，同时，增加了大量的图像干扰信息，为后续的图像处理增加了较大的难度。近年来，有学者提出了一种主动视觉智能导航方法<sup>[7]</sup>，借鉴人类观察道路时的眼球转动机理，将摄像机安装在可旋转控制云台系统上，通过一定的反馈控制，实时修正摄像机焦点和行驶路线正前方的夹角，保证行驶路线一直处于摄像机视角范围内。由于该方法在保证视角清晰的前提下，大幅扩展了摄像机的视角范围，近年来在目标跟踪<sup>[8]</sup>、人脸检测<sup>[6]</sup>等领域得到了较多的研究和应用。其中，如何精确获取导航参量是主动视觉导航系统的关键问题之一<sup>[9]</sup>。传统的计算方法主要通过预先设置的高精度标定参照物，通过空间图像和平面图像的有效映射关系求取相关的参量值，该类方法标定精度高，但是应用范围有限且标定复杂，不利于变化场景的导航<sup>[10]</sup>。文献[11]提出了基于视觉图像的自计算方法，该方法通过前端获取的视频帧图像进行系统参量的计算，利用Kruppa方程和分层逐步标定的方式实现了导航参量的计算，该方法灵活性强、使用范围较广，但是计算精度和鲁棒性较差，在背景存在干扰的情况下计算误差较大，甚至引起导航失败<sup>[12]</sup>。文献[13]利用相机进行可控运动，通过约束运动的性质来实现导航参量的计算，提升了主动视觉导航的参量计算精度和鲁棒性。在此基础上，先后发展出了旋转计算方法<sup>[14]</sup>、平面正交计算方法<sup>[15]</sup>以及基于无穷远平面单应性矩阵<sup>[16]</sup>的计算方法。该类方法计算精度高、鲁棒性好，但是该类方法需要计算的参量过多且计算复杂，在实时导航系统中很难应用。文献[17]在此基础上进一步对计算复杂性进行优化，利用二维频移运动的相对计算方法求解线性模型的部分参数，并通过畸变的方法引入非线性优化，有效地简化了计算过程，但是这种非线性畸变的过程对系统的初值和噪声都非常敏感，计算稳定性较差。</p><p>针对这些问题，本文提出了一种基于方向引导优化的主动视觉导航参量计算方法。该方法的实现过程可以大致概括为三个步骤：(1)座标系的变换。为了实现理论计算与实际导航系统的高精度拟合，首先给出了车辆物理座标系与视觉图像座标系的变换方程。(2)车道边缘线的精确检测。精确地获取车道边缘线是进行视觉导航的前提，为了解决道路积水、阴影等背景干扰问题，在传统Canny算子初步检测的基础上，提出了方向引导优化的方法。(3)大曲率弯道线精确检测问题。为了保证在大曲率转弯情况下车道线的精确检测问题，在前期优化的基础上，提出了基于直线与曲线阈值优化的广义Hough变换方法，对不同曲率的线段进行优化选择，精确检测道路标志线和边缘线，实时计算和修正导航中心引导线的偏离角度。</p><p><strong>1 座标变换</strong></p><p>座标变换是进行视觉导航实现的首要条件，为了实现图像座标与实际车辆物理座标的意义映射，本文基于车辆行驶的实际道路环境构建座标系，将摄像机中心定为座标原点，X轴为车辆行驶方向，Y轴为行驶方向的正左方，将控制云台的纵向轴设置为Z轴。为便于后续云台控制的分析，将车辆物理座标系获取的图像表示为(x<sub>r</sub>，y<sub>r</sub>，z<sub>r</sub>)，相应的像素座标系可以表示为(u，v)，图1表示了座标变换前后之间的关系，具体的变换关系计算如下<sup>[10]</sup>：</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/65be0007500383aa7f79><p>由于车辆导航过程中需要检测的道路标志线一直处于平面状态(z<sub>r</sub>=0)，为方便计算，可将座标系重新修正为x<sub>r</sub>Oy<sub>r</sub>座标系，将式(1)重新计算为：</p><p><strong>2 道路边缘检测及方向引导优化实现</strong></p><p><strong>2.1 方向引导优化实现</strong></p><p>首先通过Canny算进行初步检测，获取图像边缘信息以后，保留图像中的轮廓信息，但是由于阴影、积水和路面裂缝等路面特征的干扰，导致杂波轮廓信息同样得到了保留，因此，该部分主要采用方向引导搜索优化去除阴影干扰<sup>[14]</sup>。假设摄像机前端获取的图像被划分为3×3图像块，当前像素点(如图2(a)中的灰色中心点)具有8个邻接的像素。为说明搜索的方向性，假设目前的像素处于左车道，则车辆行驶的方向只有3个方向，如图2(a)所示。同样，处于右车道也具有3个行驶方向，如图2(b)所示。</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/65bb0008f95b18892367><p>根据车辆在道路上的行驶规则，可以定义为最优选择方向为90°、次优选择为45°、级别最低为0°，以车辆在左边车道行驶为例给出搜索过程描述如下<sup>[15]</sup>。</p><p>(1)以图像的左下角为参考进行平面扫描，如果当前像素判定为边缘，记录并创建候选线段；否则，继续扫描直到找到边缘点，并执行第(2)步。</p><p>(2)根据方向优先原理进行扫描，判定边缘点在3个方向中的位置并记录座标，继续扫描，直到结束；如果3个方向均未扫描到边缘点，则跳转第(3)步。</p><p>(3)遍历整幅图像，寻找新的边缘点，直到结束。</p><p>上面的方向优先搜索完成以后，可以建立线段集合，并记录每一条线段的起始座标。</p><p><strong>2.2 导航参量的计算</strong></p><p>在2.1小节检测的基础上，为进一步精确引导车辆的行驶，需基于检测的边缘线和道路标志线进行导航中心引导线的提取以及偏离角度的计算。首先采用图像重心分割的方法获取精确的导航引导线<sup>[16]</sup>，具体如图3所示。</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/65bd00088813bbc71418><p>通过计算两个标志线以内的图像（包括边缘线与标志线以内的图像，主要是机器人行驶路线所在的边界标志）的重心，基于中心的纵座标进行二次分割，获取上下图像的中心A和B点，直线AB即为机器人行驶区域内的中心引导线。如图3(b)所示，O为该帧图像的整体重心，I<sub>1</sub>和I<sub>2</sub>主要用于偏离角度的计算。具体的计算过程如图4所示。</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/65bc0008fa767e467ee1><p>为计算机器人的行驶偏角及偏距，在获取机器人引导线以后，利用线段端点座标及长度画圆，并结合线段另一端点像素所在的座标位置，计算引导线的偏角。实验中，首先将机器人放置在行驶的路段进行引导线初始化，利用图3(a)拟合道路引导线，进而基于图3(b)计算引导线的线性方程，并确定其具体的位置m。以相机为O点，基于I<sub>1</sub>和I<sub>2</sub>计算机器人的位置偏移D和偏角α。</p><p><strong>3 实验与结果分析</strong></p><p>为验证本文方法的有效性，该部分主要针对路况复杂的弯道行驶进行分析，视频帧图像大小为400像素×300像素。图5(a)所示为在校园内弯道测试实验现场获取的弯道导航图像，图5(b)为本文优化后的检测结果。</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/65ba00142d59da74a218><p>表1为弯道视频帧序列计算结果平均比较结果，从表中可以看出在弯道行驶情况下，3种方法的计算精度均有所下降，其中，文献[13]和文献[17]的性能明显变差，而本文方法针对该序列的计算精度仍然保持了相当高的精度，平均偏航角度的计算误差控制在1.5°以内，平均行驶偏距控制在5个像素左右。</p><img alt=基于方向引导优化的视觉导航方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/65bc0008fa7738076949><p><strong>4 结论</strong></p><p>本文主要针对主动视觉导航系统参量的计算方法展开研究，提出了一种基于方向引导优化的主动视觉导航参量计算方法。该方法是在文献[13]的基础上进行优化和改进，利用主动视觉相机的运动可控性进行参量的计算。通过对传统Canny算子检测结果进行方向引导优化以后，明显降低了道路阴影、路面积水等杂波的干扰，在此基础上，进一步采用阈值优化的广义Hough变换方法对检测结果进行分类优化，实现车道线的内外边缘及道路标志线的精确检测。实验结果表明，本文方法在弯道行驶情况下导航参量的计算精度明显提升，具有优秀的性能指标。</p><p><strong>参考文献</strong></p><p>[1] 姬长英，周俊.农业机械导航技术发展分析[J].农业机械学报，2014，45(9)：4-54.</p><p>[2] 李林，魏新华，朱文静，等.机器视觉辅助导航系统研究[J].农业机械学报，2015，46(5)：1-7.</p><p>[3] 张志斌，罗锡文，周学成，等.基于Hough变换和Fisher准则的垄线识别算法[J].中国图象图形学报，2007，12(12)：2164-2168.</p><p>[4] GUERRERO J M，GUIJARRO M，MONTALVO M，et al.Automatic expert system based on images for accuracy crop row detection in maize fields[J].Expert Systems with Applications，2013，40(2)：656-664.</p><p>[5] WALKER J S，CHEN Y J.Image denoising using tree base wavelet subband correlation and shrinking[J].Optical Engineering，2000，39(11)：2900-2908.</p><p>[6] Ji Wei，Zhao Dean，Cheng Fengyi，et al.Automatic recognition vision system guided for apple harvesting robot[J].Computers and Electrical Engineering，2012，38(5)：1186-1195.</p><p>[7] Li Bin，Wang Maohua.In-field recognition and navigation path extraction for pineapple harvesting robots[J].Intelligent Automation & Soft Computing，2013，19(1)：9-20.</p><p>[8] Wei Xiangqin，Jia Kun，Lan Jinhui，et al.Automatic method of fruit object extraction under complex agricultural back-ground for vision system of fruit picking robot[J].Optik International Journal for Light and Electron Optics，2014，125(19)：5684-5689.</p><p>[9] Tang Jinglei，Jing Xu，He Dongjian，et al.Visual navigation control for agricultural robot using serial BP neural network[J].Transactions of the Chinese Society of Agricultural Engineering，2011，27(2)：194-198.</p><p>[10] 李景彬，陈兵旗，刘阳.棉花铺膜播种机导航路线图像检测方法[J].农业机械学报，2014，40(1)：40-45.</p><p>[11] 张征明，卢伟，陆静霞.基于快速伪球滤波的智能拖拉机视觉导航中场景去雾方法[J].机器人，2015，37(5)：603-613.</p><p>[12] 李颢，杨明.基于非线性逆透视变换的摄像机畸变参数标定[J].上海交通大学学报，2008，42(10)：1136-1139.</p><p>[13] Su Jianbo.Camera calibration based on receptive fields[J].Pattern Recognition，2007，40(10)：2837-2845.</p><p>[14] DANG T，HOFFMANN C，STILLER C.Continuous stereo self-calibration by camera parameter tracking[J].IEEE Transactions on Image Processing，2009，18(7)：1536-1550.</p><p>[15] 胡占义，吴福朝.基于主动视觉摄像机标定方法[J].计算机学报，2002，25(11)：1149-1156.</p><p>[16] BAKKER T，WOUTERS H，ASSELT K V，et al.A vision based row detection system for sugar beet[J].Computers and Electronics in Agriculture，2008，60(1)：87-95.</p><p>[17] 朱嘉，李醒飞，徐颖欣.摄像机的一种主动视觉标定方法[J].光学学报，2010，30(5)：1297-1303.</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'引导','优化','视觉'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>