<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论 | 极客快訊</title><meta property="og:title" content="第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/3d1ef02f01fc4702b9118ba289a0bb1c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d2429ee.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d2429ee.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/d2429ee.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>停用词是一种删除没有信息量的单词的一种方法，该方法就是舍弃那些出现次数太多以至于没有信息量的次。主要有两种方法：使用特定语言的停用词（stopword）列表或舍弃那些出现过于频繁的单词</p><p>在scikit-learn的feature-extraction模块中提供了英语停用词的内置列表，代码示例如下：</p><p>from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS</p><p>print("Number of stop word: {}".format(len(ENGLISH_STOP_WORDS)))</p><p>print("Every 10th stopword:\n{}".format(list(ENGLISH_STOP_WORDS)[::10]))</p><p><strong>运行上述代码其结果为：</strong></p><p>Number of stop word: 318</p><p>Every 10th stopword:</p><p>['mine', 'meanwhile', 'again', 'across', 'off', 'though', 'such', 'something', 'myself', 'if', 'noone', 'call', 'been', 'interest', 'whose', 'behind', 'fifteen', 'even', 'often', 'found', 'sometime', 'done', 'alone', 'they', 'forty', 'last', 'co', 'part', 'whenever', 'somewhere', 'anything', 'anyhow']</p><p>由上述运行结果可知，删除上述列表中的停用词只能使得特征数量少了318个（即上述列表的长度），下面我们来看一下是否对性能产生影响。代码如下：</p><p>#指定stop_words=“English”将使用内置列表</p><p>#也可以扩展这个列表并传入自己的列表</p><p>from sklearn.feature_extraction.text import CountVectorizer</p><p>from sklearn.model_selection import GridSearchCV</p><p>from sklearn.linear_model import LogisticRegression</p><p>param_grid = {'C':[0.001,0.01,0.1,1,10,100]}</p><p>vect = CountVectorizer(min_df=10, stop_words="english").fit(text_train)</p><p>x_train = vect.transform(text_train)</p><p>print("x_train with stop words:\n{}".format(repr(x_train)))</p><p>grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)</p><p>grid.fit(x_train, y_train)</p><p>print("Best coss validation score is: {:.3f}".format(grid.best_score_))</p><p><strong>运行后其对应的结果如下</strong>：</p><p>x_train with stop words:</p><p>&lt;75000x31610 sparse matrix of type '&lt;class 'numpy.int64'>'</p><p>with 6538340 stored elements in Compressed Sparse Row format></p><p>Best coss validation score is: 0.713</p><p>使用停用词偶网格搜索性能有所下降，但是鉴于3万多个数据减少300多个数据不太可能对性能或解释造成很大影响，所以这个列表似乎是不值得的，固定的列表主要对小型数据很有帮助，这些数据集可能没有包含足够的信息，模型从数据本身无法判断哪些单词是停用词。</p><p>下面我们通过设置CountVectorizer的max_df选项来舍弃出现最频繁的单词，并查看其对特征数量和性能有什么影响。</p><p><strong>用tf_idf缩放数据</strong>：另一种删除没有信息量的单词（也是最常用的方法）是词频-逆向文档频率（tf-idf）方法，该方法对在某个特定文档中经常出现的术语给予很高的权重，但对于在语料库的许多文档中经常出现的术语给予的权重却不高。</p><p>如果一个单词在某个特定文档中经常出现，但是在许多文档中却不常出现，那么这个单词很可能是对文档的很好描述。scikit-learn在两个类中实现了td-idf的方法——TfidfTransform和TfidfVectorizer。前者接受CountVectorizer生成的稀疏矩阵并将其变换，后者接受文本数据并完成词袋特征提取和tf-idf变换。</p><p>由于tf-idf实际上利用了训练数据的统计学属性，所以我们将使用管道以确保网格搜索结果有效，对应代码如下：</p><p>from sklearn.feature_extraction.text import TfidfVectorizer</p><p>from sklearn.pipeline import make_pipeline</p><p>pipe = make_pipeline(TfidfVectorizer(min_df=5),LogisticRegression())</p><p>#对于高维稀疏数据，类似于LogisticRegression的线性模型通常效果最好</p><p>param_grid = {'logisticregression__C':[0.001, 0.01, 0.1, 1, 10],</p><p>'tfidfvectorizer__ngram_range':[(1,1),(1,2),(1,3)]}</p><p>#首先需要用一个字典指定要搜索的参数，字典的键是我们要调节的参数名称</p><p>grid = GridSearchCV(pipe, param_grid, cv=5)#cv=5,分层k折交叉验证中k取值为5</p><p>grid.fit(text_train, y_train)</p><p>#grid对象的行为就像一个分类器，我们可以对它调用标准的fit、predict、score方法</p><p>#调用fit时，对我们指定的所有参数组合都运行交叉验证</p><p>#拟合fit对象不仅会搜索最佳参数，还会利用得到的最佳验证性能的参数在整个训练数据集上自动拟合一个新模型</p><p>#可以用predict、score方法来访问重新训练过的模型</p><p>#我们找到的参数保存在best_params_中</p><p>#交叉验证的最佳精度保存在best_score_中</p><p>print("Best cross-validation score:{:.3f}".format(grid.best_score_))</p><p><strong>运行上述代码后结果为</strong>：</p><p>Best cross-validation score:0.723</p><p>从运行结果可以看出，使用tf-idf替代仅统计词数对性能有所提高，同时要注意的是tf-idf可以查看找到的最重要的单词，其缩放目的是找到能够区分文档的单词，但是它完全是一种无监督技术。因此，这里的“重要”不一定是我们所需要的“正面评论”和“负面评论”标签相关，所以我们还需要进行如下操作：</p><p>首先，从管道中提取TfidfVectorizer：</p><p>vectorizer = grid.best_estimator_.named_steps["tfidfvectorizer"]</p><p>x_train=vectorizer.transform(text_train)</p><p>#变换训练数据集，并找到数据集中每个特征的最大值</p><p>max_value = x_train.max(axis=0).toarray().ravel()</p><p>sorted_by_tfidf = max_value.argsort()</p><p>#获取特征名称</p><p>feature_names = np.array(vectorizer.get_feature_names())</p><p>print('Features with lowest tfidf:\n{}'.format(feature_names[sorted_by_tfidf[:20]]))</p><p>print('Features with highest tfidf:\n{}'.format(feature_names[sorted_by_tfidf[-20:]]))</p><p>#下面是找出逆向文档频率较低的词——出现次数很多，但是被认为不那么重要的单词</p><p>#这些词被保存在idf_属性中</p><p>sorted_by_idf=np.argsort(vectorizer.idf_)</p><p>print('Feature with lowest idf:\n{}'.format(feature_names[sorted_by_idf[:100]]))</p><p><strong>运行结果如下：</strong></p><div class=pgc-img><img alt="第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/3d1ef02f01fc4702b9118ba289a0bb1c><p class=pgc-img-caption>tf-idf 对应的各种特征</p></div><p><br></p><p>tf-idf较小的特征要么在很多文档里都很常用，要么就是很少使用，且仅出现在非常长的文档中。而tf-idf叫他的特征实际上对应的是特定的电影或演出中。而在lowest idf中表现出来的是对应的停用词。</p><p>接着我们来看一下这些评估分数对应的热图，对应代码如下：</p><p>scores=grid.cv_results_['mean_test_score'].reshape(-1,3).T</p><p>#获取对应热图</p><p>heatmap=mglearn.tools.heatmap(</p><p>scores,xlabel='C',ylabel='ngram_range',cmap='viridis',fmt='%.3f',</p><p>xticklabels=param_grid['logisticregression__C'],</p><p>yticklabels=param_grid['tfidfvectorizer__ngram_range']</p><p>)</p><p>plt.colorbar(heatmap)</p><div class=pgc-img><img alt="第72集 python机器学习：停用词和tf-idf缩放数据用于电影评论" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d9034926fcf543bfa4eaa0eec278cdd7><p class=pgc-img-caption>ngram_range和C参数控制下的预测分数热图</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'72','python','机器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>