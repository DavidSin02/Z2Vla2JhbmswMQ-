<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>在机器学习模型中使用XGBoost | 极客快訊</title><meta property="og:title" content="在机器学习模型中使用XGBoost - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/1536987068038afafd18f06"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="在机器学习模型中使用XGBoost"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/d333b549.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>在机器学习模型中使用XGBoost</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=在机器学习模型中使用XGBoost onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536987068038afafd18f06><p class=pgc-img-caption></p></div><p>在本教程中，我们将介绍XGBoost，这是一种机器学习算法，最近主导了应用的机器学习空间。</p><p>本文主要内容</p><ul><li>什么是XGBoost？</li><li>你为什么要用XGBoost？</li><li>促进Vis-a-vis Bagging</li><li>在Python中应用XGBoost</li><li>XGBoost的超参数</li><li>使用XGBoost时的交叉验证</li><li>在XGBoost中可视化特征的重要性</li><li>结论</li></ul><p>什么是XGBoost？</p><p>XGBoost是一个开源库，为Python，Java和C ++，R和Julia 提供梯度增强。在本教程中，我们将重点介绍Python。Gradient Boosting是一种用于分类和回归问题的机器学习技术，可以从弱决策树集合中进行预测。</p><p>你为什么要用XGBoost？</p><p>您使用此算法的主要原因是其准确性，效率和可行性。它是一个线性模型和一个树学习算法，可以在一台机器上进行并行计算。它还具有用于进行交叉验证和计算特征重要性的额外功能。以下是该模型的一些主要特征：</p><ul><li>稀疏性：它接受树booster 和线性booster 的稀疏输入。</li><li>定制：它支持定制的目标和评估功能。</li><li>DMatrix：其优化的数据结构，可提高其性能和效率。</li></ul><p>提升Vis-a-vis Bagging</p><p>Boosting是一种机器学习集成算法，它减少了将弱学习者转化为强学习者的偏差和方差。XGBoost是一个增强算法示例。另一方面，Bagging是一种技术，人们从数据中随机抽取样本，建立学习算法，找到Bagging概率。</p><p>在Python中应用XGBoost</p><p>接下来让我们展示一下如何将XGBoost应用到他们的机器学习模型中。如果您没有安装XGBoost，如果您正在使用pip包管理，可以通过在终端中键入以下命令来安装XGBoost：</p><pre>pip3 install xgboost</pre><p>我们将使用Scikit-learn附带的Boston Housing Dataset 。我们假设读者了解基本的科学包，如Pandas，Scikit-learn和numpy。</p><p>我们从sklearn.datasets加载数据集开始。然后我们导入pandas以使我们能够将Boston Housing Dataset转换为dataframe。接下来，我们使用feature_name 属性获取特征。我们使用target属性获取目标变量，在本例中为price列。</p><pre>from sklearn.datasets import load_bostonboston = load_boston()import pandas as pddata = pd.DataFrame(boston.data)data.columns = boston.feature_namesdata['PRICE'] = boston.target</pre><p>我们将使用XGBoost来预测数据集的price列。在这种情况下，数据集中的所有要素都是数字。值得注意的是，XGBoost仅适用于数值。如果我们有分类特征，我们必须使用诸如one-hot-encoding之类的技术将它们转换为数字。</p><p>接下来，我们导入XGBoost，numpy mean_squared_error，我们将其用作评估指标，以检查训练模型在测试数据集上的性能。然后，我们继续使用pandas iloc实用程序将特征变量与目标变量分开。</p><pre>import xgboost as xgbfrom sklearn.metrics import mean_squared_errorimport numpy as npX, y = data.iloc[:,:-1],data.iloc[:,-1]</pre><p>为了充分利用XGBoost的性能和效率，我们将数据集转换为DMatrix。这是通过使用XGBoost的Dmatrix函数实现的。</p><pre>data_dmatrix = xgb.DMatrix(data=X,label=y)</pre><p>XGBoost的超参数</p><p>XGBoost为我们提供了一种调整参数的方法，以获得最佳结果。基于树的学习者（如XGBoost）最常见的调整参数是：</p><p>. Booster：指定使用哪种booster 。它可以是gbtree，gblinear或者dart。gbtree和dart使用基于树模型，而gblinear使用线性函数。gbtree是默认值。</p><ul><li>silent：0表示打印运行消息。1表示静音模式。默认值为0。</li><li>nthread 是用于运行XGBoost的并行线程数。</li><li>disable_default_eval_metric是禁用默认度量标准的标志。设置为> 0以禁用。默认值为0。</li><li>num_pbuffer是预测缓冲区的大小，通常设置为训练实例的数量。缓冲区用于保存最后一个boosting 步骤的预测结果。它由XGBoost自动设置，因此无需由用户设置</li><li>num_feature是boosting中使用的特征尺寸，设置为特征的最大尺寸。它由XGBoost自动设置，因此不需要由用户设置</li></ul><p>然后，我们使用model_selection模块中的train_test_split函数将数据集分割为训练和测试集。我们将测试大小设置为20%，并将随机状态设置为100，以确保得到相同的结果。</p><pre>from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)</pre><p>下一步是创建XGBoost Regressor类的实例。参数说明如下：</p><ol><li>objective =’reg:linear’ 指定学习任务是线性的。</li><li>colsample_bytree是构造每棵树时列的子采样率。子采样将在每次boosting迭代中发生一次。该数字的范围为0到1。</li><li>learning_rate是步长shrinkage ，用于防止过度拟合。该数字的范围为0到1。</li><li>max_depth指定树的最大深度。增加此数字会使模型复杂化并增加过度拟合的可能性。默认值为6。</li><li>alpha是权重的L1正则化。增加这个数字使模型更加保守。</li><li>n_estimators 是适合增强树木的数量</li></ol><pre>xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5,alpha = 10, n_estimators = 10)</pre><p>下一步是调整回归量并使用它进行预测。</p><pre>xg_reg.fit（X_train，y_train）preds = xg_reg.predict（X_test）</pre><p>在此之后，我们计算均方根误差，以评估我们模型的性能。</p><pre>xg_reg.fit(X_train,y_train)preds = xg_reg.predict(X_test)</pre><p>使用XGBoost时的交叉验证</p><p>使用交叉验证使模型更加健壮是一种非常常见的做法。XGboost通过该cv() 函数支持K-fold验证。我们将使用它来对我们的模型应用交叉验证。</p><p>现在我们指定一个新的变量params来保存除n_estimators之外的所有参数，因为我们将使用cv()工具中的num_boost_rounds。cv()实用程序所取的参数如下所示:</p><ol><li>dtrain 是要训练的数据。</li><li>params 指定booster 参数。</li><li>nfold 是交叉验证函数中的folds 数。</li><li>num_boost_round 是boosting迭代的数量。</li><li>early_stopping_rounds 激活early stopping。CV error 需要至少每轮&lt;early_stopping_rounds>)减少才能继续。</li><li>metrics 是交叉验证中要观察的评估指标。</li><li>as_pandas如果True将返回一个pandas dataframe; 如果为false，它将返回一个numpy数组。</li></ol><pre>params = {"objective":"reg:linear",'colsample_bytree': 0.3,'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10} cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,num_boost_round=50,early_stopping_rounds=10,metrics="rmse", as_pandas=True, seed=100</pre><p>该cv_results变量将返回训练并测试每次boosting round的RMSE。最终 boosting round 指标可以如下获得：</p><pre>print((cv_results["test-rmse-mean"]).tail(1))</pre><p>在XGBoost中可视化特征重要性</p><p>您可能有兴趣查看数据集中最重要的特征。</p><p>XGBoost具有一个plot_importance()函数，使您可以查看数据集中按重要性排名的所有特征。Python代码如下：</p><pre>import matplotlib.pyplot as pltxgb.plot_importance(xg_reg)plt.rcParams['figure.figsize'] = [5, 5]plt.show()</pre><div class=pgc-img><img alt=在机器学习模型中使用XGBoost onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15369872842899e0dfafd0a><p class=pgc-img-caption></p></div><p>您可以使用上述可视化为机器学习模型选择最相关的特征。</p><p>结论</p><p>您可以使用其他技术（如网格搜索）来改进机器学习模型。Grid Search的工作原理是对estimator的指定参数值进行详尽搜索。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'机器','学习','XGBoost'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>