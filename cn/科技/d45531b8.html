<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Net2Net 知识迁移 加速神经网络的训练 | 极客快訊</title><meta property="og:title" content="Net2Net 知识迁移 加速神经网络的训练 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/15310348721318f64b5c196"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d45531b8.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d45531b8.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="Net2Net 知识迁移 加速神经网络的训练"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/d45531b8.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Net2Net 知识迁移 加速神经网络的训练</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>什么是Net2Net？</strong></p><p>Net2Net(Net to Net) 是利用知识迁移来解决大型网络的训练速度慢的问题，例如先训练一个小的网络，然后Net2Net，训练一个更大的网络，训练更大的网络时可以利用在小网络中已经训练好的权重，使得再训练大型的网络速度就变的非常快，利用小网络的权重的这个过程就是知识迁移的过程。</p><p>真实场景下的机器学习系统，最终都会变成终身学习系统(Lifelong learning system)，不断的有新数据，通过新的数据改善模型，刚开始数据量小，我们使用小的网络，可以防止过拟合并加快训练速度，但是随着数据量的增大，小网络就不足以完成复杂的问题了，这个时候我们就需要在小网络上进行扩展变成一个大网络了。</p><div class=pgc-img><img alt="Net2Net 知识迁移 加速神经网络的训练" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15310348721318f64b5c196><p class=pgc-img-caption></p></div><p>那么如何操作才能使得网络的拓扑结构改变后还能利用旧网络的权重呢？</p><p>改变拓扑结构但是不改变网络的效果，对于同样的输入有同样的输出。</p><p><strong>如何进行Net2Net？</strong></p><p>我们定义两个操作 Net2WiderNet 和 Net2DeeperNet</p><p><strong>Net2WiderNet</strong></p><p>Net2WiderNet 操作使得某一层更宽，例如让全连接层有更多的单元，让卷积层有更多的channel。</p><p>我们希望能够使得这层更宽并且变化后的结构对于同样的输入会得到相同的输出。</p><div class=pgc-img><img alt="Net2Net 知识迁移 加速神经网络的训练" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531034921058d7c1090d4d><p class=pgc-img-caption></p></div><p>如上图，对于一个全连接层来说，如果我们新增了一个节点，那么我们随机从已有节点中选择一个节点copy它的输入权重，使得这个节点的值和已有选择的节点的值相同，对于输出的节点来说，需要把前一层的节点的值求和激活，这时我们发现我们选择的那个节点的值扩大了两倍，于是我们可以把他们各自都除以2，这样我们就实现了全连接层的恒等替换。</p><p>对于一个卷积层来说，道理也类似，如果我想增加一个channel，我可以随机选一个channel然后copy它的权重(filter)，对于输出时要再进行卷积的filter而言，我们把filter中这两层的channel的权重除以2就可以，这样也在channel增加的情况实现了恒等替换。</p><p><strong>Net2DeeperNet</strong></p><p>Net2DeeperNet操作使得我们可以增加一层，例如在一个全连接层后面再加一个全连接层，在一个卷积层后面再加一个卷积层。</p><div class=pgc-img><img alt="Net2Net 知识迁移 加速神经网络的训练" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531034944175d99b408997><p class=pgc-img-caption></p></div><p>对于一个全连接层来说，我们利用一个单位矩阵做权值，添加一个和上一个全连接层维度完全相同的全连接层，把前一个全连接层的值copy过来，实现恒等映射，此时再结合Net2WiderNet，就可以使这一层再变宽。但是我们可能很难实现把这个层变瘦。</p><p>对于一个卷积层来说，我们利用一个只有中间位置是1，其它位置全是0的filter，就很轻松的实现了恒等映射。</p><p><strong>总结</strong></p><p>综上，我们通过定义两个操作，实现了从小网络到大网络的转换，但是我们这个不是一个可以泛化的方法，有一定的局限性，因为不是所有的情况都有事先恒等映射的方法。</p><p>但是对于全连接层和卷积层等来说，我们可以利用如上的方法大大加速大网络的训练，尤其是在结合终身机器学习系统或者神经网络架构搜索的方向上。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Net2Net','知识','迁移'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>