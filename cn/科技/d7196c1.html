<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ | æå®¢å¿«è¨Š</title><meta property="og:title" content="æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ - æå®¢å¿«è¨Š"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/6ee200033390f3f6b2ca"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><meta property="article:published_time" content="2020-10-29T21:05:34+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:34+08:00"><meta name=Keywords content><meta name=description content="æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ"><meta name=author content="æå®¢å¿«è¨Š"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/d7196c1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>ğŸ¤“ æå®¢å¿«è®¯ Geek Bank</a></h1><p class=description>ä¸ºä½ å¸¦æ¥æœ€å…¨çš„ç§‘æŠ€çŸ¥è¯† ğŸ§¡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>çŒœä½ å–œæ­¡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=ç§‘æŠ€>ç§‘æŠ€</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=éŠæˆ²>éŠæˆ²</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=ç§‘å­¸>ç§‘å­¸</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>ç§‘æŠ€</a></span></div><div class=post-content><div><h1>å†…å®¹å¯¼è¯»</h1><blockquote><p>MNISTåªåŒ…å«70000å¼ 28x28åƒç´ çš„æ‰‹å†™æ•°å­—çš„å•é€šé“ç°åº¦å›¾ï¼Œå¯¹äºç°åœ¨çš„ç®—åŠ›æ¥è¯´æ˜¯å¾ˆå°çš„æ•°æ®ã€‚æˆ‘å®šä¹‰ä¸€ä¸ªæ¨¡å‹è®­ç»ƒå‡½æ•°ï¼Œç›®æ ‡æ˜¯ä¸æ–­ä¼˜åŒ–æƒé‡å’Œåå·®å¾—åˆ°æœ€ä½³ç»„åˆã€‚ç°åœ¨è¾“å…¥å±‚åˆ°éšè—å±‚æˆ‘é€‰æ‹©äº†ReLuä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œä»å›¾å½¢ä¸­çœ‹å‡ºå®ƒå…·å¤‡å·¦ä¾§ç¡¬é¥±å’Œçš„ç‰¹æ€§ã€‚æ¥ä¸‹æ¥è‡ªç„¶å°±ä¼šæ€è€ƒï¼Œæƒé‡å’Œåå·®å¦‚ä½•è¿­ä»£ä¼˜åŒ–å‘¢? é¦–å…ˆæ­£å‘ä¼ æ’­è®¡ç®—å‡ºoutput_layerèŠ‚ç‚¹ï¼Œç”¨æŸå¤±å‡½æ•°è®¡ç®—ä¸€ä¸‹å’Œæ ‡æ³¨yçš„å·®è·ï¼Œæ ¹æ®æŸå¤±å¤§å°è¿”å›æ¥ä¿®æ­£æƒé‡å’Œåå·®ï¼Œè¿™ä¸ªé€šè¿‡é“¾å¼æ³•åˆ™å¯¹å¤šå±‚å¤åˆå‡½æ•°æ±‚å¯¼çš„è¿‡ç¨‹å°±æ˜¯åå‘ä¼ æ’­ï¼Œå…¶ç›®æ ‡å°±æ˜¯è¦æœ€å°åŒ–è®­ç»ƒé›†ä¸Šçš„ç´¯ç§¯è¯¯å·®ã€‚ç¬¬äºŒç§æ–¹å¼æ˜¯æ¯è·‘è®­ç»ƒé›†ä¸­çš„ä¸€æ¡æ•°æ®å°±è®¡ç®—æŸå¤±å‡½æ•°å¹¶æ›´æ–°å‚æ•°ï¼Œé€Ÿåº¦æ¯”è¾ƒå¿«ï¼Œä½†æ”¶æ•›æ€§ä¸å¤ªå¥½ï¼Œå¯èƒ½ä¼šå‡ºç°è¾ƒå¤šæ¯›åˆºåœ¨æœ€ä¼˜ç‚¹é™„è¿‘æ‘‡æ‘†ã€‚å®Œæˆæ¨¡å‹è®­ç»ƒä»£ç åå¯ä»¥å†å®šä¹‰ä¸€ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è§‚å¯Ÿæ”¶æ•›æ•ˆæœï¼Œè¿­ä»£åˆ°ä¸‰äº”åƒæ¬¡çš„æ—¶å€™å…¶å®å·²ç»å·®ä¸å¤šäº†ï¼Œåé¢çš„å‡ ä¸‡æ¬¡å­¦ä¹ ä¾ç„¶ä¼šä¸æ—¶å‡ºç°ä¸€äº›æ¯›åˆºå½±å“å‡†ç¡®ç‡ã€‚</p></blockquote><p>MNISTå°±æ˜¯æœºå™¨å­¦ä¹ çš„Hello World, æˆ–è€…è¯´å›¾ç‰‡å¤„ç†çš„Lena, æ˜¯å¿…ä¸å¯å°‘çš„ç»å…¸åˆä½“éªŒã€‚å®ƒå·²æœ‰20å¤šå¹´çš„å†å²ï¼Œä½†æ˜¯åˆ°ä»Šå¤©ä¾ç„¶é­…åŠ›ä¸å‡ï¼Œä¾ç„¶æ˜¯æœ€é«˜å¼•ç”¨çš„æ•°æ®é›†ã€‚MNISTåªåŒ…å«70000å¼ 28x28åƒç´ çš„æ‰‹å†™æ•°å­—çš„å•é€šé“ç°åº¦å›¾ï¼Œå¯¹äºç°åœ¨çš„ç®—åŠ›æ¥è¯´æ˜¯å¾ˆå°çš„æ•°æ®ã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee200033390f3f6b2ca></p><p>Denise Krebs on Flickr</p><p>ç½‘ä¸Šå¤§å¤šæ•°çš„MNISTæ•™ç¨‹ï¼ŒåŒ…æ‹¬TensorfFlowå®˜æ–¹æ•™ç¨‹å¸¦ç»™æˆ‘ä»¬çš„éƒ½æ˜¯ä¸€ç§è‡ªç„¶ä¸»ä¹‰çš„å­¦ä¹ ä½“éªŒï¼Œç»™å‡ºä»£ç ç¤ºä¾‹ç®€å•æ•™ä¼šæ­¥éª¤ï¼Œå¯¹ç€ä»£ç æ•²ä¸€ä¸‹å°±èƒ½è¿è¡Œï¼Œæ¯•ç«Ÿå‚ä¸æ„Ÿä¸å¤Ÿã€‚ä»ç»“æ„ä¸»ä¹‰çš„å­¦ä¹ æ–¹å¼æ¥çœ‹ï¼Œæˆ‘ä»¬åº”è¯¥è‡³å°‘å°è¯•ä¸€æ¬¡ä¸ç”¨ä»»ä½•æ·±åº¦å­¦ä¹ çš„ç°æˆæ¡†æ¶ï¼Œçº¯æ‰‹å·¥ä»é›¶å¼€å§‹å®ç°ä¸€æ¬¡ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”æ‰“å¼€å…¶ä¸­çš„é»‘ç›’ï¼Œä»¥å¯è§†åŒ–çš„å‘ˆç°æ–¹å¼å½¢è±¡ç†è§£ç¥ç»ç½‘ç»œå¦‚ä½•å·¥ä½œï¼Œè¿™å°±æ˜¯æˆ‘å†™æ­¤æ–‡çš„ç›®çš„ã€‚</p><p><strong>æ•°æ®å‡†å¤‡ (Data Preparation)</strong></p><p>MNISTæ•°æ®é›†ä¸­Train datasetæœ‰60000å¼ å›¾ç‰‡ä¸ç›¸åº”çš„æ ‡æ³¨ï¼Œå…¶ä¸­55000å¼ è®­ç»ƒé›†ï¼Œ5000å¼ éªŒè¯é›†(Validation)ï¼ŒTest datasetæœ‰10000å¼ è®­ç»ƒé›†ï¼Œä¸‹è½½å®Œè¿™å››ä¸ªæ–‡ä»¶åæˆ‘ä¿å­˜åˆ°MNIST-dataç›®å½•ä¸‹ã€‚</p><blockquote><p>train-images-idx3-ubyte.gz: training set images (9912422 bytes)<br>train-labels-idx1-ubyte.gz: training set labels (28881 bytes)<br>t10k-images-idx3-ubyte.gz: test set images (1648877 bytes)<br>t10k-labels-idx1-ubyte.gz: test set labels (4542 bytes)</p></blockquote><p>æ•°æ®é›†å°±æ˜¯è¿™ä¹ˆå››ä¸ªæ–‡ä»¶ï¼Œéƒ½æ˜¯ç‰¹æ®Šçš„Binaryæ ¼å¼ã€‚è§£æèµ·æ¥è´¹ç‚¹åŠŸå¤«ï¼Œä¸è¿‡TensorFlowå·²å°è£…å¥½äº†ä¾¿åˆ©çš„æ¥å£ - input_data.read_data_setsã€‚è™½ç„¶è¿™æ¬¡æˆ‘ä¸ç”¨TensorFlowæ¡†æ¶çš„ç¥ç»ç½‘ç»œï¼Œä½†æ˜¯è§£ææ•°æ®éƒ¨åˆ†å€Ÿç”¨ä¸€ä¸‹æ— å¦¨ã€‚è¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨å°è¯•ä¸‹è½½æ•°æ®é›†åˆ°æŒ‡å®šç›®å½•ä¸­ï¼Œä¸è¿‡å¼ºçƒˆå»ºè®®è‡ªå·±æ‰‹å·¥ä¸‹è½½å¥½è¿™å››ä¸ªæ–‡ä»¶ï¼Œç”±äºä¸å¯æè¿°çš„åŸå› ï¼Œç”¨è¿™ä¸ªæ–¹æ³•ç›´æ¥ä¸‹è½½æ•°æ®åŸºæœ¬éƒ½æ˜¯ä»¥time outå¤±è´¥å‘Šç»ˆã€‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æŒ‡å®šçš„æ•°æ®é›†å­˜æ”¾è·¯å¾„ï¼Œç¬¬äºŒä¸ªå‚æ•°å†³å®šæ˜¯å¦ä»¥ç‹¬çƒ­é”®(one-hot)å½¢å¼è¯»å–æ ‡ç­¾ï¼Œå¦‚æœè®¾ä¸ºTrueåˆ™ä»¥10ç»´å‘é‡å½¢å¼ä»£è¡¨ä¸€ä¸ªæ•°å­—ã€‚</p><blockquote><p>mndata = input_data.read_data_sets("MNIST-data/", one_hot=True)</p></blockquote><p>åˆ†åˆ«è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›¾ç‰‡å’Œæ ‡æ³¨</p><blockquote><p>X_train=mndata.train.images # training set<br>y_train=mndata.train.labels<br>X_test=mndata.test.images # testing set<br>y_test=mndata.test.labels</p></blockquote><p>ç„¶åå†™ä¸€ä¸ªç”»å›¾çš„å‡½æ•°ï¼Œè¯»å–çŸ©é˜µæ•°æ®åœ¨è¡¨æ ¼ä¸­å±•ç¤ºï¼Œä»…å±•ç¤ºé0æ•°å­—ä¸”ä¿ç•™ä¸¤ä½å°æ•°ã€‚</p><blockquote><p># visualize grid data of a matrix, zero cell shown as empty<br>def plt_grid(data):<br>fig, ax = plt.subplots()<br>fig.set_size_inches(30,30)<br>width, height = data.shape</p><p>#imshow portion<br>imshow_data = np.random.rand(width, height)<br>ax.imshow(imshow_data, cmap=plt.cm.Pastel1, interpolation='nearest')</p><p>for x in range(0, height):<br>for y in range(0, width):<br>if (data[y][x]>0):<br>ax.text(x, y, np.round(data[y][x],2), va='center', ha='center', fontsize=20)<br>plt.show()</p></blockquote><p>éšä¾¿æ‰¾ä¸ªå‰åˆ©æ•°å­—88ä½œä¸ºindex, ä»è®­ç»ƒé›†ä¸­æŠ½ä¸€å¼ å›¾ç‰‡æ‰“å°åŸå§‹æ•°æ®çœ‹çœ‹è¿™ä¸ª28x28çš„çŸ©é˜µé‡Œåˆ°åº•å­˜æ”¾äº†ä»€ä¹ˆ</p><blockquote><p>plt_grid(X_train[88].reshape(28,28))</p></blockquote><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25df9767538></p><p>æ•°å­—3</p><p>é0çš„æ•°å€¼æœ¬èº«å°±å·²ç»èƒ½çœ‹åˆ°æ•°å­—çš„å½¢çŠ¶äº†ï¼Œæ˜¯ä¸ª3. æ•°å€¼è¶Šæ¥è¿‘1è¡¨ç¤ºé¢œè‰²è¶Šç™½ï¼Œè¾¹ç¼˜çš„é¢œè‰²åº”è¯¥æ˜¯æ¯”è¾ƒç°çš„ï¼Œè€ŒèƒŒæ™¯æ•°å€¼ä¸º0è‡ªç„¶å°±æ˜¯é»‘è‰²ã€‚</p><p>æ‰“å°ç›¸åº”çš„æ ‡ç­¾å‡ºæ¥ä¹Ÿæ˜¯3: [ 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]</p><p>ä¸‹é¢æˆ‘å†ç›´æ¥æŠŠå›¾ç‰‡æŠ½å‡ºæ¥æ‰“å°å¯¹æ¯”ä¸€ä¸‹ï¼Œæœä¸å…¶ç„¶, å’Œä¸Šå›¾é•¿çš„ä¸€æ¨¡ä¸€æ ·ã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25e98f04787></p><p><strong>ç½‘ç»œæ¶æ„ (Network Layouts)</strong></p><p>æ•°æ®å‡†å¤‡å¥½åå°±å¼€å§‹è®¾è®¡ç¥ç»ç½‘ç»œäº†, ç®€å•ä¸€ç‚¹å°±ä¸‰å±‚: input layer, hidden layer, output layer</p><p>input layer(è¾“å…¥å±‚)çš„èŠ‚ç‚¹å°±æ˜¯è¦å–‚ç»™ç¥ç»ç½‘ç»œçš„åƒç´ å€¼ï¼Œå…±784ä¸ªèŠ‚ç‚¹ã€‚</p><p>hidden layer(éšè—å±‚)å¯ä»¥è®©ç½‘ç»œåœ¨æŠ½è±¡å±‚æ¬¡ä¸Šå­¦ä¹ ç‰¹å¾ï¼Œè™½ç„¶æˆ‘åªæ”¾ä¸€å±‚ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥æœ‰å¤šå±‚ã€‚å°‘é‡éšè—å±‚ä¼šå¾—åˆ°æµ…å±‚ç¥ç»ç½‘ç»œSNNï¼Œéšè—å±‚å¾ˆå¤šæ—¶å°±æ˜¯æ·±å±‚ç¥ç»ç½‘ç»œDNNã€‚ç†è®ºä¸Šï¼Œå•éšè—å±‚ç¥ç»ç½‘ç»œä¹Ÿå¯ä»¥é€¼è¿‘ä»»ä½•è¿ç»­å‡½æ•°ï¼Œåªè¦ç¥ç»å…ƒæ•°é‡å¤Ÿå¤šã€‚å¦‚æœå¢åŠ éšè—å±‚æˆ–è€…éšè—å±‚ç¥ç»å…ƒçš„æ•°é‡ï¼Œç¥ç»ç½‘ç»œçš„å®¹é‡ä¼šå˜å¤§ï¼Œç©ºé—´è¡¨è¾¾èƒ½åŠ›ä¼šå˜å¼ºï¼Œä½†å¦‚æœå¤ªå¤šçš„è¯ä¹Ÿå®¹æ˜“è¿‡æ‹Ÿåˆã€‚å…ˆæš‚å®š15ä¸ªèŠ‚ç‚¹å§ã€‚</p><p>output layer(è¾“å‡ºå±‚)æœ‰10ä¸ªèŠ‚ç‚¹ï¼Œå› ä¸ºå›¾ç‰‡è¦åˆ†ç±»æ˜ å°„åˆ°åä¸ªæ•°å­—ä¸Šã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee50002bef9200dccef></p><p>Neural Network and Deep Learning</p><p><strong>æƒé‡å’Œåå·® (Weights and Bias)</strong></p><p>ä¸Šå›¾ä¸­ä¸¤ä¸ªç¥ç»å…ƒä¹‹é—´çš„æ¯ä¸€æ¡è¿çº¿éƒ½ä»£è¡¨ä¸€ä¸ªæƒé‡å€¼ï¼Œç¥ç»ç½‘ç»œé€šè¿‡ä¸æ–­è°ƒæ•´æƒé‡æ¥é€¼è¿‘ç»“æœã€‚é¦–å…ˆæŠŠä¸€ç»„æƒé‡åº”ç”¨åœ¨input layerçš„èŠ‚ç‚¹ä¸Šï¼ŒåŠ ä¸Šåå·®å€¼åå¾—åˆ°hidden layerçš„èŠ‚ç‚¹ï¼Œç„¶åå¯¹hidden layerçš„èŠ‚ç‚¹åº”ç”¨å¦ä¸€ç»„æƒé‡ï¼ŒåŠ ä¸Šåå·®å€¼åæœ€ç»ˆå¾—åˆ°output layerçš„èŠ‚ç‚¹ã€‚</p><p>å…ˆè®¾ç½®ä¸€ä¸‹ä¸¤ç»„æƒé‡å’Œåå·®çš„åˆå§‹å€¼ï¼Œåé¢å†çœ‹å¦‚ä½•æ›´æ–°è¿™äº›æƒé‡å’Œåå·®ã€‚æˆ‘å®šä¹‰ä¸€ä¸ªæ¨¡å‹è®­ç»ƒå‡½æ•°ï¼Œç›®æ ‡æ˜¯ä¸æ–­ä¼˜åŒ–æƒé‡å’Œåå·®å¾—åˆ°æœ€ä½³ç»„åˆã€‚ç¬¬ä¸€ç»„æƒé‡æ˜¯ä¸€ä¸ª784 x 15çš„çŸ©é˜µï¼Œç¬¬äºŒç»„æƒé‡æ˜¯ä¸€ä¸ª15 x 10çš„çŸ©é˜µï¼Œç”¨éšæœºå‡½æ•°ç”Ÿæˆä¸€å †0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°å€¼ï¼Œåå·®å°±å…ˆéƒ½è®¾ä¸º0. ä¸¤ç»„æƒé‡éƒ½é™¤ä»¥5æ˜¯æˆ‘åœ¨è°ƒå‚è¿‡ç¨‹ä¸­å‘ç°åˆå§‹æƒé‡æ•°å€¼è¦æ›´å°ä¸€äº›æ•ˆæœæ¯”è¾ƒå¥½ï¼Œéšä¾¿æ‹çš„ä¸€ä¸ªæ•°ã€‚</p><blockquote><p>input_layer_size = 28 * 28<br>hidden_layer_size = 15<br>output_layer_size = 10</p><p>def train_model():<br># init weights and bias<br>np.random.seed(1)<br>W1 = np.random.random([input_layer_size, hidden_layer_size])/5 # 784 x 15<br>b1 = np.zeros((1, hidden_layer_size))<br>W2 = np.random.random([hidden_layer_size, output_layer_size])/5 # 15 x 10<br>b2 = np.zeros((1, output_layer_size))</p></blockquote><p>ç°åœ¨å¯ä»¥æŠŠæƒé‡W1ä¹Ÿæ‰“å°å‡ºæ¥çœ‹çœ‹ï¼Œæˆ‘åªæ‹¿è¾“å…¥å±‚ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å’Œéšè—å±‚ç¬¬ä¸€ä¸ªç®€å•ä¹‹é—´çš„ä¸€æ ¹çº¿æ¥æŸ¥çœ‹ã€‚å¯ä»¥çœ‹åˆ°éƒ½æ˜¯éå¸¸å¾®å°çš„éšæœºæ•°å­—ï¼Œæœ€å¤§ä¸ä¼šè¶…è¿‡0.2</p><blockquote><p>plt_grid(W1.T[0].reshape(28,28))</p></blockquote><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee400030db6324f2555></p><p>ç¬¬ä¸€æ¡çº¿æƒé‡</p><p>åæ¥åœ¨è®­ç»ƒ50000æ¬¡ä¹‹åå¯ä»¥ç”¨pltå°†åä¸ªæ•°å­—æƒé‡çš„çƒ­åŠ›å›¾å¯è§†åŒ–å‘ˆç°:</p><blockquote><p>for i in range(10):<br>plt.subplot(2, 5, i+1)<br>weight = W1[:,i]<br>plt.title(i)<br>plt.imshow(weight.reshape([28,28]), cmap=plt.get_cmap('seismic'))<br>frame1 = plt.gca()<br>frame1.axes.get_xaxis().set_visible(False)<br>frame1.axes.get_yaxis().set_visible(False)</p></blockquote><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee2000333910cb8c03c></p><p>Weight Heatmap</p><p><strong>æ¿€æ´»å‡½æ•° (Activation Function)</strong></p><p>Montreal å¤§å­¦çš„ Bengio æ•™æˆåœ¨ ICML 2016 ä¸­ç»™å‡ºäº†æ¿€æ´»å‡½æ•°å®šä¹‰: æ¿€æ´»å‡½æ•°æ˜¯æ˜ å°„ h:Râ†’Rï¼Œä¸”å‡ ä¹å¤„å¤„å¯å¯¼ã€‚</p><p>å¼•å…¥æ¿€æ´»å‡½æ•°æ˜¯ä¸ºäº†å°†æƒå€¼è½¬åŒ–ä¸ºåˆ†ç±»ç»“æœï¼Œæœ‰å¤šé‡é€‰æ‹©: Sigmoid(Så‹), Tanh(åŒåˆ‡æ­£åˆ‡), ReLu(åªä¿ç•™éé›¶), Softmax(å½’ä¸€åŒ–) etc. è¿™äº›å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°å¤šæ•°éƒ½æ˜¯éçº¿æ€§çš„ï¼Œä¸ºäº†å¼¥è¡¥çº¿æ€§å‡½æ•°åŒºåˆ†åº¦ä¸å¤Ÿå¥½çš„çŸ­æ¿ï¼Œè€Œä¸”æ¿€æ´»å‡½æ•°è¦èƒ½ä¿è¯æ•°æ®è¾“å…¥ä¸è¾“å‡ºä¹Ÿæ˜¯å¯å¾®çš„ã€‚æœ¬æ¥æˆ‘å°è¯•ç”¨Sigmoidä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œä½†æ˜¯å¯èƒ½ç”±äºæˆ‘çš„å®ç°æ–¹å¼å¯¼è‡´æ•ˆæœä¸å¥½ï¼Œå‡†ç¡®ç‡åˆ°70%å¤šæˆ‘å°±ä¼˜åŒ–ä¸ä¸‹å»äº†ï¼Œå¯èƒ½å®ƒæœ¬èº«ç”±äºè½¯é¥±å’Œæ€§ä¹Ÿå®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œåªå¥½æš‚æ—¶æ”¾å¼ƒã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee400030db7c8a5f18f></p><p>ä¸Šé¢è¿™å¥è¯æˆ‘å†è§£é‡Šä¸€ä¸‹ï¼ŒSigmoidå°±æ˜¯å¤„å¤„å¯å¯¼çš„Så‹æ›²çº¿ï¼Œä¸”ä¸¤ä¾§å¯¼æ•°è¶‹è¿‘äº0ï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªè½¯é¥±å’Œå‡½æ•°ï¼Œè€Œä¸”å·¦å³ä¸¤ä¾§éƒ½æ˜¯è½¯é¥±å’Œã€‚ä¸€æ—¦è½å…¥äº†è½¯é¥±å’ŒåŒºf'(x)å°±æ¥è¿‘äº0äº†ï¼Œæ— æ³•å†ç»§ç»­ä¼ é€’æ¢¯åº¦ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æ¢¯åº¦æ¶ˆå¤±ã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b641874e0002></p><p>Sigmoidå›¾å½¢</p><p>ç°åœ¨è¾“å…¥å±‚åˆ°éšè—å±‚æˆ‘é€‰æ‹©äº†ReLuä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œä»å›¾å½¢ä¸­çœ‹å‡ºå®ƒå…·å¤‡å·¦ä¾§ç¡¬é¥±å’Œçš„ç‰¹æ€§ã€‚</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee50002befac5b3752a></p><p>ReLu Formula</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25f8187a1ea></p><p>ReLu å›¾å½¢</p><p>ä»£ç å®ç°å¦‚ä¸‹</p><blockquote><p>def relu(x):<br>return np.maximum(x, 0)</p></blockquote><p>ä»éšè—å±‚åˆ°è¾“å‡ºå±‚æˆ‘é€‰æ‹©äº†softmaxä½œä¸ºæ¿€æ´»å‡½æ•°</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b6427c984347></p><p>Softmax Formula</p><p>åºåˆ—ä¸­æœ€å¤§çš„é‚£ä¸ªæ•°æ˜ å°„çš„åˆ†é‡é€¼è¿‘äº 1, å…¶ä»–å°±é€¼è¿‘äº 0ï¼Œéå¸¸é€‚åˆå¤šåˆ†ç±»é—®é¢˜ã€‚å–æŒ‡æ•°æ˜¯ä¸ºäº†è®©é©¬å¤ªæ•ˆåº”å‡¸æ˜¾ï¼Œå¤§æ•°è¿›ä¸€æ­¥æ”¾å¤§ï¼ŒåŒæ—¶ä¹Ÿæ»¡è¶³äº†å¯å¯¼å‡½æ•°çš„éœ€æ±‚ã€‚</p><p>Softmaxä»£ç å®ç°å¦‚ä¸‹ (å¦‚æœå‡ºç°overflowçš„è¯å¯ä»¥å‚è€ƒscikit-learnæºç çš„å®ç°æ–¹å¼)</p><blockquote><p>def softmax(x):<br>e_x = np.exp(x - np.max(x))<br>return e_x / e_x.sum()</p></blockquote><p><strong>æ­£å‘ä¼ æ’­(Forward Propagation)</strong></p><p>æ­£å‘ä¼ æ’­çš„è®¡ç®—å°±æ˜¯æŠŠè¾“å…¥å±‚åˆ°éšè—å±‚çš„èŠ‚ç‚¹ä¸æƒé‡å’Œåå·®ç»“åˆï¼Œè®¡ç®—å‡ºè¾“å‡ºå±‚èŠ‚ç‚¹çš„è¿‡ç¨‹ã€‚<br>å¯¹äºè¿™ä¸ªä¸‰å±‚ç½‘ç»œï¼Œå‡å®šxæ˜¯åŒ…å«ä¸€ä¸ªå•ä¸€è®­ç»ƒæ ·æœ¬çš„åˆ—å‘é‡ã€‚åˆ™å‘é‡åŒ–çš„æ­£å‘ä¼ æ’­æ­¥éª¤å¦‚ä¸‹ï¼š(è¿™ä¸ªå›¾æˆ‘ç”»å®Œä»¥åæ„Ÿè§‰ç”¨æ›´ä¸¥è°¨çš„æ–¹å¼æ¥æè¿°çš„è¯ï¼Œå››ä¸ªæ ‡æ³¨åº”è¯¥æ˜¯éšè—å±‚çš„è¾“å…¥ï¼Œéšè—å±‚çš„è¾“å‡ºï¼Œè¾“å‡ºå±‚çš„è¾“å…¥ï¼Œè¾“å‡ºå±‚çš„è¾“å…¥ï¼Œä½†æ‡’å¾—æ”¹å›¾äº†)</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee200033392be486202></p><p>Forward Propagation</p><p>å‡è®¾æˆ‘è¦è®­ç»ƒ50000æ¬¡ï¼Œtrain_modelæ–¹æ³•ä¸­åŠ å…¥æ­£å‘ä¼ æ’­çš„å¾ªç¯ä»£ç å®ç°å¦‚ä¸‹</p><blockquote><p>batch= 50000<br>for i in range(0, batch):<br>X = X_train[i]<br>y = y_train[i]</p><p>input_layer = X.dot(W1)<br>hidden_layer = relu(input_layer + b1)<br>output_layer = np.dot(hidden_layer, W2) + b2<br>output_probs = softmax(output_layer)</p></blockquote><p>æˆ‘è¿˜æ˜¯ç»§ç»­æ‹¿indexä¸º88çš„æ•°å­—3å›¾ç‰‡ä¸ºä¾‹çœ‹çœ‹å„å±‚æ˜¯ä»€ä¹ˆæ•°å­—</p><p>input_layeræ˜¯è¾“å…¥å±‚çŸ©é˜µä¸æƒé‡1çŸ©é˜µç›¸ä¹˜å¾—åˆ°15ç»´å‘é‡</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b643db70a946></p><p>input_layer</p><p>hidden_layeræ˜¯ä¸Šä¸€å±‚åŠ ä¸Šåå·®1ä½œä¸ºReLuçš„è¾“å…¥è®¡ç®—å‡ºæ¥çš„, ç»´åº¦åŒä¸Š</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee10003f4e8682c1c90></p><p>Hidden Layer</p><p>æ­¤æ—¶æƒé‡2æ˜¯15x10çš„çŸ©é˜µ</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee60001d260fa9e6fff></p><p>W2</p><p>æƒé‡2å’Œhidden_layerçŸ©é˜µç›¸ä¹˜åŠ ä¸Šåå·®2å¾—åˆ°åç»´å‘é‡output_layer, è¿™é‡Œæœ€å¤§çš„æ•°å­—æ˜¯ç¬¬ä¹ä½çš„20.09</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee2000333933ca14ae4></p><p>output_layer</p><p>output_layerä½œä¸ºsoftmaxè¾“å…¥è®¡ç®—åå¾—åˆ°æœ€ç»ˆç»“æœoutput_probs, ç¬¬ä¹ä½è¢«è½¬æˆäº†éå¸¸æ¥è¿‘1çš„ä¸€ä¸ªå°æ•°ï¼Œä¹Ÿæ˜¯åºåˆ—ä¸­æœ€å¤§çš„æ•°å­—ã€‚è¿™æ˜¯è®­ç»ƒä¹‹åˆçš„æ•°å€¼ï¼Œå®é™…ä¸Šæœ€å¤§çš„æ•°å­—åº”è¯¥åœ¨ç¬¬å››ä½ï¼Œæ‰€ä»¥æ­¤æ—¶è¯¯å·®æ¯”è¾ƒå¤§ã€‚å¤§æ¦‚åœ¨å­¦ä¹ 3000æ¬¡ä¹‹åå·²ç»èƒ½è¾ƒå¤§æ¦‚ç‡çš„åœ¨ç¬¬å››ä½é€¼è¿‘1</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee50002befb6df58064></p><p>output_probs</p><p><strong>åå‘ä¼ æ’­ (Backward Propagation)</strong></p><p>æ¥ä¸‹æ¥è‡ªç„¶å°±ä¼šæ€è€ƒï¼Œæƒé‡å’Œåå·®å¦‚ä½•è¿­ä»£ä¼˜åŒ–å‘¢? é¦–å…ˆæ­£å‘ä¼ æ’­è®¡ç®—å‡ºoutput_layerèŠ‚ç‚¹ï¼Œç”¨æŸå¤±å‡½æ•°è®¡ç®—ä¸€ä¸‹å’Œæ ‡æ³¨yçš„å·®è·ï¼Œæ ¹æ®æŸå¤±å¤§å°è¿”å›æ¥ä¿®æ­£æƒé‡å’Œåå·®ï¼Œè¿™ä¸ªé€šè¿‡é“¾å¼æ³•åˆ™å¯¹å¤šå±‚å¤åˆå‡½æ•°æ±‚å¯¼çš„è¿‡ç¨‹å°±æ˜¯åå‘ä¼ æ’­ï¼Œå…¶ç›®æ ‡å°±æ˜¯è¦æœ€å°åŒ–è®­ç»ƒé›†ä¸Šçš„ç´¯ç§¯è¯¯å·®ã€‚</p><p>åœ¨å‰æ–‡"<a target=_blank>äººå·¥ç¥ç»å…ƒæ˜¯å¦‚ä½•æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒçš„</a>"ä¸­æˆ‘æåˆ°æœºå™¨å­¦ä¹ éœ€è¦ä¸æ–­è°ƒæ•´weightå’Œbiasæ¥é€æ­¥é€¼è¿‘é¢„æœŸçš„è¾“å‡ºå€¼ï¼Œ<strong>è€Œä¸”å¿…é¡»ä¿è¯weightå’Œbiasçš„å¾®å°å˜åŒ–ä¹Ÿåªä¼šå¸¦æ¥è¾“å‡ºå€¼çš„å¾®å°å˜åŒ–.</strong></p><p>è°ƒå‚çš„è¿‡ç¨‹å°±åƒæ‰“é«˜å°”å¤«ä¸€æ ·ï¼Œç›®æ ‡æ˜¯ä»¥æœ€å°‘çš„æ†æ•°å°†çƒæ‰“è¿›æ´ï¼Œå¦‚æœè¿‡äºè°¨æ…å¯èƒ½è€—è´¹çš„æ†æ•°å¤ªå¤šï¼Œå¦‚æœå¤ªè¿‡æ¿€è¿›å¯èƒ½çƒè¢«æ‰“è¿›äº†æ²™æ± æˆ–è€…æ°´å‘ï¼Œæ¬²é€Ÿåˆ™ä¸è¾¾ã€‚æ¯ä¸€æ†éƒ½è¦è®©çƒç¦»çƒæ´æ›´è¿‘ï¼Œè¿›å…¥æœå²­çš„æ—¶å€™è¿˜è¦ç¡®ä¿ä¸è¦ç”¨åŠ›è¿‡åº¦è®©çƒè·‘è¿‡å¤´äº†ã€‚(è§ä¸‹æ–‡<strong>å­¦ä¹ ç‡</strong>)</p><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b6445aa7d4e4></p><p>åœ¨train_modelæ–¹æ³•ä¸­ç»§ç»­å®ç°è¿™ä¸ªé€†å‘è¿‡ç¨‹, è®¡ç®—è¾“å‡ºå±‚çš„error, å†å°†æ­¤erroré€†å‘ä¼ æ’­åˆ°éšè—å±‚ï¼Œæœ€åæ ¹æ®éšè—å±‚çš„erroræ¥å¯¹è¿æ¥æƒé‡ä¸åå·®è¿›è¡Œè°ƒæ•´ï¼Œè¿­ä»£å¾ªç¯ä¸‹å»ä¸æ–­æ›´æ–°è®©erroræ”¶æ•›ã€‚æ ¸å¿ƒé€»è¾‘æ˜¯æ¢¯åº¦ä¸‹é™çš„ç®—æ³•ï¼Œè¿™é‡Œæœ‰ä¸‰ç§é€‰æ‹©: æ‰¹é‡æ¢¯åº¦ä¸‹é™(Batch Gradient Descent)ï¼Œéšæœºæ¢¯åº¦ä¸‹é™(Stochastic Gradient Descent)å’Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ã€‚</p><p>ç¬¬ä¸€ç§æ–¹å¼éå†å®Œæ•´è®­ç»ƒé›†ç®—å‡ºä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œç„¶åæ›´æ–°å‚æ•°å†è·‘ä¸€æ¬¡å®Œæ•´è®­ç»ƒé›†ï¼Œå¦‚æ­¤è¿­ä»£å¾ªç¯ï¼Œæ‰€ä»¥è®¡ç®—é‡å¾ˆææ€–ã€‚ç¬¬äºŒç§æ–¹å¼æ˜¯æ¯è·‘è®­ç»ƒé›†ä¸­çš„ä¸€æ¡æ•°æ®å°±è®¡ç®—æŸå¤±å‡½æ•°å¹¶æ›´æ–°å‚æ•°ï¼Œé€Ÿåº¦æ¯”è¾ƒå¿«ï¼Œä½†æ”¶æ•›æ€§ä¸å¤ªå¥½ï¼Œå¯èƒ½ä¼šå‡ºç°è¾ƒå¤šæ¯›åˆºåœ¨æœ€ä¼˜ç‚¹é™„è¿‘æ‘‡æ‘†ã€‚æœ€åä¸€ä¸ªæ˜¯å‰ä¸¤è€…çš„è¿™ç§æ–¹æ¡ˆï¼Œæ—¢ä¸æ˜¯è·‘å…¨é‡æ•°æ®è€Œä¸æ˜¯è·‘å•ä¸ªæ•°æ®ï¼Œè€Œæ˜¯æ‹¿ä¸€å°æ‰¹æ•°æ®æ¥è®¡ç®—æŸå¤±å‡½æ•°æ›´æ–°å‚æ•°ã€‚æˆ‘å…ˆç”¨SGDæ¥è·‘ï¼Œåé¢å¯ä»¥é€šè¿‡å›¾åƒçœ‹åˆ°æ¯›åˆºçš„é—®é¢˜ã€‚</p><p>ç”¨æ•°å­¦è¯­è¨€æ¥æè¿°ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ ¸å¿ƒæ˜¯<strong>å¤šå…ƒå‡½æ•°æ±‚å¾®</strong>ï¼Œé’ˆå¯¹æ¯ä¸€ä¸ªå˜é‡éƒ½åˆ†åˆ«æ±‚å¾®ï¼Œæ¯ä¸€æ¬¡è¿­ä»£éƒ½ç”¨å¤šå…ƒå‡½æ•°å‡å»å¤šå…ƒå‡½æ•°çš„å¾®åˆ†ä¸å­¦ä¹ ç‡çš„ä¹˜ç§¯ã€‚ä¸‹é¢ä»£ç ä¸­ç¬¬ä¸€è¡Œè®¾ç½®çš„å‚æ•°æ˜¯å­¦ä¹ ç‡ï¼Œè¿™ä¸ªå‚æ•°æ˜¯è¦åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼Œå­¦ä¹ ç‡å¤ªå¤§åˆ™è®­ç»ƒçš„å¿«ä½†ç²¾åº¦ä¸å¤Ÿ(æ¯æ¬¡å‡»çƒéƒ½å¾ˆå¤§åŠ›)ï¼Œå­¦ä¹ ç‡å¤ªå°åˆ™æå‡ç²¾åº¦ä½†è¿‡äºè€—è´¹æ—¶é—´(æ¯æ¬¡å‡»çƒéƒ½å°å¿ƒç¿¼ç¿¼è½»è½»æŒ¥æ†ä¿è¯ç²¾å‡†)ï¼Œè¿™é‡Œè®¾ç½®çš„å­¦ä¹ ç‡æ˜¯å›ºå®šçš„ï¼Œè¿™æ ·çš„é™æ€è®¾ç½®æ˜¾ç„¶ä¸ä¼šæ˜¯æœ€ä½³é€‰æ‹©ï¼Œä¸è¿‡å¤„äºå­¦ä¹ ç›®çš„ä¹Ÿå¤Ÿäº†ã€‚</p><blockquote><p>learning_rate = .01<br>reg_lambda = .01</p><p>output_error = (output_probs - y) / output_probs.shape[0]</p><p>hidden_error = np.dot(output_error, W2.T)<br>hidden_error[hidden_layer &lt;= 0] = 0</p><p># gradient layer2 weights and bias<br>g2_weights = np.dot(hidden_layer.T, output_error)<br>g2_bias = np.sum(output_error, axis = 0, keepdims = True)</p><p># gradient layer1 weights and bias<br>g1_weights = np.dot(X.reshape(input_layer_size,1), hidden_error)<br>g1_bias = np.sum(hidden_error, axis = 0, keepdims = True)</p><p># gradient descent parameter update<br>W1 -= learning_rate * g1_weights<br>b1 -= learning_rate * g1_bias<br>W2 -= learning_rate * g2_weights<br>b2 -= learning_rate * g2_bias</p></blockquote><p><strong>æ­£åˆ™åŒ–å¹²æ‰° (Regularization Terms)</strong></p><p>ä¸ºäº†è®©æ‹Ÿåˆæ•ˆæœæ›´å¥½å¯ä»¥åœ¨erroråé¢åŠ å…¥æ­£åˆ™å¹²æ‰°é¡¹, è®©æ¨¡å‹å’Œæ ·æœ¬ä¸è¦å®Œå…¨æ‹Ÿåˆï¼Œå½“å‡ºç°æ¬ æ‹Ÿæ—¶å¹²æ‰°é¡¹çš„å½±å“è¦å°ï¼Œå½“å‡ºç°è¿‡æ‹Ÿæ—¶å¹²æ‰°é¡¹çš„å½±å“è¦å¤§ã€‚reg_lambdaå°±æ˜¯è®¾ç½®çš„æ‹Ÿåˆå‚æ•°ï¼Œæ‰€ä»¥å¯ä»¥åœ¨æ›´æ–°wå’Œbä¹‹å‰å†åŠ ä¸¤è¡Œä»£ç ã€‚</p><blockquote><p># add regularization terms<br>g2_weights += reg_lambda * W2<br>g1_weights += reg_lambda * W1</p></blockquote><p><strong>é¢„æµ‹å‡½æ•°</strong></p><p>è¿™ä¸ªé€»è¾‘å¾ˆç®€å•ï¼Œå’Œè®­ç»ƒé›†çš„æ­£å‘ä¼ æ’­å®Œå…¨ä¸€æ ·ï¼Œåªä¸è¿‡è¾“å…¥å‚æ•°æ¢æˆæµ‹è¯•é›†æ•°æ®ï¼Œä»£å…¥å·²ç»è®­ç»ƒå¥½çš„æƒé‡å’Œåå·®ï¼Œç»Ÿè®¡æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹ã€‚</p><blockquote><p>input_layer = np.dot(X_test[:10000], W1)<br>hidden_layer = relu(input_layer + b1)<br>scores = np.dot(hidden_layer, W2) + b2<br>probs = softmax(scores)<br>print ('Test accuracy: {0}%'.format(accuracy(probs, y_test[:10000])))</p></blockquote><p>å®Œæˆæ¨¡å‹è®­ç»ƒä»£ç åå¯ä»¥å†å®šä¹‰ä¸€ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è§‚å¯Ÿæ”¶æ•›æ•ˆæœï¼Œè¿­ä»£åˆ°ä¸‰äº”åƒæ¬¡çš„æ—¶å€™å…¶å®å·²ç»å·®ä¸å¤šäº†ï¼Œåé¢çš„å‡ ä¸‡æ¬¡å­¦ä¹ ä¾ç„¶ä¼šä¸æ—¶å‡ºç°ä¸€äº›æ¯›åˆºå½±å“å‡†ç¡®ç‡ã€‚</p><blockquote><p>def cross_entropy_loss(probs, y_onehot):<br>indices = np.argmax(y_onehot, axis = 0).astype(int)<br>predicted_prob = probs[np.arange(len(probs)), indices]<br>log_preds = np.log(predicted_prob)<br>loss = -1.0 * np.sum(log_preds) / len(log_preds)<br>return loss</p></blockquote><p><img alt=æ‰‹å·¥æ‰“é€ ç¥ç»ç½‘ç»œï¼šé€è§†åˆ†æ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee200033394c684d879></p><p>æœ€åæŠŠä¸Šé¢çš„ä»£ç é‡æ„ä¸€ä¸‹æ•´åˆèµ·æ¥è´´å‡ºå®Œæ•´ä»£ç (ä¸åŒ…å«è°ƒè¯•æ‰“å°å›¾ç‰‡å’Œæ—¥å¿—)ï¼Œé¢„æµ‹å‡†ç¡®ç‡90%, ä¸‹ä¸€ç¯‡æˆ‘å°†æ”¹ç”¨TensorFlowå¯¹Fashion MNISTé¢„æµ‹ï¼Œå¹¶æå‡å‡†ç¡®ç‡ã€‚</p><blockquote><p>import numpy as np</p><p>from tensorflow.examples.tutorials.mnist import input_data</p><p>import matplotlib.pyplot as plt</p><p>mndata = input_data.read_data_sets("MNIST-data/", one_hot=True)</p><p>X_train=mndata.train.images # training set</p><p>y_train=mndata.train.labels</p><p>X_test=mndata.test.images # testing set</p><p>y_test=mndata.test.labels</p><p>input_layer_size = 28 * 28</p><p>hidden_layer_size = 15</p><p>output_layer_size = 10</p><p>reg_lambda = .01</p><p>learning_rate = .01</p><p># visualize grid data of a matrix, zero cell shown as empty</p><p>def plt_grid(data):</p><p>fig, ax = plt.subplots()</p><p>fig.set_size_inches(30,30)</p><p>width, height = data.shape</p><p>#imshow portion</p><p>imshow_data = np.random.rand(width, height, 2)</p><p>ax.imshow(imshow_data, cmap=plt.cm.Pastel1, interpolation='nearest')</p><p>for x in range(0, height):</p><p>for y in range(0, width):</p><p>if (data[y][x]>0):</p><p>ax.text(x, y, np.round(data[y][x],8), va='center',</p><p>ha='center', fontsize=20)</p><p>plt.show()</p><p>def softmax(x):</p><p>e_x = np.exp(x - np.max(x))</p><p>return e_x / e_x.sum()</p><p>def relu(x):</p><p>return np.maximum(x, 0)</p><p>def cross_entropy_loss(probs, y_onehot):</p><p>indices = np.argmax(y_onehot, axis = 0).astype(int)</p><p>predicted_prob = probs[np.arange(len(probs)), indices]</p><p>log_preds = np.log(predicted_prob)</p><p>loss = -1.0 * np.sum(log_preds) / len(log_preds)</p><p>return loss</p><p># init weights and bias</p><p>def init_weights_bias():</p><p>np.random.seed(1)</p><p>W1 = np.random.random([input_layer_size, hidden_layer_size])/5 # 784 x 15</p><p>b1 = np.zeros((1, hidden_layer_size))</p><p>W2 = np.random.random([hidden_layer_size, output_layer_size])/5 # 15 x 10</p><p>b2 = np.zeros((1, output_layer_size))</p><p>model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}</p><p>return model</p><p># derivative weights and bias</p><p>def derivative_weights_bias(output_error, hidden_layer, X, model):</p><p>W1, _, W2, _ = model['W1'], model['b1'], model['W2'], model['b2']</p><p>hidden_error = np.dot(output_error, W2.T)</p><p>hidden_error[hidden_layer &lt;= 0] = 0</p><p># gradient layer2 weights and bias</p><p>g2_weights = np.dot(hidden_layer.T, output_error)</p><p>g2_bias = np.sum(output_error, axis = 0, keepdims = True)</p><p># gradient layer1 weights and bias</p><p>g1_weights = np.dot(X.reshape(input_layer_size,1), hidden_error)</p><p>g1_bias = np.sum(hidden_error, axis = 0, keepdims = True)</p><p># add regularization terms</p><p>g2_weights += reg_lambda * W2</p><p>g1_weights += reg_lambda * W1</p><p>param = { 'dW1': g1_weights, 'db1': g1_bias, 'dW2': g2_weights, 'db2': g2_bias}</p><p>return param</p><p>def forward_propagation(X, model):</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p>input_layer = np.dot(X, W1)</p><p>hidden_layer = relu(input_layer + b1)</p><p>output_layer = np.dot(hidden_layer, W2) + b2</p><p>probs = softmax(output_layer)</p><p>return probs, hidden_layer</p><p>def accuracy(predictions, labels):</p><p>preds_correct_boolean = np.argmax(predictions, 1) == np.argmax(labels, 1)</p><p>correct_predictions = np.sum(preds_correct_boolean)</p><p>accuracy = 100.0 * correct_predictions / predictions.shape[0]</p><p>return accuracy</p><p>#predict test set</p><p>def predict(X, model):</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p>input_layer = np.dot(X_test[:10000], W1)</p><p>hidden_layer = relu(input_layer + b1)</p><p>output_layer = np.dot(hidden_layer, W2) + b2</p><p>probs = softmax(output_layer)</p><p>print ('Test accuracy: {0}%'.format(accuracy(probs, y_test[:10000])))</p><p># - batch: Size of passes through the training data for gradient descent</p><p>def train_model(batch, X, y):</p><p>model = init_weights_bias()</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p># Gradient descent. For each batch...</p><p>for i in range(0, batch):</p><p>output_probs, hidden_layer = forward_propagation(X[i], model)</p><p>output_error = (output_probs - y[i]) / output_probs.shape[0]</p><p>param = derivative_weights_bias(output_error, hidden_layer, X[i], model)</p><p>dW1, db1, dW2, db2 = param['dW1'], param['db1'], param['dW2'], param['db2']</p><p># gradient descent parameter update</p><p>W1 -= learning_rate * dW1</p><p>b1 -= learning_rate * db1</p><p>W2 -= learning_rate * dW2</p><p>b2 -= learning_rate * db2</p><p>model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}</p><p>loss = cross_entropy_loss(output_probs, y[i])</p><p>if (i % 2000 == 0):</p><p>print('loss @ %d is %f' % (i, loss))</p><p>return model</p><p>model = train_model(50000, X_train[:50000], y_train[:50000])</p><p>predict(X_test[:10000], model)</p></blockquote><p><em>References:</em></p><p><em><a rel=nofollow target=_blank>Neural Network Vectorization</a></em></p><p><em><a rel=nofollow target=_blank>Neural Network and Deep Learning</a></em></p><p><em>Not another MNIST tutorial with TensorFlow OReilly Media</em></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'ç¥ç»','ç½‘ç»œ','é€è§†'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=æœç´¢>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>ğŸ”</button></form></section><section class=widget><h3 class=widget-title>æœ€æ–°æ–‡ç«  âš¡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>å…¶ä»–</h3><ul class=widget-list><li><a href=TOS.html>ä½¿ç”¨æ¢æ¬¾</a></li><li><a href=CommentPolicy.html>ç•™è¨€æ”¿ç­–</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>è¯çµ¡æˆ‘å€‘</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>æå®¢å¿«è¨Š</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>