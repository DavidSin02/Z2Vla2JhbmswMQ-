<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 | 极客快訊</title><meta property="og:title" content="论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/53350006726e50ef72f9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><meta property="article:published_time" content="2020-10-29T21:08:15+08:00"><meta property="article:modified_time" content="2020-10-29T21:08:15+08:00"><meta name=Keywords content><meta name=description content="论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/db47ae3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>《测绘学报》</p><p>构建与学术的桥梁 拉近与权威的距离</p><p>许夙晖<sup>1</sup><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/53350006726e50ef72f9>, 慕晓冬<sup>1</sup>, 张雄美<sup>1</sup>, 柴栋<sup>2</sup></p><p>1. 火箭军工程大学信息工程系, 陕西 西安 710025; 2. 北京航空工程技术研究中心, 北京 100076</p><p>收稿日期：2017-06-05；修回日期：2017-10-24</p><p>基金项目：国家自然科学基金（61640007）</p><p>第一作者简介：许夙晖(1989-), 女, 博士生, 研究方向为遥感图像处理和模式识别。E-mail:xu_suhui@163.com</p><p><strong>摘要</strong>：使用机器学习进行遥感影像标注的一个重要前提是有足够的训练样本，而样本的标注是非常耗时的。本文采用了域适应的方法来解决遥感影像场景分类中小样本量的无监督学习问题，提出了结合对抗网络与辅助任务的遥感影像域适应方法。首先建立了基于深度卷积神经网络的遥感影像分类框架；其次，为了学习到域不变特征，在标签分类器的基础上增加域分类器，并使域损失函数在其反射传播时的梯度与标签损失的梯度相反，从而保证域分类器不能区分样本来自于哪个域；最后引入了辅助分类任务，扩充了样本的同时使网络更具泛化能力。试验结果表明，本文方法优于主流的无监督域适应方法，在小样本遥感影像无监督分类中得到了较好的效果。</p><p><strong>Unsupervised Remote Sensing Domain Adaptation Method with Adversarial Network and Auxiliary Task</strong></p><p>XU Suhui<sup>1</sup>, MU Xiaodong<sup>1</sup>, ZHANG Xiongmei<sup>1</sup>, CHAI Dong<sup>2</sup></p><p><strong>Abstract</strong>: An important prerequisite when annotating the remote sensing images by machine learning is that there are enough training samples for training, but labeling the samples is very time-consuming. In this paper, we solve the problem of unsupervised learning with small sample size in remote sensing image scene classification by domain adaptation method. A new domain adaptation framework is proposed which combines adversarial network and auxiliary task. Firstly, a novel remote sensing scene classification framework is established based on deep convolution neural networks. Secondly, a domain classifier is added to the network, in order to learn the domain-invariant features. The gradient direction of the domain loss is opposite to the label loss during the back propagation, which makes the domain predictor failed to distinguish the sample's domain. Lastly, we introduce an auxiliary task for the network, which augments the training samples and improves the generalization ability of the network. The experiments demonstrate better results in unsupervised classification with small sample sizes of remote sensing images compared to the baseline unsupervised domain adaptation approaches.</p><p>Key words: remote sensing image scene classification domain adaptation deep convolutional neural network adversarial network multi-task learning</p><p>遥感影像的分类效果很大程度取决于提取的影像特征，文献[1]将现有的遥感影像特征提取方法分为3大类：①人工特征，如影像的光谱、纹理、空间、GIST、SIFT、HOG等；②基于无监督的特征，如主成分分析、K-均值聚类、稀疏编码等；③深度特征，如SAE、CNNs等。由于深度特征可以代表影像更为抽象的特征，因此近两年大量研究采用深度神经网络来提取遥感影像的特征<sup>[2-8]</sup>。然而，深度网络能够提取出有效特征的前提是有足够的训练样本<sup>[9]</sup>。对于一幅陌生的遥感影像，首要的是选取大量的样本并且对其进行标记，这在实际过程中非常耗时<sup>[10-11]</sup>。因此在训练样本有限甚至没有的情况下如何训练出泛化能力较强的网络是目前深度学习领域正在解决的热点问题。</p><p>假设已有一个相对较大的已经标注过的遥感影像数据集，若利用其更加丰富的数据作为训练样本，理论上可以训练出更为成熟、泛化能力更强的网络，用这个网络将会对新的遥感影像提取出更好的特征。然而，不同数据集之间由于传感器、拍摄角度、季节等的差异，造成同一类型的地物在不同的域中差异巨大。直接将大规模数据集样本训练的网络来预测目标数据集，得到的分类结果并不理想。由此，不同数据集之间的域适应问题得以提出，在域适应问题中，提供训练样本的数据集所在的域称为源域，对需要进行分类的数据集称为目标域。</p><p>近些年，诸多学者对域适应问题进行了研究，研究的图像对象主要集中在Office/Caltech数据集，和Mnist/Mnist_M/USPS/SVHN数据集，前者包含4个域，内容为数码照片，后者是0-9数字图像。研究的问题可按照目标域中是否有可用标签分为两类<sup>[12]</sup>：一种是监督/半监督学习，即目标域中所有类或者部分类中部分图像含有标签，可以直接作为训练样本；另一种是完全无监督学习，即目标域中没有可用标签。研究的方法通常有两种类型：一是用人工特征、或者训练好的CNN网络对遥感影像进行特征提取，然后求出一个转换矩阵，将源域的特征映射到目标域中，使两个域的影像享有同一个特征空间，这类方法的相关研究有ARC-t<sup>[13]</sup>、MMDT<sup>[14]</sup>、HFA<sup>[15]</sup>、GFK<sup>[16]</sup>、Landmarks<sup>[17]</sup>等，其中，GFK和Landmarks是无监督的，其他方法为监督学习的方法。</p><p>域适应的另外一种类型是基于深度学习的方法。文献[18]在标签代价函数的基础上，引入了称为域混淆损失的代价函数，具体做法是在最后一层全连接层之前加了域适应层，源域和目标域的样本经过该层的输出特征后，计算其最大平均偏差距离(maximum mean discrepancy，MMD)，该距离与标签损失之和为新的目标函数。针对监督和半监督分类，文献[19]在文献[18]的基础上加入了软标签损失，用来保持源域和目标域各类之间相对分布的一致性。文献[20]使用了对抗网络框架<sup>[21]</sup>来解决域适应问题，其目标函数包括标签分类器和域分类器两部分，该方法的对抗思想体现在：对于域适应问题，一是希望网络学到的特征表示具有域不变的特征，这就导致域分类器不能正确进行域分类，即域分类器的分类损失最大；二是在对域分类器训练同时，要求标签分类器能尽可能地正确分类，即标签分类器的分类损失最小。</p><p>目前域适应方法普遍的试验对象为普通图像，近年来也有学者针对遥感影像的域适应方法进行针对性的研究<sup>[22-23]</sup>。遥感影像相对于普通图像在域适应问题上有很大不同：一方面其源域和目标域差异较大；另一方面图像包含的地物信息丰富，需要更深的网络，而更深的网络需要更为丰富的样本数据支持。传统域适应方法直接用于遥感影像很难取得较好的分类效果。</p><p>针对遥感影像域适应过程中的高分辨率遥感影像尺寸大而数据量小的问题，本文提出了基于对抗网络和辅助任务的遥感影像域适应方法，其创新点在于：①首次进行遥感影像无监督域适应场景分类的研究，构建了遥感影像域适应试验的数据集，设计了结合辅助任务的对抗网络架构；②引入域损失函数，在目标函数中增加了域分类任务，使分类器学习到域不变特征；③引入不同标签空间的辅助分类任务，丰富了训练样本，提高网络的泛化能力和特征提取能力。试验表明，本文方法加入了域损失任务与辅助分类任务，与主流域适应算法相比，在分类效果上有明显的优势。</p><p>1 本文提出的方法</p><p>问题描述：设源域数据集合为<em>S</em>={(<strong>x</strong><sub>s</sub><sup>i</sup>,<strong>y</strong><sub>s</sub><sup>i</sup>)}<em>i</em>=1n<sub>s</sub>，其中<strong>x</strong><sub>s</sub><sup>i</sup>为源域中图像数据，<strong>y</strong><sub>s</sub><sup>i</sup>为相应的标签，<strong>y</strong><sub>s</sub><sup>i</sup>∈Y<sub>s</sub>={0，1，2，…<em>l</em>,<em>l</em>+1, …<em>L</em>}, n<sub>s</sub>为源域中样本数量；目标域数据集合为<em>T</em>={(<strong>x</strong><sub>t</sub><sup>i</sup>)}<em>i</em>=1n<sub>t</sub>，<strong>x</strong><sub>t</sub><sup>i</sup>为目标域中图像数据，n<sub>t</sub>为目标域中样本数量，目标域中每个样本的标签<strong>y</strong><sub>t</sub><sup>i</sup>是未知的，但是其所在空间是已知的，<strong>y</strong><sub>t</sub><sup>i</sup>∈Y<sub>t</sub>={0，1，2，…<em>l</em>}，即Y<sub>T</sub>⊂Y<sub>S</sub>。<em>S</em>和<em>T</em>服从不同的分布, 记<em>S</em>~D<sub>s</sub>，<em>T</em>~D<sub>t</sub>，且D<sub>s</sub>≠D<sub>t</sub>。将源域中与目标域享有共同标签空间的样本称为主样本<em>S</em><sub>main</sub>={(<strong>x</strong><sub>main</sub><em>i</em>,<strong>y</strong><sub>main</sub><em>i</em>)}<em>i</em>=1<em>n</em><sub>main</sub>，源域中不属于目标域空间的样本称为辅助样本<em>S</em><sub>aux</sub>={(<strong>x</strong><sub>aux</sub><em>i</em>,<strong>y</strong><sub>aux</sub><em>i</em>)}<em>i</em>=1<em>n</em><sub>aux</sub>，且满足</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78850002c6504800eb79><p>(1)</p><p>式中，<strong>x</strong><sub>main</sub><em>i</em>和<strong>x</strong><sub>aux</sub><em>i</em>分别为主样本和辅助样本中图像数据；<strong>y</strong><sub>main</sub><em>i</em>和<strong>y</strong><sub>aux</sub><em>i</em>为相应的标签；<em>n</em><sub>main</sub>和<em>n</em><sub>aux</sub>为样本数量。</p><p>算法的目的是，利用源域数据<em>S</em>，求解一个分类器C<sub>θ</sub>，使得</p><p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/727c000a5b882d789ebe>(2)</p><p>本文方法的框架如图 1所示，源域和目标域的数据共同输入到多层卷积神经网络提取特征，然后将辅助样本的特征作为辅助标签预测器(上侧区域)的输入；将主样本的特征输入到主标签预测器(中间区域)和域预测器中(下侧区域)；将目标域的特征输入到域预测器中。所有分类器输出后与相应的标签计算损失。本文方法的损失函数为</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727b000a5b46164aea98><p>图 1 本文方法的框架Fig. 1 Framework of the proposed method</p><p>图选项</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/727b000a5b478f342a48><p>(3)</p><p>损失函数由3部分构成：主损失函数<em>L</em><sub>main</sub>、辅助类损失函数<em>L</em><sub>aux</sub>和域损失函数L<sub>d</sub>，<em>λ</em>与<em>γ</em>为相应的权重系数。</p><p>1.1 对抗网络</p><p>本文设计的网络基于两个目的：一是网络可以对地物类型进行分类，二是网络具有域不变特性，即网络区分不出来输入影像来自于哪一个域。前者可以理解调整网络参数，使类损失函数最小；后者可以通过一个域损失函数来实现。对于两个不同域的影像，除了其自带的类标签，人为定义一个域标签，比如对于源域其标签为0，对于目标域其标签为1。域损失越大，域分类器就越难区别输入影像来自源域或目标域，网络的域适应性也就越好。因此，网络参数需要同时满足分类损失最小化和域损失最大化，这两个部分是对抗的。</p><p>主损失函数为类别损失，其定义如下</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/78810007964f7fe3914b><p>(4)</p><p>式中，<strong>x</strong><sub>main</sub>、<strong>y</strong><sub>main</sub>分别为共享样本数据和标签；<strong>θ</strong><sub>f</sub>为特征提取单元的网络参数；<strong>θ</strong><sub>main</sub>为主分类器的网络参数，该分类器由若干个全连接层组成，分类器最后输出的单元数为主类的类别数；1为指示函数，当<strong>y</strong><sub>main</sub>=<em>m</em>成立时值取1，否则取0；p<sub>m</sub>为softmax层的输出值，p<sub>m</sub>=softmax[<strong>θ</strong><sub>main</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>main</sub>;<strong>θ</strong><sub>f</sub>)]。</p><p>按照所在域的不同，分别为源域中的主样本和目标域中的样本增加一个域标签，记为<strong>y</strong><sub>d</sub><sup>main</sup>与<strong>y</strong><sub>d</sub><sup>t</sup>，并定义：{<strong>y</strong><sub>d</sub><sup>main</sup>}<em>n</em><sub>main</sub>=0，{<strong>y</strong><sub>d</sub><sup>t</sup>}n<sub>t</sub>=1。域损失定义如下</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78840004935e983be61e><p>(5)</p><p>式中，<strong>θ</strong><sub>d</sub>为域分类器的网络参数，该分类器输出的单元数为域标签的类别数，即为2；1为指示函数，当<strong>y</strong><sub>d</sub>=<em>d</em>成立时值取1，否则取0；p<sub>d</sub>为域分类器softmax层的输出值，p<sub>d</sub>=softmax[<strong>θ</strong><sub>d</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>main</sub>,<strong>x</strong><sub>t</sub>;<strong>θ</strong><sub>f</sub>)]。</p><p>由于对抗网络的目标是学习到域不变特征，也就是说域分类器分辨不出类别最好。因此域的损失函数不能与类别损失函数一样越小越好，而是在源域类别损失相对较小的情况下，域损失函数越大越好。因此求解目标是</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727c000a5b89e9728132><p>(6)</p><p>注意到式(6)中，L<sub>d</sub>的求解目标是使其最大化，这种情况不能用梯度下降进行求解。为了解决这个问题，定义一个中间函数<em>R</em>(<strong>x</strong>)，在前向与反向传播中</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8ad0841e93><p>(7)</p><p>式(7)表示正向传播时无影响，而反向用梯度更新参数时进行梯度反转，由此就得到可以满足使用梯度下降法的表现形式。</p><p>1.2 辅助任务</p><p>在本文遥感影像域适应应用场景中，源域样本中还包括了目标域中不存在类别的样本。为了充分利用源域的样本，本文加入了辅助任务，其思想来源于多任务学习。多任务学习在单一任务的基础上，结合了辅助的任务学习共同的特征表示<sup>[24-25]</sup>。通过辅助任务学习，最大限度地丰富了训练样本，学习到的特征相对於单任务学习具有更好的泛化能力，并且有效地减小类内距离与增大类间距离，有利于提高分类精度。</p><p>本文的辅助损失函数的定义如下</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78850002c6510fc1fab6><p>(8)</p><p>式中，<strong>x</strong><sub>aux</sub>、<strong>y</strong><sub>aux</sub>分别为辅助样本数据和标签；<strong>θ</strong><sub>aux</sub>为辅助类线性分类器的网络参数，分类器最后输出的单元数为辅助类的类别数；1为指示函数，当<strong>y</strong><sub>aux</sub>=<em>k</em>成立时值取1，否则取0；p<sub>k</sub>为softmax层的输出值，p<sub>k</sub>=softmax[<strong>θ</strong><sub>aux</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>aux</sub>;<strong>θ</strong><sub>f</sub>)]。辅助损失函数为类别损失，要求其损失越小越好，即求解目标为<img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727c000a5b8b56611e3e></p><p>1.3 算法流程</p><p>本文方法的参数更新流程如下</p><p>输入：源域数据<em>S</em>={(<strong>x</strong><sub>s</sub><sup>i</sup>,<strong>y</strong><sub>s</sub><sup>i</sup>)}<em>i</em>=1n<sub>s</sub>，目标域数据<em>T</em>={(<strong>x</strong><sub>t</sub><sup>i</sup>)}<em>i</em>=1n<sub>t</sub>，初始化参数<strong>θ</strong><sub>f</sub>、<strong>θ</strong><sub>aux</sub>、<strong>θ</strong><sub>main</sub>、<strong>θ</strong><sub>d</sub>，权重系数<em>λ</em>与<em>γ</em>，迭代次数<em>i</em>=0，初始学习率<em>ϕ</em>(0)，最大迭代次数num_step，单次输入样本数量batchsize</p><p>While <em>i</em>＜num_step:</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78840004935f28fcfafb><p>更新参数：</p><p><strong>θ</strong><sub>main</sub>=<strong>θ</strong><sub>main</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>main</sub>，<strong>θ</strong><sub>aux</sub>=<strong>θ</strong><sub>aux</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>aux</sub>，<strong>θ</strong><sub>d</sub>=<strong>θ</strong><sub>d</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>d</sub>，<strong>θ</strong><sub>f</sub>=<strong>θ</strong><sub>f</sub>-<em>ϕ</em>(<em>i</em>)·Δ<em>θ</em><sub>f</sub></p><p><em>i</em>+=1</p><p>End while</p><p>输出：<strong>θ</strong><sub>f</sub>，<strong>θ</strong><sub>main</sub>，并预测标签<img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78830004b643de75aaf0></p><p>本方法有3个需要人工设置的参数，<em>λ</em>、<em>γ</em>及学习率<em>ϕ</em>。其中，<em>λ</em>是固定的，<em>γ</em>和<em>ϕ</em>按照式(9)和式(10)更新</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/788400049360c9e7da8e><p>(9)</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78820006a523263632c2><p>(10)</p><p>式中，<em>ϕ</em>(0)为初始学习率；<em>t</em>=<em>i</em>/num_step，<em>i</em>为当前迭代次数，num_step为最大迭代次数。</p><p>2 试验2.1 构建数据集</p><p>目前还没有公开的适用于遥感影像域适应试验的数据集，故本文使用了3个数据作为数据源构建域适应数据集，分别是：①NWPU-RESISC45数据集<sup>[1]</sup>(简称NWPU)，该数据集含有45类场景的遥感影像，每类影像都包含有700张图片，共31500张影像；②一整幅遥感影像为Quickbird卫星拍摄的西安市遥感影像(简称Xian)，尺寸为13312×7680像素。对Xian进行了切割，并人工分类标注，选出与NWPU重叠的8个类，共339张影像；③一整幅遥感影像为高分二号卫星拍摄的广州市遥感影像(简称GZ)，与处理Xian类似，对其进行切割与人工标注，选出与NWPU重叠的8个类，共826幅影像。因此以上3个数据集共构成了两组遥感影像域适应数据集，将其分别命名为NWPU-Xian8及NWPU-GZ8。示例图像如图 2所示，每张示例图像底部数字为该类样本数。从图 2可以看出，NWPU-Xian8的图像差异较大，Xian的影像颜色存在失真，并且噪声较为严重，而NWPU-GZ8影像差异较小。两组数据集中NWPU的其余37类影像在这里不再展示，请参考文献[1]。以上所有影像的尺寸为256×256。</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8d72caf960><p>图 2 数据集各类示例Fig. 2 Samples from each category in the domain adaptation datasets</p><p>图选项</p><p>2.2 试验设置</p><p>针对两组数据集进行的试验中，分别将NWPU整个45类作为源域，Xian及GZ作为目标域。因此在NWPU-Xian8及NWPU-GZ8中，主任务的数据类别都为8类，辅助类别为37类。训练及测试时对输入到网络中的影像随机裁剪为227×227，网络的各个参数，比如卷积核大小，步长和卷积层的层数如图 3所示，前8个方框表示特征提取层，本文特征提取阶段使用了预训练的Alexnet网络结构<sup>[24]</sup>。紧接着特征提取层，为3个网络分支，这3个分支分别为主分类器，辅助分类器和域分类器。3个分类器都是由全连接层构成，其最终输出结点分别为8、37和2。本文所有试验代码基于tensorflow进行搭建，硬件环境为Amazon EC2的P2.xlarge实例，该实例的GPU型号为nvidia tesla k80。</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78820006a5288b384718><p>图 3 本文方法的网络结构Fig. 3 The net structure of the proposed approach</p><p>图选项</p><p>2.3 试验结果与分析</p><p>将本文方法与文献中其他方法进行试验对比。对比的方法有：①source only，将源域数据输入到网络进行训练，直接对目标域进行分类，不加入域损失和辅助损失函数；②GFK，文献[5]中的方法；③Landmark，文献[6]所介绍的方法，是文献[5]方法的扩展，GFK和Landmark，其使用的图像特征是由预训练的alexnet网络的fc7层提取得到，每张图像都表示为4096维特征；④source+domain，文献[20]中的方法，即源域样本分类与域分类同时进行，没有增加辅助分类任务；⑤MMD，文献[7]中的方法，使用MMD损失函数进行域间最小化。对于source only及后3种方法，设置初始学习率<em>ϕ</em>(0)=0.002，batchsize=64，最大迭代次数为10000；MMD中，MMD损失是用fc7的输出进行计算得到，系数为0.25；本文方法中，<em>λ</em>=1。各类方法最后对目标域数据进行分类，对于GFK和Landmark，计算20次试验的平均精度作为其最终精度。对于其他方法，设置每训练25次进行一次测试，将最后10次测试的平均精度作为其最终精度，6种方法最终测试精度列于表 1。基于最后一次测试的结果计算各方法预测的混淆矩阵，将各个方法对于NWPU-Xian8数据集的混淆矩阵列于图 4。</p><p>表 1 不同算法分类精度Tab. 1 Classification accuracy of different algorithms</p><table><thead><tr><td colspan=7>(%)</td></tr><tr><br><td>source only</td><td>GFK</td><td>Landmark</td><td>source+domain</td><td>MMD</td><td>本文方法</td></tr></thead><tbody><tr><td>NWPU-Xian8</td><td>58.40</td><td>60.47</td><td>69.44</td><td>76.40</td><td>63.12</td><td>79.63</td></tr><tr><td>NWPU-GZ8</td><td>76.99</td><td>78.32</td><td>81.07</td><td>83.50</td><td>77.05</td><td>84.63</td></tr></tbody></table><p>表选项</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8ed703d2e5><p>图 4 NWPU-Xian8数据集混淆矩阵Fig. 4 Confusion matrix for NWPU-Xian8 dataset</p><p>图选项</p><p>从表 1可以得到看出，本文方法在精度上优于其他算法，source+domain次之。图 4中，本文方法相对于其余5类方法，表现较为均衡，对于容易混淆的intersection、freeway和overpass这3类的精度也有了一定的提高。由此表明了对抗网络和辅助任务可以较好地学习到域不变特征，提高网络的泛化能力和分类精度。</p><p>为了进一步验证本文方法提取域不变特征的优势，用高维数据可视化工具t-SNE对NWPU-Xian8数据集聚类结果进行可视化(t-SNE详情参见文献[27])。聚类的对象为进入到分类器之前目标域所有数据的特征。如图 5所示，图(a)为直接采用预训练的Alexnet网络提取的fc7层特征，图(b)为本文方法倒数第2层输出的特征，两种特征都为4096维。两张图分别表示未进行域适应和进行了域适应后目标域数据各类之间的关系。可以看出进行域适应后，目标域各类之间距离增大，同类之间距离减小，很好地学习到了域不变特征。</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/78850002c65381cefecb><p>图 5 NWPU-Xian8数据集目标域图像特征的二维可视化Fig. 5 2-D visualization of image feature in the target domain for NWPU-Xian8 dataset</p><p>图选项</p><p>3 结论</p><p>本文针对遥感影像场景分类中小样本量的无监督学习问题，提出了一种结合对抗网络与辅助任务的遥感影像域适应方法，建立了基于深度卷积神经网络的遥感影像分类框架，在标签损失函数的基础上加入了域分类器，并使得域损失函数与标签损失形成对抗的关系，最后引入了辅助分类任务，扩充训练样本。在本文构建的遥感影像域适应数据集上试验结果表明，本文方法能够通过域损失学习到域不变特征，通过辅助分类任务增加类间距离、减小类内距离，并使网络具有良好的泛化能力，在不同域的无监督分类中有明显的优势。对小样本量的Xian和GZ数据集无监督分类精度达到79.63%和84.63%，相对于直接利用大样本量数据集NWPU对Xian和GZ数据集分类(58.40%和76.99%)，本文方法分类效果有显著提高。</p><p><strong>【引文格式】许夙晖，慕晓冬，张雄美，等。结合对抗网络与辅助任务的遥感影像无监督域适应方法[J]. 测绘学报，2017，46(12)：1969-1977. DOI: 10.11947/j.AGCS.2017.20170291</strong></p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/39d40000b5178f24974d><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/1d58000c77f8222af5dc><p>往期精彩回顾</p><img alt=论文推荐｜许夙晖：结合对抗网络与辅助任务的遥感影像无监督域适应方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/3009000f15ca5ebfaebd><p><strong>李德仁院士：老师教我做人做学问</strong></p><p><strong>关于稿件“时间”安排那些事儿~</strong></p><p><strong>重磅！新增博士、硕士学位授权点名单出炉，有你的母校吗</strong></p><p><strong>组建“自然资源部”的来龙去脉</strong></p><p>权威 | 专业 | 学术 | 前沿</p><p>微信投稿邮箱 | song_qi_fan@163.com</p><p>微信公众号中搜索「测绘学报」，<strong>关注我们</strong>，长按上图二维码，关注学术前沿动态。</p><p>进群请备注：姓名+单位+稿件编号</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'论文','推荐','许夙晖'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>