<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 | 极客快訊</title><meta property="og:title" content="用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/04e01b83d68b4296803a0991ae351b03"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dfc16c0.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dfc16c0.html><meta property="article:published_time" content="2020-10-29T21:05:26+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:26+08:00"><meta name=Keywords content><meta name=description content="用编码器-解码器-重构器框架实现英语-日语的神经机器翻译"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/dfc16c0.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>用编码器-解码器-重构器框架实现英语-日语的神经机器翻译</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>针对神经机器翻译翻译过度和翻译不足的问题，Tu et al. (2017) 的论文《Neural Machine Translation with Reconstruction》提出了一种“编码器-解码器-重构器框架”，其使用了回译来提升翻译准确度。日本首都大学东京的研究者在英语-日语翻译任务上实现了该框架。机器之心技术分析师对该实现的论文进行了解读和梳理。</p><p>论文链接：https://arxiv.org/pdf/1706.08198.pdf</p><p>论文作者：Yukio Matsumura, Takayu kiSato, Mamoru Komachi</p><h1>引言</h1><p>神经机器翻译（NMT）近段时间发展迅猛，已经在传统的统计机器翻译基础上实现了很大的提升，并且已经在很多语言内的翻译任务上实现了当前最佳表现。</p><p>但是，NMT 翻译过度和翻译不足的问题都存在，也就是说，有时候它可能会重复翻译某些词，有时候它可能会遗漏某些词。这是因为 NMT 模型通常可被看作是黑箱，而我们并不完全清楚它们背后的机制，即它们将源句转换成目标句的方式。</p><p>针对这一问题，Tu et al. (2017) 为 NMT 提出了一种“编码器-解码器-重构器框架”，其使用了回译（back translation）来提升翻译准确度。这篇论文是该框架在英语-日语翻译任务上的实现。</p><p>此外，这篇论文还指出，除非顺译（forward translation）模型的训练方式类似传统的基于注意的 NMT（也被称为预训练），否则该框架不能实现让人满意的表现。</p><h1>传统的基于注意的 NMT 模型</h1><p>下面展示了 Bahdanau et al. (2015) 提出的传统的基于注意的 NMT 模型。</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/04e01b83d68b4296803a0991ae351b03><p class=pgc-img-caption></p></div><p>图 1：基于注意的 NMT</p><p>其中编码器将源句转换成固定长度的向量 C，并将其作为语境向量（context vector）。在每个时间步骤 t 都使用一个双向 RNN，那么该编码器的隐藏状态 h_t 就可表示为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e52e4e277c5e4bac933470604f2d089e><p class=pgc-img-caption></p></div><p>其中前向状态和反向状态可分别按以下方式计算：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5760acbcf7c74141a75f6029774f836a><p class=pgc-img-caption></p></div><p>和</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/74863e37f9614fdba938fcb34836a554><p class=pgc-img-caption></p></div><p>r 和 r’ 都是非线性函数。那么语境向量 C 就变成：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ca423d5b38e04283b445d1b54f6d4d89><p class=pgc-img-caption></p></div><p>其中 q 也是一个非线性函数。</p><p>在经典的编码器-解码器模型中，编码器计算得到的语境向量 C 会被解码器直接“解码”成目标句。但因为解码器必须处理整个向量，所以之前的信息可能会被之后处理的信息覆盖。因此，语境向量越长，模型就越有可能丢失重要信息。这就是引入基于注意的机制的原因，这能让模型在每个步骤关注语境向量的特定部分以确保信息充分足够。</p><p>在每个时间步骤 i，输出词的条件概率可以这样计算：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6214bc816f394a99aa53e0608ebc26a9><p class=pgc-img-caption></p></div><p>其中 s_i 是解码器的隐藏状态，计算方式为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/92581ba20ed049aa8c4b1285771575aa><p class=pgc-img-caption></p></div><p>根据这一等式，我们可以看到时间步骤 i 的隐藏状态 s_i 是使用语境向量 c_i 以及前一个时间步骤 i-1 的隐藏状态和目标词计算的。</p><p>不同于前文提及的较长的长度固定的向量 C，语境向量 c_i 是编码器的每个隐藏状态 h_j 的加权和，计算方式为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e24267c911f149e0b89fdfd94411866b><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/33ff56a93d37474c963a5babdd78cebb><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/611fbf5092874f90969a6c0bf34905b7><p class=pgc-img-caption></p></div><p>其中权重矩阵 e_ij 是由一个“对齐模型”生成的，该模型的作用是将位置 j 附近的输入与位置 i 处的输出对齐；而 α 可被理解成是一个“注意分配”向量。</p><p>最后，目标函数定义为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b9ed56c9b58a4d9eb9773984732f141e><p class=pgc-img-caption></p></div><p>其中 N 是数据的数量，θ 是一个模型参数。</p><h1>编码器-解码器-重构器框架</h1><p>Tu et al. (2017) 为 NMT 提出的编码器-解码器-重构器框架在原来的 NMT 模型上增加了一个新的“重构器”结构。其目的是将解码器架构的隐藏状态翻译回源句，以进行比较并提升翻译准确度。下面描述了这种新结构：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e21ef64d305b4d4ca7a9e2d15d067e72><p class=pgc-img-caption></p></div><p>图 2：编码器-解码器-重构器</p><p>在每个时间步骤 i，输出的“源词”的条件概率的计算方式为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/62201853a4e243089c4db5c0c5caf1f0><p class=pgc-img-caption></p></div><p>隐藏状态 s' 的计算方式与之前的解码过程类似：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a21e84249fe048f8a120e77cf56d5659><p class=pgc-img-caption></p></div><p>注意这里的 c’ 被称为“逆语境向量”，计算方式为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/60150eaec8874ee78a0bcab31ef9b7a6><p class=pgc-img-caption></p></div><p>其中 s 只是解码器的每个隐藏状态（在顺译时的）。</p><p>类似地，可以进一步计算 α’：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3afd3ecbedcb47a682cd729ede9e5a80><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/599e7ae0d1414b15b8ca9d8dada7ea27><p class=pgc-img-caption></p></div><p>目标函数定义为：</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d9647db78c1c4ba88ff0399cc3a2700c><p class=pgc-img-caption></p></div><p>注意这个优化函数包含两个部分，即顺译部分和回译部分。超参数 λ 指定了顺译和回译之间的权重。</p><p>根据这篇论文，顺译部分衡量的是翻译流畅度，而回译部分衡量的是翻译充分性。以这种方式，这种新结构可以增强整体的翻译质量。</p><h1>实验</h1><p>这篇论文使用了 2 个英语-日语平行语料库：Asian Scientific Paper Excerpt Corpus（ASPEC）（Nakazawa etal.,2016）和 NTCIR PatentMT Parallel Corpus （Goto et al., 2013）。</p><p>实验中所用的 RNN 模型有 512 个隐藏单元、512 个嵌入单元、30000 的词汇量和 64 的批大小。训练平台是 GeForce GTX TITAN X GPU。</p><p>基准 NMT 模型是普通的基于注意的 NMT。</p><p>注意在这些实验中超参数 λ 设置为 1。</p><p>下面给出了一些英语-日语翻译任务的示例。注意“联合训练（jointly-training）”是指没有预训练的编码器-解码器-重构器。</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/da37d810cff245cdbcba3414ed54ed27><p class=pgc-img-caption></p></div><p>表1：英语-日语翻译的输出示例</p><h1>结果</h1><p>表 2 和 3 展示了 BLEU 分数表示的翻译准确度、通过 bootstrap 重采样得到的显著性检验的 p 值（Koehn, 2004）以及在收敛之前的训练时间。</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3008b581291b4dc1879f09ac61f11a13><p class=pgc-img-caption></p></div><p>表 2：英语-日语翻译结果</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/7419d4fbb03445b59452b40385772e48><p class=pgc-img-caption></p></div><p>表 3：日语-英语翻译结果</p><p>这个结果表明新的编码器-解码器-重构器框架所需的训练时间长于基准 NMT，但在英语-日语翻译中，其在 ASPEC 上的翻译准确度显著提升了 1.01 分，在 NTCIR 上提升了 1.37 分。但其在日语-英语翻译任务上却没有实现这样的提升。此外，联合训练得到的模型的表现甚至比基准模型还差一些。</p><p>此外，这篇论文还检查了这种新模型是否能更好地解决上面提到的翻译过度和翻译不足的问题。比如，图 3 表明基准模型无法输出“乱流と粘性の数値的粘性の関系を基に”，而新提出的模型能成功翻译它。图 4 表明基准模型重复翻译了“新生児”和“30歳以上の”，新提出的模型则表现更好。</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/85e9e7c0238b441e80524b3783374027><p class=pgc-img-caption></p></div><p>图 3：示例 1 中的注意层：对翻译不足问题的改进；其中左为基准 NMT，右为编码器-解码器-重构器</p><div class=pgc-img><img alt=用编码器-解码器-重构器框架实现英语-日语的神经机器翻译 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/79400536e3014aa89182af42d8e866b7><p class=pgc-img-caption></p></div><p>图 4：示例 2 中的注意层：对翻译过度问题的改进；其中左为基准 NMT，右为编码器-解码器-重构器</p><h1>结论</h1><p>这篇论文在英语-日语翻译任务上分析了新提出的编码器-解码器-重构器框架。结果表明，这种编码器-解码器-重构器能在英语-日语翻译任务上实现显著的 BLEU 分数提升，并且能缓解翻译中重复和遗漏词的问题。此外，通过将其与顺译和回译联合训练的模型进行比较，这篇论文还评估了预训练的重要性。</p><h1>评阅者点评</h1><p>回译一直都是翻译研究的一种有用方法，也能让人类译者检查他们是否翻译准确。在机器翻译任务中使用这种传统翻译方法是一个相当了不起的思路。</p><p>未来，语言学知识和自然语言处理会结合得更加紧密，这可能会成为一种新思路，有助于更好地提升语言处理任务的表现，比如机器翻译，尤其是对于日语这样具有很多“语法模板”（即日语的“文法”）的语言。</p><h1>参考文献</h1><ol><li>Dzmitry Bahdanau,Kyunghyun Cho,and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. Proceedings of the 3rd International Conference on Learning Representations (ICLR), pages 1–15.</li><li>Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, and Hang Li. 2017. Neural Machine Translation with Reconstruction. Proceedings of the ThirtyFirst AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 3097–3103.</li><li>Philipp Koehn. 2004. Statistical Significance Tests for MachineTranslationEvaluation. Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 388–395.</li></ol></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'编码器','解码器','重构器'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>