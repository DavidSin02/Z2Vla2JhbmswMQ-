<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Lucene（全文检索）进阶-第二篇 | 极客快訊</title><meta property="og:title" content="Lucene（全文检索）进阶-第二篇 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/37d9000385d3ea9c9c67"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e3c80a1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e3c80a1.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="Lucene（全文检索）进阶-第二篇"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/e3c80a1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Lucene（全文检索）进阶-第二篇</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>1.Lucene入门</h1><p>1.1. 需求</p><p>将数据库中的图书信息，创建为索引，然后去根据索引进行搜索。</p><p>1.2. Lucene准备</p><p>Lucene可以在官网上下载。我们使用的是4.10.3版本，如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37d9000385d3ea9c9c67></p><p>解压后的效果：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e20001a984373dd864></p><p>使用这三个文件的jar包，就可以实现lucene功能</p><p>使用的数据是MySQL数据库的数据，所以还需要MySQL的连接包</p><p>如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e00003b19d905fdc86></p><p>1.1. 开发环境</p><p>JDK： 1.7 （Lucene4.8以上，必须使用JDK1.7及以上版本）</p><p>IDE： eclipse Mars2</p><p>数据库： MySQL</p><p>MySQL数据如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37df0003c00a79e872cc></p><p>1.1. 创建Java工程</p><p>创建java工程测试即可，效果如下：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37d800039bf2dbcceaf6></p><p>1.1. 索引流程</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37d9000389a6c9f980d7></p><p><strong>IndexWriter</strong>是Lucene实现索引过程的核心组件，通过IndexWriter可以创建新索引、更新索引、删除索引操作。IndexWriter需要通过Directory对索引进行存储操作。</p><p><strong>Directory</strong>描述了索引的存储位置，底层封装了I/O操作，负责对索引进行存储。它是一个抽象类，它的子类常用的包括</p><p>FSDirectory（在文件系统存储索引）、RAMDirectory（在内存存储索引）。</p><p>1.1.1. 数据采集</p><p>在电商网站中，全文检索的数据源在数据库中，需要通过jdbc访问数据库中book表的内容。</p><p>1.1.1.1. 创建pojo</p><p><strong>public</strong> <strong>class</strong> Book {</p><p>// 图书ID</p><p><strong>private</strong> Integer id;</p><p>// 图书名称</p><p><strong>private</strong> String name;</p><p>// 图书价格</p><p><strong>private</strong> Float price;</p><p>// 图书图片</p><p><strong>private</strong> String pic;</p><p>// 图书描述</p><p><strong>private</strong> String description;</p><p>get/set。。。</p><p>}</p><p>1.1.1.2. 创建DAO接口</p><p><strong>public</strong> <strong>interface</strong> BookDao {</p><p>/**</p><p>* 查询所有的book数据</p><p>* <strong>@return</strong></p><p>*/</p><p>List&lt;Book> queryBookList();</p><p>}</p><p>1.1.1.3. 创建DAO接口实现类</p><p>使用jdbc实现</p><p><strong>public</strong> <strong>class</strong> BookDaoImpl <strong>implements</strong> BookDao {</p><p>@Override</p><p><strong>public</strong> List&lt;Book> queryBookList() {</p><p>// 数据库链接</p><p>Connection connection = <strong>null</strong>;</p><p>// 预编译statement</p><p>PreparedStatement preparedStatement = <strong>null</strong>;</p><p>// 结果集</p><p>ResultSet resultSet = <strong>null</strong>;</p><p>// 图书列表</p><p>List&lt;Book> list = <strong>new</strong> ArrayList&lt;Book>();</p><p><strong>try</strong> {</p><p>// 加载数据库驱动</p><p>Class.forName("com.mysql.jdbc.Driver");</p><p>// 连接数据库</p><p>connection = DriverManager.getConnection("jdbc:mysql://localhost:3306/solr", "root", "root");</p><p>// SQL语句</p><p>String sql = "SELECT * FROM book";</p><p>// 创建preparedStatement</p><p>preparedStatement = connection.prepareStatement(sql);</p><p>// 获取结果集</p><p>resultSet = preparedStatement.executeQuery();</p><p>// 结果集解析</p><p><strong>while</strong> (resultSet.next()) {</p><p>Book book = <strong>new</strong> Book();</p><p>book.setId(resultSet.getInt("id"));</p><p>book.setName(resultSet.getString("name"));</p><p>book.setPrice(resultSet.getFloat("price"));</p><p>book.setPic(resultSet.getString("pic"));</p><p>book.setDesc(resultSet.getString("desc"));</p><p>list.add(book);</p><p>}</p><p>} <strong>catch</strong> (Exception e) {</p><p>e.printStackTrace();</p><p>}</p><p><strong>return</strong> list;</p><p>}</p><p>}</p><p>1.1.2. 实现索引流程</p><p>1. 采集数据</p><p>2. 创建Document文档对象</p><p>3. 创建分析器（分词器）</p><p>4. 创建IndexWriterConfig配置信息类</p><p>5. 创建Directory流对象，声明索引库存储位置</p><p>6. 创建IndexWriter写入对象</p><p>7. 把Document写入到索引库中</p><p>8. 释放资源</p><p><strong>public</strong> <strong>class</strong> CreateIndexTest{</p><p>@Test</p><p><strong>public</strong> <strong>void</strong> testCreateIndex() <strong>throws</strong> Exception {</p><p>// 1. 采集数据</p><p>BookDao bookDao = <strong>new</strong> BookDaoImpl();</p><p>List&lt;Book> bookList = bookDao.queryBookList();</p><p>// 2. 创建Document文档对象</p><p>List&lt;Document> documents = <strong>new</strong> ArrayList&lt;>();</p><p><strong>for</strong> (Book book : bookList) {</p><p>Document document = <strong>new</strong> Document();</p><p>// Document文档中添加Field域</p><p>// 图书Id</p><p>// Store.YES:表示存储到文档域中</p><p>document.add(<strong>new</strong> TextField("id", book.getId().toString(), Store.<strong>YES</strong>));</p><p>// 图书名称</p><p>document.add(<strong>new</strong> TextField("name", book.getName().toString(), Store.<strong>YES</strong>));</p><p>// 图书价格</p><p>document.add(<strong>new</strong> TextField("price", book.getPrice().toString(), Store.<strong>YES</strong>));</p><p>// 图书图片地址</p><p>document.add(<strong>new</strong> TextField("pic", book.getPic().toString(), Store.<strong>YES</strong>));</p><p>// 图书描述</p><p>document.add(<strong>new</strong> TextField("desc", book.getDesc().toString(), Store.<strong>YES</strong>));</p><p>// 把Document放到list中</p><p>documents.add(document);</p><p>}</p><p>// 3. 创建Analyzer分词器,分析文档，对文档进行分词</p><p>Analyzer analyzer = <strong>new</strong> StandardAnalyzer();</p><p>// 4. 创建Directory对象,声明索引库的位置</p><p>Directory directory = FSDirectory.open(<strong>new</strong> File("C:/itcast/lucene/index"));</p><p>// 5. 创建IndexWriteConfig对象，写入索引需要的配置</p><p>IndexWriterConfig config = <strong>new</strong> IndexWriterConfig(Version.<strong>LUCENE_4_10_3</strong>, analyzer);</p><p>// 6.创建IndexWriter写入对象</p><p>IndexWriter indexWriter = <strong>new</strong> IndexWriter(directory, config);</p><p>// 7.写入到索引库，通过IndexWriter添加文档对象document</p><p><strong>for</strong> (Document doc : documents) {</p><p>indexWriter.addDocument(doc);</p><p>}</p><p>// 8.释放资源</p><p>indexWriter.close();</p><p>}</p><p>}</p><p>执行效果：</p><p>在文件夹中出现了以下文件，表示创建索引成功</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e00003b3814e8a154a></p><p>1.1.1. 使用Luke查看索引</p><p>Luke作为Lucene工具包中的一个工具（http://www.getopt.org/luke/），可以通过界面来进行索引文件的查询、修改</p><p>luke所在位置如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37df0003c1dbfa40863c></p><p>打开Luke方法：打开cmd命令行运行命令：java -jar lukeall-4.10.3.jar</p><p>打开后，使用如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37e20001ae0582c247b9></p><p>下图是索引域的展示效果：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37e20001ae3a1d6ea0d8></p><p>下图是文档域展示效果</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37d900038b177de577d9></p><p>1.1. 搜索流程</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e00003b4c267cf1451></p><p>1.1.1. 输入查询语句</p><p>Lucene可以通过<strong>Query</strong><strong>对象</strong>输入查询语句。同数据库的sql一样，lucene也有固定的查询语法：</p><p>最基本的有比如：<strong>AND, OR, NOT</strong> 等（必须大写）</p><p>举个栗子:</p><p>用户想找一个description中包括java关键字和lucene关键字的文档。</p><p>它对应的查询语句：description:java AND description:lucene</p><p>如下图是使用luke搜索的例子：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37d900038baa84591b54></p><p>1.1.1. 搜索分词</p><p>和索引过程的分词一样，这里要对用户输入的关键字进行分词，一般情况<strong>索引和搜索使用的分词器一致</strong>。</p><p>比如：输入搜索关键字“java学习”，分词后为java和学习两个词，与java和学习有关的内容都搜索出来了，如下：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37d8000396a3acbac978></p><p>1.1.1. 代码实现</p><p>1. 创建Query搜索对象</p><p>2. 创建Directory流对象,声明索引库位置</p><p>3. 创建索引读取对象IndexReader</p><p>4. 创建索引搜索对象IndexSearcher</p><p>5. 使用索引搜索对象，执行搜索，返回结果集TopDocs</p><p>6. 解析结果集</p><p>7. 释放资源</p><p>IndexSearcher搜索方法如下：</p><table><tbody><tr class=firstRow><td><p>方法</p></td><td><p>说明</p></td></tr><tr><td><p>indexSearcher.search(query, n)</p></td><td><p>根据Query搜索，返回评分最高的n条记录</p></td></tr><tr><td><p>indexSearcher.search(query, filter, n)</p></td><td><p>根据Query搜索，添加过滤策略，返回评分最高的n条记录</p></td></tr><tr><td><p>indexSearcher.search(query, n, sort)</p></td><td><p>根据Query搜索，添加排序策略，返回评分最高的n条记录</p></td></tr><tr><td><p>indexSearcher.search(booleanQuery, filter, n, sort)</p></td><td><p>根据Query搜索，添加过滤策略，添加排序策略，返回评分最高的n条记录</p></td></tr></tbody></table><p>代码实现</p><p>public class SearchIndexTest {</p><p>@Test</p><p>public void testSearchIndex() throws Exception {</p><p>// 1. 创建Query搜索对象</p><p>// 创建分词器</p><p>Analyzer analyzer = new StandardAnalyzer();</p><p>// 创建搜索解析器，第一个参数：默认Field域，第二个参数：分词器</p><p>QueryParser queryParser = new QueryParser("description", analyzer);</p><p>// 创建搜索对象</p><p>Query query = queryParser.parse("description:java AND lucene");</p><p>// 2. 创建Directory流对象,声明索引库位置</p><p>Directory directory = FSDirectory.open(new File("C:/itcast/lucene/index"));</p><p>// 3. 创建索引读取对象IndexReader</p><p>IndexReader reader = DirectoryReader.open(directory);</p><p>// 4. 创建索引搜索对象</p><p>IndexSearcher searcher = new IndexSearcher(reader);</p><p>// 5. 使用索引搜索对象，执行搜索，返回结果集TopDocs</p><p>// 第一个参数：搜索对象，第二个参数：返回的数据条数，指定查询结果最顶部的n条数据返回</p><p>TopDocs topDocs = searcher.search(query, 10);</p><p>System.out.println("查询到的数据总条数是：" + topDocs.totalHits);</p><p>// 获取查询结果集</p><p>ScoreDoc[] docs = topDocs.scoreDocs;</p><p>// 6. 解析结果集</p><p>for (ScoreDoc scoreDoc : docs) {</p><p>// 获取文档</p><p>int docID = scoreDoc.doc;</p><p>Document doc = searcher.doc(docID);</p><p>System.out.println("=============================");</p><p>System.out.println("docID:" + docID);</p><p>System.out.println("bookId:" + doc.get("id"));</p><p>System.out.println("name:" + doc.get("name"));</p><p>System.out.println("price:" + doc.get("price"));</p><p>System.out.println("pic:" + doc.get("pic"));</p><p>// System.out.println("description:" + doc.get("description"));</p><p>}</p><p>// 7. 释放资源</p><p>reader.close();</p><p>}</p><p>}</p><h1>1.分词器</h1><p>1.1. 分词理解</p><p>在对Docuemnt中的内容进行索引之前，需要使用分词器进行分词 ，分词的目的是为了搜索。分词的主要过程就是先分词后过滤。</p><p>l分词：采集到的数据会存储到document对象的Field域中，分词就是将Document中Field的值切分成一个一个的词。</p><p>l过滤：包括去除标点符号过滤、去除停用词过滤（的、是、a、an、the等）、大写转小写、词的形还原（复数形式转成单数形参、过去式转成现在式。。。）等。</p><p>什么是停用词？停用词是为节省存储空间和提高搜索效率，搜索引擎在索引页面或处理搜索请求时会自动忽略某些字或词，这些字或词即被称为Stop Words(停用词)。比如语气助词、副词、介词、连接词等，通常自身并无明确的意义，只有将其放入一个完整的句子中才有一定作用，如常见的“的”、“在”、“是”、“啊”等。</p><p>对于分词来说，不同的语言，分词规则不同。Lucene作为一个工具包提供不同国家的分词器，本例子使用StandardAnalyzer，它可以对用英文进行分词。</p><p>如下是org.apache.lucene.analysis.standard.standardAnalyzer的部分源码：</p><p>@Override</p><p><strong>protected</strong> TokenStreamComponents createComponents(<strong>final</strong> String fieldName, <strong>final</strong> Reader reader) {</p><p><strong>final</strong> StandardTokenizer src = <strong>new</strong> StandardTokenizer(getVersion(), reader);</p><p>src.setMaxTokenLength(maxTokenLength);</p><p>TokenStream tok = <strong>new</strong> StandardFilter(getVersion(), src);</p><p>tok = <strong>new</strong> LowerCaseFilter(getVersion(), tok);</p><p>tok = <strong>new</strong> StopFilter(getVersion(), tok, stopwords);</p><p><strong>return</strong> <strong>new</strong> TokenStreamComponents(src, tok) {</p><p>@Override</p><p><strong>protected</strong> <strong>void</strong> setReader(<strong>final</strong> Reader reader) <strong>throws</strong> IOException {</p><p>src.setMaxTokenLength(StandardAnalyzer.<strong>this</strong>.maxTokenLength);</p><p><strong>super</strong>.setReader(reader);</p><p>}</p><p>};</p><p>}</p><p>Tokenizer就是分词器，负责将reader转换为语汇单元即进行分词处理，Lucene提供了很多的分词器，也可以使用第三方的分词，比如IKAnalyzer一个中文分词器。</p><p>TokenFilter是分词过滤器，负责对语汇单元进行过滤，TokenFilter可以是一个过滤器链儿，Lucene提供了很多的分词器过滤器，比如大小写转换、去除停用词等。</p><p>如下图是语汇单元的生成过程：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37d8000396fd8b94798b></p><p>从一个Reader字符流开始，创建一个基于Reader的Tokenizer分词器，经过三个TokenFilter生成语汇单元Token。</p><p>比如下边的文档经过分析器分析如下：</p><p>Ø原文档内容：</p><table><tbody><tr class=firstRow><td><p>Lucene is a Java full-text search engine.</p></td></tr></tbody></table><p>Ø分析后得到的多个语汇单元：</p><table><tbody><tr class=firstRow><td><p>lucene 、java、full、text、search、engine</p></td></tr></tbody></table><p>1.1. Analyzer使用时机</p><p>1.1.1. 索引时使用Analyzer</p><p>输入关键字进行搜索，当需要让该关键字与文档域内容所包含的词进行匹配时需要对文档域内容进行分析，需要经过Analyzer分析器处理生成语汇单元（Token）。分析器分析的对象是文档中的Field域。当Field的属性tokenized（是否分词）为true时会对Field值进行分析，如下图：</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37df0003c40ee07cfe18></p><p>对于一些Field可以不用分析：</p><p>1、不作为查询条件的内容，比如文件路径</p><p>2、不是匹配内容中的词而匹配Field的整体内容，比如订单号、身份证号等。</p><p>1.1.1. 搜索时使用Analyzer</p><p>对搜索关键字进行分析和索引分析一样，使用Analyzer对搜索关键字进行分析、分词处理，使用分析后每个词语进行搜索。比如：搜索关键字：spring web ，经过分析器进行分词，得出：spring web拿词去索引词典表查找 ，找到索引链接到Document，解析Document内容。</p><p>对于匹配整体Field域的查询可以在搜索时不分析，比如根据订单号、身份证号查询等。</p><p><strong></strong><strong>注意：搜索使用的分析器要和索引使用的分析器一致。</strong></p><p>1.2. 中文分词器</p><p>1.2.1. 什么是中文分词器</p><p>学过英文的都知道，英文是以单词为单位的，单词与单词之间以空格或者逗号句号隔开。所以对于英文，我们可以简单以空格判断某个字符串是否为一个单词，比如I love China，love 和 China很容易被程序区分开来。</p><p>而中文则以字为单位，字又组成词，字和词再组成句子。中文“我爱中国”就不一样了，电脑不知道“中国”是一个词语还是“爱中”是一个词语。</p><p><strong>把中文的句子切分成有意义的词，就是中文分词，也称切词</strong>。我爱中国，分词的结果是：我、爱、中国。</p><p>1.2.2. Lucene自带中文分词器</p><p>lStandardAnalyzer：</p><p>单字分词：就是按照中文一个字一个字地进行分词。如：“我爱中国”，</p><p>效果：“我”、“爱”、“中”、“国”。</p><p>lCJKAnalyzer</p><p>二分法分词：按两个字进行切分。如：“我是中国人”，效果：“我是”、“是中”、“中国”“国人”。</p><p>上边两个分词器无法满足需求。</p><p>lSmartChineseAnalyzer</p><p>对中文支持较好，但扩展性差，扩展词库，禁用词库和同义词库等不好处理</p><p>1.3. 第三方中文分词器</p><p>lpaoding： 庖丁解牛最新版在 https://code.google.com/p/paoding/ 中最多支持Lucene 3.0，且最新提交的代码在 2008-06-03，在svn中最新也是2010年提交，已经过时，不予考虑。</p><p>lmmseg4j：最新版已从 https://code.google.com/p/mmseg4j/ 移至 https://github.com/chenlb/mmseg4j-solr，支持Lucene 4.10，且在github中最新提交代码是2014年6月，从09年～14年一共有：18个版本，也就是一年几乎有3个大小版本，有较大的活跃度，用了mmseg算法。</p><p>l<strong>IK-analyzer</strong>： 最新版在https://code.google.com/p/ik-analyzer/上，支持Lucene 4.10从2006年12月推出1.0版开始， IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开 始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词 歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。 但是也就是2012年12月后没有在更新。</p><p>lansj_seg：最新版本在 https://github.com/NLPchina/ansj_seg tags仅有1.1版本，从2012年到2014年更新了大小6次，但是作者本人在2014年10月10日说明：“可能我以后没有精力来维护ansj_seg了”，现在由”nlp_china”管理。2014年11月有更新。并未说明是否支持Lucene，是一个由CRF（条件随机场）算法所做的分词算法。</p><p>limdict-chinese-analyzer：最新版在 https://code.google.com/p/imdict-chinese-analyzer/ ， 最新更新也在2009年5月，下载源码，不支持Lucene 4.10 。是利用HMM（隐马尔科夫链）算法。</p><p>lJcseg：最新版本在git.oschina.net/lionsoul/jcseg，支持Lucene 4.10，作者有较高的活跃度。利用mmseg算法。</p><p>1.4. 使用中文分词器IKAnalyzer</p><p>IKAnalyzer继承Lucene的Analyzer抽象类，使用IKAnalyzer和Lucene自带的分析器方法一样，将Analyzer测试代码改为IKAnalyzer测试中文分词效果。</p><p>如果使用中文分词器ik-analyzer，就需要在索引和搜索程序中使用一致的分词器：IK-analyzer。</p><p>1.4.1. 添加jar包</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37df0003c44d3d172f9c></p><p>1.1.1. 修改分词器代码</p><p>@Test</p><p><strong>public</strong> <strong>void</strong> testCreateIndex() <strong>throws</strong> Exception {</p><p>// 1. 采集数据</p><p>BookDao bookDao = <strong>new</strong> BookDaoImpl();</p><p>List&lt;Book> bookList = bookDao.queryBookList();</p><p>// 2. 创建Document文档对象</p><p>List&lt;Document> documents = <strong>new</strong> ArrayList&lt;>();</p><p><strong>for</strong> (Book book : bookList) {</p><p>Document document = <strong>new</strong> Document();</p><p>// Document文档中添加Field域</p><p>// 图书Id</p><p>// Store.YES:表示存储到文档域中</p><p>document.add(<strong>new</strong> TextField("id", book.getId().toString(), Store.<strong>YES</strong>));</p><p>// 图书名称</p><p>document.add(<strong>new</strong> TextField("name", book.getName().toString(), Store.<strong>YES</strong>));</p><p>// 图书价格</p><p>document.add(<strong>new</strong> TextField("price", book.getPrice().toString(), Store.<strong>YES</strong>));</p><p>// 图书图片地址</p><p>document.add(<strong>new</strong> TextField("pic", book.getPic().toString(), Store.<strong>YES</strong>));</p><p>// 图书描述</p><p>document.add(<strong>new</strong> TextField("description", book.getDescription().toString(), Store.<strong>YES</strong>));</p><p>// 把Document放到list中</p><p>documents.add(document);</p><p>}</p><p>// 3. 创建Analyzer分词器,分析文档，对文档进行分词</p><p>// Analyzer analyzer = new StandardAnalyzer();</p><p>Analyzer analyzer = <strong>new</strong> IKAnalyzer();</p><p>// 4. 创建Directory对象,声明索引库的位置</p><p>Directory directory = FSDirectory.open(<strong>new</strong> File("C:/itcast/lucene/index"));</p><p>// 5. 创建IndexWriteConfig对象，写入索引需要的配置</p><p>IndexWriterConfig config = <strong>new</strong> IndexWriterConfig(Version.<strong>LUCENE_4_10_3</strong>, analyzer);</p><p>// 6.创建IndexWriter写入对象</p><p>IndexWriter indexWriter = <strong>new</strong> IndexWriter(directory, config);</p><p>// 7.写入到索引库，通过IndexWriter添加文档对象document</p><p><strong>for</strong> (Document doc : documents) {</p><p>indexWriter.addDocument(doc);</p><p>}</p><p>// 8.释放资源</p><p>indexWriter.close();</p><p>}</p><p>1.2. 扩展中文词库</p><p>如果想配置扩展词和停用词，就创建扩展词的文件和停用词的文件。</p><p>注意：不要用window自带的记事本保存扩展词文件和停用词文件，那样的话，格式中是含有bom的。</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37dd0001db20abeceb0e></p><p>从ikanalyzer包中拷贝配置文件</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37df0003c5003936cc5a></p><p>拷贝到资源文件夹中</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37d900038e2c5f8d9993></p><p>IKAnalyzer.cfg.xml配置文件</p><p>&lt;?xml version="1.0" encoding="UTF-8"?></p><p>&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"></p><p>&lt;properties></p><p>&lt;comment>IK Analyzer 扩展配置&lt;/comment></p><p>&lt;!--用户可以在这里配置自己的扩展字典 --></p><p>&lt;entry key="ext_dict">ext.dic;&lt;/entry></p><p>&lt;!--用户可以在这里配置自己的扩展停止词字典--></p><p>&lt;entry key="ext_stopwords">stopword.dic;&lt;/entry></p><p>&lt;/properties></p><p>中文词库，添加新词的地方</p><p>最终分词效果</p><p><img alt=Lucene（全文检索）进阶-第二篇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37d800039a7c1c7bb4c7></p><p>持续发布中，敬请关注。如有问题，欢迎交流指正。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Lucene','检索','进阶'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>