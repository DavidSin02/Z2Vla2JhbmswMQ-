<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望 | 极客快訊</title><meta property="og:title" content="论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><meta property="article:published_time" content="2020-11-14T21:08:27+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:27+08:00"><meta name=Keywords content><meta name=description content="论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/e55aaf9b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong class=highlight-text toutiao-origin=span>《测绘学报》</strong></p><p><strong class=highlight-text toutiao-origin=span>构建与学术的桥梁 拉近与权威的距离</strong></p><p><strong>航摄影像密集匹配的研究进展与展望</strong></p><p>袁修孝<sup>1</sup><img alt="论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY>, 袁巍<sup>1,2</sup>, 许殊<sup>1,3</sup>, 纪艳华<sup>1</sup></p><p>1. 武汉大学遥感信息工程学院, 湖北 武汉 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">30</i>0<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">79</i>;</p><p>2. 东京大学空间信息科学中心, 东京 柏市 277-6568;</p><p>3. 中国科学院空天信息创新研究院, 北京 100094</p><p>收稿日期：2019-10-31；修回日期：2019-11-20</p><p>基金项目：国家自然科学基金(4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">177</i><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">147</i>9);国家高分专项(民用部分)(50-H31D01-0508-13/15)</p><p>第一作者简介：袁修孝(1963-), 男, 博士, 教授, 博士生导师, 主要研究航空航天遥感高精度对地目标定位理论与方法、高分辨率卫星遥感影像几何处理等。E-mail:yuanxx@whu.edu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">.cn</i></p><p><strong>摘要</strong>：给出了航摄影像密集匹配的总体流程，依据是否显式使用光滑假设将密集匹配方法分为局部最优密集匹配和全局最优密集匹配两类，深入探讨了两种方法的关键技术，指出了从理论、技术、普适性和实用性方面值得<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">关注</i>的问题，期望能对相关研究有所裨益。</p><p>关键词：航摄影像 密集影像匹配 局部最优匹配 全局最优匹配 光流场法 深度学习方法</p><p><strong>Research developments and prospects on dense image matching in photogrammetry</strong></p><p>YUAN Xiu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">xi</i>ao<sup>1</sup>, YUAN Wei<sup>1,2</sup>, XU Shu<sup>1,3</sup>, JI Yanhua<sup>1</sup></p><p>1. School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">30</i>0<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">79</i>, China;</p><p>2. Center for Spatial Information Science, University of Tokyo, Kashiwa 2776568, Japan;</p><p>3. Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China</p><p>Foundation support: The National Natural Science Foundation of China (No. 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">177</i><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">147</i>9); The National High-Resolution Earth Observation System (the Civil Part) (No. 50-H31D01-0508-13/15)</p><p>First author: YUAN Xiu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">xi</i>ao(1963—), male, PhD, professor, PhD supervisor, majors in theory and method for high precision airborne and spaceborne photogrammetric positioning and geometric processing of high-resolution satellite remote sensing imagery.E-mail:yuanxx@whu.edu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">.cn</i>.</p><p><strong>Abstract</strong>: The general workflow for dense matching of aerial images is given in this paper. Dense matching is divided into two categories, namely, those that utilize local matching algorithms and global matching algorithms, respectively. The key technologies of the two methods are analyzed in details. Concerns in theory, technology, universality and practicability are proposed. We hope it will be helpful to the related research on dense matching.</p><p>Key words: aerial image dense image matching local matching algorithm global matching algorithm optical flow field-based method deep learning-based method</p><p>航摄影像密集匹配是在获得影像间的相对位置关系之后于重叠区域内寻找每个像素同名像点的稠密影像匹配方法，是从二维航摄影像自动重建三维物体模型的最有效手段之一。由此生成的三维点云具有位置精准、密度甚高、纹理丰富、逼真度好、成本低廉等特点，不但可用于数字表面模型(digital surface model, DSM)、数字高程模型(digital elevation model, DEM)和数字正射影像图(digital orthphoto map, DOM)等地理信息的自动提取，而且可为数字/智慧城市建设直接提供目标三维座标源数据<sup>[1</sup><sup>-2</sup><sup>]</sup>。</p><p>航摄影像的密集匹配不同于影像量测的稀疏匹配<sup>[3</sup><sup>]</sup>，主要表现在：①点位不可选择。密集影像匹配要尽可能地做到逐像素匹配，这就无法回避较大几何畸变、弱纹理及重复纹理等特殊纹理区域。②<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>策略不一样。密集影像匹配通常是在核线影像上设定的视差范围内进行一维<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>，而稀疏影像匹配往往需要在一个较大的平面区域或者核线段内进行遍历。③复杂度不一致。密集影像匹配的代价或流程不宜太复杂，否则会因计算机的性能限制或耗时太长而缺乏实用价值，稀疏影像匹配由于只需对特定的特征点进行识别，即使是设计出相对复杂的描述符或流程往往也是可以接受的。④匹配约束不相同。密集影像匹配由于需要对每个像素都识别同名像点，很容易施加普遍的显式光滑约束，而稀疏影像匹配一般无须这样处理。</p><p>纵观现行的航摄影像密集匹配方法，根据所采用的图像基元可以将其分为基于灰度的密集匹配、基于特征的密集匹配和基于相位的密集匹配3大类型。基于灰度的密集匹配能够获得非常稠密的匹配点云，但其精度受影像几何和辐射畸变的影响较大，像素点约束窗口的大小和形状难以选择；基于特征的密集匹配可以得到高精度的匹配点云，但特征提取计算代价太大，容易受到地物遮蔽、纹理重复等因素的影响，匹配效率比较低；基于相位的密集匹配一般不太适合于光学遥感影像。另一方面，根据所采用的优化理论又可以将影像密集匹配分为局部最优密集匹配和全局最优密集匹配两种。前者虽然效率高，但是误匹配点较多，精度比较低；后者虽然能够得到整体高精度的匹配点云，但是优化代价太大，匹配效率不高。为此，本文拟对当前广泛应用的密集影像匹配方法进行综合分析和探讨，以期对相关的研究起到抛砖引玉的作用。</p><p><strong toutiao-origin=span>1 密集影像匹配的总体流程</strong></p><p>航摄影像的密集匹配可以对单个立体影像对<sup>[4</sup><sup>-5</sup><sup>]</sup>、也可以对多度重叠的多视影像序列<sup>[6</sup><sup>-7</sup><sup>]</sup>进行。在获得影像的内、外方位元素或者影像的相对方位元素的前提下，实施过程大体分为核线影像生成、匹配代价计算、匹配代价聚合、视差计算与精化、三维点云生成几个主要步骤。其一般流程可描述为图 1。</p><img alt="论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RnOpWS8FDt1USz><p>图 1 航摄影像密集匹配Fig. 1 Dense image matching for aerial images</p><p>图选项</p><p><strong toutiao-origin=span>2 现行的密集影像匹配方法</strong><strong toutiao-origin=span>2.1 局部最优密集匹配</strong></p><p>局部最优密集匹配通过计算待匹配点与周围局部邻域点的匹配代价，隐式地使用光滑假设约束，采用WTA(winner-takes-all)策略选取匹配代价最小点作为同名像点<sup>[8</sup><sup>]</sup>。由于这类方法大多采用矩形窗口进行匹配代价聚合，所以又称为基于窗口的密集影像匹配。最具代表性的有基于绝对误差和(sum of absolute differences, SAD)<sup>[9</sup><sup>]</sup>、绝对平方差和(sum of squared differences, SSD)<sup>[10</sup><sup>]</sup>测度的密集匹配和基于相关系数的密集匹配<sup>[11</sup><sup>]</sup>等。这类方法的优势在于计算复杂度低，冗余计算量少<sup>[12</sup><sup>]</sup>；缺点是容易陷入局部最优，导致匹配结果与真实地形不太相符<sup>[13</sup><sup>-15</sup><sup>]</sup>。究其原因就在于：①假设视差在匹配窗口内一致，与事实明显不符，导致在影像深度不连续处(多为地物边缘)和遮蔽区域的匹配效果不佳；②由于同谱异物现象，使算法出现病态，无法正确找到同名像点，特别是在影像纹理贫乏区匹配效果较差。为此，在代价聚合方式上逐渐演化出如下3种解决方案。</p><p><strong toutiao-origin=span>2.1.1 窗口形状改变法</strong></p><p>这类方法通过调节匹配窗口的形状，或者从多个窗口中选择一个视差较为一致的窗口，来解决匹配窗口视差不一致的问题，同时也希望通过扩大窗口来最大限度地提高匹配的可靠性。早期的研究有移动窗口法<sup>[9</sup><sup>]</sup>和形状自适应窗口法<sup>[16</sup><sup>]</sup>。这类方法对以目标像素为中心的匹配窗口聚合代价，前者将窗口内的最小代价直接赋给待匹配像素，本质上是以内部更加一致的窗口代替了邻近或横跨边缘的聚合窗口，使视差不连续处的匹配效果得以改善，以牺牲地物的边缘信息为代价；后者是在假设匹配窗口内视差满足一定条件(譬如高斯分布)的前提下，通过窗口内视差的均值和方差来获得不确定度，依此选择窗口变化的方向和大小。这种方法简化了现实场景的复杂度，增加了不确定度的迭代计算量。此后，人们又提出了基于十字的代价聚合方法<sup>[17</sup><sup>]</sup>。它依据颜色相近的像素很有可能具有一样视差的假设，在某个阈值下为每个像素判断出连续的十字范围，通过截取目标像素水平臂上相应像素的垂直臂的并集来获得代价聚合区域，取得了比较好的试验结果。由于方法高度的规则性，代价聚合可以通过积分影像技术进行加速，但阈值需要根据匹配效果来人工调节。</p><p><strong toutiao-origin=span>2.1.2 窗口权重改变法</strong></p><p>这类方法是在匹配代价聚合过程中通过改变匹配窗口内原始代价的权值来实现的，分为基于滤波的和基于分割的两种方法。</p><p>滤波的方法是依据颜色一致区域的视差非常接近、连续区域具有更加相近的视差的假设，确定匹配窗口内每个像素的权重，以此来进行匹配代价聚合。其本质是对不满足窗口假设条件的代价赋予小的权值<sup>[18</sup><sup>]</sup>。具体说来，就是用与中心像素的几何距离以及与中心像素颜色的差异来定权。离中心像素越远、颜色差异越大，其权值就越小。这种方法首次将局部匹配方法的正确率提升到了与全局方法相当的程度，但由于其需要大量的重复计算，效率比较低。此外，由于地物边缘处会出现颜色相近像素较少的情况，效果明显变差。为了提高密集影像匹配的效率，人们又进行了一系列的改进<sup>[19</sup><sup>-20</sup><sup>]</sup>，加速了匹配代价聚合的过程。文献[18]的假设在大多数情况下都能满足，但在复杂空间中颜色相近、视差相距甚远的情况也时有发生。文献[21]用测地线距离定权来解决这个问题，即当目标像素与中心像素有一条通路上的颜色没有明显改变时，可以获得较大的权值，以此来附加聚合区域的联通约束。这种改进，对区域相对简单的场合比较有效，但对于结构高度复杂的区域，由于定权方式所导致的聚合区域过小而变得效果不佳。沿着这种滤波思路，人们相继又提出了旨在提高计算效率并解决边缘支持度不足的基于引导滤波的定权方法<sup>[22</sup><sup>-23</sup><sup>]</sup>和利用空间通道可靠性定权的方法<sup>[24</sup><sup>]</sup>。</p><p>分割的方法是假定分割块的边缘与深度不连续处保持一致，且在每个分割块内的视差保持一致或满足某种关系(譬如仿射变换)，并以待匹配点是否落在分割块内作为定权的一个重要参考依据<sup>[25</sup><sup>]</sup>。文献[26]使用Mean Shift方法所获得的分割结果作为辅助，给聚合窗口内与中心像素处于同一个分割块的匹配代价以高权值，将位于其他分割块内的匹配代价视为粗差，给予其低权值直至零值。文献[27]顾及了对称的两张影像的分割，以避免遮蔽等在使用一张影像时的影响。这类方法依赖于影像分割的质量，新分割方法(如SLIC分割<sup>[28</sup><sup>]</sup>)的应用常常会促进方法的进步。尽管该类方法始于分割和局部匹配，但目前还是倾向于同时确定分割和视差、面向对象的匹配、语意匹配<sup>[29</sup><sup>-33</sup><sup>]</sup>等全局方法。</p><p><strong toutiao-origin=span>2.1.3 非前向平行窗口法</strong></p><p>与前面两类方法不同，这类方法采用了非前向平行的聚合窗口，在处理与影像面有较大夹角的空间结构时，具有更好的匹配效果。其关键在于如何估计符合场景的斜面的方向。早期尝试了平面聚类方法<sup>[34</sup><sup>-35</sup><sup>]</sup>，通过估计并使用非前向平行平面进行代价聚合和视差确定。此后，基于面片匹配的方法<sup>[36</sup><sup>-37</sup><sup>]</sup>为每个像素随机生成初始视差及视差空间的法向量。依据空间相邻像素和左右影像上潜在的同名像点具有同一参数的准则，通过比较利用邻近像素和潜在同名点参数与使用当前点参数所计算出的匹配代价，选定一组更能符合实际情况的参数，并取代价小的参数作为新参数。为了进一步减小匹配代价，这类方法对选定的参数进行了精化。具体做法是在参数允许的最大变化范围内，在原始参数上随机地<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">加上</i>一个增量，观察是否减小了代价。若减小了，则更新为新参数。否则，继续增加，直至减小为止。在随机初始化后，面片匹配方法希望能在具有相同或相近参数的区域中至少找到一个像素对应的参数能够接近正确参数值。这类方法的缺点是：①因为随机过程有可能遗漏了正确的候选视差，而根本无法获得正确的匹配结果；②空间传播和视传播并非并行模式，不利于加速计算；③没有显式的光滑约束。针对这些问题，又衍生出了许多改进的方法。譬如，通过增加候选视差产生方式来避免遗漏；开始时为每一个像素准备好所有可能的参数，并非通过传播和精化手段来逐渐增加，以利于并行处理；将其运用在全局方法中以显式地建立光滑约束。</p><p>以上3种方法中，窗口形状改变法和窗口权重改变法是在使用前向平行窗口时，努力使聚合窗口内的视差保持一致，而非前向平行窗口法则是使用了倾斜窗口，以便尽可能地估计出与实际情况相符的支持区域。</p><p><strong toutiao-origin=span>2.2 全局最优密集匹配</strong></p><p>全局最优密集匹配是通过构建全局能量函数来优化基于像素或者基于对象的匹配代价的，通过显示式地使用光滑假设约束及相应的优化方法来获取视差图，从而找到同名像点，使得最终的匹配结果达到全局最优<sup>[38</sup><sup>]</sup>。在全局能量函数构建中，将像素间的光度相似性构成了代价函数的数据项，将对相近像素视差的变化约束惩罚构成了代价函数的光滑项。由于顾及了影像中每个像素的信息，匹配精度较高，但冗余计算较大，匹配效率比较低。目前的研究主要集中在全局能量函数的构建和优化求解上。在匹配代价计算上，主要采用了基于互信息的匹配代价<sup>[39</sup><sup>]</sup>、基于梯度的匹配代价<sup>[40</sup><sup>]</sup>、基于Census变换的匹配代价<sup>[10</sup><sup>]</sup>和来自于深度学习的匹配代价<sup>[41</sup><sup>-42</sup><sup>]</sup>；在优化求解上，除了采用传统的模拟退火<sup>[43</sup><sup>]</sup>、动态规划<sup>[44</sup><sup>]</sup>等方法以外，图割优化<sup>[45</sup><sup>-46</sup><sup>]</sup>、置信度传播<sup>[47</sup><sup>-48</sup><sup>]</sup>等一系列方法的应用，使该类方法得以长足的发展。</p><p>为了能够充分发挥全局最优密集匹配精度高和局部最优密集匹配速度快的优势，文献[39]最早提出了半全局密集匹配(semi-global matching, SGM)方法。其基本思想来源于线性规划，通过多方向动态规划提高了计算效率，但在影像匹配时并没有考虑到全部像素，仅顾及了所有的非遮蔽点，相对于全局匹配和局部匹配方法而言，其精度和效率都有了不同程度的提高。具体表现为，在对相邻像素视差依据其变化的程度差异给予不同惩罚值之后，首先对原始的全局方法分别按照8个或16个方向进行1维扫描线优化，然后通过<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">累加</i>多个方向的代价而获得整体的聚合代价，最后运用WTA方法获得每一个像素对应的视差值，从而导出同名像点。然而，这类方法存在的主要问题是扫描线优化时需要人为设定控制视差变化的两个惩罚因子。惩罚过大则在视差断裂处易出现过度平滑的情况，惩罚过小则在平滑区域会受噪声影响而产生凹凸不平的现象。SGM方法曾试图使用影像梯度来克服这个问题，即在高梯度区域使用低惩罚，在低梯度区域使用高惩罚。但是，由于影像梯度大的地方并不完全对应着深度不连续区域，因此在影像复杂纹理区域其效果并不理想。目前效果较好的遥感影像密集匹配商用软件SURE<sup>[49</sup><sup>]</sup>采用了Canny边缘检测算子来自适应地调整匹配参数，在一定程度上缓解了上述矛盾，但对影像灰度噪声仍相当<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">敏感</i>。文献[2]通过分析核线影像的纹理信息，使用局部梯度、标准差计算纹理指标，在纹理缺乏区域施加较大视差连续性约束，在纹理丰富区域保留更大的匹配代价权重，以达到自适应调整参数的目的。文献[5]充分利用稀疏匹配所获得的较为可靠的匹配点作为约束，改善了密集匹配的效果。</p><p>为了提高航摄影像密集匹配对遮蔽和噪声的稳健性，多视影像的密集匹配方法成为了另一个研究主题。计算机视觉中顾及了多视影像间的几何关系和冗余信息的基于面片的密集匹配算法被引入了摄影测量领域。通过提取到的影像中的稀疏特征点，构建若干小的特征面片集合，经匹配传播达到密集匹配的效果<sup>[50</sup><sup>-52</sup><sup>]</sup>。文献[7]提出的基于面片的多视影像匹配(patch-based multi-view stereo, PMVS)方法备受推崇。由于PMVS不需要先验知识和初始化设置，并且适用于大场景影像的三维重建，被广泛应用于无人机低空摄影测量中。Ai等将高精度的稀疏匹配点输入PMVS作为种子点，对无人机航摄影像进行密集匹配，<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">大大</i>提高了PMVS的效率<sup>[53</sup><sup>]</sup>。文献[54]将PMVS的匹配点作为初始值构建扩张的面片集，通过最小二乘精化和MPGC(multi-photo geometrical constrained)方法对面片中匹配点的位置进行调整，提高了匹配结果对遮蔽和噪声的稳健性，获得的匹配点云更加稠密<sup>[55</sup><sup>]</sup>。</p><p>在综合分析SGM和PMVS算法的基础上，文献[56]于2016年率先将光流场引入航摄影像的密集匹配中，提出了一种基于光流场的航摄立体影像密集匹配方法(optical flow field-based dense image matching, OFFDIM)。其基本思想是以稀疏匹配所提取的高精度像片连接点作为种子点，运用基于特征金字塔L-K方法和基于三角网多层B样条插值方法，快速估计出立体影像对重叠区域内的密集光流场，得到逐像素的粗匹配点，然后<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">结合</i>几何约束和影像纹理信息，采用基于Census变换的匹配代价，运用快速引导滤波优化算法对初始视差图进行精化，以此为基础对粗匹配点进行逐一修正，以提取密集匹配点云。这种方法充分利用光流场信息，采用由粗到精的金字塔匹配策略，缩小了影像匹配的<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>范围，减少了大量的冗余计算，可用于宽基线大幅面航摄影像的密集匹配。经对普通数字航摄影像和无人机低空航摄影像的试验，真正实现了逐像素的密集匹配，达到了子像素级的匹配精度，速度快，可靠性高，完全可以满足摄影测量中的目标三维重建、DSM/DOM自动生成等的应用需求<sup>[57</sup><sup>]</sup>。</p><p>近年来，随着深度学习的飞速发展，众多深度神经网络模型被运用于影像密集匹配中。基于深度学习的密集匹配方法大体上可分为分布式方法和端到端方法两类。分布式方法通常运用深度神经网络模型计算立体像对间的匹配代价<sup>[42</sup><sup>, 58</sup><sup>]</sup>，然后采用传统的匹配代价聚合方法生成视差图，从而找到同名像点。相较于传统的逐像素密集匹配方法，其在常规纹理区域的匹配精度有显著的提高。然而，在纹理贫乏、地物遮蔽和光照较强区域，其匹配效果依然不尽人意。端到端方法通过在深度神经网络模型中加入三维卷积层，达到计算匹配代价聚合的目的<sup>[59</sup><sup>-61</sup><sup>]</sup>。这类方法进一步提高了密集匹配的精度，但由于三维卷积计算的大量内存消耗和高计算复杂度，通常只能处理较小的影像块，其实用性远不如传统密集方法和分布式方法。此外，基于深度学习的密集方法对输入的训练标签有着极强的依赖性。训练数据中，每个像素都必须提供相应的深度真值或者视差真值，这类训练数据通常由人为准备，这也使得其普适性和适用性比较差。</p><p><strong toutiao-origin=span>2.3 两种密集匹配方法的比较</strong></p><p>总体说来，局部最优密集匹配方法比全局最优密集匹配方法简单快速，但正确率和精度要稍逊一筹，表 1对这两类方法作了简要的比较。此外，大多数全局最优密集匹配方法借鉴了局部最优密集匹配方法的代价聚合模式，这就使得后者的很多优点在前者中得以体现。实际应用中，两种方法是存在互补的。</p><p>表 1 局部最优与全局最优密集匹配方法的比较Tab. 1 Comparision between local matching algorithm and global matching algorithm</p><table><thead><tr><td>密集匹配方法</td><td>光滑约束</td><td>正确率</td><td>速度</td><td>计算机内存占用</td><td><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">关注</i>要点</td><td>约束引入</td></tr></thead><tbody><tr><td>局部最优</td><td>隐式</td><td>较高</td><td>快</td><td>少</td><td>代价聚合</td><td>难</td></tr><tr><td>全局最优</td><td>显式</td><td>高</td><td>较快</td><td>多</td><td>建模优化</td><td>易</td></tr></tbody></table><p>表选项</p><p>图 2为采用国际摄影测量与遥感学会(ISPRS)公开的数据集，在德国Vahingen地区利用DMC相机获取的多光谱合成影像(相机主距120 mm, 像幅7680×13 824像素，像元大小12.0 μm, 航向重叠度为60%)，使用SGM、PMVS和OFFDIM的匹配点云图，从中可以清楚看出它们在匹配效果上的差异。</p><img alt="论文推荐 | 袁修孝：航摄影像密集匹配的研究进展与展望" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RnOpWSs3ugyrsM><p>图 2 利用半全局密集影像匹配生成的点云Fig. 2 Dense 3D point clouds acquired by semi-globe dense image matching for single stereo image pairs</p><p>图选项</p><p><strong toutiao-origin=span>3 展望</strong></p><p>目前，航摄影像的密集匹配普遍采用半全局匹配方法，一批以SURE、PhotoScan、Smart3D为代表的商业软件也相继推向了市场，但人们对密集匹配算法的研究依然表现出了浓厚的兴趣。如何获得更优的匹配代价、采用更好的匹配代价聚合方式、更合理地构建全局能量方程及其优化求解，依然是当前密集影像匹配的桎梏。近些年来，出现了大量的利用卷积神经网络获取匹配代价、顾及影像边缘的自适应代价聚合<sup>[63]</sup>、置信度传播、图割优化等技术，已成为密集影像匹配新的研究热点。尽管如此，笔者认为以下4个方面的问题值得<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">关注</i>：</p><p>(1) 如何构建更能反映像素间相似度的数据项是密集匹配的理论基础。事实上，我们无法建立真实反映像素间相似度的数据项，原因就在于现实世界中异物同谱现象的存在以及摄影曝光和光照的不同，有些像素不再满足光度一致性条件；而且由于航摄影像场景复杂，地物相互遮挡、地形突变致深度不连续、纹理重复等现象，给密集匹配带来了极大的挑战。在动态规划的框架下，计算错误的数据项往往会影响邻域点的视差估计，并将错误扩散。因此，构建更能反映像素间相似度的数据项模型，对于减少误匹配、提高密集影像匹配的精度和可靠性是至关重要的。稳健的数据项应对航摄场景中的复杂地形变化、光照变化等噪声不<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">敏感</i>，能很好地顾及重复纹理、深度不连续等的影响因素。</p><p>(2) 如何自适应设定可估计像素间视差不连续的平滑项是非局部密集匹配的技术关键。平滑项是对相邻像素间的视差不连续性的惩罚因子，非局部密集匹配平滑项存在的主要问题是需要人为设定控制视差变化的两个惩罚参数。为了保持视差的平滑，非局部密集匹配算法的平滑项采用双参数<em>P</em><sub>1</sub>和<em>P</em><sub>2</sub>(<em>P</em><sub>2</sub>><em>P</em><sub>1</sub>)来建立相邻像素间视差的光滑约束，用参数表达惩罚强度。惩罚参数<em>P</em><sub>1</sub>和<em>P</em><sub>2</sub>的选择对最终的匹配结果有较大的影响：参数过大则容易在深度不连续处过度平滑，导致无法保持地物边缘等重要特征；参数过小则难以保证视差平滑，产生明显的匹配噪声，造成凹凸不平的现象。现行方法对整个立体像对采用同一参数，是难以适应不同地形条件的，往往会导致物体边缘不锐利，前景视差延伸到地面等问题，使生成的DSM、DOM的地物边缘带有明显的毛刺。</p><p>(3) 如何有效消除地物遮蔽处及特殊纹理区域的匹配空洞是密集匹配的普适性问题。密集匹配的终极目标是能够达到影像重叠区域内的逐像素匹配，对于纹理丰富、视差比较连续的影像区域，实现这一目标并非难事，但对于影像遮蔽区域，特别是在高楼林立、阴影交错的城区以及纹理重复的森林和农田地区，公认的半全局匹配经常会产生较大范围的点云空洞。基于光流场的密集影像粗匹配能够真正实现像素级的逐像素密集匹配，但为了生成子像素级的高精度DSM，精匹配算法还有待改进。无论是精化算法的本身，还是多度重叠序列影像的整体匹配策略，都值得进一步探讨。</p><p>(4) 如何通过并行计算提高影像匹配的效率是密集匹配的实用性问题。当前的密集匹配方法大多来自于计算机视觉领域，算法均是针对短基线的小幅面影像而设计，航摄影像一般是宽基线的大幅面影像序列，密集影像匹配的计算复杂度非常高、匹配结果的数据海量、误匹配率也很高，这不但对计算机的内外存储器、计算性能等硬件指标提出了苛刻的要求，而且也要求在匹配和误匹配点剔除等算法的程序实现上尽可能地采用诸如影像分块、CPU多线程并行处理、GPU加速计算等技术，使1亿像素幅面影像对的密集匹配时间可以控制在分钟级的可接受范围内。</p><p>【引文格式】袁修孝, 袁巍, 许殊, 等. 航摄影像密集匹配的研究进展与展望. 测绘学报，2019，48(12)：<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">154</i>2-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">155</i>0. DOI: 10.11947/j.AGCS.2019.20190453</p><p></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'论文','推荐','袁修'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>