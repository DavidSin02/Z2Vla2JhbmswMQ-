<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020 | 极客快訊</title><meta property="og:title" content="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RqSgmP9HojtMNK"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e6f09df.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e6f09df.html><meta property="article:published_time" content="2020-10-29T21:01:04+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:04+08:00"><meta name=Keywords content><meta name=description content="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/e6f09df.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqSgmP9HojtMNK><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RwbvBUd8jBuBiK><p>作者 | VincentLee</p><p>来源 | 晓飞的算法工程笔记</p><p>在训练过程中，特征值梯度的回传和权值梯度的计算占了大部分的计算消耗。由于这两个操作都是以特征值梯度作为输入，而且零梯度不会占用计算资源，所以稀疏化特征值梯度可以降低回传阶段的计算消耗以及内存消耗。论文的目标在于高效地降低训练负载，从而在资源有限的平台进行大规模数据集的训练。</p><p>本论文假设特征值梯度服从正态分布，基于此计算阈值，随后使用随机剪枝算法(stochastic pruning)将小于阈值的特征值梯度随机置为零或。经理论推理和实验证明，这种方法不仅能够有效地稀疏化特征值梯度，还能在加速训练的同时，不影响训练的收敛性。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqMqLxPCXik3SR><p></p><h1 toutiao-origin=h1>General Dataflow</h1><p>卷积层通常包含4个阶段：推理、特征值梯度回传、权值梯度计算和权值更新。为了表示这些阶段的计算，论文定义了一些符号：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDczvGSHam2N><p>卷积层的四个训练阶段的总结为：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDd0kizx4gi><p>论文通过可视化发现，回传阶段的特征值梯度几乎全是非常小的、接近于零的值，自然而然地想到将这些值去掉不会对权值更新阶段造成很大的影响，所以论文认为剪枝特征值梯度能够加速卷积层在训练时的计算。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqMqLy93x95UEx><p><strong>Sparsification Algorithms</strong></p><p><strong toutiao-origin=span>Distribution Based Threshold Determination (DBTD)</strong></p><p>剪枝操作最关键的步骤是决定选择哪些元素进行消除，先前有研究使用最小堆进行元素选择，但这会带来较大的额外计算开销。为此，论文采用简单的阈值过滤进行元素选择。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDd16Fg6ArP4><p>论文首先分析了两种经典的卷积网络结构的特征值梯度分布：Conv-ReLU结构和Conv-BN-ReLU结构：</p><ul><li><p>对于Conv-ReLU结构，输出的特征值梯度是稀疏的，但其分布是无规律的，而结构的输入特征值梯度几乎全是非零值。通过统计发现，的分布以零值对称分布，且密度随着梯度值的增加而下降。</p></li><li><p>对于Conv-BN-ReLU结构，BN层设置在卷积层与ReLU层中间，改变了梯度的分布，且的分布与类似，。</p></li></ul><p>所以，上述的两种结构的梯度都可认为服从零均值、方差为的正态分布。对于Conv-ReLu结构，由于ReLU不会降低稀疏性，能够继承的稀疏性，将是作为Conv-ReLU结构中的剪枝目标梯度。而对于Conv-BN-ReLU结构，则将作为剪枝目标。这样，两种结构的剪枝目标都可统一为正态分布。假设的数量为，可以计算梯度的绝对值的均值，并得到该均值的期望为：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdPGEqyZFhp><p>这里的期望为从分布中采样个点的期望，而非分布的整体期望，再定义以下公式</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S8KDdPnGEDpV44><p>将公式2代入公式1中，可以得到：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdQ6GXvV0GV><p>从公式3可以看出为参数的无偏估计，接近于真实的均值，且的整体计算消耗是可以接受的。基于上面的分析，论文结合正态分布的累积函数、剪枝率和计算阈值：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdQQ6Mh28ty><p></p><h2 toutiao-origin=h3><strong toutiao-origin=span>Stochastic Pruning</strong></h2><p>剪枝少量值较小的梯度几乎对权值的更新没有影响，但如果将这些值较小的梯度全部设为零，则会对特征值梯度的分布影响很大，进而影响梯度更新，造成严重的精度损失。参考Stochastic Rounding算法，论文采用随机剪枝来解决这个问题。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdQg8wuzlwH><p>随机剪枝逻辑如算法1所示，对于小于阈值的梯度值，随机采样一个缩放权重来计算新阈值，再根据新阈值将梯度值置为零或。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S8KDdr8GaY6PbX><p>随机剪枝的效果如图2所示，能够在保持梯度分布的数学期望的情况下进行剪枝，与当前的方法相比，论文提出的方法的优点如下：</p><ul><li><p>Lower runtime cost：DBTD的计算复杂度小于top-k算法，且DBTD对硬件更友好，能够在异构平台实现。</p></li><li><p>Lower memory footprint：随机裁剪能保持收敛性，且不需要存储而外的内存。</p></li></ul><p>至此，Sparsification Algorithms在梯度回传时的特征值梯度计算为：</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdrW7NPaxqj><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqMqMYY7LcGio6><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S8KDdro6RGyQZn><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDdsADXlXPel><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S8KDdsd7qezEcU><p>在CIFAR-10、CIFAR-100以及ImageNet上进行准确率验证。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S8KDeOwQPh4x1><p>在CIFAR-10和ImageNet上进行收敛性验证。</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S8KDePi9E2W7Jo><p>在不同的设备上进行加速效果验证。</p><h1 toutiao-origin=h1><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqMqMZM85xvsbJ><br></h1><p></p><h1 toutiao-origin=h1>结论</h1><p>论文通过DBTD方法计算过滤阈值，再结合随机剪枝算法对特征值梯度进行裁剪，稀疏化特征值梯度，能够降低回传阶段的计算量，在CPU和ARM上的训练分别有3.99倍和5.92倍的加速效果。</p><p>论文提出的特征值稀疏化算法看似很简单，其实进行了充分的理论推导以及实验验证，才得到最终合理的过滤方法，唯一可惜的是没在GPU设备上进行实验验证。论文对算法的收敛性以及期望有详细的理论验证，不过这里没有列出来，有兴趣的可以去看看原文。</p><p>论文地址：</p><p>https://arxiv.org/abs/1908.00173</p><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/R69FpRH4d90a7d><img alt="简单的特征值梯度剪枝，CPU和ARM上带来4-5倍的训练加速 | ECCV 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S8CaNxWGzaUaAe></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'剪枝','简单','特征值'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>