<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答 | 极客快訊</title><meta property="og:title" content="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/89d6bb2700894ec79b76fdc99e8768e9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><meta property="article:published_time" content="2020-10-29T21:00:10+08:00"><meta property="article:modified_time" content="2020-10-29T21:00:10+08:00"><meta name=Keywords content><meta name=description content="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/eab7e4e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><br></p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/89d6bb2700894ec79b76fdc99e8768e9><p class=pgc-img-caption></p></div><blockquote><p><em>作者: 北京大学硕士 易鸿伟</em><br><em>公众号：<strong>将门创投</strong>(thejiangmen)</em></p></blockquote><p style=text-align:start><br></p><p style=text-align:start><strong>ECCV 2020系列文章专题 第·5·期</strong></p><p style=text-align:start>本文将分享<strong>北京大学硕士易鸿伟</strong>等在<strong>ECCV 2020</strong>上发表的两篇关于<strong>多视图立体几何</strong>的工作：基于自适应视角选择的金字塔多视角立体几何神经网络(PVA-MVSNet)及采用动态一致性检测的密集混合式多视角立体几何循环神经网络(D2HC-RMVSNet(spotlight))。更多ECCV精彩内容，关注<strong>将门创投（</strong><em><strong>thejiangmen</strong></em><strong>）公众号，</strong>后台回复“ECCV”即可查看！</p><p style=text-align:start>好消息，我“门”首次举办的顶会线上活动——<strong>将门「ECCV 2020鲜声夺人云际会」</strong>火热报名中，扫描下方二维码，或复制 http://thejiangmen2222.mikecrm.com/OUKtdGm至浏览器，马上报名，抢占席位！</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cd08693bbbad4f6987233f17e20760c1><p class=pgc-img-caption>快来报名吧！</p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/aaa7c65e0fac475692beb44daa7fa5e5><p class=pgc-img-caption></p></div><p style=text-align:start>文章链接：https://arxiv.org/abs/1912.03001v2</p><p style=text-align:start>代码链接：https://github.com/yhw-yhw/PVAMVSNet</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5484e2a300ba4beda63de519f40019bf><p class=pgc-img-caption></p></div><p style=text-align:start>文章链接：https://arxiv.org/pdf/2007.10872.pdf</p><p style=text-align:start>代码链接：https://github.com/yhw-yhw/D2HC-RMVSNet</p><h1 class=pgc-h-arrow-right><strong>一、导读</strong></h1><p style=text-align:start>从图像中重建3D几何是数十年来经典的计算机视觉问题，主要方法之一是<strong>Multi-view Stereo </strong>(MVS)，旨在给定两个以上的较准图片，使用立体对应作为主要信息恢复稠密3D场景表示。</p><p style=text-align:start>在针对普通消费者的领域，该技术可以用于用户对自己喜欢的物体通过拍摄照片，进行实时或云端的三维重建，从而获得该物体的三维模型。在针对商业用户的领域，该技术可以为商业用户提供三维重建服务，在建筑领域、测绘领域及游戏领域均有重要的应用价值。</p><p style=text-align:start>基于深度学习的多视图立体几何方法，从训练数据中学习知识可以推断出从立体匹配算法中难以获得的信息去解决匹配模糊性，但是这些方法并没有使用如下非常重要的信息：<strong>多视角图像的差别和多尺度信息</strong>。基于此两点，我们提出一种<strong>基于自适应视角选择的金字塔多视角立体几何神经网络模型(PVA-MVSNet)</strong>：</p><ol start=1><li>自适应视图聚合模块，考虑在不同视角图像间多重匹配的不同重要性，将更好的匹配区域特征得到增强，错误匹配的区域特征得到抑制。</li><li>多尺度度量约束金字塔深度图聚合，通过多尺度度量约束聚合由VA-MVSNet产生的金字塔深度图为一张融合后的深度图。</li></ol><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a87c2c130b6f4c4486ddd31dd5e7becd><p class=pgc-img-caption></p></div><p style=text-align:start>除上述问题之外，首先，一些基于3D CNN的方法需要消耗大量内存，所以无法处理高分辨率的图像；虽然基于RNN的方法试图解决占内存大的问题，但是牺牲了准确性。其次，大部分的基于神经网络的方法都采用了非常大的降采样模块来完成特征的提取，除了占内存外，信息也在降采样的过程中丢失了。最后，这些基于深度学习的多视角立体几何方法都需要将每一张作为参考图像计算出来的深度图进行融合，在融合的时候采用固定的启发式策略和参数，会过滤掉很多高精度的点云。</p><p style=text-align:start>为了解决上述问题，我们提出<strong>采用动态一致性检测的密集混合式多视角立体几何网络</strong>，该算法包括了一个新的神经网络结构，和一个动态的后处理融合深度图的方法。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/89e01ff8a4254d51a1d408ac78954524><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>二、算法细节</strong></h1><h1 class=pgc-h-arrow-right><strong>1、PVA-MVSNet</strong></h1><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2d3b82251d6a480992bfb074b1ed7c4c><p class=pgc-img-caption></p></div><ul><li><strong>自适应视角聚合</strong></li></ul><p style=text-align:start>为了处理任意N视图图像输入以及不同图像之间的差异来源，我们提出自适应视角度聚合，一种是<strong>像素级视角聚合</strong>(pixel-wise view aggregation)，另一种是<strong>体素级视角聚合</strong>(voxel-wise view aggregation)。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9da7a018e95f4505bad066c55ce64e53><p class=pgc-img-caption></p></div><p style=text-align:start>像素级视角聚合引入在高度和宽度维度自选择带权重的注意力图，在深度采样假设的维度共享权重，经过规范化的3D代价卷如下：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/efa5cd304c134bb381809b1e1b783c4f><p class=pgc-img-caption></p></div><p style=text-align:start><br></p><p style=text-align:start>其中</p><p style=text-align:start>Wh,w表示2D带权重注意力图，</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9abc8b870bf94ed49ead6d6db18f8d75><p class=pgc-img-caption>表示元素级乘法操作</p></div><p style=text-align:start>为了产生2D带权重注意力图，我们设计了weightnet网络来学习W h,w，其中weightnet由几层卷积层和一个ResNet块组成：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d831aa4102f6463f8f291580a99e470f><p class=pgc-img-caption></p></div><p style=text-align:start>体素级视角聚合考虑每一个图像像素不同的深度假设都被视为不同，所以3D代价卷中每一个体素都学习它自身的重要性。基于此，我们设计了一个weightnet-3d网络直接学习3D代价卷的3D注意力图，规范化的3D代价卷如下：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/10bed8c860c54c00a2113bbfbf3b54a8><p class=pgc-img-caption></p></div><p style=text-align:start>我们的自适应视图聚合模块可以增强多视图立体几何网络，从而生成更多具有较高置信度精确的深度估计。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3796b326529c4cbfbdfa617aeff1e1d2><p class=pgc-img-caption></p></div><ul><li><strong>多度量金字塔深度图聚合</strong></li></ul><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/feb176d83b6b4e8db561725edb28feb9><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/14fc972da0b54d7589ca50b445cba23e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5b87e74356464b889617b1cdf7b9612e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>2、D2HC-RMVSNet</strong></h1><ul><li><strong>密集感受野扩张子网DRENet</strong></li></ul><p style=text-align:start>在这个子网络中，我们引入了<strong>不同的扩张卷积层来产生多个尺度的背景信息，并且保持了分辨率</strong>，使得我们能够输出输入图像分辨率大小的深度图。DRENet的网络细节如下表所示。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1ee229da8e194236a4f5192b77a36909><p class=pgc-img-caption></p></div><p style=text-align:start>Conv和Deconv表示2D卷积和2D反卷积。GR是组归一化(Group Normalization)和ReLU的简称. MaxPooling表示了2维最大化池化层。ConvLSTMCell表示了有着2维卷积的LSTM循环神经元。N，H，W，D是输入的多视角图像的个数，图像的长、宽，和深度假设的个数。</p><ul><li><strong>混合循环正则化HRU-LSTM</strong></li></ul><p style=text-align:start>之前的方法中有两种不同的方法来正则代价卷，从而得到描述深度图的概率图。一种是<strong>MVSNet用的3DCNN U-Net</strong>，它利用了局部信息和多尺度背景信息，但是却不能直接用于回归和输入图像大小一样的深度图，因为这种结构非常占内存。另一种，是<strong>R-MVSNet用的堆叠起来的卷积RGU</strong>，它通过沿着深度方向依次处理3D代价卷来提升效率，但是却没有融合多尺度的背景信息。</p><p style=text-align:start>因此，我们吸收了这两种方法的优点，提出了一种混合式的循环正则网络结构，这种结构包含了比GRU更加有力的循环卷积神经元，我们称之为<strong>LSTMConvCell</strong>。我们把LSTMConvCell作为每一层从而构建了一种新的2D U-Net结构，从而既考虑了多尺度背景信息，又能依次处理三维代价卷，从而减少内存消耗。这种结构相比于R-MVSnet直接减少了19.4%的内存消耗。细节结构见上表。LSTMConvCell用三个门map来控制信息流，并且可以集成不同尺度的背景信息。</p><ul><li><strong>动态一致性检验</strong></li></ul><p style=text-align:start>我们提出了动态的几何一致性检测策略，<strong>用一种整体的一致性度量替换之前方法所提固定视角阈值的方法，从而尽可能地保留那些更为准确的深度值</strong>，进而提高最终生成点云的精度与召回率。对于参考图像上的某个深度值而言，我们将其反投影到三维空间并投影到其相邻的图片上，再重复这一过程将其相邻图片上的对应像素重投影回原图像，并计算出相应的重投影像素误差与深度误差：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6ba4d9bb4eeb4f3db61b19abf888b6e2><p class=pgc-img-caption></p></div><p style=text-align:start>为了定量地衡量这些误差值的影响，我们将这两个误差整合为一个整体的一致性度量为：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ace75dbad9ac405a855dd3b899db40b0><p class=pgc-img-caption></p></div><p style=text-align:start>最后根据在每个相邻视角的结果计算出全局几何一致性度量之和衡量深度值的可靠性：</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2c213bec78124ec6987c9bd2622bfb74><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>三、实验结果</strong></h1><p style=text-align:start>我们均在DTU数据集上训练PVA-MVSNet和D2HC-RMVSNet，并直接在Tanks andTemples或者BlendedMVS上进行测试。</p><h1 class=pgc-h-arrow-right><strong>1、PVA-MVSNet</strong></h1><ul><li><strong>DTU 测试集</strong></li></ul><p style=text-align:start>我们的VA-MVSNet和PVA-MVSNet（具有体素视图聚合）的性能在完整性和整体质量方面相比其他方法都有显著改善，并且能够生成更加准确、连续和完整的深度图。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/134becb2232347e385ff3a810e6a095b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3b11b1811a524a4cafa7de8495f3c828><p class=pgc-img-caption></p></div><ul><li><strong>Tanks and Temples</strong></li></ul><p style=text-align:start>我们的算法在该榜单上也取得与P-MVSNet相当的结果，表明本文提出的算法具有较强的通用性。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e816c942db044455978e21998cc4fb8b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cb791e4e095d44379092aba5f1048947><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>2、D2HC-RMVSNet</strong></h1><ul><li><strong>DTU 测试集：</strong></li></ul><p style=text-align:start>D2HC-RMVSNet能够提升其来源方法MVSNet和R-MVSNet对重建物体的准确性和完整度，从而能够重建更加完整和准确的点云。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/992670c4706846f2964a80a4c36ae15a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3c4445d21d2043b4ad59ace4aa5d32af><p class=pgc-img-caption></p></div><ul><li><strong>Tanks and Temples</strong></li></ul><p style=text-align:start>D2HC-RMVSNet在该榜单上排名第一，重建更加稠密和准确的点云。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/af87a16095e2430096039394a6017b6c><p class=pgc-img-caption></p></div><ul><li><strong>BlendedMVS</strong></li></ul><p style=text-align:start>BlendedMVS是一个新的大规模MVS数据集，它是根据Altizure的3D重建模型合成的。我们的方法D2HC-RMVSNet可以很好地重建大型场景和小型汽车，而R-MVSNet却失败了。</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/497394c8f39c4edf8ae203fcfa061f2e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>四、未来工作</strong></h1><p style=text-align:start>未来我们会考虑将法相或者平面先验加入到多视图立体几何网络中，并探索多视图立体几何在具有更多无纹理区域以及更多平面的室内场景中的应用。</p><h1 class=pgc-h-arrow-right><strong>作者介绍</strong></h1><p style=text-align:start><strong>易鸿伟 | 北京大学 硕士</strong></p><p style=text-align:start>易鸿伟，将于今年九月加入MPI-PS实验室师从Michael J. Black教授攻读博士学位，本科毕业于北京邮电大学，硕士毕业于北京大学。目前研究方向涉及人脸重建和多视图立体几何，即通过拍摄单张图片重建人脸模型和通过多张环拍图片重建稠密场景点云。</p><h1 class=pgc-h-arrow-right><strong>ECCV 2020独家攻略</strong></h1><p style=text-align:start><strong>//1</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6859166022080037389/?group_id=6859166022080037389" rel="noopener noreferrer" target=_blank>活动报名 | 「将门ECCV 2020鲜声夺人云际会」踏浪而来</a></p><p style=text-align:start><strong>// 2</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6852505428085965324/?group_id=6852505428085965324" rel="noopener noreferrer" target=_blank>ECCV 2020 | 云端参会攻略之Oral篇，前排占位、强势围观</a></p><p style=text-align:start><strong>// 3</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6853974407581270536/?group_id=6853974407581270536" rel="noopener noreferrer" target=_blank>ECCV 2020 | 精彩教程大揭秘，云端参会也easy</a></p><p style=text-align:start><strong>// 4</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6857341929441460747/?group_id=6857341929441460747" rel="noopener noreferrer" target=_blank>ECCV 2020|Workshop第一弹：视觉研讨会，最新研究成果一网打尽</a></p><h1 class=pgc-h-arrow-right>ECCV 2020论文精选</h1><p style=text-align:start><strong>// 1</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6855119185048142350/?group_id=6855119185048142350" rel="noopener noreferrer" target=_blank>ECCV 2020 Oral|当AI遇见三维时装:来看现今最大的三维服装数据集</a></p><p style=text-align:start><strong>// 2</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6855482358905176579/?group_id=6855482358905176579" rel="noopener noreferrer" target=_blank>ECCV 2020 | GRNet: 用于稠密点云补全的网格化残差网络</a></p><p style=text-align:start><strong>// 3</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6856932870309872142/?group_id=6856932870309872142" rel="noopener noreferrer" target=_blank>ECCV 2020 | 中科大&微软提出挑图神器：GIQA，一键挑出高质量图像</a></p><p style=text-align:start><strong>// 4 </strong><a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6857685969777197581/?group_id=6857685969777197581" rel="noopener noreferrer" target=_blank>ECCV 2020 | 基于对抗路径采样的反事实视觉语言导航</a></p><p style=text-align:start><br></p><p style=text-align:start>最后，别忘了</p><p style=text-align:start><strong>将门「ECCV 2020鲜声夺人云际会」</strong>火热报名中~</p><p style=text-align:start>扫描下方二维码</p><p style=text-align:start>或复制 http://thejiangmen2222.mikecrm.com/OUKtdGm至浏览器，</p><p style=text-align:start>马上报名，抢占席位！</p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7e8d0a62b6064f8ea38ad3d7932ccb04><p class=pgc-img-caption>快来报名吧~</p></div><h1 class=pgc-h-arrow-right>关于我“门”</h1><p style=text-align:start><strong>将门</strong>是一家以专注于<strong>发掘、加速及投资技术驱动型创业公司</strong>的新型<strong>创投机构</strong>，旗下涵盖将门创新服务、将门技术社群以及将门创投基金。将门成立于2015年底，创始团队由微软创投在中国的创始团队原班人马构建而成，曾为微软优选和深度孵化了126家创新的技术型创业公司。</p><p style=text-align:start><strong>将门创新服务</strong>专注于使创新的技术落地于真正的应用场景，激活和实现全新的商业价值，服务于行业领先企业和技术创新型创业公司。</p><p style=text-align:start><strong>将门技术社群</strong>专注于帮助技术创新型的创业公司提供来自产、学、研、创领域的核心技术专家的技术分享和学习内容，使创新成为持续的核心竞争力。</p><p style=text-align:start><strong>将门创投基金</strong>专注于投资通过技术创新激活商业场景，实现商业价值的初创企业，关注技术领域包括机器智能、物联网、自然人机交互、企业计算。在近四年的时间里，将门创投基金已经投资了包括量化派、码隆科技、禾赛科技、宽拓科技、杉数科技、迪英加科技等数十家具有高成长潜力的技术型创业公司。</p><p style=text-align:start>如果您是技术领域的初创企业，不仅想获得投资，还希望获得一系列持续性、有价值的投后服务，欢迎发送或者推荐项目给我“门”: bp@thejiangmen.com</p><p style=text-align:start><br></p><div class=pgc-img><img alt="ECCV 2020|多视角图像的差别和多尺度信息如何利用？两篇论文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/88a48157d21744e8978e1ce71ad0cef4><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'ECCV','2020','多视'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>