<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>走近kafka-Partition分配与消息可靠性 | 极客快訊</title><meta property="og:title" content="走近kafka-Partition分配与消息可靠性 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/311889dfdfba473ebd6970f1ada0c1c5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f04f8059.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f04f8059.html><meta property="article:published_time" content="2020-11-14T21:07:11+08:00"><meta property="article:modified_time" content="2020-11-14T21:07:11+08:00"><meta name=Keywords content><meta name=description content="走近kafka-Partition分配与消息可靠性"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/f04f8059.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>走近kafka-Partition分配与消息可靠性</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>Kafka的高可用源于其多个副本(replication)。</p><p>拥有多个副本，那么带来的问题就是数据怎么同步。我们都知道数据是存放在partition物理目录下的文件里面。通过前面几节的介绍，我们也知道消息过来后直接跟partition leader交互，然后由leader进行数据同步。由于partition 的replication机制，在kafka看来partition不分leader 和 follower之分的，都是replica。</p><p>同一个partition可能会有多个replica，此时需要在这些replica之间选出一个leader,producer和Consumer只与leader交互，其它replica作为follower从leader中复制数据。</p><div class=pgc-img><img alt=走近kafka-Partition分配与消息可靠性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/311889dfdfba473ebd6970f1ada0c1c5><p class=pgc-img-caption></p></div><p>图片来源自网络</p><p>一个topic下可能会有多个partition,同一个partition又可能有多个replica，那它们是怎么分配的，不可能无秩序的。</p><p>为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。Kafka分配Replica的算法如下：</p><p>· 将所有存活的N个Brokers和待分配的Partition排序</p><p>· 将第i个Partition分配到第(i mod n)个Broker上，这个Partition的第一个Replica存在于这个分配的Broker上，并且会作为partition的优先副本</p><p>· 将第i个Partition的第j个Replica分配到第((i + j) mod n)个Broker上</p><p>假设集群一共有4个brokers，一个topic有4个partition，每个Partition有3个副本。下图是每个Broker上的副本分配情况。</p><div class=pgc-img><img alt=走近kafka-Partition分配与消息可靠性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4a629dc1f9104f729f673d287b78dbd9><p class=pgc-img-caption></p></div><p>图片来源自网络</p><p>Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication有多少个，Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。</p><p>为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。</p><p>Consumer读消息也是从Leader读取，只有被commit过的消息才会暴露给Consumer。</p><div class=pgc-img><img alt=走近kafka-Partition分配与消息可靠性 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1d95fb5d744a4003aa7446a36df01477><p class=pgc-img-caption></p></div><p>图片来源自网络</p><h1>消息投递的可靠性</h1><ol><li>当ack=0的时候，表示producer发送出去message，只要对应的kafka broker topic partition leader接收到的这条message，producer就返回成功，不管partition leader 是否真的成功把message真正存到kafka。</li><li>当ack=1的时候，表示producer发送出去message，同步的把message存到对应topic的partition的leader上，然后producer就返回成功，partition leader异步的把message同步到其他partition replica上。</li><li>当ack=all或-1，表示producer发送出去message，同步的把message存到对应</li></ol><p>topic的partition的leader和对应的replica上之后，才返回成功</p><h1>消息消费的可靠性</h1><p><strong>at most once：</strong>最多一次，这个和JMS中"非持久化"消息类似，发送一次，无论成败，将不会重发。消费者fetch消息，然后保存offset，然后处理消息；当client保存offset之后，但是在消息处理过程中出现了异常，导致部分消息未能继续处理。那么此后"未处理"的消息将不能被fetch到，这就是"at most once"。</p><p><strong>at least once：</strong>消息至少发送一次，如果消息未能接受成功，可能会重发，直到接收成功。消费者fetch消息，然后处理消息，然后保存offset。如果消息处理成功之后，但是在保存offset阶段zookeeper异常导致保存操作未能执行成功，这就导致接下来再次fetch时可能获得上次已经处理过的消息，这就是"at least once"，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态。</p><p><strong>exactly once：</strong>消息只会发送一次。kafka中并没有严格的去实现（基于2阶段提交），我们认为这种策略在kafka中是没有必要的。</p><p>通常情况下 at-least-once 是我们首选。</p><p>这一节对上一节留的问题说完了，partition replica的分配及消息的可靠性（投递和消费），下一节会说到，kafka 针对broker是怎么判断“活着”的状态以及leader的选举，再着重说说kafka顺序写入与数据读取其中涉及到的zero-copy</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'kafka','Partition','可靠性'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>