<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>通过对抗数据扩增泛化到未知域 | 极客快訊</title><meta property="og:title" content="通过对抗数据扩增泛化到未知域 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/8e1c483ddff5401a8d76313d9bd9a3db"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0a69e6c.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0a69e6c.html><meta property="article:published_time" content="2020-11-14T21:02:25+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:25+08:00"><meta name=Keywords content><meta name=description content="通过对抗数据扩增泛化到未知域"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/f0a69e6c.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>通过对抗数据扩增泛化到未知域</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p style=text-align:start><br></p><h1 class=pgc-h-arrow-right>摘　要</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们关注的学习模型可以很好地推广到不同的未知领</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">域</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">。我们考虑了最坏情况下在特征空间中</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">源域</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">附近的数据分布。仅使用单个源分布的训练数据，我们通过在当前模型下“困难”的虚拟目标域中的示例提出了一个增加数据集的迭代过程。我们证明了我们的迭代方案是一种自适应的数据扩充方法，其中我们会在每次迭代后附加对抗性示例。对于 softmax 的损失，我们证明了我们的方案是一种域数据相关的正则化方案，其行为与正则化为零的经典正则化器（例如 ridge 或 lasso）不同。在数字识别与语义分割的任务上，我们的方法学习模型改进一系列先验未知目标域的性能。</span></p><h1 class=pgc-h-arrow-right>1. 引言</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在许多机器学习的现代应用中，我们希望学习一种能够在多个人群中均匀表现的系统。但由于数据采集成本高，所以数据集中的人口来源通常有限。在对数据集进行验证评估时表现良好的</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">标准模型，通常是从相同人群中的训练集中收集的，所以一般对不同于训练数据集的人群表现不佳[15,3,1,32,38]。在本文中，我们关注的是在我们无法访问来自未知目标分布的任何数据的环境中，对不同于训练分布的人群进行推广。例如，考虑一个自动驾驶汽车的模块，需要在整个天气条件和培训期间未开发的城市环境中进行泛化。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">许多作者在设置中提出了自适应领域的方法（例如，见[9,39,36,26,40]），其中可以获得完全标记的源数据集和来自固定目标分布的未标记（或部分标记）的一组示例数据集。虽然这样的算法可以成功的学习在已知目标分布上表现良好的模型，但是在实际场景中先验固定目标分布的假设可能是限制性的。例如，考虑机器人使用的语义分割算法：每个任务、机器人、环境和摄像机的配置将产生不同的目标分布，并且只有在训练和部署模型之后才能识别这些不同的场景，这使得从它们收集样本变得困难。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在这项工作中，我们开发的方法可以更好地学习推广到新的未知领域。我们考虑了限制性设置，其中训练数据仅来自单个源领域。受到分布式强大优化和对抗性训练的最新发展的启发[34,20,12]，我们考虑围绕源分布（训练）P0 的以下最坏情况问题。</span></p><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8e1c483ddff5401a8d76313d9bd9a3db><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/67f3dbd1dd5542549551afd3a23bcb65><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">最坏情况问题的解决方案（1）保证了针对远离源域 P0 的距离 ρ 的数据分布的良好性能。 为了允许对源 P0 具有不同支持的数据分布，我们使用 Wasserstein 距离作为我们的度量 D。我们的距离将在语义空间 3 上定义，因此满足 D（P，P0）小于等于 ρ 的目标群体 P 代表真实的协变量 保留源的相同语义表示的移位（例如，向灰度图像添加颜色）。 在这方面，我们期望解决最坏情况问题（1） - 我们希望学习的模型在语义空间中的协变量变化中具有良好的性能。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们提出了一个迭代过程，旨在解决问题（1）一次得到一个小的 ρ 值，并对模型 θ 进行关于这些虚构的最坏情况目标分布的随机梯度更新（第 2 节）。 我们方法的每次迭代都使用小的 ρ 值，我们提供了许多方法的理论解释。 首先，我们证明了我们的迭代算法是一种自适应数据扩增方法，我们在当前模型中将对侧扰动样本添加到数据集（第 3 节）。 更准确地说，我们的对手生成的样本大致对应于 Tikhonov 正则化 Newton-steps 关于语义空间中的损失。 此外，我们表明，对于 softmax 损失，我们方法的每次迭代都可以被认为是一种依赖于数据的正则化方案，其中我们向与真实标签相对应的参数向量进行正则化，而不是像经典正则化器那样向零正则化，例如 ridge 或者 lasso。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">从实际的角度来看，应用最坏情况公式（1）的关键难点在于协变量偏移 ρ 的大小是先验未知的。 我们提出学习一组对应于不同距离 ρ 的模型。 换句话说，我们的迭代方法生成一组数据集，每个数据集对应一个不同的数据集间距离水平 ρ，我们为每个数据集学习一个模型。 在测试时，我们使用启发式方法从集合中选择合适的模型。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们在简单的数字识别任务上测试我们的方法，并在不同的季节和天气条件下测试更现实的语义分割任务。 在这两种设置中，我们观察到我们的方法允许学习能够改善与原始源域具有不同距离的先验未知目标分布的性能的模型。</span></p><h1 class=pgc-h-arrow-right>相关工作</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">关于对抗性训练的文献[10,34,20,12]与我们的工作密切相关，因为主要目标是设计训练程序，学习对输入波动具有鲁棒性的模型。与对抗性训练中考虑的难以察觉的攻击不同，我们的目标是学习抵抗较大扰动的模型，即分布式样本。Sinha 等[34]提出了一种原则性的对抗性训练程序，其中生成最大化某些风险的新图像，并且针对那些对抗性图像优化模型参数。设计用于防御难以察觉的对抗性攻击，新的图像是在损失的情况下学习的，这种损失会惩罚原始图像和新图像之间的差异。在这项工作中，我们依赖于类似于 Sinha 等人提出的极小极大游戏。 在[34]中，是我们在语义空间中强加了约束，以便允许来自虚拟分布的对抗样本在像素级别上不同，同时共享相同的语义。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">关于领域适应的大量工作[15,3,32,9,39,36,26,40]旨在更好地推广到在训练时标识未知的先验固定目标领域。这种设置与我们的不同之处在于这些算法需要在训练期间从目标分布访问样本。领域概括方法[28,22,27,33,24]提出了更好地推广到未知领域的不同方法，这也与我们的工作有关。这些算法要求从不同的域中提取训练样本（同时在训练期间可以访问域标签），而不是单个源，这是我们的方法没有的限制。从这个意义上讲，人们可以将我们的问题设置解释为无监督域概括。托宾等人[37]提出了域随机化，它适用于模拟数据并使用模拟器创建各种随机渲染，希望现实世界将被解释为其中之一。我们的目标是相同的，因为我们的目标是获得更类似于现实世界的数据分布，但我们通过实际学习新数据点来实现它，从而使我们的方法适用于任何数据源而无需模拟器。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">Hendrycks 和 Gimpel [13]认为，检测测试样本是否超出给定模型的分布的一种好的经验方法是评估 softmax 输出的统计数据。我们在我们的设置中调整这个想法，学习用我们的方法训练的模型的集合，并在测试时选择具有最大 softmax 值的模型。</span></p><h1 class=pgc-h-arrow-right>2. 方法</h1><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d17b6beed1874697a1f5df87a6a30015><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/666a6e21f9354fe29891abf4d0c20f65><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/68dd55e4e6604d0e80bc9d8488461245><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">采取惩罚缓和（4）的对偶重新形成，我们可以获得一个有效的解决程序。以下结果是对[2，定理 1]的较小修改；为了简化符号，我们定义了鲁棒代理损失。</span></p><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/11f8e5ecd5534fa9a4b01682d55496b2><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/bf67540af2c842868ae4ebd3aee2fdf5><p class=pgc-img-caption></p></div><p><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">迭代过程 我们提出了一个迭代训练过程，其中两个阶段交替进行：最大化阶段，通过计算内部最大化来学习新的数据点问题（5）和最小化阶段，其中模型参数是根据在最大化阶段生成的对抗示例中评估的损失梯度来更新的。后者等效于鲁棒替代损耗的随机梯度步骤，并因此而得名。 这里的主要思想是从虚拟目标中反复学习“硬”数据点分布，同时保留原始数据点的语义特征。</span></p><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5b1e10ff0b2d40a4bfedcd47bcdc81ec><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0878cd218b8e4cc79897c9c14df2ab12><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>3. 理论动机</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在我们的迭代算法（算法 1）中，最大化阶段（8）是用对抗性扰动的数据点扩充数据集的关键步骤，其后是对模型参数的标准随机梯度更新。在本节中，我们提供对扩增步骤（8）的一些理论理解。首先，我们表明在当前模型下，扩充后的数据点（8）可以解释为 Tikhonov 正则化牛顿步骤[21，25]。粗略地说，从某种意义上讲，算法 1 是一种自适应数据扩增算法，可以从虚拟“硬”目标分布中添加数据点。其次，回想一下鲁棒的代理损耗（5），其随机梯度用于在最小化步骤（等式（7））中更新模型参数 θ。在分类设置中，我们表明健壮的代理人（5）大致对应于 softmax loss`上的一种新的数据相关正则化方案。与数据相关的正则化术语不会惩罚像经典正则化器（例如 ridge 或套索）那样向零惩罚的方法，而是惩罚与真实标签对应的参数向量的偏差。</span></p><h1 class=pgc-h-arrow-right>3.1. 自适应数据扩增</h1><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/03eb263cb40d4548ab22b82e88889fa3><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5171379e28c949bcbbe07c22b21842c3><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9bdcc4bdab3b4e1f900370c0c0711e33><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>3.2. 数据相关的正则化</h1><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bdff575c671e43d78fbf5e84da384466><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad8391bd081e41c7a5aea3fd99ca1000><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>4. 实验</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们按照域适应技术的评估方案[9、39、14]评估了分类和语义分割设置的方法，尽管在我们的情况下，目标域在训练时是未知的。 我们总结了实验设置，包括每个任务的实施细节，评估指标和数据集。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">数字分类 我们在 MNIST [19]数据集上进行训练，并在 MNIST-M [9]，SVHN [30]，SYN [9]和 USPS [6]上进行测试。 我们使用 10，000 位数的样本进行训练，并使用准确性作为度量标准，在不同目标域的各个测试集上评估我们的模型。 为了使用可比较的数据集，我们将所有图像的大小调整为 32×32，并将来自 MNIST 和 USPS 的图像视为 RGB。 我们使用具有体系结构 conv-pool-conv-pool-fc-fc-softmax 的 ConvNet [18]并设置超参数 α= 0.0001，η= 1.0，Tmin = 100 和 Tmax =15。在最小化阶段，我们使用 Adam [17]，批次大小等于 324。我们将我们的方法与经验风险最小化（ERM）基准和不同的正则化技术（Dropout [35]，山脊）进行了比较。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">语义场景分割 我们使用 SYTHIA [31]数据集进行语义分割。 数据集包含来自不同位置的图像（我们使用高速公路，类似纽约的城市和欧洲老城），以及不同的天气/时间/日期条件（我们使用黎明，雾，夜，春和冬。在源上训练模型） 领域并在其他领域进行测试，使用标准平均联合交叉口（mIoU）指标来评估我们的性能[8]。在整个实验过程中，我们从左前摄像头中任意选择了图像。对于每一个图像，我们随机抽取 900 张图像（调整大小） 到 192×320 像素），我们使用具有 ResNet-50 [11]主体的完全卷积网络（FCN）[23]，并设置超参数 α= 0.0001，η= 2.0，Tmin = 500 和 Tmax = 50.在最小化阶段，我们使用批次大小等于 8 的 Adam [17]。将我们的方法与 ERM 基准进行比较。</span></p><h1 class=pgc-h-arrow-right>4.1. 数字分类结果</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在本节中，我们介绍并讨论数字分类实验的结果。 首先，我们对分析我们施加的语义约束的作用感兴趣。 图 1a（顶部）显示</span></p><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6143f24f41bc486ea079ee649188669e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e006e34d139c44c6886d0006a05f2de0><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">图 1.与用 10，000 MNIST 样本训练并在 SVHN，MNIST-M，SYN 和 USPS（分别为第一栏，第二栏，第三栏和第四栏）上测试的模型相关的结果。面板（a），顶部： 像素空间（黄色）和语义空间（蓝色），其中 γ= 104 且 K =1。面板（a），底部：比较我们的 K = 2 和不同 γ 值的方法（蓝色条）和 ERM（红线） ）。 面板（b），顶部：γ= 1.0 与不同迭代次数 K（蓝色），ERM（红色）和 Dropout [35]（黄色）之间的比较。 面板（b），中间：用 ridge（绿色）和 ridge +我们的方法（γ= 1.0 和 K = 1（蓝色））规范化的模型之间的比较。面板（b），底部：使用模型的与整体方法有关的结果 使用我们的方法进行了训练，迭代次数 K 不同（蓝色），并且使用通过 ERM 训练的模型（红色）。 报告的结果是通过平均 10 多次不同的运行获得的； 黑条表示跨度精度范围。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">与用算法 1 训练的模型具有 K = 1 和 γ= 104 关联的模型的性能，在语义空间（如第 2 节所述）和像素空间[34]（分别为蓝色和黄色</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">条</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">）中具有约束。图 1a（底部）显示了使用我们的方法训练的模型的性能，其中使用了不同的超参数 γ 值（K = 2）和 ERM（分别为蓝色条和红色线）。这些图显示了（i）在模型在未知域上进行测试时，移动语义空间上的约束会带来好处；（ii）在样本外域上，对于任何 γ 值，使用算法 1 胜过模型训练的模型都使用 ERM 进行训练（SVHN，MNIST-M 和 SYN）。后一个结果是相当理想的成就，因为该超参数无法正确地交叉验证。在 USPS 上，我们的方法会导致准确性下降，因为 MNIST 和 USPS 是非常相似的数据集，因此我们的算法在训练过程中不会探索 USPS 所属的图像域，从而优化了最坏情况下的性能。</span></p><div class=pgc-img><img alt=通过对抗数据扩增泛化到未知域 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9b486fcdb2144913a73032155d82b7dc><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">图 2.使用 ERM 训练的语义分割模型（红色）和 K = 1 且 γ= 1.0（蓝色）的方法获得的结果。 最左边的面板与在 Highway 上训练的模型相关联，最右边的面板与在类似纽约的城市上训练的模型相关联。 测试数据集是公路，纽约市和欧洲古城。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">图 1b（顶部）报告了与用我们的方法训练的模型相关的结果（蓝色条），改变了迭代次数 K 并固定 γ= 1.0，结果与 ERM（红色条）和 Dropout [35]（黄色条）相关。 我们观察到，我们的方法改善了 SVHN，MNIST-M 和 SYN 的性能，在统计上</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">显著</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">优于 ERM 和 Dropout [35]。 在图 1b（中）中，我们比较了用岭正则化训练的模型（绿色条）与用算法 1（K = 1 和 γ= 1.0）和</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">岭</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">正则化训练的模型（蓝色条）进行比较。 这些结果表明，我们的方法可能会从其他正则化方法中受益，因为在这种情况下，我们观察到了两种效果的总和。 我们在附录 B 中进一步报告了我们的方法与非监督域自适应算法（ADDA [39]）之间的比较，以及与超参数 γ 和 K 的不同值相关的结果。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">最后，我们报告通过学习模型集成获得的结果。由于超参数 γ 对于设置先验而言并非无关紧要，因此我们使用 softmax 置信度（9）选择在测试时使用哪种模型。我们学习模型的集合，每个模型通过运行算法 1 来训练，其中算法 γ 的不同值为 γ =10^-i，其中 i = 0、1、2、3、4、5、6。图 1b（底部）显示了我们的方法在不同迭代次数 K 和 ERM（分别为蓝色和红色条形）之间的比较。为了区分整体学习的作用，我们学习了一组各自对应于不同初始化的基线模型。对于基线（ERM）和我们的方法，我们将集合中的模型数量固定为相同。将图 1b（底部）</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">与</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">图 1b（顶部）和图 1a（底部）进行比较，我们的集成方法可在不同的测试场景中实现更高的精度。我们观察到，随着迭代次数 K 的增加，我们的样本外性能会提高。同样在集成设置中，对于 USPS 数据集，我们看不到任何改进，我们推测这是在远离训练的域和靠近训练的域之间的良好性能之间进行权衡的产物。</span></p><h1 class=pgc-h-arrow-right>4.2. 语义场景分割结果</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们报告了使用 ERM 训练的模型和使用我们的方法训练的模型之间的比较（算法 1，K = 1）。 我们在每个实验中都将 γ= 1.0，但是要强调的是这是一个任意值； 在这种情况下，我们没有观察到 γ 的不同值与模型的一般行为之间的强相关性。 如第 2 节中所述，它在集成模型中的作用更有意义，因为每个模型都具有不同级别的鲁棒性。在这种情况下，我们不应用集成方法，而仅评估单个模型的性能。做出此选择的主要原因是这样的事实，即在测试时开发的启发式方法实际上是在选择正确的模型，因此无法直接将其应用于语义分割问题。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">图 2 报告了获得的数值结果。具体来说，最左边的划分报告的结果与模型相关联，这些模型是根据“高速公路”拆分中的序列训练的，并在类似纽约的城市和“欧洲老城”拆分中进行了测试（分别为左上和左下）；最右边的划分报告与模型相关的结果，这些模型是在类似纽约市的城市划分的序列上训练的，并在高速公路和旧欧洲城镇的划分（分别为右上和右下）上进行了测试。训练序列（黎明，雾，夜，春和冬季）显示在 x 轴上。红色和蓝色条分别表示通过 ERM 训练的模型和通过我们的方法训练的模型获得的平均 mIoU。通过对每个模型在测试集的不同条件下获得的 mIoU 进行平均，可以计算出这些结果。可以看出，使用我们的方法训练的模型通常可以更好地推广到未知数据分布。特别是，当训练图像来自夜间场景时，我们的方法总是在统计上优于基线，这是因为在夜间图像上训练的基线模型强烈偏向黑暗的风景，而在最恶劣的情况下进行训练的结果案例分布，我们的模型可以克服这种强烈的偏见，并更好地在不同的看不见的领域进行概括。</span></p><h1 class=pgc-h-arrow-right>5. 结论与未来工作</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我们研究了一种新的对抗性数据扩增程序，该程序可以学习更好地概括看不见的数据分布，并定义一种集成方法来在分类中利用该技术框架。这与领域适应算法相反，领域适应算法需要来自已知的先验固定目标分布的足够数量的样本。我们的实验结果表明，我们的迭代过程为数字识别以及跨季节和跨天气语义分割任务提供了广泛的概括行为。对于将来的工作，我们希望通过定义新颖的决策规则来扩展集成方法。提议的启发式方法（9）仅适用于分类设置，将它们扩展到包括语义分割在内的广泛任务领域是一个重要的方向。许多理论问题仍然存在。例如，量化第 3 节中介绍的依赖数据的正则化方案的行为，将有助于我们总体上更好地理解对抗训练方法。</span></p><h1 class=pgc-h-arrow-right>致谢</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">本论文由 iSE 实验室 2020 级硕士生贺璐转述。</span></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'泛化','通过','抗数据'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>