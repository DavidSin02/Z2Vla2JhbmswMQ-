<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>中科院提出人群密度检测算法 DSNet，准确率提升 30% | 极客快訊</title><meta property="og:title" content="中科院提出人群密度检测算法 DSNet，准确率提升 30% - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/4828e46d5ba9456d80dbf495bdcb1612"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f67ae26.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f67ae26.html><meta property="article:published_time" content="2020-10-29T20:51:33+08:00"><meta property="article:modified_time" content="2020-10-29T20:51:33+08:00"><meta name=Keywords content><meta name=description content="中科院提出人群密度检测算法 DSNet，准确率提升 30%"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/f67ae26.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>中科院提出人群密度检测算法 DSNet，准确率提升 30%</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><strong>点击底部“了解更多” 阅读全文</strong><br>计算机视觉领域近年来对群体计数问题展开了广泛的研究。由于尺度变化（scale variation）较大，该项任务仍然具有很大的挑战性。在这篇论文中，中科院计算技术研究所提出了一种简单而有效的群体数量统计网络：DSNet。该网络的核心结构是密集扩张卷积块，其中每个扩张层与其他层紧密相连，防止信息受到尺度变化的影响。论文还介绍了一种新的多尺度密度水平一致性损失，提升了网络的表现性能。作者在四个群体计数数据集（ShanghaiTech、UCF-QNRF、UCF_CC_50 和 UCSD）上与最新算法进行了比较。实验结果表明，DSNet 在所有四个数据集上均达到最佳性能，并有显著的提升：在 UCF-QNRF 和 UCF_CC_50 数据集上计数准确率提高了 30%，在 Shanghai Tech 和 UCSD 数据集上准确率提高了 20%。本文是 AI 前线第 84 篇论文导读。</blockquote><h1 class=ql-align-justify>1 介绍</h1><p class=ql-align-justify>近年来，随着人口的快速增长，群体计数在视频监控、交通管制和体育赛事等方面得到了广泛应用。早期的研究工作通过检测身体或头部来估计人群数量，而其他一些方法则学习从局部或全局的特征到实际数量的映射关系来估计数量。最近，群体计数问题被公式化为人群密度图的回归，然后通过对密度图的值进行求和以得到图像中人群的数量。随着深度学习技术的成功，研究人员采用卷积神经网络（CNN）生成准确的群体密度图，并能获得比传统方法更好的表现。</p><p class=ql-align-justify></p><p class=ql-align-justify>然而，由于尺度变化（scale variation）较大、遮挡严重、背景噪声和透视失真，群体计数仍然是一项极具挑战性的任务。其中，尺度变化是最主要的问题。为了更好地处理尺度变化，研究人员提出了许多多列（multi-column）或多分支（multi-branch）网络。这些架构一般由 CNN 的几个列或主干网络不同阶段的几个分支组成。这些列或分支具有不同的感受野，以感知人群大小的变化。尽管这些方法有了很好的改进，但它们捕获的尺度多样性受到列或分支数的限制。</p><p class=ql-align-justify></p><p class=ql-align-justify>尺度变化的主要挑战在于两个方面。首先，如图 1 左所示，人群图像中的人通常大小不同，从几个像素到几十个像素不等。这就要求网络能够处理尺度变化很大的数据。第二，如图 1 右所示，整个图像的尺度通常连续变化，特别是对于高密度图像。这就要求网络能够对尺度范围进行密集采样。然而，现有的方法并不能同时应对这两个挑战。</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4828e46d5ba9456d80dbf495bdcb1612><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p>图 1 群体计数数据集中存在较大的尺度变化。左：Shanghai Tech 中输入图像和对应的真实密度图。右：UCF-QNRF 数据集中输入图像和对应的真实密度图。</p><p class=ql-align-justify>本文提出了一种新的密集尺度单栏神经网络——DSNet，用于群体计数。DSNET 由密集连接的扩张卷积块组成，因此它可以输出具有不同感受野的特征，并且捕获不同尺度的人群信息。DSNet 的卷积块与 DenseASPP 结构相似，但具有不同的扩张率组合。作者为块内的层仔细选择这些比率，这样每个块对连续变化的尺度进行更密集的采样。同时，所选择的扩张率组合可以利用感受野的所有像素进行特征计算，防止网格化效果。为了进一步提高 DSNet 捕获的尺度多样性，作者堆叠了三个密集扩张卷积块，并利用残差连接（residual connection）进行密集连接。最终的网络能够以更密集的方式对非常大的尺度变化范围进行采样，从而能够处理群体计数中尺度变化较大的问题。</p><p class=ql-align-justify></p><p class=ql-align-justify>以前大多数方法使用传统的欧几里德损失（Euclidean loss）训练网络，这是基于像素独立性的假设。这种损失忽略了密度图的全局和局部一致性，会影响群体计数的结果。为了解决这一问题，作者提出了多尺度密度水平一致性损失，用于保证估计的人群密度图和真实人群密度图之间的全局和局部的密度水平保持一致。</p><p class=ql-align-justify>论文贡献</p><blockquote>* 提出了密集扩张卷积块（DDCB），其扩张率是仔细选择的。DDCB 能够对连续变化的尺度进行密集采样。DSNet 可以进行端到端的训练，并且可以处理拥挤和稀疏的人群图像。* 引入了多尺度密度水平一致性损失，以提高模型表现。该损失加强了估测密度图和真实密度图之间的全局和局部一致性。* 作者在四个具有挑战性的公开群体统计数据集上进行了广泛的实验。与现有的最先进方法相比，该方法获得了最佳性能。在 UCF-QNRF 和 UCF_CC_50 数据集上的计数准确率提高了 30%，在 Shanghai Tech 和 UCSD 数据集上的计数准确率提高了 20%。</blockquote><h1 class=ql-align-justify>2 DSNet</h1><p class=ql-align-justify>该方法基本思想是一个端到端的单列 CNN，具有更密集的尺度多样性，以应对密集和稀疏场景中的大的尺度变化和密度水平差异。DSNET 的体系结构如图 2 所示。</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d3eaa03b1e6e426380fe6fde5db92db6><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>2.1 DSNet 结构</p><p class=ql-align-justify>我们提出的 DSNET 包含主干网络作为特征提取器，三个密集的扩张卷积块，由密集残差连接堆叠，扩大了尺度多样性，以及三个卷积层，用于人群密度图回归。</p><p class=ql-align-justify>主干网络</p><p class=ql-align-justify>本文所用的主干网络为 VGG-16 的前十层，以及三个池化层。经验表明，在多列网络中，使用内核较小但层数较多的卷积层比内核更大但层数更少的卷积层更有效。此外，它还实现了准确率与计算量之间的最佳权衡，适用于准确、快速的人群计数。</p><p class=ql-align-justify>密集扩张卷积块（Dense dilated convolution block，DDCB）</p><p class=ql-align-justify>为了应对尺度变化的挑战，需要一种能够以尽可能密集的方式捕获大范围尺度变化的网络架构。本文提出了一种新的密集扩张卷积块，它包含三个扩张卷积层，其扩张率为 1，2，3。这种设置可以保留来自更密集尺度的信息，并且感受野尺寸差距较小。区块内的每个扩张层与其他层紧密相连，因此每个层都可以访问所有后续层，并传递需要保留的信息。密集连接后，获得的尺度多样性增加，如图 3 所示。</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3ac99eb1b6dc429b84afca39d23660d6><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p>图 3 DDCB 尺度多样性与密集堆叠的扩张卷积中扩张率（1，2，3）的设置相对应。k 表示相应组合的感受野大小。</p><p class=ql-align-justify>精心选择膨胀率的另一个优点是，它可以克服网格化效果。如图 4 所示，扩张率为 6 的扩胀卷积层位于扩张率为 3 的扩张卷积层下方。在一维情况下，经过这两层之后，一个像素的最终结果只能从 7 个像素中获得信息。当输入数据是二维时，这种现象会变得更糟。因此，最终像素只能以网格方式查看原始信息，并丢失大部分（86.4%）信息。由于原始特征图的局部信息完全丢失，并且由于扩张率大，信息在大距离内可能不相关，这不利于群体计数中捕获详细特征。通过采用新的扩张率组合，顶层可以覆盖原始特征图的所有像素信息，避免中间层扩张率过大造成的大距离无关信息。这对于人群计数的准确性至关重要。</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ed3dbecf657a4dc5b169cd9e624c5eda><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>密集残差连接（Dense residual connection，DRC）</p><p class=ql-align-justify>虽然 DDCB 提供了密集尺度多样性，但不同块之间的层次特征没有得到充分利用。因此，作者通过密集的残差连接来改进体系结构，以进一步改进信息流。此外，与传统的密集连接相比，它们还可以防止网络变得更宽。这样，DDCB 的输出可以直接访问后续 DDCB 的每一层，从而实现连续的信息传递。与普通的残差连接相比，进一步扩大了尺度多样性，并在信息流过程中自适应地保留了适合特定场景的特征。</p><p class=ql-align-justify>2.2 损失函数</p><p class=ql-align-justify>以往的研究大多使用欧几里得距离损失作为群体计数的损失函数，它只考虑像素误差，而忽略了估计密度图和真实密度图之间的全局和局部相关性。在本文中，作者将多尺度密度水平一致性损失与欧几里得损失结合起来，衡量全局和局部的一致性。</p><p class=ql-align-justify>欧几里得损失</p><p class=ql-align-justify>欧几里得距离用于测量估计密度图与真实值之间像素级的估计误差。损失函数定义如下：</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/70ae8cf1b5ec4d138f69bf640c911a34><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p>其中 N 是一个 batch 中图像的数目，G(Xi;θ) 是训练图像 Xi 的估测密度图，参数为θ。D 是 Xi 的实际密度图。</p><p class=ql-align-justify>多尺度密度水平一致性损失</p><p class=ql-align-justify>除了像素级损失函数外，作者还考虑了估计密度图和真实值之间的全局和局部密度水平一致性。新提出的训练损失定义为：</p><p class=ql-align-justify></p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/86df87723f5f45f59c2277d455129642><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p>其中 s 是用于一致性检查的尺度级别数，P 是平均池化操作，kj 为平均池化的指定输出大小。</p><p class=ql-align-justify>尺度级别将密度图分割成不同的子区域，并形成池化表示，说明不同位置的人群密度级别。根据密度水平的上下文，在不同的尺度上，估计的密度图需要与实际情况保持一致。此外，尺度级别的数量和特定尺度的输出尺寸控制着训练速度和估计精度之间的权衡。作者采用三个尺度级别，每个输出尺寸分别为 1×1、2×2 和 4×4。输出大小为 1×1 的第一个尺度级别捕获密度水平的全局特征，而其他两个尺度级别表示图像块的局部密度水平。</p><p class=ql-align-justify>最终目标函数</p><p class=ql-align-justify>通过对上述两个损失函数加权求和，整个网络使用以下目标函数进行训练：</p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/89e60d96848d4f1abb8d5844631f0a06><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><div class=pgc-img><img alt="中科院提出人群密度检测算法 DSNet，准确率提升 30%" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ce7c564da78040f0864e75ddb59abdae><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p>表 1 不同数据集的λ值</p><h1 class=ql-align-justify>3 实现</h1><p class=ql-align-justify><br></p><p class=ql-align-justify>3.1 生成真实值</p><p class=ql-align-justify>3.2 评价方法</p><p>点击“了解更多”获取原文</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'检测','DSNet','准确'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>