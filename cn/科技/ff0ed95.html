<!doctype html><html lang=cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Spark 2.x 中文文本分类 | 极客快訊</title><meta property="og:title" content="Spark 2.x 中文文本分类 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="cn"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/6153457d5b9e4bc6908d327df8170a58"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/ff0ed95.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/ff0ed95.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="Spark 2.x 中文文本分类"><meta name=author content="极客快訊"><meta property="og:url" content="/cn/%E7%A7%91%E6%8A%80/ff0ed95.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快讯 Geek Bank</a></h1><p class=description>为你带来最全的科技知识 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Spark 2.x 中文文本分类</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=cn/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>﻿今天将我写的中文二分类的例子分享给大家</h1><p><strong>整体步骤就是</strong></p><ol><li><strong>获取文本数据</strong></li><li><strong>文本分词处理</strong></li><li><strong>HashTF映射</strong></li><li><strong>选择算法模型</strong></li><li><strong>测试预测结果</strong></li></ol><p>Now我们看一下数据长什么样儿</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6153457d5b9e4bc6908d327df8170a58><p class=pgc-img-caption>原始数据</p></div><p>这个数据就是某个店铺的评论数据，上述数据可以发现并没有好评标签，所以需要我们人为的给它们人工加标签（加标签这一步可以在这里进行也可以分词后再进行）。</p><p>接下来我们要进行分词处理，我这里使用了<strong>结巴分词器</strong>（其它的分词器还有SnowNLP</p><p>和NLPIR etc）</p><p>分词的代码贴个图吧，这里需要注意的是要加载停用词（停用词就是遇到这个词就删掉 比如说 了，的，啊，喔 等没有意义的词）</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/133f901fe9b6412ca29b556538b8d673><p class=pgc-img-caption>结巴分词</p></div><p>接下来我们看分词完后加上人工标签后的数据：</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b32bbaee39d64e239149d2789d9b32b0><p class=pgc-img-caption>分词后的数据</p></div><p>上图看的出分词效果还不错哈。</p><p>接下来就上我们的Spark，本次我是用的databrick平台进行的运算，因为其平台可视化比较好</p><p>首先上传数据</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d4258f960f024e1da9dedce3f596bb89><p class=pgc-img-caption>使用databriks平台上传数据</p></div><p>接着正式写Spark</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7cae0c0ed1f04533b3957a5ef5afd123><p class=pgc-img-caption>导入相关包</p></div><p>定义UDF函数，将字符串转为INT的函数</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8c1fbe0ae0f647d8a0c6be65a36ab9b6><p class=pgc-img-caption>定义UDF</p></div><p>读取上传的数据，并打印出数据</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0509a743a3de4a31bd81efb6bb1c343a><p class=pgc-img-caption>读取打印数据</p></div><p>接着使用我们定义的udf函数将labelStr列转为数值INT类型</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0d393e045f774a48a217735a7f25023a><p class=pgc-img-caption>新增label列替换labelStr</p></div><p>接下来映射HashTF，由于数据量不大，所以只映射为500个hash桶，大家没意见吧，没意见的话我们接着使用IDF进行词频统计，并选择逻辑回归算法模型进行计算</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/eb7433d1971b49ce90712647a0da598e><p class=pgc-img-caption>映射hashTF并使用IDF</p></div><p>构建pipeline管道，将上面创建好的常量统统丢进去！！！</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6186d882267f47a5842ab517876ba9a6><p class=pgc-img-caption>创建管道</p></div><p>这边就是使用pipeline.fit()方法训练数据得到模型model</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c8a2e77bf20d418bbfcab1c16037fe59><p class=pgc-img-caption>训练数据得到model</p></div><p>最后我们将需要测试的数据<strong>先进行分词然后丢进来</strong></p><p>分词完后的测试数据样例：</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c3603c2ef7f2432482dcaffb770823ca><p class=pgc-img-caption>测试数据样例</p></div><p>然后和刚才一样上传到databrick平台，读取上传文件的数据</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b9a359d03be941edad817bdc4cef195f><p class=pgc-img-caption>读取上传的测试数据</p></div><p>最后就是拿刚才的模型进行训练啦！！！！</p><div class=pgc-img><img alt="Spark 2.x 中文文本分类" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a33e0b6b426649c5be1d130b4a04d21b><p class=pgc-img-caption>训练的结果</p></div><p>从训练的结果来看，分类并没有很准确 能有个7、8成吧。</p><h1><strong>可能的原因有</strong></h1><ul><li><strong>数据量太小、</strong></li><li><strong>分词不够准确、</strong></li><li><strong>关键词没有确认、</strong></li><li><strong>模型没有选对</strong></li></ul><p>Spark的算法模型还有NavieBayes、SVC等等，这些算法大家可以去尝试一下。</p><p>如果想学习databrick，请查看我的其他文章</p><h1>如果你想要数据的话 记得<strong> 点赞 转发 评论 收藏</strong></h1><p>谢谢啦 加班完成分享</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>'Spark','分类','文本'</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-146415161-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>