<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>常用數據挖掘算法從入門到精通 第十一章 支持向量機算法 | 极客快訊</title><meta property="og:title" content="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/37dd0003bcc2aafbf1d2"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/04a590e1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/04a590e1.html><meta property="article:published_time" content="2020-10-29T21:13:00+08:00"><meta property="article:modified_time" content="2020-10-29T21:13:00+08:00"><meta name=Keywords content><meta name=description content="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/04a590e1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>常用數據挖掘算法從入門到精通 第十一章 支持向量機算法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><p>上一章為大家介紹了<strong>支持向量機（Support Vector Machine，SVM）</strong>的理論基礎—<strong>統計學習理論</strong>的一些重要知識點，本章正式為大家介紹<strong>支持向量機算法</strong>。</p><p>支持向量機是在<strong>統計學習理論</strong>的<strong>VC維</strong>和<strong>結構風險最小化原理</strong>的基礎上發展起來的一種新的<strong>機器學習方法</strong>。SVM根據<strong>有限樣本</strong>的信息在<strong>模型的複雜性</strong>（即<strong>對特定樣本的學習精度</strong>）和<strong>學習能力</strong>（即<strong>無錯誤地識別任意樣本的能力</strong>）之間尋求最佳<strong>折中</strong>，以期獲得最好的<strong>推廣能力</strong>。</p><h1>結構風險最小化(Structural Risk Minimization，SRM）</h1><p>統計學習理論從VC維的概念出發，推導出關於<strong>經驗風險</strong>和<strong>期望風險（真實風險的期望風險）</strong>之間關係的重要結論，稱為<strong>泛化誤差界</strong>，統計學習理論給出了以下估計真實風險的不等式。<br></p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37dd0003bcc2aafbf1d2></p><p class=pgc-img-caption>估計真實風險的不等式</p><p>其中R(w)是<strong>真實風險</strong>，Remp(w)表示<strong>經驗風險</strong>，Φ(n/h)稱為<strong>置信風險（置信範圍）</strong>；n代表<strong>樣本數量</strong>，h是函數集合的<strong>VC維</strong>，Φ是<strong>遞減函數</strong>。</p><p>上述不等式（定理）說明，學習機器的<strong>期望風險</strong>由兩部分組成：</p><ul class=list-paddingleft-2><li><p>第一部分是<strong>經驗風險（學習誤差引起的損失）</strong>，依賴於預測函數的選擇</p></li><li><p>第二部分稱為<strong>置信範圍</strong>，是關於函數集<strong>VC維h</strong>的增函數</p></li></ul><p>顯然，如果<strong>n/h較大</strong>，則期望風險值由經驗風險值決定，此時為了最小化期望風險，我們只需最小化經驗風險即可；</p><p>相反，如果<strong>n/h較小</strong>，經驗風險最小並不能保證期望風險一定最小，此時我們必須同時考慮<strong>不等式右端的兩項之和</strong>，稱為<strong>結構風險</strong>。</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37de000044fb10b2449c></p><p class=pgc-img-caption>結構風險最小化</p><ul class=list-paddingleft-2><li><p>一般的學習方法(如神經網絡)是<strong>基於 Remp(w) 最小，</strong>滿足對<strong>已有訓練數據的最佳擬和，</strong>在理論上可以通過增加算法（如神經網絡）的<strong>規模</strong>使得Remp(w) 不斷降低以至為0</p></li><li><p>但是,這樣使得算法（神經網絡）的<strong>複雜度增加</strong>，<strong>VC維h增加，</strong>從而<strong>Φ</strong><strong>(n/h)增大，</strong>導致<strong>實際風險R(w)增加</strong>，這就是學習算法的<strong>過擬合(Overfitting)</strong>.</p></li></ul><p>大家如果想更好地理解<strong>結構風險最小化原則</strong>，可以先看一下前一篇文章<strong>《 第十章 支持向量機理論基礎》</strong>，裡面有一些關於統計學習理論主要知識的比較詳細的介紹。</p><h1>分類問題的數學表示</h1><p><strong>2維</strong>空間上的分類問題⇨<strong>n維</strong>空間上的分類問題。</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37e4000069129513b1a6></p><p class=pgc-img-caption>分類問題的數學表示</p><h1>分類問題的學習方法</h1><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e300008062bbae99ed></p><p class=pgc-img-caption>分類問題的學習方法</p><p>SVM分類問題大致有三種：<strong>線性可分問題、近似線性可分問題、線性不可分問題</strong>。</p><h1>線性可分情形：最大間隔原理</h1><p>對於線性可分的情況，<strong><em>l</em>_</strong>到<strong><em>l0</em></strong>和<strong><em>l+</em></strong>到<strong><em>l0</em></strong>的距離和，利用兩條平行直線間的距離公式很容易得到距離（間隔）=<strong>2/||w||</strong>，最大化間隔就是求w的最小值。<em>S.T.</em>說明必須<strong>在滿足約束條件（正確分類）的前提下求w的最小值</strong>。<br></p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/37e500007683980dd25e></p><p class=pgc-img-caption>線性可分情形</p><blockquote><p><strong>模型求解：</strong></p></blockquote><p>原始問題是一個典型的<strong>線性約束的凸二次規劃問題</strong>，模型求解主要用到了<strong>運籌學</strong>裡面的方法，在這裡就不仔細展開了，求解的思想主要是：</p><ol class=list-paddingleft-2><li><p>第一步，在原始問題中引入<strong>拉格朗日乘子</strong>轉化為無約束問題（拉格朗日乘子法）;</p></li><li><p>第二步，根據最優化的<strong>一階條件</strong>將原始問題轉化為<strong>對偶問題</strong>;</p></li><li><p>第三步，根據<strong>KKT條件</strong>得到求得最優解時應滿足的條件.</p></li></ol><blockquote><p>KKT條件是拉格朗日乘子法的泛化，在有等式約束時使用拉格朗日乘子法，在有不等約束時使用KKT條件</p></blockquote><ul class=list-paddingleft-2><li><p><strong>支持向量：</strong></p></li></ul><p>在兩類樣本中<strong>離最優分類超平面最近</strong>且在平行於最優分類超平面的平面<strong><em>l_</em></strong>,<em><strong>l+</strong></em>上的訓練樣本就叫做<strong>支持向量</strong>，理解為它們支撐起了<strong>超平面</strong><strong><em>l_</em></strong>和<strong><em>l+</em></strong>，所以稱為<strong>支持向量</strong>，數學含義如下。</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37dd00040c0b4d16de93></p><p class=pgc-img-caption>支持向量</p><h1>近似線性可分情形</h1><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37dd000415cde11c2b99></p><p class=pgc-img-caption>近似線性可分情形</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e60000a245e904203f></p><p class=pgc-img-caption>引入鬆弛變量</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37de0000b054e48174ff></p><p class=pgc-img-caption>引入懲罰函數</p><p>即，<strong>C代表了經驗風險與置信風險的折中。</strong></p><h1>線性不可分情形</h1><p>把尋找<strong>低維空間非線性的“最大超曲面”</strong>問題轉化為在<strong>高維空間</strong>中求解<strong>線性的“最大間隔平面”</strong>問題。即，把<strong>非線性可分的樣本映射到高維空間，使樣本線性可分</strong>。</p><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/37e50000ed267e348feb></p><p class=pgc-img-caption>線性不可分情形</p><ul class=list-paddingleft-2><li><p>線性不可分模型</p></li></ul><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37e40000c6157e64036d></p><p class=pgc-img-caption>線性不可分模型</p><p>模型（3）的求解，必須知道<strong>非線性映射Ф的具體形式</strong>，但實際工作上，給出Ф的具體形式往往是<strong>非常困難</strong>的。</p><ul class=list-paddingleft-2><li><p>線性不可分問題的求解</p></li></ul><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37de0000f419a5ac5ea0></p><p class=pgc-img-caption>線性不可分問題的求解</p><h1><strong>核函數K(xi,xj)</strong></h1><p>K(xi,xj)=(Ф(xi),Ф(xj))=Ф(xi)*Ф(xj)是樣本xi,xj<strong>在特徵空間中的內積</strong>，稱為<strong>輸入空間</strong>X上的<strong>核函數</strong>。</p><ul class=list-paddingleft-2><li><p>對非線性問題, 可以通過<strong>非線性變換</strong>轉化為某個高維空間中的線性問題, 在變換空間求最優分類面. 這種<strong>變換可能比較複雜</strong>, 因此這種思路在一般情況下不易實現</p></li><li><p>為了避免從低維空間到高維空間可能帶來的<strong>維數災難問題</strong>，避免進行<strong>高維的內積運算</strong><br></p></li></ul><p>綜上考慮引入核函數。</p><ul class=list-paddingleft-2><li><p>利用<strong>核函數</strong>代替向<strong>高維空間的非線性映射</strong>，並且不需要知道<strong>映射函數</strong></p></li><li><p>在最優分類面中採用適當的<strong>核函數</strong>就可以實現某一<strong>非線性變換後的線性分類</strong>,而<strong>計算複雜度卻沒有增加</strong></p></li><li><p>通過計算<strong>K(xi,xj)的值</strong>可以<strong>避免高維空間的內積運</strong>算，這種內積運算可通過<strong>定義在原空間中的核函數</strong>來實現, 甚至不必知道<strong>變換的形式</strong><br></p></li></ul><blockquote><p>SVM中不同的核函數將形成不同的算法，主要的核函數有三類：</p></blockquote><p><img alt="常用數據挖掘算法從入門到精通 第十一章 支持向量機算法" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/37de000106419f7199b0></p><p class=pgc-img-caption>SVM常見的核函數</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>算法</a></li><li><a>數據</a></li><li><a>從入</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/ef6637be.html alt=數據結構與算法——最小生成樹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/36b27200eb7c41258d8210393c3e09bf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/ef6637be.html title=數據結構與算法——最小生成樹>數據結構與算法——最小生成樹</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/5f49cdf4.html alt="算法數據結構 | 圖論基礎算法——拓撲排序" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/08463ba999024f5196ee88aa19271453 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/5f49cdf4.html title="算法數據結構 | 圖論基礎算法——拓撲排序">算法數據結構 | 圖論基礎算法——拓撲排序</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2a4da90.html alt=數據結構與算法系列——棧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/0d4a7d6b37a44c58a0ea25dcacf791fe style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2a4da90.html title=數據結構與算法系列——棧>數據結構與算法系列——棧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c3e3bf2.html alt=數據結構與算法（5）棧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/64b8a77987c34980862b62b33586c54e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c3e3bf2.html title=數據結構與算法（5）棧>數據結構與算法（5）棧</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/cf78e53.html alt=數據結構與算法：算法的時間複雜度 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e6eb9908a8c7481089159ead17c42eae style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/cf78e53.html title=數據結構與算法：算法的時間複雜度>數據結構與算法：算法的時間複雜度</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3d54fe0b.html alt="深度研究自然梯度優化，從入門到放棄 | Deep Reading" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2cc1b8ef47a5458190c22d26d8bd164c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3d54fe0b.html title="深度研究自然梯度優化，從入門到放棄 | Deep Reading">深度研究自然梯度優化，從入門到放棄 | Deep Reading</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ed4abe39.html alt=算法小專欄：散列表（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a831970b0ccf4e4cbe591777ebd3f2a3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ed4abe39.html title=算法小專欄：散列表（二）>算法小專欄：散列表（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html alt=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3e507bb24abc482fb28df1121a7ee097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html title=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出>數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html alt="數據科學家常犯的 10 個編程錯誤" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html title="數據科學家常犯的 10 個編程錯誤">數據科學家常犯的 10 個編程錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html alt=數據科學家常遇到的10個錯誤 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/59f660bac8b541888e71459b604ba733 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html title=數據科學家常遇到的10個錯誤>數據科學家常遇到的10個錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html alt=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f120ed2c1ed549e39bfa60bb3a86d591 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html title=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定>WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html alt="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7aa6ee1b961f467e8090ed56f45c110f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html title="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成">多列數據合併一列，還在用數據透視就out了，用=號只要三步完成</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/38aea254.html alt=七大查找算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/15393515221731c57aa8da1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/38aea254.html title=七大查找算法>七大查找算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51e4e55b.html alt=掌握算法-散列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7fe8d19cb78241e999d77102bee7e16c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51e4e55b.html title=掌握算法-散列>掌握算法-散列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html alt=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3609570de59a49a9be5667dd9a637f65 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html title=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心>數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>