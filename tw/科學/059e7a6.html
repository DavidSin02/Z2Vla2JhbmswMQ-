<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比 | 极客快訊</title><meta property="og:title" content="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/f6a60d9d13f84286a71f27b8edb150f1"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/059e7a6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/059e7a6.html><meta property="article:published_time" content="2020-10-29T21:01:37+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:37+08:00"><meta name=Keywords content><meta name=description content="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/059e7a6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><h1 class=ql-align-center><strong>簡介</strong></h1><p class=ql-align-justify><strong><em>MachineLearning Yearning</em></strong>Sharing 是北京科技大學“機器學習研討小組”旗下的文獻翻譯項目，其原文由Deep Learning.ai 公司的吳恩達博士進行撰寫。本部分文獻翻譯工作旨在研討小組內部交流，內容原創為吳恩達博士，學習小組成員只對文獻內容進行翻譯，對於翻譯有誤的部分，歡迎大家提出。歡迎大家一起努力學習、提高，共同進步！</p><blockquote><p><strong>【關注微信公眾號：人工智能前沿講習班，回覆“MLY”，獲取完整版PDF電子書】</strong></p></blockquote><h1 class=ql-align-center><strong>致謝</strong></h1><p class=ql-align-justify>Deep Learning.ai公司</p><p class=ql-align-justify>吳恩達（原文撰稿人）</p><p class=ql-align-justify>陸順（1-5章）</p><p class=ql-align-justify>樑爽（6-10章）</p><p class=ql-align-justify>鄭燁（11-15章）</p><p class=ql-align-justify>吳晨瑤（16-20章）</p><p class=ql-align-justify>玉巖（21-25章）</p><p class=ql-align-justify>陳波昊（25-30章）</p><p class=ql-align-justify>翟昊（31-35章）</p><p class=ql-align-justify>高宏宇（36-40章）</p><p class=ql-align-justify>丁韓旭（41-45章）</p><p class=ql-align-justify>李湯睿（46-50章）</p><p class=ql-align-justify>馬聰 （整體彙總）</p><p class=ql-align-justify>北京科技大學“機器學習研討小組”</p><p class=ql-align-justify>人工智能前沿學生論壇（FrontierForum of Artificial Intelligence）</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f6a60d9d13f84286a71f27b8edb150f1><p class=pgc-img-caption></p></div><h1 class=ql-align-justify><strong>28、診斷偏差和方差：學習曲線</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：陳波昊</p><p class=ql-align-justify>我們已經見過了一些用於估計有多少訓練錯誤可歸因於可避免的誤差和方差的方法。我們通過估計最佳錯誤率和計算算法在訓練集和驗證集上的誤差來實現這一點。現在我們要討論一種能提供更多信息的技術：繪製學習曲線。</p><p class=ql-align-justify>學習曲線圖將算法在驗證集上的誤差同訓練的實例數目做對照。為了繪製它，你需要以不同規模的訓練集來訓練你的算法。例如，你有1000個數據，你可以分別以100、200、300……直到1000的訓練集規模來訓練你的算法。然後你可以繪製驗證集上的誤差同訓練數目的關係。以下是一個例子：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/679390c725c24bd8ae7843146ec6f01d><p class=pgc-img-caption></p></div><p class=ql-align-center>可以看出，隨著訓練集規模的上升，誤差在逐漸下降。</p><p class=ql-align-justify>我們經常有一些希望我們的算法能夠在實際訓練過程中實現的“理想錯誤率”。例如：</p><ul><li class=ql-align-justify>如果我們期待算法有人類級別的表現，那麼人類的錯誤率就是我們期待的“理想錯誤率”。</li><li class=ql-align-justify>如果我們的學習算法服務於某些產品（如提供貓的圖片），我們會對能給客戶完美體驗的表現所需的“理想錯誤率”有一個大致的推測。</li><li class=ql-align-justify>如果你已經為一個重要的項目工作了很久，那麼你可能已經對於下個階段或下一年的進展有了直覺上的推測。</li></ul><p class=ql-align-justify>在學習曲線上添加期待的性能指標：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/73f4a81ba06c4e40864c1db91417785f><p class=pgc-img-caption></p></div><p class=ql-align-center>你可以視覺上直觀的推測出，利用增加數據量的方式能夠使得紅色的誤差曲線和期望性能差距縮小多少。從上面圖表中曲線的下降趨勢來看，加倍數據集的規模可能會使算法達到期待的性能。</p><p class=ql-align-justify>但是如果誤差曲線已經“穩定化”（即曲線趨勢變平），那麼你可以立刻推斷出，再多的數據也不可能實現期待的性能。</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d595a8050ef348cabdddedbeb908845f><p class=pgc-img-caption></p></div><p class=ql-align-justify>參考這幅學習圖像，或許能幫助你避免花費好幾個月收集雙倍的訓練數據，結果只是證明這個方法是無效的。</p><p class=ql-align-justify>這個過程的一個缺點是，如果你只參考繪製出的誤差曲線，那麼很難推測出紅色曲線之後的走向。如果你有更多的訓練數據，那麼有一個附加的曲線圖可以幫助你預測在更多數據下的訓練效果：訓練誤差圖。</p><h1 class=ql-align-center><strong>29、繪製訓練誤差曲線</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：陳波昊</p><p class=ql-align-justify>隨著訓練集大小的增長，你的驗證集（和訓練集）誤差應該會減少。但訓練集上的誤差通常會隨著訓練集規模的增長而增加。</p><p class=ql-align-justify>讓我們用一個例子說明這種現象。假定你的訓練集只有兩個訓練樣本：一隻貓的圖片和一隻不是貓的圖片。在訓練集中，算法非常容易“記住”這兩個樣本，並且可以取得0%的訓練集誤差。即使至少有一個樣本被錯誤標記了，算法也非常容易記住這兩個標籤。</p><p class=ql-align-justify>現在假設你的訓練集有100個樣本。可能有一些樣本標記錯誤或者模稜兩可——圖像非常模糊，即使人類也不能確定這是不是一隻貓。或許學習算法能記住大部分或者全部的訓練集，但在現在的情況下，已經很難做到100%的準確率了。就本次簡單地將訓練集規模從2加大到100的過程中，你就能發現算法對訓練集的準確率會略有下降。</p><p class=ql-align-justify>最後，我們假設訓練集有10000個樣本。在這種情況下，算法對完全適合這10000個樣本變得更加困難，尤其是裡面還有一些模糊樣本或者錯誤樣本。因此，你的學習算法將會在這個訓練集上表現的更糟糕一些。</p><p class=ql-align-justify>讓我們在之前的圖表上增加一個訓練誤差和訓練集規模的關係曲線：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/64231c0e340e4302b9cc33677ebc19b9><p class=pgc-img-caption></p></div><p class=ql-align-center>可以看到，藍色的“訓練誤差”曲線隨著訓練集規模的增長而上升。此外，算法在訓練集上的表現經常優於在驗證集上的表現。從而使得紅色的偏差曲線通常嚴格地位於藍色訓練誤差曲線上。</p><p class=ql-align-justify>我們接下來討論如何解釋這些圖。</p><h1 class=ql-align-center><strong>30、解釋誤差曲線：高偏差</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：陳波昊</p><p class=ql-align-justify>假定你的驗證集誤差曲線如下圖：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c6faf4c5a95643e2b6f6fe87f41150fb><p class=pgc-img-caption></p></div><p class=ql-align-center>正如我們之前所說，如果你的驗證集誤差曲線進入到平緩期，你就不太可能通過單純添加數據使得算法達到期望的性能。</p><p class=ql-align-justify>但是，我們很難知道紅色誤差曲線之後的發展趨勢究竟是怎麼樣的。如果驗證集很小，則由於曲線上疊加的環境噪聲，會更加不確定曲線的發展趨勢。</p><p class=ql-align-justify>假設我們繼續在圖中添加訓練誤差曲線，如下圖：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/242e341b85034d9bbc4b97f09d1a3170><p class=pgc-img-caption></p></div><p class=ql-align-center>現在我們可以非常確定增加更多的數據也不會使算法的表現更優秀了，因為算法的性能已經提升到了極限。為什麼我們可以得出這個結論？請記住我們的兩條觀察結果：</p><ul><li class=ql-align-justify>隨著我們添加更多的訓練數據，訓練誤差曲線只會變得更差。因此，藍色的訓練誤差曲線只可能保持現狀或者增高。因此，它只能離期待的性能（綠線）越來越遠。</li><li class=ql-align-justify>紅色驗證集誤差曲線通常高於藍色訓練誤差曲線。因此，在當前訓練誤差曲線已經高於期待的性能情況下，幾乎沒有辦法通過添加數據來使得紅色驗證集誤差曲線低於期待的性能水平。</li></ul><p class=ql-align-justify>通過在一張圖上同時做出驗證集誤差和訓練誤差兩條曲線，我們瞭解了更多關於驗證集誤差曲線的情況。</p><p class=ql-align-justify>為了便於討論，我們假定期望的性能就是我們估計的最佳錯誤率。上圖的具有高可避免偏差的學習曲線基本是一個“教科書”級的示例：在最大的訓練集規模下——與我們全部的訓練數據相對應，在訓練集誤差和期望的性能之間有很大差距。表明有大量可避免的偏差。此外，訓練集誤差和驗證集誤差曲線之間差距很小，表明方差較小。</p><p class=ql-align-justify>之前我們只在圖表最正確的位置測量訓練集和開發集誤差，對應於真實情況下我們使用全部的可用數據。畫出的完整學習曲線可以使我們在不同規模的訓練集情況下較為全面地瞭解算法性能。</p><h1 class=ql-align-center><strong>31、解釋學習曲線：其他情況</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：翟昊</p><p class=ql-align-justify>考慮下面的學習曲線：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5031edc3b1ca4601a81323eae8c3329a><p class=pgc-img-caption></p></div><p class=ql-align-justify>該圖是否表示了高偏差、高方差的情況，或者兩個兼具？</p><p class=ql-align-justify>藍線所表示的訓練集錯誤曲線相對較低，並且紅線所表示的驗證集錯誤比藍色的訓練集錯誤高很多。因此，偏差很小，但是方差很大。添加更多的訓練數據可能會使得驗證集和訓練集錯誤之間的差距減小。</p><p class=ql-align-justify>現在，轉而考慮下面的：</p><div class=pgc-img><img alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/bc8df1d1aab440b5a1c3bbebce089582><p class=pgc-img-caption></p></div><p class=ql-align-justify>這種情況下，訓練集錯誤很大，而且遠超過期望水平。驗證集錯誤同樣也比訓練集錯誤大很多。因此，會得到巨大的偏差和巨大的方差。你將需要去在你的算法中找到同時減少偏差和方差的方法。</p><h1 class=ql-align-center><strong>32、繪製學習曲線</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：翟昊</p><p class=ql-align-justify>假設你有一個很小的訓練集，只有100個樣例。你隨機從訓練集中依次選出10個、20個、30個，直到100個樣例去訓練算法，每次增加10個。之後你用這些間隔為10的數據點畫出學習曲線。你可能會發現曲線在較小的訓練集大小的時候看起來有噪點（意為取值比預期要高/低些）。</p><p class=ql-align-justify>當訓練只有10個隨機樣例的數據集的時候，你可能會很不幸的選到特別“壞”的訓練集，比如一個有著很多模糊/貼錯標籤樣例的訓練集。或者，你可能會很幸運選到特別“好”的訓練集。在一個小訓練集的條件下，意味著驗證集和訓練集錯誤可能會隨機波動。</p><p class=ql-align-justify>如果你的機器學習應用程序嚴重的偏向於一類（比如對於貓的分類任務，其中負例的份數遠遠大於正例），或者它有許多類（比如識別100種不同的動物），那麼選到特別“不具有代表性”或者壞的訓練集的可能性也很大。舉例來說，如果你的例子中80%是負例（y=0），只有20%是正例（y=1），那麼就有可能在一個有10個例子的訓練集中只含有負例，就使得算法很難學到有意義的東西。</p><p class=ql-align-justify>如果訓練曲線的噪點使得我們很難看清真實的趨勢，下面給出兩種解決辦法：</p><ul><li class=ql-align-justify>相比起只用10個樣例訓練一個模型，更應該選擇幾組（比如說3-10組）隨機採樣的含有10個樣例的訓練集，這些訓練集是從原來的100個樣例的訓練集中不重複地採樣<sup>[1]</sup>的。對它們用一個不同的模型進行訓練，計算每個訓練集所產生的模型的訓練集錯誤和驗證集錯誤。計算並繪製出平均訓練集錯誤和平均驗證集錯誤的圖像。</li><li class=ql-align-justify>如果你的訓練集偏向於一類，或者有很多類，那麼相比從100個樣例中隨機選出10個作為訓練集，選擇一個“平衡的”子集是更好的做法。舉例來說，當你可以確認訓練集中的2/10是正例、8/10是負例的情況時就適用。更一般地，當你可以確認某一類的樣例所佔比例很接近全部樣例的時候都適用。</li></ul><p class=ql-align-justify>除非已經嘗試繪製學習曲線，並且是由於曲線的噪點太大而無法看出潛在的趨勢，否則我不會理會這些技巧。如果你的訓練集很大（比如超過10,000個樣例）並且你的分類傾向性不是很強，那麼你可能不需要這些技巧。</p><p class=ql-align-justify>最後需要說的是，繪製學習曲線可能在計算資源花費上很昂貴：舉例來說，你可能需要分別用1,000個、2,000個，直到10,000個樣例訓練十個模型。用小數據集訓練模型會比用大數據集訓練快很多。因此，相比於向上面那樣線性分佈訓練集大小，用1,000、2,000、4,000、6,000和10,000個樣例訓練可能更好。這樣也能在學習曲線中給你清晰的對趨勢的感覺。當然了，這個技巧只有在訓練所有額外模型的計算花費很大的時候才有用。</p><blockquote><p>[1]這裡的原文是“sampling <em>with replacement</em>”，意為：先從100個樣例中隨機選出10個不同的樣例作為第一個訓練集。然後再一次選擇10個樣例作為第二個訓練集，不過不能選第一次已經選過的樣例。因此，通常來講一個特定的樣例同時出現在第一個和第二個訓練集是可能的；但與之相對的<em>不重複</em>採樣，第二個訓練集就是從剩下的90個沒在第一次選出的樣例中選擇。在實踐中，重複採樣和不重複採樣不會產生很大的差別，但是前者是常見做法。</p></blockquote><h1 class=ql-align-center><strong>33、為什麼我們要和人類水平的表現相比較</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：翟昊</p><p class=ql-align-justify>許多機器學習系統目標是在人類擅長的領域實現自動化，例如圖像識別、語音識別和垃圾郵件分類。由於學習算法的進步，我們現在能在更多的領域超越人類水平的表現。</p><p class=ql-align-justify>此外，如果你在嘗試做一些人類擅長領域的任務，建立機器學習系統會更加容易。下面給出了幾個原因：</p><p class=ql-align-justify><strong>1、易於獲取人類貼標數據。</strong>舉例來說，由於人類很容易識別帶有貓的圖片，所以為你的學習算法提供高準確率的貼標數據是很自然的事情。</p><p class=ql-align-justify><strong>2、 對錯誤的分析可以借鑑人類的直覺。</strong>假設某個語音識別算法的識別率不如人類水平，並且對一段音頻“This recipe call for a <em>pear</em>of apples”發生了錯誤，把“pair”識別為了“pear”。你可以借鑑人類的直覺，嘗試去理解在人類正確處理的過程中運用了哪些信息，然後將這些信息運用到修改學習算法上面。</p><p class=ql-align-justify><strong>3、運用人類水平的表現去預測最佳的錯誤概率、設置“期望的錯誤概率”。</strong>假設你的算法在一項任務上達到了10%的錯誤率，但是人類可以達到2%的錯誤率，那麼我們就明白最佳的錯誤概率至少是2%，算法可避免的偏差還有至少8%。因此，你可以嘗試減少偏差的技巧。</p><p class=ql-align-justify>即使第3項可能聽起來不是那麼重要，但我發現當有一個有意義的、可實現的目標對於加快團隊進展很有幫助。知曉你的算法還有很大的可避免的偏差很重要，會激起你去嘗試的慾望。</p><p class=ql-align-justify>有很多工作即使是人類也不擅長，例如選一本書推薦給你、選一個廣告在網站中展示給用戶亦或是預測股票市場。計算機已經在這些工作上超越了大部分人類，由此產生了以下這些問題：</p><ul><li class=ql-align-justify><strong>獲取標籤更難了。</strong>舉例來說，很難讓人類貼標者給數據庫中的用戶推薦“最佳”的書去閱讀。如果你在運作一個買書的網站或者應用程序，你可以獲取用戶都買了什麼書的數據；如果你沒有在運作這樣的網站，你就得用更巧的手段獲取數據。</li><li class=ql-align-justify><strong>很難借鑑人類的直覺了。</strong>舉例來說，很多人都無法預測股票市場的走勢。所以即使一個股票預測算法還不如隨機瞎猜，那也很難找到改善它的方法。</li><li class=ql-align-justify><strong>很難知道最佳錯誤概率和合理期望錯誤概率。</strong>假設你有一個圖書推薦系統，並且運行良好，那麼如果沒有人類作為基準你怎麼知道它還能提升多少呢？</li></ul><h1 class=ql-align-center><strong>34、如何定義人類水平的表現</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：翟昊</p><p class=ql-align-justify>假設你在研發一個處理醫學圖像的應用程序，它能自動從X光照片中獲取診斷結果。一個沒有任何醫學背景的人經過基礎的訓練可以在此項工作上達到15%的錯誤概率；一位年輕的醫生可以達到10%的錯誤概率；一位經驗豐富的醫生可以達到5%的錯誤概率；一個小的醫學團隊通過研討每一張圖片可以達到2%的錯誤概率。那麼應該把上述的哪個定義為“人類水平的表現”呢？</p><p class=ql-align-justify>在這種情況下，我將會用2%的人類水平的表現作為最佳錯誤概率。你也可以用2%作為期望的表現水準，因為前一章講的三個原因適用這種情況：</p><ul><li class=ql-align-justify><strong>易於獲取人類貼標數據。</strong>你可以找到一個醫學團隊幫助你做只有2%錯誤率的標註。</li><li class=ql-align-justify><strong>對錯誤的分析可以借鑑人類的直覺。</strong>通過和此醫學團隊討論有關圖片的內容，你可以很好地借鑑人類的直覺。</li><li class=ql-align-justify><strong>運用人類水平的表現去預測最佳的錯誤概率、設置“期望的錯誤概率”。</strong>使用2%的錯誤概率作為最佳錯誤率是很合理的。最佳錯誤概率可以低於2%，但不能再高了，因為一個醫學團隊可以達到2%的錯誤概率。相反地，使用5%、10%作為最佳錯誤概率是不合理的，因為我們知道這些對於人類來說都太高了。</li></ul><p class=ql-align-justify>問題來到了如何獲取已標記的數據，你不會希望醫學團隊討論每一張圖片，因為那樣太貴了。沒準你可以讓一個年輕的醫生去做主要部分的標記，然後把難於辨認的少量圖片給富有經驗的醫生或者醫學團隊去辨認。</p><p class=ql-align-justify>如果你的系統現在有40%的錯誤率，那麼你用年輕的醫生（10%的錯誤率）亦或是有經驗的醫生（5%的錯誤率）去標記你的數據、提供指導也就都沒什麼區別了。但如果你的系統已經達到10%的錯誤概率，那麼定義一個2%的人類水平作為參考能夠更好的提升你的系統。</p><h1 class=ql-align-center><strong>35、超越人類水平的表現</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：翟昊</p><p class=ql-align-justify>你現在正研發語音識別並且有一個語音片段的數據庫。假設你的數據庫有很多有噪的語音片段，導致人類都會有10%的識別錯誤。假設你的系統已經達到了8%的錯誤概率。你還能繼續使用第33章中提到的三個技巧使得你的系統快速提升嗎？</p><p class=ql-align-justify>如果你可以分辨出數據的某個子集，其中人類仍然遠超於你系統的識別水平，那麼你就依舊可以使用那些技巧來使得你的系統快速提升。舉例來說，假設你的系統在識別噪聲方面超越了人類，但是人類依舊在快速說話的時候識別率更勝一籌，那麼就符合了上述的情況。</p><p class=ql-align-justify>對於那些快速說話的數據子集：</p><p class=ql-align-justify>1、你依然可以從人類那裡獲得質量高於算法的成績單。</p><p class=ql-align-justify>2、你可以考慮人類直覺是如何正確聽懂快速說話的發聲的，而你的系統卻不可以。</p><p class=ql-align-justify>3、你可以用在識別快速說話方面人類水平的表現作為期望表現的目標。</p><p class=ql-align-justify>更普遍地，只要在驗證集中出現人類正確而你的系統錯誤的樣例，那麼上述的很多技巧就適用。即使你的系統在驗證集/測試集的全局平均表現已經超越人類，這仍舊是對的。</p><p class=ql-align-justify>在很多重要的機器學習應用中，機器已經超越的人類的表現水平。舉例來說，機器對於預測電影的評價、送貨車到某地的用時、是否批准貸款等方面已經比人類更好。一旦人類很難去辨認對於某個樣例算法一定出錯了，那麼就只有一部分技巧適用了。結論就是，在機器已經超越人類的問題上，進展往往很慢；然而在機器仍舊追趕人類步伐的問題上，進展往往很快。</p><blockquote><p><strong>【關注微信公眾號：人工智能前沿講習班 ，回覆“MLY”，獲取完整版PDF電子書】</strong></p></blockquote></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>吳恩達</a></li><li><a>ML</a></li><li><a>Yearning</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/23e2014.html alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/6f70b8b7cd0f4dad93aced78cc14ffcf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/23e2014.html title="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析">吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f564827a.html alt="吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dfa0587764f14afb8ccfd7a33796cd74 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f564827a.html title="吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)">吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/efabb5bb.html alt=吳恩達深度學習筆記(106)-風格遷移網絡講解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/01def15aa8654252990f709965d5b769 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/efabb5bb.html title=吳恩達深度學習筆記(106)-風格遷移網絡講解>吳恩達深度學習筆記(106)-風格遷移網絡講解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3605c009.html alt="吳恩達深度學習筆記(67)-遷移學習（Transfer learning)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f00ccb946c7a451aa25adba4b28799e5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3605c009.html title="吳恩達深度學習筆記(67)-遷移學習（Transfer learning)">吳恩達深度學習筆記(67)-遷移學習（Transfer learning)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9819f021.html alt="吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d934f6fbf66144dca95cbb6ce8223d62 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9819f021.html title="吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）">吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f60a5385.html alt=吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e2a9b89ccb4a4ad58614763e86e85e0a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f60a5385.html title=吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5)>吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b64e226d.html alt=AI和ML在網絡安全中的用例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2ecb2e5d786743a688e69abfd136a5a0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b64e226d.html title=AI和ML在網絡安全中的用例>AI和ML在網絡安全中的用例</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/1ebabf70.html alt=ML基礎：協方差矩陣 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a8ebdba18ae5461a8e462d5fcce85ee4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/1ebabf70.html title=ML基礎：協方差矩陣>ML基礎：協方差矩陣</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/78490c4c.html alt=吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/08fb5feee25546a993820104d81c965a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/78490c4c.html title=吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2)>吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2)</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/31a4d4f2.html alt="吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/c34f86938ddb484298ca8e0a20494ff2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/31a4d4f2.html title="吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)">吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/ebed9a9e.html alt=為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3c8b122558234a6fa193f00f54ae1b1f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/ebed9a9e.html title=為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法>為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d9e4144e.html alt=吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/78ac000683f4faa986fc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d9e4144e.html title=吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野>吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/99e43ab.html alt=「ML」一文詳盡系列之CatBoost class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f2a5caed2d82451b8d9e0b0f1135f42f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/99e43ab.html title=「ML」一文詳盡系列之CatBoost>「ML」一文詳盡系列之CatBoost</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b3820d4.html alt=「ML」深入理解CatBoost class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f7e6e06fe4c243baa728efbdb3621da6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b3820d4.html title=「ML」深入理解CatBoost>「ML」深入理解CatBoost</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/72a9b3c.html alt=吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b64cd54d8477428589d89e078a3e37b4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72a9b3c.html title=吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹>吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>