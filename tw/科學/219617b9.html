<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>為什麼要進行因子正交化處理？ | 极客快訊</title><meta property="og:title" content="為什麼要進行因子正交化處理？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/ca2925bb8f364c5294c8bfd17a2d5067"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/219617b9.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/219617b9.html><meta property="article:published_time" content="2020-11-14T20:52:23+08:00"><meta property="article:modified_time" content="2020-11-14T20:52:23+08:00"><meta name=Keywords content><meta name=description content="為什麼要進行因子正交化處理？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/219617b9.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>為什麼要進行因子正交化處理？</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><p><strong>摘要</strong></p><p>選股多因子模型中常進行因子正交化處理。如果因子之間不滿足正交性，則它們會相互影響各自的迴歸係數，這可能造成迴歸係數過大的估計誤差，對因子的評價產生負面影響。</p><p class=ql-align-center><strong>1 多因子模型求解</strong></p><p>在選股多因子模型中，人們常提到的一個概念是<strong>因子正交化處理</strong>。本文就從多因子截面迴歸求解的角度來簡單說說為什麼我們喜歡相互正交的因子，以及如果因子之間不正交對迴歸係數會有什麼影響。</p><p class=ql-align-center>一個多因子模型可以寫成如下的形式：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ca2925bb8f364c5294c8bfd17a2d5067><p class=pgc-img-caption></p></div><p class=ql-align-center>其中 <strong>y</strong> 是 N × 1 階股票下一期的收益率向量，<strong>X</strong> 為 N × K 階當期的因子暴露矩陣，<strong>b</strong> 為 K × 1 階待通過迴歸求解得到的因子收益率向量，<strong>ε</strong> 為 N × 1 階殘差向量。假設 <strong>X </strong>滿足列滿秩，則上述模型的 OLS（ordinary least squares）迴歸求解為：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/112967f9b82b445ba797d93a1b0ea287><p class=pgc-img-caption></p></div><p>需要注意的是，在上面這個模型以及 <strong>b</strong> 的表達式中，因子向量 X 已經包括了所有的 regressors，因此迴歸模型右側沒有額外的截距項。這意味著，如果我們假設截距項也是一個因子，則它對應的 N × 1 階向量 [1,1,…,1]^T 已經作為 <strong>X</strong> 的某一列（通常是第一列）存在於 <strong>X</strong> 之中了；如果我們假設截距項不是一個因子，則 <strong>X</strong> 中沒有 [1,1,…,1]^T 這一列。</p><p>在 Barra 的多因子模型 CNE5 中考慮了國家因子，所有個股在該因子上的暴露都是 1，因此它的作用就相當於一個截距因子；[1,1,…,1]^T 這個向量在 Barra 模型中正是 <strong>X</strong> 的第一列。另外，對於我們最熟悉的 simple regression model，它的右側只有一個截距和一個解釋變量：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2382faff418d41a4aea861f5be401a5b><p class=pgc-img-caption></p></div><p class=ql-align-center>按照上述說明，該模型對應的矩陣 <strong>X</strong> 包括兩列：一列對應截距，一列對應真正的解釋變量 <strong>x</strong>：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cf9b9202c1a74a318fd9a0ae49521453><p class=pgc-img-caption></p></div><p>從 <strong>b</strong> 的表達式來看，它和 (<strong>X</strong>^T)<strong>X</strong> 有關。<strong>當 X 的各列（即迴歸模型中的不同解釋變量，或我們研究問題中的不同因子暴露向量）之間不正交時，則在計算 </strong>(<strong>X</strong>^T)<strong>X 乃至最終的 b 時，X 不同列之間是相互影響的，而這種影響不是什麼好事兒。</strong></p><h1 class=ql-align-center><strong>2 簡單一元迴歸</strong></h1><p>讓我們從最簡單的一元迴歸（simple univariate regression）說起。</p><p class=ql-align-center>假設有一元迴歸模型 <strong>y</strong> = b<strong>x</strong> + <strong>ε</strong>（模型右側只有一個解釋變量，<strong>沒有截距項</strong>）。對於兩個同階向量 <strong>m</strong> 和 <strong>n</strong>，令 &lt;<strong>m</strong>, <strong>n</strong>> 表示它們的內積，即 &lt;<strong>m</strong>, <strong>n</strong>> = Σ(m_i)(n_i)，則該一元迴歸模型的 OLS 解為（求解對象就是標量 b）：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2ed08abf442d4954871a611154974194><p class=pgc-img-caption></p></div><p class=ql-align-center>這個結論非常簡單，但是它十分重要。在上一節中，我們給出了多元迴歸 OLS 求解的表達式：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cf4d266e5405499abea7c7f15fe48a55><p class=pgc-img-caption></p></div><p class=ql-align-center>比較一元迴歸模型的標量 b 和多元迴歸模型的向量 <strong>b</strong> 不難發現如下現象：在多元迴歸模型中，如果所有的解釋變量兩兩正交，即 &lt;<strong>x</strong>_i, <strong>x</strong>_j> = 0, i ≠ j，則向量 <strong>b</strong> 中的每一個係數 b_i 恰恰等於：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a2376107090a4dbc99bb6ca5e55b0199><p class=pgc-img-caption></p></div><p>這是因為 &lt;<strong>x</strong>_i, <strong>x</strong>_j> = 0 保證了 (<strong>X</strong>^T)<strong>X</strong> 的所有非對角元素都是 0，因此它是一個對角陣。對角陣的逆矩陣就是把該對角陣對角線上的元素都取倒數，所以逆矩陣仍然是對角陣。因此，(<strong>X</strong>^T)<strong>X</strong> 的第 i 個對角元素為 1/&lt;<strong>x</strong>_i, <strong>x</strong>_i>。另一方面，(<strong>X</strong>^T)<strong>y</strong> 是一個 K × 1 向量，它的第 i 個元素是 <strong>x</strong>_i 和 <strong>y</strong> 的內積，即 &lt;<strong>x</strong>_i, <strong>y</strong>>。最終，多元迴歸的 b_i 正是 &lt;<strong>x</strong>_i, <strong>y</strong>>/&lt;<strong>x</strong>_i, <strong>x</strong>_i>。</p><p>怎麼樣？b_i 和一元迴歸中的 b 的表達式一模一樣，說明<strong>當所有解釋變量相互正交時，不同的因子（即 x</strong>_i<strong>）對彼此的參數估計（即 </strong>b_i<strong>，因子收益率）沒有任何影響。</strong>這便是正交的好處。</p><p>那麼，當因子（解釋變量）之間不正交時又會怎樣呢？為了回答這個問題，我們首先來看看回歸的幾何意義。</p><h1 class=ql-align-center><strong>3 迴歸的幾何意義</strong></h1><p class=ql-align-center>將 <strong>b</strong> 的表達式代入迴歸模型得到 <strong>ε</strong> 的表達式，並計算 <strong>X</strong> 和 <strong>ε</strong> 的內積有；</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/abe476b960dd4424b401d1f8186abe9d><p class=pgc-img-caption></p></div><p>上式說明，OLS 的殘差 <strong>ε</strong> 和解釋變量 <strong>X</strong> 正交。來看看這在幾何上意味著什麼。</p><p class=ql-align-center>首先考慮最簡單的情況，即一元迴歸 <strong>y</strong> = b<strong>x</strong> + <strong>ε</strong>（再次提醒，沒有截距項）。它的幾何意義如下圖所示：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e2c90251b66c4e1ebe7a4cc186644fd1><p class=pgc-img-caption></p></div><p>這個圖說明，OLS 迴歸實際上將 <strong>y</strong> <strong>垂直投影到（orthogonally projected onto）x 之上</strong>，使得 <strong>y</strong> 和其在 <strong>x</strong> 上的投影之間的距離（<strong>ε</strong> 的長度）最短（殘差平方和最小）。這就是 OLS 的幾何意義。</p><p class=ql-align-center>再來看看二元迴歸 <strong>y</strong> = b_1<strong>x</strong>_1 + b_2<strong>x</strong>_2 + <strong>ε</strong>，並首先<strong>假設 x</strong>_1<strong> 和 x</strong>_2<strong> 之間是正交的</strong>。該回歸的幾何意義如下：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d8f2a64bd5994bf18936b014d6218f0f><p class=pgc-img-caption></p></div><p>對於二元迴歸，它的幾何意義是將 <strong>y</strong> 垂直投影到由 <strong>x</strong>_1 和 <strong>x</strong>_2 生成的超平面內，其投影正如上圖中綠色向量所示。此外，我們可以分別、獨立的將 <strong>y</strong> 投影到 <strong>x</strong>_1 和 <strong>x</strong>_2 上（圖中兩個橘黃色向量）。在本例中，<strong>由於 x</strong>_1<strong> 和 x</strong>_2<strong> 相互正交（垂直），因此綠色向量恰好等於兩個橘黃色向量之和。</strong>這說明當 <strong>x</strong>_1 和 <strong>x</strong>_2 正交時，迴歸係數 b_i 僅由 <strong>x</strong>_i 和 <strong>y</strong> 決定、其他任何解釋變量 <strong>x</strong>_j (j ≠ i) 對 b_i 均沒有影響。</p><p class=ql-align-center>下面來看看 <strong>x</strong>_1 和 <strong>x</strong>_2 非<strong>正交</strong>的情況。該二元迴歸的幾何意義如下：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5749d0dd258b4a43a2d8148acf0b8201><p class=pgc-img-caption></p></div><p>它和前一種情況最大的區別是，<strong>當 x</strong>_1<strong> 和 x</strong>_2<strong> 非正交時，y 在由 x</strong>_1<strong> 和 x</strong>_2<strong> 生成的超平面內的投影不等於 y 分別在 x</strong>_1<strong> 和 x</strong>_2<strong> 上的投影之和。</strong>在這種情況下，解釋變量之間對各自的迴歸係數有不同的作用，因此 OLS 的迴歸係數 b_i <strong>不再等於</strong> &lt;<strong>x</strong>_i, <strong>y</strong>>/&lt;<strong>x</strong>_i, <strong>x</strong>_i>。</p><p>非正交 <strong>x</strong>_i 之間的相互作用如何影響迴歸係數 b_i 呢？通過連續正交化來求解多元線性迴歸可以回答這個問題。</p><h1 class=ql-align-center><strong>4 用正交化過程求解多元迴歸</strong></h1><p class=ql-align-center>還是拿我們最熟悉的 simple regression model 為例；該模型有兩個解釋變量 —— 截距項和 <strong>x</strong>。</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/982968f883614773ad708ca0ae9171d1><p class=pgc-img-caption></p></div><p class=ql-align-center>令 <strong>x</strong>_0 表示截距項對應的解釋變量，即 <strong>x</strong>_0 = [1,1,…,1]^T；<strong>x</strong>_1 表示上式中的解釋變量 <strong>x</strong>。假設 <strong>x</strong>_0 和 <strong>x</strong>_1 非正交（正交的話我們就不用費勁了）。對於簡單迴歸模型，迴歸係數 a（對應 <strong>x</strong>_0）和 b（對應 <strong>x</strong>_1）的解為：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5e8f424845d1478a8c9294d587552d45><p class=pgc-img-caption></p></div><p class=ql-align-center>下面就來看看如何通過正交化求解 a 和 b。由於 <strong>x</strong>_0 和 <strong>x</strong>_1 非正交，首先需要構造出一組正交向量。令 <strong>z</strong>_0 = <strong>x</strong>_0 為其中的一個向量，將 <strong>x</strong>_1 用 <strong>z</strong>_0 進行一元迴歸（不帶截距）得到的殘差就是和 <strong>z</strong>_0 互相垂直（正交）的向量，記為 <strong>z</strong>_1。由一元迴歸的性質可知：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4db2714299e0418a979ccbd81e9bc2cd><p class=pgc-img-caption></p></div><p>其中 \bar x 表示 <strong>x</strong> 的均值，<strong>1</strong> 表示列向量 [1,1,…,1]^T，即 <strong>z</strong>_0。</p><p>So far so good？接下來，注意了：</p><p class=ql-align-center><strong>將 y 用上面得到的 z</strong>_1<strong> 進行一元迴歸（不帶截距），得到的迴歸係數就是上述 simple regression model 中解釋變量 x 的迴歸係數 </strong>b<strong>！</strong></p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/058f606b06dc4ad0a2469f5a3e25f85b><p class=pgc-img-caption></p></div><p class=ql-align-center>怎麼樣？我們並沒有直接對該模型求解，而是通過正交化的方式就求出瞭解釋變量 <strong>x</strong>_1 的迴歸係數 b。反應快的小夥伴也許馬上會問 a 呢？a 是否等於 &lt;<strong>z</strong>_0, <strong>y</strong>>/&lt;<strong>z</strong>_0, <strong>z</strong>_0> 呢？別急，我們一會兒就聊 a，但是在那之前先來看一個<strong>通過連續正交化求解多元迴歸的算法</strong>（Hastie et al. 2016）：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d796938df6ae47a0bc735048e3803ce6><p class=pgc-img-caption></p></div><p><strong>該算法的核心是通過連續的正交化計算把一組非兩兩正交的向量 x</strong>_i<strong> 轉換成一組兩兩正交的向量 z</strong>_i<strong>，並以此方便的求出最後一個被正交化的解釋變量的多元迴歸係數。</strong>雖然它只有三步，但是每一步都值得解讀一下：</p><ol><li>第一步是初始化，在所有解釋變量中（如果迴歸中有截距項，就把 [1,1,…,1]^T 看做一個解釋變量）任意挑選一個當作 <strong>x</strong>_0 進行初始化 <strong>z</strong>_0 = <strong>x</strong>_0。</li><li>第二步是<strong>根據我們自己選定的遞歸順序（任意順序都可以）</strong>，對 <strong>x</strong>_1, <strong>x</strong>_2, …, <strong>x</strong>_p 依次進行正交化。例如，對 <strong>x</strong>_j 的正交化處理就是用它和之前已經被處理過後的正交向量 <strong>z</strong>_0, <strong>z</strong>_1, …, <strong>z</strong>_{j-1} <strong>逐一獨立</strong>一元迴歸得到係數 &lt;<strong>z</strong>_k, <strong>x</strong>_j>/&lt;<strong>z</strong>_k, <strong>z</strong>_k>, k = 0, 1, ..., j - 1，進而用 <strong>x</strong>_j 減去 (&lt;<strong>z</strong>_k, <strong>x</strong>_j>/&lt;<strong>z</strong>_k, <strong>z</strong>_k>)<strong>z</strong>_k, k = 0, 1, ..., j - 1 之和，得到的殘差就是最新的正交化向量 <strong>z</strong>_j。</li><li>使用 <strong>y</strong> 和 <strong>z</strong>_p 進行一元迴歸，得到的係數 &lt;<strong>z</strong>_p, <strong>y</strong>>/&lt;<strong>z</strong>_p, <strong>z</strong>_p> 正是這個多元迴歸 OLS 求解中原始解釋變量 <strong>x</strong>_p 的迴歸係數 b_p。注意，這一結論僅對<strong>最後一個</strong>（第 p 個）被正交化後的解釋變量成立。換句話說，對於別的解釋變量 j &lt; p，&lt;<strong>z</strong>_j, <strong>y</strong>>/&lt;<strong>z</strong>_j, <strong>z</strong>_j> 並不是多元迴歸中原解釋變量 <strong>x</strong>_j 的迴歸係數。</li></ol><p>看到這裡，有的小夥伴可能會問，這個算法確實不錯，但是費了半天勁算出了一大堆相互正交的向量 <strong>z</strong>_j，但是求解迴歸係數的結論僅對最後一個被正交化的解釋變量成立，這不是坑爹嗎？</p><p>答案是並不坑爹！這是因為上述算法中的關鍵一點是，<strong>正交化這些解釋變量的順序是任意的</strong>。我們可以選任何一個來初始化，也可以選任何一個作為最後一個被正交化的解釋變量。無論我們怎麼選，上述過程都保證了最後一個被正交化的解釋變量的迴歸係數滿足 b_p = &lt;<strong>z</strong>_p, <strong>y</strong>>/&lt;<strong>z</strong>_p, <strong>z</strong>_p>。因此，<strong>我們只需要依次挑選這些解釋變量作為最後一個被正交化的，就可以通過上述步驟方便的求出它們的迴歸係數。</strong>而它所反映出來的本質是：</p><blockquote><p><strong>在多元線性迴歸中，解釋變量 x</strong>_j<strong> 的迴歸係數 </strong>b_j<strong> 等於 x</strong>_j<strong> 在被其他 x</strong>_0<strong>, x</strong>_1<strong>, …, x</strong>_{j-1}<strong>, x</strong>_{j+1}<strong>, …, x</strong>_p <strong>調整之後（即正交化，從而排除其他 x</strong>_i<strong> 對 x</strong>_j<strong> 的影響）仍能夠對 y 產生的增量貢獻。</strong></p></blockquote><p><strong>這個算法叫作多元迴歸的 Gram-Schmidt（格拉姆-施密特）正交化過程。</strong></p><p>本小節開始的 simple regression model 已經驗證了上述結論。我們使用 <strong>x</strong>_0 將 <strong>x</strong>_1 正交化處理得到 <strong>z</strong>_1，然後用 <strong>y</strong> 和 <strong>z</strong>_1 迴歸得到的正是 <strong>x</strong>_1 的迴歸係數 b；如果將 <strong>x</strong>_1 選為 <strong>z</strong>_0，然後用它正交化 <strong>x</strong>_0 = [1,1,…,1]^T，就可以方便的求出迴歸係數 a。</p><p class=ql-align-center>讓我們來好好審視一下這個結論，即：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/affa1718799541b9a7ae9b2458c4adff><p class=pgc-img-caption></p></div><p class=ql-align-center>上式說明，解釋變量 <strong>x</strong>_p 的迴歸係數 b_p 和正交化後的 <strong>z</strong>_p 的大小（<strong>z</strong>_p 自己的內積為分母）有關。<strong>如果 x</strong>_p<strong> 和其他解釋變量高度相關（即非常不正交），那麼 z</strong>_p<strong> 就會很小，則會導致 </strong>b_p<strong> 非常不穩定（一點點樣本數據的變化都會導致 </strong>b_p<strong> 的大幅變化）。</strong>當 y_i 滿足獨立同分布時，假設它的方差為 σ^2，可以證明迴歸係數 b_p 的方差和 <strong>z</strong>_p 的大小成反比，即 <strong>z</strong>_p 越小，b_p 的誤差越大：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a8d4ec53cda2413492c78854c4732ec4><p class=pgc-img-caption></p></div><p>在多因子模型中，b_p 代表的是因子 p 的收益率。<strong>為避免因子收益率的估計非常不穩定，要求不同的因子之間儘量滿足正交化。</strong>舉例來說，在 Barra 的 CNE5 模型中，非線性規模因子和規模因子之間進行了正交化處理；殘差波動率因子和規模以及 BETA 因子也進行了正交化處理。</p><p>在結束本小節的討論之前，我還想介紹一個有意思也有用的特性。本節的論述說明我們可以任選一個解釋變量作為最後一個，然後根據連續正交化方便的求出它的迴歸係數。這意味著如果我們有 20 個解釋變量，需要進行 20 次上述操作。那麼，<strong>是否存在什麼辦法僅通過進行一次連續正交化就求出所有的迴歸係數 </strong>b_j, j = 0, 1, …, p<strong> 呢？答案是肯定的。</strong></p><p class=ql-align-center>假設我們按照某給定順序 <strong>x</strong>_0, <strong>x</strong>_1, …, <strong>x</strong>_p 進行了連續正交化過程，得到了 <strong>z</strong>_0, <strong>z</strong>_1, …, <strong>z</strong>_p，且我們現在知道 b_p = &lt;<strong>z</strong>_p, <strong>y</strong>>/&lt;<strong>z</strong>_p, <strong>z</strong>_p>。由於 b_p 是解釋變量 <strong>x</strong>_p 的迴歸係數，因此 b_p(<strong>x</strong>_p) 正是 <strong>x</strong>_p 所解釋的 <strong>y</strong> 的部分。如果從 <strong>y</strong> 中剔除 b_p(<strong>x</strong>_p)，並把得到的 <strong>y</strong> - b_p(<strong>x</strong>_p) 用 <strong>x</strong>_0, <strong>x</strong>_1, …, <strong>x</strong>_{p-1} 迴歸，則結果就和 <strong>x</strong>_p 無關了。在這個新的迴歸中，<strong>x</strong>_{p-1} 就變成了最後一個被正交化的解釋變量，其對應的正交向量為 <strong>z</strong>_{p-1}。因此，<strong>x</strong>_{p-1} 的迴歸係數就是用新的 <strong>y</strong> - b_p(<strong>x</strong>_p) 和 <strong>z</strong>_{p-1} 迴歸的結果：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/47d56dbf1be44f89a83ae1deb3217d84><p class=pgc-img-caption></p></div><p class=ql-align-center>以此類推，我們可以按照 b_p, b_{p-1}, …, b_0 的<strong>倒序</strong>求解出多元迴歸中所有解釋變量的迴歸係數 b_j（Drygas 2011）：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/31bb8ea22f104ddfb7919e31198d0e21><p class=pgc-img-caption></p></div><p class=ql-align-center>最後用本小節開始的 simple regression model 檢驗一下。我們用上述方法求解截距項的迴歸係數 a 看看。根據定義有 <strong>z</strong>_0 = <strong>1</strong> 並假設已知 b。則根據上面的表達式可得：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3b36a9180fbd4d6db0d991c9cb8c82eb><p class=pgc-img-caption></p></div><p>這正是直接求解 simple regression model 得到的迴歸係數 a（請往前滾屏比較看看）。</p><h1 class=ql-align-center><strong>5 一個例子</strong></h1><p class=ql-align-center>本節用一個例子來驗證一下上一節的各種公式。假設有四個解釋變量 <strong>x</strong>_0 到 <strong>x</strong>_3，以及 <strong>y</strong>：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f5e9ccf126b2452cb72c3ca54175743d><p class=pgc-img-caption></p></div><p class=ql-align-center>直接使用迴歸係數 <strong>b</strong> 的表達式求解，則它們的迴歸係數分別為：b_0 = 0.38548073, b_1 = 0.96332683, b_2 = -0.36300685, b_3 = 0.37189391。按照 <strong>x</strong>_0, <strong>x</strong>_1, <strong>x</strong>_2, <strong>x</strong>_3 的順序進行連續正交化，得到的正交向量為：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4ed02972fc9d40a291f3b1a2f683cf6e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fa145604e50340dc8347d1c559524c6c><p class=pgc-img-caption></p></div><p class=ql-align-center>使用 Drygas (2011) 提出的解法按照 b_3, b_2, b_1, b_0 的順序求解各個迴歸係數 b_j：</p><div class=pgc-img><img alt=為什麼要進行因子正交化處理？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fd08d069506146ae83ae82722fcdfbe4><p class=pgc-img-caption></p></div><p>上述公式求出 b_0 = 0.38548073, b_1 = 0.96332683, b_2 = -0.36300685, b_3 = 0.37189391，和使用迴歸係數 <strong>b</strong> 的表達式求解的結果完全一致。另外，我們也可以分別選擇 <strong>x</strong>_0, <strong>x</strong>_1, <strong>x</strong>_2 替換 <strong>x</strong>_3 作為最後一個被正交化的解釋變量（前三個變量的順序也不重要），並利用 b_p = &lt;<strong>z</strong>_p, <strong>y</strong>>/&lt;<strong>z</strong>_p, <strong>z</strong>_p> 求解，得出的 b_j 也和上面的完全相同。</p><h1 class=ql-align-center><strong>6 正交等於不相關？</strong></h1><p>在我們平常說因子之間正交的時候，另一個常用的詞彙是因子之間“不相關”（這裡不相關指的是不同因子的 Pearson 相關係數為零）。那麼“正交”和“不相關”是否等價呢？</p><p>從定義出發，兩個因子向量 <strong>x</strong>_1 和 <strong>x</strong>_2 正交意味著它們的內積，即 &lt;<strong>x</strong>_1, <strong>x</strong>_2> 為零。而 <strong>x</strong>_1 和 <strong>x</strong>_2 的相關係數為零則意味著 &lt;<strong>x</strong>_1 – E[x_1]·<strong>1</strong>, <strong>x</strong>_2 - E[x_2]·<strong>1</strong>> 為零，因為在計算相關係數時，必須先分別減去其均值，這就是個 centering 的過程。由於 &lt;<strong>x</strong>_1, <strong>x</strong>_2> 為零不一定意味著 &lt;<strong>x</strong>_1 – E[x_1]·<strong>1</strong>, <strong>x</strong>_2 - E[x_2]·<strong>1</strong>> 也為零，因此正交不一定等於不相關。</p><p>舉個例子，[4, 2]^T 和 [3, -6]^T 的內積為零，這兩個向量正交。而各自減去均值後，[4, 2]^T和 [3, -6]^T 分別變為 [1, -1]^T 和 [4.5, -4.5]^T。這兩個新向量在一條直線上、內積不為零，因此 [4, 2]^T 和 [3, -6]^T 的相關係數不為零（事實上，它們的相關係數等於 1）。從多元迴歸求解的角度來說，我們在乎的是他們是否正交，而非 centering 之後的內積是否為零（即是否不相關）。</p><p>不過對於因子暴露向量來說，因為個股在每個因子上的暴露都經過 demean 處理了，所以每個因子向量的均值已經是零了（這裡考慮的就是簡單等權均值的情況，而不是像 Barra 那種用市值作為權重進行去均值的情況）。從這個意義上說，因子向量之間正交和它們之間不相關等價。</p><h1 class=ql-align-center><strong>7 結語</strong></h1><p>本文掰扯了一大堆公式其實就是想說明下面這句話：<strong>在多元線性迴歸中，解釋變量 x</strong>_j<strong> 的迴歸係數 </strong>b_j<strong> 等於 x</strong>_j<strong> 在被其他 x</strong>_0<strong>, x</strong>_1<strong>, …, x</strong>_{j-1}<strong>, x</strong>_{j+1}<strong>, …, x</strong>_p<strong> 調整之後仍能夠對 y 產生的增量貢獻。如果 x</strong>_j<strong> 和其他解釋變量高度相關，則它的迴歸係數 </strong>b_j<strong> 會有很大的估計誤差。這對於多因子模型中評價因子收益非常不利。</strong></p><p>如果看完之後你對這句話有一定的體會，那我的功夫就沒白花。</p><p>在計算機算法進行多元迴歸求解的時候，並不是試圖按照 <strong>b</strong> 的公式計算 (<strong>X</strong>^T)<strong>X</strong> 的逆矩陣，而採用的正是正交化的思路。在正交化的過程中可以非常容易的得到 <strong>X</strong> 的 QR 分解，其中 <strong>Q</strong> 是正交陣、<strong>R</strong> 是上三角陣。這也極大的化簡了迴歸係數 <strong>b</strong> 以及 <strong>y</strong> 預測值的求解。由於篇幅原因（我也好意思說篇幅……），本文就不給出 QR 分解的具體表達式了，感興趣的讀者請參考 Hastie et al. (2016)。</p><p><strong>參考文獻</strong></p><ul><li>Drygas, H. (2011). On the Relationship between the Method of Least Squares and Gram-Schmidt Orthogonalization. <em>Acta et Commentationes Universitatis Tartuensis de Mathematica</em>, Vol. 15(1), 3 – 13.</li><li>Hastie, T., R. Tibshirani, and J. Friedman (2016). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>, 2nd Ed. Springer.</li></ul><p><strong>免責聲明：</strong>文章內容不可視為投資意見。市場有風險，入市需謹慎。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>什麼</a></li><li><a>進行</a></li><li><a>化處理</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd8fa496.html alt=為什麼要對工業用水進行處理，有什麼意義？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e9abd30171f44af0b4ac5ea242cdf6ea style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd8fa496.html title=為什麼要對工業用水進行處理，有什麼意義？>為什麼要對工業用水進行處理，有什麼意義？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/56c5bf4e.html alt=玻璃幕牆為什麼要進行遮陽？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/0ae746c0-3309-484b-acfe-5a207243025d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/56c5bf4e.html title=玻璃幕牆為什麼要進行遮陽？>玻璃幕牆為什麼要進行遮陽？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0d756dcc.html alt=鍍鋅之後為什麼要進行鈍化處理？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fd670fb68ea94a9f9746e19757aa95f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0d756dcc.html title=鍍鋅之後為什麼要進行鈍化處理？>鍍鋅之後為什麼要進行鈍化處理？</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/a6281a5b.html alt=運動教室｜為什麼在進行LSD訓練時，心率會呈現增長趨勢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/a6180003b23fe81b1387 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/a6281a5b.html title=運動教室｜為什麼在進行LSD訓練時，心率會呈現增長趨勢？>運動教室｜為什麼在進行LSD訓練時，心率會呈現增長趨勢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d94fa0b.html alt=為什麼要用六自由度搖擺臺進行礦井模擬培訓？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17d70a9588b445c8a253c354758d6355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d94fa0b.html title=為什麼要用六自由度搖擺臺進行礦井模擬培訓？>為什麼要用六自由度搖擺臺進行礦井模擬培訓？</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/32f6837.html alt=為什麼需要對線性進行Logistic迴歸？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/0b4da5d009f846e69b3c191ed6d860bc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/32f6837.html title=為什麼需要對線性進行Logistic迴歸？>為什麼需要對線性進行Logistic迴歸？</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/cc81ed9.html alt="養蚯蚓需要注意什麼 要在什麼條件下進行呢?" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b19bf88e293441efac5284869f0c9b1b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/cc81ed9.html title="養蚯蚓需要注意什麼 要在什麼條件下進行呢?">養蚯蚓需要注意什麼 要在什麼條件下進行呢?</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/690d558.html alt=機械加工為什麼要進行熱處理？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/87798bd3da0a481b982f3cc82b33f397 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/690d558.html title=機械加工為什麼要進行熱處理？>機械加工為什麼要進行熱處理？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/080257a.html alt=什麼是反電動勢？如何進行永磁同步伺服電機反電動勢測試？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1536542620706bfbc36dc9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/080257a.html title=什麼是反電動勢？如何進行永磁同步伺服電機反電動勢測試？>什麼是反電動勢？如何進行永磁同步伺服電機反電動勢測試？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ab44727.html alt=為什麼要進行機械密封處理？常見的密封方式與洩露檢修，值得保存 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fdc6c4a705ee4851a1097e0b07daddec style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ab44727.html title=為什麼要進行機械密封處理？常見的密封方式與洩露檢修，值得保存>為什麼要進行機械密封處理？常見的密封方式與洩露檢修，值得保存</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/72139afe.html alt=怎樣對臍橙樹進行扭枝（彎枝）促花？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fe6ea8ad111f421c9673e3f61072fa1f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72139afe.html title=怎樣對臍橙樹進行扭枝（彎枝）促花？>怎樣對臍橙樹進行扭枝（彎枝）促花？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bdedb94f.html alt=科普貼！丨你知道港珠澳大橋為什麼是彎的嗎！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d84b472b45474058bfd6bd4b87450f53 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bdedb94f.html title=科普貼！丨你知道港珠澳大橋為什麼是彎的嗎！>科普貼！丨你知道港珠澳大橋為什麼是彎的嗎！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/52ecc739.html alt=科普！看完這篇文章，你就知道港珠澳大橋為什麼是彎的了！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8f0b8a6daf6e4f9bab21e7c06cbc9111 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/52ecc739.html title=科普！看完這篇文章，你就知道港珠澳大橋為什麼是彎的了！>科普！看完這篇文章，你就知道港珠澳大橋為什麼是彎的了！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8bbd5f8a.html alt=長知識！什麼是榫卯結構？為什麼現代建築當中不常見了？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1537941825042b6f495fa56 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8bbd5f8a.html title=長知識！什麼是榫卯結構？為什麼現代建築當中不常見了？>長知識！什麼是榫卯結構？為什麼現代建築當中不常見了？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/83641773.html alt=什麼是懸挑結構？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/faebf061b82546f58e63afab5ede5fa2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/83641773.html title=什麼是懸挑結構？>什麼是懸挑結構？</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>