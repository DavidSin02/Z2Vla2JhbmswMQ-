<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>自動擴增：從數據中學習擴增策略 | 极客快訊</title><meta property="og:title" content="自動擴增：從數據中學習擴增策略 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/d586af26d42e45c68336e42b6ea21bf8"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/29092e3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/29092e3.html><meta property="article:published_time" content="2020-10-29T21:03:38+08:00"><meta property="article:modified_time" content="2020-10-29T21:03:38+08:00"><meta name=Keywords content><meta name=description content="自動擴增：從數據中學習擴增策略"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/29092e3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>自動擴增：從數據中學習擴增策略</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><p><br></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d586af26d42e45c68336e42b6ea21bf8><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>引用</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V. Le; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019: 113-123.</span></p><h1 class=pgc-h-arrow-right>摘要</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">數據擴增是一種能夠提高圖像分類器準確度的技術，目前是手動設計實現。本文將簡述 AutoAugment 的執行過程，即通過自動搜索的方式改進數據擴增策略。我們設計了一個搜索空間，將一個策略劃分為多個子策略，一個子策略每次批處理隨機選取一張圖片。子策略由兩個操作組成，每次操作包括對圖像進行平移、旋轉或剪切等處理，以及執行這些處理的概率和幅度。我們使用搜索算法來尋找最佳策略，以使神經網絡在目標數據集上產生最高的驗證準確率。我們的方法在 CIFAR-10、CIFAR-100、SVHN 和 ImageNet 上達到當下最先進的準確度。在 ImageNet 獲得 83.5％的最高準確率，比之前的記錄 83.1％高出 0.4％；在 CIFAR-10 實現 1.5％的錯誤率，這比目前最優的方法要好 0.6％。我們的擴增策略可在數據集之間移植。在 ImageNet 學到的策略，在其他數據集上同樣可以獲得很好的提升效果，例如 Oxford Flowers、Caltech-101、Oxford-IIT Pets、FGVC Aircraft 和 Stanford Cars 等數據集。</span></p><h1 class=pgc-h-arrow-right>介紹</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">深度神經網絡是功能強大的機器學習系統，使用大量數據進行訓練後，它們往往會運行良好。數據擴增是通過隨機“擴充”數據來增加數據量和多樣性的有效技術。在圖像領域，常見的擴增方法包括將平移或翻轉圖像。數據擴增常被用於訓練關於數據域不變性的模型：分類對象通常對水平翻轉或平移不敏感。與直接將不變性硬編碼到模型體系結構中相比，使用數據擴增合併潛在的不變性會更容易。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">表 1 不同數據集上的錯誤率對比表</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8732fb7227c849f980f814d84113df69><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">本文旨在使目標數據集找到有效數據擴增策略的過程自動化。在我們的實現方法中，每個策略表示擴增操作的幾種潛在選擇及其順序。其中每種擴增操作都是對圖形進行處理(平移、旋轉或顏色歸一化)以及調用各個處理的概率和幅度。我們使用搜索算法來挖掘這些操作的最佳選擇和順序，以便可以訓練神經網絡並獲得最佳驗證準確率。實驗中，我們暫且將強化學習作為搜索算法，如果存在更合適的算法，相信實驗結果可以進一步得到優化。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">大規模的實驗表明 AutoAugment 在以下兩個用例中有出色的提升：</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">1）直接應用於某個數據集，以找到最佳的擴充策略；</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">2）將學習到的策略移植到新的數據集。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">首先，對於直接應用，我們的方法在諸如 CIFAR-10、CIFAR-100、SVHN 和 ImageNet 等數據集上達到了最先進的準確性。在 CIFAR-10，我們實現了 1.5％的錯誤率，這比最新其他技術要好 0.6％。 在 SVHN，我們將錯誤率從 1.3％提高到了 1.0％。在精簡的數據集上，我們的方法無需使用任何未標記的數據即可實現與半監督方法相當的性能。在 ImageNet，我們實現了高達 83.5％的準確率，比之前的最優記錄 83.1％高出 0.4％。其次，如果認為直接應用成本過高，那麼移植擴增策略是一個不錯的選擇。我們已經證明獲得的策略可以在不同模型和數據集之間得到很好地移植。例如，在 ImageNet 發現的策略對各種 FGVC 數據集都有顯著地改進。即使對於在 ImageNet 上預訓練權重微調權重的數據集也無明顯幫助，例如 斯坦福汽車公司（Stanford Cars）和 FGVC 飛機公司通過 ImageNet 策略進行培訓，分別將測試集誤差降低了 1.2％和 1.8％。該結果表明，移植數據擴增策略為權重標準化移植學習提供了另一種方法。</span></p><h1 class=pgc-h-arrow-right>相關工作</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">圖像領域的數據擴增方法通常是手動設計的，最佳的擴增策略也是針對特定數據集的。例如，在 MNIST，大多數排名靠前的模型都使用彈性變形、比例、平移和旋轉。在自然圖像數據集（例如 CIFAR-10 和 ImageNet）上，隨機裁剪、圖像鏡像和顏色偏移/增白更為常見。由於這些方法是手動設計的，因此需要專業知識和</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">時</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">間。我們從數據中學習數據擴增策略的方法原則上可以用於任何數據集，而不僅僅是一個數據集。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我們將尋找最佳擴增策略的問題轉化為離散搜索問題。我們的方法包括兩個部分：一個搜索算法和一個搜索空間。在較高的級別上，搜索算法（實現為控制器 RNN）對數據擴增策略 S 進行採樣，該策略包含使用哪種圖像處理操作、每輪使用該操作的概率以及操作幅度等信息。方法的核心是使用策略 S 來訓練具有固定體系結構的神經網絡，該神經網絡的驗證精度 R 被反饋以更新控制器。由於 R 是不可微的，控制器將通過策略梯度方法進行更新。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">搜索空間：在我們的搜索空間中，一個策略由 5 個子策略組成，每個子策略包含兩個要依次應用的圖像操作。此外，每個操作還與兩個超參數相關聯：</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">1） 應用該操作的概率；2）該操作的幅度。</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b01034c2fca94985b1bf9b030ec314d3><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">圖 1 數據擴增策略框架概述</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">圖 2 是一個在搜索空間中包含 5 個子策略的策略。第一個子策略規定 ShearX 和 Invert 先後順序，應用 ShearX 的概率為 0.9，其幅度為 7/10。我們以 0.8 的概率應用 Invert，Invert 操作不使用幅度信息。值得注意的是，這些操作是根據特定順序執行的。</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/95b55a75adf34c06907e6135ee4ecd66><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">圖 2 SVHN 上的一種訓練策略</span></p><p><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我們的搜索空間中合計有 16 個圖片操作手段。我們將幅度範圍</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">離散</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">為 10 個值（均勻間距），以便我們可以使用離散搜索算法來找到它們。我們用同樣的方式離散化了將該操作應用於 11 個值（均勻間距）的概率。在</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bbdfef06e4d443c0b68f1a2cc7d887ef><p class=pgc-img-caption></p></div><p><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">個可能的空間中查找每個子策略必然成為一個搜索問題。我們的目標是同時找到 5 個這樣的子策略，以增加多樣性。具有 5 個子策略的搜索空間大約有</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0bedab289c5c4af7ade6b84df95460f6><p class=pgc-img-caption></p></div><p><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">種可能性。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">搜索算法：包含兩個部分：一個控制器（遞歸神經網絡）和一個訓練算法（近距離策略優化算法）。在每個步驟中，控制器都會預測 softmax 產生的決策。然後將該謂詞作為嵌入信息送入下一步。控制器總共有 30 個 softmax 預言，以便預測 5 個子策略，每個子策略有 2 個操作，每個操作都需要一個操作類型、幅度和概率。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">控制器 RNN 的訓練：控制器通過獎勵信號進行訓練，這是該策略在改善“子模型”的泛化性方面的策略。在我們的實驗中，我們預留了一個驗證集來衡量子模型的泛化。通過在訓練集（不包含驗證集）上應用 5 個子策略生成的擴增數據來訓練子模型。對於小批量中的每個示例，隨機選擇 5 個子策略之一來擴增圖像。然後，在驗證集上評估子模型，以測量準確性，該準確性用作訓練循環網絡控制器的獎勵信號。在每個數據集上，控制器採樣約 15,000 個策略。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">控制器 RNN 和訓練超參數的架構：控制器 RNN 是一層 LSTM，每層具有 100 個隱藏單元，併為與每個體系結構決策相關的兩個卷積單元（其中 B 通常為 5）提供 2×5B softmax 預測。控制器 RNN 的 10B 個預測中的每個都與一個概率相關聯。子網絡的聯合概率是這些 10Bsoftmax 時所有概率的乘積。該聯合概率用於計算控制器 RNN 的梯度。通過子網絡的驗證精度來縮放梯度，以更新控制器 RNN，以便控制器為較差子網絡分配低概率，為較好子網絡分配高概率。我們採用學習策略為 0.00035 的近距離策略優化（PPO）。為促進探索，還使用權重為 0.00001 的熵</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">罰</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">。基線函數是先前獎勵的指數移動平均值，權重為 0.95。控制器的權重在-0.1 到 0.1 之間均勻初始化。為了方便起見，我們選擇使用 PPO 訓練控制器，儘管先前的工作表明其他方法（例如，擴增型隨機搜索和進化策略）甚至可以達到更好的效果。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">在搜索結束時，我們將</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">最佳</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B"> 5 個策略中的子策略合併為一個策略（包含 25 個子策略）。具有 25 個子策略的最終策略用於訓練每個數據集的模型。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">以上搜索算法是我們可以用來找到最佳策略的許多可能的搜索算法之一。有可能使用其他離散搜索算法，例如遺傳編程甚至隨機搜索進一步改善本文的實驗結果。</span></p><h1 class=pgc-h-arrow-right>實驗</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">首先，我們將通過直接搜索數據集（CIFAR-10、CIFAR-100、SVHN 和 ImageNet）的最佳擴增策略來對 AutoAugment 進行基準測試。結果表明，直接應用的方式能顯著改善基線模型，並在這些具有挑戰性的數據集上獲得最先進的準確率。其次，我們將研究擴增策略在數據集之間的可移植性。最後結果表明，擴增策略具有驚人的可移植性，顯著改進許多數據集的基礎模型。與其他自動數據擴充方法比較，AutoAugment 明顯更好。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">為節省擴充數據期間訓練子模型的時間搜索過程，我們在由 4000 個隨機選擇的示例組成的“精簡 CIFAR-10”數據集上搜索最佳策略。結果表明，訓練相同的時間，子模型訓練的週期數比數據量更為有效。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">CIFAR-10 結果：我們在 TensorFlow 中構建並復現 Wide-ResNet-28-10、Shake-Shake 和 ShakeDrop 模型，發現權重衰減和學習率超參數為基線擴增的常規訓練提供最佳的驗證</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">集</span><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">準確率。其他超參數與模型論文中敘述的相同，除了對 Wide-ResNet-28-10 使用餘弦學習衰減。隨後，我們使用相同的模型和超參數來評估 AutoAugment 的測試集準確性。對於 AmoebaNets，我們使用與基線擴增和 AutoAugment 相同的超參數。我們通過 ShakeDrop 模型獲得了 1.5％的錯誤率，這比最新技術要好 0.6％。此收益遠大於 AmoebaNet-B 先前對 ShakeDrop 取得的收益（+ 0.2％）和 ShakeDrop 對 Shake-Shake 取得的收益（+ 0.2％）</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我們還在最近提出的 CIFAR-10 測試集上評估 AutoAugment 訓練出的最佳模型。Recht 等人的 Shake-Shake + Cutout 在此新數據集上表現最佳，錯誤率達 7.0％（相對於原始 CIFAR-10 測試集的錯誤率高 4.1％）。此外，PyramidNet + ShakeDrop 在新數據集上實現了 7.7％的錯誤率（相對於原始測試集高 4.6％）。我們最好的模型 PyramidNet + ShakeDrop 經過 AutoAugment 訓練，可實現 4.4％的錯誤率（比原始測試集的錯誤率僅高 2.9％）。與在此新數據集上評估的其他模型相比，我們的模型的準確率下降幅度小得多。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">CIFAR-100 結果：我們還在 CIFAR-100 上訓練模型，並在“精簡 CIFAR-10”使用相同的自動擴增策略。我們獲得的最新結果，擊敗 ShakeDrop 正則化之前的錯誤率 12.19％。最後，我們用相同的 AutoAugment 策略在“精簡 CIFAR-10”上訓練模型（用於尋找最佳策略的相同 4000 個示例訓練集）。我們訓練了 4,000 個帶有標籤的樣本，但在訓練期間不使用 46,000 個未標記的樣本。與完整數據集相比，準確性在精簡數據集的提高更為顯著。隨著訓練集規模的增長，我們預計數據擴增的效果會降低。但實際上即使應用於 SVHN 和 ImageNet 等較大的數據集，AutoAugment 仍然可以提高泛化精度。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">SVHN 結果：為節省搜索時間，我們創建一個精簡的 SVHN 數據集，其中包含從 SVHN 核心訓練集中隨機採樣的 1,000 個示例。子模型的模型架構和訓練過程與 CIFAR-10 的上述實驗相同。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">搜索結束後，我們將 5 個最佳策略組合在一起，將它們應用於現有標準擴增策略體系結構，並預留訓練集中的最後 7325 個樣本來構造驗證集。我們根據驗證集的性能調整權重衰減和學習率。由於整個 SVHN 數據集很大，我們僅針對 160 個週期（而不是 1,800 個）訓練 Shake-Shake 模型。AutoAugment 結果將基線預處理與在 SVHN 上學習到的策略結合在一起。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">我們還訓練獲得“精簡 SVHN”上的最佳策略（在相同的 1000 個示例訓練集中找到了最佳策略）。精簡集上的 AutoAugment 結果與目前領先的半監督方法相當，其誤差範圍從 5.42％到 3.86％。與完整數據集相比，AutoAugment 在精簡數據集上帶來更大的優化。</span></p><p><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">ImageNet 結果：我們使用 ImageNet 訓練集的縮減子集（具有 120 個類別（隨機選擇）和 6,000 個樣本）來搜索策略。我們使用餘弦衰落訓練 200 個週期的 Wide-ResNet 40-2。權重衰減為，學習速率為 0.1。在 ImageNet 上找到的最佳策略類似於在 CIFAR-10 上找到的最佳策略，重點是基於顏色的轉換。一個區別是 ImageNet 策略上通常使用旋轉變換。</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/61e88605a8364a769116165b0b4d875a><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">圖 3 ImageNet 上一種成功策略</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">同樣，我們將 5 個最佳策略組合在一起，總共使用了 25 個子策略，以創建 ImageNet 培訓的最終策略。然後，我們使用 ResNet-50 和 ResNet-200 模型針對 270 個週期使用此策略從頭開始訓練整個 ImageNet。我們使用的批量大小為 4096，學習率為 1.6。在第 90、180 和 240 個週期，我們將學習率降低了 10 倍。對於基線擴增，我們使用標準的 Inception-style 進行預處理，將像素值縮放為[-1,1]，以 50％的概率進行水平翻轉，以及顏色的隨機失真。對於使用 AutoAugment 訓練的模型，我們使用基線預處理和 ImageNet 上學習的策略。 我們發現消除顏色的隨機失真不會更改自動擴增的結果。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">表 2 ImageNet 上 Top-1 / Top-5 的驗證準確性（％）</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bfe62108b34d456ba42f632addf87a6f><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">從結果可以看出，在從 ResNet-50 到最先進的 AmoebaNets 的各種模型中，AutoAugment 改進了廣泛使用的 Inception 預處理。其次，將 AutoAugment 應用於 AmoebaNet-C 可以將其 top-1 和 top-5 準確性從 83.1％/ 96.1％提高到 83.5％/ 96.5％。鑑於在 5,000 張圖像上顯示了最佳擴增策略，因此改進得非常出色。我們希望當有更好的計算性能時，實驗結果會更好，AutoAugment 可以使用更多圖像來發現更好的擴增策略。 83.5％/ 96.5％的準確度也是該數據集上最新的 top-1 / top-5 準確度。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">可移植性：直接在特定數據集（AutoAugment-direct）上找擴增策略，這種方式很多時候會佔用大量資源。我們試圖探索是否能將擴增策略從一個數據集轉移到另一個數據集（AutoAugment-transfer）。為了評估在 ImageNet 上找到的策略的可移植性，我們對五個圖像大小與 ImageNet 相似的 FGVC 數據集使用在 ImageNet 上學習到的策略。實驗結果如圖所示，使用 AutoAugment-transfer 後錯誤率仍然能得到顯著優化。</span></p><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">表 3 FGVC 數據集的最佳錯誤率</span></p><div class=pgc-img><img alt=自動擴增：從數據中學習擴增策略 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b46603c87fa5423394be01cb914415ff><p class=pgc-img-caption></p></div><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">消融實驗：即使是從我們的搜索空間中隨機採樣的數據擴增策略也優於基線擴增策略。但是，隨機策略的改進效果要遜於 AutoAugment 策略（2.6％±0.1％對 3.0％±0.1％的錯誤率）。此外，在 AutoAugment 策略中學習的概率和幅度信息似乎很重要，因為當這些參數隨機化時，其效果會大大降低。</span></p><h1 class=pgc-h-arrow-right>致謝</h1><p style=text-align:start><span style="color:#4a4a4a;--tt-darkmode-color: #9B9B9B">本文由南京大學軟件學院 2020 級碩士生錢雨波翻譯轉述。</span></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>擴增</a></li><li><a>自動</a></li><li><a>數據</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/03becdf.html alt=更改數據後單元格自動填充顏色，從此以後再也不用核對數據了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/b063c054-5883-43d7-83e0-653e597ff01b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03becdf.html title=更改數據後單元格自動填充顏色，從此以後再也不用核對數據了>更改數據後單元格自動填充顏色，從此以後再也不用核對數據了</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/c1cc99e.html alt="數據擴增技術如何實現正 margin 距離？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/02f1fd170fdc46fba1f49a9cee641fdf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/c1cc99e.html title="數據擴增技術如何實現正 margin 距離？">數據擴增技術如何實現正 margin 距離？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a46017d.html alt=輸入數據時，自動為單元格添加顏色和邊框 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fa317762ec254b0f9bf4e6f83c9832df style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a46017d.html title=輸入數據時，自動為單元格添加顏色和邊框>輸入數據時，自動為單元格添加顏色和邊框</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html alt=方大九鋼檢測部推出生石灰自動取樣器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html title=方大九鋼檢測部推出生石灰自動取樣器>方大九鋼檢測部推出生石灰自動取樣器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html alt=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html title=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好>方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html alt=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3e507bb24abc482fb28df1121a7ee097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html title=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出>數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html alt="數據科學家常犯的 10 個編程錯誤" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html title="數據科學家常犯的 10 個編程錯誤">數據科學家常犯的 10 個編程錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html alt=數據科學家常遇到的10個錯誤 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/59f660bac8b541888e71459b604ba733 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html title=數據科學家常遇到的10個錯誤>數據科學家常遇到的10個錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html alt=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f120ed2c1ed549e39bfa60bb3a86d591 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html title=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定>WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html alt=excel小技巧：自動求和，當新增數據時自動求和 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523970520159b755ba89ba style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html title=excel小技巧：自動求和，當新增數據時自動求和>excel小技巧：自動求和，當新增數據時自動求和</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html alt="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7aa6ee1b961f467e8090ed56f45c110f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html title="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成">多列數據合併一列，還在用數據透視就out了，用=號只要三步完成</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html alt=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3609570de59a49a9be5667dd9a637f65 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html title=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心>數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html alt=「數據結構」Hash表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/617a6d43032e4efbac6b996c9bb5ab11 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html title=「數據結構」Hash表>「數據結構」Hash表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html alt=備戰秋招——算法與數據結構（5） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ab6859411bd8435bb2616d6fef468556 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html title=備戰秋招——算法與數據結構（5）>備戰秋招——算法與數據結構（5）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html alt=懂了數據結構框架思維，一切算法不過是紙老虎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad2c8a60d9634e0aa36b5d8a664de355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html title=懂了數據結構框架思維，一切算法不過是紙老虎>懂了數據結構框架思維，一切算法不過是紙老虎</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>