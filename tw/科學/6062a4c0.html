<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 | 极客快訊</title><meta property="og:title" content="BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/6d474536ff3d4b1fba0cbfc85968ff6f"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/6062a4c0.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/6062a4c0.html><meta property="article:published_time" content="2020-11-14T20:52:43+08:00"><meta property="article:modified_time" content="2020-11-14T20:52:43+08:00"><meta name=Keywords content><meta name=description content="BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/6062a4c0.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><p>在完成上篇（第三十一篇）感知機的理解文章後，本想開始梳理SVM（支持向量機），不想感知機也是深度學習神經網絡的源頭。於是小白根據對感知機的理解，進一步思考一個基本深度學習模型---BP（Back Propagation）神經網絡，深深被其背後簡單，深刻，奇妙的思想所吸引。因此，本篇以思維遞進方式為文章內容推進的線索，記錄下小白對BP神經網絡的理解和思考，進而呈現小白所感受的簡單，深刻和奇妙。</p><h1>第三十二篇 BP神經網絡的線性本質的理解和剖析</h1><h1>我們看待函數的視角</h1><p>我們如何理解一個事物，關鍵在於我們看待事物的視角。比如函數y=x^2，我們可以看作是二維座標軸的拋物線，也看以理解為一個正方形的面積的隨著邊長而增長。</p><p><strong>那麼，我們有哪些視角來看待一個線性函數呢？</strong></p><p>視角1：線性函數是一條直線或一個超平面</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6d474536ff3d4b1fba0cbfc85968ff6f><p class=pgc-img-caption></p></div><p>如上圖所表示，兩者都為線性函數。對於二位座標空間，線性函數為一條直線；對於三維座標空間，線性函數為一個二維的平面；<strong>對於N維座標空間，線性函數為一個N-1位的超平面；</strong></p><p>視角2：線性函數創造了一維的線性空間和一維的特徵</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1d1db1af712144b9a16496dd4089ccd4><p class=pgc-img-caption></p></div><p>如上圖，0=Wx+b為一個直線，x是一個二維向量，實際為（x，y），如：0=3x+2y+b。我們有理解，0=Wx+b是一個平面，假如令f(x)=Wx+b，對超平面上的點有f（x）=0。</p><p>對於超平面外的點有f(x)=m 。我們可以體會：f(x)是一個線性空間，把Ｎ維的空間映射成一個一維的空間：</p><p><strong>ｍ是ｘ在新空間（新的一維空間）下的座標（或者叫特徵，或者理解為"通過線性函數形成對於樣本x的重新標記，這個標記是m"）。我們知道這個座標"ｍ"就是函數距離，如果函數歸一化後，ｍ就是ｘ到超平面（Ｗｘ＋ｂ＝０）的幾何距離。</strong></p><p>視角3：線性函數即感知機，也即神經元</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e8d2eff869484c3f9711b485f06c9988><p class=pgc-img-caption></p></div><p>如上圖，左邊是一個神經細胞，它內部有一個感知機（線性函數），當外界刺激它時，他會把他轉化為座標，然後產生是移動（叉表示 ）或靜止不動的行為（圈表示）。而右圖則是一塊磚，對外界的刺激不會產生任何反饋。</p><p>我們知道，左側其實就是一個生命體（試想萬億年前地球上第一個具有神經反應的細胞產生），因為，它本身是一個感知機，可以對外界的刺激產生行為，這個感知機是一個線性函數；而右側是一個無機體。我們可以形象的把線性神經元表示成如下形式。</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/92fe692bd5e14dcea68a549477b2ae63><p class=pgc-img-caption></p></div><p>視角四：線性函數可以無限逼近任何事物的邊界</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/40a00a2c6db1435888cce195f4f99d80><p class=pgc-img-caption></p></div><p>`如上右側的圖，對於一個曲線，我們可以想象，可以用很多的切線無限的逼近。但同時，我們結合視角２看（如左圖），假如我們用Ｎ條切線逼近，切線其實就是線性函數，每條切線相當於一個線性空間。這樣，相當於產生一個Ｎ維的線性空間，那麼：</p><p><strong>原來的P點在Ｎ維的線性空間下有一個對應一個Ｎ維的座標(x1,x2,x3…xn) ，也即Ｎ維的特徵，每個特徵即是Ｐ點到切線的距離。</strong></p><p>到這裡，小白有一個想法。一個感知機是一個線性函數，那麼，多個感知機是多個線性函數。如上篇關於感知機的文章介紹，感知機可以學習到線性分類邊界。那麼：</p><p><strong>多個感知機組織在一起是否可以學習和逼近一個非線性分類的邊界。既然感知機可以理解為神經元，那麼就稱它為"神經網絡"。答案是可以的。</strong></p><h1>神經網絡建模</h1><p>根據前面的介紹，其實我們可以形成如下的一個結構，來表示剛才對曲線的逼近。</p><p><strong>輸入層：</strong>是原始數據輸入；</p><p><strong>中間層：</strong>由多個神經元組成，每個神經元其實是一個線性空間，會根據輸入層的輸入產生一個特徵，Ｎ箇中間層神經元相當於Ｎ維線性空間，將產生Ｎ個特徵；</p><p><strong>輸出層：</strong>根據中間層的產生的N個特徵再進行線性映射形成對最終特徵的判斷（也成預測）。</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/244f317a453f4f5abe63ca635ca5d568><p class=pgc-img-caption></p></div><p>小白思考，上面的中間層以及輸出層的四個神經元總體能呈現出<strong>非線性的表達</strong>嗎？答案是否否定的。我們來推導下。假如，中間層神經元分別是(w1,b1), (w2,b2), (w3,b3)，輸出層Ｗ=(c1,c2,c3)。那麼，我們有如下推導：</p><p>Y=W(w1x+b1),(w2x+b2),w3x+b3)+b</p><p>=c1w1x+c1b1+c2w2x+c2b2+c3w3x+c3b3+b</p><p>=(c1w1+c2w2+c3w3)x + (c1b1+c2b2+c3b3+b)</p><p><strong>我們發現上述中間層和輸出層兩層神經元的結構，本質上只能表達一條直線，不能夠表達曲線。因此，</strong>我們需要持續改進上述模型。</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4d1c7bad21f948ab9b9a2378b3187c6b><p class=pgc-img-caption></p></div><p>回到剛才思路，如上我們發現，對於線性逼近，我們建模了每條切線（每一箇中間層的神經元），但是我們發現我們忽視了一個因素，<strong>即切線如何過度到另外一條切線？這個因素是必要的，只有這樣，多條切線才可手拉手形成對非線性邊界的逼近。</strong></p><p>我們思考，切線的過度形成對曲線的逼近，相當於我們建模了從一個切點滑動到另一個切點。我們回憶下上篇關於"感知機"介紹的描述：</p><p>"<strong>越靠近最優超平面的點，被誤分類次數越多，被疊加的越多，其對Ｗ的影響越大"。</strong></p><p>而當前的切點，不僅僅是靠近最優超平面（逼近的切線），而是就在超平面（切線）上，因此，其不僅僅是影響，而是完全決定。因此，對於切點的滑動，其行為的本意是捨棄一個感知機（切線），然後決定了另一個感知機（切線）。因此，我們體會到，<strong>當我們試圖逼近曲線時，表現為切線在曲線周圍滑動，這個過程可以看作，一個切線沉寂，另一個切線被激活的過程。因此，我們可以在感知機的後面加一個激活的處理，我們稱之為激活函數。</strong>於是，我們的線性神經元，加上了一個激活開關，如下：</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/af5eac45201f4161ba4c09e72235f45f><p class=pgc-img-caption></p></div><h1>前饋神經網絡</h1><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1b84c81229db4d76ba86d7a4f6bdff80><p class=pgc-img-caption></p></div><p>根據上面的分析，我們順理成章，改善模型並得到了如上圖神經網絡模型，稱之為<strong>前饋神經網絡。</strong>這個神經網絡模型有兩層（隱藏層，輸出層）神經元，從輸輸入到輸出逐層映射，最終輸出到Y，故名前饋。</p><p>對於前饋神經網絡，有輸入層，輸出層，<strong>中間層我們稱之為隱藏層，或隱層。</strong></p><h1>BP（Back Propagation）算法</h1><p>有了前饋神經網絡模型，我們下一步需要思考，如何訓練這個模型（也即是這個模型如何學習），我們不防藉助於感知機的思想，如下圖：</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dbed8c0edb1045099fd666fc6e612305><p class=pgc-img-caption></p></div><p>從感知機的學習過程看，整個過程都聚焦於xi（神經元的輸入），w（神經元輸入的權重）以及yi（輸出的偏差）三者的計算和調整，即根據當前的感知機的狀態w和輸入xi得到輸出（即預測值），通過輸出和樣本xi的特徵標記得到誤差yi，yi和xi的乘積（yi*xi）即為梯度，然後沿著梯度的方向通過一定的學習速率來調整w。依葫蘆畫瓢，對於前饋神經網絡，我們的思路是：</p><p><strong>計算隱藏層和輸出層神經元的誤差，根據誤差和輸入調整隱藏層和輸出層的神經元的ｗ。此外，我們還需要注意一點，對於前饋神經網絡，我們引入了激活函數。如下：</strong></p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b9bf07daf805464e964c3ceff865d831><p class=pgc-img-caption></p></div><p>如下計算輸出層神經元的梯度：</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d99ba2815d3941998a9079b80e2988de><p class=pgc-img-caption></p></div><p>我們再思考，隱藏層神經元只有預測值，而沒有誤差，因為，隱藏層沒有樣本的標記。但，我們知道，隱藏層神經元是我們創造的一箇中間過程的線性感知機，那麼我們其實也同時創造對應的樣本標記，並且這些隱藏層神經元的樣本標記通過輸出層神經元再次疊加成最終的標記。<strong>因此，我們需要找出我們創建的隱藏層神經元的誤差，它是存在的。並且我們知道，輸出層的誤差本質上就是隱藏層的誤差，他們之所以不一樣，是因為所在空間不一樣。</strong></p><p><strong>前者，是在輸出神經元構成的多維線性空間下觀察到的誤差，而後者是在隱藏層神經元所構成的多維線性空間下觀察到的誤差。因此，我們把輸出層的誤差，退回到（Back Propagation）隱藏層多維空間下就會得到隱藏層各神經元的誤差。</strong></p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a43f2c0664bf4748b8ec8681bca8b7b6><p class=pgc-img-caption></p></div><p>上圖的推導，是相對於"輸出層神經元的誤差"的 隱層神經元輸入權重調整的梯度。我們可以看到上圖中的梯度是通過多個"隱層神經元誤差和 隱層神經元的輸入乘積"的疊加的方式呈現。於是，對於單個隱層神經元，我們得到：</p><div class=pgc-img><img alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d350178c0a8947b6b87d8e3702c9eeeb><p class=pgc-img-caption></p></div><p>這樣我們就可以更新隱層神經元的權重了。</p><h1>總結</h1><p>小白體會，如果認為感知機是一個線性神經元的話，那麼，BP神經網絡是感知機神經元的一次進化，這個進化體現在三個方面。</p><p>1， 感知神經元增多了，進而感知更多的信息；</p><p>2， 感知神經元增多了以後，那麼，就需要對多個神經元產生的特徵進行總和和彙總（即再次的感知和映射）。因此，產生了分層；</p><p>3， 多個神經元之間需要激活函數作為連接體，這樣，才能完備的形成對非線性邊界的模擬和逼近；</p><p>而BP算法本質上也是梯度下降算法伴隨著多層神經網絡進化而成，其本質仍是梯度下降算法。BP後向傳播可以從誤差從深層（如輸出層）到淺層神經元（入隱層）的逐層傳播，進而"全網同步計算各神經元輸入權重的梯度下降幅度"。因此，BP神經網絡是局部最優的。需要其他算法的輔助來達到全局最優。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>BP</a></li><li><a>神經</a></li><li><a>網絡</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html alt=BP神經網絡學習筆記 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fc5cec456c184c48b1ee22a233b9ee0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html title=BP神經網絡學習筆記>BP神經網絡學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html alt=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/65c4000bda98898dcdbb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html title=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼>谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html alt=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/470f0001d893b2ad09e2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html title=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮>你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html alt=神經網絡與圖靈機的複雜度博弈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/4af200040ff1f5233c1c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html title=神經網絡與圖靈機的複雜度博弈>神經網絡與圖靈機的複雜度博弈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html alt=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/3c0b503678da4b15be05f6f56c0d213f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html title=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成>基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/f149efd9.html alt=用於調整深度神經網絡的簡單參考指南 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15379529924702cde52ac04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/f149efd9.html title=用於調整深度神經網絡的簡單參考指南>用於調整深度神經網絡的簡單參考指南</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html alt=貝葉斯神經網絡(系列)：第二篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RKYlnth9DPo8ac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html title=貝葉斯神經網絡(系列)：第二篇>貝葉斯神經網絡(系列)：第二篇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html alt=針對深度神經網絡的簡單黑盒對抗攻擊 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b9ec712cd33442338496141ebfcecb45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html title=針對深度神經網絡的簡單黑盒對抗攻擊>針對深度神經網絡的簡單黑盒對抗攻擊</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html alt=模式識別與神經網絡的發展 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523254283784d3d276a90f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html title=模式識別與神經網絡的發展>模式識別與神經網絡的發展</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce4eaa0.html alt=基於改進BP神經網絡的心電信號分類方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RTdCgkOFwO8jZS style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce4eaa0.html title=基於改進BP神經網絡的心電信號分類方法>基於改進BP神經網絡的心電信號分類方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d7196c1.html alt=手工打造神經網絡：透視分析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6ee200033390f3f6b2ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d7196c1.html title=手工打造神經網絡：透視分析>手工打造神經網絡：透視分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html alt=機器學習：神經網絡學習之多層前饋神經網絡（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a0a4cd0f7d9244a6a12da3c0af6893a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html title=機器學習：神經網絡學習之多層前饋神經網絡（一）>機器學習：神經網絡學習之多層前饋神經網絡（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html alt=機器學習：神經網絡學習之多層前饋神經網絡（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/2d53a815-ab09-4da3-94a2-5b6843366e3a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html title=機器學習：神經網絡學習之多層前饋神經網絡（二）>機器學習：神經網絡學習之多層前饋神經網絡（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html alt=一文幫你梳理清楚深度神經網絡的基礎知識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f16bcb220e14085a04994454ea4998a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html title=一文幫你梳理清楚深度神經網絡的基礎知識！>一文幫你梳理清楚深度神經網絡的基礎知識！</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>