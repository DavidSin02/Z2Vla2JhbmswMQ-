<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度學習訓練數據的評估與數據增強 | 极客快訊</title><meta property="og:title" content="深度學習訓練數據的評估與數據增強 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/85ac7dab7c6d41b2b0725f2a70be0bec"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/76643ef2.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/76643ef2.html><meta property="article:published_time" content="2020-11-14T20:51:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:51:54+08:00"><meta name=Keywords content><meta name=description content="深度學習訓練數據的評估與數據增強"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/76643ef2.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度學習訓練數據的評估與數據增強</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><blockquote><p><strong>引用：</strong>Junhua Ding ; XinChuan Li ; Venkat N. Gudivada,2017 IEEE International Conference on Big Data (Big Data),11-14 Dec. 2017</p></blockquote><h1><strong>關鍵詞</strong></h1><p>大數據; 機器學習; 神經網絡; 深度學習; 卷積神經網絡; 支持向量機; 衍射圖像</p><h1><strong>摘要</strong></h1><p>深度學習是從大數據中提取價值的重要技術。然而，我們需要大量高質量的訓練數據保證深度學習的有效性。在許多情況下，訓練數據的大小不足以有效地訓練深度學習分類器。數據增強是一種用於增加訓練數據量的廣泛採用的方法，但數據增強後數據的質量可能有問題，因此，對數據進行系統評估至關重要。此外，如果訓練數據有噪聲，則必須自動分離出噪聲數據。在本文中，我們提出了一種深度學習分類器，用於自動將良好的訓練數據與噪聲數據分離。為了有效地訓練深度學習分類器，我們需要轉換原始訓練數據以適應分類器的輸入格式。我們研究了不同的數據增強方法，以從有限大小的原始訓練數據生成足夠數量的訓練數據，通過使用不同的分類算法對分類精度進行交叉驗證來評估訓練數據的質量。我們還檢查每個數據項的圖像並比較數據集的分佈。 我們通過對大規模生物醫學圖像的自動分類的實驗研究證明了所提出的方法的有效性。 我們的方法是通用的，很容易適應其他大數據域。</p><p><strong>關鍵詞</strong>：大數據; 機器學習; 神經網絡; 深度學習; 卷積神經網絡; 支持向量機; 衍射圖像</p><h1>介紹</h1><p>我們需要可擴展的高性能數據處理基礎架構和分析工具來從大數據中提取價值。例如，深度學習算法和GPU已被廣泛用於分析大數據。數據集的規模和質量決定了從大數據中有效提取價值的難度，可用於訓練算法的數據通常不夠大。現在，通過將現有數據項轉換為新數據的方法來進行數據擴增是一種廣泛使用的實踐，但是，很難確定數據擴增後是否有效。我們有必要使用轉換的方法系統地評估生成的數據的質量。生成的訓練數據也可能包括有錯誤標記數據形式的噪聲。</p><p>已發表的研究表明，訓練數據集中的異常和噪聲可能會顯著降低數據分析的性能和準確性。為了解決這些問題，我們有兩種選擇：設計強大的機器學習算法，可以處理嘈雜的訓練數據，或通過濾波提高數據質量。</p><p>機器學習算法已被用於檢測來自多個源的數據中的重複數據。數據過濾是一種通過噪聲消除來提高數據質量的方法。數據發佈者和訂閱者可以使用域模型來過濾噪聲數據。由於大數據的規模巨大，自動過濾數據至關重要。然而，朝這個方向的研究才剛剛開始出現。</p><p>在本文中，我們介紹了一種從生物醫學圖像數據集中分離噪聲數據的系統方法，以便從大數據中提取信息。更具體地說，我們開發了一種機器學習方法，用於從數據集中分離無效和有噪聲的數據。我們的方法包括使用深度學習分類器迭代地將噪聲數據與常規數據分離的p-DIFC可以獲得每秒近100個細胞的衍射圖像。 使用p-DIFC，我們為不同類型的細胞收集了超過一百萬個衍射圖像。我們通過使用不同的分類算法對分類精度進行交叉驗證來評估數據質量。我們還檢查每個數據項的圖像並比較它們的分佈。</p><p>我們描述了我們提出的方法，並通過將生物細胞的衍射圖像分成幾個類別（包括噪聲類別）來證明其有效性。 我們使用偏振衍射圖像流式細胞儀（p-DIFC）獲取細胞的衍射圖像，其用於定量和分析單細胞的3D形態，這些特徵用於精確分類細胞類型。p-DIFC每秒可以獲得近100個細胞的衍射圖像。 使用p-DIFC，我們為不同類型的細胞收集了超過一百萬個衍射圖像。</p><h1>細胞衍射圖像：</h1><p>文獻中已經講述了使用機器學習對細胞衍射圖像進行分類的工作。然而，p-DIFC成像可包括許多不是細胞的顆粒，例如鬼細胞體，聚集的球形顆粒（又稱破裂的細胞），以及細胞碎片和小顆粒（統稱為碎片）。我們將具有完整結構的活細胞稱為細胞。從非細胞的顆粒獲得的衍射圖像也被收集到衍射圖像數據集中，這些衍射圖像包括噪聲數據。</p><p>為了精確地對細胞進行分類，有必要將非細胞衍射圖像（即，噪聲）與細胞衍射圖像分離。從實際角度來看，手動將噪聲圖像與細胞圖像分離是不可行的。為了解決這個問題，我們開發了一種深度學習方法，用於衍射圖像的自動分類。我們將衍射圖像分為三類：細胞，破碎細胞和碎片。我們使用基於AlexNet [9]和TensorFlow框架的深度學習架構開發了分類器。我們使用細胞，破碎細胞和碎片的衍射圖像訓練了分類器。</p><p>原始8位灰度級p-DIFC衍射圖像的尺寸是640×480像素。由於AlexNet使用大小的圖像是227x227像素，我們調整原始衍射圖像的大小為227x227。由於用於衍射圖像的AlexNet分類器需要大量的訓練圖像，我們開發了一種從原始圖像生成幾個小衍射圖像（又名增強衍射圖像）的方法。通過<strong>n倍交叉驗證（NFCV）</strong>和<strong>混淆矩陣</strong>來交叉檢查分類精度。為了檢查訓練數據的質量，我們使用支持向量機（SVM）對三類衍射圖像進行分類。我們先分別在原始和增強衍射圖像數據集上訓練分類器，然後比較分類的精度。我們還研究了小圖像是否能夠捕獲足夠的形態信息作為數據集原始圖像，因此我們要求每個小圖像與其原始圖像不同。 此外，我們希望從同一原圖生成的所有小圖像都表現出不同的文本模式。最後，我們檢查原始數據集和增強數據集中選定的特徵值的分佈，以確定它們是否一致。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/85ac7dab7c6d41b2b0725f2a70be0bec><p class=pgc-img-caption></p></div><p>圖1. A. p-DIFC的光散射圖 B.軟件模擬衍射圖像 C. p-DIFC獲得的衍射圖像。</p><h1>衍射圖像的自動分類:</h1><p>我們首先討論基於形態學的細胞分類，然後使用SVM和深度學習技術進行衍射圖像的自動分類。</p><p><strong>A.基於形態學的細胞分類</strong></p><p>細胞通過細胞內細胞器表現出高度變化和捲曲的三維（3D）結構，以維持表型變異和功能。細胞分類對生物學和生命科學研究具有重要意義。 p-DIFC用於從單個細胞快速獲取交叉極化衍射圖像（p-DI）對，它採用斯托克斯矢量和穆勒矩陣來解釋由於折射率，n（r，λ）或其3D形態的細胞內分佈導致的散射光的偏振變化。入射光及其偏振態由斯托克斯矢量（I0，Q0，U0，V0）表示，其沿z軸傳播。同樣的，散射光及其偏振沿（Θs，Φs）方向表示狀態向量（Is，Qs，Us，Vs），如圖1所示。與非相干光獲取的圖像不同，p-DI 由於入射激光束引起的細胞內分子偶極子發出的相干光散射，這些對呈現出特徵模式。 因此，p-DI數據提供了探測照射細胞的3D形態的數據源，其需要機器學習技術來提取形態學和分子信息。</p><p>在過去十年中，丁先生等人開發了不同的用於細胞衍射圖像的快速和準確的細胞形態學分析的機器學習方法，其中包括支持向量機（SVM）和深度學習方法。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/b09f2697754b4830951c4058c344dece><p class=pgc-img-caption></p></div><p>圖2.p-DIFC獲得的衍射圖像（a）完整結構的活細胞，（b）重影細胞體或聚集的球形顆粒，和（c）細胞碎片或小顆粒。 右上角顯示每個圖像的相應粒子。</p><p><strong>B.數據集</strong></p><p>一個使用p-DIFC獲取的衍射圖像的集合可以包括從非常規細胞獲取的圖像，尤其是樣本中的破碎細胞和碎片。對於一些研究項目，人們只需要正常的細胞圖像，然而對於其他一些研究，如細胞凋亡研究，我們只需要破碎的細胞圖像。因此，有必要建立一種工具來自動分離三種類型的衍射圖像。三種類型的細胞顆粒具有不同的形態結構，其在p-DIFC衍射圖像中精確捕獲。使用這些文本模式，生物學家可以在視覺上分離這三種類型的圖像。圖2顯示了樣品p-DIFC衍射圖像及其相應的顆粒。完整結構的活細胞的衍射圖像的文本圖案包含許多明亮的正常斑點，一個鬼細胞體或聚集的球形顆粒則包括亮條，最後，細胞碎片或小顆粒顯示出許多大的漫射斑點。</p><p>三類衍射圖像的文本模式的差異足以使用機器學習算法來分離這三個類別。</p><p>我們使用p-DIFC為三類粒子獲得了許多衍射圖像，然後選擇了數千個衍射圖像作為初始數據集。對於實驗研究，我們選擇了總共7519個衍射圖像，然後手動檢查每個衍射圖像並標記其類別。正常細胞被標記為細胞，破碎細胞被標記為條帶，碎片被標記為碎片。初始圖像數據集由2232個正常細胞，1645個破碎細胞和3642個碎片組成。衍射圖像的每個類別存儲在單獨的目錄中。我們注意到一些衍射圖像可能被錯誤地標記，而另一些衍射圖像由於視覺質量低而難以標記。</p><p><strong>C.以SVM為基礎的圖片分類</strong></p><p>SVM通常執行二進制分類。 為了實現多類分類，通過比較“一個與其餘”或“一個與一個”來組合幾個SVM分類。 我們使用LIBSVM 實現了衍射圖像的分類，這是一個用於SVM的開源工具包。</p><p>衍射圖像的文本模式是使用一組灰度層協作矩陣（GLCM）特徵定義的。 我們總共使用了20個功能 - 其中14個是原始圖像的特徵，6個是擴展圖像的特徵。 每個特徵的定義都可以在丁先生先前的工作中找到。 下面給出了為衍射圖像構建SVM分類器的過程：</p><ol><li>計算訓練和測試數據集中每個衍射圖像的GLCM特徵。</li><li>用其類別（例如其細胞類型）標記每個衍射圖像，並構建由其GLCM特徵值及其標記組成的特徵向量。 數據集中所有衍射圖像的特徵向量形成特徵矩陣。</li><li>使用選擇的kernel和訓練數據集的特徵矩陣訓練SVM分類器。</li><li>使用測試數據集中的衍射圖像測試分類器，並使用諸如N倍交叉驗證（NFCV）和混淆矩陣之類的標準驗證分類性能。</li></ol><p>我們使用衍射圖像數據集構建了SVM分類器。 我們為三個類別中的每一個選擇了1000個衍射圖像，並使用GLCM特徵值和相應的類型構建了特徵矩陣。 每個特徵向量包括16個GLCM特徵值，因為一個特徵的值全部為0，而另外三個特徵是在圖像格式上定義的，本研究中未對其進行說明。 細胞，碎片和條帶的10倍交叉驗證（10FCV）的平均分類準確度分別為74.50％，81.50％和62.00％。 簡化的混淆矩陣如表I所示[16]。</p><p>為了提高SVM分類器的分類精度，我們嘗試了許多不同的技術，例如使用圖像處理和聚類分析技術預先選擇圖像或者是特徵選擇。 我們最近的實驗表明，深度學習方法極大地提高了分類準確性。</p><p><strong>D.基於機器學習的分類器</strong></p><p>衍射圖像數據集由於其低分辨率和沒有背景噪聲的原因相對簡單。 因此，我們選擇了在Tensor-Flow框架中實現的AlexNet模型來構建深度學習分類器。 由於深度學習需要大量特徵，因此訓練數據集的大小也很大。</p><p>AlexNet使用大約120萬張圖像進行訓練。 我們沒有使用預先訓練過的AlexNet，而只使用了它的網絡架構。 我們只收集了7519個原始衍射圖像，這些圖像不足以訓練AlexNet。因此，我們使用數據增強方法來生成更大的訓練數據集。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fa3da08cd3c745b0b8e456dea95b0383><p class=pgc-img-caption></p></div><p><strong>E.數據增強</strong></p><p>單元的原始衍射圖像的尺寸是640×490。它足夠大，可以分成幾個大小為227x227像素的小圖像，這是AlexNet輸入圖像的尺寸。精心選擇的子圖像可以具有足夠的信息來代表整個圖像。衍射圖像還可以包括大的黑色背景，其對於分類是無用的。因此，需要一種用於產生小圖像的嚴格方法。該性質可以通過圖7中所示的衍射圖像進一步證實，其通過使用DDA（光散射模擬程序）模擬散射體的光散射而產生。</p><p><strong>F.裁剪圖像</strong></p><p>如前所述，AlexNet接受輸入圖像的尺寸為227x227像素，而原始衍射圖像的尺寸是640×480像素。因此，小圖像約為原始圖像尺寸的1/5。此外，由於衍射圖像可能包含顯著的黑色區域，因此文本圖案的中心（例如亮斑點或條帶）可能不是圖像的中心。我們需要找到文本模式區域的中心來執行裁剪，裁剪通常是圖像中最亮的區域。</p><p>使用5x5像素窗口，裁剪程序計算窗口的平均亮度。然後，它將窗口逐步滑動幾個像素以覆蓋整個圖像，以確定具有最大平均亮度的窗口。例如，8位分辨率圖像的亮度範圍是從0到255，將平均亮度最大的窗口設置為裁剪小圖像的中心。如果多個窗口具有最大的平均亮度，則選擇距離邊界最遠的窗口作為中心。首先從中心周圍的原始圖像中裁剪出一個小圖像，然後通過從中心向任意方向的某些像素滑動窗口來裁剪更小的圖像，如圖3所示。</p><p><strong>G.池化圖像</strong></p><p>裁剪技術不適用於整個圖像都對分類至關重要的情況。在這種情況下，從局部區域提取的局部特徵不足以表示從整個圖像中提取的全局特徵。從有限數量的原始圖像產生訓練數據需要不同的技術。我們嘗試了一種用於生成大量訓練數據的池化技術。使用池化將原始衍射圖像下采樣為小圖像。可以從具有不同池化配置的原始圖像生成多個小圖像。此外，可以使用不同的池函數（如最大池或平均池）生成小圖像。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c14c71cff58641a78a996369feff0366><p class=pgc-img-caption></p></div><p>圖4.衍射圖像及其池化圖像（a）細胞，（b）碎片，（c）破碎的細胞，（d）是（a）池化後的細胞，（e）是（b）池化後的碎片，和（f）是（c）池化後的破碎細胞。</p><p>我們已經嘗試了三種池功能，包括平均池，最大池和最小池。 但是，數據集僅使用相同的池功能。 三個不同數據集的實驗結果將在下一節中討論。</p><p><strong>H.實驗結果</strong></p><p>所有實驗均在相同的原始細胞衍射圖像，破碎細胞和碎片上進行。 三個圖像類別存儲在三個不同的文件夾中，然後對每個圖像應用裁剪或池化，以生成每個類別約100,000個小圖像併為其標記。 小圖像根據其標籤/類別存儲在三個文件夾中。 8FCV和混淆矩陣用於驗證分類結果。 我們已經進行了許多實驗來檢查和驗證分類精度，但我們將僅描述本節中的重要結果。</p><p>1）裁剪圖像的實驗結果：8FCV顯示正常細胞的平均分類準確度為99.36％，碎片為97.74％，斷裂細胞為99.81％。圖5顯示了4組的混淆矩陣。從8FCV結果來看，我們注意到基於AlexNet的分類器可以有效地對衍射圖像的類別進行分類。此外，從原始圖像生成的數據集足以訓練分類器。</p><p>2）使用池化圖像的實驗結果：基於使用平均池化生成的數據集的分類的8FCV結果顯示碎片和條帶的平均分類精度略高於通過裁剪建立的數據集。然而，細胞的平均分類準確度要低得多，為85.7％ vs 94.22％。如表II所示，近10％的細胞被錯誤地分類為碎片，只有4.5％的細胞被錯誤地分類為條帶。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e35c047a84574c7ea20f7ab5a530f051><p class=pgc-img-caption></p></div><h1>評估數據增強的質量</h1><p>在本節中，我們將討論如何使用裁剪或池化技術系統地評估從原始衍射圖像生成的數據集的質量。 我們使用代表性，準確性和多樣性來評估數據集。 代表性意味著數據集包括原始數據集中的所有信息，並且它可以表示用於訓練機器學習分類器的原始數據集。 準確度是指生成的數據項無法與原始源區分開的事實。 多樣性意味著增強數據集應該可以用於不普遍的特徵。 對於衍射圖像案例的研究中，我們首先研究了小尺寸衍射圖像是否可以使用基於SVM算法對衍射圖像進行分類，實現與原始圖像相似的精度。然後我們檢查了小圖像的文本模式，以確保小圖像可以捕獲足夠的形態信息作為其原始圖像。最後，我們比較了增強數據集和原始圖像數據集的特徵值的分佈。</p><p>A.檢查SVM分類器的分類準確性</p><p>B.檢查衍射圖像中的文本模式</p><p>C.檢查數據集中的特徵圖像</p><p>我們的實驗表明，任何小的衍射圖像都可以準確地表示其原始衍射圖像的分類。深度學習分類器總是將小圖像分類為與源衍射圖像相同的類別，這是一件好事，但與此同時，有必要檢查小圖像對培訓效果的貢獻。如果來自原始圖像的小圖像具有相同的特徵值，則這些圖像對於訓練是多餘的。因此，有必要檢查這些小圖像區域的特徵值有多接近。我們在最後一個全連接層上收集輸出，其中包括AlexNet中的4096個特徵，然後我們比較兩個輸入衍射圖像之間的特徵值。雖然找到兩個特徵向量之間的差異並不困難，但計算兩個特徵向量之間的差異是相當具有挑戰性的，因為每個特徵都不是簡單的標量參數。因此，我們使用不同的方法來評估小衍射圖像。由於文本模式對於衍射圖像的分類是必不可少的，我們可以檢查兩個圖像之間的<strong>GLCM</strong>特徵值的差異。如果小圖像的GLCM特徵值與其原始圖像不同，我們還需要檢查小圖像的數據集的分佈以及原始圖像的數據集的分佈。如果由相同原始圖像產生的小衍射圖像的GLCM特徵值不同，則小圖像的數據集的GLCM特徵的分佈與原始圖像的數據集的GLCM特徵的分佈一致。我們相信小圖像的數據集很好地代表了原始圖像，並有助於訓練的泛化。</p><p>1）比較衍射圖像的GLCM特徵值：我們首先計算每個衍射圖像的GLCM特徵值，並將小圖像與其原始圖像組合在一起。然後我們比較了一組中所有圖像的每個GLCM特徵。如果兩個圖像具有至少一個GLCM特徵不同，則認為這兩個圖像不同。表V顯示了6個GLCM特徵中合併的小圖像及其原始圖像的部分比較結果。 Img 1至Img 5是來自原始圖像Img 0的合併圖像。我們檢查了每組圖像，沒有在每組中找到兩個相同的圖像。</p><p>2）比較數據集的GLCM特徵分佈：我們為屬於同一類型的所有原始圖像創建了GLCM特徵的分佈。然後，我們為從原始圖像生成的一組小圖像創建了相同的分佈。我們比較了兩個分佈，看看分佈是否一致。圖9展示了原始衍射圖像數據的GLCM特徵與從原始衍射圖像數據合併的小衍射圖像之一的正態分佈的比較。</p><p>我們使用歸一化的特徵值（即最小-最大歸一化），均值和標準差創建了正態分佈，並且基於概率質量函數繪製了曲線。很難看出這兩個分佈並不完全相同。但是，它們都是正常分佈的。使用相同的分佈檢查不同的GLCM特徵和不同的組圖像，我們發現原始圖像的數據集與合併的數據集或原始圖像中的裁剪圖像之間的分佈模式是一致的。因此，我們得出結論，池化和裁剪對於衍射圖像的數據增強都是有效的。</p><div class=pgc-img><img alt=深度學習訓練數據的評估與數據增強 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e6c4fe15315a423c91ce5fca0a692545><p class=pgc-img-caption></p></div><p>圖9 比較原始圖像的數據集的GLCM和從原始圖像合併的小圖像的數據集特徵值的分佈。</p><h1><strong>總結</strong></h1><p>訓練深度學習模型通常需要大量高質量的訓練數據，然而大量訓練數據可能包括噪聲數據。因此，有必要將噪聲數據與訓練數據分開。在本文中，我們提出了一種深度學習方法，用於將訓練數據自動分類為不同類別的數據，其中一種是噪聲類別。在許多情況下，需要將原始訓練數據轉換為滿足深度學習模型的輸入大小要求，在其他情況下，由於原始數據的大小不足，因此需要通過數據增強來獲取新數據。我們討論了不同的數據增強方法。我們還通過交叉驗證評估了培訓數據的質量。</p><p>為了證明所提出的數據增強方法有效，我們對大規模衍射圖像的自動分類進行了全面的實驗研究。從該實驗研究中收集的建議方法和經驗可用於數據增強和其他領域的大數據評估。</p><h1>參考文獻</h1><p>[1]J. Gao, C. Xie, and C. Tao, “Big data validation and quality assurance</p><p>– issuses, challenges, and needs,” in <em>2016 IEEE Symposium on Service- Oriented System Engineering (SOSE)</em>, March 2016, pp. 433–441.</p><p>[2]J. Ding, D. Zhang, and X. Hu, “An application of metamorphic testing for testing scientiﬁc software,” in <em>1st Intl. workshop on metamorphic testing with ICSE</em>, Austin, TX, May 2016.</p><p>[3] J. Ding, X. Kang, X. H. Hu, and V. Gudivada, “Building a deep learning classiﬁer for enhancing a biomedical big data service,” in <em>2017 IEEE Intl. Conf. on Services Computing</em>, Honolulu, HI, June 2017.</p><p>[4] J. Ding, J. Wang, X. Kang, and X. Hu, “Building an svm classiﬁer for automated selection of big data,” in <em>2017 IEEE International Congress on Big Data</em>, Honolulu, HI, 2017.</p><h1><strong>致謝</strong></h1><p>此文由南京大學軟件學院2016級本科生何天行翻譯轉述。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>數據</a></li><li><a>學習</a></li><li><a>訓練</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/6c5fd8d3.html alt=學習數據結構--第五章：圖（圖的遍歷操作） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4ac580af5ff049439daeba5a4406153a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/6c5fd8d3.html title=學習數據結構--第五章：圖（圖的遍歷操作）>學習數據結構--第五章：圖（圖的遍歷操作）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3d0e687.html alt=數據集中存在錯誤標註怎麼辦？置信學習幫你解決 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/Rm2RCGm4dso1ct style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3d0e687.html title=數據集中存在錯誤標註怎麼辦？置信學習幫你解決>數據集中存在錯誤標註怎麼辦？置信學習幫你解決</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/81aca76.html alt=學習數據結構--第六章：查找（查找） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ea3ba670175e4051920426c6f51ed0a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/81aca76.html title=學習數據結構--第六章：查找（查找）>學習數據結構--第六章：查找（查找）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6ff19cd8.html alt=中小學作文訓練之描寫專題（九）場面描寫 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/75eab302c96d43e8a680908253f96bcc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6ff19cd8.html title=中小學作文訓練之描寫專題（九）場面描寫>中小學作文訓練之描寫專題（九）場面描寫</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0926be43.html alt="筋膜放鬆練習 - 按摩滾輪訓練方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d8d39047a8ef48fdbc8ca96ec24e1957 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0926be43.html title="筋膜放鬆練習 - 按摩滾輪訓練方法">筋膜放鬆練習 - 按摩滾輪訓練方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html alt=直流鍋爐給水控制學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/eba10edcc8d14d9f8cde6fd5b212d90e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html title=直流鍋爐給水控制學習>直流鍋爐給水控制學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html alt=HTMLCSS學習筆記（六）——元素類型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb5988349894ce9bf568c6418f85b7d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html title=HTMLCSS學習筆記（六）——元素類型>HTMLCSS學習筆記（六）——元素類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html alt="web前端（從零開始），每天更新學習筆記 HTML5元素分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/46d70004fcd55e1ddad3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html title="web前端（從零開始），每天更新學習筆記 HTML5元素分類">web前端（從零開始），每天更新學習筆記 HTML5元素分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html alt="MySQL 學習筆記" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html title="MySQL 學習筆記">MySQL 學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html alt=深入學習MySQL事務：ACID特性的實現原理「轉」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/cdc702d66d6943499997d11e931425eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html title=深入學習MySQL事務：ACID特性的實現原理「轉」>深入學習MySQL事務：ACID特性的實現原理「轉」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html alt=如何學習模擬IC設計？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html title=如何學習模擬IC設計？>如何學習模擬IC設計？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html alt=小猿圈python學習-三大特性之多態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad0e8e3777854337abeb7c779ad79a04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html title=小猿圈python學習-三大特性之多態>小猿圈python學習-三大特性之多態</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>