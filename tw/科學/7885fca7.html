<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>一文看懂支持向量機 | 极客快訊</title><meta property="og:title" content="一文看懂支持向量機 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/b14f689acfb94e968e379121dee31bbb"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/7885fca7.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/7885fca7.html><meta property="article:published_time" content="2020-10-29T21:13:00+08:00"><meta property="article:modified_time" content="2020-10-29T21:13:00+08:00"><meta name=Keywords content><meta name=description content="一文看懂支持向量機"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/7885fca7.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>一文看懂支持向量機</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><h1 class=ql-align-center><strong>1 前言</strong></h1><p><strong>支持向量機（support vector machines，SVM）</strong>是我最早接觸的有監督分類算法之一。早在 MIT 修統計學的時候，我用它做過一箇舊金山灣區上班族通勤模式的分類研究，但當時只是很粗淺的認識。後來由於工作的關係又非常系統的學習了一下，這其中包括認真學習了斯坦福 Andrew Ng（吳恩達）的機器學習課（吳講的真的非常好，深入淺出），參閱了大量的關於 SVM 的理論和實際應用的文獻。</p><p>對於有監督分類算法的表現，業界常用大概 10 種不同的指標來評判，包括 Accuracy，LIFT，F-Score，ROC，Precision / Recall Break-Even Point，Root Mean Squared Error 等。<strong>無論以哪種準確性的評價指標來看，SVM 的效果都不輸於人工神經網絡 ANN 或者高級的集合算法如隨機森林。</strong>SVM 的另一個特點是其自身可以在一定程度上防止過擬合，這對於其在量化投資上的應用格外重要。這是因為任何人工智能算法有效的前提是：<strong>歷史樣本和未來樣本是來自同一個（未知）的整體，滿足同分布</strong>。只有這樣，基於歷史樣本學習出來的規律才會在未來繼續有效。<strong>但是對於金融數據來說，這個假設在很多問題上無法滿足。</strong>因此，如果機器學習算法在歷史數據上過擬合的話，那麼基本可以肯定這個模型對未來的數據毫無作用。</p><p>鑑於我對 SVM 的鐘愛，我很早以前就打算寫一篇介紹它的短文，作為對知識的一個梳理。不過後來，我讀了一篇來自 quantstart.com 的文章，名為 Support Vector Machines: A Guide for Beginners。作者並沒有使用大量的數學公式，而是用精煉的語言和恰如其分的圖例對 SVM 的基本原理進行了闡述。平心而論，讓我自己憋幾天也不一定能寫的比人家更清晰和生動，因此今天不如就索性把這篇文章大致翻譯過來，作為對 SVM 的一個介紹。我會跳過一些不影響理解的文字、對原文的結構做一些改動，並在一些地方加入自己的理解（<strong>在第 7、8 節中，有一些該文沒有的核心內容</strong>）。對那些閱讀英語比閱讀中文更舒服的小夥伴，也不妨看看原文https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners。</p><h1 class=ql-align-center><strong>2 初識 SVM</strong></h1><p>支持向量機解決的是<strong>有監督的二元分類問題（supervised binary classification）</strong>：</p><blockquote><strong>對於新的觀測樣本，我們希望根據它的屬性，以及一系列已經分類好的歷史樣本，來將這個新樣本分到兩個不同的目標類中的某一類。</strong></blockquote><p>垃圾郵件識別就是這麼一個例子：一個郵件要麼屬於垃圾郵件，要麼屬於非垃圾郵件。對於一封新郵件，我們希望機器學習算法自動對它分類。為此，我們首先通過人工對大量的歷史郵件進行 spam 或 non-spam 標識，然後用這些標識後的歷史郵件對機器學習算法進行訓練。</p><p>在處理這類分類問題時，SVM 的作用對象是樣本的特徵空間（feature space），它是一個有限維度的向量空間，每個維度對應著樣本的一個特徵，而這些特徵組合起來可以很好的描述被分類的樣本。比如在上面的垃圾郵件識別例子中，一些可以有效辨別 spam 和 non-spam 郵件的詞彙就構成了特徵空間。</p><p>為了對新的樣本分類，SVM 算法會根據歷史數據在特徵空間內構建一個超平面（hyperplane）；它將特徵空間線性分割為兩個部分，對應著分類問題的兩類，分別位於超平面的兩側。構建超平面的過程就是模型訓練過程。對於一個給定的新樣本，根據它的特徵值，它會被放在超平面兩側中的某一側，這便完成了分類。不難看出，SVM 是一個非概率的線性分類器。這是因為 SVM 模型回答的是非此即彼的問題，新樣本會被確定的分到兩類中的某一類。</p><p>在數學上表達上，每一個歷史樣本點由一個 (<strong>x</strong>, y) 元組表示，其中粗體的 <strong>x</strong> 是特徵向量，即 <strong>x</strong> = (x_1, …, x_p)，其中每一個 x_j 代表樣本的一個特徵，而 y 代表該樣本的已知分類（通常用 +1 和 -1 表示兩個不同的類）。SVM 會根據這些給定的歷史數據來訓練算法的參數，找到最優的線性超平面。理想情況下，這個超平面可以將兩類樣本點完美的分開（即沒有錯分的情況）。<strong>對於給定的訓練數據，可以將它們完美分開的超平面很可能不是唯一的，比如一個超平面稍微旋轉一個角度便得到一個仍然能夠完美分割的超平面。在眾多的能夠實現分類的超平面中，只有一個是最優的。</strong>我們會在下文介紹這個“最優”的定義。</p><p><strong>在實際應用中，很多數據並非是線性可分的。</strong>SVM 的強大之處在於它不僅僅侷限於是一個高維空間的線性分類器。<strong>它通過非線性的核函數（kernel functions）把原始的特徵空間映射到更高維的特徵空間（可以是無限維的），在高維空間中再將這些樣本點線性分割。高維空間的線性分割對應著原始特徵空間的非線性分割，因此在原始特徵空間中生成了非線性的決策邊界。此外，這麼做並不以增加計算機的計算負擔為代價。因此 SVM 相當高效。</strong></p><p>下面，我們會解釋如何找到最優的線性超平面。基於它引出最大間隔分類器（maximal margin classifier）的概念。通過實例，我們會發現最大間隔分類器有時無法滿足實際問題，這是因為不同類型的樣本點錯綜的交織在一起，讓它們無法被完美分割。為了解決這個問題，我們必須允許分類器故意的錯誤劃分一些點，從而得到對整體樣本總體分類效果的最優，這便引出了支持向量分類器（support vector classifier）。最後，我們介紹核函數的概念。支持向量分類器結合核函數便得到了支持向量機。最後，我們總結 SVM 的優缺點。</p><h1 class=ql-align-center><strong>3 線性超平面</strong></h1><p><strong>線性超平面是 SVM 的核心。</strong>對於一個 p 維空間，超平面是一個 p-1 維的物體，它將這個 p 維空間一分為二。下圖分別是 2 維和 3 維特徵空間中超平面的例子。在 2 維特徵空間中，超平面就是一條 1 維的直線，在 3 維特徵空間中，超平面是一個 2 維的平面。（注意，我們並不要求超平面一定要通過特徵空間的原點。）</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b14f689acfb94e968e379121dee31bbb><p class=pgc-img-caption></p></div><p>對於一個 p 維的特徵空間 <strong>x</strong> = (x_1, …, x_p)，我們可以通過下面這個式子來定義一個超平面：</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/92f3bc402caf4b328e602927a5d816cc><p class=pgc-img-caption></p></div><p>如果用向量和內積來表達，這個式子變為 <strong>b</strong>•<strong>x</strong> + b_0 = 0。任何滿足這個式子的向量 <strong>x</strong> 都落在這個 p-1 維超平面上。該超平面將 p 維特徵空間分為兩個區域，如下圖所示（示意圖，假設 p = 2，兩個顏色代表特徵空間中兩個不同的區域）：</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2b839baadf3249fb985eaa8cf7c4247b><p class=pgc-img-caption></p></div><p>如果一個向量 <strong>x</strong> 滿足 <strong>b</strong>•<strong>x</strong> + b_0 > 0，則它會落在超平面上方的區域；如果一個向量 <strong>x</strong> 滿足 <strong>b</strong>•<strong>x</strong> + b_0 &lt; 0，則它會落在超平面下方的區域。通過判斷 <strong>b</strong>•<strong>x</strong> + b_0 的符號，就可以對 <strong>x</strong> 分類。</p><h1 class=ql-align-center><strong>4 分類問題</strong></h1><p>在郵件識別的例子中，假設我們有 n 個歷史郵件，每一封都被標識為 spam（+1）或者 non-spam（-1）。每一封郵件中都有一些詞被選為關鍵詞。所有這 n 封郵件中不重複的關鍵詞就組成了我們的特徵。假設不重複的關鍵詞一共有 p 個。</p><p>如果將上面這個問題用數學語言轉化為分類問題，則我們有 n 個訓練樣本，每一個樣本都是一個 p 維的特徵向量 <strong>x</strong>_i。此外，每一個訓練樣本都有一個已知的分類 y_i（例如 spam 或者 non-spam）。因此，我們有 n 對訓練樣本 (<strong>x</strong>_i, y_i)。分類器將通過學習這些訓練樣本來優化自身的參數，得到最終的分類模型。我們使用測試樣本來檢查分類器的分類效果。</p><p>讓我們來看一個簡化的例子。考慮 2 維特徵空間並假設訓練樣本都是完美可分的（如下圖所示）。圖中，紅色和藍色代表了兩類不同的樣本點。三天虛線表示三個不同的超平面；它們都可以將這些點完美分開。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d00f568dc7194309a817157487ab4855><p class=pgc-img-caption></p></div><p>在這個例子中，這三條線都可以將特徵空間一分為二。然而，我們如何確定哪條線才是最優的呢？<strong>直觀上說，無論是（1）還是（3），都離某些紅色和藍色的樣本點太近了，給我們的感覺是這兩條線僅是“將將”把這些點分開；而位於中間的（2）號虛線離任何紅色的和藍色的點都比較遠，給我們的感覺是它非常清晰地將這些點區分開了。因此，如果從這三條裡面選的話，（2）號虛線應該是最好的選擇。</strong>在數學上，上述直觀感受被精確的翻譯為數學優化方程，即最大間隔超平面。</p><h1 class=ql-align-center><strong>5 最大間隔超平面</strong></h1><p>在上一節中，我們看到能夠實現分類的超平面可能不唯一。在這種情況下我們需要找到最優的。對於一個給定的超平面，我們可以計算每個樣本點到該平面的距離，<strong>這些距離中最小的一個就是這個超平面的間隔距離（margin）</strong>。因此，對於每一個超平面我們可以計算出它的 margin。<strong>所有可行的超平面中，margin 最大的那個就是我們要找的最優超平面，即最大間隔超平面（maximal margin hyperplane）。</strong>使用該超平面進行分類的分類器就稱為<strong>最大間隔分類器</strong>。</p><p>考慮下面這個 2 維特徵空間示意圖。圖中有紅色和藍色兩類樣本點。黑色的實線就是最大間隔超平面。在這個例子中，A，B，C 三個點到該超平面的距離相等。<strong>注意，這些點非常特別，這是因為超平面的參數完全由這三個點確定。該超平面和任何其他的點無關。</strong>如果改變其他點的位置，只要其他點不落入虛線上或者虛線內，那麼超平面的參數都不會改變。A，B，C 這三個點被稱為<strong>支持向量（support vectors）</strong>。最大間隔超平面非常依賴支持向量的位置（這很明顯是個缺點，我們會在後面解決）。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/744ff2e8f2c6469787f3c938452ca916><p class=pgc-img-caption></p></div><p>在數學上，求解最大間隔超平面參數相當於求解下面這個最優化問題：</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/33bc955b55aa46c4be72e54ec6ac63ef><p class=pgc-img-caption></p></div><p>這個優化問題雖然看起來複雜，但是它非常容易求解，不過關於它的求解過程不在本文的討論範圍內。</p><p>需要強調的是，上面的假想例子假設兩類樣本點是可以完美的被分開的。而在在實際問題中，這樣的情況幾乎是不存在的。考慮下面的例子，紅藍兩類樣本點糾結在一起，我們無法找到一個超平面將它們完美的分開。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/188056d84e9946f29e98ee14944640f3><p class=pgc-img-caption></p></div><p>在這種情況下，我們怎麼辦呢？<strong>解決的思路是放鬆我們的要求，即我們不要求所有的訓練樣本都被正確的分類，由此引出軟間隔（soft margin）和支持向量分類器（support vector classifier）的概念。</strong></p><h1 class=ql-align-center><strong>6 支持向量分類器</strong></h1><p>引出軟間隔和支持向量分類器的概念有兩個動機。</p><p><strong>第一個動機是最大間隔分類器非常依賴支持向量的位置，這使得它對新的訓練樣本非常敏感。</strong>考慮下面這個例子，右圖中僅僅因為增加了一個訓練樣本而它恰好是支持向量，前後得到的超平面完全不同。很顯然，左圖中的超平面對所有點的整體分類效果更好，而右圖中因為一個新樣本的加入，造成了模型的過擬合。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a6c09cd2b31e45a290065e404aed2029><p class=pgc-img-caption></p></div><p><strong>第二個動機就是上一節最後提到的，實際問題中，訓練樣本幾乎無法被完美分開。</strong></p><p>為了解決這兩種情況，我們允許一部分樣本點被錯誤的分類，並以此為代價追求分類器的魯棒性以及分類器在全局所有樣本點上分類效果的整體最優。一個支持向量分類器允許一些樣本點出現在最大間隔線之內甚至是超平面錯誤的一側。下圖左圖中，A、B 兩點雖然沒有被分錯類，但它們出現在了最大間隔邊界（虛線）之內；下圖右圖中，C 和 D 兩點則出現在超平面錯誤的一側。然而付出這些代價所換取的都是中間這條整體分類效果非常好的超平面（黑色實線）。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bf642bda7e104f2791e937ed7b5b462b><p class=pgc-img-caption></p></div><p>在數學上，引入 soft margin 後，優化問題變為如下形式：</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9e0e95e1be8c4e4f8ba27e244def27ef><p class=pgc-img-caption></p></div><p>其中，對於每一個訓練樣本點 i，定義了一個非負的鬆弛係數 e_i，它的取值表示該點是否滿足最大間隔。e_i 等於 0 則表示該點滿足最大間隔；如果 e_i 在 0 和 1 之間，說明這個樣本點在最大間隔邊界之內但仍然分類正確；如果 e_i 大於 1 這說明該點被分到了超平面的錯誤一側。</p><p>係數 C 表示我們允許 soft margin 的程度。C 越小意味著我們越不允許出現不滿足最大間隔的情況。從直觀上說，C 的取值決定了最多有多少個訓練樣本點可以被分類錯誤。下面的例子說明，對於不同的 C 的取值，得到的超平面也會有很大差異。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2bd3c462aaed4f4a90b2f89a4a804b19><p class=pgc-img-caption></p></div><p><strong>一個分類器的誤差由它的偏差和方差共同決定。在選取 C 時，我們必須權衡這兩者。一個很小的 C 往往意味著模型有很低的偏差但是很高的方差（因為新的樣本點會很容易改變超平面的參數）；一個很大的 C 通常意味著模型有很高的偏差（無法充分利用數據、找到有效的支持向量）和較低的方差。在實際應用中，C 的取值可以通過交叉驗證來確定。</strong></p><h1 class=ql-align-center><strong>7 支持向量機</strong></h1><p>支持向量分類器是一個很好的線性分類器（在允許錯誤樣本分類的前提下，找到對整體最優的超平面）。<strong>然而對於有的問題，數據本身的特性決定了線性分類器無論如何也不可能取得很好的效果。</strong>考慮下面這個例子。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/26bd2273ae2f44a5a610cddf79c157a1><p class=pgc-img-caption></p></div><p>如果僅使用線性的支持向量分類器，則只能得到上圖中黑色實線表示的超平面。它的分類效果是非常差的。這時，我們就需要對這個分類器進行非線性的變換，這就是支持向量機。</p><p><strong>這裡變換的核心是對特徵空間進行非線性的變換。</strong>比如，對於 p 個特徵 x_1, …, x_p，我們可以通過平方把它們變換到 2p 維的特徵空間，即 x_1, (x_1)^2, …, x_p, (x_p)^2。然後在 2p 空間內尋找線性的超平面進行分類。雖然超平面在 2p 維度是線性的，但是由於它是原始特徵的二次函數，因此從原始特徵空間來看，我們實際上得到了一個非線性的分類器！</p><p>那什麼是核函數呢？<strong>在求解超平面參數的最優化問題中，最優參數的取值僅僅依賴於訓練樣本特徵向量之間的內積。</strong>假設兩個樣本點的特徵向量為 <strong>x</strong> 和 <strong>z</strong>，則它們的內積為 <strong>x</strong>•<strong>z</strong>（或者 (<strong>x</strong>^T)<strong>z</strong>）。假設特徵空間的非線性映射為 phi，因此在映射後我們的樣本特徵向量變為 phi(<strong>x</strong>) 和 phi(<strong>z</strong>)。在這個新的特徵空間求解超平面時，我們需要使用的實際上是 phi(<strong>x</strong>)•phi(<strong>z</strong>)。對於這個映射，我們定義它對應的<strong>核函數</strong>為：K(<strong>x</strong>, <strong>z</strong>) = phi(<strong>x</strong>)•phi(<strong>z</strong>)。</p><p>因此，在優化問題的求解中，我們只要把 <strong>x</strong>•<strong>z</strong> 都替換為 K(<strong>x</strong>, <strong>z</strong>) 就相當於是在 phi 這個映射下的特徵空間內求解超平面。當我們知道映射 phi 的形式後，可以通過分別計算 phi(<strong>x</strong>) 和 phi(<strong>z</strong>)，然後再求它們的內積得到 K(<strong>x</strong>, <strong>z</strong>)。然而，這對於計算機來說是非常低效的。假如原始特徵空間的維度為 p，而我們把它映射到維度為 p^2 的特徵空間，則 SVM 算法的計算量就由 O(p) 變成了 O(p^2)。如果 p 很大的話（在很多實際問題中，p 是非常大的），這麼做會大大的損害 SVM 的效率。</p><p>對此，<strong>核函數的優勢是，對於很多應用中常見的特徵空間映射 phi 函數，核函數 </strong>K(<strong>x, z</strong>)<strong> 存在一個非常方便計算的解析式。</strong>通過計算這個解析式，我們便可以繞過計算 phi(<strong>x</strong>) 和 phi(<strong>z</strong>)，而直接得到 K(<strong>x</strong>, <strong>z</strong>) 的取值。然後我們只需要將 K(<strong>x</strong>, <strong>z</strong>) 的值帶到最優化參數的解中，便可得到最優的超平面。這大大的降低了 SVM 的計算時間，使其成為高維空間分類的利器。</p><p>讓我們來看一個例子，考慮下面這個核函數（它又稱作多項式核）：</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/68628d756eb64822b2cf8bbe065d652f><p class=pgc-img-caption></p></div><p>它的計算量只有 O(p)。當 p = 3 時，它對應的映射 phi 卻是下面這個 13 維空間！</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b409bbd2c7da4648b14a8d899fc09102><p class=pgc-img-caption></p></div><p>僅僅通過計算核函數的表達式就相當於巧妙的進行了從 3 維到 13 維空間的非線性映射，這是多麼美妙！</p><p><strong>SVM的核心就是通過使用核函數（某一個給定的非線性方程），將原始的特徵空間變換為更高維的特徵空間。</strong></p><p>常見的核函數除了上面這個多項式核外，還有徑向基（高斯）核。它的表達式如下，這裡不再贅述。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d8684fd844994c8a954fb07f5151b3f8><p class=pgc-img-caption></p></div><p>對於前面那個線性分類器無能為力的例子，在使用了適當的核函數後，我們可以在原始特徵空間得到非線性的分類邊界（下面左圖使用了多項式核，右圖使用了高斯核）。顯然，它們的分類效果比線性分類器的效果要好很多，這是因為它們充分利用了訓練數據的非線性特徵。</p><div class=pgc-img><img alt=一文看懂支持向量機 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fe75b5c2b89c4e9aa41450d4c282ab86><p class=pgc-img-caption></p></div><h1 class=ql-align-center><strong>8 SVM 的優缺點</strong></h1><p><strong>優點：</strong></p><ol><li><strong>高維度：</strong>SVM 可以高效的處理高維度特徵空間的分類問題。這在實際應用中意義深遠。比如，在文章分類問題中，單詞或是詞組組成了特徵空間，特徵空間的維度高達 10 的 6 次方以上。</li><li><strong>節省內存：</strong>儘管訓練樣本點可能有很多，但 SVM 做決策時，僅僅依賴有限個樣本（即支持向量），因此計算機內存僅僅需要儲存這些支持向量。這大大降低了內存佔用率。</li><li class=ql-align-justify><strong>應用廣泛：</strong>實際應用中的分類問題往往需要非線性的決策邊界。通過靈活運用核函數，SVM 可以容易的生成不同的非線性決策邊界，這保證它在不同問題上都可以有出色的表現（當然，對於不同的問題，如何選擇最適合的核函數是一個需要使用者解決的問題）。</li></ol><p><strong>缺點：</strong></p><ol><li><strong>不易解釋特徵的重要性</strong>（這是我自己加的，我認為這條最重要）：SVM 取得優異的分類效果固然可喜，但人們更願意知道是哪些特徵起了作用（解釋特徵的重要性）。在這方面，SVM 更像是一個黑盒（這可能也是增加其神祕色彩的直接原因）。SVM 在特徵空間構建了最優的超平面。在數學上，超平面是這 p 個特徵的線性組合，SVM 的分類依據是將待分類樣本點的特徵值帶入到這個線性組合中，然後看它的結果是大於 0 還是小於 0。不難看出，在特徵的線性組合中，<strong>每個特徵的係數 </strong>b_j<strong> 的絕對值的大小可以在一定程度上反映特徵的重要性，這是因為當某個特徵的係數非常接近 0 時，該特徵對於線性組合的符號的影響會非常微弱。</strong>然而，<strong>這種方便的解釋僅僅在我們沒有使用非線性核的時候適用</strong>。當我們使用了一些複雜的非線性核函數將原始特徵空間擴展到更高維的特徵空間後，我們很難知道新生成的特徵長什麼樣子（即求解時，我們只關心核函數的解析表達式，而“不關心”該核函數對應的特徵空間映射 phi 長什麼樣子，因此我們就無法知道映射後的特徵長什麼樣子）。因此，即便我們知道某個映射後的特徵的係數（的絕對值）很大，如果我們不知道特徵的表達式，我們仍然無法解釋。再退一步說，即便我們知道映射 phi 的形式，也知道映射後特徵的表達式，映射後的特徵仍然是原始特徵的非線性方程，例如 x_1×sqrt(x_2)×exp(x_3)，這種原始特徵的複雜非線性組合也許很難從問題本身的業務邏輯中得到令人滿意的解釋。</li><li><strong>非概率性：</strong>在某些分類問題中，我們希望分類器告訴我們這個樣本多大的概率屬於第一類，多大的概率屬於第二類，這些概率有助於我們判斷分類的可信程度。SVM 無法直接回答這個問題，因為樣本只能在超平面的某一側。但是我們仍然可以通過計算樣本點到超平面的距離來做近似的判斷：樣本點越遠離超平面，它屬於該類的可能性越高；樣本點越靠近超平面，它屬於該類的可能性也相應降低。</li><li><strong>要求樣本數大於特徵數：</strong>特徵數 p 大於樣本數 n 會使 SVM 的效果大打折扣。這很好理解。因為如果沒有足夠的樣本，就無法在特徵空間中找到真正有效的支持向量，這樣在面對新的待分類樣本時，SVM 的分類效果就會變得很差。</li></ol><h1 class=ql-align-center><strong>9 結語</strong></h1><p>SVM 算是有監督分類算法的一個利器。它原理清晰、計算高效、易在高維空間處理非線性關係。<strong>但是，和任何一個機器學習算法一樣，最難的不是使用一個算法，而是真正明白我們要解決的問題。</strong>如果問題的本質需要非線性分類邊界，而我們使用了線性的核函數，那結果可想而知。反過來也是一樣。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>向量</a></li><li><a>一文</a></li><li><a>支持</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/d61d6a42.html alt=支持向量機（第八章） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/153985032133768ee02ea64 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d61d6a42.html title=支持向量機（第八章）>支持向量機（第八章）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/0ad6da61.html alt=一文解釋支持向量機 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3d38e71602404ee1bf306ccc937d4289 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/0ad6da61.html title=一文解釋支持向量機>一文解釋支持向量機</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/58f11d6c.html alt=初識支持向量機 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/593c00005f9561757b88 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/58f11d6c.html title=初識支持向量機>初識支持向量機</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/9816751.html alt=支持向量機（第四章） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/153914838549618d2616eb5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/9816751.html title=支持向量機（第四章）>支持向量機（第四章）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/883ad22a.html alt=一文看懂電子電路圖，值得收藏 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/844b295b552548ab8a1ea362d28154f8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/883ad22a.html title=一文看懂電子電路圖，值得收藏>一文看懂電子電路圖，值得收藏</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e1a84312.html alt=127：平面向量(基底法，容易掉坑裡) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/798fe5150f7e41db847e88330e26f9d1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e1a84312.html title=127：平面向量(基底法，容易掉坑裡)>127：平面向量(基底法，容易掉坑裡)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a0542c8d.html alt=一文讀懂傳統製造業的物流技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a046d17df4a94bd39bba1ba16b156b34 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a0542c8d.html title=一文讀懂傳統製造業的物流技術>一文讀懂傳統製造業的物流技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/809b57c5.html alt=一文了解電源及其分類 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/Rpnb2FCETSFAju style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/809b57c5.html title=一文了解電源及其分類>一文了解電源及其分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a2d9ba7c.html alt=一文看懂集成電路有多費錢 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a2d9ba7c.html title=一文看懂集成電路有多費錢>一文看懂集成電路有多費錢</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/091e3705.html alt=一文讀懂：集成電路的工作原理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b197ddc4748d4f7f8e8da10c2941ac09 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/091e3705.html title=一文讀懂：集成電路的工作原理>一文讀懂：集成電路的工作原理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a6560bc0.html alt=“孃家”支持！他的創業路越走越穩！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a0c141c4347841cb8c41c9097bb352cc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a6560bc0.html title=“孃家”支持！他的創業路越走越穩！>“孃家”支持！他的創業路越走越穩！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/96140ee6.html alt=一文讀懂“光纖通信” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/68f7348192e640a581ed6a4aca5d7338 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/96140ee6.html title=一文讀懂“光纖通信”>一文讀懂“光纖通信”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9b97f53d.html alt=一文讀懂電機控制，收藏 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/a38d90926a724277a62b56ef7970faab style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9b97f53d.html title=一文讀懂電機控制，收藏>一文讀懂電機控制，收藏</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3bb906c.html alt=一文帶你看懂二叉樹的序列化 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/da5436c407ec4fc68dfb02f6948e3ba9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3bb906c.html title=一文帶你看懂二叉樹的序列化>一文帶你看懂二叉樹的序列化</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6be45896.html alt=一文讀懂鏈路追蹤 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a93af5a2f1414fd3b84ec8ade909bebd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6be45896.html title=一文讀懂鏈路追蹤>一文讀懂鏈路追蹤</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>