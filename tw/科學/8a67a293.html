<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來 | 极客快訊</title><meta property="og:title" content="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/a3075a8735e64936ace126341edaf869"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/8a67a293.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/8a67a293.html><meta property="article:published_time" content="2020-11-14T20:56:31+08:00"><meta property="article:modified_time" content="2020-11-14T20:56:31+08:00"><meta name=Keywords content><meta name=description content="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/8a67a293.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><p>近年來，圖表示學習（Graph Embedding）和圖神經網絡（Graph Neural Network, GNN）成為網絡數據分析與應用的熱點研究問題，其特點是將深度神經網絡技術用於網絡結構的建模與計算，誕生了以 DeepWalk、LINE 和 node2vec 為代表的圖表示學習技術，以 GCN 為代表的圖神經網絡，能夠利用分佈式表示方案實現對網絡中的節點、邊及其附帶的標籤、屬性和文本等信息的建模，從而更好地利用網絡結構進行精細建模和深度推理，相關技術已經被廣泛用於數據挖掘、社會網絡分析、推薦系統、自然語言處理、知識圖譜等領域。<br>為了推進國內在該領域的發展，由中國中文信息學會社會媒體處理專委會和北京智源人工智能研究院聯合主辦的“圖神經網絡在線研討會 2020”於 3 月 29 日下午召開，邀請了宋國傑、沈華偉、唐傑、石川四位國內著名學者介紹圖表示學習和圖神經網絡的最新理論進展和應用探索。<br><strong>清華大學計算機系教授、系副主任，中國中文信息學會社會媒體處理專委會常務副主任，智源研究院學術副院長唐傑老師進行了主題為“圖表示學習和圖神經網絡的最新理論進展”的分享，主要介紹了圖神經網絡及其在認知推理方向的一些進展。</strong><br>唐傑老師主要研究興趣包括人工智能、認知圖譜、數據挖掘、社交網絡和機器學習，主持研發研究者社交網絡挖掘系統 AMiner 等。<br>以下內容是根據唐傑老師的演講進行的總結。</p><p><br></p><p><strong>引言</strong></p><p><br></p><p>我們正在經歷第三次人工智能浪潮，世界上很多國家都推出了相應的戰略和發展規劃。但也有人說第三次人工智能浪潮已經接近尾聲，馬上就要到達“冰點”，第四次浪潮已經在醞釀之中。關於下一次浪潮的具體內容，今天暫時不做過多的討論，我們先剖析一下這次浪潮的具體情況。<br>AI 這幾年發展很快，其中一個重要原因是產業界的很多研究者、資源加入進來，一起推動 AI 的發展，如谷歌的 AlphaGo 和無人駕駛汽車。國內的相關企業也在蓬勃發展，從我的角度來說，我們做的事和硬件的關聯沒那麼緊密，很多的是偏軟件的東西，比如在圖片識別過程中，我們更關注怎麼將其中的語義信息抽取、識別出來，怎麼把文本的語義信息和圖片的語義信息混合起來做計算等。比如下圖，通過將一張狗的圖片減去關鍵詞“dog”，再加上關鍵詞“cat”，從而將貓的圖片識別出來。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a3075a8735e64936ace126341edaf869><p class=pgc-img-caption></p></div><p><br></p><p>這就是一個典型的多媒體的數據，在兩個方面怎麼做處理是我們當下最關心的一些的問題。人工智能在這方面快速發展，總結一下：<strong>這個時代是一個感知的時代，AI 到目前為止基本上解決了所有的感知問題</strong>。如果回顧過去的話，會發現計算機主要是做一些存儲和計算的工作；如果展望未來的話，我們想倡導的應該是在認知方面怎麼把計算、推理做到神經網絡中。<br>現在這個<strong>感知時代最大的特點是算法</strong>。下面這張圖彙總了最近幾十年 AI 算法的一些進展。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/085c48642a124d0ca4ac1d754a4b68c0><p class=pgc-img-caption></p></div><p><br></p><p>這張圖最上面的淺紫色的部分大致梳理了卷積神經網絡的發展歷史。1953 年，感知機（Perceptron）被提出來。1986 年，多層感知機（Multi-Layer Perception，MLP）開始出現。1998 年，Yann Le Cun 提出手寫字體識別模型 LeNet 及卷積神經網絡（CNN），但是當時 CNN 並沒有大規模被人關注，因為當時大火的支持向量機（SVM）壓住了 CNN 的風頭。直到 2012 年，Geoffrey Hinton 的學生在 LeNet 的基礎上加上了 ReLU、Dropout 等內容，實現了 AlexNet，把 CNN 的效率大規模提高，才推動了這個方向的發展。<br>第二部分淡綠色部分的內容表示自編碼（AutoEncoder），這部分不是今天的重點，不再展開。<br>第三層淺黃色的部分可以被稱為循環神經網絡（Recurrent Neural Network, RNN）的發展。放大來看，它的理論和上面的一樣優美，它其實就是一個概率統計模型，即把神經網絡用圖的方式連接起來，雖然最早期的時候大家做的都是序列化的模型，如 RNN，或者是在語言模型（Language Model）上面做一些相關的工作，甚至是Seq2Seq，但是最近更多的工作是在圖上，如唐建他們有一篇文章就是把圖模型(Graphical Model)加上神經網絡，一起連接起來，於是就變成一個基於圖模型的神經網絡(Graphical Model based Neural Network)。<br>如果結合最上面淺紫色的內容和淺黃色的內容，即<strong>把卷積神經網絡加上圖模型，這形成我們今天經常說的圖神經網絡的基本思想。</strong><br>可以看出來，圖神經網絡有很長的歷史，是一個非常簡單的機器學習算法在圖上的一個自然地延伸。為什麼現在大家覺得圖神經網絡火得不行？好像所有的人都在研究圖神經網絡？也有些人說這個東西是簡單地把某些東西用在另一個數據集上？其實機器學習所有的發展歷史都有這樣一個過程，它最早期都是從一個簡單的單樣本分析開始，然後逐步複雜化，最後再把樣本與樣本之間的關聯關係考慮進來，如圖神經網絡就是用一個簡單的思路把它結合起來。最早的線性條件隨機場（Conditional Random field，CRF）、最大熵馬爾可夫模型（Maximum Entropy Markov Model，MEMM）等模型的思路都是在原來的思路上擴展的。<strong>GNN就是神經網絡在圖上的一個自然地延伸。</strong>當然，這一波自然延伸的結果是必然有下一波階躍。如原來在圖模型上有了 CRF、MEMM 以後，概率統計模型基本到了一個極致，後續延伸自然就到了下一個階段。<br>最下面是一個強化學習（Reinforcement Learning），這裡也不再多講。<br>回到我們的背景。既然有 CNN、有大量網絡化的數據，就可以做很多相關的研究。<br>首先，這些數據的規模非常大。如阿里巴巴、Facebook、新浪微博等積累了超大規模的社交網絡數據，如果泛化來看，我們還有經濟方面的網絡（Economic networks）、生物醫學方面的網絡（Biomedical networks）……甚至還有大腦中神經元的網絡（Networks of neurons），這裡面有很多相關的應用，如果從機器學習的角度歸納一下相關的應用，可以發現以下幾個核心的任務。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/da66acbbbd6948dfa07b4f597efddd90><p class=pgc-img-caption></p></div><p><br></p><p>下面詳細展開介紹一下。<br>（1）點分類，做一個點的表示，然後做預測它的類型是什麼。<br>（2）兩個點的鏈接生成，如兩個點之間有沒有可能生成一條邊，或者再放大來看，看有沒有可能找到一個子圖，或者找網絡相似度。這個方面在過去有很多相關的研究，今天我們會大概涉獵這些東西。這方面最早的研究可以追溯到 Geoffrey Hinton 研究的分佈式表示（Distributed representation），但是這個概念在當時被 SVM 壓制，一直沒有火起來，直到 2013 年 Tomas Mikolov 提出了非常快速的算法 Word2vec，才迅速讓深度學習算法在文本分析領域快速落地。到了 2014 年，Bryan Perozzi 很巧妙地將 Word2vec 直接用到了神經網絡中，開啟了在網絡中做表示學習的浪潮，後來唐建、Yann Le Cun、Max Welling 等都做出了大量的工作，最後整個這方面的研究形成了我們今天看到的 GNN，如果放到更高的層面去看，就是網絡表示學習這麼一個領域。</p><p><br></p><p><strong>回顧網絡表示學習</strong></p><p><br></p><p>首先回歸一下網絡表示學習。<strong>網絡表示學習在本質上就是給定一個網絡，我們要學習裡面每一個節點在低維空間上的一個表示。</strong>我們希望當網絡在低維空間時，如果兩個節點之間的距離很近，它們就一定比較相似，如果它們不是同一個類型的節點，距離就應該比較遠。<br>這個問題為什麼比較難呢？這是因為：（1）如果我們用 CNN 或者相關的算法在圖片上做學習，由於圖片是典型的二維的、有上下之分，每個點上、下、前、後、左、右是什麼很清楚，但是在網絡中，它是一個複雜的拓撲結構，甚至沒辦法用上、下描述，只能用拓撲結構來說明，或者說兩個節點的距離有多遠，而沒有一個嚴格的空間的概念。（2）節點之間沒有文本那樣的先後關係；（3） 整個網絡是非常動態的，並且可能有一些相關的信息、相關的屬性。比如做一個人的行為分析的話，某個節點可能有很多的屬性信息，還有很多網絡結構的屬性和信息，我們可以把網絡結構的表示學出來，還可以把網絡屬性的表示學出來，這就有兩種不同的表示。有時候人們可能還發出一些圖片、語音等其他媒體的信息，怎麼把這些表示都學出來非常困難。<br>最早在網絡上做表示學習是把整個研究規約到一個很簡單的 Word2vec 問題上，就是我說的 DeepWalk 的思路，即用 word2vec 的思路來做網絡的表示學習。這個思路非常簡單，即 word2vec 就是上下位，如果上下位相同的單詞，他的意思就比較相似，於是學出來的表示也比較相似，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2cabe3593b2b40a291caf8bea181ec2b><p class=pgc-img-caption></p></div><p><br></p><p>在網絡表示學習中，DeepWalk 的思路是：既然節點沒有先後關係，就做一個先後關係。從任意一個節點開始，在上面跑一個隨機遊走（Random Walk），跑完了以後可以形成了一個序列，形成一個和 DeepWalk 處理文本一樣的上下位信息，於是v1 這個節點就由 v3、v4、v5、v6 作為它的上下位，剩下給一個隨機的低維表示，然後在上面進行 SkipGram with Hierarchical softmax 的一個學習，最後就可以得到一個希望的表示結果，如下圖所示。<br>這裡做 SkipGram with Hierarchical softmax 是為了提高計算速度，不再詳細說明。最後的參數學習可以用一個基於梯度的學習很快做到。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/08c35479975f499cba1a19029e04f09a><p class=pgc-img-caption></p></div><p><br></p><p>這篇文章最初在當時並沒有引起大規模的關注，但是它開啟了一個在網絡中做表示學習的新紀元。最初大家覺得在網絡中做表示學習是一件很麻煩的事，後來發現神經網絡可以用在網絡中，可以學習每個節點的表示，並且學到的表示可能可以用於不同的網絡，如 Blog Catalog，使得它的效果還不錯。後來又試了其他的網絡，如 Youtube 中的網絡，發現效果也不錯。後來就引起了大規模的相關的研究，討論怎麼來提高在網絡上做表學習的效果。於是大家就分析 DeepWalk 的一些缺點。<br>首先它的上下文是固定的，而它的隨機遊走並沒有考慮到網絡的特性，於是後面一大堆的研究，如 LINE 等。下圖中 5 和 6 這兩個節點根據我們人的行為來看是很相似的。5 和 6 有四個相近節點（1、2、3、4），但是 6 和 7 是直連的。如果用剛才的 DeepWalk，即 RandomWalk 在上面隨機遊走，6 和 7 可能距離反而更近，它的相似度反而更高。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4faa9af2a62f487a8673c254d1a45e21><p class=pgc-img-caption></p></div><p><br></p><p>但是根據人的直覺，5 和 6 顯然更相似，於是 LINE 就加上了一個二階的相似度，有一階有二階。後來研究者又把它擴展到一個異構網絡（PTE）上，即這個網絡不是單純的一個網絡，而是一個異構網絡。後來有人又給它加上了社交的屬性（Social Information）。在 RandomWalk 中，左邊三角形 x1vt 是一個閉合三角形，而右邊是一個開合的三角形，開合的三角形和閉合的三角形的相似度或者 RandomWalk 的度應該不一樣，於是就加上了這麼一個 biased RandomWalk。把 Performance 在社交的數據又進一步提高。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/beaf817de8234b94b8cfcc70ae6fc2d1><p class=pgc-img-caption></p></div><p><br></p><p>剛才給大家講了這麼多 Natural in Bedding 的一些很基本的算法都是感知的，它們本質上到底是什麼呢？沈華偉（中國科學院計算技術研究所研究員）老師講的圖神經網絡給出了一個很好的解釋，其實<strong>它們在本質上都是在做信通的處理</strong>。<br><strong>通過數學分析我們發現最簡單的網絡表示學習在本質上都是在做一個矩陣分解，在做一個奇異值分解（Singular Value Decomposition，SVD），只是分解的形式不一樣，如下圖所示。</strong>DeepWalk 分解的是第 1 個式子，LINE 分解的是第 2 個式子，PTE 分解了一個異構的網絡，node2vec 分解了一個更復雜的網絡，因為它裡面考慮到了三個節點形成的矩陣。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f48921fea4ca44b484ce80b8671ca152><p class=pgc-img-caption></p></div><p><br></p><p>這樣的話我們就可以把剛才給大家看的 DeepWalk 的過程給定網絡，找到這種隨機遊走的 Context，然後再做 Skip Graphs，直接把這兩步組合在一起就變成一個矩陣分解，通過這個矩陣分解可以直接得到最後的結果。這裡面我們給出了一個嚴格的數學分析，最後就發現這個 DeepWalk 在本質上就在分析下圖下方的東西。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/770d01136ae5480bab0813c9288fad64><p class=pgc-img-caption></p></div><p><br></p><p>更有意思的 LINE 也是在分解一個矩陣，而且這個矩陣和 DeepWalk 隨機遊走的矩陣比起來，兩個式子非常相似，但又不一樣。仔細看一下會發現，如果把 DeepWalk（其實就是 Windows Size，也就是我們的上下文的長度）設成 1，它在本質上一下子就等於 LINE 了。於是從這個角度上來說，LINE 就變成 DeepWalk 的一個特例。我剛才講到 PTE 是把 LINE 擴展到了異構網絡，從某種角度上來說，你把異構網絡變成一個同構網絡，變成一個超級大的同構網絡。於是 PTE 又可以變成一個 LINE 的特例，從某種角度上來說，PTE 又變成了一個 DeepWalk 的一個特例。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89e92bfd5d694c30b0cdd033b11c2b55><p class=pgc-img-caption></p></div><p><br></p><p>此外，node2vec 是一個 Biased Random Walks。原來我們是說隨機遊走從u這個節點往任何節點的隨機遊走都是一樣的，如下圖所示。但是現在 node2vec 給出了另外一個思路：讓寬度優先的隨機遊走，可能跟深度優先的隨機遊走的概率不要一樣。或者簡單說，閉合三角形跟開合三角形的隨機遊走的概率不一樣，於是在本質上就相當於做了兩件事：一個是 local 的隨機遊走，一個是 global 的隨機遊走。因為開合的它更容易遊走到其他的那些子領域，你比如說左邊是個子領域，右邊是另一個子領域，於是它相當於開合的就遊走到兩個子領域裡面去了，而閉合的就更容易在同樣一個子領域裡面流走。這就是 node2vec 很巧妙的地方。node2vec 的思路非常簡單，優美的地方是我們同樣可以通過一個數據分析，把它歸約到一個矩陣分解上。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/072a0fd1c6c1470593ce78a54b12febe><p class=pgc-img-caption></p></div><p><br></p><p>這樣就把剛才的矩陣分解統一起來了。我們可以說所有的這種網絡表示學習或者說很多表示學習算法都可以歸約到一個簡單的矩陣分解，或者說 SVD 的一個過程。<br>但是這樣又出現了新的問題：我們現在怎麼來做 GNN 或者圖神經網絡呢？畢竟在圖神經網絡中要結合網絡化的信息，如剛才提到的網絡表示學習結合的是一個上下文信息，用上下文信息做這種網絡表示學習，怎麼真的把這種網絡結構化的信息利用上，而且要讓他速度特別快呢?<br>我們首先做了一個很巧妙的事情，我們做了一個被稱為 ProNE 的算法，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1b67286a39684e6c8579933d188654fd><p class=pgc-img-caption></p></div><p><br></p><p>這個算法是什麼呢？首先，構造一個非常稀疏的矩陣；然後，在這個稀疏矩陣裡面用剛才的方法做一個矩陣分解，做一個 SVD 分解；最後，在 SVD 分解的基礎上做普傳播，也就是說我們來做傳播，於是每一個節點傳播的東西就變成了表示學習學到的結果，而不是傳播本身。於是就相當於把表示學習學到的低維表示在圖上做傳播。<br>大家可以想象一下，如果我們做一個特別快速的 SVD 分解（如做一個線性的算法，基本做到點和邊成線性關係），同時，把剛才學到的低維表示在所有的邊上做傳播，事實上跟這個邊又呈線性關係，於是整個算法可以做成一個跟網絡節點和邊呈線性關係的一個算法，這樣的話整個算法的模型會就可以做得非常快。有人提到說這個可能複雜度很高，對此我要再解釋一下，如果我們做一個非常快速的 SVD 分解，我們可以做一個線性算法，比原來傳統的 SVD 算法快兩個數量級，它基本上是個線性關係。舉一個例子。下圖是我們跑出來的一個結果。我們是 ProNE 加上普傳播得到的一個結果，可以看到結果比原來最快的LINE快一個數量級，比 node2vec 快兩個數量級。而且我們最近還發現另外一個算法，它可以比原來 randomize 的 TSVD 分解還要再快一個數量級，甚至加上譜傳播都可以比其他兩個速度還要快。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/efc86041c6fc493c87a60f010073ef28><p class=pgc-img-caption></p></div><p><br></p><p>而且在超大規模的網絡中，比如說百萬級的網絡上，我們基本上幾分鐘就可以把它全部跑完，把網絡表示的結果全部跑完。更有意思的是效果還可以做的非常好。大家可以看一下下面這個效果，我們基本上不用任何的普傳播，只用 SMF 時，即只用稀疏矩陣分解的時候，就可以做到跟原來的算法得到的效果差不多。如果用了的話，就比原來的算法明顯好得多。這樣就很優美。我們可以在擁有上億的點的圖上，用單機花 29 個小時跑出一個結果，比原來的結果的精度還要好、速度還比較快。<br>以上就是快速回顧了一下網絡表示學習的一些東西。這裡主要是講的 NetMF（也就是矩陣分解）及傳播的一些東西，如下圖所示。下圖中間這一部分沒有講，大家有興趣也可以去看一下。我們主要是把 NetMF 做了稀疏化，做了一個理論分析，給大家可以在理論上做了一個保證。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2e546d2ad50e4ece8411a4c2edf1e8c0><p class=pgc-img-caption></p></div><p><br></p><p><strong>現在是 GNN 的時代</strong></p><p><br></p><p>今天想跟大家分享一下更重要的是：<strong>現在其實是在一個 GNN 的時代</strong>。GNN 從 2017 年 Max Welling 的論文發表出來以後，已經越來越火，越來越多人提出了很多問題，說現在已經進入一個 GNN 的“坑”。那麼，GNN 的本質是什麼呢？<strong>核心、簡單來講，GNN 希望把原來的淺層的這種網絡變得更加深層。</strong></p><p><br></p><p>這個問題現在其實是個悖論。首先，很多人說我們要把原來的 Shallow 的神經網絡變成深度的神經網絡，這樣可能會提高效果，但是這導致了兩個嚴重的問題。<br>第一個嚴重的問題是網絡到底要多深才算深？比如說在網絡中，假如我們真的做了很多深層次的話，如果每一次深層次的都是在做一個鄰居節點的傳播，這時候深層次、很深的網絡會導致這個信息就擴散整個網絡了，這個時候就導致一個過平滑（over-smooth）的問題，而不是過擬合 (Overfitting)。另外一個問題就是整個網絡的深度學習假如都像剛才都是矩陣分解，如果沒有一個非線性的變化，所有的矩陣分解就讓它深度下去，它其實本質上還是一個矩陣分解。這個到底是怎麼回事呢？我們在這裡做一定的分析。在 GNN 中我們其實分解的就是下圖這樣一個簡單的矩陣。這是一個鄰接矩陣，H 是上一層的隱變量，W 是權重，激活函數是非線性的。其實之前有研究已經證明了，GCN 如果沒有這個激活函數的話，整個 GCN 其實可以退化成一個非常簡單的矩陣，而且效果還有可能更好。所以這也是一個悖論，等一下我們也在後面再探討一下。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f1944567fd43447b8d8ee6d876746661><p class=pgc-img-caption></p></div><p><br></p><p>在探討之前，我們先快速說明一下 GCN 的本質。<strong>GCN 的本質其實就是在一個網絡中把鄰居節點的表示信息放到自己當前節點上。</strong>比如說對於下圖中 v 節點來講，它有鄰居節點 a、b、c、d、e，每一個節點可能都有一個表示（從 <strong>h</strong>a 到 <strong>h</strong>e）。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a3e6ec338b154089b82f13eb8c10a331><p class=pgc-img-caption></p></div><p><br></p><p>怎麼把鄰居節點的引表示通過某種方法或某種函數（如 f 函數可能是線性變化，也可能是個非線性變化），把它 Aggregate 到當前節點，得到 <strong>h</strong>v。當然，從下圖所示的內容裡表示我們就可以看出一個結果：左邊給出了一個在鄰居節點身上做的卷積，得到對當前節點進行卷積的結果。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad7f6197822a4e2f85754c541ca08a21><p class=pgc-img-caption></p></div><p><br></p><p>我們可以構造出一個加上了非線性的激活函數的函數，如下圖所示。是權重，是鄰居節點。是當前節點的表示， v 是當前節點，另外還有一個非線性的激活函數。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/61aeb36fb8d9486c8c70143264dca154><p class=pgc-img-caption></p></div><p><br></p><p>基於這樣的思想，後來在最早的 GCN 相關的論文上也有很多的延續，如 GraphSage。GraphSage 的思想非常簡單，它把原來單純的當前節點和其他所有節點的聚合整合到一起了，變成當前節點的表示和其他所有節點的表示連接在一起，如下圖所示。這樣的話效果反而提高了。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3e5f0fdc1afc4b4db0d11390181ab32d><p class=pgc-img-caption></p></div><p><br></p><p>這個思路後來又被 GAT 給打敗了，GAT 是什麼？我們現在 aggregate 的時候，也就是每個節點信息往中間節點傳的時候，它的權重不一樣。從 Social network 的角度來說，它的本質就是影響力不一樣，就相當於某個節點對其他的不同的節點的影響是不一樣的。<strong>怎麼把這種影響力在網絡中度量，是社交網絡區別於其他很多網絡一個非常重要的方面。</strong>當然，從數學上可以把 GCN 看作是下圖上方的式子，而 GAT 是下圖下方的式子，可以看到唯一的變化就是加上了一個 Attention 參數，這樣的話可以看一些初步的結果，加上 Attention 參數的效果確實比原有算法的效果要好。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/08bd73b5446841c8ad233df820993981><p class=pgc-img-caption></p></div><p><br></p><p>我們現在再次問自己一個問題：<strong>所有的這些卷積網絡的本質是什麼</strong>？剛才說了，網絡表示學習的本質是一個矩陣分解，那捲積網絡的本質是什麼？而且卷積網絡面臨著很多問題，除了我們經常說的機器學習普遍存在的過擬合問題，這裡還存在更重要的問題——過平滑及不健壯的問題。因為在網絡中可能存在鏈接，甚至很多噪聲鏈接，這些鏈接可能會大幅影響效果，這個時候該怎麼辦？<br>我們先來看一看下圖的分析。GCN 每一層的傳播在本質上都是一個矩陣分解，從前面的分析可以看到，對矩陣分解其實可以進一步做一定的分析，把矩陣分解變成一個信通問題。而藉助信通的思路其實還有一個很有意思的擴展，我們可以把網絡中的鄰接矩陣 <strong>A </strong>做一定的變換，我們可以在前面做一定的信通的變換，在後面也可以做信通的變換。這樣的話整個網絡其實可以變成一個 Signal Rescaling 的一個思路。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e19f83a022e6445d94e1088ea04c41dd><p class=pgc-img-caption></p></div><p><br></p><p>這樣的好處是可以把原來的每一層都做一個矩陣分解直接變換成相關的一些變化，我們可以把網絡中的節點的 status，或者網絡中的影響力全部嵌入卷積神經網絡。這樣的話對每一層的卷積層都可以做一定的變換，它可以是多層的，甚至是可以做 Multi-head Propagation mechanism，還可以做 Multi-hop variants。如果我們去掉每一層的非線性函數，事實上 Multi-hop variants 就和單純的 GCN 等價了。這樣一個分析的思路就把前面所有的注意力機制，如 Node attention、Edge attention、K-hop edge attention 或 Path attention 全部歸一化了起來。更優美的是基於這樣的思想，其實我們在以後就可以不用研究刻意去研究 GCN 的這種結構、架構，而是去研究在 GCN 裡的不同的操作。我們可以基於剛才的函數對裡面的 P、Q 做變換，或者對 L 值直接做變換。這樣的話我們就可以對整個 GCN 做三種操作：Rescale，Re-normalize、Propagate，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cf46d9017ce14716a421e3a9c83a5be8><p class=pgc-img-caption></p></div><p><br></p><p>前面是前者，我們可以做加在 pre 上，也就是說我們在做拉普拉斯分解之前，可以先做一個 Rescale 把 P 升上去，也可以在做完拉普拉斯分解以後做 Re-normalize，還可以進一步再做一個 Post Propagation。於是我們自然就把 P、L、Q 給分解了。<strong>分解完了最大的好處是 GCN 就是一個簡單的拉普拉斯矩陣的分解，</strong>而 GAT 既包括分解，也包括 normalization，還包括 Rescaling。而 ASGCN 同樣可以被歸約成一個 normalization，加上一個 propagation。大家可以看到這三個操作在不同的方法中，事實上都相當於這三個原子操作的一個組合。<br>我們還可以進一步看，GraphSAGE 就相當於構造了一個 L，它沒有做 Rescaling，而是先做了一個 normalization，再做了一個 propagation。而 FastGCN 先做了 normalization，再做了一個 propagation，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/675a1dea634b48b58a8446a72806cf96><p class=pgc-img-caption></p></div><p><br></p><p>甚至我們可以把所有的這些卷積網絡的方法全部用 signal Rescaling 的方法把它統一起來，而統一的思想就是以上的三個操作，就用三個 operation 把所有的操作都給歸一化起來，如下圖所示。從這個角度上大家可以看到，在網絡表示學習方面，我們把它歸一化到矩陣分解，用矩陣分解把網絡表示學習都給歸一化起來了。而在卷積網絡中或者是叫圖神經網絡（當然更多的是卷積網絡）中，我們就用三個操作+矩陣分解，用矩陣分解把形式化統一，然後用三個操作把不同的方法全部給統一起來。於是這個時候我們有了一個統一的框架，基本上都是矩陣分解加不同的一個操作（這裡更多的是 signal Rescaling）這麼一個思路，再把它統一起來。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/edf37af5e45545ecbd86246fd6e2fb21><p class=pgc-img-caption></p></div><p><br></p><p>我們還做了一些實驗。我們發現結果也比以前確實要好，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/84f7bf63c4de4b66890d0d1f29af43d8><p class=pgc-img-caption></p></div><p><br></p><p>我們加上不同的操作以後，前面有 rescaling，post 叫 propagation，還有 normalization，我們用不同的操作加在上面可以組合成不同的方法。而這些不同的方法可以用一個 AutoML 的方法來做 Tune，這樣就比原來歸一化表示的其他方法的效果都要好。從效果上我們可以得到更好的一個結果。這樣就可能解決“在數學上的分析很漂亮，我們都說是一個 signal Rescaling 的問題，但是我們怎麼讓結果真的比原來好很多，這個時候就有很大的一個麻煩”這個問題。關於這一部分的很多細節沈華偉老師講了很多，所以我在這裡跳過一些，有興趣的可以查看相關的視頻。<br>接下來我們來看一下最近的一些思路。最近大家都知道自然語言處理及很多其他領域中，預訓練已經變成一個標配了，BERT 從 2018 年底出現到現在已經打敗了很多相關的一些方法，甚至已經出現了關於 BERT 的一系列相關的方法（BERTology），如 XLNet, Roberta, ALBert, TinyBERT 等。在計算機視覺（CV）方向也有很多相關的研究，最近一個很重要的進展就是 Contrastive Learning，即利用無監督學習（Unsupervised Learning）的方法或者是一個非常簡單的 Contrastive Learning 的思路來做的效果更好。MoCo 在 2019 年年底出來，基本上一下子就做到無監督學習的結果基本上就可以跟監督學習（Supervised learning）的結果差不了太多。後來 Geoffrey Hinton 團隊的 SimCLR 又打敗了 MoCo，最近 MoCo2 又把效果進一步提高，打敗了 SimCLR。它們的核心思想都 Contrastive Learning，本質上都是在用 self learning 來做表示學習，類似於做一個預訓練。<br>我認為這方面是一個可能的方向，未來在這方面可能會有一些發展。但是怎麼跟網絡化的數據、跟圖掛鉤，就是把圖跟預訓練掛鉤，這方面其實還是一個很大的挑戰。所以總體來講，在 GNN 時代，如果光從算法的來考慮，我覺得值得考慮的其實有兩大核心的挑戰：（1）怎麼把預訓練思路，包括剛才的 Contrastive Learning 和圖結合起來。其實現在還沒有一個特別里程碑式的進展。（2）我們在這裡面怎麼解決它過平滑、過擬合、不健壯的問題。這幾個問題怎麼解決是很難的問題。</p><p><br></p><p><strong>GNN+推理會產生什麼</strong></p><p>我們現在再來看一看 GNN 怎麼和推理結合起來。說到推理，可能有些人說這個問題太大了，所以我們先從一個非常簡單的問題（Multi-hop Question Answering，QA）來說。</p><p><br></p><p>這個問題是個自然語言處理的問題。假如我們要解決一個問題“找到一個 2003 年在洛杉磯的 Quality 咖啡館拍過電影的導演（Who is the director of the 2003 film which has scenes in it filmed at The Quality Cafe in Los Angeles）”。如果是人來解決這個問題的話，可能是先追溯相關的文檔，如 Quality 咖啡館的介紹文檔，洛杉磯的維基百科頁面等，我們可能會從中找到相關的電影，如 Old School，在這個電影的介紹文檔裡面，我們可能會進一步找到該電影的導演 Todd Phillips，經過比對電影的拍攝時間 2003 年，最終確定答案是 Todd Phillips，具體流程如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/324bb2f48b594fadafe116752d55ad8f><p class=pgc-img-caption></p></div><p><br></p><p>但是計算機會怎麼做？計算機不像人，計算機沒有這麼聰明。如果我們用一個簡單的方法，也就是說我們用卷積神經網絡的方法來做的話，應該怎麼做？我們可以用 BERT 或 XLNet，BERT 可以做到 512 的 Context 了，我們現在甚至可以做到 1024、2048 的 Context，當然訓練要求就更高了，甚至沒有足夠的機器來完成。但是這裡面核心的一個問題不是說它能不能解的問題（當然第 1 個方面是它能不能解），而是像人那樣解決這個問題，即需要人的推理過程，但 BERT 可能根本就解決不了。<br>第 2 個更難的是缺乏知識層面上的一個推理能力，尤其是缺乏可解釋性。我們到最後得到的一個可能的結果：BERT 給出了一個和真實結果比較相似的結果，說這就是答案，然後就結束了。要想完美解決這個問題，需要有一個推理路徑或者一個子圖，我們怎麼在這方面來做這樣的事情？這很難。怎麼辦呢？我們來看一看人的推理過程。人的推理過程是：人在拿到這個問題以後，首先可能找到 Quality 咖啡館相關的文檔，這是最好的一個文檔（因為洛杉磯市的相關文檔不是一個好的初始文檔）。找到 Quality 咖啡館相關的文檔以後，我們可以從裡面找到 old school 的相關文檔，然後從 old school 的文檔中可以找到 Todd Phillips。整個過程有好幾個步驟，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/40473850919a499b8d57fc7f84487a93><p class=pgc-img-caption></p></div><p><br></p><p>我們怎麼把步驟形式化成一個計算機或者說機器學習能做的事情就是我們下一步要探討的。<br>我們把這個問題跟認知科學中的一個很重要的理論——雙通道理論（Dual Process Theory）結合起來。為什麼和雙通道理論結合起來呢？人在做推理的時候，我們發現有兩個系統：System 1 和 System 2。System 1 被叫作直覺系統，直覺系統是說給定某個關係以後，只要算出相似度，就立馬把相似度給出來。比如當大家聽到 3 月 29 號下午有一個圖神經網絡的研討會時，大家覺得有興趣，決定要聽一下。System 2 會做進一步的推理、邏輯思考、決策。它可能會想下午還要帶小孩出去玩，或者下午還有另外一門課，這個課不能翹，於是你最後說算了，下午不去了，最後你就不參加了。所以 System 2 它是帶有邏輯思考的。<br>以上就是人思考問題的過程。AI 怎麼跟人來結合？我們在去年探討這個問題的時候，正好 Yoshua Bengio 他們也在聊這個問題，他在去年的 NIPS 上更直接地講了：“深度學習應該直接從 System 1 做到 System 2。現在 System 1 主要是在做直覺式（Intuitive）的思考。而 System 2 應該做一些邏輯加上一些推理，再加上一些 planning 的思考”如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8e7e59dbb2654fc7817196651a7df33c><p class=pgc-img-caption></p></div><p><br></p><p>他直接說的是說<strong>要做 System 2 的深度學習</strong>。我們當時其實還沒有直接提 System 2 的深度學習。我們講的是“<strong>機器學習跟人的邏輯思考，甚至加上常識知識圖譜，兩者結合起來</strong>”。在這個基礎上，我們在去年其實跟 Yoshua Bengio 他們同時發了兩篇文章。<br>我們當時做了什麼？我們就用 System 1 來做知識擴展，來做直覺的知識擴展；用 System 2 來做決策，我們就把它叫作<strong>認知圖譜（Cognitive Graph）</strong>。這個思想用剛才那個例子來說大概是下面這樣。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d988681c4c1c4832ad224fc5b4c910f3><p class=pgc-img-caption></p></div><p><br></p><p>首先，回到剛才那個問題，我們可以很快找到這個問題中的實體，這個很簡單，可以用實體識別或者用自然語言處理做到。System 1 可以利用知識圖譜或 BERT、通過 Quality 咖啡館自動做擴展，如說我們可以找到 old school 和 Gone in 60 seconds 這兩部電影。然後 System 2 在這上面來做決策。old school 是我們要的答案嗎？Gone in 60 seconds 是我們要的答案嗎？如果不是，System 2 就考慮要不要把信息回放到 System 1 中，給 System 1 做擴展。System 1 可能繼續做擴展，比如 old school 是 Todd Phillips 導演的，System 2 對此進一步做決策說 Todd Phillips 就是要找的，於是分析就停止了。這就是一個基本的認知圖譜的思想。<br>最後怎麼實現呢？對於 System 1，我們剛才說做擴展，如果我們回到深度學習，這就跟 Yoshua Bengio 的思路基本上結合起來了。System 1 還可以用表示學習的各種方法，如可以用 BERT、ProNE、NetFM 甚至 DeepWalk 等方法。我們可以做一個簡單的相似度的擴展，於是我們就有了 System 1。<br>System 1 是做知識的擴展，System 2 是做決策和推理的。對 System 2 該怎處理呢？我們把 System 2 做成下圖所示的樣子。System 2 裡面核心的東西有一個推理和決策功能，於是我們就用卷積神經網絡或者圖神經網絡來實現。這裡面相當於匯聚了所有的信息，它把 System 1 中的拿出來的各種信息匯聚過來，判斷這個是不是我需要的答案，最後做決策。於是我們就把兩個神經網絡系統給整合到一起了，我們把它叫做認知圖譜（Cognitive Graph）。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dc7116437a04425ca05d4a312b634765><p class=pgc-img-caption></p></div><p><br></p><p>在具體實現方面，System 1 可以用 BERT 做幾個 top-k 的 negative threshold 的相似度的查找，如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/b5b0f178ed624928ade288a75d05c625><p class=pgc-img-caption></p></div><p><br></p><p>找到以後，我們把它作為 Cognitive Graph 拿給 System 2 來做決策。System 2 就相當於做直接做一個 prediction，相當於學一個 prediction 的模型。用 GNN 直接來做預測。如果是答案就結束，如果不是答案，但是有用，就把它交給 System 1 來接著做。具體結構如下圖所示。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2076006438de460ea76cc9389104e0c7><p class=pgc-img-caption></p></div><p><br></p><p>以上就是一個基本的思路。<br>後來我們在去年的時候去參加了 SQuAD 的 HotpotQA 的一個多跳的競賽。就在這個競賽中，當時我們一下子拿到了第 1 名，而且在第 1 名的位置上保持了三個月。大家可以看一下下圖這個結果可以發現更有意思的事：CogQA（CogGraph）的結果比當時的 BERT 好 50%。CogQA 可以做到 49%，而當時的 BERT 在 F1 值上最好的結果是 31%。更優美的是它給出了一個很強的可解釋性，我前面介紹了可解釋性非常重要，尤其是在多跳的情況下。首先，對多跳的效果的提升是很明顯的，如 hop 跳得如果越高的話，即跳出越多的話，CogQA 的結果就明顯的比原來的方法要好得多。其次，它的可解釋性非常強。比如我給你一個答案，這個答案是 40，如下圖左下角所示。這個事實大家可以看到，而我可以告訴你為什麼能拿到 40。我是先找到這 Ken Pruitt，然後再找到 Florida Senate，最後找到 40。這裡有一個可解釋、可追溯的這麼一個結果，一下就把可解釋性大幅提高。它甚至可以從本質上幫助機器學習。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9cad943dae344c589b2d2e4595f37405><p class=pgc-img-caption></p></div><p><br></p><p>機器學習原來是依靠某個信息做預測，這個時候可能沒有擴展的信息，而依靠認知圖譜，可以用 system 1 擴展出來新的信息，如果拓展的信息精度不夠高，還可以通過做一層推理給出更多的信息，這個時候機器學習系統可以結合更多的信息再來做預測，這可能又進一步提高了效果。當機器學習系統做了一個錯誤的預測以後，認知圖譜還可以回溯錯誤是怎麼產生的。這個方面有很多相關的應用。<br>有人可能會說，這個是不是隻能做問答？不是的，它既可以做問答，也可以做知識圖譜的補齊，下圖左邊是一個知識圖譜，右邊是基於剛才的模型來做知識圖譜的一個補齊，這是一個基本的一個思路。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d8d59b4b939b43ff903e9d8656558991><p class=pgc-img-caption></p></div><p><br></p><p>這就是認知圖譜怎麼和推理結合在一起。</p><p><br></p><p><strong>GNN 的挑戰與未來</strong></p><p>未來我們有很多挑戰，但是也有很多機遇。</p><p><br></p><p>張鈸院士在 2015 年提出人工智能基本上在做兩件事。</p><p><br></p><p>第一件事：<strong>做知識的表示和知識的推理。</strong>其實知識表示和知識推理在 20 世紀 50 年代第一個人工智能時代就已經有了。當時的推理就已經很先進了。但是一直沒有發展起來，一個原因就是規模小，另一個原因是固定、死板，不能自學習。這跟當時的計算機計算能力差、缺乏大規模的數據有關係。</p><p><br></p><p>第二件事：<strong>第二波人工智能浪潮的興起是機器學習驅動的，第三波人工智能浪潮（也就是這一次人工智能浪潮）是依靠深度學習把整個基於學習的人工智能推向了一個頂峰，所以我說這是一個感知時代的頂峰</strong>。</p><p><strong>現在人工智能最大的問題缺乏可解釋性，而且缺乏健壯性</strong>。我剛才講了，存在一個噪聲可能就會導致整個網絡的表示學習的結果就不行了，甚至缺乏這種可信的結果和可擴展的結果。這些方面都需要我們做進一步的研究，所以當時張院士就提出要做第三代人工智能。DARPA 在 2017 年也做了 XAI 項目，提出一定要做可解釋性的機器學習。<br>2018 年，清華大學正式提出第三代人工智能的理論框架體系：<strong>（1）建立可解釋、健壯性的人工智能理論和方法。（2）發展安全、可靠、可信及可擴展的人工智能技術。（3）推動人工智能創新應用。</strong></p><p><br></p><p><br>結合剛才講到的內容，我認為：（1）數據和知識的融合是非常關鍵的，我們要考慮怎麼把知識融合到數據裡面。（2）我們怎麼跟腦科學、腦啟發、腦認知的方法結合起來。所以剛才我拋磚引玉給了一個思想，即我們用認知圖譜這種思想，可能可以把人的常識知識和一些推理邏輯結合到深度學習中，甚至可以把一些知識的表示也結合到裡面。這樣的話“認知+推理”就是未來。這裡面還有一個核心的基石：要<strong>建造萬億級的常識知識圖譜</strong>，這是我們必須要做的。這裡面路還非常遠，我也非常歡迎大家一起加入來做這方面的研究和探討。<br>這裡面再次拋磚引玉，提一下幾個相關的研究。（1）在推理方面有幾個相關的工作，如 DeepMind 的 graph_net 就把關係融合到網絡表示中，在網絡表示學習中發揮一定的作用。（2）最近的一篇文章把知識圖譜融合到了 BERT 中，這樣的話知識圖譜中就有了與 BERT 相關的一些東西，可以用這種知識圖譜來幫助 BERT 的預訓練。當然，我不是說它是最好的，但它們都提出了一個思路，講到了怎麼把表示學習和 GNN 結合起來，這是很重要的一些事情。<br>下圖列出了一些相關的論文，還有一兩篇是我們沒有發表的文章，包括剛才說的 Signal Rescaling，其實我們在那篇文章裡面做了很多數學分析。</p><p><br></p><div class=pgc-img><img alt="認知推理：從圖表式學習和圖神經網絡的最新理論來看AI 的未來" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8b08d4d10d4f42a58862074e668a81f6><p class=pgc-img-caption></p></div><p><br></p><p>總的來講，<strong>未來的 GNN 一定是面向推理、面向認知的</strong>。我們在感知時代、網絡時代裡面做了很多網絡表示，如 GCN、GNN 等，還有一些把知識結合了起來，但是<strong>下一步我們怎麼做推理（reasoning）、規劃（planning）、邏輯（logical）的這種表示，甚至人的這種表示</strong>？這是一個很大的問題。人工智能終極目的就是讓計算機能夠像人一樣互相的表示，所以這也是未來非常重要的研究方向。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>認知</a></li><li><a>圖表式</a></li><li><a>學習</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html alt=直流鍋爐給水控制學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/eba10edcc8d14d9f8cde6fd5b212d90e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html title=直流鍋爐給水控制學習>直流鍋爐給水控制學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html alt=HTMLCSS學習筆記（六）——元素類型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb5988349894ce9bf568c6418f85b7d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html title=HTMLCSS學習筆記（六）——元素類型>HTMLCSS學習筆記（六）——元素類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html alt="web前端（從零開始），每天更新學習筆記 HTML5元素分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/46d70004fcd55e1ddad3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html title="web前端（從零開始），每天更新學習筆記 HTML5元素分類">web前端（從零開始），每天更新學習筆記 HTML5元素分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html alt="MySQL 學習筆記" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html title="MySQL 學習筆記">MySQL 學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html alt=深入學習MySQL事務：ACID特性的實現原理「轉」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/cdc702d66d6943499997d11e931425eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html title=深入學習MySQL事務：ACID特性的實現原理「轉」>深入學習MySQL事務：ACID特性的實現原理「轉」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html alt=如何學習模擬IC設計？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html title=如何學習模擬IC設計？>如何學習模擬IC設計？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html alt=小猿圈python學習-三大特性之多態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad0e8e3777854337abeb7c779ad79a04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html title=小猿圈python學習-三大特性之多態>小猿圈python學習-三大特性之多態</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html alt=地理學習5——地球的運動（地球的公轉及其地理意義） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7b2b74c871eb40beb8ee143627d29611 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html title=地理學習5——地球的運動（地球的公轉及其地理意義）>地理學習5——地球的運動（地球的公轉及其地理意義）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html alt=繼續學習打卡，還真心學不會了，努力，堅持 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f36d6d47a06840aaaf78138853b9d9d1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html title=繼續學習打卡，還真心學不會了，努力，堅持>繼續學習打卡，還真心學不會了，努力，堅持</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html alt=一造學習筆記—管理篇（2）：工程造價管理的組織和內容 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/9e65b076-038f-4720-96ff-182898f42dee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html title=一造學習筆記—管理篇（2）：工程造價管理的組織和內容>一造學習筆記—管理篇（2）：工程造價管理的組織和內容</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>