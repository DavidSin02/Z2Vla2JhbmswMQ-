<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>自動駕駛中車輛的如何使用點雲定位？ | 极客快訊</title><meta property="og:title" content="自動駕駛中車輛的如何使用點雲定位？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/56a108f6423b4886bade22f016a2053c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/90d2a289.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/90d2a289.html><meta property="article:published_time" content="2020-11-14T20:51:07+08:00"><meta property="article:modified_time" content="2020-11-14T20:51:07+08:00"><meta name=Keywords content><meta name=description content="自動駕駛中車輛的如何使用點雲定位？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/90d2a289.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>自動駕駛中車輛的如何使用點雲定位？</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><p>以下文章來源於點雲PCL ，作者dianyunPCL</p><div class=pgc-img><img alt=自動駕駛中車輛的如何使用點雲定位？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/56a108f6423b4886bade22f016a2053c><p class=pgc-img-caption></p></div><p><strong>點雲</strong><strong>PCL</strong></p><p>公眾號將會推送基於PCL庫的點雲處理，SLAM，三維視覺，高精地圖相關的文章。公眾號致力於理解三維世界相關內容的乾貨分享。不僅組織技術交流群，而且組建github組群，有興趣的小夥伴們可以自由的分享。歡迎關注參與交流或分享。</p><div class=pgc-img><img alt=自動駕駛中車輛的如何使用點雲定位？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d158c21f818e40fe8106cbc7be361a0b><p class=pgc-img-caption></p></div><p>激光雷達傳感器能夠獲取豐富，稠密且精確的三維空間中物體的點雲數據，這可以幫助自動駕駛車輛實現定位和障礙物的跟蹤，lidar也將成為實現完全自動駕駛的核心傳感器。本篇文章將主要介紹三維激光雷達在自動駕駛定位領域最新的研究，並分析各種方法的定位的效果。</p><p style=text-align:justify>本文來源：點雲PCL</p><p style=text-align:justify><br></p><p style=text-align:center><strong>01. 介紹</strong></p><p><br></p><p>自動駕駛的定位意味著能夠在地圖中找到車輛的位置和方向。這裡的地圖也是隻使用激光雷達獲取的，使用激光束獲取測量的距離併產生點雲數據，其中的每個點表示傳感器獲取的物體表面的（XYZ）的座標。基於點雲的高精地圖是可以通過lidar掃描離線的構建出來，也可以在導航過程中通過里程計實現閉環的構建地圖，也就是SLAM系統。</p><p><br></p><p>這裡首先分析使用激光雷達的點雲數據作為定位的優缺點，與圖像或其他傳感器相比。</p><p><br></p><ol start=1><li>lidar數據能夠在獲取更為豐富且精確的空間信息，這也使得車輛在定位中更為有優勢。</li><li>由於激光雷達的數據不斷的下降，這使傳感器更易於大眾使用和研究，並且對於汽車廠商來說也逐漸被接受。</li></ol><p><br></p><p>但是使用3D lidar作為定位設備通常也會有一些問題，由於lidars數據數量巨大，因此需要快速處理輸出並確保系統的實時性，所以確保車輛的實時定位具有一定的挑戰和難度。所以通常需要使用下采樣或者特徵點提取的方法來高效的簡化點雲信息。</p><p><br></p><p>我們知道在車輛的實時定位系統中生成里程計是必不可少的部分，在過去的研究中，已經提出了很多的使用lidar的點雲數據來計算車輛的里程計的方法，這些方法中主要有三個不同的類別：</p><p><br></p><p>（1）基於點雲數據的配準方法[1]：這是一種很好的離線的構建高精地圖的方法，這種方法由於太慢而無法實時的處理，因為該方法考慮了lidar點雲數據中的所有點進行配準，可以將這種方法歸納為稠密的方法。</p><p><br></p><p>（2）基於點雲特徵點的方法：受2D圖像特徵提取和匹配方法的啟發[2,3,4]，根據3D點雲的特徵點的提取，計算連續幀之間的位移，這種方法的準確性和實時處理還是可以的，但是對快速運動不夠魯棒。這種方法僅僅使用了點雲中提取的特徵點來代表一幀的點雲數據進行配準，可以歸納為稀疏的方法。</p><p><br></p><p>（3）基於點雲數據的深度學習的方法：深度學習在決定車輛的定位問題上的研究獲得越來越多的研究。在[5,6,7,8]文章中首先使用2D的圖像來預測和計算里程計，並且最終的定位效果還是可以接受的。但仍不能超過現有的技術水平。</p><p><br></p><p>最近很多的工作正在探索使用lidar點雲數據，而結果上提有著很好的效果。接下來講介紹各種點雲定位技術對比和測試結果。</p><p><br></p><p><strong>02. 自動駕駛車輛的3D激光雷達定位</strong></p><p><br></p><p>首先回顧和討論文獻中可用的所有方法，在這些文獻中，僅使用3D LIDAR傳感器即可實現對車輛的3D定位。我們將可用方法分為三類（點雲配準，3D特徵點匹配法和深度學習的方法），並在下表中列出了它們。並在接下來的閱讀中細細介紹。</p><p><br></p><div class=pgc-img><img alt=自動駕駛中車輛的如何使用點雲定位？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/94997e4701c24fd8b61531da7f6efd35><p class=pgc-img-caption></p></div><p><br></p><p><strong>1.1 3D點雲配準方法</strong></p><p><br></p><p>這裡主要回顧基於3d 點雲的配準的定位方法，配準的目的是實現一對點雲能夠對齊在同一座標系下，從而可以計算出兩次掃描之間的點雲的變換，在自動駕駛定位場景下，可以通過兩種方法使用配準的方法：</p><p><br></p><p>（1）通過將獲取的掃描幀點雲與預構建的高精點雲地圖的一部分進行配準，對車輛進行定位。</p><p>（2）通過連續的Lidar掃描獲取的點雲計算出車輛的里程計信息。</p><p><br></p><p><strong>點雲配準主要用於形狀對齊和場景重建等領域，其中迭代最近點算法（ICP）是最受歡迎的算法之一</strong>，在ICP中通過最小化點雲數據之間的度量誤差來優化源點雲和目標點雲之間的轉換。並在該研究領域有多種ICP算法的變種【47】，常見的變種算法有點到線段的ICP[48],點到面的ICP[49]以及通用的ICP[10],ICP算法可以認為是解決點雲配準的經典算法，在文章【11】中將點雲配準和迴環檢測以及車輛位姿圖的優化結果在一起，以減少連續配準帶來的累計誤差。</p><p><br></p><p>在論文【50】中提出了一種計算里程計並整合雷達傳感器數據的特徵來改善ICP算法，這是一種通過對點雲的下采樣和點雲數據的幾何性質抑制點雲匹配的ICP算法，作者在KITTI數據集上的里程計漂移下降了27%,但是ICP算法最終被3D正態分佈（NDT）算法所超越【14】【51】3DNDT算法其實是一種將2D NDT算法的擴展到三維空間的算法，與ICP算法類似的是源點雲和目標點雲質檢的轉換也需要進行迭代和優化，但是這種方法的優化的誤差方程不在點對之間，而在根據預先計算的體素中存在的點的均值和協方差，<strong>NDT首先將點雲轉換為概率密度函數（PDF），然後將概率密度函數與高斯牛頓算法結合優化</strong>，找到兩點雲之間的空間變換，在【52】中提出了對3D NDT算法的擴展並命名為概率NDT算法，該算法嘗試解決經典的NDT算法的稀疏性。這種不再給予點的數量而是概率的點的概率的方法能夠獲取LIDAR數據之間的轉換關係，但是在自動駕駛中，這種方法很少能夠滿足實時運行計算的要求。所以一般會加入一下輔助的傳感器，比如IMU，作為初始的定位值。</p><p><br></p><p><strong>在IMLS-SLAM[20]算法中提出了</strong><strong>三部</strong><strong>算法：</strong></p><p><br></p><p>（1）首先是動態對象的刪除，該動態對象通過對掃描幀點雲數據的聚類獲取再刪除。</p><p>（2）對於刪除動態障礙物的剩餘點雲進行下采樣，</p><p>（3）最後是匹配步驟，通過掃描到模型的匹配策略，使用隱式最小移動法（IMLS）計算和優化轉換關係.</p><p><br></p><p>另外一種流行的處理方法是計算點雲的surfel（SURFace ELement）文章【24】構建點雲的surel貼圖，構建的貼圖和法線貼圖可用於ICP算法來計算車輛的里程計，並通過surfel實現迴環檢測和軌跡優化。在文章[38]中，通過以下步驟將激光雷達掃描轉換為線點雲：從相鄰環的相鄰點之間採樣線段。然後使用迭代方法將這些線點雲對齊：首先，計算生成的線的中心點。然後，通過在目標點雲中找到中心距源點雲中最近的線，將這些點用於查找連續掃描之間的轉換。然後使用其他後期處理技巧來提高準確性，例如使用以前的變換來預測和初始化下一個姿勢估計步驟。有時，減小LIDAR數據的維數也可以產生合理的結果，例如在[40]中，將傳入的掃描數據投影到具有佔用柵格和高度的2.5D網格圖上。</p><p><br></p><p><strong>1.2 基於3D特徵的定位方法</strong></p><p><br></p><p>3D的點雲特徵有【55】【56】【57】是代表在時間和空間上具有一致性的可識別區域的興趣點，這些特徵點通常用於3D的對象檢測使用特徵描述子作為唯一的向量表示法，並且描述子可以用於匹配兩個不同點雲中的特徵，通過找到足夠且一致的匹配項，再使用優化的方法計算兩次掃描點雲之間的轉換關係。從而能夠構建里程計，在文章【12】中作者提出了一項研究著重於尋找出在自動駕駛實現精確定位的特徵信息，但是由於點簇的分佈由於場景的不同，該方法提取出來的特徵點也是不穩定的，在論文【16】中，提出了PoseMap的方法，作者認為地圖的連續性是實現車輛定位的關鍵，並且預先構建的點雲高精地圖，然後根據重疊閾值對齊進行二次採樣，以生成維持關鍵幀姿態的環境集合，這些子地圖可以在不同的時間點彼此獨立的更新，然後通過簡單的使用兩個與當前車輛最近的子地圖並且最小化舊地圖和和新特徵之間的距離，通過滑動窗口的方法解決定位問題。</p><p><br></p><p>還有論文【21】【22】利用自動駕駛車輛環境中<strong>存在的幾何形狀作為定位的要素</strong>，將平面提取算法與幀與幀之間的技術相結合以產生姿態的估計用於車輛的定位，與通過ICP算法獲得的結果比較平面提取和對齊的方法在準確性和速度上都顯示出了極大的提高。</p><p><br></p><p>目前KITTI里程計排行榜上排名第一的方法[25]，首先根據點的平滑度和遮擋度提取平面和角點要素。這些特徵與後續掃描中的點patch相匹配，然後使用Levenberg-Marquardt方法求解LIDAR運動。正如通常在大多數SLAM流程中所做的那樣，在後臺線程中以比里程計估計更慢的頻率構建地圖，這有助於改善最終定位結果。在文章[26]中提出了對該方法的擴展方法，以提高其速度並保證里程計計算的實時性。主要的改進在於通過消除不可靠的特徵並使用兩次LevenbergMarquardt方法來加快優化步驟，從而充分利用地面的信息。儘管如此，LOAM流程中的主要遺留問題之一是由於累積誤差導致的里程錶漂移。但是，將回環檢測算法加入到流程中是可以解決此問題，如[28]或[27]中所示。</p><p><br></p><p><strong>1.3 基於3D點雲深度學習的定位方法</strong></p><p><br></p><p>深度學習的方法應用在里程計和定位上還是比較新穎的研究方向，但是在深度學習被證明在圖像領域的價值之後，並且像PointNet【60】和PointNet++這樣的方法表明，深度學習的使用將會越來越流行，涉及到深度學習的方法可以嘗試使用原始點雲作為輸入並使用單個網絡直接預測車輛的位移以端到端的方式解決此任務，提出使用深度學習方法解決里程計的方法是論文【13】，為了簡化深度學習的網絡的輸入不是直接對3D點雲進行處理而是將LIDAR點雲投影到2D空間上生成全景的深度圖像，然後將其輸入到卷積網絡中，求解兩個輸入幀之間的旋轉和平移，獲得的結果低於標準，但是確是探索使用深度學習解決此任務的方案。</p><p><br></p><p>全景的深度圖像是lidar數據的一種常見的表示形式，另一種使用深度圖像的方法是DeepPCO【17】將雷達投影生成的全景深度圖分別輸入到兩個卷積網絡中，分別用於計算兩幀之間的旋轉和平移。另外還有將雷達點雲投影到球形座標系下生成兩個新的2D圖像，<strong>分別是定點圖（表示每個點的位置（XYZ）)和發現圖</strong>（表示每個點的法線值），將兩個圖像分別輸入到兩個網絡中，分別是：VertexNet他以定點圖作為輸入，用於預測連續幀之間的轉換，NormalNet以法線圖作為輸入，預測兩者之間的旋轉。</p><p><br></p><p>在[44]中提出了一種稱為CAE-LO的解決方案，其中使用無監督卷積自動編碼器以多尺度方式從LIDAR數據的球形投影中提取特徵。附加的自動編碼器用於生成特徵描述符，然後使用基於RANSAC的幀到幀匹配來匹配點。最後，ICP算法用於完善里程計結果。</p><p><br></p><p>在[29]中，<strong>提出了LORAX算法</strong>。這種方法引入了超點的概念，超點是位於球體內並描述了點雲局部表面的點的子集，這些超點被投影到2D空間上以形成2D深度圖。然後使用一系列測試對這些深度圖進行過濾，僅留下相關的超點，並使用PCA和深度自動編碼器進行編碼。然後，再進行粗配準步驟（其中使用涉及RANSAC算法的迭代方法）之前，根據特徵之間的歐式距離來選擇要匹配的候選對象。作為最後一步，使用ICP算法微調，以提高整個算法結果的準確性。</p><p><br></p><p>在集成一系列的論文[32]，[31]，[33]，[34]後提出SegMap方法[35]的作者探索瞭如何使用簡單的卷積網絡有效地從點雲中提取和編碼片段，用於解決定位和構建地圖相關任務。<strong>這種方法的主要貢獻在於其數據驅動的3D片段描述符</strong>，該描述符是使用由一系列卷積和完全連接的層組成的網絡提取的。使用由兩部分組成的損失函數訓練描述符提取器網絡：分類損失和重建部分。最終，使用k-Nearest Neighbors（k-NN）算法找到提取的片段及其候選對應關係，這使得解決定位任務成為可能。</p><p><br></p><p>當試圖使兩幀點雲之間的運動迴歸時，前面討論的大多數方法都會不可避免地遭受場景中動態對象（汽車，行人等）的影響。已知在場景中刪除動態對象可以改善大多數SLAM流程中的里程計計算結果。但是，以有監督的方式檢測然後從場景中刪除動態對象會帶來額外的複雜性，這可能導致更長的處理時間和不穩定的結果。為了以一種無監督的方式解決這個問題，論文[37]中的作者提出了為動態掩碼預測的任務訓練編碼器-解碼器分支。<strong>這是通過優化幾何一致性損失函數來完成的</strong>，該函數說明了點雲數據的法線可以對幾何一致性進行建模的區域。完整的網絡稱為LO-Net可以通過端對端的方式進行訓練，方法是將幾何一致性損失，里程計迴歸損失和交叉熵損失結合起來以進行正則化。</p><p><br></p><div class=pgc-img><img alt=自動駕駛中車輛的如何使用點雲定位？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a5624799660541acb98aff7c186669c4><p class=pgc-img-caption></p></div><p>在KITTI訓練數據集上的3D深度學習定位方法的比較</p><p><br></p><div class=pgc-img><img alt=自動駕駛中車輛的如何使用點雲定位？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/50ff4b467c544d379c3902d7f3bb9c17><p class=pgc-img-caption></p></div><p>在KITTI測試數據集上3D定位方法的比較。</p><p><br></p><p>有些深度學習方法不是直接使用LIDAR進行定位車輛的，而是嘗試學習常見流程中的錯誤模型。換句話說，深度學習可用於校正已經可用的里程計計算，產生功能強大且靈活的插件模塊。論文[39]的作者建議學習一個偏差校正項，目的是改善以LIDAR數據作為輸入的狀態估計器的結果。高斯模型用於對6個測距誤差進行相互獨立的建模，其精心選擇的輸入特徵集中在受誤差影響最大的3個自由度上。在[41]中，提出了一種更高級的方法，稱為L3-Net，可以將其關聯到偏差校正問題上，因為此處的作者提出了一個嘗試學習殘差項的網絡，而不是預測幀之間的轉換關係。首先提取相關特徵並將其輸入miniPointNet中以生成其相應的特徵描述符。然後構建殘差項，並使用3D卷積神經網絡對其進行正則化。<strong>此外，將RNN分支添加到網絡中，以確保位移預測的時間平滑性。</strong>同一作者在[42]，[43]中提出了一個更完整，更通用的L3-Net變種，並將其命名為DeepICP。在這裡，使用PointNet ++提取特徵，然後使用僅保留最相關特徵的加權層進行過濾。與先前的方法類似，使用miniPointNet結構計算特徵描述符，然後將其反饋到相應的點雲生成層，該層在目標點雲中生成相應的關鍵點。為了使變換的最終值迴歸，將兩個損失函數組合在一起，並對局部相似度和全局幾何約束進行編碼。</p><p><br></p><p><strong>03. 總結</strong></p><p><br></p><p>我們根據先前在KITTI里程計數據集[9]上報告的結果對先前引用的方法進行比較，該基準測試是最流行的用於戶外里程計評估的大型數據集之一：它包含使用Velodyne HDL-64E記錄的22個序列激光雷達掃描儀已經過預處理，以補償車輛的運動。地面真值可用的11個序列，並且是使用高級GPS / INS系統獲得的。儘管LOAM仍然佔據著KITTI排行榜的第一位，但是很明顯，涉及深度學習的方法正變得越來越準確。例如，DeepICP的報告平均結果優於訓練數據集上提出的任何其他方法。但是，我們很難將它們歸類為“最先進”的方法，主要有兩個原因：</p><p><br></p><p>（1）DeepICP報告，配準每對點雲大約需要2秒鐘。這太慢了，以至於不能在現實生活中運行的真正的自動駕駛汽車上使用。</p><p><br></p><p>（2）尚未報告測試數據集上這些方法的結果。在測試數據集上的良好結果將證明這些方法能夠在實際場景中使用，而不僅是在深度神經網絡已經看到的數據上。在此之前，LOAM及其變體仍然是真正的自動駕駛部署的最佳選擇和最可信賴的。</p><p><br></p><p><strong>在本文中，主要回顧，分析，比較和討論了自動駕駛汽車3D LIDAR定位領域中的大多數最新進展和發現。</strong>考慮了使用唯一的傳感器是3D LIDAR的系統，這是由於該傳感器在當今最準確的感知和定位系統中的重要性日益增加，此外，它對大眾和製造商的可用性也有所提高。從論文對KITTI里程計數據集進行比較，得出以下結論：儘管基於深度學習的方法展現出良好的結果，並且似乎代表了未來的研究方向，但是基於3D特徵檢測和匹配的方法由於在現實應用中具有一定的穩定性，仍被認為是最佳且有效的方案。</p><p><br></p><p><strong>參考文獻</strong></p><p><br></p><p>向上滑動閱覽</p><p><br></p><p>[1] G. K. Tam, Z.-Q. Cheng, Y.-K. Lai, F. C. Langbein, Y. Liu, D. Marshall, R. R. Martin, X.-F. Sun, and P. L. Rosin, “Registration of 3d point clouds and meshes: A survey from rigid to nonrigid,” IEEE transactions on visualization and computer graphics, vol. 19, no. 7, pp. 1199–1217, 2012.</p><p>[2] R. Mur-Artal, J. M. M. Montiel, and J. D. Tardos, “Orb-slam: a versatile and accurate monocular slam system,” IEEE transactions on robotics, vol. 31, no. 5, pp. 1147–1163, 2015.</p><p>[3] R. Mur-Artal and J. D. Tard ´os, “Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras,” IEEE Transactions on Robotics, vol. 33, no. 5, pp. 1255–1262, 2017.</p><p>[4] D. Scaramuzza and F. Fraundorfer, “Visual odometry [tutorial],” IEEE robotics & automation magazine, vol. 18, no. 4, pp. 80–92, 2011.</p><p>[5] K. R. Konda and R. Memisevic, “Learning visual odometry with a convolutional network.” in VISAPP (1), 2015, pp. 486–490.</p><p>[6] S. Wang, R. Clark, H. Wen, and N. Trigoni, “Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks,” in 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017, pp. 2043–2050.</p><p>[7] R. Clark, S. Wang, H. Wen, A. Markham, and N. Trigoni, “Vinet: Visual-inertial odometry as a sequence-to-sequence learning problem,” in Thirty-First AAAI Conference on Artificial Intelligence, 2017.</p><p>[8] N. Yang, R. Wang, J. Stuckler, and D. Cremers, “Deep virtual stereo odometry: Leveraging deep depth prediction for monocular direct sparse odometry,” in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 817–833.</p><p>[9] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, “Vision meets robotics: The kitti dataset,” The International Journal of Robotics Research, vol. 32, no. 11, pp. 1231–1237, 2013.</p><p>[10] A. Segal, D. Haehnel, and S. Thrun, “Generalized-icp.” in Robotics: science and systems, vol. 2, no. 4. Seattle, WA, 2009, p. 435.</p><p>[11] E. Mendes, P. Koch, and S. Lacroix, “Icp-based pose-graph slam,” 2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR), pp. 195–200, 2016.</p><p>[12] K. Yoneda, H. T. Niknejad, T. Ogawa, N. Hukuyama, and S. Mita, “Lidar scan feature for localization with highly precise 3-d map,” 2014 IEEE Intelligent Vehicles Symposium Proceedings, pp. 1345– 1350, 2014.</p><p>[13] A. Nicolai, R. Skeele, C. Eriksen, and G. A. Hollinger, “Deep learning for laser based odometry estimation.”</p><p>[14] M. Magnusson, A. Lilienthal, and T. Duckett, “Scan registration for autonomous mining vehicles using 3d-ndt,” Journal of Field Robotics, vol. 24, no. 10, pp. 803–827, 2007.</p><p>[15] B. Zhou, Z. Tang, K. Qian, F. Fang, and X. Ma, “A lidar odometry for outdoor mobile robots using ndt based scan matching in gps-denied environments,” in 2017 IEEE 7th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER). IEEE, 2017, pp. 1230–1235.</p><p>[16] P. Egger, P. V. Borges, G. Catt, A. Pfrunder, R. Siegwart, and R. Dub´e, “Posemap: Lifelong, multi-environment 3d lidar localization,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018, pp. 3430–3437.</p><p>[17] W. Wang, M. R. U. Saputra, P. Zhao, P. Gusmao, B. Yang, C. Chen, A. Markham, and N. Trigoni, “Deeppco: End-to-end point cloud odometry through deep parallel neural network,” arXiv preprint arXiv:1910.11088, 2019.</p><p>[18] Y. Cho, G. Kim, and A. Kim, “Deeplo: Geometry-aware deep lidar odometry,” arXiv preprint arXiv:1902.10562, 2019.</p><p>[19] K. Ji, H. Chen, H. Di, J. Gong, G. Xiong, J. Qi, and T. Yi, “Cpfgslam:a robust simultaneous localization and mapping based on lidar in off-road environment,” in 2018 IEEE Intelligent Vehicles Symposium (IV), June 2018, pp. 650–655.</p><p>[20] J. Deschaud, “IMLS-SLAM: scan-to-model matching based on 3d data,” CoRR, vol. abs/1802.08633, 2018. [Online]. Available: http://arxiv.org/abs/1802.08633</p><p>[21] K. Pathak, A. Birk, N. Vaskevicius, M. Pfingsthorn, S. Schwertfeger, and J. Poppinga, “Online three-dimensional slam by registration of large planar surface segments and closed-form pose-graph relaxation,” Journal of Field Robotics, vol. 27, no. 1, pp. 52–84, 2010.</p><p>[22] W. S. Grant, R. C. Voorhies, and L. Itti, “Finding planes in lidar point clouds for real-time registration,” in 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2013, pp. 4347– 4354. [23] H. Yin, L. Tang, X. Ding, Y. Wang, and R. Xiong, “Locnet: Global localization in 3d point clouds for mobile vehicles,” in 2018 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2018, pp. 728–733.</p><p>[24] J. Behley and C. Stachniss, “Efficient surfel-based slam using 3d laser range data in urban environments.”</p><p>[25] J. Zhang and S. Singh, “Loam: Lidar odometry and mapping in realtime.”</p><p>[26] T. Shan and B. Englot, “Lego-loam: Lightweight and groundoptimized lidar odometry and mapping on variable terrain,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018, pp. 4758–4765.</p><p>[27] X. Ji, L. Zuo, C. Zhang, and Y. Liu, “Lloam: Lidar odometry and mapping with loop-closure detection based correction,” in 2019 IEEE International Conference on Mechatronics and Automation (ICMA), Aug 2019, pp. 2475–2480.</p><p>[28] J. Lin and F. Zhang, “A fast, complete, point cloud based loop closure for lidar odometry and mapping,” 09 2019.</p><p>[29] G. Elbaz, T. Avraham, and A. Fischer, “3d point cloud registration for localization using a deep neural network auto-encoder,” in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017, pp. 2472–2481.</p><p>[30] X. Chen, A. M. E. Palazzolo, P. Gigu`ere, J. Behley, and C. Stachniss, “Suma + + : Efficient lidar-based semantic slam,” 2019.</p><p>[31] A. Cramariuc, R. Dub´e, H. Sommer, R. Siegwart, and I. Gilitschenski, “Learning 3d segment descriptors for place recognition,” arXiv preprint arXiv:1804.09270, 2018.</p><p>[32] R. Dube, D. Dugas, E. Stumm, J. Nieto, R. Siegwart, and C. Cadena, “Segmatch: Segment based place recognition in 3d point clouds,” 05 2017, pp. 5266–5272.</p><p>[33] R. Dub´e, M. G. Gollub, H. Sommer, I. Gilitschenski, R. Siegwart, C. Cadena, and J. Nieto, “Incremental-segment-based localization in 3-d point clouds,” IEEE Robotics and Automation Letters, vol. 3, no. 3, pp. 1832–1839, 2018.</p><p>[34] R. Dub, A. Gawel, H. Sommer, J. Nieto, R. Siegwart, and C. Cadena, “An online multi-robot slam system for 3d lidars,” in 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Sep. 2017, pp. 1004–1011.</p><p>[35] R. Dub´e, A. Cramariuc, D. Dugas, J. Nieto, R. Siegwart, and C. Cadena, “Segmap: 3d segment mapping using data-driven descriptors,” arXiv preprint arXiv:1804.09557, 2018.</p><p>[36] C. Park, S. Kim, P. Moghadam, C. Fookes, and S. Sridharan, “Probabilistic surfel fusion for dense lidar mapping,” 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), pp. 2418–2426, 2017.</p><p>[37] Q. Li, S. Chen, C. Wang, X. Li, C. Wen, M. Cheng, and J. Li, “Lo-net: Deep real-time lidar odometry,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 8473–8482. [38] M. Velas, M. Spanel, and A. Herout, “Collar line segments for fast odometry estimation from velodyne point clouds,” 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 4486–4495, 2016.</p><p>[39] T. Tang, D. Yoon, F. Pomerleau, and T. D. Barfoot, “Learning a bias correction for lidar-only motion estimation,” in 2018 15th Conference on Computer and Robot Vision (CRV). IEEE, 2018, pp. 166–173.</p><p>[40] L. Sun, J. Zhao, X. He, and C. Ye, “Dlo: Direct lidar odometry for 2.5 d outdoor environment,” in 2018 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2018, pp. 1–5.</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>自動</a></li><li><a>駕駛中</a></li><li><a>車輛</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/51abe352.html alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/12df25dc0418499f8f6eb033f4074160 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51abe352.html title=視覺交通仿真研究：自動駕駛中的模型，評估和應用>視覺交通仿真研究：自動駕駛中的模型，評估和應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bf43c44e.html alt="混合動力車輛電纜 EMC 測量分析和選擇原則" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9af211de8ada4a13bf7e04b00df176cf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bf43c44e.html title="混合動力車輛電纜 EMC 測量分析和選擇原則">混合動力車輛電纜 EMC 測量分析和選擇原則</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/88ba81f5.html alt=小型履帶車輛的驅動系統--液壓驅動橋，靈活的小胖子 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dc0a73ddaf1b4cd9bdc3ac2ce98084ce style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/88ba81f5.html title=小型履帶車輛的驅動系統--液壓驅動橋，靈活的小胖子>小型履帶車輛的驅動系統--液壓驅動橋，靈活的小胖子</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html alt=方大九鋼檢測部推出生石灰自動取樣器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html title=方大九鋼檢測部推出生石灰自動取樣器>方大九鋼檢測部推出生石灰自動取樣器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html alt=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html title=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好>方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9f355005.html alt=車輛維修導致貶值怎麼辦？記住這點，殘值高5千 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1527060230294e8da57a0ad style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9f355005.html title=車輛維修導致貶值怎麼辦？記住這點，殘值高5千>車輛維修導致貶值怎麼辦？記住這點，殘值高5千</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html alt=excel小技巧：自動求和，當新增數據時自動求和 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523970520159b755ba89ba style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html title=excel小技巧：自動求和，當新增數據時自動求和>excel小技巧：自動求和，當新增數據時自動求和</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html alt=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4e8a4e07bff64e6db5dcef502221fa45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html title=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀>37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html alt=「乾貨」自動噴水滅火系統三大報警閥組原理探索 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/46846030db1d42069626e2365af33521 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html title=「乾貨」自動噴水滅火系統三大報警閥組原理探索>「乾貨」自動噴水滅火系統三大報警閥組原理探索</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html alt=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html title=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求>「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html alt=新版自動噴水滅火系統規範：第六章-報警閥組 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15251639042140ad0c55a7b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html title=新版自動噴水滅火系統規範：第六章-報警閥組>新版自動噴水滅火系統規範：第六章-報警閥組</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html alt=消防自動噴淋糸統的溼式式報警閥組的工作原理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f728f8c921f4740983ffec87a508565 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html title=消防自動噴淋糸統的溼式式報警閥組的工作原理>消防自動噴淋糸統的溼式式報警閥組的工作原理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/830c83f4.html alt=溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/526e34ac258043fe92a9f2f078ea5a6c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/830c83f4.html title=溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！>溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c73c40a0.html alt=自動噴水滅火系統溼式報警閥組成及原理圖 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9ba360b558964895b7024e2057d4d331 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c73c40a0.html title=自動噴水滅火系統溼式報警閥組成及原理圖>自動噴水滅火系統溼式報警閥組成及原理圖</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8caf26ac.html alt=自動噴水滅火系統（8）報警閥組的設置 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/616c3e2a-0421-408e-b7b3-e74d6bcf420f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8caf26ac.html title=自動噴水滅火系統（8）報警閥組的設置>自動噴水滅火系統（8）報警閥組的設置</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>