<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） | 极客快訊</title><meta property="og:title" content="U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/90096e117f23408880d5dc3a760d72f5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/95ed377.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/95ed377.html><meta property="article:published_time" content="2020-10-29T21:03:33+08:00"><meta property="article:modified_time" content="2020-10-29T21:03:33+08:00"><meta name=Keywords content><meta name=description content="U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/95ed377.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文）</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>U-Net:卷積網絡用於生物醫學圖像分割</h1><p><strong>題目：</strong></p><p>U-Net: Convolutional Networks for Biomedical Image Segmentation</p><p><strong>作者：</strong></p><p>Olaf Ronneberger, Philipp Fischer, Thomas Brox</p><p><strong>來源：</strong></p><p>Machine Learning (cs.LG)</p><p>conditionally accepted at MICCAI 2015</p><p>Submitted on 18 May 2015</p><p><strong>文檔鏈接：</strong></p><p>https://arxiv.org/pdf/1505.04597v1.pdf</p><p><strong>代碼鏈接：</strong></p><p>https://github.com/milesial/Pytorch-UNet</p><p>https://github.com/qubvel/segmentation_models</p><p>https://github.com/divamgupta/image-segmentation-keras</p><h1 class=pgc-h-arrow-right>摘要</h1><p>人們普遍認為，深度網絡的成功訓練需要數千個帶註釋的訓練樣本。在本文中，我們提出了一種網絡和訓練策略，它依賴於數據擴充的強大使用，以更有效地使用可用的帶註釋的樣本。該體系結構由捕獲上下文的收縮路徑和支持精確定位的對稱擴展路徑組成。我們證明這樣的網絡可以從非常少的圖像端到端的訓練，並且在ISBI挑戰中在電子顯微鏡棧中神經結構的分割上勝過先前的最佳方法(滑動窗口卷積網絡)。我們使用相同的網絡訓練透射光學顯微鏡圖像(相位對比和DIC)，在2015年ISBI細胞跟蹤挑戰賽中，我們在這些類別中獲得了巨大的優勢。此外，網絡是快速的。在最近的GPU上，512x512圖像的分割需要不到一秒的時間。完整的實現(基於Caffe)和經過培訓的網絡可以在http://lmb.informatik.uni-reiburg.de/people/ronneber/u-net上找到。</p><p><br></p><h1 class=pgc-h-arrow-right>英文原文</h1><p>There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.</p><p><br></p><h1 class=pgc-h-arrow-right>要點</h1><p><br></p><p><strong>背景</strong></p><p><br></p><p>2012年Ciresan等人[1]在滑動窗口設置中訓練一個網絡，通過提供一個圍繞該像素的局部區域(patch)來預測每個像素的類標籤輸出。首先，這個網絡可以本地化。其次，以patch表示的訓練數據遠遠大於訓練圖像的數量。由此產生的網絡在2012年ISBI會議上以較大優勢贏得了EM細分挑戰。</p><p><strong>發現問題</strong></p><p>顯然，Ciresan等人的[1]策略有<strong>兩個缺點</strong>。首先，它非常慢，因為每個補丁都必須單獨運行網絡，而且由於重疊的補丁存在大量冗餘。其次，本地化的準確性和上下文的使用之間存在權衡。更大的補丁需要更多的最大池化層，這會降低定位精度，而小的補丁只允許網絡看到很少的上下文。最近的一些方法[11,4]提出了一種考慮多層特徵的分類器輸出。好的本地化和上下文的使用是可以同時進行的。</p><p><strong>U-Net簡介</strong></p><p>在本文中，我們構建了一個更優雅的架構，即所謂的全卷積網絡[9]。我們修改和擴展了這個架構，使它工作在非常少的訓練圖像和產生更精確的分割;參見圖1。[9]的主要思想是通過連續層來補充通常的收縮網絡，其中池操作符被上採樣操作符取代。因此，這些層增加了輸出的分辨率。為了進行局部化，收縮路徑的高分辨率特徵與上採樣輸出相結合。然後，一個連續的卷積層可以學習根據這些信息組裝一個更精確的輸出。</p><div class=pgc-img><img alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/90096e117f23408880d5dc3a760d72f5><p class=pgc-img-caption></p></div><p>我們架構中的一個重要修改是，在上採樣部分，我們還有大量的特徵通道，這些通道允許網絡將上下文信息傳播到更高分辨率的層。因此，擴展路徑或多或少與收縮路徑對稱，併產生一個u型架構。網絡沒有任何完全連接的層，只使用每個卷積的有效部分，即。，則分割地圖只包含在輸入圖像中提供完整上下文的像素。該策略允許通過重疊策略對任意大的圖像進行無縫分割(見圖2)。為了預測圖像邊界區域的像素，通過鏡像輸入圖像來推斷缺失的上下文。這種平鋪策略對於將網絡應用於大型圖像非常重要，否則分辨率將受到GPU內存的限制。</p><div class=pgc-img><img alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/7d76514a63ab4ed3b9330d7466af051a><p class=pgc-img-caption></p></div><p><br></p><h1 class=pgc-h-arrow-right>實驗</h1><p><br></p><p><strong>數據擴增處理：</strong></p><p>當只有很少的訓練樣本可用時，數據擴充是向網絡傳授所需的不變性和魯棒性的關鍵。對於顯微鏡下的圖像，我們首先需要的是<strong>平移</strong>和<strong>旋轉</strong>的不變性，以及對<strong>變形</strong>和<strong>灰度值變化</strong>的魯棒性。特別是訓練樣本的隨機彈性變形似乎是訓練帶有少量註釋圖像的分割網絡的關鍵概念。我們使用隨機位移矢量在粗糙的3×3網格上生成平滑變形。位移採樣的高斯分佈與10像素的標準差。然後使用雙三次插值計算每個像素的位移。收縮路徑末端的退出層執行進一步的隱式數據擴充。</p><p><br></p><p><strong>數據集：</strong></p><p><strong>來源：</strong>數據集是由EM分割挑戰提供的，該挑戰始於2012年ISBI會議。</p><p><strong>任務：</strong>電子顯微記錄中神經元結構的分割。訓練數據是一組30張果蠅一齡幼蟲腹神經索(VNC)連續切片透射電鏡圖像(512x512像素)。每個圖像都配有相應的完全註釋的細胞(白色)和細胞膜(黑色)的地面真相分割地圖。</p><p><strong>評估：</strong>測試集是公開的，但其分割地圖是保密的。通過將預測的膜概率圖發送給組織者，可以得到評價。評估是通過在10個不同的水平上對地圖進行閾值化，並計算<strong>翹曲誤差</strong>、Rand誤差和<strong>像素誤差</strong>[14]來完成的。。</p><p><br></p><p><strong>實驗結果：</strong></p><p>u-net(平均超過7個旋轉版本的輸入數據)在沒有進一步預處理或後處理的情況下獲得了0.0003529的翹曲誤差(新的最佳值，見表1)和0.0382的隨機誤差。</p><p><strong>各模型在各數據集上的性能評價指標結果：</strong></p><div class=pgc-img><img alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3f914552722e40bf9e9712a3f21a0029><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4442c63fa6b14ad483736dca65cc4685><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cb1fe280c82b43ca8063e974e1023943><p class=pgc-img-caption></p></div><p><br></p><h1 class=pgc-h-arrow-right>結論</h1><p>U-Net架構在非常不同的生物醫學分割應用上取得了非常好的性能。由於數據擴充與彈性變形，它只需要非常少的註釋圖像，並有一個非常合理的訓練時間只有10小時，在NVidia Titan GPU (6GB)。我們提供完整的基於[6]的實現和訓練有素的網絡。我們確信U-Net體系結構可以很容易地應用於更多的任務。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Net</a></li><li><a>卷積</a></li><li><a>網絡用</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/e6e28dd8.html alt=時域卷積網絡TCN詳解：使用卷積進行序列建模和預測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d7a0cea6243e43c4bf1756bbc29f76c2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e6e28dd8.html title=時域卷積網絡TCN詳解：使用卷積進行序列建模和預測>時域卷積網絡TCN詳解：使用卷積進行序列建模和預測</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0379bcd1.html alt=那些英文中常見的【網絡用語縮寫】都是啥意思？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ae1605a729d94cd0b787d6f77a0022ee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0379bcd1.html title=那些英文中常見的【網絡用語縮寫】都是啥意思？>那些英文中常見的【網絡用語縮寫】都是啥意思？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fae72201.html alt=".Net Core 3.0 IdentityServer4 快速入門" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f15647f0f33b4702bceef5e2365bb375 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fae72201.html title=".Net Core 3.0 IdentityServer4 快速入門">.Net Core 3.0 IdentityServer4 快速入門</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/23830dc1.html alt=".Net零基礎破解教程 —— 第二課（獲得註冊碼）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/32ef6e163f064d13806698d45a73b14c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/23830dc1.html title=".Net零基礎破解教程 —— 第二課（獲得註冊碼）">.Net零基礎破解教程 —— 第二課（獲得註冊碼）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/372c161.html alt=用於圖像降噪的卷積自編碼器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/449c17c702f54ceca0b90a4ddcc4a0bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/372c161.html title=用於圖像降噪的卷積自編碼器>用於圖像降噪的卷積自編碼器</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/915b745.html alt=深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1528704399761722b85d065 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/915b745.html title=深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索>深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/62e8881.html alt=拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/feef6487a74040428c66119cc454abae style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/62e8881.html title=拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界>拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>