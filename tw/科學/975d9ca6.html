<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Petuum提出新型正則化方法：非重疊促進型變量選擇 | 极客快訊</title><meta property="og:title" content="Petuum提出新型正則化方法：非重疊促進型變量選擇 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/1531883438038916a224afa"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/975d9ca6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/975d9ca6.html><meta property="article:published_time" content="2020-11-14T20:57:31+08:00"><meta property="article:modified_time" content="2020-11-14T20:57:31+08:00"><meta name=Keywords content><meta name=description content="Petuum提出新型正則化方法：非重疊促進型變量選擇"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/975d9ca6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Petuum提出新型正則化方法：非重疊促進型變量選擇</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><p><strong>選自arXiv，作者：John Olafenwa，機器之心編譯，參與：Geek AI、路。</strong></p><blockquote><p>第 35 屆國際機器學習會議（ICML 2018）正在瑞典斯德哥爾摩舉行。人工智能創業公司 Petuum 共有 5 篇論文入選，包含門控規劃網絡、變換自迴歸網絡和無限可微分蒙特卡羅估計器等研究。本文將摘要介紹其中一篇論文《Nonoverlap-Promoting Variable Selection》，其中提出了一種有效的新型正則化方法，能夠促進變量選擇中的非重疊效應。</p></blockquote><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1531883438038916a224afa><p class=pgc-img-caption></p></div><p>在評估模型質量的各種指標中，有兩個比較常用：（1）在未曾見過的數據上的預測準確度；（2）對模型的解釋。對於（2），科學家更喜歡更簡單的模型，因為響應和協變量之間的關係更清晰。當預測量（predictor）的數量很大時，簡約性問題就會變得尤其重要。當預測量的數量很大時，我們往往希望確定出一個能展現最強效果的小子集。</p><p>為了能在選擇出重要因素的一個子集的同時得到準確的預測，研究者常常使用基於正則化的變量選擇方法。其中最值得提及的是 L1 正則化（Tibshirani, 1996），這能促進模型係數變得稀疏。其變體包括 L1/L2 範數（Yuan & Lin, 2006），其中引入了組稀疏效應（group sparsity effect）和彈性網絡（elastic net）（Zou & Hastie, 2005），這能強烈地促進大量預測量中互相相關的預測量共同進入或離開模型。</p><p>在很多機器學習問題中，都可以基於同一個協變量集預測出多種響應。比如，在多任務分類任務中，具有 m 個類別的分類器建立在一個共享的特徵集之上，而且每個分類器都有一個類別特定的係數向量。在主題建模任務（Blei et al., 2003）中，可以在同一個詞彙庫上學習到多個主題，並且每個主題都有一個基於詞的特有多項式分佈。不同的響應與協變量的不同子集相關。比如，教育主題會與「學生」、「大學」和「教授」等詞相關，而政治主題則會與「政府」、「總統」和「選舉」等詞相關。為了在執行變量選擇時考慮到不同響應之間的差異，我們希望為不同響應選出的變量之間的重疊更少。</p><p>這個問題可用以下數學形式描述。設有 m 個響應共享 d 個協變量。每個響應都有一個特定的 d 維權重向量 w，其中每一維都對應於一個協變量。設</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153188341860497fe5216bf><p class=pgc-img-caption></p></div><p>為 w 的支撐集，索引了一個響應的所選變量。對於任意兩個響應 i 和 j，我們希望它們的所選變量 s(wi) 和 s(wj) 有更少的重疊，其重疊度的衡量方式為</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/153188341852993b2b8d1f3><p class=pgc-img-caption></p></div><p>。為了達到這個效果，我們提出了一種正則化器（regularizer），可同時促進不同的權重向量接近正交且每個向量變得稀疏，這能聯合促使向量的支撐集的重疊更小。我們也通過實驗表明：最小化該正則化器能夠降低所選變量之間的重疊。</p><p>這項研究工作的主要貢獻包括：</p><ul><li>我們提出了一種新型正則化方法，能夠促進變量選擇中的非重疊效應。</li><li>我們將新提出的正則化器應用在了 4 種模型上：多類 logistic 迴歸、距離度量學習、稀疏編碼和深度神經網絡。</li><li>我們導出了求解這些正則化問題的有效算法。尤其值得提及的是，我們為正則化稀疏編碼開發了一種基於 ADMM 和座標下降（coordinate descent）的算法。</li><li>我們分析了新提出的正則化器能提升泛化性能的原因。</li><li>我們通過實驗表明了這種正則化器的實際有效性。</li></ul><p><strong>方法</strong></p><p>在這一節，我們提出了一種非重疊促進型正則化器，並將其應用在了 4 種機器學習模型上。</p><p><strong>1 非重疊促進型正則化</strong></p><p>我們假設模型有 m 個響應，其中每一個都使用一個權重向量進行了參數化。對於向量 w，其支撐集 s(w) 定義為</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153188341862684903229a6><p class=pgc-img-caption></p></div><p>——w 中非零項的索引。而且這個支撐集包含所選變量的索引。我們首先定義一個分數</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153188341857308d9c01802><p class=pgc-img-caption></p></div><p>來衡量兩個響應的所選變量之間的重疊程度：</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531883418623bb5199daf8><p class=pgc-img-caption></p></div><p>這是支撐集的 Jaccard 指數。越小，則兩個所選變量的集合之間的重疊程度就越低。對於 m 個變量集，重疊分數則定義為各對分數之和：</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1531883418571bb05046a8d><p class=pgc-img-caption></p></div><p>這個分數函數不是平滑的，如果被用作正則化器會很難優化。我們則根據</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1531883418772b1fe0dfebb><p class=pgc-img-caption></p></div><p>提出了一個平滑的函數，並且可以實現與 o(W) 相近的效果。其基本思想是：為了促進重疊較小，我們可以讓（1）每個向量有少量非零項，（2）向量之間的支撐集的交集較小。為了實現（1），我們使用一個 L1 正則化器來促使向量變得稀疏。為了實現（2），我們促使向量接近正交狀態。對於兩個稀疏向量，如果它們接近正交，那麼它們的支撐集將會落在不同的位置。這樣能讓支撐集的交集較小。</p><p>我們遵循了（Xie et al., 2017b）提出的方法來促進正交性。為了讓兩個向量 wi 和 wj 接近正交，可讓它們的 L2 範數</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883418880f2e7d3d66f><p class=pgc-img-caption></p></div><p>、</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153188341881354725f37dc><p class=pgc-img-caption></p></div><p>接近 1，讓它們的內積</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/153188341891108b8f44608><p class=pgc-img-caption></p></div><p>接近 0。基於此，就可通過促使這些向量的 Gram 矩陣</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531883418902e0732242ff><p class=pgc-img-caption></p></div><p>接近於一個單位矩陣 I 來促進一組向量之間的正交性。因為 G 和 I 各自的對角線上沒有了</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15318834189603e45e20f9e><p class=pgc-img-caption></p></div><p>和 0，而分別是</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883419095612455b5cc><p class=pgc-img-caption></p></div><p>和 1，所以要讓 G 接近 I，本質上就是讓</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15318834189603e45e20f9e><p class=pgc-img-caption></p></div><p>接近 0，讓</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883419095612455b5cc><p class=pgc-img-caption></p></div><p>接近 1。由此，就促使 wi 和 wj 接近正交了。（Xie et al., 2017b）提出的一種用於衡量兩個矩陣之間的「接近度」的方法是使用對數行列式散度（LDD：log-determinant divergence）（Kulis et al., 2009）。兩個 m×m 正定矩陣 X 和 Y 之間的 LDD 定義為</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15318834190449bb23c1801><p class=pgc-img-caption></p></div><p>，其中 tr(·) 表示矩陣的跡。G 和 I 之間的接近度可以通過讓它們的 LDD</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883419122d6cc658190><p class=pgc-img-caption></p></div><p>更小來得到。</p><p>將正交促進型 LDD 正則化器與稀疏度促進型 L1 正則化器組合到一起，我們就得到了以下 LDD-L1 正則化器：</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15318834191416aa2e4a350><p class=pgc-img-caption></p></div><p>其中 γ 是這兩個正則化器之間的權衡參數。我們的實驗已經驗證，這種正則化器可以有效地促進非重疊。對（3）式和（2）式之間的關係的形式分析留待未來研究。值得提及的是，單獨使用 L1 或 LDD 都不足以降低重疊。如圖 1 所示，其中 (a) 是僅使用了 L1 的情況——儘管這兩個向量是稀疏的，但它們的支撐集完全重疊。在 (b) 中僅使用了 LDD——儘管這兩個向量非常接近正交，但因為它們是密集的，所以它們的支撐集完全重疊。(c) 中則使用了 LDD-L1 正則化器，這兩個向量是稀疏的且接近正交。因此，它們的支撐集不重疊。</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15318834191740d5167b6e0><p class=pgc-img-caption></p></div><p>圖 1：(a) 使用 L1 正則化的情況，向量是稀疏的但它們的支撐集重疊；(b) 使用 LDD 正則化的情況，向量是正交的但它們的支撐集重疊；(c) 使用 LDD-L1 正則化的情況，向量稀疏且互相正交，它們的支撐集不重疊。</p><p><strong>2 案例研究</strong></p><p>我們將 LDD-L1 正則化器應用在了 4 種機器學習模型上：</p><ul><li>多類 logistic 迴歸（MLR）</li><li>距離度量學習（DML）</li><li>稀疏編碼（SC）</li><li>深度神經網絡（DNN）</li></ul><p><strong>3 算法</strong></p><p>對於 LDD-L1 正則化的 MLR、NN 和 DML 問題，我們使用近端梯度下降（Parikh & Boyd, 2014）求解它們。這種近端操作針對的是 LDD-L1 中的 L1 正則化器。算法會迭代地執行以下三個步驟，直到收斂：（1）計算</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883419195639b500f51><p class=pgc-img-caption></p></div><p>的梯度，其中 L(W) 是未正則化的機器學習模型的損失函數，</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531883419323ee711e9726><p class=pgc-img-caption></p></div><p>是 LDD-L1 中的 LDD 正則化器；（2）執行 W 的梯度下降更新；（3）將 L1 正則化器的近端算子應用於 W。</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531883419445e4f3ed69df><p class=pgc-img-caption></p></div><p>算法 1：求解 LDD-L1-SC 問題的算法</p><p><strong>實驗</strong></p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531883419460a4e62f31d9><p class=pgc-img-caption></p></div><p>表 2：在 20-News 和 RCV1 的測試集上的分類準確度，以及訓練準確度和測試準確度之間的差距</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531883419635285985181c><p class=pgc-img-caption></p></div><p>表 4：在 PTB 測試集上的詞級困惑度</p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153188341958774509c8041><p class=pgc-img-caption></p></div><p>表 5：在 CIFAR-10 測試集上的分類誤差（%）</p><p><strong>論文：非重疊促進型變量選擇（Nonoverlap-Promoting Variable Selection）</strong></p><div class=pgc-img><img alt=Petuum提出新型正則化方法：非重疊促進型變量選擇 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15318834195043ba2024577><p class=pgc-img-caption></p></div><p>論文地址：http://proceedings.mlr.press/v80/xie18b/xie18b.pdf</p><p>變量選擇是機器學習（ML）領域內的一個經典問題，在尋找重要的解釋因素以及提升機器學習模型的泛化能力和可解釋性方面有廣泛的應用。在這篇論文中，我們研究了要基於同一個協變量集預測多個響應的模型的變量選擇。因為每個響應都與一個特定協變量子集有關，所以我們希望不同響應的所選變量之間有較小的重疊。我們提出了一種能同時促進正交性和稀疏性的正則化器，這兩者能共同帶來降低重疊的效果。我們將這種正則化器應用到了 4 種模型實例上，並開發了求解正則化問題的有效算法。我們對新提出的正則化器可以降低泛化誤差的原因進行了形式分析。我們在仿真研究和真實世界數據集上都進行了實驗，結果表明我們提出的正則化器在選擇更少重疊的變量和提升泛化性能上是有效的。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Petuum</a></li><li><a>正則化</a></li><li><a>重疊促</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/1b43051a.html alt=在深度學習中對正則化的直觀認識 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1823dce03cf84870a3a026b913ecaa1d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/1b43051a.html title=在深度學習中對正則化的直觀認識>在深度學習中對正則化的直觀認識</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/316bfb0b.html alt="機器不學習：深度學習訓練淫技2 L1正則化和L2正則化" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1535372399398ea02c0c526 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/316bfb0b.html title="機器不學習：深度學習訓練淫技2 L1正則化和L2正則化">機器不學習：深度學習訓練淫技2 L1正則化和L2正則化</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>