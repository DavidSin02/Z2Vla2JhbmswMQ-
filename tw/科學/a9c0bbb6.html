<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度學習：隨機值不可思議的有效性 | 极客快訊</title><meta property="og:title" content="深度學習：隨機值不可思議的有效性 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/c0374f7078464b66b439cc3fb16e9d27"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/a9c0bbb6.html><meta property="article:published_time" content="2020-11-14T20:51:44+08:00"><meta property="article:modified_time" content="2020-11-14T20:51:44+08:00"><meta name=Keywords content><meta name=description content="深度學習：隨機值不可思議的有效性"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/a9c0bbb6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度學習：隨機值不可思議的有效性</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><h1>深度學習：隨機值不可思議的有效性</h1><p>ICLR 2017會議於法國土倫召開，我們收到了截止日期內提交的論文，與預期的關於深度學習新研究的涓涓細流不同，我們迎來了一場凶猛的洪水。這是一個研究領域的寶庫，每時每刻都有新的文章發表。許多論文都對如今最前沿的技術做出了進一步的完善。我本希望能夠找到一些更基本的關於深度學習本質的理論和實驗成果，但是很遺憾的是，這樣的論文寥寥無幾。儘管如此，仍有兩個研究令人眼前一亮，此外，還有一篇論文值得關注，我曾一度懷疑這篇論文，但最終還是接受了它那難以置信的結果。這確實是一個好消息，但也是一個不好的開始。</p><p>首先，讓我們來討論下好消息。這個難以置信的發現是，你可以訓練一個神經網絡，讓它學會如何學習（即元學習）。具體來說，已經有一些研究團隊訓練出了能夠執行隨機梯度下降（SGD）的神經網絡。不僅這些研究團隊可以證明他們的神經網絡能夠學習SGD，而且這種網絡的效果比任何人工調試的方法都要好。這兩篇發表的文章分別是《Deep Reinforcement Learning for Accelerating the Convergence Rate》和《Optimization as a Model for Few-Shot Learning》。可惜的是，在這之前，這兩個研究團隊被Deep Mind搶先一步，其論文《Learning to Learn by gradient descent by gradient descent》介紹了這種做法。後兩篇論文均訓練了一個長短期記憶網絡（LSTM），而第一篇論文則通過強化學習的方式進行訓練。我本以為實現元學習需要更久的一段時間，但它的發展之快超出了我的預期。</p><p>另外兩個團隊也不甘示弱，實現了能夠設計新型深度學習網絡的機器，而且通過這種方式，我們可以改進現有的技術。這是在學習如何設計神經網絡。兩篇發表的論文分別是《Designing Neural Network Architectures using Reinforcement Learning》和《Neural Architecture Search with Reinforcement Learning》。前一篇論文使用了強化Q學習算法來發現卷積神經網絡架構。你可以在Caffe中找到一些他們生成的卷積神經網絡。而後一篇論文才是真正令人震驚的（沒有Google的計算資源，你根本做不到這一點）。他們不僅展示了最新的卷積神經網絡，而且這種機器實際上學習了一些LSTM節點的變種。由機器創建的LSTM節點如下所示（左圖和下圖）：</p><div class=pgc-img><img alt=深度學習：隨機值不可思議的有效性 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c0374f7078464b66b439cc3fb16e9d27><p class=pgc-img-caption></p></div><p>所以，不僅手工優化梯度下降方法的研究人員失業了，那些依靠設計神經網絡來謀生的人們也難逃一劫！實際上這僅僅是能夠自學習的深度學習系統的開始。所以，在這裡我要分享一幅施米德胡貝的漫畫，它恰當地描述了正在發生的事情。</p><div class=pgc-img><img alt=深度學習：隨機值不可思議的有效性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ddba55a545c848bf8c9a70ecb589b596><p class=pgc-img-caption></p></div><p>這絕對是令人震驚的，而且我們對深度學習算法能發展得多快一無所知。這種元特性允許你將其應用至自身，遞歸地創建出越來越優秀的系統。</p><p>現在，請允許我告訴你那個壞消息。這裡有一篇論文傳達了這個消息：《Understanding Deep Learning required Rethinking Generalization》。我對泛化思考了很多，也在Quora上提了一些關於泛化和隨機性的問題，希望有人可以分享一下他們對此的見解。然而，直到上述論文的作者進行了一系列有趣的實驗之前，沒有人給出一份令我滿意的答案或理解這個問題的重要性。以下是他們論文中的一部分發現：</p><p><em>1.神經網絡的有效容量是足夠大的，甚至足夠使用暴力記憶的方式記錄整個數據集。</em></p><p><em>2.即便使用隨機標籤，進行優化仍然是很容易的。實際上，與使用真實標籤進行訓練相比，隨機標籤的訓練時間僅僅增長了一個小的常數因子。</em></p><p><em>3.標籤隨機化僅僅是一種數據轉換，學習問題的其他性質仍保持不變。</em></p><p>那個令人震驚的真相顯現出來了。深度學習網絡僅僅是大規模的關聯記憶存儲。深度學習網絡即使在擬合隨機數據時，仍能保持良好的泛化能力。這確實很奇怪，許多支撐神經網絡有效性的依據都建立在這樣一個猜想之上：“自然”數據往往存在於多維空間中一個非常窄的流形中。然而，隨機數據並不具備這樣的趨勢。</p><p>在今年早些時候，John Hopcroft寫了一篇論文，檢驗神經網絡與關聯記憶間的二元性。下面是他論文中的一幅插圖：</p><div class=pgc-img><img alt=深度學習：隨機值不可思議的有效性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e377e3aca78f45b4bd715452e76b9317><p class=pgc-img-caption></p></div><p>《Understanding Deep Learning required Rethinking Generalization》這篇論文甚至進一步檢驗了我們行之有效且久經考驗的泛化工具（即正則化），並發現：</p><p><em>顯式正則化或許能提高泛化性能，但這既不必要也不足以控制泛化誤差。</em></p><p>換句話說，我們所有的正則化工具可能並沒有我們想象中那麼有效！而且，更難以置信的是，SGD那不可思議的效果，實際上只是另一種碰巧有效的正則化方法！</p><p><em>參照線性模型，我們分析了SGD如何進行隱式的正則化。</em></p><p>事實上，另一個團隊在提交至ICLR2017的名為《An Empirical Analysis of Deep Network Loss Surfaces》的論文中，確認了這些網絡的局部極小值是不同的：</p><p><em>我們的實驗表明，不同的最優化方法會找到不同的極小值，即使在訓練過程中非常靠後的階段，從一種方法切換至另一種方法，也同樣如此。此外，我們發現，不同最優化方法找到的極小值具有不同的形狀，但這些極小值在最重要的度量——泛化精度上是相似的。</em></p><p>這表明，你對學習算法的選擇“操縱”著算法如何得出最終結果。隨機性是無所不在的，無論你如何規範自己的網絡或者使用何種SGD變種算法，網絡都會趨近於收斂（如果你設置了正確的隨機條件）！SGD的什麼性質使機器具備了學習的能力？是同分化關聯的屬性還是其他更一般的屬性？如果我們可以讓一個網絡學會執行SGD，那麼我們能夠教會它執行這種未知的廣義學習方法嗎？</p><p>實際上，在今年早些時候論文《A Powerful Generative Model Using Random Weights for the Deep Image Representation》證明了這種隨機性的有效性。這篇論文也是由John Hopcroft合著，表明你可以使用隨機初始化的未經任何訓練的網絡生成逼真的圖像。這怎麼可能呢？</p><p>因此，要理解深度學習，我們必須擁抱隨機性。隨機性起源於最大熵，而最大熵最有趣的是它的自身結構！神經網絡的存儲容量似乎最接近於隨機權重。這裡很奇怪的是，宇宙中隨機性無處不在。熵值更大的方向反映了時間流向。那麼，如果這個性質也是學習機器的基礎，那又會發生什麼呢？</p><p><strong>文章原標題《Deep Learning: The Unreasonable Effectiveness of Randomness》，作者：Carlos E. Perez</strong></p><p><strong>本文由阿里云云棲社區組織翻譯。</strong></p><p>文章為簡譯，更為詳細的內容，請查看原文</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>學習</a></li><li><a>隨機值</a></li><li><a>思議</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html alt=直流鍋爐給水控制學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/eba10edcc8d14d9f8cde6fd5b212d90e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html title=直流鍋爐給水控制學習>直流鍋爐給水控制學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html alt=HTMLCSS學習筆記（六）——元素類型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb5988349894ce9bf568c6418f85b7d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html title=HTMLCSS學習筆記（六）——元素類型>HTMLCSS學習筆記（六）——元素類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html alt="web前端（從零開始），每天更新學習筆記 HTML5元素分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/46d70004fcd55e1ddad3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html title="web前端（從零開始），每天更新學習筆記 HTML5元素分類">web前端（從零開始），每天更新學習筆記 HTML5元素分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html alt="MySQL 學習筆記" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html title="MySQL 學習筆記">MySQL 學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html alt=深入學習MySQL事務：ACID特性的實現原理「轉」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/cdc702d66d6943499997d11e931425eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html title=深入學習MySQL事務：ACID特性的實現原理「轉」>深入學習MySQL事務：ACID特性的實現原理「轉」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html alt=如何學習模擬IC設計？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html title=如何學習模擬IC設計？>如何學習模擬IC設計？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html alt=小猿圈python學習-三大特性之多態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad0e8e3777854337abeb7c779ad79a04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html title=小猿圈python學習-三大特性之多態>小猿圈python學習-三大特性之多態</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html alt=地理學習5——地球的運動（地球的公轉及其地理意義） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7b2b74c871eb40beb8ee143627d29611 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html title=地理學習5——地球的運動（地球的公轉及其地理意義）>地理學習5——地球的運動（地球的公轉及其地理意義）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html alt=繼續學習打卡，還真心學不會了，努力，堅持 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f36d6d47a06840aaaf78138853b9d9d1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html title=繼續學習打卡，還真心學不會了，努力，堅持>繼續學習打卡，還真心學不會了，努力，堅持</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html alt=一造學習筆記—管理篇（2）：工程造價管理的組織和內容 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/9e65b076-038f-4720-96ff-182898f42dee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html title=一造學習筆記—管理篇（2）：工程造價管理的組織和內容>一造學習筆記—管理篇（2）：工程造價管理的組織和內容</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>