<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 | 极客快訊</title><meta property="og:title" content="機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/098e7c3fc26e4c148cd535acf6e21f94"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/be7a95a.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/be7a95a.html><meta property="article:published_time" content="2020-10-29T20:56:37+08:00"><meta property="article:modified_time" content="2020-10-29T20:56:37+08:00"><meta name=Keywords content><meta name=description content="機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/be7a95a.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>SVM概述</h1><p>支持向量機(SVM)是一種有監督的分類算法，並且它絕大部分處理的也是二分類問題，先通過一系列圖片瞭解幾個關於SVM的概念。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/098e7c3fc26e4c148cd535acf6e21f94><p class=pgc-img-caption></p></div><p>上圖中有橙色點和藍色點分別代表兩類標籤，如果想要將其分類，需要怎麼做呢？可能有的夥伴會想到上一篇文章講到的邏輯迴歸擬合決策邊界，這肯定是一種不錯的方法，本文所講的SVM也是可以解決這種分類問題的；既然都是分類算法，所以通過一個例子可以比對出二者的相同點和不同點。</p><h1 class=pgc-h-arrow-right>超平面</h1><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0bebd7cab35e4f5ca0e2b7679f1c95f6><p class=pgc-img-caption></p></div><p>可以看到，這裡給出了兩種劃分方式，就圖中實線而言，在邏輯迴歸中可以稱作決策邊界，而在SVM中它被稱為超平面(hyperplane)。</p><p>上面例子中數據點都分佈在二維平面上，所以此時超平面就為一條直線。如果給出的數據集是三、四、... 、N維呢？此時超平面對應的維度就是二、三、...、N-1維的，下圖展示了數據集多維時的超平面。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0406111ff74e4bcd87587b979cf43c53><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>最大間隔</h1><p>對於這個例子，可以將其準確分類的超平面可能有多個，其中具有最大間隔(兩條虛線之間的距離)的超平面就是SVM要找的最優解，這個最優解對應兩側虛線所穿過的樣本點，就是“支持向量(support vector)”,支持向量到超平面的距離被稱為間隔(margin)，如下圖繪製標識。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c324ed062baf44c7a81912c5de04f894><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>公式推導</h1><h1 class=pgc-h-arrow-right>超平面方程</h1><p>我們利用SVM算法建模最後想要從眾多超平面中求解具有最大間隔的超平面，所以這也是一個最優化問題。</p><p>這裡需要了解一下最優化問題的兩個基本因素：</p><ul class=ul-list><li>目標函數：你希望什麼東西的什麼指標達到最好。</li><li>優化對象：你希望改變哪些因素使目標函數達到最優。 在線性SVM算法中，目標函數就是“間隔”，優化對象則是“超平面”。</li></ul><p>所以首先需要推導“超平面”的方程，二維空間內“超平面”的公式也就是直線方程，如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/81210d9fc1794452acae4ea928e0328f><p class=pgc-img-caption></p></div><p>這裡將x變成x1，y變成x2的操作是為了將其向量化。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/de455f16343f414c84a9b51be2767ae9><p class=pgc-img-caption></p></div><p>最後將其整理成：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5880a4b27e1a434197976285d5843bcc><p class=pgc-img-caption></p></div><p>一般的向量為列向量，所以這裡對$\omega$進行了轉置，並且$\omega$向量與我們所設直線是相互垂直的，只需要假定直線斜率a為一個常數，繪圖即可證明，其中$\omega$控制著直線的方向，b則控制著直線的位置，所以直線方程中需要改變$\omega$和b使目標函數達到最優。</p><h1 class=pgc-h-arrow-right>間隔公式</h1><p>“間隔”就是圖中點到“超平面”的距離，公式如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/660c03f30ede4593a41dd8518cbff380><p class=pgc-img-caption></p></div><p>其中d代表間隔，$||\omega||$代表的是$\omega$的二範數(模)，即對所有元素的平方和開平方。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cc096ef1d8ed420cb5e661444e362f0a><p class=pgc-img-caption></p></div><p>建模的目標就是為了找到最大間隔，其中最大間隔W=2d，只要W越大，則代表該模型分類的效果越好，最後也就變成了求解d最大化的問題。</p><h1 class=pgc-h-arrow-right>約束條件</h1><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b549b4a3c1de4daeb352e4cb6b160f55><p class=pgc-img-caption></p></div><p>針對上述我們所建分類器，當我們輸入數據給分類器時，它會返回一個類別標籤，這裡先規定藍色為負樣本(-1)、紅色為正樣本(+1)，我們可以得到一組公式，如果超平面能夠準確對圖中樣本點分類，則可得到以下公式：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/cde06375176846a688c6f6e7985e1d19><p class=pgc-img-caption></p></div><p>上述公式可歸化成：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d705dacf21554c6895742868b2558645><p class=pgc-img-caption></p></div><blockquote><p>s.t.表示"subject to"即服從某種條件</p></blockquote><p>這裡再回顧一下上面的最大間隔方程，求最大間隔的思想可以概括為求<strong>最小的</strong>點到超平面的幾何距離的<strong>最大化</strong>。最小是為了分類時不同類別都能夠得到準確分類，距離最大化則是為了獲取”最大間隔“，以達到對分類器調優，公式如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9a43217808ae4cab93ee4f1297475369><p class=pgc-img-caption></p></div><p>如果我們希望最優的超平面的間隔的幾何距離為$\gamma$,即所有樣本點到超平面的幾何距離至少為$\gamma$，所以下面公式一定成立。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/da50d7d6b96542528e5b639b25211610><p class=pgc-img-caption></p></div><p>這裡$\gamma$將其設定為1。可以這麼想，不論我們$\gamma$設定的是幾，將等式兩邊同時除以$\gamma$，$\omega$和b的係數縮小了$\gamma$倍，但超平面是不動的，係數是可以同比例縮放的，可以類比直線方程。 固定$\gamma$之後，可以得到以下公式。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ad85e3aadab44e029dfebad271ceb48f><p class=pgc-img-caption></p></div><p>這裡對$\omega$做了一定處理，最大化$\frac{1}{||\omega||}$和最小化$\frac{1}{2}||\omega||^2$是等價的，這樣做是為了在進行最優化時對目標函數求導方便，對最優解沒有影響。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9ac64e7eed49420f9a90ef3a0717a4cc><p class=pgc-img-caption></p></div><p>其中第一個公式為我們的目標函數，第二公式也就是這個最優化問題中的約束條件，由於$min\frac{1}{2}||\omega||^2$是一個凸函數，所以這個問題是凸優化問題。</p><h1 class=pgc-h-arrow-right>求解最優化問題</h1><h1 class=pgc-h-arrow-right>最優化問題分類</h1><p>最優化問題一般可分為兩大類：無約束優化問題和約束優化問題，而約束優化問題又可分為含等式約束優化問題和含不等式約束優化問題。</p><ul class=ul-list><li>對於無約束優化問題，可以對函數求導，然後令其為零，從候選值中選取最優值，並加以驗證；若函數為凸函數，則可以保證是最優解。隨機梯度下降和批量梯度下降就是無約束優化方法。</li><li>對於含等式約束優化問題，常用的方法是利用拉格朗日乘子法將其轉化為無約束優化問題求解。具體為將約束條件和函數寫成一個函數，稱為拉格朗日函數，係數為拉格朗日乘子；通過拉格朗日函數對各個變量求導，令其為零，從候選值中選取最優值，並加以驗證。</li><li>對於含不等式約束優化問題，主要通過KKT條件將其轉化成無約束優化問題求解。具體為通過構建拉格朗日函數，在一些條件下求出最優值的必要條件，這個條件就是KKT條件。</li></ul><blockquote><p>A的必要條件就是A可以推出的結論</p></blockquote><p>對於我們所構造出的最優化問題明顯是屬於含不等式約束優化問題，關於拉格朗日函數的概念不過多介紹，下面介紹拉格朗日乘子法，並通過拉格朗日乘子法引出對偶問題和KKT條件。</p><h1 class=pgc-h-arrow-right>拉格朗日乘子法</h1><p>拉格朗日乘子法的思想就是通過引入拉格朗日乘子，將有d個變量和k個約束條件的最優化問題轉化為d+k個變量的無約束優化問題求解。</p><p>這裡感興趣的夥伴可以搜一下大佬的博客或者西瓜書上都有詳細介紹，真是後悔高數課上沒有仔細聽這部分。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d855d89a93964caf96c0209a1420ea86><p class=pgc-img-caption></p></div><p>通過引入拉格朗日乘子$\lambda$可以將上述的最優化問題轉化成下面形式：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7bbdc038625d4ae88b1e6b4123ea0ed3><p class=pgc-img-caption></p></div><p>其中需要注意的是$\lambda>=0$,$1-y_i(\omega^Tx_i+b)=0$,通過拉格朗日函數我們可以將上述公式轉化為： ![](https://imgkr.cn-bj.ufileos.com/e173f775-5680-4a4b-a383-c9d3da743e07.png) 有的夥伴這裡可能會不理解，為什麼是拉格朗日函數最大值的最小化，下圖介紹了原因。 ![](https://imgkr.cn-bj.ufileos.com/8efbe616-5baa-4f98-8ccf-508857c6d6e1.png) 很明顯當$1-y_i(\omega^Tx_i+b)0$時，目標函數取值為正無窮是沒有意義的，而當$1-y_i(\omega^Tx_i+b)&lt;=0$時,兩者則是等價的。</p><h1 class=pgc-h-arrow-right>對偶問題</h1><p>利用對偶性可以將上述原問題轉化成對偶問題，如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ecfa8aa871414b0d8dc2115ec473cc2b><p class=pgc-img-caption></p></div><p>這個過程的主要操作就是將min和max互掉位置，並且二者之間有一個性質，即前者>=後者，這就好比在高個子人群中挑一個身高較矮的要高於在矮個子人群中挑一個身高較高的。默認情況下二者是呈弱對偶關係的，但在此目標函數和約束條件下是呈強對偶關係(等價關係)的。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0c507e1057d644d18ab262347c3fc991><p class=pgc-img-caption></p></div><p>在轉化成對偶問題之後，我們可以先求$min_\omega,bL(\omega,b,\lambda)$,分別令函數$L(\omega,b,\lambda)$對$\omega,b$求偏導，並使其等於0。</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/389eb43b62134614baca0983d4f0c35d><p class=pgc-img-caption></p></div><p>在將上述兩個式子帶入至構建的拉格朗日函數中，可得：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/44aeb394816849cbb3c525f1dd5ef4f3><p class=pgc-img-caption></p></div><p>最後整理一下得出我們推導過後最終的優化問題，如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/db66604b4a1d4ee79957a41bccde5e4e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>KKT條件</h1><p>假設有這樣一個含不等式約束的優化問題：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2c30bf4da412434ba2c5919d7f26ac50><p class=pgc-img-caption></p></div><p>如果想利用KKT條件處理此優化問題，需要利用拉格朗日乘子法將不等式約束、等式約束和目標函數合併寫成一個式子，如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/77a6b43e0d5c4c37903a8b3cad369d77><p class=pgc-img-caption></p></div><p>KKT條件就是說取到的最優值必須滿足以下條件：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8b60a1af75144eea981cd0fb12e6f366><p class=pgc-img-caption></p></div><p>當原問題與對偶問題呈強對稱關係是此問題滿足KKT條件的充分必要條件，所以本文最優化問題滿足的條件如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1fdb3dcd599e43948738d16bc2d9026c><p class=pgc-img-caption></p></div><p>根據這些條件，我們可以得出只有在樣本點為支持向量(樣本點處於虛線上)時，$\lambda$可以取任意值，而其他位置的樣本點$\lambda$一定為0。這就和邏輯迴歸有不同之處了，邏輯迴歸在擬合決策邊界時，所有樣本都會有影響，而SVM有作用的主要是邊界線附近的樣本。</p><p>因為我們所設超平面方程為$f(x)=\omega^Tx+b$，所以我們求得原始最優化問題的解為$\omega^、b^$，在L對$\omega$求導時得到了$\omega^$的解，而對於$b^$,求解過程如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/ba338df255e345ac8d6aa32c15b46fa3><p class=pgc-img-caption></p></div><p>這裡需要注意的點是設定$(x_k,y_k)$是支持向量，所以$y_k=+1或y_k=-1$,$(y_k)^2=1$就可以消去。最終獲取到的最優超平面方程如下：</p><div class=pgc-img><img alt=機器學習筆記(九)——手撕支持向量機SVM之間隔、對偶、KKT推導 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5391e0484d774a739d11bfa3c6f1251d><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>總結</h1><ul class=ul-list><li>介紹了超平面與最大間隔的概念。</li><li>在二維空間內推導超平面方程並介紹間隔公式。</li><li>推導該優化問題的約束條件。</li><li>介紹了最優化問題的分類及對應解決思想。</li><li>通過拉格朗日乘子法引出對偶問題。</li><li>在對偶問題的基礎上講解KKT條件。</li><li>博主還是個菜鳥，歡迎指出文中出現的問題。</li></ul><p>本文不包含代碼，著重於公式推導，對於手寫代碼比較重要的部分應該在於公式推導，只有瞭解每一步驟的思想及由來，才能更好的進行編程，下篇文章將會介紹一個簡化版的序列最小化(SMO)算法，歡迎關注、感謝閱讀。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>筆記</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html alt=HTMLCSS學習筆記（六）——元素類型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb5988349894ce9bf568c6418f85b7d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html title=HTMLCSS學習筆記（六）——元素類型>HTMLCSS學習筆記（六）——元素類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html alt="MySQL 學習筆記" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html title="MySQL 學習筆記">MySQL 學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html alt=一造學習筆記—管理篇（2）：工程造價管理的組織和內容 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/9e65b076-038f-4720-96ff-182898f42dee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html title=一造學習筆記—管理篇（2）：工程造價管理的組織和內容>一造學習筆記—管理篇（2）：工程造價管理的組織和內容</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0a02618e.html alt=某教程學習筆記（一）：17、php漏洞 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/6d21bdb33b0a49e8b6eaa2c2a725a1d8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0a02618e.html title=某教程學習筆記（一）：17、php漏洞>某教程學習筆記（一）：17、php漏洞</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b37aac89.html alt=【學習筆記】Android開發之kotlin語言（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ee3f9c8348ae4de58a5f62922d2042e1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b37aac89.html title=【學習筆記】Android開發之kotlin語言（一）>【學習筆記】Android開發之kotlin語言（一）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>