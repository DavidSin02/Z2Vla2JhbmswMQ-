<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>乘風破浪的 GAN——回顧 GAN 的發展之路 | 极客快訊</title><meta property="og:title" content="乘風破浪的 GAN——回顧 GAN 的發展之路 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/5116e26223d74fa8b31fefbcd408c6c8"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/bf084a7.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/bf084a7.html><meta property="article:published_time" content="2020-10-29T20:55:39+08:00"><meta property="article:modified_time" content="2020-10-29T20:55:39+08:00"><meta name=Keywords content><meta name=description content="乘風破浪的 GAN——回顧 GAN 的發展之路"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/bf084a7.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>乘風破浪的 GAN——回顧 GAN 的發展之路</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><blockquote><p>本文來源於Hulu知乎官方賬號文章《&lt;百面深度學習>試讀 | 系列二：回顧GAN的發展之路》，葫蘆娃著。</p></blockquote><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5116e26223d74fa8b31fefbcd408c6c8><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>2014 年，在一間酒吧裡，Ian Goodfellow 與朋友觥籌交錯暢談生成模型之際，生成式對抗網絡（Generative Adversarial Network, GAN）誕生了。2020年，GAN 一路乘風破浪，披荊斬棘，在各種領域成功“出道”。</h1><p style=text-align:start>有興趣的讀者可以去記錄了五百多種 GAN 的 GAN Zoo 裡 pick 你喜歡的 GAN。那麼 GAN 是如何從一個博弈的想法，進化到如今這樣高產的呢？這之中又有多少艱難險阻呢？今天我們就來回顧一下 GAN 的發展之路。</p><h1 class=pgc-h-arrow-right>回到 GAN 最原始的模樣</h1><p style=text-align:start>GAN 是一種非常能展現“創造性”的模型。從名字就可以看出，<strong>GAN 的核心在於“生成”和“對抗”：</strong>“生成”指的是生成式模型，其目的是模擬多個變量的聯合概率分佈；“對抗”指的是對抗訓練方法，又名 “互懟”、“相愛相殺”。這兩者結合，就產生出了神奇的 GAN。</p><p style=text-align:start>GAN 是專門為了<strong>優化生成任務</strong>而提出的模型。生成模型的一大難點在於如何度量生成分佈與真實分佈的相似度。一般情況下，我們只知道這兩個分佈的採樣結果，很難知道具體的分佈表達式，因此難以找到合適的度量方法。<strong>GAN 的思路是，把這個度量任務交給一個神經網絡來做，這個網絡被稱為判別器</strong>（Discriminator）。GAN 在訓練階段用對抗訓練方式來交替優化生成器 G(⋅) 與判別器 D(⋅)。整個模型的優化目標是：</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/acd9b9ba0fad43abbefe2a9baaa143cc><p class=pgc-img-caption></p></div><p style=text-align:start>上述公式直觀地解釋了<strong> GAN 的原理</strong>：判別器D(⋅)的目標是區分真實樣本和生成樣本，對應在目標函數上就是使上式的值儘可能大，也就是對真實樣本的輸出D(x)儘量接近1，對生成樣本的輸出D(G(z))儘量接近0；生成器G(⋅)的目標是欺騙判別器，儘量生成“以假亂真”的樣本來逃過判別器的“法眼”，對應在目標函數上就是讓上式的值儘可能小，也就是讓D(G(z))也儘量接近1。</p><p style=text-align:start>這是一個 "MiniMax" 遊戲，在遊戲過程中G(⋅)和D(⋅)的目標是相反的，這就是 GAN 名字中“對抗”的含義。通過對抗訓練，生成器與判別器交替優化，共同成長，最終修煉為兩個勢均力敵的強者。Fig. 1 是 GAN 的基本框架圖。</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a51601c28c3d408a896aead63e8d1ce6><p class=pgc-img-caption></p></div><p>Figure 1: GAN 的基本框架</p><h1 class=pgc-h-arrow-right>不完美的 GAN</h1><p style=text-align:start>GAN 最初的樣子看上去簡潔又優美。 可是誕生不久，一些對於 GAN 的負面評價開始出現，<strong>“梯度消失”、“訓練不穩定”、“模式坍塌”</strong>...... 對 GAN 有過了解的人應該對這些詞彙並不陌生。而想要弄清這些問題究竟是什麼原因造成的，需要深入到模型背後對其原理進行詳細地分析。</p><ul><li><strong>梯度消失</strong></li></ul><p style=text-align:start>在 Goodfellow 提出的原始 GAN [1] 中，模型的優化目標為 Eq. 1。如果將判別器 D(⋅) 看作一個二分類器，真實樣本的訓練標籤為 1，生成樣本的訓練標籤為 0，D(⋅) 的優化目標可以解釋為最大化該分類問題的對數似然函數，也即最小化交叉熵損失。這個看起來簡潔又直觀的定義，在理論上存在著一些問題。</p><p style=text-align:start>這是因為，在一開始訓練時，生成器還很差，生成的數據與真實數據相差甚遠，判別器可以很輕鬆地作出正確的判斷，也就是輸出與訓練標籤基本一致的結果。有監督的訓練需要通過損失函數的<strong>梯度</strong>來更新模型，若模型輸出結果與標籤基本一致，也就意味著梯度接近於0，這會讓判別器覺得自己已經足夠強大，失去優化自己的“動力”。簡單用一句話概括來說，就是在訓練的早期階段，目標函數 Eq. 1 無法為生成器提供足夠大的梯度。</p><p style=text-align:start>我們還可以從<strong>“散度”</strong>的角度來理解這個問題：當判別器達到最優時，根據損失函數 L(G)，此時生成器的目標其實是最小化真實分佈與生成分佈之間的 JS 散度。JS 散度（Jensen–Shannon divergence），用於度量兩個概率分佈的相似度，其定義為：</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/878200dd714f459d8a383785e46de0e9><p class=pgc-img-caption></p></div><p style=text-align:start>然而，JS 散度有一個特性：當兩個分佈沒有重疊的部分，或幾乎沒有重疊時，JS 散度為常數（這可以根據 JS 散度的定義 Eq. 2 得到）。那麼在 GAN 中，真實分佈和生成分佈的重疊部分有多大呢？</p><p style=text-align:start>生成器一般是從一個低維空間（如 128 維）中採樣一個向量並將其映射到一個高維空間中（比如一個 32×32 的圖像就是 1024 維），所以生成數據只是高維空間中的一個低維流形（比如生成樣本在上述 1024 維圖像空間的所有可能性實際上是被那 128 維的輸入向量限定了）。</p><p style=text-align:start>同理，真實分佈也是高維空間中的低維流形。高維空間中的兩個低維流形，在這樣“地廣人稀”的空間中碰面的機率趨於 0，所以生成分佈與真實分佈是幾乎沒有重疊部分的。高維空間中的 JS 散度遇到了<strong>“降維打擊”</strong>，只能無奈地輸出一個常數，導致梯度消失問題。</p><ul><li><strong>模式坍塌（mode collapse）</strong></li></ul><p style=text-align:start>為解決梯度消失問題，Goodfellow 提出了改進方案，採用以下公式來替代生成器的損失函數：</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7e071b15700f4367a5dcc286d9853a93><p class=pgc-img-caption></p></div><p style=text-align:start>可以看到，兩個公式就是差了一個“1”，但就能在訓練早期階段可以為生成器提供更大的梯度（參見文獻[1]）。</p><p style=text-align:start>然而，改進後的損失函數也存在不合理之處。此時最小化損失函數相當於最小化</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8e770ba2ed1a4db8b0b98e580e817b26><p class=pgc-img-caption></p></div><p style=text-align:start>（推導略，詳情見《百面深度學習》對應章節），這就既要最小化生成分佈與真實分佈的 KL 散度，即減小兩個分佈的距離，又要最大化兩者的 JS 散度，即增大兩個分佈的距離，這會在訓練時造成梯度的不穩定。</p><p style=text-align:start>另外，KL 散度是一個非對稱度量，因此還存在對不同錯誤懲罰不一致的問題。當生成器缺乏多樣性但能生成某一種簡單的模式時，生成的樣本對損失函數貢獻趨近於0；當生成器嘗試去生成其他更復雜的模式下的樣本時，懲罰會趨於無窮大。</p><p style=text-align:start>舉個簡單的例子，美術課上“判別器”老師，給了一些英短貓、銀漸層、緬因貓、Hello Kitty 等等各式各樣形態各異的貓的樣例，要求“生成器”學生們創作屬於自己的貓，選擇高難度種類的創作並不會獲得獎勵，但是與樣例的的水準差距明顯則會受到請家長並記過的懲罰。由於懲罰過於嚴厲，學生們紛紛選擇了最簡單的Hello Kitty，其他形態各異，胖瘦不一的貓貓由於太難而無人問津。</p><p style=text-align:start>真實數據的分佈也往往是高度複雜並且是多模態的，數據分佈有很多模式（modes），相似的樣本屬於一個模式。由於懲罰的不一致，生成器寧願多生成一些真實卻屬於同一個模式的樣本，也不願意冒著巨大懲罰的風險去生成其他不同模式的、具有多樣性的樣本來欺騙判別器，這就是所謂的<strong>模式坍塌</strong>（mode collapse）。</p><ul><li><strong>模型收斂性</strong></li></ul><p>在實際應用中，一般常用深度神經網絡來表示 G(⋅) 和 D(⋅)，然後採用<strong>梯度下降法</strong>和<strong>反向傳播算法</strong>來更新網絡參數，而不是直接學習</p><p><br></p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bb308d37437f426ca60d89ad7f2a3e53><p class=pgc-img-caption></p></div><p>本身。然而，Goodfellow 給出的收斂性證明是基於概率密度函數空間上</p><p><br></p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/57ee5a75546842c4b06967b8be74a208><p class=pgc-img-caption></p></div><p>的凸性，當問題變成了參數空間的優化時，凸性便不再確定了，所以理論上的收斂性在實際中不再有效。</p><p style=text-align:start>另外，訓練的收斂性的判斷也是一個難題。由於存在對抗，生成器與判別器的損失是反相關的，一個增大時另一個減小，因而無法根據損失函數的值來判斷什麼時候應該停止訓練。當然，我們也很難直接通過損失函數或者生成器的輸出來判斷生成數據的質量，例如難以比較哪個圖更“真實”，哪些生成數據多樣性更高。</p><p></p><h1 class=pgc-h-arrow-right>GAN 的成長之路</h1><p style=text-align:start>近幾年來，GAN 發展十分迅速，各式各樣的 GAN 不斷湧現，有很多工作都致力於解決 GAN 訓練的不穩定、提高生成數據真實性和多樣性等問題。主要可以歸類為對於目標函數的優化、對於模型結構的優化以及對於訓練過程的優化。</p><ul><li><strong>目標函數的優化</strong></li></ul><p style=text-align:start>前文已經提到，基於 JS 散度距離度量的 GAN 會存在一些問題，在分佈距離度量方式上進行優化自然的成為一個改進的方向。採用 Wasserstein 距離的 WGAN [2] 就是一個典型的代表。 另一種比較典型的對目標函數的優化是摺頁損失（Hinge Loss）形式的損失函數，它起源於 Geometric GAN [3]。</p><p style=text-align:start>在 Geometric GAN 中，研究者將 GAN 解釋為在特徵空間進行的三步操作：(1) 分類超平面搜索；(2) 判別器向遠離超平面的方向更新；(3) 生成器向超平面的方向更新。各種 GAN 之間的主要區別就在於分類超平面的構建方法以及特徵向量的幾何尺度縮放因子的選擇，具體理論推導參見文獻 [3]。</p><p style=text-align:start>在訓練階段，批（mini-batch）的大小往往遠小於特徵空間的維度，這種情況下的分類問題被稱為<strong>高維低採樣尺寸</strong>（High-Dimension-Low-Sample-Size, HDLSS）問題。支持向量機（SVM）中最大化兩類的分類邊界以及軟邊界的思想被廣泛應用在 HDLSS 問題中，並被證明具有魯棒性。Geometric GAN 借鑑 SVM 的思想，判別器的損失函數形式與 SVM 中的摺頁損失的形式很相似。Geometric GAN 出現後，這種具有摺頁損失形式的 GAN 損失函數在很多方法中被採用，包括 2018 年熱門的 SAGAN [4] 和 BigGAN [5]。</p><ul><li><strong>模型結構的優化</strong></li></ul><p style=text-align:start>生成器和判別器的網絡結構對於訓練過程的穩定性和模型表現至關重要。在 GAN 模型結構的各種改進方法中，最先要提到的是 <strong>DCGAN</strong>（Deep Convalutional GAN）[6]，它首次將卷積神經網絡用到 GAN 中，為 GAN 家族貢獻了一個重要的基準結構。之後比較具有代表性的結構改進包括加入自動編碼器的結構（auto-encoder architecture），比如 VAE-GAN [7]， ALI [8]；以及層次化的結構，例如 Stacked GAN [9] 通過堆疊多個“生成器-判別器-編碼器”來構造層次化結構。也有方法通過在訓練過程中對單個 GAN 進行動態地堆疊以構成層次化結構，例如 Progressive GAN [10] 就僅用一個“生成器-判別器”對，但在訓練過程中逐漸增加網絡的層數，其模型結構如 Fig. 2 所示。</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d34118830e57457bb717e7c7d1ab2826><p class=pgc-img-caption></p></div><p>Figure 2: Progressive GAN 結構示意圖</p><ul><li><strong>訓練過程的優化</strong></li></ul><p style=text-align:start>GAN 的訓練過程實際上是在極高維參數空間中尋找一個非凸優化問題的納什均衡點的過程，該過程常常是很不穩定的。很多文獻中提出了一些針對神經網絡訓練過程的改進方法來提升 GAN 的效果，還有一些是在實際應用中發現的能夠穩定訓練過程的經驗和技巧，如特徵匹配技術 [11]、單邊標籤平滑 [11]、譜歸一化 [12] 等等。</p><h1 class=pgc-h-arrow-right>碩果累累的 GAN</h1><p style=text-align:start>隨著 GAN 在理論上突飛猛進的發展，各種 GAN 在不同領域中的應用也遍地開花。在計算機視覺中的應用包括圖像和視頻的生成、圖像與圖像或文字之間的翻譯、物體檢測、語義分割等。除了圖像領域，GAN 還被應用在<strong>半監督學習、遷移學習、強化學習、多模態學習、特徵學習</strong>等領域。在 GAN 的應用中，除了上面提到的一些偏基礎的改進以外，研究者們往往會根據具體的場景和問題因地制宜地對模型進行進一步的改進和調整。下圖以人臉合成任務為例，列舉了GAN 在不同時期的合成效果。</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2fcba20cf66f420298c2a5d28b0120ed><p class=pgc-img-caption></p></div><p>Figure 3: 基於 GAN 的人臉圖像合成示例 [13]</p><p style=text-align:start>GAN 的故事還有很多，GAN 的未來也非常值得期待。如果讀者們心中還是有對 GAN 的各種問號，或是想了解更多更深入的關於 GAN 的知識，歡迎到《百面深度學習》書中尋找答案。</p><div class=pgc-img><img alt="乘風破浪的 GAN——回顧 GAN 的發展之路" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5116e26223d74fa8b31fefbcd408c6c8><p class=pgc-img-caption></p></div><p><br></p><p><strong>參考文獻：</strong></p><blockquote><p>[1] GOODFELLOW I, POUGET-ABADIE J, MIRZA M, 等. Generative adversarial nets[C]//Advances in Neural Information Processing Systems. 2014: 2672–2680.<br>[2] ARJOVSKY M, CHINTALA S, BOTTOU L. Wasserstein GAN[J]. arXiv preprint arXiv:1701.07875, 2017.<br>[3] LIM J H, YE J C. Geometric GAN[J]. arXiv preprint arXiv:1705.02894, 2017.<br>[4] ZHANG H, GOODFELLOW I, METAXAS D, 等. Self-attention generative adversarial networks[J]. arXiv preprint arXiv:1805.08318, 2018.<br>[5] BROCK A, DONAHUE J, SIMONYAN K. Large scale GAN training for high fidelity natural image synthesis[J]. arXiv preprint arXiv:1809.11096, 2018.<br>[6] RADFORD A, METZ L, CHINTALA S. Unsupervised representation learning with deep convolutional generative adversarial networks[J]. arXiv preprint arXiv:1511.06434, 2015.<br>[7] LARSEN A B L, SØNDERBY S K, LAROCHELLE H, 等. Autoencoding beyond pixels using a learned similarity metric[J]. arXiv preprint arXiv:1512.09300, 2015.<br>[8] DUMOULIN V, BELGHAZI I, POOLE B, 等. Adversarially learned inference[J]. arXiv preprint arXiv:1606.00704, 2016.<br>[9] ZHANG H, XU T, LI H, 等. StackGAN: Text to photo-realistic image synthesis with stacked generative adversarial networks[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 5907–5915.<br>[10] KARRAS T, AILA T, LAINE S, 等. Progressive growing of GANs for improved quality, stability, and variation[J]. arXiv preprint arXiv:1710.10196, 2017.<br>[11] SALIMANS T, GOODFELLOW I, ZAREMBA W, 等. Improved techniques for training GANs[C]//Advances in Neural Information Processing Systems. 2016: 2234–2242.<br>[12] MIYATO T, KATAOKA T, KOYAMA M, 等. Spectral normalization for generative adversarial networks[J]. arXiv preprint arXiv:1802.05957, 2018.<br>[13] GUI J, SUN Z, WEN Y, 等. A review on generative adversarial networks: Algorithms, theory, and applications[J]. arXiv preprint arXiv:2001.06937, 2020.</p></blockquote></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>GAN</a></li><li><a>乘風</a></li><li><a>回顧</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/87271504.html alt=泛CG直播回顧《哪吒》視效導演石超群分享CG新趨勢-虛擬製作 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/25796a7cd2e04f9cb8a97fdbeec46036 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/87271504.html title=泛CG直播回顧《哪吒》視效導演石超群分享CG新趨勢-虛擬製作>泛CG直播回顧《哪吒》視效導演石超群分享CG新趨勢-虛擬製作</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9b8d997c.html alt="2018我們一起來回顧 尼嘉斯的三十年的產品盛典" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/566e000a9e1d489d7966 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9b8d997c.html title="2018我們一起來回顧 尼嘉斯的三十年的產品盛典">2018我們一起來回顧 尼嘉斯的三十年的產品盛典</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d98ab36.html alt=風華高科何時才能乘風破浪？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1336904f79e0423eb016f3762d7a1fa4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d98ab36.html title=風華高科何時才能乘風破浪？>風華高科何時才能乘風破浪？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e438ac8b.html alt="富士通杯回顧系列（103） 快槍戳碎電子計算機 曹薰鉉高歌猛進" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4987a2c48bb46cd8392d1931199148c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e438ac8b.html title="富士通杯回顧系列（103） 快槍戳碎電子計算機 曹薰鉉高歌猛進">富士通杯回顧系列（103） 快槍戳碎電子計算機 曹薰鉉高歌猛進</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/81cbfb45.html alt="富士通杯回顧系列（136） 電子計算機已老化 曹薰鉉再破石田芳夫" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/37ceb98362a3418dbb268ae2aaddd049 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/81cbfb45.html title="富士通杯回顧系列（136） 電子計算機已老化 曹薰鉉再破石田芳夫">富士通杯回顧系列（136） 電子計算機已老化 曹薰鉉再破石田芳夫</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9a9548c2.html alt=仿真軟件10年回顧和展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/d3641be9-ecd5-41a0-af85-b49739d37cf7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9a9548c2.html title=仿真軟件10年回顧和展望>仿真軟件10年回顧和展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/330fd633.html alt=回顧一下己出售的蘭花品種集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/61bc80f7112341baba31f2c609bcd1f0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/330fd633.html title=回顧一下己出售的蘭花品種集>回顧一下己出售的蘭花品種集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e01935fe.html alt=全面回顧：從知識工程到知識圖譜 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/0bd3ad5610cd4559b8d67d52178858ed style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e01935fe.html title=全面回顧：從知識工程到知識圖譜>全面回顧：從知識工程到知識圖譜</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8668225c.html alt=從知識工程到知識圖譜全面回顧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RPUfnTjEp79Eds style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8668225c.html title=從知識工程到知識圖譜全面回顧>從知識工程到知識圖譜全面回顧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9cb8d920.html alt=3日科技熱點回顧：excel中怎麼跳至有內容的最後一個單元格？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8bc1ff70e2a74131a43c9ac9ea424bf3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9cb8d920.html title=3日科技熱點回顧：excel中怎麼跳至有內容的最後一個單元格？>3日科技熱點回顧：excel中怎麼跳至有內容的最後一個單元格？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/af81b582.html alt=亮劍！國運之戰：回顧半導體發達地區的興衰成敗 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/78b4000d4566421bcf99 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/af81b582.html title=亮劍！國運之戰：回顧半導體發達地區的興衰成敗>亮劍！國運之戰：回顧半導體發達地區的興衰成敗</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c749d30b.html alt="19平臺直播 4次亮相 乘風破浪的民族品牌康師傅再獲殊榮" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/S4y6qRl3PkdkkQ style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c749d30b.html title="19平臺直播 4次亮相 乘風破浪的民族品牌康師傅再獲殊榮">19平臺直播 4次亮相 乘風破浪的民族品牌康師傅再獲殊榮</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3a7488ee.html alt="回顧2019 年5個重大宕機事件" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RoQoLi05UkDjd7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3a7488ee.html title="回顧2019 年5個重大宕機事件">回顧2019 年5個重大宕機事件</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/21edb619.html alt=精彩回顧｜上週要聞 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/400e00009c06f81d836f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/21edb619.html title=精彩回顧｜上週要聞>精彩回顧｜上週要聞</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/73d949cb.html alt=全國人大法工委回顧2019年立法工作：已制定法律4件 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RlA1dRpG1Qsi3B style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/73d949cb.html title=全國人大法工委回顧2019年立法工作：已制定法律4件>全國人大法工委回顧2019年立法工作：已制定法律4件</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>