<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習入門第2章：SVM（支持向量機）—理論 | 极客快訊</title><meta property="og:title" content="機器學習入門第2章：SVM（支持向量機）—理論 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/db2b59aa64f64e189449ae9773356bed"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c75c54fc.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c75c54fc.html><meta property="article:published_time" content="2020-10-29T21:13:01+08:00"><meta property="article:modified_time" content="2020-10-29T21:13:01+08:00"><meta name=Keywords content><meta name=description content="機器學習入門第2章：SVM（支持向量機）—理論"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/c75c54fc.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習入門第2章：SVM（支持向量機）—理論</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/db2b59aa64f64e189449ae9773356bed><p class=pgc-img-caption>Coding is but art of thinking than typing.</p></div><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/34b88298c8734d81ada3ec5453fe6d96><p class=pgc-img-caption>A bug in the code is worth two in the documentation.</p></div><p><br></p><p>歡迎來到監督式機器學習的第二個墊腳石。 同樣，本章分為兩個部分。 第1部分（本部分）討論了理論，工作和調整參數。 第2部分（在此），我們將進行小型編碼練習挑戰。</p><p>如果您還沒有閱讀過樸素貝葉斯，我建議您在<a class=pgc-link data-content=mp href="https://www.toutiao.com/i6786627837139878407/?group_id=6786627837139878407" target=_blank>這裡</a>仔細閱讀。</p><h1 class=pgc-h-arrow-right><strong>0.簡介</strong></h1><p>支持向量機（SVM）是由分離超平面正式定義的判別式分類器。 換句話說，給定帶標籤的訓練數據（監督學習），該算法將輸出最優超平面，該超平面將新示例分類。 在二維空間中，此超平面是將平面分為兩部分的線，每一部分位於每一側。</p><p>令人困惑？ 不用擔心，我們將以通俗易懂的方式學習。</p><p>假設您在圖形上得到了兩個標籤類的圖，如圖（A）所示。 您可以為類別決定分隔線嗎？</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7c4d03bad1534d7f89b19462a4d5704f><p class=pgc-img-caption>Image A: Draw a line that separates black circles and blue squares.</p></div><p><br></p><p>您可能想出了類似於下圖（圖B）的內容。 它公平地將兩個類分開。 線左邊的任何點都屬於黑色圓圈類，而右邊的點屬於藍色正方形類。 類別分離。 這就是SVM的工作。 它找出線/超平面（在分隔出類的多維空間中）。 很快，我們將討論為什麼我要寫多維空間。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/bc5bc41e7954408a892004c2ef8de3e6><p class=pgc-img-caption>s Image B: Sample cut to divide into two classes.</p></div><p><br></p><h1 class=pgc-h-arrow-right><strong>1.使它有點複雜...</strong></h1><p>到目前為止，一切都很好。 現在考慮如果我們有如下圖所示的數據怎麼辦？ 顯然，在此x-y平面中沒有線可以將兩個類分開。 那麼我們該怎麼辦？ 我們應用變換並添加一個維度，我們稱之為z軸。 假設z平面上的點值為w =x²+y²。 在這種情況下，我們可以將其作為點到z起點的距離進行操作。 現在，如果我們在z軸上繪圖，則可以看到清晰的分隔線並可以繪製一條線。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f2c46ab9ac744e9285974d53bfc578a6><p class=pgc-img-caption>Can you draw a separating line in this plane?</p></div><p><br></p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f199fc01569f478fa9f42b61f220ee42><p class=pgc-img-caption>plot of zy axis. A separation can be made here.</p></div><p><br></p><p>當我們將這條線轉換回原始平面時，它映射到圓形邊界，如圖E所示。這些轉換稱為核。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b5e8f85ff069487499d7fcff07f35f4e><p class=pgc-img-caption>Transforming back to x-y plane, a line transforms to circle.</p></div><p><br></p><p>值得慶幸的是，您不必每次都對數據集進行猜測/推導。 sklearn庫的SVM實現將其內置。</p><h1 class=pgc-h-arrow-right><strong>2.使它更加複雜…</strong></h1><p>如果數據圖重疊，該怎麼辦？ 或者，如果某些黑點在藍色的內部呢？ 我們應該畫1或2之間的哪條線？</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fbcc545ac8a245b6ad4fc9f95a84fb41><p class=pgc-img-caption>What in this case?</p></div><p><br></p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6553140046c9459daf581b939482e6cd><p class=pgc-img-caption>Image 1</p></div><p><br></p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e79d3bebf6da4326a47e9ea9cc0f6a94><p class=pgc-img-caption>Image 2</p></div><p><br></p><p>您認為哪一個？ 好吧，兩個答案都是正確的。 第一個容忍一些離群點。 第二個嘗試通過完美分區實現零容忍。</p><p>但是，需要權衡取捨。 在實際應用中，為數百萬個訓練數據集找到理想的分類需要大量時間。 如您將在編碼中看到的。 這稱為正則化參數。 在下一節中，我們定義兩個術語正則化參數和gamma。 這些是SVM分類器中的調整參數。 改變這些，我們可以在合理的時間內以更高的精度獲得可觀的非線性分類線。 在編碼練習（本章第二部分）中，我們將看到如何通過調整這些參數來提高SVM的精度。</p><p>另外一個參數是內核。 它定義了我們是否要線性分離。 下一節還將對此進行討論。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/295306d5fe304cedbaec87f33e118360><p class=pgc-img-caption>When somebody asks me for advice.</p></div><p><br></p><h1 class=pgc-h-arrow-right><strong>3.調整參數：內核，正則化，伽瑪和邊距。</strong></h1><p><strong>內核</strong></p><p>通過使用一些線性代數轉換問題，可以完成線性SVM中超平面的學習。 這是內核起作用的地方。</p><p>對於線性核，使用輸入（x）與每個支持向量（xi）之間的點積來預測新輸入的方程式如下：</p><p>f(x) = B(0) + sum(ai * (x,xi))</p><p>這是一個方程，涉及計算訓練數據中所有支持向量與新輸入向量（x）的內積。 必須通過學習算法從訓練數據中估算出係數B0和ai（對於每個輸入）。</p><p>多項式內核可以寫成K（x，xi）= 1 + sum（x * xi）^ d，指數寫成K（x，xi）= exp（-gamma * sum（（x —xi²）））。</p><p>多項式和指數核可計算出較高維的分隔線。 這稱為內核技巧</p><p><strong>正則化</strong></p><p>正則化參數（在python的sklearn庫中通常稱為C參數）告訴SVM優化，您要避免避免對每個訓練示例進行錯誤分類的程度。</p><p>對於較大的C值，如果該超平面在使所有訓練點正確分類方面做得更好，則優化將選擇一個較小邊距的超平面。 相反，很小的C值將導致優化器尋找較大利潤的分離超平面，即使該超平面對更多點進行了錯誤分類。</p><p>下面的圖像（與第2節中的圖像1和圖像2相同）是兩個不同的正則化參數的示例。 左一由於歸一化值較低而分類錯誤。 更高的價值會帶來如正確的結果。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/701eba88cd5a4c95af726d3434d74519><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0bff672170224ff5b389062c2f7124c3><p class=pgc-img-caption>Left: low regularization value, right: high regularization value</p></div><p><br></p><h1 class=pgc-h-arrow-right><strong>Gamma伽瑪</strong></h1><p>gamma參數定義單個訓練示例的影響力達到的程度，低值表示"遠"，高值表示"接近"。 換句話說，對於較低的伽瑪係數，在計算分隔線時應考慮遠離合理的分隔線的點。 高伽馬意味著在計算中考慮接近合理線的點。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0514d33bf3be4d06a029cf5d27958653><p class=pgc-img-caption>High Gamma</p></div><p><br></p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/71aca5ae515240ad8a935b358ecd3b26><p class=pgc-img-caption>Low Gamma</p></div><h1 class=pgc-h-arrow-right><strong>Margin餘量</strong></h1><p>最後是SVM分類器的最後一個非常重要的特徵。 支持核心的SVM試圖獲得良好的利潤。</p><p>邊距是最接近類別點的線的分隔。</p><p>良好的餘量是兩個類之間的差距較大的一個。 下圖給出了良好和不良邊距的直觀示例。 足夠的餘量可以使這些點處於各自的類中，而不會交叉到其他類。</p><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/690de1c230044baaac2c4a147bdd0857><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=機器學習入門第2章：SVM（支持向量機）—理論 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/23faafb1b679498e927f9b94d7525e97><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>4.在本章的下一部分中，</strong></h1><p>在下一部分（此處）中，我們將調整和播放調整參數，並使用python的sklearn庫為SVM分類器（也稱為SVC）實現一個小型項目。 我們將結果與樸素貝葉斯分類器進行比較。 在此處查看編碼部分：</p><h1 class=pgc-h-arrow-right><strong>5.結論</strong></h1><p>我希望本節對理解SVM分類器的工作有所幫助。 如果您有任何意見，建議或建議，請在下方寫下來。</p><p>(本文翻譯自Savan Patel的文章《Chapter 2 : SVM (Support Vector Machine) — Theory》，參考：https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>入門</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9b52b0.html alt=機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a6894d2d1ea64a8eb3bad2b892648639 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9b52b0.html title=機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼）>機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4b5cbda.html alt=機器學習入門：偏差和方差 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4d7bca8189b4528b0f564ee473d2a68 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4b5cbda.html title=機器學習入門：偏差和方差>機器學習入門：偏差和方差</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2d4007c7.html alt=“黑客”入門學習之“Windows組策略” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ea21244d5f5c420ebef29650f3fafd1c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2d4007c7.html title=“黑客”入門學習之“Windows組策略”>“黑客”入門學習之“Windows組策略”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c914526c.html alt=新手入門PLC，掌握學習方法是關鍵 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15355275026304e8d787f10 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c914526c.html title=新手入門PLC，掌握學習方法是關鍵>新手入門PLC，掌握學習方法是關鍵</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>