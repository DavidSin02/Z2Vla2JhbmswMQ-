<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>日均TB級數據，攜程支付統一日誌框架 | 极客快訊</title><meta property="og:title" content="日均TB級數據，攜程支付統一日誌框架 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/cc9239c0fc84441eb2792791f3fd4550"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/c93d5a52.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/c93d5a52.html><meta property="article:published_time" content="2020-10-29T21:13:10+08:00"><meta property="article:modified_time" content="2020-10-29T21:13:10+08:00"><meta name=Keywords content><meta name=description content="日均TB級數據，攜程支付統一日誌框架"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/c93d5a52.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>日均TB級數據，攜程支付統一日誌框架</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>一、背景</h1><p style=text-align:justify>支付中心作為攜程集團公共部門，主要負責的業務包括交易、實名綁卡、賬戶、收單等，由於涉及到交易相關的資金流轉以及用戶實名認證，部分用戶操作環節的中間數據應內控/審計要求需要長時間保存。當前研發應用多，日誌量大、格式各異，對於日誌的存儲和使用產生較大的挑戰，故支付數據與研發團隊群策群力，共同開發了一套統一日誌框架。</p><h1 class=pgc-h-arrow-right>二、總體架構圖</h1><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cc9239c0fc84441eb2792791f3fd4550><p class=pgc-img-caption></p></div><p style=text-align:justify>核心模塊包括：日誌生產、日誌採集、日誌解析，其中調用流程如下：</p><p style=text-align:justify>1）研發應用/服務接入基於log4j2擴展的統一日誌組件，將日誌拋送至kafka。</p><p style=text-align:justify>2）週期性啟動消費kafka topic的camus job將日誌寫入hdfs。</p><p style=text-align:justify>3）T+1啟動MR job讀取camus寫入的hdfs內容並load到hive表。</p><h1 class=pgc-h-arrow-right>三、日誌生產-統一日誌組件</h1><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/724644f715ca4067bf70a6c6adaccd44><p class=pgc-img-caption></p></div><p style=text-align:justify>支付研發基於log4j2自定義了多個Appender，將應用日誌以服務調用形式拋送至kafka，並被log_process_service 服務統一處理並提交至攜程常用基礎日誌框架如：CLOG、CAT、ES，各應用無需關心公司日誌框架，統一由日誌平臺處理。</p><p style=text-align:justify>其優點：</p><ul><li>不同日誌框架對應著不同的Appender，方便進行日誌框架接入的擴展。</li><li>採用AOP編程，對於接入的業務侵入性小，接入簡單。</li><li>定義了豐富的java註解，便於日誌配置化輸出，其中可打印日誌包括但不限於：類名、方法名、方法入參、返回值、異常等，支持敏感字段脫敏。</li></ul><p style=text-align:justify>存在的問題：</p><ul><li>日誌格式不規範：研發應用數百個，研發人員較多，日誌格式差異大，給數據分析和使用帶來巨大挑戰。</li><li>存儲時長短：當前公司在線CLOG存儲系統只能查詢最近幾天數據、ES保存稍長一段時間數據且不支持批量查詢，基礎離線CLOG hive表由於數據量巨大，僅能做到T+2，無法滿足T+1的報表需求。</li></ul><p style=text-align:justify>故支付數據團隊在研發團隊統一日誌組件的基礎上，結合數據分析和數據存儲生命週期開發了統一日誌框架。</p><p style=text-align:justify><strong>3.1 統一日誌-埋點設計</strong></p><p style=text-align:justify>支付研發團隊負責數百個服務或應用，支持的業務包括：路由、鑑權、免密、卡服務、訂單、錢包實名、電子支付等，不同的業務又可拆分app、h5、online、offline等項目，整合這些數據是個極大的挑戰。如果各系統研發埋點任意指定，會給BI數據分析帶來極大的困難，數據分析準確性難以得到保障，故支付數據基於業務特點定義了一套統一日誌埋點規範。</p><p style=text-align:justify>字段定義主要是基於日常分析需求，致力於簡化數據的使用，故總體原則為json形式，當前原始日誌有兩部分組成：tag/message，其中tag數據結構為Map，關鍵數據一般是通過tag內的數據進行檢索，明細數據通過message進行檢索，tag與message的組成格式為：[[$tag]]$message，目前標準字段包括兩類：規範性字段和通用性字段。</p><p style=text-align:justify>3.1.1 規範性字段格式</p><p style=text-align:justify>規範性字段需要應用研發一定程度的參與，提供符合字段命名的類和方法。部分字段名稱及定義如下：</p><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/06c5fc3595394415912f75620eceacd2><p class=pgc-img-caption></p></div><p style=text-align:justify>其中tag可以靈活填充，主要擴展字段如下：</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3832e45479a34d8e9ed125ca64b9d77c><p class=pgc-img-caption></p></div><p style=text-align:justify>3.1.2 通用字段格式</p><p style=text-align:justify>日誌框架能夠自動獲取屬性，無需研發編碼，即可打印。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2be306bc0d684854941f664bbd0345aa><p class=pgc-img-caption></p></div><p><strong>3.2 分區/分桶字段的定義</strong></p><p>當前離線數據分析基於hive引擎，hive的分區分桶設計極大的影響了查詢性能，特別是在日誌量巨大的場景下，分區字段的選擇尤為關鍵。如：用戶進入支付收銀臺可能會有上百個場景，而每種場景下會有多次服務調用，其中不同場景下服務調用頻率差異很大，佔用的空間差異也較大，故針對每種場景分配一個唯一的場景號，通過場景號進行分區，可以高效的進行數據分析，而過多的分區也可能導致較多的小文件，對hadoop namenode產生較大的影響，此時結合分桶能夠達到優化查詢效率且避免分區無限制野蠻增長產生眾多過多小文件的問題。</p><h1 class=pgc-h-arrow-right>四、日誌採集</h1><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/926d8a0c8d2e4478aae9f692c7c47f1c><p class=pgc-img-caption></p></div><p style=text-align:justify>日誌採集框架基於LinkedIn的開源項目Camus，Camus使用MapReduce讀取kafka數據然後寫入hdfs，由於無reduce階端，所有數據處理及寫入都在Map側，很少會發生數據傾斜，Camus具有接入簡單，方便擴展，故我們進行了二次開發，以滿足當前業務的需要：</p><ul><li>自定義decoder/partitioner，原生的decoder/partitioner支持的hdfs落地路徑主要基於日期，較為粗糙，無法適應業務的需要。故自定義decoder 抽取原始日誌分區字段，然後代入partitioner中，生成具有業務含義的hdfs輸出路徑，為特定時間範圍數據回刷提供了高效的解決方案。</li></ul><ul><li>自定義provider，原生的StringRecordWriterProver僅支持text文件方式落地，佔用空間大、壓縮後無法並行切分，容易錯列錯行，而orc格式數據，有效的節約了hdfs佔用空間，查詢效率高且可以切分，有利於日誌解析job的高效執行。其中在配置Camus job過程中需要關注如下問題：</li></ul><p><strong>4.1 camus 任務執行</strong></p><ul><li>執行頻率設置</li></ul><pre><code>Error: java.io.IOException: target exists.the file size(614490 vs 616553) is not the same.</code></pre><p style=text-align:justify>由於kafka消息保存天數有限和單個分區size有限(Server 配置：log.retention.bytes)，攜程側為3天和10G，如果camus同步kafka頻率較低時，可能會出現數據丟失，故需要根據日誌量大小，設置camus 調度任務的執行頻率，防止數據丟失。</p><ul><li>任務重疊執行</li></ul><pre><code>Error: java.io.IOException: target exists.the file size(614490 vs 616553) is not the same.</code></pre><p style=text-align:justify>camus從kafka 讀取數據，任務要以單例形式執行，任務執行完成後才會更新kafka的offset，若一個任務執行了多次，就會導致數據大小無法對齊，此時需要刪除配置路徑下的所有數據後重新啟動任務，即可完成修復。</p><p><strong>4.2 如何控制camus落地文件的大小</strong></p><p style=text-align:justify>當kafka各partition數據寫入量不平衡時，由於各partition會寫入一個hdfs文件中，如果研發日誌集中寫入kafka某個partition，會導致這個partition對應的hdfs文件佔用空間特別大，如果恰巧這個文件是不可切分的，極端情況下會導致只有一個線程去解析這個大文件，降低了數據讀寫的併發度，拉長了數據解析時間，遇到這種問題的解決辦法是：</p><ul><li>臨時解決方案：研發日誌分散寫入kafka partition，不要導致某類數據集中寫入一個partition；</li><li>高效解決方案：數據側採用可切分的輸入格式，進行數據切分；</li></ul><p><strong>4.3 寫入orc文件格式注意事項</strong></p><ul><li>orc寫入timeout</li></ul><pre><code>AttemptID:attempt_1587545556983_2611216_m_000001_0 Timed out after 600 secs</code></pre><p style=text-align:justify>orc文件寫入速度較text文件會慢很多，如果同時寫入的的文件較多或者內存回收佔用時間較長，會導致map方法在600秒內沒有讀、寫或狀態更新，job會被嘗試終結，解決方法是調高默認的task超時時間，由10分鐘調高到20分鐘。</p><pre><code>mapreduce.task.timeout=1200000</code></pre><ul><li>OOM 內存溢出</li></ul><pre><code>beyond physical memory limits. Current usage: 2.5 GB of 2.5 GB physical memory used; 4.2 GB of 5.3 GB virtual memory used. Killing container.</code></pre><p style=text-align:justify>在orc寫文件的時候如果出行較多的OOM，此時需要加大map執行的內存。</p><pre><code>mapreduce.map.memory.mb=8096mapreduce.map.java.opts=-Xmx6000m</code></pre><h1 class=pgc-h-arrow-right>五、統一日誌-解析</h1><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cead0dc87be94a0ab74c41d97528b35a><p class=pgc-img-caption></p></div><p>鑑於日誌解析工作主要集中在MapReduce的Map側，而Map側通過參數調整能夠很容易控制map的個數，以提高數據解析的併發度，MapReduce主要分為：intputformat、map、shuffle、reduce等幾個核心階段，通過優化各階段的執行時間，可以顯著提高日誌解析的速度。</p><p><strong>5.1 inputsplit優化</strong></p><p>MR job中影響map的個數主要有：</p><ul><li>文件個數：如果不採用CombineFileInputFormat，那麼不會進行小文件合併，每個文件至少有一個map處理，當小文件太多時，頻繁啟動和回收線程也會對性能產生影響，同時對集群其它job資源分配產生影響。</li><li>文件屬性：當文件較大且可切分時，系統會生成多個map處理大文件，inputsplit塊按照MR最小單元進行文件切割(split)，並且一個split對應一個MapTask。</li></ul><p>前期日誌解析程序的性能較高，一天的全量日誌解析約25分鐘，中間有段時間任務執行時間從25分鐘延遲到4個小時，原因是研發將大量訂單號為空的日誌寫入到指定的partition中，日誌量巨大，導致其中少量map在讀取大文件時執行時間特別長。</p><p>經過分析發現text+snappy 文件無法切分，只能夠被一個map處理，將camus落地數據格式從text+snappy換為orc+snappy格式，同時開發了支持orc文件格式的CombineFileInputFormat，既減少了小文件對hadoop計算資源果斷的佔用也提高了job的併發程度。</p><p><strong>5.2 shuffle優化</strong></p><p>使map的輸出能夠更加均勻的映射到reduce側，由於默認的分區策略是對map的輸出key hash取reduce個數的模，容易導致數據傾斜，解決辦法是在key上面增加時間戳或者重寫partition函數。</p><p><strong>5.3 批量日誌解析</strong></p><p>當前MR的輸出會作為hive外表的數據源，hive表會按照業務過程進行分區，所有數據的解析結果路徑為：日期+業務過程，而業務過程可能有數百個，採用了MultipleInputs/MultipleOutputs 能夠在一個mapreduce job中實現多輸入多輸出的功能，以適應業務自定義解析，並歸一化後統一拋到reduce側。</p><p>5.3.1 空文件生產</p><p>在使用的過程中會出現生成眾多臨時小文件及生成size 為0的小文件，增加了hdfs namenode內存壓力，同時空文件也會導致spark表查詢失敗，可通過LazyOutputFormat進行修復。</p><p>5.3.2 文件重複創建</p><p>MultipleOutputs輸出文件一般以name-r-nnnnn的格式進行命名，其中name與程序指定的文件名有關，nnnnn表示reduce任務號。在處理數據較多時，可能會存在reduce側反覆創建已存在的文件，導致任務長時間運行而不能成功，中間生成了大量小文件，對hadoop namenode產生較大壓力，影響整個集群響應時間。</p><p>解決方案為：在reduce側進行數據寫入時，需要對exception進行捕捉，一旦出現數據寫入exception，即將對應的寫入reduce文件刪除並終止程序，由於MR支持高可用，當一個reduce taks 失敗後會自動重試，重試一定次數依然不能夠成功就會導致整個任務失敗，每次重試避免了不停的重複創建已存在的文件，引起NN響應時間極速下降。</p><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e3630e43a6114d4888b724a0d7e0df90><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=日均TB級數據，攜程支付統一日誌框架 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ddad9a10eeca492f80883794207d43e0><p class=pgc-img-caption></p></div><p><strong>5.4 reduce個數調整</strong></p><p>目前日誌解析的reduce側主要用於orc數據寫入，當reduce個數較少時，會導致reduce內存溢出，而reduce個數較多時，可能會導致非常多的小文件且佔用集群過多資源，可以通過計算map側輸入文件的個數及總佔用空間，動態計算需要的reduce個數，以達到合理利用資源的目的。</p><h1 class=pgc-h-arrow-right>六、日誌治理</h1><p>日誌落地導致的一個問題是存儲空間增長迅速，當前支付中心日均新增ORC壓縮原始數據量TB級別且還在持續增長中。</p><p>支付數據側根據研發、產品的需求對不同類型日誌進行分級，對於不同類別的日誌設置不同的存儲週期，主要劃分為：研發排障日誌、審計日誌、數據分析日誌等；同時在camus將日誌寫入hdfs時，由於按照業務分區進行落地，導致生成了大量小文件，需要對這些小文件進行合併並且設置TTL，避免對hadoop namenode產生較大的影響。</p><h1 class=pgc-h-arrow-right>七、總結與展望</h1><p>目前日均TB級數據解析時間在30分鐘內完成，後期計劃將日誌系統導入clickhouse等對實時要求高的場景共運營使用，以支持業務精細化運營和分析。</p><p><strong>【作者簡介】</strong>英明，攜程數據研發專家，負責支付離線數據倉庫建設及BI業務需求，對並行計算、大數據處理及建模等有濃厚興趣。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>TB</a></li><li><a>數據</a></li><li><a>攜程</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html alt=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3e507bb24abc482fb28df1121a7ee097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html title=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出>數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html alt="數據科學家常犯的 10 個編程錯誤" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html title="數據科學家常犯的 10 個編程錯誤">數據科學家常犯的 10 個編程錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html alt=數據科學家常遇到的10個錯誤 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/59f660bac8b541888e71459b604ba733 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html title=數據科學家常遇到的10個錯誤>數據科學家常遇到的10個錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html alt=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f120ed2c1ed549e39bfa60bb3a86d591 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html title=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定>WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html alt="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7aa6ee1b961f467e8090ed56f45c110f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html title="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成">多列數據合併一列，還在用數據透視就out了，用=號只要三步完成</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html alt=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3609570de59a49a9be5667dd9a637f65 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html title=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心>數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html alt=「數據結構」Hash表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/617a6d43032e4efbac6b996c9bb5ab11 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html title=「數據結構」Hash表>「數據結構」Hash表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html alt=備戰秋招——算法與數據結構（5） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ab6859411bd8435bb2616d6fef468556 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html title=備戰秋招——算法與數據結構（5）>備戰秋招——算法與數據結構（5）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html alt=懂了數據結構框架思維，一切算法不過是紙老虎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad2c8a60d9634e0aa36b5d8a664de355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html title=懂了數據結構框架思維，一切算法不過是紙老虎>懂了數據結構框架思維，一切算法不過是紙老虎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e03941dc.html alt=數據結構一(哈希表)想進大廠的必備知識點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/86ad7a2f62cc48f98bbe53b42ca4bf9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e03941dc.html title=數據結構一(哈希表)想進大廠的必備知識點>數據結構一(哈希表)想進大廠的必備知識點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/385a3c55.html alt="數據結構中的 Hash 表" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/0e43812c-6f05-4cf6-af7e-18011d0a316a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/385a3c55.html title="數據結構中的 Hash 表">數據結構中的 Hash 表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html alt=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5d4a0000046e1bea8b90 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html title=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？>Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/46925324.html alt=什麼，每組數據都要直觀顯示出趨勢？別慌，迷你圖來幫你 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dacc2e5d44c547fbb97f666290862260 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/46925324.html title=什麼，每組數據都要直觀顯示出趨勢？別慌，迷你圖來幫你>什麼，每組數據都要直觀顯示出趨勢？別慌，迷你圖來幫你</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0f6d007f.html alt=數據顯示，這幾組“情商”低的表現可得小心了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/aaa6491f8e334aa1a7dd2a3904f423c7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0f6d007f.html title=數據顯示，這幾組“情商”低的表現可得小心了>數據顯示，這幾組“情商”低的表現可得小心了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4646402b.html alt=為什麼Excel數據透視表不能按日期創建組？教你輕鬆解決 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d0ad14c0ac504f878152ad79a041b645 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4646402b.html title=為什麼Excel數據透視表不能按日期創建組？教你輕鬆解決>為什麼Excel數據透視表不能按日期創建組？教你輕鬆解決</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>