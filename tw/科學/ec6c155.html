<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ECCV 2020附代碼論文合集(目標檢測） | 极客快訊</title><meta property="og:title" content="ECCV 2020附代碼論文合集(目標檢測） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/31e617a451a4464484945f89ca231e68"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/ec6c155.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/ec6c155.html><meta property="article:published_time" content="2020-10-29T20:56:20+08:00"><meta property="article:modified_time" content="2020-10-29T20:56:20+08:00"><meta name=Keywords content><meta name=description content="ECCV 2020附代碼論文合集(目標檢測）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/ec6c155.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ECCV 2020附代碼論文合集(目標檢測）</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/31e617a451a4464484945f89ca231e68><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p>上次我們給大家帶來了關於CNN與圖像分割主題的論文，本次的主題是目標檢測，包含2D、3D的目標檢測，旋轉目標檢測，視頻目標檢測，同樣每篇論文都附帶論文代碼，大家在閱讀論文的同時也可親自動手實踐，快來看看吧！</p><p><br></p><h1 class=pgc-h-arrow-right>目標檢測</h1><p style=text-align:center><strong><br></strong></p><p>目標檢測是與計算機視覺與圖像處理的計算機技術，處理的是在數字圖像和視頻中檢測出的特定類別的語義對象（如人類、建築物或汽車）的實例。目標檢測的研究領域包括人臉檢測和行人檢測。目標檢測在計算機視覺的許多領域都有應用，包括圖像檢索和視頻監控 。</p><p><br></p><h1 class=pgc-h-arrow-right>2D目標檢測</h1><p><strong><br></strong></p><p><em><strong>1 Dense RepPoints: Representing Visual Objects with Dense Point Sets</strong></em><br><strong>作者：</strong>Yang Ze,Xu Yinghao,Xue Han,Zhang Zheng,Urtasun Raquel,Wang Liwei,Lin Stephen,Hu Han<br><strong>機構：</strong>北京大學，香港中文大學<br><strong>簡介：</strong>本文提出了一種對象表示法，稱為dense Rep Points，用於靈活而詳細地建模對象外觀和幾何體。與邊界框的粗幾何定位和特徵提取不同，DenseRepPoints自適應地將一組密集的點分佈到對象上具有重要幾何意義的位置，為對象分析提供信息提示。技術的發展是為了解決與監督訓練從圖像片段和符號密集點集相關的挑戰，並使這種廣泛的表示在理論上是可行的。此外，該表示的多功能性被用於在多個粒度級別上建模對象結構。稠密的表示點顯著提高了面向幾何的可視化理解任務的性能，包括在具有挑戰性的COCO基準測試中對象檢測的1:6AP增益。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3475fd6f304f4b7daf14ccb1641adde3><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5e0333623a55aca24ec3eeed/<br><strong>代碼地址：</strong>https://github.com/justimyhxu/Dense-RepPoints</p><p style=text-align:justify><br></p><p style=text-align:justify><br><em><strong>2 Corner Proposal Network for Anchor-free, Two-stage Object Detection</strong></em><br><strong>作者：</strong>Kaiwen Duan,Lingxi Xie,Honggang Qi,Song Bai,Qingming Huang,Qi Tian<br><strong>機構：</strong>中國科學院大學，華為<br><strong>簡介：</strong>目標檢測的目標是確定目標在圖像中的類別和位置。本文提出了一種新的無錨的兩階段框架，該框架首先通過尋找潛在的角點組合來提取多個目標方案，然後通過獨立的分類階段為每個方案分配一個類別標籤。作者證明這兩個階段分別是提高查全率和查準率的有效解決方案，並且可以集成到一個端到端網絡中。他們的方法被稱為角點建議網絡（Corner proposition Network，CPN），它具有檢測不同尺度對象的能力，並且避免了被大量的誤報建議所迷惑。在MS-COCO數據集上，CPN達到了49.2%的AP，這在現有的目標檢測方法中具有競爭力。CPN同樣適用於計算效率的場景，在26.2/43.3fps時，CPN的AP達到41.6%/39.7%，超過了大多數具有相同推理速度的競爭對手。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3197ba7fc7674e0983b65a605b5cc130><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f213ebe91e011f62007af97/<br><strong>代碼地址：</strong>https://github.com/Duankaiwen/CPNDet</p><p><br></p><p><br><em><strong>3 BorderDet: Border Feature for Dense Object Detection</strong></em><br><strong>作者：</strong>Han Qiu,Yuchen Ma,Zeming Li,Songtao Liu,Jian Sun<br><strong>機構：</strong>曠視科技，西安交通大學<br><strong>簡介：</strong>密集型目標探測器依賴於滑動窗口模式，它可以在規則的圖像網格上預測目標。同時，採用網格點上的特徵映射生成邊界盒預測。點特徵使用方便，但可能缺少精確定位的明確邊界信息。本文提出了一種簡單高效的邊界對齊算子，從邊界的極值點提取“邊界特徵”，以增強點特徵。在BorderAlign的基礎上，作者設計了一種新的檢測體系結構BorderDet，它明確地利用了邊界信息來實現更強的分類和更精確的定位。使用ResNet-50主幹，他們的方法將單級探測器FCOS提高了2.8 AP增益（38.6 v.s.41.4）。通過ResNeXt-101-DCN主幹，他們的BorderDet獲得了50.3 AP，優於現有的最新方法。</p><p><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/488d7e1c896f47e5943ca21f2bf929c9><p class=pgc-img-caption></p></div><p><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f19565a91e01182befeea14/<br><strong>代碼地址：</strong>https://github.com/Megvii-BaseDetection/BorderDet</p><p style=text-align:justify><br></p><p style=text-align:justify><br><em><strong>4 Multi-Scale Positive Sample Refinement for Few-Shot Object Detection</strong></em><br><strong>作者：</strong>Jiaxi Wu,Songtao Liu,Di Huang,Yunhong Wang<br><strong>機構：</strong>北京航空航天大學<br><strong>簡介：</strong>少鏡頭目標檢測（FSOD）有助於檢測器適應訓練實例較少的看不見的類，在手動標註耗時或數據採集受限的情況下非常有用。與以往利用少量鏡頭分類技術來促進FSOD的嘗試不同，本研究強調了處理尺度變化問題的必要性，該問題由於樣本分佈的獨特性而具有挑戰性。為此，作者提出了一種多尺度正樣本優化（MPSR）方法來豐富FSOD中的目標尺度。它生成多尺度正樣本作為目標金字塔，並在不同尺度上對預測進行細化。作者通過將其作為一個輔助分支集成到流行的快速R-CNN和FPN架構中，展示了它的優勢，提供了一個強大的FSOD解決方案。在PASCAL-VOC和MS-COCO上進行了多個實驗，結果表明，該方法取得了最新的結果，顯著優於其他同類方法，顯示了其有效性。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6aaad78223894789a4ac18c46de86848><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f16b7ca91e011b48ae9413e/<br><strong>代碼地址：</strong>https://github.com/jiaxi-wu/MPSR</p><p><br></p><p><br><em><strong>5 PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments</strong></em><br><strong>作者：</strong>Zhiming Chen,Kean Chen,Weiyao Lin,John See,Hui Yu,Yan Ke,Cong Yang<br><strong>機構：</strong>擴博智能，上海交通大學<br><strong>簡介：</strong>使用定向包圍盒（OBB）進行目標檢測，可以減少與背景區域的重疊，從而更好地定位旋轉對象。現有的OBB方法大多建立在水平包圍盒探測器上，通過引入一個額外的角度維度，通過距離損失來優化。然而，由於距離損失只會最小化OBB的角度誤差，並且它與IoU鬆散相關，因此它對高寬高比的對象不敏感。因此，提出了一種新的損失，像素IoU（PIoU）損失，利用角度和IoU進行精確的OBB迴歸。PIoU損失由IoU度量導出，採用像素形式，簡單易行，適用於水平和定向包圍盒。為了證明其有效性，作者評估了基於錨定和無錨框架的PIoU損失。實驗結果表明，PIoU損耗可以顯著提高OBB探測器的性能，特別是對於高寬高比和複雜背景的目標。此外，以前的評估數據集不包括對象具有高寬高比的場景，因此引入了一個新的數據集Retail50K，以鼓勵社區採用OBB檢測器來適應更復雜的環境。</p><p><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2c86c881e234017875f12c8c1eb766d><p class=pgc-img-caption></p></div><p><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f16be7c91e011b48ae94206/<br><strong>代碼地址：</strong>https://github.com/clobotics/piou</p><p><br></p><p><br><em><strong>6 Boosting Weakly Supervised Object Detection with Progressive Knowledge Transfer</strong></em><br><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f116cbb91e011264d4475a6/<br><strong>代碼地址：</strong>https://github.com/mikuhatsune/wsod_transfer</p><p><br></p><p><br><em><strong>7 Probabilistic Anchor Assignment with IoU Prediction for Object Detection</strong></em><strong><br>論文鏈接：</strong>https://www.aminer.cn/pub/5f11708491e011264d44761b/<br><strong>代碼地址：</strong>https://github.com/kkhoot/PAA</p><p><br></p><p><br><em><strong>8 HoughNet: Integrating near and long-range evidence for bottom-up object detection</strong></em><br><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f044d8d91e0114d4aaa49dc/<br><strong>代碼地址：</strong>https://github.com/nerminsamet/houghnet<br></p><p><em><strong>9 OS2D: One-Stage One-Shot Object Detection by Matching Anchor Features</strong></em><br><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5e71f49891e0115656f5cfcb/<br><strong>代碼地址：</strong>https://github.com/aosokin/os2d<br></p><p><em><strong>10 End-to-End Object Detection with Transformers</strong></em><br><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5ece3bcb91e011dc23c22581/<br><strong>代碼地址：</strong>https://github.com/facebookresearch/detr<br></p><p><em><strong>11 Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training</strong></em><br><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5e96db3891e01129d1a04120/<br><strong>代碼地址：</strong>https://github.com/hkzhang95/DynamicRCNN</p><p><br></p><h1 class=pgc-h-arrow-right>遙感旋轉目標檢測</h1><p style=text-align:justify><strong><br></strong></p><p style=text-align:justify><em><strong>1 Arbitrary-Oriented Object Detection with Circular Smooth Label</strong></em><strong><br>作者：</strong>Yang Xue,Yan Junchi<br><strong>機構：</strong>上海交通大學<br><strong>簡介：</strong>任意方向的目標檢測由於在航空圖像、場景文本、人臉等方面的重要性，近年來在視覺領域引起了越來越多的關注。本文研究了現有的基於迴歸的旋轉檢測器存在邊界不連續的問題，這是由角週期性或角點排序直接引起的。通過仔細研究，作者發現其根本原因是理想的預測超出了規定的範圍。作者設計了一個新的旋轉檢測基線，通過將角度預測從迴歸問題轉化為一個精度損失很小的分類任務來解決邊界問題，與以往使用粗粒度旋轉檢測的工作相比，設計了高精度的角度分類。他們還提出了一種圓形平滑標籤（CSL）技術來處理角度的週期性，並增加了對相鄰角的誤差容限。進一步介紹了CSL中的四個窗口函數，並探討了不同窗口半徑對檢測性能的影響。對DOTA、HRSC2016以及場景文本數據集ICDAR2015和MLT進行了大量的實驗和可視化分析，證明了該方法的有效性。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4cf2835d14aa4186a00156b52f1d3356><p class=pgc-img-caption></p></div><p><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5e6cacc991e01145573c766b/<br><strong>代碼地址：</strong>https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow</p><p style=text-align:justify><br></p><h1 class=pgc-h-arrow-right>3D目標檢測</h1><p><br></p><p><br><em><strong>1 Rethinking Pseudo-LiDAR Representation</strong></em><br><strong>作者：</strong>Xinzhu Ma,Shinan Liu,Zhiyi Xia,Hongwen Zhang,Xingyu Zeng,Wanli Ouyang<br><strong>機構：</strong>悉尼大學，商湯科技<br><strong>簡介：</strong>最近提出的基於偽激光雷達的三維探測器大大提高了單目/立體三維探測任務的基準。然而，研究界對其潛在的機制仍不甚清楚。本文對偽激光雷達的數據表示進行了深入研究，發現偽激光雷達表示的有效性來自於座標變換，而不是數據表示本身。在此基礎上，作者設計了一種基於圖像的CNN探測器Patch-Net，它是一種更通用的、可以實例化為基於偽激光雷達的3D探測器。此外，本文的PatchNet中的偽激光雷達數據被組織為圖像表示，這意味著現有的2D CNN設計可以很容易地用於從輸入數據中提取深層特徵並提高3D檢測性能。作者在具有挑戰性的KITTI數據集上進行了大量的實驗，其中提出的PatchNet優於所有現有的基於偽激光雷達的同類產品。</p><p><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/28b5bc7a9beb4f2cac3ef98e6e87ad7d><p class=pgc-img-caption></p></div><p><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f33bd4591e011861cfa0fe6/<br><strong>論文地址：</strong>https://github.com/xinzhuma/patchnet</p><p style=text-align:justify><br></p><p style=text-align:justify><br><em><strong>2 Pillar-based Object Detection for Autonomous Driving</strong></em><br><strong>作者：</strong>Yue Wang,Alireza Fathi,Abhijit Kundu,David Ross,Caroline Pantofaru,Tom Funkhouser,Justin Solomon<br><strong>機構：</strong>MIT，Google<br><strong>簡介：</strong>本文提出了一種簡單靈活的自動駕駛目標檢測框架。在觀察到該應用中的點雲非常稀疏的基礎上，提出了一種實用的基於柱的方法來解決錨定引起的不平衡問題。特別地，本文的算法在多視點特徵學習中加入了柱面投影，預測了每個柱而不是每個點或每個錨點的邊界盒參數，並且包含了一個對齊的柱到點投影模塊來提高最終預測。本文的無錨方法避免了與以往方法相關的超參數搜索，簡化了三維目標檢測，同時顯著提高了最先進的水平。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4d00911d73c745c78cf7d7b09f610959><p class=pgc-img-caption></p></div><p><br></p><p><strong>論文鏈接:</strong>https://www.aminer.cn/pub/5f16d62b91e011b48ae944e9/<br><strong>代碼地址：</strong>https://github.com/WangYueFt/pillar-od</p><p><br></p><p><br><em><strong>3 EPNet: Enhancing Point Features with Image Semantics for 3D Object Detection</strong></em><br><strong>作者：</strong>Tengteng Huang,Zhe Liu,Xiwu Chen,Xiang Bai<br><strong>機構：</strong>華中科技大學<br><strong>簡介：</strong>本文針對三維檢測任務中的兩個關鍵問題，即多傳感器（即LiDAR點雲和相機圖像）的開發以及定位和分類置信度之間的不一致性。為此，作者提出了一種新的融合模塊，在不需要任何圖像註釋的情況下，對具有語義特徵的點特徵進行逐點增強。此外，使用一致性強制損失來明確鼓勵本地化和分類可信度的一致性。作者設計了一個端到端的可學習框架EPNet來集成這兩個組件。在KITTI和SUN-RGBD數據集上進行的大量實驗證明了EPNet優於最先進的方法。</p><p><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b5e8d146e40643b8a9dbbd7322c7db1b><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p><strong>論文鏈接：</strong>https://www.aminer.cn/pub/5f156bfa91e011d7db223ac2/<br><strong>代碼地址：</strong>https://github.com/happinesslz/EPNet</p><p><br></p><h1 class=pgc-h-arrow-right>視頻目標檢測</h1><p style=text-align:justify><strong><br></strong></p><p style=text-align:justify><em><strong>1 Learning Where to Focus for Efficient Video Object Detection</strong></em><br><strong>作者：</strong>Zhengkai Jiang,Y. Liu,Ceyuan Yang,Jihao Liu, Peng Gao,Qian Zhang,Shiming Xiang,C. Pan<br><strong>機構：</strong>騰訊<br><strong>簡介：</strong>將現有的基於圖像的檢測器轉移到視頻中是非常重要的，因為部分遮擋、罕見姿勢和運動模糊會導致幀質量下降。以前的方法利用光流翹曲在視頻幀間傳播和聚集特徵。然而，直接將圖像級光流應用於高層特徵可能無法建立精確的空間對應關係。為此，提出了一種新的可學習時空採樣（LSTS）模塊來準確地學習相鄰幀特徵之間的語義級對應關係。首先對採樣點進行隨機初始化，然後迭代更新，在檢測監督的指導下逐步尋找更好的空間對應關係。此外，還分別引入稀疏遞歸特徵更新（SRFU）模塊和密集特徵聚合（DFA）模塊來建模時間關係和增強每幀特徵。該方法在imagenetvid數據集上實現了最先進的性能，計算複雜度和實時速度都很低。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/669adf852afe488592aa151c7a4f9087><p class=pgc-img-caption></p></div><p style=text-align:center><br></p><p><strong>論文鏈接：</strong>https://arxiv.org/pdf/1911.05253.pdf<br><strong>代碼地址：</strong>https://github.com/jiangzhengkai/LSTS</p><p><br></p><p><br>AMiner 會議智圖開放平臺 ECCV 2020 專題了解會議的精彩內容，其內容包括論文、作者、華人學者、一作華人學生、論文 PPT 和視頻等多維分析服務，是參會學者的會議智能助理。</p><p><br></p><p><br>頂會專題鏈接：https://www.aminer.cn/conf/eccv2020</p><p><br></p><div class=pgc-img><img alt="ECCV 2020附代碼論文合集(目標檢測）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/589f2bac19d24f36a335895555259828><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ECCV</a></li><li><a>2020</a></li><li><a>附代碼</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/eab7e4e.html alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/89d6bb2700894ec79b76fdc99e8768e9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eab7e4e.html title="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答">ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html alt="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9d1db0f2d2884c99b22fed2f8726ff26 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html title="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈">2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html alt=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6090cec007b4477094c4dee77aa55cab style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html title=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》>2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html alt=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/147a09b4453942c4b8f8f277957352b2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html title=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係>2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html alt=2020最新網頁設計，入門到精通教程+網頁素材，小白速領 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b1791402c6954e31bde2d2e6686776ce style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html title=2020最新網頁設計，入門到精通教程+網頁素材，小白速領>2020最新網頁設計，入門到精通教程+網頁素材，小白速領</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html alt=2020年二級建築答案（部分僅供參考） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html title=2020年二級建築答案（部分僅供參考）>2020年二級建築答案（部分僅供參考）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html alt="2020 一起感受前沿科學的魅力" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RoKukVcIMipJlM style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html title="2020 一起感受前沿科學的魅力">2020 一起感受前沿科學的魅力</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html alt=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3e29dad6969c439eb635b60d7b56ece8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html title=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念>2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html alt="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4d506eba5ab436ea0c06314cea9156a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html title="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實">一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html alt=2020年一級建造師每日一練習題及答案解析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html title=2020年一級建造師每日一練習題及答案解析>2020年一級建造師每日一練習題及答案解析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html alt=2020焊工（中級）考試題及焊工（中級）複審模擬考試 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1e535667de7d4f2bb53fcc15449cf2cd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html title=2020焊工（中級）考試題及焊工（中級）複審模擬考試>2020焊工（中級）考試題及焊工（中級）複審模擬考試</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html alt=2020年建築焊工(建築特殊工種)證模擬考試題庫 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/da22da92ae304596ad940f56f54806eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html title=2020年建築焊工(建築特殊工種)證模擬考試題庫>2020年建築焊工(建築特殊工種)證模擬考試題庫</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/df2816c1.html alt=2020年上半年國內丙烯供需平衡分析及三季度供需展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/df2816c1.html title=2020年上半年國內丙烯供需平衡分析及三季度供需展望>2020年上半年國內丙烯供需平衡分析及三季度供需展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0a47d7ff.html alt=「丙烯」2020年丙烯新產能投放進展 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6fb3fed02f5247a7af4ddaac5ef5595f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0a47d7ff.html title=「丙烯」2020年丙烯新產能投放進展>「丙烯」2020年丙烯新產能投放進展</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce532b9d.html alt=「丙烯」2020年中盤點與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1b09f15c6a994a13a46b33cc10b2dce4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce532b9d.html title=「丙烯」2020年中盤點與展望>「丙烯」2020年中盤點與展望</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>