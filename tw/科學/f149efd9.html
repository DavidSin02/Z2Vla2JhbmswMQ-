<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>用於調整深度神經網絡的簡單參考指南 | 极客快訊</title><meta property="og:title" content="用於調整深度神經網絡的簡單參考指南 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/15379529924702cde52ac04"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e5%ad%b8/f149efd9.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e5%ad%b8/f149efd9.html><meta property="article:published_time" content="2020-11-14T20:52:19+08:00"><meta property="article:modified_time" content="2020-11-14T20:52:19+08:00"><meta name=Keywords content><meta name=description content="用於調整深度神經網絡的簡單參考指南"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E5%AD%B8/f149efd9.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>用於調整深度神經網絡的簡單參考指南</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E5%AD%B8.html>科學</a></span></div><div class=post-content><div><h1>入門</h1><p>考慮到所涉及的參數很多，設計深度神經網絡可能是一項痛苦的任務，並且沒有通用公式適合所有用例。我們可以使用卷積神經網絡(CNN)進行圖像分類，LSTM進行NLP相關的任務，但是特徵的數量、特徵的大小、神經元的數量、隱藏層的數量、激活函數的選擇、權重的初始化等在不同的用例中將會有所不同。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15379529924702cde52ac04><p class=pgc-img-caption>圖像數據集：與相鄰像素相關</p></div><p>參數的這些變化可歸因於不同類型的數據，需要獨立於其他數據集的分析。像圖像數據集將具有不同的屬性，因為相鄰位置中的像素是相關的，但是在關係數據庫條目中可以是隨機的而沒有關係。因此，需要採用不同的方法。</p><p>我們能夠為它們推廣數據類型和合適的神經網絡結構類型，如CNN用於圖像，音頻，視頻和用於NLP相關任務的RNN / LSTM等。但是，為了實現最大性能，我們應該使它們變得智能化。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1537953025888b31f3bd006><p class=pgc-img-caption></p></div><p>dim（h）&lt;dim（xi）&lt; - undercomplete autoencoder || overcomplete autoencoder - > dim（h）≥dim（xi）</p><p>為了簡化，我們將討論侷限於自動編碼器，這是一種特殊類型的前饋神經網絡，它對隱藏層中的輸入進行編碼並從此隱藏表示中進行解碼。每個神經網絡架構都有自動編碼器作為其基本塊。因此，通過對它們的討論，我們可以擴展不同深度學習架構的想法。</p><p>在本文中，我們將探索微調網絡的技術，以獲得更好的驗證準確性，從而實現更好的預測。此外，我們還將研究這些技術背後的一些數學，以瞭解這些技術的幕後故事。</p><h1>創建智能自動編碼器有什麼問題？</h1><p>我們真正想從神經網絡中得到的是從可用數據中歸納出來的而不是記憶出來的。死記硬背的問題是模型最終可能會過度擬合。由於深度學習模型是複雜的，往往會超出目標函數。考慮一些非常基本的情況，其中模型在訓練數據集上進行了廣泛的訓練，從而使訓練數據集上的誤差最小化並趨近於零。神經網絡有可能不去捕捉數據的趨勢，而只是記住了用複雜函數再現整個數據的方法。</p><p>讓我們使用偏差v / s方差權衡的概念更清楚地理解這一點。看一下下圖，x軸表示模型複雜度，而y軸表示誤差。隨著複雜性的增加，訓練誤差趨於減小，但方差增加，顯示出高驗證誤差。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15379530650296a699b545f><p class=pgc-img-caption>藍色：訓練誤差，紅色：驗證誤差</p></div><p>模型最初偏差將很高，隨著訓練誤差接近零，模型將過度擬合導致高方差。</p><p>我們希望模型能夠更敏感地捕捉稀疏但重要的特性的細微細節。因此，不擬合數據根本不是一種選擇。因為更復雜的模型對變化更敏感。只有在深度學習的背景下進行關於過度擬合的討論才有意義。</p><p>以overcomplete編碼器為例，在這種情況下，他們可以學習簡單的編碼複製粘貼整個網絡的值。就像將輸入（xi）複製到隱藏層（h）然後再從h複製到輸出層（x hat）。顯然，誤差將是最小的，但沒有學習</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153795308629567c82f1ad6><p class=pgc-img-caption></p></div><p>它也是一種過度擬合，因為自動編碼器捕獲訓練數據中權重映射的所有變化。</p><p>讓我們建立在以上討論的基礎上，為了讓深度學習的自動編碼器成功，過度擬合必須被移除。當然，還存在數據不足、參數量大、相關特徵是否掌握、何時停止訓練等問題。可以說，智能自動編碼器是概括我們可以觀察和學習重要的趨勢的信息，從中他們可以作出預測。讓我們開始探索這些技術，目的是發展直覺，理由是使用它們和合適的例子來增強我們的學習。</p><ol><li>數據集增強</li><li>提早停止</li><li>l2正則化</li><li>避免Vanilla 自動編碼器：噪音和稀疏度</li><li>參數共享和綁定</li><li>DropOut和DropConnect的集成方法</li></ol><h1>數據集增強</h1><p>在計算機視覺分類任務中，訓練數據越多，模型學習效果越好。但是巨大數據的問題是它增加了訓練時間。</p><p>在深度學習模型中，參數的數量是巨大的(百萬數量級)。如果一開始就沒有足夠的可用數據，這顯然會有幫助。但是，如果你已經有了足夠的數據，這會有幫助嗎?是的，因為它將增加數據集中的相關特徵，這將幫助自動編碼器學習重要的稀疏特徵，而不是無關的豐富特徵。</p><p>數據增強是一種技術，我們用現有數據創建新數據，目的是增加原始數據中的相關特徵。請參閱下面的插圖以瞭解數據增強的概念。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953117129da192a12b6><p class=pgc-img-caption></p></div><p>不變性：數據根據平移，旋轉，大小，視點和照明的差異進行穩健分類</p><p>以這種方式增加最明顯的分類特徵成為最相關的特徵。在ML管道中增加數據的位置？首先是離線擴充應用轉換並將圖像添加到數據集。但是，它會根據應用的轉換次數增加大小。其次，在進入我們的學習模型之前，在線增強是應用於小批量的。在這裡，請參閱一些Tensorflow腳本進行此類轉換，假設我們不關心圖像邊界之外的情況。</p><p>這是什麼意思 ？假設圖像的某些部分沒有任何東西，即它是未知空間，那麼我們需要不同的變換如下。例如，一些帶有黑色背景的旋轉圖像。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953136350c9e49a084c><p class=pgc-img-caption></p></div><p>從左側開始，constant, edge, reflect, symmetric and wrap transformations applied</p><p>Tensorflow腳本基於上述關於在小批量上應用簡單數據轉換的假設。Python示例代碼如下：</p><pre># 1. Flip: 'x' = A placeholder for an image.shape = [height, width, channels]x = tf.placeholder(dtype = tf.float32, shape = shape)flip_2 = tf.image.flip_up_down(x)flip_5 = tf.image.random_flip_left_right(x)# 2. Rotate: 'y' = A batch of images# To rotate in any angle. In the example below, 'angles' is in radiansshape = [batch, height, width, 3]y = tf.placeholder(dtype = tf.float32, shape = shape)rot_tf_180 = tf.contrib.image.rotate(y, angles=3.1415)# 3. Noise: 'x' = A placeholder for an image.shape = [height, width, channels]x = tf.placeholder(dtype = tf.float32, shape = shape)# Adding Gaussian noisenoise = tf.random_normal(shape=tf.shape(x), mean=0.0, stddev=0.5,dtype=tf.float32)output = tf.add(x, noise)</pre><p>可以類似地為隨機裁剪，wrapping，顏色通道移位等編寫其他增強。</p><h1>提早停止</h1><p>正如名字（Early Stopping）所示，它確實給我們提供了一些信息，即我們在訓練時提早停止以避免擬合。但是如何提前停止呢？基本上，我們的目標是在訓練誤差被推向零並且驗證誤差即將爆發之前停止。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153795316583428ef6c6045><p class=pgc-img-caption></p></div><p>參數P：如果您在步驟k並且在之前的步驟中驗證誤差沒有改善，則停止訓練並返回在步驟k-p存儲的模型。</p><p>這些提早停止規則通過將原始訓練集分成新的訓練集和驗證集來工作。驗證集上的誤差用於替代原始訓練誤差，以確定過度擬合何時開始。使用Keras，您可以使用以下方法執行此操作。Python示例如下：</p><pre>keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')</pre><p>min_delta是否在某個epoch量化損失作為改進的門檻。如果損失的差值低於min_delta，則將其量化為沒有改善。patience參數表示一旦損失開始增加（停止改善），停止前的epochs數。mode參數取決於您監控數量的方向（它應該是減少還是增加），因為我們監控損失，我們可以使用min。</p><p>現在，如果我說Early Stopping也是一種正則化技術。可以證明這句話是真的嗎？讓我們看看少量數學。請記住，正則化是指在學習神經網絡中增加一些權重和偏差約束的技術。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953197276d8f43ac7ce><p class=pgc-img-caption></p></div><p>隨機梯度下降法的更新規則。設'τ'為delta（wi）的最大值梯度。將不等式應用於上述等式，我們得到：</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953212776cfcb4a4a5c><p class=pgc-img-caption>t控制了wt到初始w0的距離</p></div><p>提早停止只允許更新參數。更重要的是，維度越大，與之相關的損失就越大，如上式所示，我們控制學習率和t，只有與梯度相關的損失是主導因素，這實際上意味著只有損失越大的重要參數才會佔更多。</p><p>在那裡,不那麼重要的將無法成長。因此，重要的參數被放大，這將導致更好的準確性。這類似於L2正則化，請參閱下面。</p><h1>L2正規化</h1><p>正則化是在學習過程中對模型的約束。L2正則化是權重衰減正則化，它使權值更接近原點，降低不那麼重要的特徵。</p><p>讓我們以直觀的方式理解true error的概念。這個誤差可以用下面這個給定的形式表示，其中添加到經驗誤差的術語是基於估計程序，因為我們不知道f（x）。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953243429c35ebb1ef7><p class=pgc-img-caption>其中yi = f（xi）+ε，ε是samll value</p></div><p>主要目的是將模型複雜性對true error的影響聯繫起來。顯然，它會訓練誤差加上一些東西。那是什麼東西？藉助Stein引理和一些數學，我們可以證明這一點</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15379532643252dabe102e7><p class=pgc-img-caption></p></div><p>當觀察中的微小變化導致估計的大的變化時（ fhat（xi）），誤差會更多。</p><p>這與複雜模型有關嗎？是的，上述觀察結果與模型越複雜，觀察變化越敏感這一事實有關。因此，我們可以說true error=經驗訓練誤差+小常數+Ω（模型複雜性）。該Ω是正則化的基礎。因此，在正則化中，我們的目標是最小化由於模型複雜性導致的誤差，而模型複雜性又與偏差 - 方差權衡相關。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1537953285768667176fdc6><p class=pgc-img-caption></p></div><p>添加該術語的直覺是訓練誤差不會達到零。 w影響上述方程的梯度和更新規則。</p><p>上面添加到更新規則和SGD公式的含義是什麼。上面提到的等式2操作在數學上表示在重要方向上的權重矩陣的縮放，即具有主要特徵值和次要特徵值的那個被縮放，但是較不重要的特徵被縮小更多。該正則化操作有效地首先旋轉權重矩陣，然後將其對角化然後再次旋轉它。在這裡，請參見這些對等contour map有效的操作。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953306512b0a3090d7b><p class=pgc-img-caption></p></div><p>權重向量（w *）旋轉到（w̃）。從幾何學上可以看出，所有特徵都在縮小，但是有些特徵縮小更多。重要特徵可以分配更多權重。</p><p>這裡是Tensorflow腳本，用於在基於上述公式的神經網絡模型中使用正則化。第一個例子是僅在一層上使用它，第二個是在所有層上使用它。Python代碼如下：</p><pre># Code 1:# Loss function using L2 Regularizationregularizer = tf.nn.l2_loss(weights)loss = tf.reduce_mean(loss + beta * regularizer)# Optimizer. optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)# Code 2:# Loss for all trainable variables, 0.001 is beta abovevars = tf.trainable_variables() regularizer = tf.add_n([ tf.nn.l2_loss(v) for v in vars ]) * 0.001# Let's say you wan't to regularize biasesregularizer = tf.add_n([ tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name ]) * 0.001# More descriptive coderegularizers = tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2) + tf.nn.l2_loss(weights_3) + tf.nn.l2_loss(weights_4) + tf.nn.l2_loss(weights_5) + tf.nn.l2_loss(weights_6)loss = tf.reduce_mean(loss + beta * regularizers)</pre><h1>避免使用Vanilla 自動編碼器：噪音和稀疏度</h1><p>考慮如上所述的overcomplete vanilla 自動編碼器的情況。顯然，他們容易過度擬合和瑣碎的學習。因此，使用這些vanilla 自動編碼器在這些情況下不會有太大的好處。通過向輸入添加噪聲來解決這個問題的一種方法是強制神經網絡不要學習瑣碎的編碼，而是集中更多的概括。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1537953336351157f6d553c><p class=pgc-img-caption></p></div><p>去噪編碼器在將其饋送到網絡之前使用概率過程（P（x（tilda）ij | xij））簡單地破壞輸入數據 。這些被稱為去噪自動編碼器。Python代碼如下：</p><pre># Generate corrupted MNIST images by adding noise with normal dist # centered at 0.618 and std=0.618 noise = np.random.normal(loc=0.618, scale=0.618, size=x_train.shape)x_train_noisy = x_train + noisenoise = np.random.normal(loc=0.618, scale=0.618, size=x_test.shape)x_test_noisy = x_test + noise# np.clip to move out of bound values inside given intervalx_train_noisy = np.clip(x_train_noisy, 0., 1.) x_test_noisy = np.clip(x_test_noisy, 0., 1.)</pre><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15379533612178b507e21be><p class=pgc-img-caption></p></div><p>Plot描述了針對不同特徵（如MNIST數據集數字的筆劃，邊緣）觸發的神經元。顯然，與Vanilla AE相比，我們可以看到通過去噪AE捕獲更有意義的模式。</p><p>隨著高斯噪聲的加入，這些隱藏的神經元成為邊緣檢測器，PCA無法給出這些邊緣檢測器。此外，噪聲可以應用於目標類別，這將導致軟目標與隨機分析而不是硬目標。</p><p>稀疏自編碼器也被用來解決這種問題與稀疏參數，這將導致神經元在罕見的情況下，當特徵是相關的觀察。可以寫成Lˆ(θ)= L(θ)+Ω(θ),L(θ)是平方誤差損失或交叉熵損失和Ω(θ)是稀疏約束力量觸發神經元的重要特徵。</p><p>好處:Contractive Autoencoders,正則化項Ω(θ)= | | J x(h)| | ^ 2是編碼器的雅可比矩陣。雅可比矩陣的(j, l)項捕獲第l個神經元輸出的變化，而第j個輸入的變化很小。L(θ)——捕捉重要變化數據&Ω(θ)——不捕捉變化數據,雅可比矩陣使神經元變化不敏感。通過這種權衡，我們只能捕獲最重要的特性。對於稀疏AE也可以進行類似的討論。</p><h1>參數共享和綁定</h1><p>共享權重僅意味著使用相同的權重向量來進行計算。這樣做的主要動機是限制參數的數量。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153795339873244b22cc04a><p class=pgc-img-caption></p></div><p>ℎ1 = · [1：3]， ℎ2 = · [3：5]， ℎ3 = · [5：7]</p><p>我們可以通過一個直觀的假設來顯著減少我們的參數，即如果一個特徵在一個點上計算很重要，那麼它在另一個點上也重要。示例：如果在特定位置檢測到邊緣很重要。因此，由於圖像的平移不變結構，所有邊緣重複自身的位置。這將導致更快的收斂。此外，我們限制了靈活性，這也可以起到避免過度擬合的正則化機制的作用。考慮這樣一種情況:我們希望並行處理兩組圖像，但還希望列共享參數。</p><pre>def function(x, reuse): with tf.variable_scope(layer_name) as s: output = tf.contrib.layers.convolution2d(inputs = x, num_outputs = 10, kernel_size = [3, 3], stride = [1, 1], padding = 'VALID', reuse = reuse, scope = s) return output output1 = function(image1, False)output2 = function(image2, True)</pre><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153795360750620831bf699><p class=pgc-img-caption></p></div><p>權重綁定概念基於與上述相同的想法，具有相同的減少參數的動機，但是應用於自動編碼器單元，其中編碼器權重和解碼器權重被綁定和使用。它降低了自動編碼器的容量，並充當正則化器。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537953427783529f23c4cb><p class=pgc-img-caption></p></div><p>綁定編碼器和解碼器的權重，即 W * = W T.</p><h1>DropOut和DropConnect集成</h1><p>Ensembles將不同模型的輸出組合在一起以減少泛化誤差，模型可以是不同的分類器。這裡，它們是在不同超參數，特徵和訓練數據的不同樣本上訓練的相同神經網絡的不同實例。Bagging是一種跨整個數據集的方法，用於在訓練數據的子集上訓練模型。因此，一些訓練示例沒有顯示在給定的模型中。它允許不同的神經元通過不同的訓練數據收集不同的相關特徵。所有模型平均預測的誤差呢?</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1537953625720c93b5400ea><p class=pgc-img-caption></p></div><p>期望平方誤差由:各模型的平均預測得到的誤差期望</p><p>從上面看，模型彼此之間的獨立性越小，誤差僅降低到（V / k）。非常好，因為當神經網絡的架構變化很大時，理想情況下誤差會非常小。但是，隨著各個模型數量的增加，訓練參數的數量會急劇增加。隨著訓練計算成本變得昂貴。</p><p>如果我們能減少這些參數不是很好嗎。此外，不同的架構將幫助我們增加模型之間的差異。Dropout解決了這兩個問題。它給出了組合許多不同網絡的近似方法，並訓練了幾個沒有任何顯著開銷的網絡。它在所有網絡之間共享權重，併為每個訓練實例採樣不同的訓練網絡。僅有效參數從正向和反向傳播更新。不是聚合2 ^ n個稀疏網絡，而是將每個節點的輸出按照訓練期間的一小部分進行縮放。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15379536402498a55dbeff7><p class=pgc-img-caption></p></div><p>Dropout refers to dropping out units。即臨時刪除節點及其所有傳入/傳出連接，從而導致網絡變薄。</p><p>它適用於每個訓練示例中的特徵，導致某些特徵對網絡不可用。因為神經元不能完全依賴於一個輸入，所以這些網絡中的表示往往更加分散，並且網絡不太可能過度擬合。這是由於dropout把掩蔽噪聲放到了阻止協同適應的隱藏單元中，本質上隱藏單元不會依賴於其他單元來檢測特定的特徵，因為這些單元可能會dropout。這使得隱藏單位更加健壯。</p><p>Python代碼如下：</p><pre># Simple keras implementation of MNIST for dropoutimport tensorflow as tfmnist = tf.keras.datasets.mnist (x_train, y_train),(x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation=tf.nn.relu), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=tf.nn.softmax)])model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5)model.evaluate(x_test, y_test)</pre><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15379536818120deb02c399><p class=pgc-img-caption></p></div><p>什麼是dropconnect ？好吧，假設我們不刪除節點而是隨機刪除子集。它的行為方式與dropout相似。將從伯努利分佈繪製的二元掩模應用於原始權重矩陣。</p><div class=pgc-img><img alt=用於調整深度神經網絡的簡單參考指南 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1537953706193215afe4de7><p class=pgc-img-caption></p></div><p>由於輸入數據類或連接對更深層的貢獻，連接不會隨機丟棄每次訓練中的連接，而是會丟棄並保持連接。</p><pre>tf.nn.dropout(W, keep_prob=p) * p ORtf.layers.dropout(W, rate=1-p) * p</pre><h1>結論</h1><p>在何時使用這些技術的直覺中，我們可以創建有效的深層神經網絡，在其核心內更智能，同時可以學習任何特定任務。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>調整</a></li><li><a>神經</a></li><li><a>網絡</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html alt=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/65c4000bda98898dcdbb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html title=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼>谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html alt=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/470f0001d893b2ad09e2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html title=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮>你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html alt=神經網絡與圖靈機的複雜度博弈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/4af200040ff1f5233c1c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html title=神經網絡與圖靈機的複雜度博弈>神經網絡與圖靈機的複雜度博弈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html alt=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/3c0b503678da4b15be05f6f56c0d213f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html title=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成>基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/6062a4c0.html alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6d474536ff3d4b1fba0cbfc85968ff6f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/6062a4c0.html title=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界>BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html alt=貝葉斯神經網絡(系列)：第二篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RKYlnth9DPo8ac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html title=貝葉斯神經網絡(系列)：第二篇>貝葉斯神經網絡(系列)：第二篇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html alt=針對深度神經網絡的簡單黑盒對抗攻擊 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b9ec712cd33442338496141ebfcecb45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html title=針對深度神經網絡的簡單黑盒對抗攻擊>針對深度神經網絡的簡單黑盒對抗攻擊</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html alt=模式識別與神經網絡的發展 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523254283784d3d276a90f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html title=模式識別與神經網絡的發展>模式識別與神經網絡的發展</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html alt=BP神經網絡學習筆記 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fc5cec456c184c48b1ee22a233b9ee0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html title=BP神經網絡學習筆記>BP神經網絡學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d7196c1.html alt=手工打造神經網絡：透視分析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6ee200033390f3f6b2ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d7196c1.html title=手工打造神經網絡：透視分析>手工打造神經網絡：透視分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html alt=機器學習：神經網絡學習之多層前饋神經網絡（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a0a4cd0f7d9244a6a12da3c0af6893a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html title=機器學習：神經網絡學習之多層前饋神經網絡（一）>機器學習：神經網絡學習之多層前饋神經網絡（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html alt=機器學習：神經網絡學習之多層前饋神經網絡（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/2d53a815-ab09-4da3-94a2-5b6843366e3a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html title=機器學習：神經網絡學習之多層前饋神經網絡（二）>機器學習：神經網絡學習之多層前饋神經網絡（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html alt=一文幫你梳理清楚深度神經網絡的基礎知識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f16bcb220e14085a04994454ea4998a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html title=一文幫你梳理清楚深度神經網絡的基礎知識！>一文幫你梳理清楚深度神經網絡的基礎知識！</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/2d00c65.html alt=理解神經網絡 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15409758920775d7570f483 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/2d00c65.html title=理解神經網絡>理解神經網絡</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>