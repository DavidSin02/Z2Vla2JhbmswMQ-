<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>圖解十大 CNN 架構 | 极客快訊</title><meta property="og:title" content="圖解十大 CNN 架構 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RY01Bu1Hn58Ql"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/0274b1cd.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/0274b1cd.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="圖解十大 CNN 架構"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/0274b1cd.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>圖解十大 CNN 架構</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01Bu1Hn58Ql><p><strong>CNN 取得的大多數進展並非源自更強大的硬件、更多的數據集和更大的模型，而主要是由新的想法和算法以及優化的網絡結構共同帶來的結果。</strong></p><p>原標題 | Illustrated: 10 CNN Architectures</p><p>翻譯 | 廖穎、had_in（電子科技大學）、愛曼紐•西蒙（東南大學）</p><blockquote><p>所謂“常見”，我指的是那些深度學習庫(如TensorFlow、Keras和PyTorch)共享的有預訓練權重的模型，以及通常在課堂上所講的模型。其中一些模型在ImageNet大規模視覺識別挑戰賽(ILSVRC)等競賽中取得了成功。</p></blockquote><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RY01BuL2AhIXPa><p>將討論的10個架構及對應論文的年份</p><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01BubFd2pXBG><p>我們將討論在Keras中具有預訓練模型的6種架構。上圖改編自Keras文檔中的一個表。</p><p>寫這篇文章的初心是考慮到目前沒有太多圖解網絡結構的博客和文章（如果你知道相關的文章，請分享給我吧）。所以我決定寫一篇文章來作為參考。出於這樣的目的，我閱讀了許多論文和代碼（大多來自TensorFlow和Keras）來完成這篇文章。</p><p>補充一點，我們平時看到的卷積神經網絡架構是很多因素的結果——升級的計算機硬件、ImageNet比賽、處理特定的任務、新的想法等等。Google 研究員 Christian Szegedy曾提到：</p><blockquote><p>CNN 取得的大多數進展並非源自更強大的硬件、更多的數據集和更大的模型，而主要是由新的想法和算法以及優化的網絡結構共同帶來的結果。（Christian Szegedy等人，2014）</p></blockquote><p>現在我們繼續介紹，看看網絡結構是如何慢慢優化起來的。</p><blockquote><p>關於可視化圖的說明：可視化圖中沒有再標註卷積核數量、padding、stride、dropout和拉平操作。</p></blockquote><p></p><h3><strong>目錄 (按發表年份排序)</strong></h3><ol><li><p>LeNet-5</p></li><li><p>AlexNet</p></li><li><p>VGG-16</p></li><li><p>Inception-v1</p></li><li><p>Inception-v3</p></li><li><p>ResNet-50</p></li><li><p>Xception</p></li><li><p>Inception-v4</p></li><li><p>Inception-ResNets</p></li><li><p>ResNeXt-50</p></li></ol><p></p><h3><strong>圖例</strong></h3><p></p><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01But9Yxh4n8><p></p><h2><strong>1. LeNet-5 (1998)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01Bv74Lx75Pu><p>圖1：LeNet-5架構，引自他們的論文</p><p>LeNet-5是最簡單的架構之一。它有2個卷積層和3個全連接層(因此是“5”——神經網絡的名稱通常是由它們擁有的卷積層和全連接層的數量派生出來的)。我們現在所知道的平均池化層被稱為子採樣層，它具有可訓練的權重(和當前設計CNNs不同)。這個架構有大約60,000個參數。</p><p></p><h3><strong>⭐️創新點：</strong></h3><p>這種架構已經成為標準的“模板”:疊加捲積層和池化層，並以一個或多個全連接層結束網絡。</p><p></p><h3><strong>發表：</strong></h3><ul><li><p>論文：Gradient-Based Learning <i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">App</i>lied to Document Recognition</p></li><li><p>作者：Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner</p></li><li><p>發表於：Proceedings of the IEEE (1998)</p></li></ul><p></p><h3><strong>2. AlexNet</strong></h3><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CHRFMrNfHt><p>圖2：AlexNet結構，引自他們的論文</p><p>AlexNet網絡有6千萬個參數，8個網絡層——5個卷積層和3個全連接層。相比於LeNet-5，AlexNet只是堆了更多的網絡層。</p><p>在論文發表時，作者指出AlexNet是“在ImageNet子集上訓練的最大的卷積神經網絡之一。”</p><p><strong>⭐️創新點：</strong></p><p>1.他們首次實現將線性整流函數（ReLus）作為激活函數。</p><p>2.使用卷積神經網絡的重疊池化。</p><p><strong>發表：</strong></p><ul><li><p>論文：深度卷積神經網絡用於ImageNet分類</p></li><li><p>作者：Alex Krizhevsky, IIya Sutskever, Geoffrey Hinton. 加拿大，多倫多大學</p></li><li><p>發表於：2012年神經信息處理系統<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">會議</i>（NeurIPS 2012）</p></li></ul><p></p><h2><strong>3. VGG-16 (2014)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CHlUU4TJ6><p>圖3：VGG-16架構，引自他們的論文</p><p>你現在應該已經注意到CNNs開始變得越來越深了。這是因為提高深度神經網絡性能最直接的方法是增加它們的大小(Szegedy et. al)。Visual Geometry Group (VGG)的工作人員提出了VGG-16，它有13個卷積層和3個全連接層，繼續採用了AlexNet的ReLU激活函數。同樣，這個網絡只是在AlexNet上堆疊了更多的層。它有138M的參數，佔用大約500mb的磁盤空間。他們還設計了一種更深的變型，VGG-19。</p><p><strong>⭐️創新點：</strong></p><p>正如他們在摘要中提到的，本文的貢獻在於設計了更深層次的網絡(大約是AlexNet的兩倍)。</p><p><strong>發表：</strong></p><ul><li><p>論文：Very Deep Convolutional Networks for Large-Scale Image Recognition</p></li><li><p>作者：Karen Simonyan, Andrew Zisserman. University of Oxford, UK.</p></li><li><p>arXiv 印本, 2014</p></li></ul><p></p><h2><strong>4. Inception-v1 (2014)</strong></h2><h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CI04dckmbm></h2><p>圖4：Inception-v1架構。這個CNN有兩個輔助網絡(在推斷時被丟棄)。體系結構引自論文中的圖3。</p><p>這個22層網絡架構具有5M的參數，被稱為 Inception-v1 網絡 。這個架構，如論文中所述，大量使用了Network In Network(參見附錄)方法。這是通過“Inception 模塊”實現的。Inception模塊的架構設計是對稀疏結構近似研究的產物(更多信息請閱讀論文)。每個模塊有3個點改進：</p><p>1.使用不同卷積的並行拓撲結構，然後進行連接，獲得1×1、3×3和5×5卷積提取的不同特徵，從而對它們進行“歸併”。這一想法的靈感來自Arora等人在論文Provable bounds for learning some deep representations，改論文提出了一種逐層構建的方法，即分析最後一層的相關統計數據，並將其歸併成具有高相關性的單元組。</p><p>2.採用1×1卷積進行降維，消除計算瓶頸。</p><p>3.1×1卷積在卷積層中加入非線性(基於Network In Network論文)。</p><p>作者還引入了兩個輔助分類器，以使分類器在較淺層的網絡部分也進行識別，以增加反向傳播的梯度信息，並提供額外的正則化。輔助網絡(連接到輔助分類器的分支)在推斷時被丟棄。</p><p><strong>⭐️創新點：</strong></p><p>使用稠密modules/blocks構建網絡。我們並非堆疊卷積層，而是堆疊modules或blocks，其中包含卷積層。Inception得名於2010年由萊昂納多·迪卡普里奧主演的科幻電影《盜夢空間》。</p><p><strong>發表：</strong></p><ul><li><p>論文：Going Deeper with Convolutions</p></li><li><p>作者：Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Google, University of Michigan, University of North Carolina</p></li><li><p>發表於：2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</p></li></ul><p></p><h2><strong>5. Inception-v3 (2015)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CIE1kA4dOq><p><strong>⭐️創新點：</strong></p><p>引入BN層(為了簡單起見，沒有反映在上面的圖中 )。</p><p><strong>✨與之前的版本 Inception-v1 相比，有什麼改進?</strong></p><p>將7×7卷積替換為一系列3×3個卷積</p><p><strong>發表：</strong></p><ul><li><p>論文：Rethinking the Inception Architecture for Computer Vision</p></li><li><p>作者：Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna. Google, University College London</p></li><li><p>發表於：2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</p></li></ul><p></p><h2><strong>6. ResNet-50 (2015)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CIVHcA1M2q><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RY01Cha4LMGoRG><p><strong>⭐️創新點：</strong>推廣跳連接結構skip connections (</p><p><strong>發表：</strong></p><ul><li><p>論文：Deep Residual Learning for Image Recognition</p></li><li><p>作者：Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. Microsoft</p></li><li><p>發表於：2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</p></li></ul><p></p><h3><strong>7. Xception(2016)</strong></h3><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01Chw3HC6zym><p>圖7：Xception 架構，基於keras-team在GitHub上的代碼。通道獨立卷積層被記作'conv sep'。</p><p>Xception是從Inception上改進，Inception模塊用通道獨立卷積層替換。它與Inception-v1的參數數量大致相同（23M）。</p><p>Xception將Inception假設引入eXtreme（因此而得名）。那麼什麼是Inception假設？謝天謝地，文章中明確提到了這一點（感謝François!)</p><ul><li><p>首先，通過1x1卷積核捕獲跨通道（或交叉特徵映射）相關性。</p></li><li><p>其次，通過常規3x3或5x5卷積捕獲每個通道內的空間相關性。</p></li></ul><p>將這個想法運用到極致意味著對每個通道執行1x1卷積，然後對每個輸出執行3x3。這與用通道獨立卷積替換初始模塊相同。</p><p></p><h4><strong>⭐️創新點：</strong></h4><p>引入完全基於通道獨立卷積層的CNN。</p><p></p><h4><strong>發表：</strong></h4><p></p><ul><li><p>論文：Xception: Deep Learning with Depthwise Separable Convolutions</p></li><li><p>作者：François Chollet. Google.</p></li><li><p>發表於：2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)</p></li></ul><p></p><h2><strong>8. Inception-v4 (2016)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RY01CiCEf7ir6g><p></p><h4><strong>發表：</strong></h4><ul><li><p>論文：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</p></li><li><p>作者：Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. Google.</p></li><li><p>發表於：Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</p></li></ul><p></p><h2><strong>9. Inception-ResNet-V2 (2016)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01CiREs05XdN><p><strong>✨與前一個版本 Inception-v3 相比，有什麼改進?</strong></p><p>1.將 Inception模塊轉化為Residual Inception模塊。</p><p>2.加入更多的Inception模塊。</p><p>3.在Stem模塊之後添加一個新的Inception模塊(Inception-A)。</p><p><strong>發表：</strong></p><ul><li><p>論文：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</p></li><li><p>作者：Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. Google</p></li><li><p>發表於：Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</p></li></ul><p></p><h2><strong>10. ResNeXt-50 (2017)</strong></h2><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01Cij2ZExHNw><p>Fig. 10: ResNeXt架構, 引自對應論文.</p><p><strong>發表：</strong></p><ul><li><p>論文：Aggregated Residual Transformations for Deep Neural Networks</p></li><li><p>作者：Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He. University of California San Diego, Facebook Research</p></li><li><p>發表於：2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</p></li></ul><p></p><h3><strong>附錄：Network In Network (2014)</strong></h3><strong>⭐️創新點：</strong><p>1.MLP卷積層, 1×1卷積</p><p>2.全局平均池化(取每個特徵map的平均值，並將結果向量輸入softmax層)</p><p><strong>發表：</strong></p><ul><li><p>論文: Network In Network</p></li><li><p>作者: Min Lin, Qiang Chen, Shuicheng Yan. National University of Singapore</p></li><li><p>arXiv印本, <i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">2013</i></p></li></ul><p><strong>這裡把10個網絡結構的可視化圖再羅列一下，作簡單的回顧：</strong></p><h3><strong>LeNet-5</strong></h3><h3><strong>AlexNet</strong></h3><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RY01D91FmBjKMY><p></p><h3><strong>VGG-16</strong></h3><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RY01D9O5aun3Uo><p></p><h2><strong>Inception-v1</strong></h2><p></p><h2><strong>Inception-v3</strong></h2><p></p><h2><strong>Inception-v4</strong></h2><p></p><h2><strong>Inception-ResNet-V2</strong></h2><p></p><h2><strong>Xception</strong></h2><p></p><h2><strong>ResNet-50</strong></h2><p></p><h2><strong>ResNeXt-50</strong></h2><p></p><h3><strong>神經網絡可視化資源</strong></h3><p>這裡有一些資源可以讓你可視化你的神經網絡:</p><ul><li><p>Netron （https://lutzroeder.github.io/netron/）</p></li><li><p>TensorBoard API by TensorFlow（https://<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">www.</i>tensorflow.org/tensorboard/r1/overview）</p></li><li><p>plot_model API by Keras（https://keras.io/visualization/）</p></li><li><p>pytorchviz package（https://github<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>/szagoruyko/pytorchviz）</p></li></ul><p></p><h3><strong>類似文章</strong></h3><ul><li><p>CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more ….</p></li><li><p>A Simple Guide to the Versions of the Inception Network</p></li></ul><p></p><h3><strong>參考</strong></h3><p>我使用了提出了上述網絡體系結構的論文作為參考。除此之外，這裡還有一些我在本文中引用的文章:</p><ul><li><p>https://github<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>/tensorflow/models/tree/master/research/slim/nets(github<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>/tensorflow)</p></li><li><p>Implementation of deep learning models from the Keras team(github<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>/keras-team)</p></li><li><p>Lecture Notes on Convolutional Neural Network Architectures: from LeNet to ResNet (slazebni.cs.illinois.edu)</p></li><li><p>Review: NIN — Network In Network (Image Classification)(towardsdatascience<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>)</p></li></ul><p>via https://towardsdatascience<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">.com</i>/illustrated-10-cnn-architectures-95d78ace614d</p><img alt="圖解十大 CNN 架構" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RXhalWP3tXXfbO></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>圖解</a></li><li><a>CNN</a></li><li><a>架構</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/24a6006e.html alt=服務器架構：十張圖帶你瞭解大型網站架構 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/2af10e2429bc47a5823244277a07bb77 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/24a6006e.html title=服務器架構：十張圖帶你瞭解大型網站架構>服務器架構：十張圖帶你瞭解大型網站架構</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/aa6ebdaa.html alt=圖解光纜、終端盒、尾纖的作用和接法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1533878533643f382d474be style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/aa6ebdaa.html title=圖解光纜、終端盒、尾纖的作用和接法>圖解光纜、終端盒、尾纖的作用和接法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6237da3d.html alt=朗坤雙模IT架構的智慧電廠，更安全、更經濟、更環保、更高效 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0670cbc9828449c782ac323a238b99e3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6237da3d.html title=朗坤雙模IT架構的智慧電廠，更安全、更經濟、更環保、更高效>朗坤雙模IT架構的智慧電廠，更安全、更經濟、更環保、更高效</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8809067a.html alt=圖解：中國首款量產的兩檔電驅動橋，專為SUV電動化而來！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/153809842787775889e4159 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8809067a.html title=圖解：中國首款量產的兩檔電驅動橋，專為SUV電動化而來！>圖解：中國首款量產的兩檔電驅動橋，專為SUV電動化而來！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/156d2a92.html alt="圖解MySQL | 「原理解析」 MySQL組提交(group commit)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e5444e9094614d6b88bd3fc8ac0524fb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/156d2a92.html title="圖解MySQL | 「原理解析」 MySQL組提交(group commit)">圖解MySQL | 「原理解析」 MySQL組提交(group commit)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/070f12d8.html alt=施工工藝管理最新圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RHC49E98HS0oHf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/070f12d8.html title=施工工藝管理最新圖解>施工工藝管理最新圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bcc93b8c.html alt=詳細圖解地球自轉與公轉的黃赤交角如何形成四季更換 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6acd8115d8fe4cf1b1b1bbce7e353cea style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bcc93b8c.html title=詳細圖解地球自轉與公轉的黃赤交角如何形成四季更換>詳細圖解地球自轉與公轉的黃赤交角如何形成四季更換</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8eeec4c4.html alt=深度剖析“買入分歧賣出一致”的買賣精髓（圖解） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9fca4cdd669d4862b254f9f2447baa06 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8eeec4c4.html title=深度剖析“買入分歧賣出一致”的買賣精髓（圖解）>深度剖析“買入分歧賣出一致”的買賣精髓（圖解）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html alt=老股民總結的賣出技巧實戰圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/7575000bb7b8e57fa260 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html title=老股民總結的賣出技巧實戰圖解>老股民總結的賣出技巧實戰圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html alt=股票交易指南：實戰圖解經典的賣出技巧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15305260751844061be70e0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html title=股票交易指南：實戰圖解經典的賣出技巧>股票交易指南：實戰圖解經典的賣出技巧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3d4671c.html alt=活動文件櫃的架構是什麼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/104d3629a97947b19d62b03dc3b8d82f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3d4671c.html title=活動文件櫃的架構是什麼>活動文件櫃的架構是什麼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0488f1da.html alt=339頁工程造價全能圖解，全方位講解，造價小白也能輕鬆搞定 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c14ba2845d1d432fbf4cc8a534775e30 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0488f1da.html title=339頁工程造價全能圖解，全方位講解，造價小白也能輕鬆搞定>339頁工程造價全能圖解，全方位講解，造價小白也能輕鬆搞定</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/64ba00ea.html alt=麒麟和獬豸傻傻分不清？圖解~ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c64d3d8c00804f93b4093eb4a4358758 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/64ba00ea.html title=麒麟和獬豸傻傻分不清？圖解~>麒麟和獬豸傻傻分不清？圖解~</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b06da4c5.html alt=圖解功率MOS管的參數 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1940284f671c4b559a1db4ef0e83976c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b06da4c5.html title=圖解功率MOS管的參數>圖解功率MOS管的參數</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b506f512.html alt=九年新浪架構師整理PHP架構核心技術教程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b3a3c32254344742b6746996f7fab54b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b506f512.html title=九年新浪架構師整理PHP架構核心技術教程>九年新浪架構師整理PHP架構核心技術教程</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>