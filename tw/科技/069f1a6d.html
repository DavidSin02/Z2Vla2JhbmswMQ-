<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 | 极客快訊</title><meta property="og:title" content="哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/S44t6ohazkQ74"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/069f1a6d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/069f1a6d.html><meta property="article:published_time" content="2020-10-29T21:10:44+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:44+08:00"><meta name=Keywords content><meta name=description content="哈工大提出基於光流估計與光照不一致監督的人臉正向化模型"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/069f1a6d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>哈工大提出基於光流估計與光照不一致監督的人臉正向化模型</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S44t6ohazkQ74><p>今天解讀的是一篇已被ECCV 2020接收的論文，在這篇論文中，來自哈工大的作者們針對之前方法忽略對側臉-正臉圖像對之間光照情況不一致的考慮，引入了一個光照保留損失，實現了圖像中光照信息和人臉身份信息的特徵解藕，同時使用光流估計在特徵層面得到了側臉-正臉之間的特徵對應關係，作為一個強有力的正向化監督信號，進而生成了更加逼真的正面人臉，同時也保留了更多的細節信息，實驗結果表明，本文方法達到了SOTA效果。</p><p>論文：《Learning Flow-based Feature Warping for Face Frontalization with Illumination Inconsistent Supervision》。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oDvGr8eBQi><p>論文鏈接：https://arxiv.org/pdf/2008.06843</p><p>代碼鏈接：https://github.com/csyxwei/FFWM</p><p><strong toutiao-origin=span>1 動機</strong></p><p>目前針對人臉正向化問題，較為流行的方法是通過大量的側臉-正臉圖像對（profile-frontal pairs）訓練一個GAN網絡，但是此類方法都忽略了側臉-正臉之間存在光照不一致的現象，光照不一致主要是由拍攝角度（拍攝現場使用固定的照明設備）造成的，尤其是側臉角度達到±90°時，光照的明暗差異非常明顯，下圖為Multi-PIE數據集中不同角度的人臉。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oDvoHwcth1E><p>之前的方法直接最小化生成人臉與ground-truth正面人臉的像素級損失，會迫使網絡同時學習對姿態和光照的轉換，對光照的轉換在一定程度上會干擾前者，本文針對該問題，在正向化過程中保留了輸入側臉的光照信息，使模型更加專注於姿態轉換的學習，從而得到了更好的生成效果。</p><p><strong toutiao-origin=span>2 方法</strong></p><p>人臉正向化本質上是人臉圖像的旋轉變化，本文使用光流場來構建側臉-正臉之間的特徵對應關係，光流估計網絡使用FlowNetSD[1]，正向光流場（Forward Flow Field）表徵側臉到正臉的特徵轉換，反向光流場（Reverse Flow Field）表徵正臉到側臉的特徵轉換。然後將得到的兩個光流場分別應用到光照保留模塊（Illumination Preserving Module）和注意力特徵轉換模塊（Warp Attention Module）。</p><p><strong>光照保留模塊</strong></p><p>光照保留模塊主要負責將人臉圖像中的光照信息與代表人臉身份的細節信息進行特徵解藕。光照保留模塊分為兩個支路，其中光照保留支路（Illumination preserving pathway）保證生成的正面圖像與輸入的側臉圖像在光照情況上一致，而光照適應支路（Illumination adaption pathway）儘可能的保證學習到與ground-truth圖像一致的身份細節特徵。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oDweEdHAaf1><p>由於光照條件很難量化到特徵空間中，所以作者直接在圖像空間對生成前後圖像的光照情況進行約束，如上圖Illumination Preserving Module中首先通過反向光流場將模型生成的正向人臉</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oDxCgxeWxv><p>轉換到側臉視角，然後對和輸入側臉</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFYr4zE0XFm><p>計算光照保留損失。</p><p>在光照適應支路中，考慮到生成圖像與ground-truth圖像</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFaLCPvtRSJ><p>的光照條件不一致，直接對它們進行約束可能會消除前面光照保留支路的效果，所以使用guided filter[2]對ground-truth圖像做光照條件的遷移得到</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oFbFvYPU96><p>，保證兩幅正面圖像有同樣的光照條件，然後對其計算細節特徵損失即可。</p><p></p><h1 toutiao-origin=h3>注意力特徵轉換模塊</h1><p>該模塊主要實現側臉到正臉的特徵轉換，使用正向光流場可以得到非常精確的像素對應關係，但是由於人臉自身旋轉帶來的自遮擋現象，使得側臉圖像會有一部分信息丟失，進而也就無法得到完整的像素對應關係，針對這個問題，作者根據人臉對稱先驗對得到的特徵圖進行水平翻轉，再通過一個注意力模塊進行特徵融合，消除翻轉特徵帶來的信息混亂。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oFba4jmMffF><p><strong toutiao-origin=span>3 損失函數</strong></p><p><strong>多尺度像素級損失</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oFcMBfJGmYS><p>為了保證生成圖像與ground-truth圖像的內容一致性，本文仿照TP-GAN[3]，CAPG-GAN[4]加入了多尺度像素級損失，本文設置了三個尺度，分別為32x32、64x64和128x128。由於ground-truth圖像與生成正面圖像的光照情況不同，所以計算該損失之前需要進行光照遷移。</p><p><strong>感知損失</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oGNS29wii2><p>為了緩解像素級損失帶來的生成圖像較為模糊的問題，本文加入了VGG-19的感知損失，為了使感知損失作用到人臉圖像中的關鍵區域，這裡重點關注了眼睛、鼻子和嘴巴部分。</p><p><strong>對抗損失</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGPT1w10KYw><p>上式為標準的圖像對抗損失，促使生成器生成更加逼真的人臉圖像。</p><p><strong>光照保留損失</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGPwfq0hM5><p>上式為本文比較核心的多尺度光照保留損失，其中S代表的多尺度與上面的多尺度像素級損失一致，本質上是對輸入側臉與經過反向光流場生成的側臉圖像計算L1距離。</p><p><strong>身份特徵保留損失</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oGQrFyhO9eD><p>人臉正向化需要保證正向化過程中儘可能的保留與輸出側臉相同的身份信息，所以本文也加入了身份特徵的保留損失，分別對LightCNN-29[5]最後一個池化層和全連接層的特徵向量計算L1距離。</p><p><strong>優化：</strong></p><p>最後將上述各項損失整合起來得到總優化目標，即以下損失項的加權和。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oGS4DCzN0T8><p><strong toutiao-origin=span>4 實驗與結果</strong></p><p>本文數據集使用了Multi-PIE數據集和LFW數據集，前者是目前比較流行的受限條件下多角度人臉數據集，後者為非受限條件下的人臉數據集。</p><p><strong>定性實驗</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S99oH4W51QCX7G><p>本文分別與4種人臉正向化方法進行了對比，可以看到其他方法得到的生成圖像的光照情況與最左側的輸入側臉的光照情況有很大差異，同時在臉部輪廓和其他細節區域與真實圖像也有明顯的差異，本文方法首先保證生成圖像的光照情況與原圖一致，使模型能夠更加明確的執行正向化。</p><p>上圖為在Multi-PIE數據集上的生成效果，下圖為在LFW數據集的效果。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oH65Ea2siPf><p><strong>定量實驗</strong></p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S99oH7Q4Oe2AyR><p>為了體現人臉正向化模型對人臉識別性能的提升以及本文方法的優越性，作者將本文方法作為人臉識別的一個預處理過程，首先對所有側臉執行正向化操作，其後將生成正臉圖像輸入到LightCNN中計算得到特徵向量，使用餘弦距離作為相似性度量計算得到Rank-1識別準確率，可以看到本文方法在大於75度的極端角度情況下可以達到SOTA效果。</p><img alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S99oH8l8YyyWfv><p>為了展示本文方法在受限場景和非受限場景中都可以得到很好的效果，作者在LFW數據集上計算了ACC和AUC指標，都達到了SOTA效果。</p><p><strong toutiao-origin=span>5 總結</strong></p><p>在這篇論文中，作者以側臉-正臉圖像對中光照條件不一致為切入點，通過光照保留模塊對人臉關鍵信息與光照信息進行解藕，然後使用雙向的光流場對兩種視角人臉特徵對應關係進行擬合，再通過注意力特徵轉換模塊消除掉一些與人臉關鍵特徵無關的信息，進而實現精確的人臉正向化。實驗結果表明，本文的方法不僅能夠生成較為逼真的正面人臉，同時也可以解決大角度的人臉識別問題。</p><p>參考引用</p><p>[1] Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox, T.: Flownet 2.0: Evolution of optical flow estimation with deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2462–2470 (2017)</p><p>[2] He, K., Sun, J., Tang, X.: Guided image filtering. In: Proceedings of the European Conference on Computer Vision. pp. 1–14. Springer (2010)</p><p>[3] Huang, R., Zhang, S., Li, T., He, R.: Beyond face rotation: Global and local per- ception gan for photorealistic and identity preserving frontal view synthesis. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 2439– 2448 (2017)</p><p>[4] Hu,Y.,Wu,X.,Yu,B.,He,R.,Sun,Z.:Pose-guidedphotorealisticfacerotation.In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8398–8406 (2018)</p><p>[5] Wu, X., He, R., Sun, Z., Tan, T.: A light cnn for deep face representation with noisy labels. IEEE Transactions on Information Forensics and Security 13(11),2884–2896 (2018)</p><p><strong toutiao-origin=span>[博文視點贈書福利]</strong></p><p>AI科技評論聯合博文視點贈送周志華教授“森林樹”十五本，在“周志華教授與他的森林書”一文留言區留言，談一談你和集成學習有關的學習、競賽等經歷。</p><p>AI 科技評論將會在留言區選出15名讀者，每人送出《集成學習：基礎與算法》一本。</p><p><strong toutiao-origin=span>活動規則：</strong></p><p>1. 在“周志華教授與他的森林書”一文留言區留言，留言點贊最高的前 15 位讀者將獲得贈書。獲得贈書的讀者請聯繫 AI 科技評論客服（aitechreview）。</p><p>2. 留言內容會有篩選，例如“選我上去”等內容將不會被篩選，亦不會中獎。</p><p>3. 本活動時間為2020年8月23日 - 2020年8月30日（23:00），活動推送內僅允許中獎一次<strong toutiao-origin=span>。</strong></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>哈工大</a></li><li><a>光流</a></li><li><a>估計</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/51ceec2d.html alt=光流估計——從傳統方法到深度學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/60d0e9a141b341f88113efb1751633e9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51ceec2d.html title=光流估計——從傳統方法到深度學習>光流估計——從傳統方法到深度學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/63ee75d2.html alt=統計學中的參數估計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/4aa6f1ede12d4cb28174fd2e927d80e8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/63ee75d2.html title=統計學中的參數估計>統計學中的參數估計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad4de335.html alt=都聽說過差速器，估計老司機也不知道它到底是什麼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/568b0005c4f030644e0d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad4de335.html title=都聽說過差速器，估計老司機也不知道它到底是什麼>都聽說過差速器，估計老司機也不知道它到底是什麼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b87ad533.html alt=專訪哈工大劉挺教授：自然語言處理迎來黃金時代 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/R9ousgTAifYEft style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b87ad533.html title=專訪哈工大劉挺教授：自然語言處理迎來黃金時代>專訪哈工大劉挺教授：自然語言處理迎來黃金時代</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a7e96455.html alt=預計負債估計退貨怎麼做分錄？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153378087799927e114014c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a7e96455.html title=預計負債估計退貨怎麼做分錄？>預計負債估計退貨怎麼做分錄？</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/8e843790.html alt=哈工大羅俊團隊特稿：雙交替極橫向磁通直線電機的優化與設計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9050e94e3968443c970df75e3d39cd91 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/8e843790.html title=哈工大羅俊團隊特稿：雙交替極橫向磁通直線電機的優化與設計>哈工大羅俊團隊特稿：雙交替極橫向磁通直線電機的優化與設計</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/4f06653e.html alt=無花果的這波神操作，你估計想不到 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RU1DLnT6LWY0Eq style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/4f06653e.html title=無花果的這波神操作，你估計想不到>無花果的這波神操作，你估計想不到</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/d29cb639.html alt=鉑金做的“天價”車鑰匙，估計只有它才這麼做吧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1901ef1183e14479b619f0f840b19468 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/d29cb639.html title=鉑金做的“天價”車鑰匙，估計只有它才這麼做吧>鉑金做的“天價”車鑰匙，估計只有它才這麼做吧</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/7980a0fb.html alt=炮塔裝甲材料及結構估計為鋁合金裝甲全焊接結構 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/152258149547251d7d1ed07 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/7980a0fb.html title=炮塔裝甲材料及結構估計為鋁合金裝甲全焊接結構>炮塔裝甲材料及結構估計為鋁合金裝甲全焊接結構</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/ae18a091.html alt=你認識這四千個漢字嗎？估計沒多少人全部認識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/53ef000474cc162f6b23 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/ae18a091.html title=你認識這四千個漢字嗎？估計沒多少人全部認識！>你認識這四千個漢字嗎？估計沒多少人全部認識！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/78b2a580.html alt=BAT機器學習工業實戰教程-數理統計與參數估計-用樣本估計參數 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1526995800466a2a8bf5ddd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/78b2a580.html title=BAT機器學習工業實戰教程-數理統計與參數估計-用樣本估計參數>BAT機器學習工業實戰教程-數理統計與參數估計-用樣本估計參數</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/90eb0850.html alt=概率統計中的參數估計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/645aef33-49d3-4162-8aa9-b38b824c9165 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/90eb0850.html title=概率統計中的參數估計>概率統計中的參數估計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/40b2c20f.html alt="優必選悉尼 AI 研究院博士生：混合比例估計在弱監督學習和遷移學習中的延伸與應用｜分享總結" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/8b4b00004d6898c5eeee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/40b2c20f.html title="優必選悉尼 AI 研究院博士生：混合比例估計在弱監督學習和遷移學習中的延伸與應用｜分享總結">優必選悉尼 AI 研究院博士生：混合比例估計在弱監督學習和遷移學習中的延伸與應用｜分享總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e41781c.html alt=北京航空航天PK哈工大，同為軍工高校，誰的實力更強？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e41781c.html title=北京航空航天PK哈工大，同為軍工高校，誰的實力更強？>北京航空航天PK哈工大，同為軍工高校，誰的實力更強？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5afa3de.html alt=北航進入國內高校前十，哈工大排16，這個大學榜單你認同嗎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/70862be777224bdd967387adb334fd8a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5afa3de.html title=北航進入國內高校前十，哈工大排16，這個大學榜單你認同嗎>北航進入國內高校前十，哈工大排16，這個大學榜單你認同嗎</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>