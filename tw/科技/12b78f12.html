<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>TensorFlow實現時間序列預測 | 极客快訊</title><meta property="og:title" content="TensorFlow實現時間序列預測 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/27d989e04ac245cf9dc645bd7b60f356"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/12b78f12.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/12b78f12.html><meta property="article:published_time" content="2020-11-14T21:03:07+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:07+08:00"><meta name=Keywords content><meta name=description content="TensorFlow實現時間序列預測"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/12b78f12.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>TensorFlow實現時間序列預測</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>常常會碰到各種各樣時間序列預測問題，如商場人流量的預測、商品價格的預測、股價的預測，等等。TensorFlow新引入了一個TensorFlow Time Series庫（以下簡稱為TFTS），它可以幫助在TensorFlow中快速搭建高性能的時間序列預測系統，並提供包括AR、LSTM在內的多個模型。</p><h2 class=pgc-h-arrow-right>時間序列問題</h2><p>一般而言，時間序列數據抽象為兩部分：觀察的時間點和觀察的值 （以商品價格為例，某年一月的價格為120元，二月的價格為130元，三月的價格為135元，四月的價格為132元。那麼觀察的時間點可以看作是1,2,3,4，而在各時間點上觀察到的數據的值為120,130,135,132） 。觀察的時間點可以不連續，比如二月的數據有缺失，那麼實際的觀察時間點為1,3,4，對應的數據為120,135,132。 所謂時間序列預測，是指預測某些未來的時間點上（如5,6）數據的值應該是多少 。</p><p>TFTS庫按照時間點+觀察值的方式對時間序列問題進行抽象包裝。觀察的 <strong>時間點用“times”表示</strong> ，對應的 <strong>值用“values”表示</strong> 。在訓練模型時，輸入數據需要同時具有times和values兩個字段；在預測時，需要給定一些初始的數值，以及需要預測的時間點times。</p><h2 class=pgc-h-arrow-right>讀入時間序列數據</h2><p>在訓練模型之前，需要將時間序列數據讀入成Tensor的形式。 <strong>TFTS</strong> 庫中提供了兩個方便的讀取器</p><ul><li><strong>NumpyReader</strong> ：用於從Numpy數組中讀入數據</li><li><strong>CSVReader</strong> ：用於從CSV文件中讀入數據</li></ul><h2 class=pgc-h-arrow-right>從Numpy數組中讀取時間序列</h2><p>導入需要的包及函數</p><pre><code>import numpy as npimport matplotlibmatplotlib.use('agg')import matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.contrib.timeseries.python.timeseries import NumpyReader</code></pre><p>接著，利用np.sin生成一個實驗用的時間序列數據。該時間序列數據實際上是在正弦曲線上加入了上升的趨勢和一些隨機的噪聲：</p><pre><code>x = np.array(range(1000))noise = np.random.uniform(-0.2, 0.2, 1000)y = np.sin(np.pi * x / 100) + x / 200. + noiseplt.plot(x, y)plt.savefig('timeseries_y.jpg')</code></pre><div class=pgc-img><img alt=TensorFlow實現時間序列預測 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/27d989e04ac245cf9dc645bd7b60f356><p class=pgc-img-caption></p></div><p>橫座標對應變量“x”，縱座標對應變量“y”，它們分別對應之前提到過的“觀察的時間點”和“觀察到的值”。TFTS讀入x和y的方式非常簡單，請看下面的代碼：</p><pre><code>data = {    tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,    tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,}reader = NumpyReader(data)</code></pre><p>首先把x和y變成Python中的字典（變量data）。上面的定義直接寫成“ <strong>data={‘times':x, ‘values':y}</strong> ”也是可以的。寫成比較複雜的形式是為了和源碼中的寫法保持一致。</p><p>得到的reader有一個read_full()方法，它的返回值是時間序列對應的Tensor，可以用下面的代碼進行試驗：</p><pre><code>with tf.Session() as sess:    full_data = reader.read_full()    # 調用read_full方法會生成讀取隊列    # 要用tf.train.start_queue_runners啟動隊列才能正常進行讀取    coord = tf.train.Coordinator()    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    print(sess.run(full_data))    coord.request_stop()</code></pre><p>在訓練時，通常不會使用整個數據集進行訓練，而是採用batch的形式。從reader出發，建立batch數據的方法也很簡單：</p><pre><code>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(    reader, batch_size=2, window_size=10)</code></pre><p>tf.contrib.timeseries.RandomWindowInputFn會在reader的所有數據中，隨機選取窗口長度為window_size的序列，幷包裝成batch_size大小的batch數據。換句話說，一個batch內共有batch_size個序列，每個序列的長度為window_size。</p><p>以batch_size=2, window_size=10為例，可以打印出一個batch的數據：</p><pre><code>with tf.Session() as sess:    batch_data = train_input_fn.create_batch()    coord = tf.train.Coordinator()    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    one_batch = sess.run(batch_data[0])    coord.request_stop()print('one_batch_data:', one_batch)# one_batch_data: {'times': array([[11, 12, 13, 14, 15, 16, 17, 18, 19, 20],#        [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]]), 'values': array([[[0.33901882],#         [0.29966548],#         [0.64006627],#         [0.35204604],#         [0.66049626],#         [0.57470108],#         [0.68309054],#         [0.46613038],#         [0.60309193],#         [0.84166497]],# #        [[0.77312242],#         [0.82185951],#         [0.71022706],#         [0.63987861],#         [0.7011966 ],#         [0.84051192],#         [1.05796465],#         [0.92981324],#         [1.0542786 ],#         [0.89828743]]])}</code></pre><p>原先的數據長度為1000的時間序列（x=np.array(range(1000))），使用tf.contrib.timeseries.RandomWindowInputFn，並指定window_size=10, batch_size=2的功能是在這長度為1000的時間序列中，隨機選取長度為10的序列，並在每個batch裡包含兩個這樣的序列。這也可以從打印出的數據中看出來。</p><p>使用tf.contrib.timeseries.RandomWindowInputFn返回的train_input_fn可以進行訓練了。這是在TFTS中讀入Numpy數組時間序列的基本方式。下面介紹如何讀入CSV格式的數據。</p><h2 class=pgc-h-arrow-right>從CSV文件中讀取時間序列</h2><p>有時，時間序列數據是存在CSV文件中的。當然可以將其先讀入為Numpy數組，再使用之前的方法處理。更方便的做法是使用tf.contrib.timeseries.CSVReader讀入。數據文件 <strong>period_trend.csv</strong></p><p>假設CSV文件的時間序列數據的形式為：</p><pre><code>1,-0.66566037142,-0.11643803593,0.73986264884,0.73686330295,0.2289480898...</code></pre><p>CSV文件的第一列為時間點，第二列為該時間點上觀察到的值。將其讀入的方法為：</p><pre><code>import tensorflow as tfcsv_file_name = './period_trend.csv'reader = tf.contrib.timeseries.CSVReader(csv_file_name)</code></pre><p>實際讀入的代碼只有一行，直接使用函數tf.contrib.timeseries.CSVReader得到了reader。將reader中所有數據打印出來的方法和之前是一樣的：</p><pre><code>with tf.Session() as sess:    data = reader.read_full()    coord = tf.train.Coordinator()    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    print(sess.run(data))    coord.request_stop()</code></pre><p>從reader出發，建立batch數據的train_input_fn的方法也完全相同：</p><pre><code>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(reader, batch_size=4, window_size=16)</code></pre><p>最後，可以打印出兩個batch的數據進行測試：</p><pre><code>with tf.Session() as sess:    data = train_input_fn.create_batch()    coord = tf.train.Coordinator()    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    batch1 = sess.run(data[0])    batch2 = sess.run(data[0])    coord.request_stop()print('batch1:', batch1)print('batch2:', batch2)</code></pre><p>以上是TFTS庫中數據的讀取方式。總的來說， 從Numpy數組或者CSV文件出發構造一個reader，再利用reader生成batch數據。最後得到的Tensor為train_input_fn，這個train_input_fn會被當作訓練時的輸入 。</p><h2 class=pgc-h-arrow-right>使用AR模型預測時間序列</h2><h2 class=pgc-h-arrow-right>AR模型的訓練</h2><p>自迴歸模型（Autoregressive model，簡稱為AR模型）是統計學上處理時間序列模型的基本方法之一。TFTS中已經實現了一個自迴歸模型，我們只需要對其進行調用即可使用。</p><p>我們先定義出一個train_input_fn</p><pre><code>x = np.array(range(1000))noise = np.random.uniform(-0.2, 0.2, 1000)y = np.sin(np.pi * x / 100) + x / 200. + noiseplt.plot(x, y)plt.savefig('timeseries_y.jpg')data = {    tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,    tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,}reader = NumpyReader(data)train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(    reader, batch_size=16, window_size=40)</code></pre><p>使用的時間序列數據如圖所示。</p><div class=pgc-img><img alt=TensorFlow實現時間序列預測 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c61ac017d78444ed87facc63b0119a1f><p class=pgc-img-caption></p></div><p>定義AR模型：</p><pre><code>ar = tf.contrib.timeseries.ARRegressor(    periodicities=200, input_window_size=30, output_window_size=10,    num_features=1,    loss=tf.contrib.timeseries.ARModel.NORMAL_LIKELIHOOD_LOSS)</code></pre><p>參數：</p><ul><li><strong>periodicities</strong> ：序列的規律性週期。在定義數據時使用的語句是“y=np.sin(np.pi * x /100)+x /200.+noise”，因此週期為200</li><li><strong>input_window_size</strong> ：模型每次輸入的值</li><li><strong>output_window_size</strong> ：模型每次輸出的值</li><li><strong>num_features</strong> ：表示在一個時間點上觀察到的數的維度。這裡每一步都是一個單獨的值，所以num_features=1</li><li><strong>loss</strong> ：指定採取哪一種損失，NORMAL_LIKELIHOOD_LOSS 或 SQUARED_LOSS</li><li><strong>model_dir</strong> ：模型訓練好後保存的地址，如果不指定的話，會隨機分配一個臨時地址</li></ul><p>input_window_size和output_window_size加起來必須等於train_input_fn中總的window_size。總的window_size為40, input_window_size為30,output_window_size為10；也是說，一個batch內每個序列的長度為40，其中前30個數被當作模型的輸入值，後面10個數為這些輸入對應的目標輸出值。</p><p>使用變量ar的train方法可以直接進行訓練：</p><pre><code>ar.train(input_fn=train_input_fn, steps=6000)</code></pre><h2 class=pgc-h-arrow-right>AR模型的驗證和預測</h2><p>TFTS中驗證（evaluation）的含義是：使用訓練好的模型在原先的訓練集上進行計算，由此可以觀察到模型的擬合效果，對應的程序段是：</p><pre><code>evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)# keys of evaluation: ['covariance', 'loss', 'mean', 'observed', 'start_tuple', 'times', 'global_step']evaluation = ar.evaluate(input_fn=evaluation_input_fn, steps=1)</code></pre><p>如果想要明白這裡的邏輯，首先要理解之前定義的AR模型：它每次都接收一個長度為30的輸入觀測序列，並輸出長度為10的預測序列。整個訓練集是一個長度為1000的序列，前30個數首先被當作“初始觀測序列”輸入到模型中，由此可以計算出下面10步的預測值。接著又會取30個數進行預測， 這30個數中有10個數是前一步的預測值 ，新得到的預測值又會變成下一步的輸入，依此類推。</p><p>最終得到970個預測值（970=1000-30，因為前30個數是沒辦法進行預測的）。970個預測值被記錄在 <strong>evaluation[‘mean']</strong> 中。evaluation還有其他幾個鍵值，如 <strong>evaluation[‘times']</strong> 表示evaluation[‘mean']對應的時間點， <strong>evaluation[‘loss']</strong> 表示總的損失等等。</p><p>evaluation[‘start_tuple']會被用於之後的預測中，它相當於最後30步的輸出值和對應的時間點。以此為起點，可以對1000步以後的值進行預測，對應的代碼為：</p><pre><code>(predictions,) = tuple(ar.predict(    input_fn=tf.contrib.timeseries.predict_continuation_input_fn(        evaluation, steps=250)))</code></pre><p>這裡的代碼在1000步之後又向後預測了250個時間點。對應的值保存在predictions[‘mean']中。可以把觀測到的值、模型擬合的值、預測值用下面的代碼畫出來：</p><pre><code>plt.figure(figsize=(15, 5))plt.plot(data['times'].reshape(-1), data['values'].reshape(-1), label='origin')plt.plot(evaluation['times'].reshape(-1), evaluation['mean'].reshape(-1), label='evaluation')plt.plot(predictions['times'].reshape(-1), predictions['mean'].reshape(-1), label='prediction')plt.xlabel('time_step')plt.ylabel('values')plt.legend(loc=4)plt.savefig('predict_result.jpg')</code></pre><div class=pgc-img><img alt=TensorFlow實現時間序列預測 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f67442c9ddd748568983486f0009d1cb><p class=pgc-img-caption></p></div><p>前1000步模型原始觀測值的曲線和模型擬合值非常接近，說明模型擬合得已經比較好了，1000步之後的預測也合情合理。</p><pre><code># coding: utf-8from __future__ import print_functionimport numpy as npimport matplotlibmatplotlib.use('agg')import matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.contrib.timeseries.python.timeseries import  NumpyReaderdef main(_):    x = np.array(range(1000))    noise = np.random.uniform(-0.2, 0.2, 1000)    y = np.sin(np.pi * x / 100) + x / 200. + noise    plt.plot(x, y)    plt.savefig('timeseries_y.jpg')    data = {        tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,        tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,    }    reader = NumpyReader(data)    train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(        reader, batch_size=16, window_size=40)    ar = tf.contrib.timeseries.ARRegressor(        periodicities=200, input_window_size=30, output_window_size=10,        num_features=1,        loss=tf.contrib.timeseries.ARModel.NORMAL_LIKELIHOOD_LOSS)    ar.train(input_fn=train_input_fn, steps=6000)    evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)    # keys of evaluation: ['covariance', 'loss', 'mean', 'observed', 'start_tuple', 'times', 'global_step']    evaluation = ar.evaluate(input_fn=evaluation_input_fn, steps=1)    (predictions,) = tuple(ar.predict(        input_fn=tf.contrib.timeseries.predict_continuation_input_fn(            evaluation, steps=250)))    plt.figure(figsize=(15, 5))    plt.plot(data['times'].reshape(-1), data['values'].reshape(-1), label='origin')    plt.plot(evaluation['times'].reshape(-1), evaluation['mean'].reshape(-1), label='evaluation')    plt.plot(predictions['times'].reshape(-1), predictions['mean'].reshape(-1), label='prediction')    plt.xlabel('time_step')    plt.ylabel('values')    plt.legend(loc=4)    plt.savefig('predict_result.jpg')if __name__ == '__main__':    tf.logging.set_verbosity(tf.logging.INFO)    tf.app.run()示例完整代碼</code></pre><h2 class=pgc-h-arrow-right>使用LSTM模型預測時間序列</h2><p>為了使用LSTM模型，需要先使用TFTS庫對其進行定義。</p><h2 class=pgc-h-arrow-right>單變量時間序列預測</h2><p>同樣，用函數加噪聲的方法模擬生成時間序列數據：</p><pre><code>x = np.array(range(1000))noise = np.random.uniform(-0.2, 0.2, 1000)y = np.sin(np.pi * x / 50) + np.cos(np.pi * x / 50) + np.sin(np.pi * x / 25) + noisedata = {    tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,    tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,}reader = NumpyReader(data)train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(    reader, batch_size=4, window_size=100)</code></pre><p>得到y和x後，使用NumpyReader讀入為Tensor形式，接著用tf.contrib.timeseries.RandomWindowInputFn將其變為batch訓練數據。一個batch中有4個隨機選取的序列，每個序列的長度為100。</p><p>接下來定義一個LSTM模型：</p><pre><code>estimator = ts_estimators.TimeSeriesRegressor(        model=_LSTMModel(num_features=1, num_units=128),        optimizer=tf.train.AdamOptimizer(0.001))</code></pre><p>num_features=1表示單變量時間序列，即每個時間點上觀察到的量只是一個單獨的數值，num_units=128表示使用隱層為128大小的LSTM模型。</p><p>訓練、驗證和預測的方法都和之前類似。在訓練時，在已有的1000步的觀察量的基礎上向後預測200步：</p><pre><code>estimator.train(input_fn=train_input_fn, steps=2000)　　　　# 訓練模型evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)　　# 測試數據evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)　　# 得到評估後的數據# 評估後預測200步數據(predictions,) = tuple(estimator.predict(    input_fn=tf.contrib.timeseries.predict_continuation_input_fn(        evaluation, steps=200)))</code></pre><p>將驗證、預測的結果取出並畫成示意圖，畫出的圖像會保存成“predict_result.jpg”文件：</p><pre><code>observed_times = evaluation["times"][0]observed = evaluation["observed"][0, :, :]evaluated_times = evaluation["times"][0]evaluated = evaluation["mean"][0]predicted_times = predictions['times']predicted = predictions["mean"]plt.figure(figsize=(15, 5))plt.axvline(999, linestyle="dotted", linewidth=4, color='r')observed_lines = plt.plot(observed_times, observed, label="observation", color="k")evaluated_lines = plt.plot(evaluated_times, evaluated, label="evaluation", color="g")predicted_lines = plt.plot(predicted_times, predicted, label="prediction", color="r")plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],           loc="upper left")plt.savefig('predict_result.jpg')</code></pre><p>預測效果如圖15-4所示，橫座標為時間軸，前1000步是訓練數據，1000~1200步是模型預測的值。</p><div class=pgc-img><img alt=TensorFlow實現時間序列預測 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4e65f29cb64440e2ae522107ff38c84d><p class=pgc-img-caption></p></div><pre><code>import numpy as npimport tensorflow as tffrom tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimatorsfrom tensorflow.contrib.timeseries.python.timeseries import model as ts_modelfrom tensorflow.contrib.timeseries.python.timeseries import NumpyReaderimport matplotlibmatplotlib.use("agg")import matplotlib.pyplot as pltclass _LSTMModel(ts_model.SequentialTimeSeriesModel):    """A time series model-building example using an RNNCell."""    def __init__(self, num_units, num_features, dtype=tf.float32):        """Initialize/configure the model object.        Note that we do not start graph building here. Rather, this object is a        configurable factory for TensorFlow graphs which are run by an Estimator.        Args:          num_units: The number of units in the model's LSTMCell.          num_features: The dimensionality of the time series (features per            timestep).          dtype: The floating point data type to use.        """        super(_LSTMModel, self).__init__(            # Pre-register the metrics we'll be outputting (just a mean here).            train_output_names=["mean"],            predict_output_names=["mean"],            num_features=num_features,            dtype=dtype)        self._num_units = num_units        # Filled in by initialize_graph()        self._lstm_cell = None        self._lstm_cell_run = None        self._predict_from_lstm_output = None    def initialize_graph(self, input_statistics):        """Save templates for components, which can then be used repeatedly.        This method is called every time a new graph is created. It's safe to start        adding ops to the current default graph here, but the graph should be        constructed from scratch.        Args:          input_statistics: A math_utils.InputStatistics object.        """        super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)        self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)        # Create templates so we don't have to worry about variable reuse.        self._lstm_cell_run = tf.make_template(            name_="lstm_cell",            func_=self._lstm_cell,            create_scope_now_=True)        # Transforms LSTM output into mean predictions.        self._predict_from_lstm_output = tf.make_template(            name_="predict_from_lstm_output",            func_=lambda inputs: tf.layers.dense(inputs=inputs, units=self.num_features),            create_scope_now_=True)    def get_start_state(self):        """Return initial state for the time series model."""        return (            # Keeps track of the time associated with this state for error checking.            tf.zeros([], dtype=tf.int64),            # The previous observation or prediction.            tf.zeros([self.num_features], dtype=self.dtype),            # The state of the RNNCell (batch dimension removed since this parent            # class will broadcast).            [tf.squeeze(state_element, axis=0)             for state_element             in self._lstm_cell.zero_state(batch_size=1, dtype=self.dtype)])    def _transform(self, data):        """Normalize data based on input statistics to encourage stable training."""        mean, variance = self._input_statistics.overall_feature_moments        return (data - mean) / variance    def _de_transform(self, data):        """Transform data back to the input scale."""        mean, variance = self._input_statistics.overall_feature_moments        return data * variance + mean    def _filtering_step(self, current_times, current_values, state, predictions):        """Update model state based on observations.        Note that we don't do much here aside from computing a loss. In this case        it's easier to update the RNN state in _prediction_step, since that covers        running the RNN both on observations (from this method) and our own        predictions. This distinction can be important for probabilistic models,        where repeatedly predicting without filtering should lead to low-confidence        predictions.        Args:          current_times: A [batch size] integer Tensor.          current_values: A [batch size, self.num_features] floating point Tensor            with new observations.          state: The model's state tuple.          predictions: The output of the previous `_prediction_step`.        Returns:          A tuple of new state and a predictions dictionary updated to include a          loss (note that we could also return other measures of goodness of fit,          although only "loss" will be optimized).        """        state_from_time, prediction, lstm_state = state        with tf.control_dependencies(                [tf.assert_equal(current_times, state_from_time)]):            transformed_values = self._transform(current_values)            # Use mean squared error across features for the loss.            predictions["loss"] = tf.reduce_mean(                (prediction - transformed_values) ** 2, axis=-1)            # Keep track of the new observation in model state. It won't be run            # through the LSTM until the next _imputation_step.            new_state_tuple = (current_times, transformed_values, lstm_state)        return (new_state_tuple, predictions)    def _prediction_step(self, current_times, state):        """Advance the RNN state using a previous observation or prediction."""        _, previous_observation_or_prediction, lstm_state = state        lstm_output, new_lstm_state = self._lstm_cell_run(            inputs=previous_observation_or_prediction, state=lstm_state)        next_prediction = self._predict_from_lstm_output(lstm_output)        new_state_tuple = (current_times, next_prediction, new_lstm_state)        return new_state_tuple, {"mean": self._de_transform(next_prediction)}    def _imputation_step(self, current_times, state):        """Advance model state across a gap."""        # Does not do anything special if we're jumping across a gap. More advanced        # models, especially probabilistic ones, would want a special case that        # depends on the gap size.        return state    def _exogenous_input_step(            self, current_times, current_exogenous_regressors, state):        """Update model state based on exogenous regressors."""        raise NotImplementedError(            "Exogenous inputs are not implemented for this example.")if __name__ == '__main__':    tf.logging.set_verbosity(tf.logging.INFO)    x = np.array(range(1000))    noise = np.random.uniform(-0.2, 0.2, 1000)    y = np.sin(np.pi * x / 50) + np.cos(np.pi * x / 50) + np.sin(np.pi * x / 25) + noise    data = {        tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,        tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,    }    reader = NumpyReader(data)    train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(        reader, batch_size=4, window_size=100)    estimator = ts_estimators.TimeSeriesRegressor(        model=_LSTMModel(num_features=1, num_units=128),        optimizer=tf.train.AdamOptimizer(0.001))    estimator.train(input_fn=train_input_fn, steps=2000)    evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)    evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)    # Predict starting after the evaluation    (predictions,) = tuple(estimator.predict(        input_fn=tf.contrib.timeseries.predict_continuation_input_fn(            evaluation, steps=200)))    observed_times = evaluation["times"][0]    observed = evaluation["observed"][0, :, :]    evaluated_times = evaluation["times"][0]    evaluated = evaluation["mean"][0]    predicted_times = predictions['times']    predicted = predictions["mean"]    plt.figure(figsize=(15, 5))    plt.axvline(999, linestyle="dotted", linewidth=4, color='r')    observed_lines = plt.plot(observed_times, observed, label="observation", color="k")    evaluated_lines = plt.plot(evaluated_times, evaluated, label="evaluation", color="g")    predicted_lines = plt.plot(predicted_times, predicted, label="prediction", color="r")    plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],               loc="upper left")    plt.savefig('predict_result.jpg')LSTM單變量完整代碼</code></pre><h2 class=pgc-h-arrow-right>多變量時間序列預測</h2><p>所謂多變量時間序列，是指在每個時間點上的觀測量有多個值。在 <strong>multivariate_periods.csv</strong> 文件中，保存了一個多變量時間序列的數據：</p><pre><code>0    0.926906299771    1.99107237682    2.56546245685    3.07914768197    4.048390578671    0.108010001864    1.41645361423    2.1686839775    2.94963962176    4.12635033032    -0.800567600028    1.0172132907    1.96434754116    2.99885333086    4.043004858643    0.0607042871898    0.719540073421    1.9765012584    2.89265588817    4.0951014426...99    0.987764008058    1.85581989607    2.84685706149    2.94760204892    6.0212151724</code></pre><p>這個CSV文件的第一列是觀察時間點，除此之外，每一行還有5個數，表示在這個時間點上觀察到的數據。換句話說，時間序列上每一步都是一個5維的向量。</p><p>使用TFTS讀入該CSV文件的方法為：</p><pre><code>csv_file_name = path.join("./data/multivariate_periods.csv")reader = tf.contrib.timeseries.CSVReader(    csv_file_name,    column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)                  + (tf.contrib.timeseries.TrainEvalFeatures.VALUES,) * 5))train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(    reader, batch_size=4, window_size=32)</code></pre><p>與之前的讀入相比，唯一的區別是column_names參數。它告訴TFTS在CSV文件中，哪些列表示時間，哪些列表示觀測量。</p><p>接下來定義LSTM模型：</p><pre><code>estimator = ts_estimators.TimeSeriesRegressor(    model=_LSTMModel(num_features=5, num_units=128),    optimizer=tf.train.AdamOptimizer(0.001))</code></pre><p>區別在於使用num_features=5而不是1，原因在於每個時間點上的觀測量是一個5維向量。</p><p>訓練、驗證、預測及畫圖的代碼與之前比較類似，最後的運行結果圖所示</p><div class=pgc-img><img alt=TensorFlow實現時間序列預測 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7de9c244d52f43d09e0bc5652d2ea00d><p class=pgc-img-caption></p></div><p>使用LSTM預測多變量時間序列</p><p>前100步是訓練數據，一條線代表觀測量在一個維度上的取值。100步之後為預測值。</p><pre><code>from os import pathimport tensorflow as tffrom tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimatorsfrom tensorflow.contrib.timeseries.python.timeseries import model as ts_modelimport matplotlibmatplotlib.use("agg")import matplotlib.pyplot as pltclass _LSTMModel(ts_model.SequentialTimeSeriesModel):    """A time series model-building example using an RNNCell."""    def __init__(self, num_units, num_features, dtype=tf.float32):        """Initialize/configure the model object.        Note that we do not start graph building here. Rather, this object is a        configurable factory for TensorFlow graphs which are run by an Estimator.        Args:          num_units: The number of units in the model's LSTMCell.          num_features: The dimensionality of the time series (features per            timestep).          dtype: The floating point data type to use.        """        super(_LSTMModel, self).__init__(            # Pre-register the metrics we'll be outputting (just a mean here).            train_output_names=["mean"],            predict_output_names=["mean"],            num_features=num_features,            dtype=dtype)        self._num_units = num_units        # Filled in by initialize_graph()        self._lstm_cell = None        self._lstm_cell_run = None        self._predict_from_lstm_output = None    def initialize_graph(self, input_statistics):        """Save templates for components, which can then be used repeatedly.        This method is called every time a new graph is created. It's safe to start        adding ops to the current default graph here, but the graph should be        constructed from scratch.        Args:          input_statistics: A math_utils.InputStatistics object.        """        super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)        self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)        # Create templates so we don't have to worry about variable reuse.        self._lstm_cell_run = tf.make_template(            name_="lstm_cell",            func_=self._lstm_cell,            create_scope_now_=True)        # Transforms LSTM output into mean predictions.        self._predict_from_lstm_output = tf.make_template(            name_="predict_from_lstm_output",            func_=lambda inputs: tf.layers.dense(inputs=inputs, units=self.num_features),            create_scope_now_=True)    def get_start_state(self):        """Return initial state for the time series model."""        return (            # Keeps track of the time associated with this state for error checking.            tf.zeros([], dtype=tf.int64),            # The previous observation or prediction.            tf.zeros([self.num_features], dtype=self.dtype),            # The state of the RNNCell (batch dimension removed since this parent            # class will broadcast).            [tf.squeeze(state_element, axis=0)             for state_element             in self._lstm_cell.zero_state(batch_size=1, dtype=self.dtype)])    def _transform(self, data):        """Normalize data based on input statistics to encourage stable training."""        mean, variance = self._input_statistics.overall_feature_moments        return (data - mean) / variance    def _de_transform(self, data):        """Transform data back to the input scale."""        mean, variance = self._input_statistics.overall_feature_moments        return data * variance + mean    def _filtering_step(self, current_times, current_values, state, predictions):        """Update model state based on observations.        Note that we don't do much here aside from computing a loss. In this case        it's easier to update the RNN state in _prediction_step, since that covers        running the RNN both on observations (from this method) and our own        predictions. This distinction can be important for probabilistic models,        where repeatedly predicting without filtering should lead to low-confidence        predictions.        Args:          current_times: A [batch size] integer Tensor.          current_values: A [batch size, self.num_features] floating point Tensor            with new observations.          state: The model's state tuple.          predictions: The output of the previous `_prediction_step`.        Returns:          A tuple of new state and a predictions dictionary updated to include a          loss (note that we could also return other measures of goodness of fit,          although only "loss" will be optimized).        """        state_from_time, prediction, lstm_state = state        with tf.control_dependencies(                [tf.assert_equal(current_times, state_from_time)]):            transformed_values = self._transform(current_values)            # Use mean squared error across features for the loss.            predictions["loss"] = tf.reduce_mean(                (prediction - transformed_values) ** 2, axis=-1)            # Keep track of the new observation in model state. It won't be run            # through the LSTM until the next _imputation_step.            new_state_tuple = (current_times, transformed_values, lstm_state)        return (new_state_tuple, predictions)    def _prediction_step(self, current_times, state):        """Advance the RNN state using a previous observation or prediction."""        _, previous_observation_or_prediction, lstm_state = state        lstm_output, new_lstm_state = self._lstm_cell_run(            inputs=previous_observation_or_prediction, state=lstm_state)        next_prediction = self._predict_from_lstm_output(lstm_output)        new_state_tuple = (current_times, next_prediction, new_lstm_state)        return new_state_tuple, {"mean": self._de_transform(next_prediction)}    def _imputation_step(self, current_times, state):        """Advance model state across a gap."""        # Does not do anything special if we're jumping across a gap. More advanced        # models, especially probabilistic ones, would want a special case that        # depends on the gap size.        return state    def _exogenous_input_step(            self, current_times, current_exogenous_regressors, state):        """Update model state based on exogenous regressors."""        raise NotImplementedError(            "Exogenous inputs are not implemented for this example.")if __name__ == '__main__':    tf.logging.set_verbosity(tf.logging.INFO)    csv_file_name = path.join("./data/multivariate_periods.csv")    reader = tf.contrib.timeseries.CSVReader(        csv_file_name,        column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)                      + (tf.contrib.timeseries.TrainEvalFeatures.VALUES,) * 5))    train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(        reader, batch_size=4, window_size=32)    estimator = ts_estimators.TimeSeriesRegressor(        model=_LSTMModel(num_features=5, num_units=128),        optimizer=tf.train.AdamOptimizer(0.001))    estimator.train(input_fn=train_input_fn, steps=200)    evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)    evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)    # Predict starting after the evaluation    (predictions,) = tuple(estimator.predict(        input_fn=tf.contrib.timeseries.predict_continuation_input_fn(            evaluation, steps=100)))    observed_times = evaluation["times"][0]    observed = evaluation["observed"][0, :, :]    evaluated_times = evaluation["times"][0]    evaluated = evaluation["mean"][0]    predicted_times = predictions['times']    predicted = predictions["mean"]    plt.figure(figsize=(15, 5))    plt.axvline(99, linestyle="dotted", linewidth=4, color='r')    observed_lines = plt.plot(observed_times, observed, label="observation", color="k")    evaluated_lines = plt.plot(evaluated_times, evaluated, label="evaluation", color="g")    predicted_lines = plt.plot(predicted_times, predicted, label="prediction", color="r")    plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],               loc="upper left")    plt.savefig('predict_result.jpg')LSTM多變量完整代碼</code></pre></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>TensorFlow</a></li><li><a>實現</a></li><li><a>時間</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/27b407d4.html alt=Excel實現日期時間快速分離的5種方法，快來了解下吧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/32121720077f4b4198c2b485be3dbb37 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/27b407d4.html title=Excel實現日期時間快速分離的5種方法，快來了解下吧>Excel實現日期時間快速分離的5種方法，快來了解下吧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac68602d.html alt=職場上實現有效時間管理，提高工作效率的方法有哪些？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/5e720001933040e62bb0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac68602d.html title=職場上實現有效時間管理，提高工作效率的方法有哪些？>職場上實現有效時間管理，提高工作效率的方法有哪些？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/35379e4.html alt=用時間繼電器實現負載間隔運行的幾種電氣控制電路 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1529732986004f0abad7973 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/35379e4.html title=用時間繼電器實現負載間隔運行的幾種電氣控制電路>用時間繼電器實現負載間隔運行的幾種電氣控制電路</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0c39d52.html alt=實現量子安全時間傳遞奠定未來導航基礎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0c39d52.html title=實現量子安全時間傳遞奠定未來導航基礎>實現量子安全時間傳遞奠定未來導航基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/14feb44.html alt=時間“倒流”首次在量子計算機上實現 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RL1WntOB3RtvPD style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/14feb44.html title=時間“倒流”首次在量子計算機上實現>時間“倒流”首次在量子計算機上實現</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d25f7fd.html alt=量子可以實現“時間”反轉了？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d3c72cb8d28a4bc3aff3d29c36cd18ec style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d25f7fd.html title=量子可以實現“時間”反轉了？>量子可以實現“時間”反轉了？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f09ac34c.html alt=彩色電子書在廣州率先實現量產 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RkPMb9G6tipobr style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f09ac34c.html title=彩色電子書在廣州率先實現量產>彩色電子書在廣州率先實現量產</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/65709773.html alt=幹海帶泡軟太浪費時間了，這個小妙招處理後，三分鐘就變軟 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/66b80001068b5f6c9893 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/65709773.html title=幹海帶泡軟太浪費時間了，這個小妙招處理後，三分鐘就變軟>幹海帶泡軟太浪費時間了，這個小妙招處理後，三分鐘就變軟</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2d12804e.html alt=[玩轉MySQL之九]MySQL實現ACID之原子性 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb044d821f74107a3fd9119fc34c642 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2d12804e.html title=[玩轉MySQL之九]MySQL實現ACID之原子性>[玩轉MySQL之九]MySQL實現ACID之原子性</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fb2bc471.html alt="「譯」 Spring 的分佈式事務實現—使用和不使用 XA—第二部分" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fb2bc471.html title="「譯」 Spring 的分佈式事務實現—使用和不使用 XA—第二部分">「譯」 Spring 的分佈式事務實現—使用和不使用 XA—第二部分</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e41fd8de.html alt="撫順各項防汛工作實現“六到位” 確保全市安全度汛" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e41fd8de.html title="撫順各項防汛工作實現“六到位” 確保全市安全度汛">撫順各項防汛工作實現“六到位” 確保全市安全度汛</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f22ee5ad.html alt="Redis 設計與實現 : Lua 腳本" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f22ee5ad.html title="Redis 設計與實現 : Lua 腳本">Redis 設計與實現 : Lua 腳本</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ebbbc375.html alt=時間繼電器測試儀的使用方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1205bf787f1f4de6a5f1e73e7737887b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ebbbc375.html title=時間繼電器測試儀的使用方法>時間繼電器測試儀的使用方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/56e2a065.html alt=這位大叔在隨機的彩票上實現了90%的中獎率 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/50ab0003166decded7e4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/56e2a065.html title=這位大叔在隨機的彩票上實現了90%的中獎率>這位大叔在隨機的彩票上實現了90%的中獎率</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cf633068.html alt="Java 多態的實現機制，看了都說好" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9d3b0e55813d46b4982ae7d9b81d1802 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cf633068.html title="Java 多態的實現機制，看了都說好">Java 多態的實現機制，看了都說好</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>