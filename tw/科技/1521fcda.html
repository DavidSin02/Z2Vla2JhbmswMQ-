<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍 | 极客快訊</title><meta property="og:title" content="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/6c3f0004669244ec2591"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1521fcda.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1521fcda.html><meta property="article:published_time" content="2020-10-29T21:10:03+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:03+08:00"><meta name=Keywords content><meta name=description content="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/1521fcda.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>【2018 新智元 AI 技術峰會倒計時 18 天】</strong></p><p><strong>諾貝爾獎唯一計算機領域評委親臨，峰會首批嘉賓陣容公佈</strong></p><p>早鳥票已經售罄，現正式進入全額票階段。 即將於北京舉辦的<strong> 2018 年中國 AI 開年盛典——2018 新智元 AI 技術峰會</strong>上，我們邀請到了德國總理默克爾的科學顧問、諾貝爾獎唯一計算機領域評委、工業 4.0 教父、世界頂級自然語言處理專家 Wolfgang Wahlste 教授。Wahlster 教授將親臨 329 峰會現場分享歐洲對人工智能科技發展和 AI 產業化的思考。想現場一睹諾獎評委的風采，點擊搶票鏈接，馬上參會！</p><p><strong>搶票鏈接：<span>http://www.huodongxing.com/event/8426451122400</span></strong></p><hr><p><strong>新智元專欄</strong></p><p>來源：阿里巴巴語音交互智能團隊</p><p>作者：畢夢霄，盧恆，張仕良，雷鳴，鄢志傑</p><p>會議：ICASSP-2018</p><p><strong>【新智元導讀】</strong>阿里巴巴語音交互智能團隊提出一種基於深度前饋序列記憶網絡的語音合成系統。該系統在達到與基於雙向長短時記憶單元的語音合成系統一致的主觀聽感的同時，模型大小隻有後者的四分之一，且合成速度是後者的四倍，非常適合於對內存佔用和計算效率非常敏感的端上產品環境。該研究已入選語音頂會ICASSP會議Oral論文，本文帶來詳細解讀。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6c3f0004669244ec2591></p><h1>研究背景</h1><p>語音合成系統主要分為兩類，<strong>拼接合成系統</strong>和<strong>參數合成系統</strong>。其中參數合成系統在引入了神經網絡作為模型之後，合成質量和自然度都獲得了長足的進步。另一方面，物聯網設備（例如智能音箱和智能電視）的大量普及也對在設備上部署的參數合成系統提出了計算資源的限制和實時率的要求。<strong>本工作引入的深度前饋序列記憶網絡可以在保持合成質量的同時，有效降低計算量，提高合成速度。</strong></p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6c3e00056702b5d97099></p><p>我們使用基於<strong>雙向長短時記憶單元（BLSTM）</strong>的統計參數語音合成系統作為基線系統。與其他現代統計參數語音合成系統相似，我們提出的<strong>基於深度前饋序列記憶網絡（DFSMN）</strong>的統計參數語音合成系統也是由3個主要部分組成，<strong>聲音合成器（vocoder），前端模塊和後端模塊</strong>，如上圖所示。我們使用開源工具WORLD作為我們的聲音合成器，用來在模型訓練時從原始語音波形中提取頻譜信息、基頻的對數、頻帶週期特徵（BAP）和清濁音標記，也用來在語音合成時完成從聲學參數到實際聲音的轉換。前端模塊用來對輸入的文本進行正則化和詞法分析，我們把這些語言學特徵編碼後作為神經網絡訓練的輸入。後端模塊用來建立從輸入的語言學特徵到聲學參數的映射，在我們的系統中，我們使用DFSMN作為後端模塊。</p><h1>深度前饋序列記憶網絡</h1><p>緊湊前饋序列記憶網絡（cFSMN）作為標準的前饋序列記憶網絡（FSMN）的改進版本，在網絡結構中引入了低秩矩陣分解，這種改進簡化了FSMN，減少了模型的參數量，並加速了模型的訓練和預測過程。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed30000e0710d626233></p><p>上圖給出了cFSMN的結構的圖示。對於神經網絡的每一個cFSMN層，計算過程可表示成以下步驟①經過一個線性映射，把上一層的輸出映射到一個低維向量②記憶模塊執行計算，計算當前幀之前和之後的若干幀和當前幀的低維向量的逐維加權和③把該加權和再經過一個仿射變換和一個非線性函數，得到當前層的輸出。三個步驟可依次表示成如下公式。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed2000333b826771ba7></p><p>與循環神經網絡（RNNs，包括BLSTM）類似，通過調整記憶模塊的階數，cFSMN有能力捕捉序列的長程信息。另一方面，cFSMN可以直接通過反向傳播算法（BP）進行訓練，與必須使用沿時間反向傳播算法（BPTT）進行訓練的RNNs相比，訓練cFSMN速度更快，且較不容易受到梯度消失的影響。</p><p>對cFSMN進一步改進，我們得到了深度前饋序列記憶網絡（DFSMN）。DFSMN利用了在各類深度神經網絡中被廣泛使用的跳躍連接（skip-connections）技術，使得執行反向傳播算法的時候，梯度可以繞過非線性變換，即使堆疊了更多DFSMN層，網絡也能快速且正確地收斂。對於DFSMN模型，增加深度的好處有兩個方面。一方面，更深的網絡一般來說具有更強的表徵能力，另一方面，增加深度可以間接地增大DFSMN模型預測當前幀的輸出時可以利用的上下文長度，這在直觀上非常有利於捕捉序列的長程信息。具體來說，我們把跳躍連接添加到了相鄰兩層的記憶模塊之間，如下面公式所示。由於DFSMN各層的記憶模塊的維數相同，跳躍連接可由恆等變換實現。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ed2000333b9bd9e193e></p><p>我們可以認為DFSMN是一種非常靈活的模型。當輸入序列很短，或者對預測延時要求較高的時候，可以使用較小的記憶模塊階數，在這種情況下只有當前幀附近幀的信息被用來預測當前幀的輸出。而如果輸入序列很長，或者在預測延時不是那麼重要的場景中，可以使用較大的記憶模塊階數，那麼序列的長程信息就能被有效利用和建模，從而有利於提高模型的性能。</p><p>除了階數之外，我們為DFSMN的記憶模塊增加了另一個超參數，步長（stride），用來表示記憶模塊提取過去或未來幀的信息時，跳過多少相鄰的幀。這是有依據的，因為與語音識別任務相比，語音合成任務相鄰幀之間的重合部分甚至更多。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ed2000333ba548e6e34></p><p>上文已經提到，除了直接增加各層的記憶模塊的階數之外，增加模型的深度也能間接增加預測當前幀的輸出時模型可以利用的上下文的長度，上圖給出了一個例子。</p><h1>實驗</h1><p>在實驗階段，我們使用的是一個由男性朗讀的中文小說數據集。我們把數據集劃分成兩部分，其中訓練集包括38600句朗讀（大約為83小時），驗證集包括1400句朗讀（大約為3小時）。所有的語音數據採樣率都為16k赫茲，每幀幀長為25毫秒，幀移為5毫秒。我們使用WORLD聲音合成器逐幀提取聲學參數，包括60維梅爾倒譜系數，3維基頻的對數，11維BAP特徵以及1維清濁音標記。我們使用上述四組特徵作為神經網絡訓練的四個目標，進行多目標訓練。前端模塊提取出的語言學特徵，共計754維，作為神經網絡訓練的輸入。</p><p>我們對比的基線系統是基於一個強大的BLSTM模型，該模型由底層的1個全連接層和上層的3個BLSTM層組成，其中全連接層包含2048個單元，BLSTM層包含2048個記憶單元。該模型通過沿時間反向傳播算法（BPTT）訓練，而我們的DFSMN模型通過標準的反向傳播算法（BP）訓練。包括基線系統在內，我們的模型均通過逐塊模型更新過濾算法（BMUF）在2塊GPU上訓練。我們使用多目標幀級別均方誤差（MSE）作為訓練目標。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ed30000e072c8706c56></p><p>所有的DFSMN模型均由底層的若干DFSMN層和上的2個全連接層組成，每個DFSMN層包含2048個結點和512個投影結點，而每個全連接層包含2048個結點。在上圖中，第三列表示該模型由幾層DFSMN層和幾層全連接層組成，第四列表示該模型DFSMN層的記憶模塊的階數和步長。由於這是FSMN這一類模型首次應用在語音合成任務中，因此我們的實驗從一個深度淺且階數小的模型，即模型A開始（注意只有模型A的步長為1，因為我們發現步長為2始終稍好於步長為1的相應模型）。從系統A到系統D，我們在固定DFSMN層數為3的同時逐漸增加階數。從系統D到系統F，我們在固定階數和步長為10,10,2,2的同時逐漸增加層數。從系統F到系統I，我們固定DFSMN層數為10並再次逐漸增加階數。在上述一系列實驗中，隨著DFSMN模型深度和階數的增加，客觀指標逐漸降低（越低越好），這一趨勢非常明顯，且系統H的客觀指標超過了BLSTM基線。</p><p><img alt="ICASSP Oral 論文：阿里提出低計算量語音合成系統，速度提升4倍" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6c3f000466932ac41f31></p><p>另一方面，我們也做了平均主觀得分（MOS）測試（越高越好），測試結果如上圖所示。主觀測試是通過付費眾包平臺，由40個母語為中文的測試人員完成的。在主觀測試中，每個系統生成了20句集外合成語音，每句合成語音由10個不同的測試人員獨立評價。在平均主觀得分的測試結果表明，從系統A到系統E，主觀聽感自然度逐漸提高，且系統E達到了與BLSTM基線系統一致的水平。但是，儘管後續系統客觀指標持續提高，主觀指標只是在系統E得分的上下波動，沒有進一步提高。</p><h1>結論</h1><p>根據上述主客觀測試，我們得到的結論是，歷史和未來信息各捕捉120幀（600毫秒）是語音合成聲學模型建模所需要的上下文長度的上限，更多的上下文信息對合成結果沒有直接幫助。與BLSTM基線系統相比，我們提出的DFSMN系統可以在獲得與基線系統一致的主觀聽感的同時，模型大小隻有基線系統的1/4，預測速度則是基線系統的4倍，這使得該系統非常適合於對內存佔用和計算效率要求很高的端上產品環境，例如在各類物聯網設備上部署。</p><p>原文鏈接：https://arxiv.org/abs/1802.09194</p><p><strong>【加入社群】</strong></p><p>新智元 AI 技術 + 產業社群招募中，歡迎對 AI 技術 + 產業落地感興趣的同學，加小助手微信號: aiera2015_1 入群；通過審核後我們將邀請進群，加入社群后務必修改群備註（姓名 - 公司 - 職位；專業群審核較嚴，敬請諒解）。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>合成系</a></li><li><a>ICASSP</a></li><li><a>Oral</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>