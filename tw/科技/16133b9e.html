<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深度語義模型以及在淘寶搜索中的應用 | 极客快訊</title><meta property="og:title" content="深度語義模型以及在淘寶搜索中的應用 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/48529b82dc7c4f048fc3e45d586717e6"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/16133b9e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/16133b9e.html><meta property="article:published_time" content="2020-11-14T21:08:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:19+08:00"><meta name=Keywords content><meta name=description content="深度語義模型以及在淘寶搜索中的應用"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/16133b9e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深度語義模型以及在淘寶搜索中的應用</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>傳統的搜索文本相關性模型，如BM25通常計算Query與Doc文本term匹配程度。由於Query與Doc之間的語義gap, 可能存在很多語義相關，但文本並不匹配的情況。為了解決語義匹配問題，出現很多LSA，LDA等語義模型。</p><p>原文：http://click.aliyun.com/m/41653/</p><p>傳統的搜索文本相關性模型，如BM25通常計算Query與Doc文本term匹配程度。由於Query與Doc之間的語義gap, 可能存在很多語義相關，但文本並不匹配的情況。為了解決語義匹配問題，出現很多LSA，LDA等語義模型。隨著深度學習在NLP的應用，在IR和QA(問答系統)中出現了很多深度模型將query和doc通過神經網絡embedding，映射到一個稠密空間的向量表示，然後再計算其是否相關，並取得很好的效果。本文調研了微軟，IBM Waston實驗室、Google等在這方面的一些工作，並介紹我們在淘寶搜索上做的些工作。</p><p>1.DSSM、CDSSM，LSTM-DSSM及相關係列工作</p><p>微軟的DSSM及相關係列模型是深度語義模型中比較有影響力的。集團內PS上有DSSM分佈式實現，而且也有多業務應用.</p><p>DSSM首先將query和doc表示成一個高維且稀疏的BOW向量，向量的維度即詞典的大小，每一維表示該term在query或doc中出現的頻次；如果向量每一位直接用單詞，會出現維度非常高，而且對一些未登錄詞無法處理。作者做了一個非常有用的trick word-hash: 將每個單詞表示成一個letter-tri-gram的序列， 例如：boy切分成#-b-o, b-o-y, o-y-#， 然後再表示成letter-tri-gram向量。把每個單詞向量累加起來即表示整段文本的向量。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/48529b82dc7c4f048fc3e45d586717e6><p class=pgc-img-caption></p></div><p>然後，通過幾層全連的網絡連接將這個高維稀疏向量壓縮成一個稠密低維向量，在這個向量空間內，通過計算query與doc向量的cosin相似度來衡量相關程度。訓練的目標是對同一query下取1個點擊doc作為正樣本， 隨機4個未點擊doc作為負樣本，讓正負樣本的區分儘可能大：</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6b0bab52126f45bf8ee4e3d416becc1c><p class=pgc-img-caption></p></div><p>由於DSSM對文本embedding時沒有考慮term的順序信息，又陸續提出了採用Convolution和LSTM對文本embedding，可以保留詞序信息。其中，Convolution是實現方式通過對query或doc用固定大小滑動窗口取片段，對每個片段內文本用word-hash+dnn壓縮， 然後取max-pooling表示整個query或doc向量。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/039ac83deec04868a1ae5a2c64e98a17><p class=pgc-img-caption></p></div><p>此外， 無論是Convolution還是LSTM對文本embedding, 都涉及到通過詞或局部片段的向量生成整個句子的向量，比較簡單粗暴的方法是直接取sum、avg或者max等。微軟的學者們進一步做了改進，提出利用Attention機制來學習各個詞組合成句子向量的權重。以LSTM-DSSM為例，LSTM在每個時間步(term)上輸出的隱向量h, 輸入給一個attention網絡s(h)s(h), 輸出權重後softmax歸一，然後對每個詞的隱向量加權平均生成句子向量。s(h)s(h)的參數和相關性目標一起來訓練。這種Attention機制也比較弱，因為不同的query對同一個doc的“關注”點可能是不一樣的, 這種方式只能對doc生成唯一的向量。</p><p>最近，微軟的學者們又提出了一個觀點：query與doc的相關程度是由query裡的term與doc文本精準的匹配，以及query語義與doc語義匹配程度共同決定。而且，term匹配與term在doc中的位置和緊密度有較大關係。因此，他們用一個local model來表達term匹配程度，distribute model表達語義匹配程度，把這兩個子模型放在同一個模型來訓練。distribute model類似與DSSM來學習語義匹配關係。Local model的輸入是一個nq∗ndnq∗nd的矩陣mm，nqnq是query中term個數，ndnd是doc中term個數，位置m(i,j)=0or1m(i,j)=0or1表示query裡的第i個詞是否與doc裡的第j個詞匹配，對這個輸入矩陣通過convolution抽取特徵並向量化。據其實驗結果，這種結合term匹配信息的模型效果要優於DSSM等語義模型。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/958853136e4c4dae8a000014a89f2d2c><p class=pgc-img-caption></p></div><p>2. Google相關工作</p><p>Google的學者在用convolution對文本向量化是相比CDSSM做了些改進。Convolution的方法參考了Nal Kalchbrenner等對文本用卷積來做分類的方法。</p><p>首先，對句子中的每個詞做embedding, 然後將詞的embedding concat起來組合成一個矩陣，有點類似圖像的表達。然後，在這個矩陣上通過不同feature map抽取特徵，然後pooling生成一個維度的向量來表達句子。 對Query和Doc的語義向量， 再通過一個bilinear的模型計算其語義相似度：sim(xq,xd)=xq∗M∗xdsim(xq,xd)=xq∗M∗xd。 最終，語義相似度與其它相關排序特徵，以及query和doc向量一起作為決定排序的因素，通過pointwise的DNN模型來訓練。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7eb1b43ad32943cc90eeb28b7202730b><p class=pgc-img-caption></p></div><p>3. IBM Waston實驗室相關工作</p><p>問答系統有很多種類型，其中給定一個Question和候選Answer，從候選Answer中挑選最合適的答案，這個過程與信息檢索中的相關性模型非常相似。Waston實驗室在InsuranceQA數據集實驗了上述類似的模型，並綜合CNN和LSTM的優勢，提出了幾種有意思的混合模型:</p><p>(1) Convolutional-pooling LSTM</p><p>用一個Bi-LSTM作為word embedding的方法，然後word embedding concat成矩陣表達句子，用卷積來抽取組合特徵作為question和anwser的向量表達，再計算cosin loss.</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e76ef6a76ea94af7bc677f4af985e77d><p class=pgc-img-caption></p></div><p>（2）Convolution-based LSTM</p><p>先對原始文本用卷積捕捉局部的N-gram信息， 然後在這個基礎上用Bi-LSTM來學習更大範圍的上下文依賴關係。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/61d197afb0b74a8099ded6726da67d43><p class=pgc-img-caption></p></div><p>(3) Attentive-LSTM</p><p>相比LSTM-DSSM, 在Attention機制上做了些改進，與NMT的Attention機制接近，即：通過Answer中的詞向量加權平均生成整個Answer的向量時，每個詞的權重是由Question向量和詞向量來決定的。Question的表達仍由其所有詞向量的avg或sum，max來表示。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/00bcee77514d474695008f863bb38dcb><p class=pgc-img-caption></p></div><p>4. 其它相關工作</p><p>上述工作主要集中在如何更好生成Query和Doc向量表達，如何設計兩個向量comparision function以計算相似度也有很多種方法。Shuohang Wang總結了6種方法：NN, NTN, EUCCOS, SUB, MULT ，SUBMULT+NN。分別對query和doc向量計算乘、減、歐式距離、cosin、bilinear、concat，以及這幾種計算的組合。</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/76415d6546c5431b976dc36062015d4d><p class=pgc-img-caption></p></div><p>另外在機器閱讀理解也有很多類似工作，本文就不展開描述了。下面介紹下我們的相關工作。</p><p>5. 我們的工作</p><p>我們對淘寶搜索做了大量的語義改寫後，matching不僅侷限於term的匹配了，下面分別從數據和模型介紹下我們的工作。</p><p>5.1 深度模型通常大量的訓練數據，而對商品搜索相關性這個問題，獲取大量高質量訓練數據並不容易。網頁搜索通常直接採用點擊數據作為是否相關的label，在商品搜索上不是很有效：用戶點擊行為與價格、圖片、個性化偏好等很多因素相關，僅依賴點擊數據對相關性樣本有太多噪聲； 而採用人工標註數據，準確率相對較高，但受時效性、成本等因素限制較大。最近學術界也逐漸意識到這個問題，提出BM25等無監督模型生成大量樣本。我們獲取訓練數據的方式有：</p><p>(1) 對行為數據採樣，並用一些類似圖像Data Augmentation的手段獲取大量(億級別)準確率相對較低的訓練數據，先用這些數據training一個較好的模型；這些方法包括：</p><p>a. query下取CTR正常的商品作為正樣本， CTR低於平均值較多的商品作為負樣本</p><p>b. query能召回的類目下隨機採樣商品作為負樣本</p><p>c. 對query中的term做一些變換，用變換後的query下點擊商品作為原始query的負樣本, 例如“紅色長袖連衣裙”變換成“藍色短袖連衣裙”， 而“藍色短袖連衣裙”下點擊商品可以作為“紅色長袖連衣裙”下的負樣本；</p><p>(2) 通過改寫模型來為相關性模型生成大量樣本，後續可以專門文章介紹這部分；</p><pre> (3) 採用數量相對少(100w)、準確率高的人工標註數據fine-tuning用上述兩種方法pre_training好的模型。</pre><p>5.2 模型設計主要考慮的幾個因素：</p><p>(1) 淘寶上Query和商品標題存在大量長尾詞，尤其大量數字和英文組合的貨號、型號、容量等，分詞無法窮盡。僅通過詞來對query和標題embedding會損失很多信息，需要考慮字符維度。</p><p>(2) 商品除了標題外了，還有圖片、類目、屬性等信息可以利用。</p><p>(3) 工程實現線上計算要輕量，兩個向量的compare function要控制計算複雜度。</p><p>我們現在採用的模型如下：</p><div class=pgc-img><img alt=深度語義模型以及在淘寶搜索中的應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d3d0f32ee4804f2f8b29b427fa583766><p class=pgc-img-caption></p></div><p>(1) 對Query和標題向量我們採用DNN + Char-LSTM組合的方式：DNN能高效地學到TOP詞的embedding, Char-LSTM能捕獲到較長尾的字符組合。引入Char-LSTM後模型比較難訓練，我們使用query和標題文本語料pretraining LSTM-AutoEncoder, 獲得比較好的初始參數；同時TOP詞的embedding採用word2vec初始化，模型能更快收斂。</p><p>(2) 在商品標題的embedding上增加了一個類目預測的輔助task, 使得不同類目的商品在向量空間內有更好的區分度，對模型效果和收斂速度都有比較好的提升。</p><p>(3) online ranking對latency要求比較高，除了工程優化外，模型上也有優化空間。在我們數據上實驗發現compare function中全連層的深度和寬度對模型影響比較大。全連層寬一些效果會比較好，但計算量增加會很大；借鑑ResNet全連層設置窄一些，並加深模型，可以保證效果同時較大減少計算量。</p><p>我們抽樣部分query抓取線上排序結果， 與該模型排序後TOP30人工評測GOOD比例提升1.31%。</p><p>5.3 後續計劃</p><p>商品除了標題和類目，圖片也是很重要的信息來源，後續加入圖片信息，同時也在嘗試用query和商品向量做召回，實現multi-modal檢索。</p><p>另外，Attention機制也是一個被證明重要的提升點。受限於線上ranking latency的要求，不可能對每個商品標題根據query來計算其"關注"的部分，但可以引入一些self-attention的方法來生成更好的標題向量。</p><p>參考文獻：</p><p>[1] Shen, Y., He, X., Gao, J., Deng, L., & Mesnil, G. (2014). A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval (pp. 101–110). Presented at the the 23rd ACM International Conference, New York, New York, USA: ACM Press. http://doi.org/10.1145/2661829.2661935</p><p>[2] Services, E. U. C. (2014). Learning Deep Structured Semantic Models for Web Search using Clickthrough Data, 1–8.</p><p>[3] Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval. (2016). Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval, 1–25.</p><p>[4] Zhai, S., Chang, K.-H., Zhang, R., & Zhang, Z. M. (2016). DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks</p><p>(pp. 1295–1304). Presented at the the 22nd ACM SIGKDD International Conference, New York, New York, USA: ACM Press. http://doi.org/10.1145/2939672.2939759</p><p>[5] Mitra, B., Diaz, F., & Craswell, N. (2016). Learning to Match Using Local and Distributed Representations of Text for Web Search, 1–9.</p><p>[6] Improved Representation Learning for Question Answer Matching. (2016). Improved Representation Learning for Question Answer Matching, 1–10.</p><p>[7] Feng, M., Xiang, B., Glass, M. R., Wang, L., & Zhou, B. (2015). APPLYING DEEP LEARNING TO ANSWER SELECTION: A STUDY AND AN OPEN TASK , 1–8.</p><p>[8] Severyn, A., & Moschitti, A. (2015). Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks (pp. 373–382). Presented at the the 38th International ACM SIGIR Conference, New York, New York, USA: ACM Press.</p><p>[9] Kalchbrenner, N., Grefenstette, E., & Blunsom, P. (2014). A Convolutional Neural Network for Modelling Sentences</p><p>[10] Wang, S., & Jiang, J. (2017). A COMPARE-AGGREGATE MODEL FOR MATCHING TEXT SEQUENCES, 1–11.</p><p>[11] Lin, Z., Feng, M., Santos, dos, C. N., Yu, M., Xiang, B., Zhou, B., & Bengio, Y. (2017). A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING, 1–15.</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>語義</a></li><li><a>應用</a></li><li><a>搜索</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/5e4be374.html alt=鈦及鈦合金鑄件的應用領域​ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/Rca7hqUCttQBq0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5e4be374.html title=鈦及鈦合金鑄件的應用領域​>鈦及鈦合金鑄件的應用領域​</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/958c038a.html alt=鑄造鋁合金應用現狀及未來前景分析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8dcaa42ff9a64e2cad814e4e025fc52c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/958c038a.html title=鑄造鋁合金應用現狀及未來前景分析>鑄造鋁合金應用現狀及未來前景分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8fcabd80.html alt=亞馬遜的Alexa的語義分析性能得到大幅度提高 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RPsVq1PFCI1UDR style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8fcabd80.html title=亞馬遜的Alexa的語義分析性能得到大幅度提高>亞馬遜的Alexa的語義分析性能得到大幅度提高</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f4c5c93c.html alt=谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/46ea0001172cab9535dc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f4c5c93c.html title=谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用>谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/657370c9.html alt=從起源講到應用，幾乎所有齒輪知識都在這裡了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/6a14e31844e14b5aace5360ee6f8601a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/657370c9.html title=從起源講到應用，幾乎所有齒輪知識都在這裡了>從起源講到應用，幾乎所有齒輪知識都在這裡了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fc32dcc9.html alt=牛常用飼料添加劑的種類與應用！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/57c1b1c2-20c8-4927-8161-242643381796 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fc32dcc9.html title=牛常用飼料添加劑的種類與應用！>牛常用飼料添加劑的種類與應用！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7fa2c409.html alt=精密三角高程在長距離一等跨河水準測量中的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/514529e0543f408583046cefc73fac13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7fa2c409.html title=精密三角高程在長距離一等跨河水準測量中的應用>精密三角高程在長距離一等跨河水準測量中的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a90a489a.html alt=JAVA中多態的概念和應用，通過案例分析成員變量、方法的訪問特點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15310942260931dda577a75 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a90a489a.html title=JAVA中多態的概念和應用，通過案例分析成員變量、方法的訪問特點>JAVA中多態的概念和應用，通過案例分析成員變量、方法的訪問特點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7f03f742.html alt=正切和差角變形式應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e1f38ef5d20445488e9e180576f12a61 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7f03f742.html title=正切和差角變形式應用>正切和差角變形式應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d1c7184b.html alt=高中數學：正、餘二倍角公式的變式及其應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/R6f5aXZEqbpi9N style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d1c7184b.html title=高中數學：正、餘二倍角公式的變式及其應用>高中數學：正、餘二倍角公式的變式及其應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3a04345b.html alt=《三極管應用分析精粹》已經交稿，從單管放大到模擬集成電路設計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3a04345b.html title=《三極管應用分析精粹》已經交稿，從單管放大到模擬集成電路設計>《三極管應用分析精粹》已經交稿，從單管放大到模擬集成電路設計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5928048c.html alt=大漆歷史文化，區域分佈，應用領域 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/768822cfc3c94c5bb8362d33fe2c6b03 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5928048c.html title=大漆歷史文化，區域分佈，應用領域>大漆歷史文化，區域分佈，應用領域</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49962cec.html alt=軸承計算器的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/152574329299180c83f9974 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49962cec.html title=軸承計算器的應用>軸承計算器的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e7e54b7c.html alt=由散列表到BitMap的概念與應用（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/0027acf8-8d1c-4dff-9c16-7c37b98e914a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e7e54b7c.html title=由散列表到BitMap的概念與應用（一）>由散列表到BitMap的概念與應用（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ffab2eea.html alt=水處理工程中的好氧生物處理的原理及應用——活性汙泥法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8b13f26a8f6e418296099383a9f76be9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ffab2eea.html title=水處理工程中的好氧生物處理的原理及應用——活性汙泥法>水處理工程中的好氧生物處理的原理及應用——活性汙泥法</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>