<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ICLR 2020會議的16篇最佳深度學習論文 | 极客快訊</title><meta property="og:title" content="ICLR 2020會議的16篇最佳深度學習論文 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/afa88e3a9b9a4c76904856ed340b09bd"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1c6b0390.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1c6b0390.html><meta property="article:published_time" content="2020-11-14T20:59:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:59:54+08:00"><meta name=Keywords content><meta name=description content="ICLR 2020會議的16篇最佳深度學習論文"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/1c6b0390.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ICLR 2020會議的16篇最佳深度學習論文</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>作者：Kamil Kaczmarek</p><p>編譯：ronghuaiyang</p></blockquote><h1 class=pgc-h-arrow-right>導讀</h1><blockquote><p>給大家介紹一下今年的ICLR上的最佳16篇深度學習論文。</p></blockquote><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/afa88e3a9b9a4c76904856ed340b09bd><p class=pgc-img-caption></p></div><p>上週，我很榮幸地參加了學習表現國際會議(<strong>ICLR</strong>)，這是一個致力於深度學習各方面研究的活動。最初，會議本應在埃塞俄比亞首Addis Ababa召開，但由於新型冠狀病毒大流行，會議變成了虛擬會議。把活動搬到網上對組織者來說是一個挑戰，但是我認為效果非常令人滿意！</p><p>1300多名演講者和5600名與會者證明，虛擬形式更容易為公眾所接受，但與此同時，會議保持了互動和參與。從許多有趣的演講中，我決定選擇16個，這些演講既有影響力又發人深省。以下是來自ICLR的最佳深度學習論文。</p><p>1. On Robustness of Neural Ordinary Differential Equations</p><p>2. Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</p><p>3. Target-Embedding Autoencoders for Supervised Representation Learning</p><p>4. Understanding and Robustifying Differentiable Architecture Search</p><p>5. Comparing Rewinding and Fine-tuning in Neural Network Pruning</p><p>6. Neural Arithmetic Units</p><p>7.The Break-Even Point on Optimization Trajectories of Deep Neural Networks</p><p>8. Hoppity: Learning Graph Transformations To Detect And Fix Bugs In Programs</p><p>9. Selection via Proxy: Efficient Data Selection for Deep Learning</p><p>10. And the Bit Goes Down: Revisiting the Quantization of Neural Networks</p><p>11. A Signal Propagation Perspective for Pruning Neural Networks at Initialization</p><p>12. Deep Semi-Supervised Anomaly Detection</p><p>13. Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells</p><p>14. Federated Learning with Matched Averaging</p><p>15. Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation</p><p>16. Network Deconvolution</p><h1 class=pgc-h-arrow-right>最佳深度學習論文</h1><h1 class=pgc-h-arrow-right>1. On Robustness of Neural Ordinary Differential Equations</h1><p>深入研究了神經常微分方程或神經網絡的魯棒性。使用它作為構建更健壯的網絡的基礎。</p><p>論文：https://openreview.net/forum?id=B1e9Y2NYvS</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/718626394c604c3c81d0e23fef0e7467><p class=pgc-img-caption></p></div><p>ODENet的結構，神經ODE塊作為一個保維非線性映射。</p><p><br></p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89422efceb9b4d4a87b60855957db0ea><p class=pgc-img-caption>第一作者：Hanshu YAN</p></div><h1 class=pgc-h-arrow-right>2. Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</h1><p>證明梯度裁剪可加速非光滑非凸函數的梯度下降。</p><p>論文：https://openreview.net/forum?id=BJgnXpVYwS</p><p>代碼：https://github.com/JingzhaoZhang/why-clipping-accelerates</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/47f43a659a0f478c97516100c0e294f3><p class=pgc-img-caption></p></div><p>PTB數據集上AWD-LSTM (Merity et al.， 2018)訓練軌跡上的對數尺度上的梯度範數vs局部梯度Lipschitz常數。顏色條表示在訓練過程中迭代的次數。</p><p>第一作者：Jingzhao Zhang</p><h1 class=pgc-h-arrow-right>3. Target-Embedding Autoencoders for Supervised Representation Learning</h1><p>新的，通用目標嵌入自動編碼器或者說TEA監督預測框架。作者給出了理論和經驗的考慮。</p><p>論文：https://openreview.net/forum?id=BygXFkSYDH</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fe98360282c941bd9a21892a122c8969><p class=pgc-img-caption></p></div><p>(a)特徵嵌入和(b)目標嵌入自動編碼器。實線對應於(主要)預測任務，虛線為(輔助)重建任務。兩者都涉及到共享組件。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f35e87e4d85e495f8b88a9de2c13104d><p class=pgc-img-caption>第一作者：Daniel Jarrett</p></div><hr><h1 class=pgc-h-arrow-right>4. Understanding and Robustifying Differentiable Architecture Search</h1><p>通過分析驗證損失的海塞矩陣的特徵值，研究了DARTS（可微結構搜索）的失效模式，並在此基礎上提出了相應的對策。</p><p>論文：https://openreview.net/forum?id=H1gDNyrKDS</p><p>代碼：https://github.com/automl/RobustDARTS</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2039a9b892a34d098340ec96cc6c5889><p class=pgc-img-caption></p></div><p>在Space1到Space4上，DARTS發現的差的網格標準。對於所有的空間，DARTS選擇的大多是無參數的操作(跳過連接)，甚至是有害的噪聲操作。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2109be19c24b4553831dd05614d8a763><p class=pgc-img-caption>第一作者: Arber Zela</p></div><h1 class=pgc-h-arrow-right>5. Comparing Rewinding and Fine-tuning in Neural Network Pruning</h1><p>在修剪神經網絡時，不需要在修剪後進行微調，而是將權值或學習率策略倒回到它們在訓練時的值，然後再從那裡進行再訓練，以達到更高的準確性。</p><p>論文：https://openreview.net/forum?id=S1gSj0NKvB</p><p>代碼：https://github.com/lottery-ticket/rewinding-iclr20-public</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9f6bb35df3be440ca14ac95aff170fef><p class=pgc-img-caption></p></div><p>通過一次修剪獲得再訓練時間的最佳可達到的精度。</p><p>![Alex Renda](The Best Deep Learning Papers from the ICLR 2020 Conference.assets/5-Alex-Renda.jpg)</p><p>第一作者：Alex Renda</p><h1 class=pgc-h-arrow-right>6. Neural Arithmetic Units</h1><p>神經網絡雖然能夠逼近複雜的函數，但在精確的算術運算方面卻很差。這項任務對深度學習研究者來說是一個長期的挑戰。在這裡，我們介紹了新的神經加法單元(NAU)和神經乘法單元(NMU)，它們能夠執行精確的加法/減法(NAU)和向量子集乘法(MNU)。</p><p>論文：https://openreview.net/forum?id=H1gNOeHKPS</p><p>代碼：https://github.com/AndreasMadsen/stable-nalu</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0e52d8202e0748a79595cb753bd87eb2><p class=pgc-img-caption></p></div><p>NMU的可視化，其中權值(Wi,j)控制門控的值1(identity)或xi，然後顯式地乘上每個中間結果以形成zj。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5cc6fe467484430c8b22826c7d17dffb><p class=pgc-img-caption>第一作者：Andreas Madsen</p></div><h1 class=pgc-h-arrow-right>7. The Break-Even Point on Optimization Trajectories of Deep Neural Networks</h1><p>在深度神經網絡訓練的早期階段，存在一個決定整個優化軌跡性質的“均衡點”。</p><p>論文：https://openreview.net/forum?id=r1g87C4KwB</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c301763e03164206808e1aea78cb9347><p class=pgc-img-caption></p></div><p>早期訓練軌跡的可視化，CIFAR-10(之前訓練精度達到65%)的一個簡單的CNN模型優化使用SGD學習率η= 0.01(紅色)和η= 0.001(藍色)。訓練軌跡上的每個模型(顯示為一個點)通過使用UMAP將其測試預測嵌入到一個二維空間中來表示。背景顏色表示梯度K (λ1K, 左)的協方差歸一化頻譜和訓練精度(右)。對於小的η，達到我們所說的收支平衡點後，對於同樣的訓練精度(右)，軌跡是引向一個地區，這個區域具有更大λ1K(左)的特點。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9327c69274844fcda51560cad9b12b36><p class=pgc-img-caption>第一作者：Stanisław Jastrzębski</p></div><h1 class=pgc-h-arrow-right>8. Hoppity: Learning Graph Transformations To Detect And Fix Bugs In Programs</h1><p>一種基於學習的方法，用於檢測和修復Javascript中的bug。</p><p>論文：https://openreview.net/forum?id=SJeqs6EFvB</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4459c89a76e14d81b459f4edc99a02a0><p class=pgc-img-caption></p></div><p>演示現有方法的侷限性的示例程序包括基於規則的靜態分析器和基於神經的錯誤預測器。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/da61e13ee3504e23a50bb65e209f78e1><p class=pgc-img-caption>第一作者：Elizabeth Dinella</p></div><h1 class=pgc-h-arrow-right>9. Selection via Proxy: Efficient Data Selection for Deep Learning</h1><p>通過使用一個更小的代理模型來執行數據選擇，我們可以顯著提高深度學習中數據選擇的計算效率。</p><p>論文：https://openreview.net/forum?id=HJg2b0VYDr</p><p>代碼：https://github.com/stanford-futuredata/selection-via-proxy</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ef50a3353baa48f0ab3fcfaa7c3db31d><p class=pgc-img-caption></p></div><p>SVP應用於主動學習(左)和核心集選擇(右)。在主動學習中，我們遵循了相同的迭代過程，即訓練和選擇標記為傳統方法的點，但是用計算成本更低的代理模型代替了目標模型。對於核心集的選擇，我們學習了使用代理模型對數據進行特徵表示，並使用它選擇點來訓練更大、更精確的模型。在這兩種情況下，我們發現代理和目標模型具有較高的rank-order相關性，導致相似的選擇和下游結果。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f5c162dafe7b439f917b3f57f4aae2a4><p class=pgc-img-caption>第一作者：Cody Coleman</p></div><h1 class=pgc-h-arrow-right>10. And the Bit Goes Down: Revisiting the Quantization of Neural Networks</h1><p>採用結構化量化技術對卷積神經網絡進行壓縮，實現更好的域內重構。</p><p>論文：https://openreview.net/forum?id=rJehVyrKwH</p><p>代碼：https://drive.google.com/file/d/12QK7onizf2ArpEBK706ly8bNfiM9cPzp/view?usp=sharing</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f61e01cbff104a5f95ec6467e0840c16><p class=pgc-img-caption></p></div><p>圖解我們的方法。我們近似一個二元分類器ϕ，通過量化權重把圖像標記為狗或貓。標準方法：使用標準目標函數來量化 ϕstandard，(1)提升分類器ϕ，試圖在整個輸入空間上近似ϕ，因此對於域內的輸入可能表現很差。我們的方法：用我們的目標函數量化ϕ(2)提升分類器ϕbactivations，使之對於域內輸入表現良好。在輸入空間的圖像由ϕactivations正確分類，但ϕstandard不正確。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/212f0b06c22d45c4a2eb541b8684a2b3><p class=pgc-img-caption>第一作者：Pierre Stock</p></div><h1 class=pgc-h-arrow-right>11. A Signal Propagation Perspective for Pruning Neural Networks at Initialization</h1><p>我們正式描述了初始化時有效剪枝的初始化條件，並分析了得到的剪枝網絡的信號傳播特性，提出了一種增強剪枝網絡可訓練性和剪枝效果的方法。</p><p>論文：https://openreview.net/forum?id=HJeTo2VFwH</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/697650339b1d4c34868606e33a8f1ba8><p class=pgc-img-caption></p></div><p>(左)layerwise稀疏模式c∈{0,1} 100×100獲得剪枝水平為κ¯= {10 . .90}%的效果。這裡，黑色(0)/白色(1)像素為修剪/保留參數，(右)各層參數的連接靈敏度(CS)所有網絡初始化γ=1.0。與線性情況不同，tanh網絡的稀疏模式在不同層上是不均勻的。當進行高等級剪枝的時候(例如，κ¯= 90%)，這成為關鍵，導致學習能力差，只有幾個參數留在後面的層。這是由連接靈敏度圖所解釋的，圖中顯示，對於非線性網絡參數，後一層的連接靈敏度低於前一層。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8c8f688ad5854592990b8d238c15677c><p class=pgc-img-caption>第一作者：Namhoon Lee</p></div><h1 class=pgc-h-arrow-right>12. Deep Semi-Supervised Anomaly Detection</h1><p>我們介紹了Deep SAD，一種用於一般性的半監督異常檢測的深度方法，特別利用了異常的標記。</p><p>論文：https://openreview.net/forum?id=HkgH0TEYwH</p><p>代碼：https://github.com/lukasruff/Deep-SAD-PyTorch</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/77ac66f84a874001a548b79a3270395d><p class=pgc-img-caption></p></div><p>半監督異常檢測的需要：訓練數據(如(a)所示)由(大部分正常)未標記數據(灰色)和少數標記正常樣本(藍色)和標註的異常樣本(橙色)組成。圖(b) - (f)顯示了測試時各種學習模式的決策邊界，以及出現的新異常(每個圖的左下角)。我們的半監督AD方法利用了所有的訓練數據：未標記的樣本，標記的正常樣本，以及標記的異常樣本。這在單類別學習和分類之間取得了平衡。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4560aa38f37649a2939d76078c55a4bc><p class=pgc-img-caption>第一作者：Lukas Ruffs</p></div><h1 class=pgc-h-arrow-right>13. Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells</h1><p>我們提出了一個名為Space2vec的表示學習模型來編碼位置的絕對位置和空間關係。</p><p>論文：https://openreview.net/forum?id=rJljdh4KDH</p><p>代碼：https://github.com/gengchenmai/space2vec</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/21ce777c666840e39dbf53dcc552393c><p class=pgc-img-caption></p></div><p>具有非常不同特徵的聯合建模分佈的挑戰。(a)(b)拉斯維加斯的POI位置(紅點)以及Space2Vec預測了女裝(使用聚類分佈)和教育(使用均勻分佈)的條件似然。(b)中的黑色區域表明市中心區域的其他類型的POIs比教育多。(c)相對於wrap， Space2Vec具有最大和最小改進的POI類型的Ripley的K曲線(Mac Aodha et al.， 2019)。每條曲線表示以某一類型的點為中心的某一半徑內某一類型點的點的個數(d)用POI密度重新規格化的Ripley’s K曲線，並以對數刻度表示。為了高效地實現多尺度表示，Space2Vec將64個尺度(波長從50米到40k米不等)的網格單元編碼作為深度模型的第一層，並以無監督的方式與POI數據進行訓練。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c05f4dcda8ec474db91184af921cb4ec><p class=pgc-img-caption>第一作者：Gengchen Mai</p></div><hr><h1 class=pgc-h-arrow-right>14. Federated Learning with Matched Averaging</h1><p>使用分層匹配來實現聯邦學習的高效交流。</p><p>論文：https://openreview.net/forum?id=BkluqlSFDS</p><p>代碼：https://github.com/IBM/FedMA</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2963131d54644d17b9954c259f63b021><p class=pgc-img-caption></p></div><p>在MNIST上進行有限次數的LeNet聯邦學習方法的比較，在CIFAR-10數據集上訓練VGG-9，LSTM在莎士比亞數據集上訓練:(a)同構數據(b)異構數據</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a0c99d611b77474f98f68414f5e5b448><p class=pgc-img-caption>第一作者：Hongyi Wang</p></div><h1 class=pgc-h-arrow-right>15. Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation</h1><p>深度神經網絡優化編譯的增強學習和自適應採樣。</p><p>論文：https://openreview.net/forum?id=rygG4AVFvH</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/789c8dd2270542fcb33f128909cc0e01><p class=pgc-img-caption>我們的模型編譯工作流的概要，突出顯示的是這項工作的範圍。</p></div><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0eff0a416beb46cfa98e8ec55cf588ab><p class=pgc-img-caption>第一作者：Byung Hoon Ahn</p></div><h1 class=pgc-h-arrow-right>16. Network Deconvolution</h1><p>為了更好地訓練卷積網絡，我們提出了一種類似於動物視覺系統的網絡反捲積方法。</p><p>論文：https://openreview.net/forum?id=rkeu30EtvS</p><p>代碼：https://github.com/yechengxi/deconvolution</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/99ae6dd72fbd45bfae87065cc4a2931b><p class=pgc-img-caption></p></div><p>使用相關濾波器(例如高斯核)對這個真實世界的圖像進行卷積，將相關性添加到生成的圖像中，這使得目標識別更加困難。去除這種模糊的過程稱為反捲積。但是，如果我們看到的真實世界的圖像本身是某種未知的相關濾波器的結果，這使得識別更加困難呢？我們提出的網絡反捲積操作可以去除底層圖像特徵之間的關聯，使得神經網絡能夠更好地執行。</p><div class=pgc-img><img alt="ICLR 2020會議的16篇最佳深度學習論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fe4aabcd69274f12bf2a8747e9a6754f><p class=pgc-img-caption>第一作者：Chengxi Ye</p></div><h1 class=pgc-h-arrow-right>總結</h1><p>ICLR的深度和廣度相當鼓舞人心。在這裡，我只介紹了“深度學習”主題的冰山一角。然而，這一分析表明，有一些是很受歡迎的領域，特別是：</p><ol start=1><li>深度學習(本文涵蓋)</li><li>強化學習</li><li>生成模型</li><li>自然語言處理/理解</li></ol><p>為了更全面地概述ICLR的頂級論文，我們正在撰寫一系列文章，每一篇都集中在上面提到的一個主題上。</p><p>英文原文：https://neptune.ai/blog/iclr-2020-deep-learning</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ICLR</a></li><li><a>2020</a></li><li><a>會議</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/3c250658.html alt="必讀 | ICLR 2020大會最佳深度學習論文" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/23b6cc0be3e34a158e87dda097dbff16 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3c250658.html title="必讀 | ICLR 2020大會最佳深度學習論文">必讀 | ICLR 2020大會最佳深度學習論文</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/4c1f6538.html alt=易成新能公司召開2020年工作會議暨2020年安全工作會議 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/4c1f6538.html title=易成新能公司召開2020年工作會議暨2020年安全工作會議>易成新能公司召開2020年工作會議暨2020年安全工作會議</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/897d7f44.html alt=2020年全市政府信息工作會議召開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/897d7f44.html title=2020年全市政府信息工作會議召開>2020年全市政府信息工作會議召開</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/eef3bf6.html alt=奧普特利集團2020年第三季度工作會議圓滿召開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/5222c89fb9aa4fd1928163c40cba85b3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/eef3bf6.html title=奧普特利集團2020年第三季度工作會議圓滿召開>奧普特利集團2020年第三季度工作會議圓滿召開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html alt="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9d1db0f2d2884c99b22fed2f8726ff26 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html title="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈">2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html alt=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6090cec007b4477094c4dee77aa55cab style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html title=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》>2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html alt=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/147a09b4453942c4b8f8f277957352b2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html title=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係>2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html alt=2020最新網頁設計，入門到精通教程+網頁素材，小白速領 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b1791402c6954e31bde2d2e6686776ce style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html title=2020最新網頁設計，入門到精通教程+網頁素材，小白速領>2020最新網頁設計，入門到精通教程+網頁素材，小白速領</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html alt=2020年二級建築答案（部分僅供參考） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html title=2020年二級建築答案（部分僅供參考）>2020年二級建築答案（部分僅供參考）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html alt="2020 一起感受前沿科學的魅力" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RoKukVcIMipJlM style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html title="2020 一起感受前沿科學的魅力">2020 一起感受前沿科學的魅力</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html alt=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3e29dad6969c439eb635b60d7b56ece8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html title=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念>2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html alt="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4d506eba5ab436ea0c06314cea9156a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html title="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實">一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html alt=2020年一級建造師每日一練習題及答案解析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html title=2020年一級建造師每日一練習題及答案解析>2020年一級建造師每日一練習題及答案解析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html alt=2020焊工（中級）考試題及焊工（中級）複審模擬考試 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1e535667de7d4f2bb53fcc15449cf2cd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html title=2020焊工（中級）考試題及焊工（中級）複審模擬考試>2020焊工（中級）考試題及焊工（中級）複審模擬考試</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html alt=2020年建築焊工(建築特殊工種)證模擬考試題庫 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/da22da92ae304596ad940f56f54806eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html title=2020年建築焊工(建築特殊工種)證模擬考試題庫>2020年建築焊工(建築特殊工種)證模擬考試題庫</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>