<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 | 极客快訊</title><meta property="og:title" content="機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/2422efca60844260be30c96b636f86dc"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f15630.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f15630.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f15630.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="機器學習基礎——帶你實戰樸素貝葉斯模型文本分類"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/1f15630.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習基礎——帶你實戰樸素貝葉斯模型文本分類</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>上一篇文章當中我們介紹了<strong>樸素貝葉斯模型的基本原理</strong>。</p><p><br></p><p>樸素貝葉斯的核心本質是假設樣本當中的變量服從某個分佈，從而利用條件概率計算出樣本屬於某個類別的概率。一般來說一個樣本往往會含有許多特徵，這些特徵之間很有可能是有相關性的。為了簡化模型，樸素貝葉斯模型假設<strong>這些變量是獨立的</strong>。這樣我們就可以很簡單地計算出樣本的概率。</p><p><br></p><p>想要回顧其中細節的同學，可以點擊鏈接回到之前的文章：<a class=pgc-link data-content=mp href="https://www.toutiao.com/i6781949890726461965/?group_id=6781949890726461965" target=_blank>機器學習基礎——一篇文章讓你學會樸素貝葉斯模型</a></p><p><br></p><p>在我們學習算法的過程中，如果只看模型的原理以及理論，總有一些紙上得來終覺淺的感覺。很多時候，道理說的頭頭是道，可是真正要上手的時候還是會一臉懵逼。或者是勉強能夠搞一搞，但是過程當中總會遇到這樣或者那樣各種意想不到的問題。一方面是我們動手實踐的不夠， 另一方面也是理解不夠深入。</p><p><br></p><p>今天這篇文章我們實際動手實現模型，並且<strong>在真實的數據集當中運行</strong>，再看看我們模型的運行效果。</p><p><br></p><h3 class=pgc-h-arrow-right><strong>樸素貝葉斯與文本分類</strong></h3><p><br></p><p>一般來說，我們認為<strong>狹義的事件</strong>的結果應該是有限的，也就是說事件的結果應該是一個離散值而不是連續值。所以早期的貝葉斯模型，在引入高斯混合模型的思想之前，針對的也是離散值的樣本（存疑，筆者推測）。所以我們先拋開連續特徵的場景，先來看看在離散樣本當中，樸素貝葉斯模型有哪些實際應用。</p><p><br></p><p>在機器學習廣泛的應用場景當中，有一個非常經典的應用場景，它的樣本一定是離散的，它就是<strong>自然語言處理</strong>（Nutural Language Processing）。在語言當中，無論是什麼語言，無論是一個語句或是一段文本，它的最小單位要麼是一個單詞，要麼是一個字。這些單元都是離散的，所以天生和樸素貝葉斯模型非常契合。</p><p><br></p><p>我們這次做的模型針對的場景是垃圾郵件的識別，這應該是我們生活當中經常接觸到的功能。現在的郵箱基本上都有識別垃圾郵件的功能，如果發現是垃圾郵件，往往會直接屏蔽，不會展示給用戶。早期的垃圾郵件和垃圾短信識別的功能都是通過樸素貝葉斯實現的。</p><p><br></p><p>在這個實驗當中，我們用的是<strong>UCI的數據集</strong>。UCI大學的機器學習數據集非常出名，許多教材和課本上都使用了他們的數據集來作為例子。我們可以直接通過網頁下載他們的數據，UCI的數據集裡的數據都是免費的。</p><p><br></p><blockquote class=js_blockquote_wrap><p>https://archive.ics.uci.edu/ml/datasets/sms+spam+collection</p></blockquote><p><br></p><p>下載完成之後，我們先挑選其中幾條來看看：</p><p><br></p><blockquote class=js_blockquote_wrap><p>ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</p><p>ham Ok lar... Joking wif u oni...spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's</p><p>ham U dun say so early hor... U c already then say...</p></blockquote><p><br></p><p>這份數據是以txt文件類型保存，每行文本的第一個單詞表示文本的類別，其中ham表示正常，spam表示是垃圾郵件。</p><p><br></p><p>我們首先讀取文件，將文件當中的內容先讀取到list當中，方便我們後續的處理。</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2422efca60844260be30c96b636f86dc><p class=pgc-img-caption></p></div><p><br></p><p>我們查看一下前三條數據：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/713a4e6cc38d4855aa9e5efc48faf8d6><p class=pgc-img-caption></p></div><p><br></p><p>可以發現類別和正文之間通過\t (tab)分開了，我們可以直接通過python的split方法將類別和正文分開。其中類別也就是我們想要模型學習的結果，在有監督學習當中稱為label。文本部分也就是模型做出預測的依據，稱為<strong>特徵</strong>。在文本分類場景當中，特徵就是<strong>文本信息</strong>。</p><p><br></p><p>我們將label和文本分開：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/86ab5e1ab9f94f43b4fa8135b88fc3ad><p class=pgc-img-caption></p></div><p><br></p><h3 class=pgc-h-arrow-right><strong>過濾標點符號</strong></h3><p><br></p><p>將文本和label分開之後，我們就需要對文本進行處理了。在進行處理之前，我們先隨便拿一條數據來查看一下，這裡我們選擇了第一條：</p><p><br></p><blockquote class=js_blockquote_wrap><p>'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n'</p></blockquote><p><br></p><p>這是一條非常典型的未處理之前的文本，當中不僅大小寫字母混用，並且還有一些特殊符號。所以文本處理的第一步就是把所有字母全部小寫，以及去除標點符號。</p><p><br></p><p>說起來比較複雜，但只要使用正則表達式，我們可以很方便地實現：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c6acb48fa4c2437eab1064cc45b1bf14><p class=pgc-img-caption></p></div><p><br></p><p>最後得到的結果如下：</p><p><br></p><blockquote class=js_blockquote_wrap><p>go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat</p></blockquote><p><br></p><p>這裡正則表達式非常簡單，就是隻保留英文字母和數字以及空格，其餘所有的內容全部過濾。我們在傳入的時候做了大小寫轉換，會把所有的大寫字母轉成小寫。到這裡為止，所有的特殊字符就都處理掉了，接下來就可以進行<strong>分詞</strong>了。</p><p><br></p><p>英文的分詞很簡單，我們直接根據空格split即可。如果是中文分詞，可以使用一些第三方庫完成，之前的文章裡介紹過，這裡就不贅述了。</p><p><br></p><h3 class=pgc-h-arrow-right><strong>安裝nltk</strong></h3><p><br></p><p>在接下來的文本處理當中，我們需要用到一個叫做nltk的自然語言處理的工具庫。當中集成了很多非常好用的NLP工具，和之前的工具庫一樣，我們可以直接使用pip進行安裝：</p><p><br></p><pre><code>pip3 install nltk</code></pre><p><br></p><p>這裡強烈建議使用Python3，因為Python2已經不再維護了。這步結束之後，只是裝好了nltk庫，nltk當中還有很多其他的資源文件需要我們下載。我們可以直接通過python進行下載：</p><p><br></p><pre><code>import nltknltk.download()</code></pre><p><br></p><p>調用這個代碼之後會彈出一個下載窗口：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/77da739a94d545c4b9725fca7094ec44><p class=pgc-img-caption></p></div><p><br></p><p>我們全選然後點擊下載即可，不過這個數據源在國外，在國內直接下載可能會很慢。除了科學上網之外，另一種方法是可以直接在github裡下載對應的資源數據：https://github.com/nltk/nltk_data</p><p><br></p><p>需要注意的是，必須要把數據放在指定的位置，具體的安裝位置可以調用一下download方法之後查看紅框中的路徑。或者也可以使用清華大學的鏡像源，使用命令：</p><p><br></p><pre><code>pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple/nltk</code></pre><p><br></p><p>下載好了之後，我們在Python當中執行：</p><p><br></p><pre><code>fron nltk.book import *</code></pre><p><br></p><p>如果出現以下結果，就說明已經安裝完畢：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d8a440532b5e4dc4b02528d4ae54497f><p class=pgc-img-caption></p></div><h3 class=pgc-h-arrow-right><br></h3><h3 class=pgc-h-arrow-right><strong>去除停用詞</strong></h3><p><br></p><p>裝好了nltk之後，我們要做的第一個預處理是去除停用詞。</p><p><br></p><p>停用詞英文是stop words，指的是文本當中對語義無關緊要的詞彙。包含了常見的虛詞、助詞、介詞等等。這些詞語大部分只是修飾作用，對文本的語義內容起不到決定作用。因此在NLP領域當中，可以將其過濾，從而減少計算量提升模型精度。</p><p><br></p><p>Nltk當中為常見的主流語言提供了停用詞表（不包括中文），我們傳入指定的語言，將會返回一個停用詞的list。我們在分詞之後根據停用詞表進行過濾即可。</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/4d43bdd73535474a821a7c5459a43cd7><p class=pgc-img-caption></p></div><p><br></p><p>我們可以打印出所有英文的停用詞看一下，大部分都是一些虛詞和助詞，可能出現在所有語境當中，對我們對文本進行分類幾乎沒有幫助。</p><p><br></p><h3 class=pgc-h-arrow-right><strong>詞性歸一化</strong></h3><p><br></p><p>眾所周知，英文當中的單詞有很多形態。比如名詞有單複數形式，有些特殊的名詞複數形式還很不一樣。動詞有過去、現在以及未來三種時態，再加上完成時和第三人稱一般時等，又有很多變化。</p><p><br></p><p>舉例來說，do這個動詞在文本當中會衍生出許多小詞來。比如does, did, done, doing等，這些單詞雖然各不相同，但是表示的意思完全一樣。因此，在做英文NLP模型的時候，需要將這些時態的單詞都還原成最基本的時態，這被稱為是詞性歸一化。</p><p><br></p><p>原本這是一項非常複雜的工作，但我們有了nltk之後，這個工作變得簡單了很多。要做單詞歸一化，我們需要用到nltk當中的兩個工具。</p><p><br></p><p>第一個方法叫做pos_tag， 它接收一個單詞的list作為入參。返回也是一個tuple的list，每個tuple當中包含兩個值，一個是單詞本身，第二個參數就是我們想要的詞性。</p><p><br></p><p>舉個例子：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5137fd02a8744bb4be3254dd4fd98e59><p class=pgc-img-caption></p></div><p><br></p><p>我們傳入只有一個單詞apple的list，在返回的結果當中除了apple之外，還多了一個NN，它表示apple是一個名詞nouns。</p><p><br></p><p>關於返回的詞性解釋，感興趣的可以自行查看官方文檔的說明。</p><p><br></p><p>我們這裡並不需要區分那麼細，只需要區分最常用的動詞、名詞、形容詞、副詞就基本上夠了。</p><p><br></p><p>我們可以直接根據返回結果的首字母做個簡單的映射：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/02d299425136444783af4010e19bc7c0><p class=pgc-img-caption></p></div><p><br></p><p>通過pos_tag方法我們很容易就可以拿到單詞的詞性，但是這還不夠，我們還需要將它還原成最基礎的形態。這個時候需要用到另一個工具：WordNetLemmatizer</p><p><br></p><p>它的用途是根據單詞以及單詞的詞性返回單詞最一般的形態，也就是歸一化的操作。</p><p><br></p><p>舉個例子：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/db82d235c56e4bb090726e73b17d3435><p class=pgc-img-caption></p></div><p><br></p><p>我們傳入了box的複數形式：boxes，以及box對應的名詞，它返回的結果正是我們想要的box。</p><p><br></p><p>我們結合剛剛實現的查詢單詞詞性的方法，就可以完成單詞的歸一化了。</p><p><br></p><p>到這裡為止，關於文本的初始化就算是差不多結束了。除了剛剛提到的內容之外，nltk還包含許多其他非常方便好用的工具庫。由於篇幅的限制，我們不能一一窮盡，感興趣的讀者可以自行鑽研，相信一定會很有收穫。</p><p><br></p><p>下面，我們把剛才介紹的幾種文本預處理的方法一起用上，對所有的短信進行預處理：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/23281c2c5bfe42b88914faa5013190a2><p class=pgc-img-caption></p></div><p><br></p><p>通過nltk的工具庫，我們只需要幾行代碼，就可以完成文本的分詞、停用詞的過濾以及詞性的歸一化等工作。</p><p><br></p><p>接下來，我們就可以進行樸素貝葉斯的模型的訓練與預測了。</p><p><br></p><p>首先，我們需要求出背景概率。所謂的背景概率，也就是指在不考慮任何特徵的情況下，這份樣本中信息當中天然的垃圾短信的概率。</p><p><br></p><p>這個其實很簡單，我們只需要分別其實正常的郵件與垃圾郵件的數量然後分別除以總數即可：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9e10f21570f7465aa7b5870661e64b7d><p class=pgc-img-caption></p></div><p><br></p><p>我們run一下測試一下結果：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/301efeeef193440bab25e3ebfab58770><p class=pgc-img-caption></p></div><p><br></p><p>可以看到垃圾短信的概率只佔13%，大部分短信都是正常的。這也符合我們的生活經驗，畢竟垃圾短信是少數。</p><p><br></p><p>接下來我們需要求出每個單詞屬於各個類別的概率，也就是要求一個單詞的概率表。這段代碼稍微複雜一些，但是也不麻煩：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8ddcda687f4d4ff4914a2ff99040e456><p class=pgc-img-caption></p></div><p><br></p><p>同樣，我們運行一下測試一下結果：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e0479aaf64094209a918deeb79c3f344><p class=pgc-img-caption></p></div><p><br></p><p>這些都有了之後，就是預測的重頭戲了。這裡有一點需要注意，根據我們上文當中的公式，我們在預測文本的概率的時候，會用到多個概率的連乘。由於浮點數有精度限制，所以我們不能直接計算乘積，而是要將它轉化成對數，這樣我們就可以通過加法來代替乘法，就可以避免連乘帶來的精度問題了。</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9a9c2744d1014cdba818646a34096bbe><p class=pgc-img-caption></p></div><p><br></p><p>預測的方法也非常簡單，我們分別計算出一個文本屬於spam以及ham的概率，然後選擇概率較大的那個作為最終的結果即可。</p><p><br></p><p>我們將原始數據分隔成訓練集以及預測集，調用我們剛剛編寫的算法獲取預測的結果：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/646d383a5c844a79a45c08d5c4de48ff><p class=pgc-img-caption></p></div><p><br></p><p>最後，我們調用一下sklearn當中的classification_report方法來獲取貝葉斯模型的預測效果：</p><p><br></p><div class=pgc-img><img alt=機器學習基礎——帶你實戰樸素貝葉斯模型文本分類 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4025a81427964513be4084175f58e951><p class=pgc-img-caption></p></div><p><br></p><p>從上圖當中看，貝葉斯模型的預測效果還是不錯的。對於垃圾文本識別的準確率有90%，可惜的是召回率低了一點，說明有一些比較模糊的垃圾文本沒有識別出來。這也是目前這個場景下問題的難點之一，但總的來說，貝葉斯模型的原理雖然簡單，但是效果不錯，也正因此，時至今日，它依舊還在發揮著用處。</p><p><br></p><p>NLP是當今機器學習領域非常複雜和困難的應用場景之一，關於文本的預處理以及模型的選擇和優化都存在著大量的操作。本文當中列舉的<strong>只是其中最簡單也是最常用的部分</strong>。</p><p><br></p><p>到這裡，關於樸素貝葉斯的實踐就結束了。我想親手<strong>從零開始</strong>寫出一個可以用的模型，一定是一件非常讓人興奮的事情。但關於樸素貝葉斯模型其實還沒有結束，它仍然有許多細節等待著大家去思考，也有很多引申的知識。模型雖然簡單，但仍然值得我們用心地體會。</p><p><br></p><p>今天的文章就到這裡，如果覺得有所收穫，請順手點個<strong>關注</strong>或者轉發吧，你們的支持是我最大的動力。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>基礎</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/576aef4.html alt=機器學習基礎之高斯分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ae51c831ad524cb29454b50116c6d470 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/576aef4.html title=機器學習基礎之高斯分佈>機器學習基礎之高斯分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/19dad067.html alt="php基礎教程 第三步 學習字符串及相關函數" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2de059299d42438197662d23644f2244 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/19dad067.html title="php基礎教程 第三步 學習字符串及相關函數">php基礎教程 第三步 學習字符串及相關函數</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fd9d0da5.html alt="php基礎教程 第二步 通俗易懂的學習變量、常量與數據類型" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e316d9706340489ba14da6d5572064a4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fd9d0da5.html title="php基礎教程 第二步 通俗易懂的學習變量、常量與數據類型">php基礎教程 第二步 通俗易懂的學習變量、常量與數據類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9d692f78.html alt=基礎通俗講解集成學習算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/36100dd3a1b940f28c135f9165ff526a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9d692f78.html title=基礎通俗講解集成學習算法>基礎通俗講解集成學習算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>