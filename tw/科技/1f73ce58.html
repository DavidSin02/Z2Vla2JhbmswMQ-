<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>復旦大學黃萱菁：自然語言處理中的表示學習 | 极客快訊</title><meta property="og:title" content="復旦大學黃萱菁：自然語言處理中的表示學習 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/77184e60d8e74b9da944a638e38aedfa"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1f73ce58.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1f73ce58.html><meta property="article:published_time" content="2020-11-14T21:00:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:19+08:00"><meta name=Keywords content><meta name=description content="復旦大學黃萱菁：自然語言處理中的表示學習"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/1f73ce58.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>復旦大學黃萱菁：自然語言處理中的表示學習</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>不到現場，照樣看最乾貨的學術報告！</p><p><br></p><p>嗨，大家好。這裡是學術報告專欄，讀芯術小編不定期挑選並親自跑會，為大家奉獻科技領域最優秀的學術報告，為同學們記錄報告乾貨，並想方設法搞到一手的PPT和現場視頻——足夠乾貨，足夠新鮮！話不多說，快快看過來，希望這些優秀的青年學者、專家傑青的學術報告 ，能讓您在業餘時間的知識閱讀更有價值。</p></blockquote><p><br></p><hr><p><br></p><p>人工智能論壇如今浩如煙海，有硬貨、有乾貨的講座卻百裡挑一。“AI未來說·青年學術論壇”系列講座由中國科學院大學主辦，百度全力支持，讀芯術、paperweekly作為合作自媒體。承辦單位為中國科學院大學學生會，協辦單位為中國科學院計算所研究生會、網絡中心研究生會、人工智能學院學生會、化學工程學院學生會、公共政策與管理學院學生會、微電子學院學生會。2020年6月20日，第16期“AI未來說·青年學術論壇”NLP前沿技術及產業化線上專場論壇以“線上平臺直播+微信社群圖文直播”形式舉行。復旦大學黃萱菁帶來報告《自然語言處理中的表示學習》。</p><p><br></p><p>黃萱菁，復旦大學計算機科學技術學院教授、博士生導師。1998年於復旦大學獲計算機理學博士學位，研究領域為人工智能、自然語言處理、信息檢索和社會媒體分析。兼任中國中文信息學會常務理事，社會媒體專委會副主任，中國計算機學會中文信息技術專委會副主任。在SIGIR, IEEE TKDE, ACL, ICML, IJCAI, AAAI, SCIS, CIKM, EMNLP, WSDM和COLING等多個高水平國際學術期刊和會議上發表了近百篇論文，負責的多個科研項目受到國家自然科學基金、科技部、教育部、上海市科委的支持。近年來擔任2014年ACM 信息與知識管理會議競賽主席，2015年ACM 互聯網搜索與數據挖掘會議組織者，2015年社會媒體處理大會程序委員會副主席，2016年、2019年全國計算語言學會議程序委員會副主席，2017年國際自然語言處理與中文計算會議程序委員會主席等學術職務，併入選由清華大學—中國工程院知識智能聯合研究中心和清華大學人工智能研究院聯合發佈的“2020年度人工智能全球女性”及“2020年度AI 2000人工智能全球最具影響力提名學者”。</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/77184e60d8e74b9da944a638e38aedfa><p class=pgc-img-caption></p></div><h3 class=pgc-h-arrow-right>自然語言處理中的表示學習</h3><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e009ba5b99644155a8c7df22305b9185><p class=pgc-img-caption></p></div><p>首先，黃萱菁教授介紹了語言表示學習的內容。語言表示學習是一個非常主觀性的概念，可以從很多角度給一個定義。從認知科學角度，語言表示是語言在人腦中的表現形式，關係到人們如何理解和產生語言；從人工智能角度，語言表示是語言的形式化或者數學描述，以便在計算機中表示語言，並且能夠讓計算機程序進行自動處理。好的文本表示是一個非常主觀性的概念，需要具有很好的表示能力，比如說模型具有一定的深度；能夠讓後續學習任務變得簡單，能夠帶來下游任務性能的提升；具有一般性，是任務或者領域獨立的。</p><p><br></p><p>早期的語言表示主要採用符號化的離散表示，詞表示為One-Hot向量，即一維為1、其餘維為0的向量，比如電腦和計算機；句子或篇章通過詞袋模型、TF-IDF模型、N元模型等方法進行轉換。離散表示的缺點是詞和詞之間沒有距離的概念，比如電腦和計算機語義幾乎相同，但是它們的One-Hot表示完全不同，這是不合理的。目前主流語言表示採用更加精確的數學表示，通常使用基於深度學習的表示。深度學習是機器學習的一個子領域，傳統機器學習方法通常需要人工設計的表示和特徵提取方法，深度學習則不需要特徵提取，甚至可以進行自動的表示學習。深度學習在自然語言處理的許多任務中都獲得了重大進展，卷積神經網絡、循環神經網絡、對抗神經網絡等神經網絡一方面可以成功運用於分詞、詞性標註、命名實體識別等基本自然語言處理任務，另一方面也可以極大提升自動問答、對話等應用系統的性能。</p><p><br></p><p>接下來，黃萱菁教授的報告內容聚焦於表示學習，特別是語義表示。基於神經網絡的表示學習是將不同粒度文本的潛在語法或語義特徵分佈式地存儲在一組神經元中，用稠密、連續、低維的向量進行表示，這裡的不同粒度包括詞語、短語、句子、句對等。短語在語義層面上類似詞語，結構上類似於句子，不同粒度的語言表示有不同的用途，比如詞語和短語表示主要用於預訓練，服務於下游任務，而句子和句對錶示可以直接用於文本分類、匹配、閱讀理解、語篇分析等具體任務。</p><p><br></p><p>詞語表示學習也稱詞嵌入，它把詞語從符號空間映射到向量空間。2013年之前，只有少量工作研究詞嵌入，包括非常有名的、Bengio提出的神經語言模型；2013年之後有了大量新工作，特別有代表性的是word2vec和glove；2016年之後出現了短暫冷卻現象；2018年之後又出現大量新工作，與從前學習相對比較獨立的詞向量不同，新工作學習帶有上下文的語境化的詞向量，經典工作有Elmo和Bert，相關的兩篇論文都獲得了NAACL最佳論文獎。學習上下文無關的詞向量的眾多模型中，word2vec是最高效的算法之一，它包括兩個模型，一個是連續詞袋模型，用上下文信息的平均預測目標詞；另一個是跳詞模型，用目標詞預測上下文，這兩種模型都可以學習高質量的詞表示。不同於word2vec，glove是由斯坦福完成的，它直接建模兩個詞的共現頻率和該詞所對應向量內積間的關係，使它們儘可能接近，作者給出不同維度、不同語料訓練詞向量的結果，在實際研究過程中很有用。</p><p><br></p><p>短語和句子表示學習的方法是類似的，都和結構預測緊密相關。幾種常見的語義組合函數都可以用於從詞語序列語義表示生成短語句子的表示，包括遞歸神經網絡、卷積神經網絡、循環神經網絡、Transformer等等，這些方法也可以組合起來使用。</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c16190df329c491683777162c5cee8be><p class=pgc-img-caption></p></div><p>上圖是卷積神經網絡對句子建模的經典工作，採用雙通道CNN得到句子表示，用於文本分類，通過動態Pooling機制解決句子變長的問題。循環神經網絡用於對句子進行序列化建模，為了解決序列化建模過程中出現的梯度消失或者梯度彌散情況，先後有人提出了長短時記憶單元（LSTM）和門循環單元（GRU）。循環神經網絡可以擴充為編碼器-解碼器的架構。其中編碼器沒有輸出，在解碼的時候則不需要新的輸入；編碼器用於理解，解碼器用於生成，如果在解碼的時候引入注意力機制，就可以進一步提升模型的性能。</p><p><br></p><p>接著，黃萱菁教授介紹了所在項目組在短語和句子表示學習方面所做的工作，他們在句子建模方面做的一項代表性工作是基於門機制的遞歸神經網絡。利用樹結構神經網絡可以獲得句子樹結構，他們對樹結構遞歸神經網絡進行了改進，添加門機制，希望對上下文窗口之間的相鄰字詞組合關係進行更為精細的建模，從字間的關係構建詞間的關係，從而構建整個句子結構。</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3fd0d9c8c9ff4f85810ca11892186e9e><p class=pgc-img-caption></p></div><p>上圖所示的例子“下雨天地面積水”，當前目標字是“地”，需要判斷“地”是詞首還是詞尾。“天地”中“地”是詞尾，“地面”中“地”是詞首。實際上，這個句子非常複雜，任何兩個相鄰字都可以構成一個詞。為了在給定上下文時預測“地”的標籤是詞尾還是詞首，網絡從底層到頂層，遞歸地進行特徵組合。圖中黑色是活躍神經元，空心是抑制神經元，邊表示消息傳遞，實線邊表示接受消息上傳，虛線邊表示拒絕，通過這樣的過程可以得到整個句子的樹結構（上圖中最右側），“下雨天-地面-積水”，還可以通過把所有組合特徵合併到網絡中來估計樹結構的得分，這種模型可以同時得到句子表示和中間結果，可用於分詞、依存句法分析和句子建模等任務。</p><p><br></p><p>黃萱菁教授的項目組所做的另一個改進是對二叉樹的改進。句子的表示可以認為是句中所有詞表示的組合，遞歸神經網絡用一棵句法樹，把詞按照句法樹的成分結構進行不斷地遞歸組合，最後得到整個句子的表示。但是，遞歸神經網絡只能處理二叉樹的結構，而不能方便地拓展到依存句法樹。因此，他們把遞歸神經網絡和卷積神經網絡進行組合，提出了一種可以處理多叉樹的遞歸卷積神經網絡模型，引入卷積層和池化層，從而把遞歸神經網絡拓展到依存句法樹上。再進一步地，黃萱菁教授的項目組發現在自然語言處理中，雖然可以用語義組合的方式得到句子的表示，但實際上並非所有短語句子語義都是合成性的，有一些短語語義不能由成分組合得到，比如馬馬虎虎、九牛二虎和馬、老虎、牛沒有關係。所以為了提升語義結構組合能力，他們採用了樹結構LSTM，基於句法樹遞歸對句子進行建模，並引入了參數化的控制器，從而能夠自適應確定非葉節點的合成方式是合成性還是非合成性。模型分成三部分，分別是合成性非葉節點、非合成性的非葉節點和控制器。合成性非葉節點相應短語的表示,例如His performance是由子成分表示組合而來的；對於非合成性非葉節點的相應短語表示，例如at fever pitch不是由主成分得來，而是作為基本語言單位學習得到，具體則使用開關控制器控制合成的方式。</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cabe65380e59423cbe9a2c7a13fa26b5><p class=pgc-img-caption></p></div><p>在句對錶示學習方面，許多自然語言處理任務都可以建模為句對編碼任務，比如句子的重述、蘊含分析、語篇分析等等，句子編碼的目的是給定兩個句子，建模其語義關係來學習表徵。比如句子的蘊含分析，需要預測文本和假設之間是什麼關係，如蘊含關係、中立關係、矛盾關係等等。黃萱菁教授的項目組在句對錶示學習方面所做的工作是對語篇關係進行檢測，即檢測篇章中句子間的關係。以兩個句子為例，一個發生在Early in the morning，另外一個發生在mid morning，它們之間是承接關係。用詞向量差值可以表現句間關係，把兩個句子的所有詞兩兩做詞向量的差值可以得到位移矩陣。通過位移矩陣可以預測句間關係，比如承接關係對應的矩陣中有大量平行箭頭。另外，由於矩陣大小隨句子長度變化，所以引入Fisher Vector的方法，把矩陣轉變為定長向量，進行語篇關係分類。同時，項目組還利用門機制組合多種句子匹配函數，採用雙向LSTM表示句中的詞語，每個詞語所對應的LSTM隱狀態就表徵詞語和上下文。為了度量隱狀態之間的相關性，項目組提出門相關性網絡，它可以組合許多匹配函數，比如雙線性張量和單層神經網絡。</p><p><br></p><p>之後黃萱菁教授介紹了近期研究趨勢，包括模型層面研究趨勢、學習層面研究趨勢、理解和解釋層面的研究趨勢。</p><p><br></p><p>模型層面包括圖神經網絡和Transformer。真實數據場景中，許多數據結構無法採用現有神經網絡表示，比如社交網絡、蛋白質交互關係、互聯網等等。為了對這類圖結構數據進行建模，研究者們提出圖神經網絡，它可以建模節點之間的語義關係、語義關聯，可以很靈活地對結構化數據進行表示學習。把圖神經網絡用在語言表示的思路是定義或者學習一個句子的圖結構，並且在圖神經網絡節點中加上上下文特徵。句子結構可以用三種方式表示，分別是序列結構、句法樹結構、任務相關語義結構，沒有單一結構能夠表示所有任務。黃萱菁教授的項目組把Transformer的自注意力機制擴展到圖神經網絡，提出語境化非局部網絡，使得不同任務動態學習結構，它既可以學習節點和邊的屬性，對它進行編碼，也可以學習節點之間的連邊。這兩點使得他們可以根據詞語語境化表示和句子複雜結構更好地學習句子表示。Transformer是這幾年最火的概念，它是全自注意力的機制，完全取代了神經網絡中的經典合成函數，在各種任務上都取得了非常好的結果，它的成功可以歸因於非局部結構偏置，句中任何一對詞的依存關係都可以被建模。通過摒棄複雜語義組合和使用非局部結構偏置，Transformer可以提供更有效的計算，為Bert等模型打下基礎，也有很好的可擴展性。但Transformer有一些缺點，例如兩兩之間計算開銷非常大，和文本長度的平方呈正比，所以它需要大規模訓練數據。黃萱菁教授的項目組提出了輕量化版本的星型Transformer，把全連接結構改成星型結構，任何兩個節點都可以通過中繼節點相連，這樣模型的複雜度就從平方變成了線性，同樣可以通過中繼節點處理長距離依賴，通過圓環上的弧處理局部依賴。因為引入了局部依賴，就不再需要Position Embedding，因為複雜度降低可以適用於小規模和中等規模的數據。</p><p><br></p><p>學習層面近期研究趨勢包括元學習、多任務學習、遷移學習等。在處理語言合成性時，如果採用同一個不變參數建模語言合成性，將無法捕捉合成的豐富性並且降低語言表現力；如果為每種合成策略分配獨立的函數，但這些函數是硬編碼的，就增加了複雜度，會引起數據稀疏。黃萱菁教授的項目組採用元學習的解決方案，他們不是直接採用可學習的參數化合成函數而是引入元神經網絡，元神經網絡可以動態生成真正用於組合樹結構的基網絡參數，從而擴展了模型表現力。多任務學習是一種聯合多個任務同時學習來增強模型表示和泛化能力的手段。黃萱菁教授介紹了他們組一篇通過整合來自多個分詞標準共享知識的論文，論文提出基於對抗策略的多標準學習方法，具體是把每個分詞標準當成一個任務，在多任務學習框架下提出了三種共享和私有模型，平行模式、疊加模式和組合模式。黃色共享層用於提取不變特徵，灰色私有層提取不同分詞標準的私有特徵。進一步地，利用對抗策略，從而可以確保共享層能夠提取所有分詞標準的不變特徵，要求共享層不能預測出分詞具體用哪一個標準語料庫。遷移學習包括兩個階段，第一階段是學習可遷移的知識，第二階段是把知識遷移到新的任務。可遷移的知識可以通過監督學習或者無監督學習方式得到。無監督學習更加熱門更受重視，先通過無監督方式學習可遷移的知識表示，再把知識遷移給新任務。預訓練模型普遍採用無監督學習，其中ELMo採用雙向LSTM；GPT首次用transformer decoder來進行預訓練，decoder相當於是單向的語言模型，等於mask掉當前和後面的詞；BERT是雙向的語言模型，為了讓預測的時候待預測詞看不到自己，它引入了mask language model，隨機mask待預測的詞，再用雙向語言模型預測這些詞。預訓練模型以ELMo為開始，以BERT為發展高潮，之後出現了非常多新的模型，這些模型逐漸發展，訓練語料越來越大、參數數量越來越多、表現性能越來越高。今年他們組的一篇期刊文章對預訓練模型進行了分類，按照是否語境化可以分為靜態和動態模型，按照模型架構可以分成LSTM、Transformer Decoder、Transformer Encoder、完整的Transformer；根據學習任務來分，分成基於監督學習的模型，比如CoVe，和更多基於無監督或者自監督的預訓練模型。</p><p><br></p><p>最後黃萱菁教授簡單總結了當前自然語言處理研究面臨的窘境。許多NLP競賽成績增長越來越慢，表明NLP系統性能趨於平臺化，接下來神經網絡NLP該往何處去？模型的可解釋性將變得越來越重要，現在許多模型有著優越的性能，但是可解釋性很低，如果不瞭解其中優缺點，很難在各種場景下做出最佳的選擇。近期一些研究從可解釋性角度對自然語言處理進行研究，可解釋性包括面向模型可解釋性和任務可解釋性。面向模型的可解釋性可以從認知角度、語言學角度看模型編碼了哪些語言學特徵，人類神經機理有什麼相似程度；任務角度可以給定一個任務例如抽取式摘要、命名實體識別，研究模型的組成部分，瞭解不同設置下模型各自適應場景是什麼，掌握怎麼樣進一步提高現有模型有效方向等。</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/77184e60d8e74b9da944a638e38aedfa><p class=pgc-img-caption></p></div><h3 class=pgc-h-arrow-right>AI未來說*青年學術論壇</h3><p><br></p><blockquote><p>第一期 數據挖掘專場</p></blockquote><p>1. 李國傑院士：理性認識人工智能的“頭雁”作用</p><p>2. 百度熊輝教授：大數據智能化人才管理</p><p>3. 清華唐傑教授：網絡表示學習理論及應用</p><p>4. 瑞萊智慧劉強博士：深度學習時代的個性化推薦</p><p>5. 清華柴成亮博士：基於人機協作的數據管理</p><p><br></p><blockquote><p>第二期 自然語言處理專場</p></blockquote><p>1. 中科院張家俊：面向自然語言生成的同步雙向推斷模型</p><p>2. 北郵李蕾：關於自動文本摘要的分析與討論</p><p>3. 百度孫珂：對話技術的產業化應用與問題探討</p><p>4. 阿里譚繼偉：基於序列到序列模型的文本摘要及淘寶的實踐</p><p>5. 哈工大劉一佳：通過句法分析看上下文相關詞向量</p><p><br></p><blockquote><p>第三期 計算機視覺專場</p></blockquote><p>1. 北大彭宇新：跨媒體智能分析與應用</p><p>2. 清華魯繼文：深度強化學習與視覺內容理解</p><p>3. 百度李穎超：百度增強現實技術及應⽤</p><p>4. 中科院張士峰：基於深度學習的通用物體檢測算法對比探索</p><p>5. 港中文李弘揚 ：物體檢測最新進展</p><p><br></p><blockquote><p>第四期 語音技術專場</p></blockquote><p>1. 中科院陶建華：語音技術現狀與未來</p><p>2. 清華大學吳及：音頻信號的深度學習處理方法</p><p>3. 小米王育軍：小愛背後的小米語音技術</p><p>4. 百度康永國：AI 時代的百度語音技術</p><p>5. 中科院劉斌：基於聯合對抗增強訓練的魯棒性端到端語音識別</p><p><br></p><blockquote><p>第五期 量子計算專場</p></blockquote><p>1. 清華大學翟薈：Discovering Quantum Mechanics with Machine Learning</p><p>2. 南方科技大學魯大為：量子計算與人工智能的碰撞</p><p>3. 荷蘭國家數學和計算機科學中心（CWI）李繹楠：大數據時代下的量子計算</p><p>4. 蘇黎世聯邦理工學院（ETH）楊宇翔：量子精密測量</p><p>5. 百度段潤堯：量子架構——機遇與挑戰</p><p><br></p><blockquote><p>第六期 機器學習專場</p></blockquote><p>1. 中科院張文生：健康醫療大數據時代的認知計算</p><p>2. 中科院莊福振：基於知識共享的機器學習算法研究及應用</p><p>3. 百度胡曉光：飛槳（PaddlePaddle）核心技術與應用實踐</p><p>4. 清華大學王奕森：Adversarial Machine Learning: Attack and Defence</p><p>5. 南京大學趙申宜：SCOPE - Scalable Composite Optimization for Learning</p><p><br></p><blockquote><p>第七期 自動駕駛專場</p></blockquote><p>1. 北京大學查紅彬：基於數據流處理的SLAM技術</p><p>2. 清華大學鄧志東：自動駕駛的“感”與“知” - 挑戰與機遇</p><p>3. 百度朱帆：開放時代的自動駕駛 - 百度Apollo計劃</p><p>4. 北理宋文傑：時空域下智能車輛未知區域自主導航技術</p><p><br></p><blockquote><p>第八期 深度學習專場</p></blockquote><p>1. 中科院文新：深度學習入門基礎與學習資源</p><p>2. 中科院陳智能：計算機視覺經典——深度學習與目標檢測</p><p>3. 中科院付鵬：深度學習與機器閱讀</p><p><br></p><blockquote><p>第九期 個性化內容推薦專場</p></blockquote><p>1. 人民大學趙鑫：基於知識與推理的序列化推薦技術研究</p><p>2. 中科院趙軍：知識圖譜關鍵技術及其在推薦系統中的應用</p><p><br></p><blockquote><p>第十期 視頻理解與推薦專場</p></blockquote><p>1. 北京大學袁曉如：智能數據可視分析</p><p><br></p><blockquote><p>第十一期 信息檢索與知識圖譜專場</p></blockquote><p>1. 北京郵電大學邵鎣俠：知識圖譜高效嵌入方法</p><p>2. 人民大學徐君：智能搜索中的排序-突破概率排序準則</p><p>3. 百度周景博：POI知識圖譜的構建及應用</p><p>4. 百度宋勳超：百度大規模知識圖譜構建及智能應用</p><p>5. 百度馮知凡：基於知識圖譜的多模認知技術及智能應用</p><p><br></p><blockquote><p>第十二期 年度特別專場</p></blockquote><p>1. 復旦大學桂韜：當NLP邂逅Social Media--構建計算機與網絡語言的橋樑</p><p>2. 清華大學董胤蓬：Adversarial Robustness of Deep Learning</p><p>3. UIUC羅宇男：AI-assisted Scientific Discovery</p><p>4. 斯坦福應智韜：Graph Neural Network Applications</p><p><br></p><blockquote><p>第十三期 AI助力疫情攻關線上專場</p></blockquote><p>1. 清華大學吳及：信息技術助力新冠防控</p><p>2. 北京大學王亞沙：新冠肺炎傳播預測模型</p><p>3. 百度黃際洲：時空大數據與AI助力抗擊疫情——百度地圖的實踐與思考</p><p>4. 百度張傳明：疫情下的“活”導航是如何煉成的</p><p><br></p><blockquote><p>第十四期 深度學習線上專場</p></blockquote><p>1. 中國科學院徐俊剛：自動深度學習解讀</p><p>2. 北航孫鈺：昆蟲目標檢測技術</p><p>3. 百度尤曉赫：EasyDL，加速企業AI轉型</p><p>4. 百度鄧凱鵬：飛槳視覺技術解析與應用</p><blockquote><p><br></p><p>第十五期 大數據線上專場</p></blockquote><p>1. 復旦趙衛東：大數據的系統觀</p><p>2. 中科大徐童：AI×Talent數據驅動的智能人才計算</p><p>3. 百度李偉彬：基於PGL的圖神經網絡基線系統</p><p>4. 中科大張樂：基於人才流動表徵的企業競爭力分</p><p><br></p><div class=pgc-img><img alt=復旦大學黃萱菁：自然語言處理中的表示學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5c6de5c5262b4bde9ba72cca19e9fed6><p class=pgc-img-caption></p></div><p><strong>留言點贊關注</strong></p><p><strong>我們一起分享AI學習與發展的乾貨</strong></p><p>如轉載，請後臺留言，遵守轉載規範</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>大學</a></li><li><a>語言</a></li><li><a>處理</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html alt=第12屆自然語言處理和知識工程國際會議將在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html title=第12屆自然語言處理和知識工程國際會議將在西華大學舉行>第12屆自然語言處理和知識工程國際會議將在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html alt=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/4e62000034a58600d55e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html title=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行>第12屆自然語言處理與知識工程國際學術會議在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html alt=你對自然語言處理了解多少呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/150674bcc0e44efcae3427c70ad2f072 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html title=你對自然語言處理了解多少呢？>你對自然語言處理了解多少呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html alt=自然語言處理中的深度學習：評析與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html title=自然語言處理中的深度學習：評析與展望>自然語言處理中的深度學習：評析與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html alt=自然語言處理中的語言模型簡介 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html title=自然語言處理中的語言模型簡介>自然語言處理中的語言模型簡介</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html alt=自然語言處理的十大應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dea6cbd6fbef4e9c935b6f56cb9b0097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html title=自然語言處理的十大應用>自然語言處理的十大應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html alt=人工智能之自然語言處理初探 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S4bjUwAFhO20v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html title=人工智能之自然語言處理初探>人工智能之自然語言處理初探</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html alt=人工智能的研究熱點：自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5fdd13a7-6c6d-45d6-9fcd-2829793b5dd3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html title=人工智能的研究熱點：自然語言處理>人工智能的研究熱點：自然語言處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html alt=什麼是自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/64bcc3b1fb8a4f9ca59d452035ca25cb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html title=什麼是自然語言處理>什麼是自然語言處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/84eef54a.html alt=有關自然語言處理的深度學習知識有哪些？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b6e6ac2f1c1948158c7edbe790f52b66 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/84eef54a.html title=有關自然語言處理的深度學習知識有哪些？>有關自然語言處理的深度學習知識有哪些？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b0abef72.html alt="深度學習自然語言處理模型實現大集合（精簡版<100行）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d1461dcb71974b569c9b1ae64e150139 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b0abef72.html title="深度學習自然語言處理模型實現大集合（精簡版<100行）">深度學習自然語言處理模型實現大集合（精簡版&lt;100行）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>