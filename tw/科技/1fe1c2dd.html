<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>瞭解生成對抗網絡（GAN） | 极客快訊</title><meta property="og:title" content="瞭解生成對抗網絡（GAN） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/634604de44ad4d17931ccc0bcf3e46ef"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/1fe1c2dd.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/1fe1c2dd.html><meta property="article:published_time" content="2020-11-14T21:08:08+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:08+08:00"><meta name=Keywords content><meta name=description content="瞭解生成對抗網絡（GAN）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/1fe1c2dd.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>瞭解生成對抗網絡（GAN）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>介紹</p><p>什麼是Generative Adversarial Networks（生成對抗性網絡）？本文中，我們將看到對抗性訓練是一種很有啟發性的想法，其簡單而實用，這代表了機器學習的真正概念進展，尤其是生成模型。</p><p>在進入細節之前，讓我們快速概述一下GANs的用途。生成對抗性網絡屬於一組生成模型集。這意味著他們能夠生成新的內容。為了說明這種“生成模型”的概念，我們可以看一些用GANs獲得結果的著名的例子。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/634604de44ad4d17931ccc0bcf3e46ef><p class=pgc-img-caption>這些是由GANs在對兩個數據集進行訓練後生成的樣本：MNIST和TFD。</p></div><p>當然，這種生成新內容的能力使GANs看起來有點“神奇”。在以下部分中，我們將深入瞭解這些模型背後的想法，數學和建模。我們不僅會討論GANs所依賴的基本概念，我們還會一步一步地構建這些概念，並從一開始就對這些概念進行推理。</p><blockquote><p>注意：儘管我們試圖使本文儘可能獨立，但仍需要具備機器學習的基本先驗知識。</p></blockquote><p>目錄</p><p>1、我們將討論從給定的分佈生成隨機變量的過程。</p><p>2、我們將通過一個例子展示GANs試圖解決的問題可以表示為隨機變量生成問題。</p><p>3、我們將討論基於匹配的生成網絡。</p><p>4、我們將呈現帶有損失函數的通用架構，並且與之前的所有部分建立連接。</p><p>生成隨機變量</p><p>我們先討論生成隨機變量的方法：逆變換方法，它允許從簡單的均勻隨機變量生成複雜的隨機變量。我們將在後面看到與生成模型存在的深層聯繫。</p><p>隨機變量可以是偽隨機生成的</p><p>從理論上講，生成真正隨機的數字是不可能的。但是，可以定義生成數字序列的算法，其特徵非常接近理論隨機數序列的屬性。特別是，計算機能夠使用偽隨機數生成器生成一個數字序列，該數字序列近似地遵循0和1之間的均勻隨機分佈。均勻的情況是非常簡單的，可以以不同的方式建立更復雜的隨機變量。</p><p>隨機變量表示的是運算或過程的結果</p><p>有不同的技術可以生成更復雜的隨機變量。我們可以找到逆變換方法，拒絕採樣法，Metropolis-Hasting算法等。所有這些方法都依賴於不同的數學技巧，這些技巧主要包括表示我們希望作為運算或過程的結果生成的隨機變量。</p><p>拒絕採樣是針對複雜問題的一種隨機採樣方法，拒絕採樣是指不從複雜分佈中採樣，而是從已知的簡單分佈中採樣，並根據一定條件接受或拒絕採樣值的過程的結果。重複這個過程直到採樣值被接受，我們可以證明在接受的條件正確的情況下，有效採樣的值將遵循正確的分佈。</p><p>在Metropolis-Hasting算法中，使用的是馬爾可夫鏈蒙特卡羅（MCMC）方法，用於從難以直接採樣的概率分佈中獲得隨機樣本序列。該序列可用於近似分佈或計算積分。我們可以使用馬爾科夫鏈（MC），使得MC的平穩分佈對應於我們需要從中抽樣的隨機變量的分佈，一旦找到這個MC，考慮到我們已經達到了一個穩定的狀態，我們就可以在這個MC上模擬出足夠長的軌跡，然後我們以這種方式獲得的最後一個值可以被認為是從有用的分佈中得出的。</p><p>逆變換 方法</p><p>逆變換方法的概念僅僅是為了表示我們的複雜，而不是數學意義中的隨機變量最為函數應用於一個我們知道如何生成的均勻隨機變量的結果。</p><p>在下面的一維例子中。設X是我們想要從中採樣的複雜隨機變量，U是[0,1]上的均勻隨機變量，我們知道如何從中採樣。我們賦予隨機變量由其累積分佈函數（CDF）完全定義。隨機變量的CDF是從隨機變量的定義域到區間[0,1]的函數，並且在一個維度中定義，例如：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/65164944d26c420b8eed4bda5be7c52b><p class=pgc-img-caption></p></div><p>在特定情況下U是我們的均勻隨機變量：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6ed93db3b3d4470380f4dd17cb08a497><p class=pgc-img-caption></p></div><p>為簡單起見，我們假設函數CDF_X是可逆的：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/68d5bbf7297d42cbb34b373a3c182f5a><p class=pgc-img-caption></p></div><p>（這個方法可以通過使用泛化的逆函數來簡單地擴展到非可逆的例子但這並不是我們想要關注的重點）。然後：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3a8cc9f8a06f4ba6a3801a8c6d737922><p class=pgc-img-caption></p></div><p>我們可以得到：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a053349795d7404da06524590c8317d5><p class=pgc-img-caption></p></div><p>我們可以看到，Y和X具有相同的CDF，然後定義相同的隨機變量。因此，通過如上定義Y（作為均勻隨機變量的函數），我們設法定義了具有目標分佈的隨機變量。</p><p>綜上所述，逆變換方法是通過使均勻隨機變量經過精心設計的“變換函數”（逆CDF）來生成遵循給定分佈的隨機變量的方式。事實上，這種“逆變換方法”的概念可以擴展到“變換方法”的概念，“變換方法”更簡單地說，在生成隨機變量作為一些更簡單的隨機變量的函數時（不一定是均勻的，然後變換函數是不再是逆CDF）。從概念上講，“變換函數”的目的是使初始概率分佈變形/重塑：變換函數從初始概率分佈相對於目標概率分佈過高的位置，並將其置於初始概率分佈過低的位置。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d50bbc81f4c84d2689e70ae38a79bde8><p class=pgc-img-caption>逆變換方法的圖示。藍色：均勻分佈在[0,1]上。橙色：標準高斯分佈。灰色：從均勻到高斯分佈的映射（逆</p></div><p><strong>生成模型</strong></p><p>我們試圖生成非常複雜的隨機變量......</p><p>假設我們生成大小為n*n像素的狗的黑白方形圖像。我們可以將每個數據重新塑造為N = n×n維向量（通過在彼此之上堆疊），使得狗的圖像可以由向量表示。然而，這並不意味著所有的向量都代表了曾經被塑造成方形的狗！因此，我們可以說，在N維空間的向量空間中，可以有效地生成一種看起來像條狗的圖形，這是根據一種特定的概率分佈在整個N維向量空間上的。本著同樣的精神，在這個N維向量空間上存在貓，鳥等圖像的概率分佈。</p><p>然後，生成狗的新圖像的問題等同於在N維向量空間上按照“狗概率分佈”生成一個的新向量的問題。事實上，我們面臨的問題是根據特定的概率分佈生成一個隨機變量。</p><p>在這一點上，我們可以提到兩件重要的事情。首先，我們提到的“狗概率分佈”是在非常大的空間內非常複雜的分佈。其次，即使我們可以假設存在這樣的基礎分佈，但我們顯然不知道如何明確地表達這種分佈。之前的兩點都使得從該分佈生成隨機變量的過程非常困難。但讓我們嘗試著解決這兩個問題。</p><p>使用神經網絡的變換方法作為函數！</p><p>當我們嘗試生成狗的新圖像時，我們的第一個問題是N維向量空間上的“狗概率分佈”是一個非常複雜的問題，我們不知道如何直接生成複雜的隨機變量。然而，正如我們非常清楚如何生成N個不相關的均勻隨機變量，我們可以利用變換方法。為此，我們需要將N維隨機變量表示為將非常複雜的函數應用於簡單的N維隨機變量的結果！</p><p>這裡，我們可以強調的事實是，發現變換函數並不像我們在描述逆變換方法時所做的那樣簡單。變換函數無法明確表達，因此，我們必須從數據中學習它。</p><p>在大多數情況下，非常複雜的函數自然意味著神經網絡建模。然後，通過神經網絡對變換函數進行建模，該神經網絡將一個簡單的N維均勻隨機變量作為輸入，並將其作為輸出返回另一個N維隨機變量，該隨機變量在訓練後應遵循正確的“dog概率分佈” 。網絡架構設計完成後，我們仍然需要對其進行訓練。後面，我們將討論訓練這些生成網絡的兩種方法，包括GANs背後的對抗訓練的概念。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/aef57f9907804c1d8fb0585af5eea121><p class=pgc-img-caption>使用神經網絡的生成模型概念的圖。顯然，我們真正談論的維度遠高於此處所表示的維度。</p></div><p><strong>生成匹配網絡</strong></p><p><strong>訓練生成模型</strong></p><p>到目前為止，我們已經證明了我們生成狗的新圖像的問題可以被重新描述為在N維向量空間中生成遵循“狗概率分佈”的隨機向量的問題，並且我們建議使用變換方法，用神經網絡來模擬變換函數。</p><p>現在，我們仍然需要訓練（優化）網絡以表達正確的變換函數。我們選擇兩種不同的訓練方法：直接訓練方法和間接訓練方法。直接訓練方法是比較真實概率分佈和生成的概率分佈，並通過網絡反向傳播差異（誤差）。這是規則生成匹配網絡（GMNs）的想法。對於間接訓練方法，我們不直接比較真實和生成的概率分佈。相反，我們訓練生成網絡，讓這兩個分佈通過選擇一個下游任務，這樣生成網絡相對於下游任務的優化過程將強制生成的分佈接近真實的分佈。</p><p><strong>比較基於樣本的兩個概率分佈</strong></p><p>如上所述，GMN的概念是通過直接比較生成分佈和真實分佈來訓練生成網絡。如果我們有一種比較基於樣本的概率分佈的方法，我們可以使用它來訓練網絡。實際上，我們有一個真實數據樣本，我們可以在訓練過程的每次迭代中生成一個生成數據的樣本。</p><p>雖然理論上可以使用任何基於樣本的距離(或相似性度量)來有效地比較兩個分佈，但我們可以特別提到最大均值差異（MMD）方法。MMD定義了可以基於這些分佈的樣本計算（估計）的兩個概率分佈之間的距離。</p><p><strong>分佈匹配誤差的反向傳播</strong></p><p>如果我們定義了一種基於樣本比較兩種分佈的方法，我們就可以定義GMN中生成網絡的訓練過程。給定具有均勻概率分佈的隨機變量作為輸入，我們希望所生成的輸出的概率分佈是“狗概率分佈”。然後，GMN的想法是通過重複以下步驟來優化網絡：</p><ul><li>產生一些統一的輸入</li><li>使這些輸入通過網絡並收集生成的輸出</li><li>比較真實的“狗概率分佈”和基於可用樣本生成的一個</li><li>使用反向傳播來進行梯度下降的一個步驟，以降低真實分佈和生成分佈之間的距離（例如MMD）</li></ul><p>如上所述，當遵循這些步驟時，我們在網絡上應用梯度下降，其具有損失函數，該函數是當前迭代時真實分佈與生成分佈之間的距離。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ebf250f92bcf429c8eb6177ee2b67d48><p class=pgc-img-caption>生成匹配網絡採用簡單的隨機輸入，生成新數據，直接比較生成數據的分佈與真實數據的分佈，並反向傳播匹配誤</p></div><p><strong>生成對抗網絡</strong></p><p><strong>“間接”訓練方法</strong></p><p>上面提出的“直接”方法在訓練生成網絡時直接比較生成分佈與真實分佈。規則GAN的好處在於用間接的比較替換這種直接比較，後者採用這兩種分佈的下游任務的形式，然後對該任務進行生成網絡的訓練，使得它迫使所生成的分佈越來越接近真實分佈。</p><p>GANs的下游任務是區分真樣本和生成樣本的任務。因此，在GAN架構中，我們有一個鑑別器，它從真實的和生成的數據中提取樣本並儘可能地對它們進行分類，還有一個生成器，它被訓練成儘可能地欺騙鑑別器。</p><p><strong>理想的情況：完美的生成器和鑑別器</strong></p><p>為了更好地理解為什麼訓練生成器來欺騙鑑別器會得到與直接訓練生成器匹配目標分佈相同的結果，讓我們採用一個簡單的一維示例。我們暫時忘記掉如何表示生成器和鑑別器，並將它們視為抽象概念。此外，兩者都被認為是“完美的”，因為它們不受任何類型（參數化）模型的約束。</p><p>假設我們有一個真正的分佈，例如一維高斯分佈，並且我們想要一個從這個概率分佈中採樣的生成器。我們所謂的“直接”訓練方法將包括迭代地調整生成器（梯度下降迭代）以校正真實分佈和生成分佈之間的測量差異/誤差。最後，假設優化過程完美，我們應該最終得到與真實分佈完全匹配的生成分佈。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2a9379d5257c4c66a0d2aeb0a4f995ea><p class=pgc-img-caption>直接匹配方法的概念的例證。藍色的分佈是真實的，而生成的分佈用橙色表示。通過逐次迭代，我們比較兩個分佈</p></div><p>對於“間接”方法，我們還必須考慮一個鑑別器。我們現在假設這個鑑別器是一種oracle，它確切知道什麼是真實和生成的分佈，並且能夠根據這些信息預測任何給定點的類（“真”或“生成”）。如果這兩個分佈很明顯，那麼鑑別器將能夠輕鬆地進行分類，並且可以對我們提供給它的大多數點進行分類。如果我們想欺騙鑑別器，我們必須使生成的分佈接近真實的分佈。當兩個分佈在所有點上相等時，鑑別器將很難預測類：</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/969a437804c648b48120c25f4668e0ee><p class=pgc-img-caption>對抗性方法的直覺。</p></div><p>藍色分佈是真實的，橙色是生成的分佈。在灰色中，右邊有相應的y軸，如果它選擇每個點中密度較高的類（假設“真實”和“生成”數據的比例相等），我們就會顯示鑑別器的概率為真。兩個分佈越接近，鑑別器就越容易出錯。在訓練時，目標是將“綠色區域”移向“紅色區域”。</p><p>在這一點上，似乎有理由懷疑這種間接方法是否真的是一個好方法。實際上，它似乎更復雜。對於第一點，直接比較基於樣本的兩個概率分佈的難度抵消了間接方法的明顯較高的複雜性。對於第二點，很明顯，鑑別器是未知的。</p><p><strong>對抗性神經網絡</strong></p><p>現在讓我們描述採用GANs架構中的生成器和鑑別器的具體形式。生成器是一個模擬轉換函數的神經網絡。它將一個簡單的隨機變量作為輸入，並且必須在訓練後返回一個遵循目標分佈的隨機變量。由於鑑別器結構複雜且未知，我們決定用另一種神經網絡對其進行建模。這個神經網絡模型具有辨別功能。它將一個點作為輸入，並將該點的概率作為輸出返回為“真”。</p><p>現在我們強加一個參數化模型來表達生成器和鑑別器，實際上並沒有對上面給出的理論產生影響：我們只是在一些參數化空間而不是理想的空間中工作，因此，在理想情況下我們應達到的最佳點可以被看作是“圓”，是由參數化模型的精確性來判定的。</p><p>一旦確定，這兩個網絡就可以(同時)以相反的目標聯合訓練：</p><ul><li>生成器的目標是欺騙鑑別器，因此訓練生成神經網絡使最終分類誤差最大化（真實數據和生成數據之間）</li><li>鑑別器的目標是檢測假的生成數據，因此訓練判別神經網絡使最終分類誤差最小化</li></ul><p>因此，在訓練過程的每次迭代中，生成網絡的權重都會更新，以便增加分類誤差，同時更新判別網絡的權重以減少分類誤差。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b22732dc147d46a6b680f8bb70c78d97><p class=pgc-img-caption>生成性對抗網絡表示</p></div><p>生成器將簡單隨機變量作為輸入並生成新數據。鑑別器採用“真實”和“生成”數據並嘗試區分它們，構建分類器。生成器的目標是欺騙鑑別器（通過將儘可能多的生成數據與真實數據混合來增加分類錯誤），鑑別器的目標是區分真實數據和生成數據。</p><p>這些相反的目標和兩個網絡的對抗性訓練的隱含概念解釋了“對抗性網絡”的名稱：兩個網絡都試圖相互擊敗對方，這樣做的目的是讓對方都變得越來越好。他們之間的競爭使這兩個網絡在各自的目標方面“進步”。從博弈論的角度來看，我們可以將此設置視為極小極大雙玩家遊戲，其中均衡狀態對應於發生器從精確目標分佈產生數據並且鑑別器預測“真實”或“生成”的情況，它接收的任何一點的概率為1/2。</p><p>關於GAN的數學方面</p><p>神經網絡建模本質上需要定義兩件事：架構和損失函數。我們已經描述了GANs的架構。它包含兩個網絡：</p><ul><li>生成網絡G，隨機輸入z定義為Pz，並返回一個輸出Xg= G（z），該輸出應該遵循（訓練後）目標概率分佈</li><li>判別網絡D，輸入X可以是“ 真實”的（Xt，用Pt表示）或“生成的”Xg，（用Pg表示是由Pz經過G輸出的）並將X的概率D（x）返回為“真實”數據</li></ul><p>現在讓我們仔細看看GAN的“理論”損失函數。如果我們以相同的比例向鑑別器發送“真實”和“生成”的數據，則鑑別器的預期絕對誤差可以表示為</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/45004b695bdf4075b01bc1c2017462c5><p class=pgc-img-caption></p></div><p>生成器的目標是欺騙鑑別器，其目標是能夠區分真實數據和生成數據。因此，在訓練生成器時，我們希望誤差最大化，同時我們想要使鑑別器的誤差最小化。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/31622e4197f845139273249418b1817e><p class=pgc-img-caption></p></div><p>對於任何給定的生成器G，最佳可能的鑑別器是最小化的鑑別器</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/689243fc81ec4f3ebcf07593a784d3be><p class=pgc-img-caption></p></div><p>為了最小化(關於D)這個積分，我們可以最小化每個x值在積分內的函數，然後定義給定生成器的最佳鑑別器</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b287e1dc74f0443ba12b450fe064c261><p class=pgc-img-caption></p></div><p>然後我們搜索G最大化</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/06affc61516b47139f40d333c9bedae8><p class=pgc-img-caption></p></div><p>同樣，為了最大化G，我們可以最大化X的每個值的積分內的函數。</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/94d87f8d109d4c3c856b56243d2d3493><p class=pgc-img-caption></p></div><p>當然，由於Pg是應該與1整合的，我們必然擁有最佳的G</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/78eeddda31964191b0e9df2ada98d1cf><p class=pgc-img-caption></p></div><p>因此，我們已經證明，在具有無限容量生成器和鑑別器的理想情況下，對抗性設置的最佳點使得生成器產生與真實數據點相同的數據點，並且鑑別器不能比真實的更好。最後，還要注意G最大化</p><div class=pgc-img><img alt=瞭解生成對抗網絡（GAN） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/69602723bb8e4ebaa294d425e817dc5d><p class=pgc-img-caption></p></div><p>在這種形式下，我們更好地看到G想要最大化鑑別器出錯的預期概率。</p><p><strong>本文的主要內容是：</strong></p><ul><li><strong>計算機基本上可以生成簡單的偽隨機變量（例如，它們可以生成非常接近均勻分佈的變量）</strong></li><li><strong>存在不同的方法來生成更復雜的隨機變量，包括“變換方法”的概念，其包括將隨機變量表示為一些更簡單的隨機變量的函數。</strong></li><li><strong>在機器學習中，生成模型試圖從給定（複雜）概率分佈生成數據</strong></li><li><strong>深度學習生成模型被建模為神經網絡（非常複雜的函數），它將一個簡單的隨機變量作為輸入，並返回一個遵循目標分佈的隨機變量（“變換方法”）</strong></li><li><strong>這些生成網絡可以“直接”訓練（通過比較生成數據與真實分佈的分佈）：這就是生成匹配網絡的想法</strong></li><li><strong>這些生成網絡也可以“間接”訓練（通過試圖欺騙同時訓練的另一個網絡來判斷“生成的”數據和“真實”數據）：這就是生成對抗網絡的想法</strong></li></ul></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>瞭解</a></li><li><a>對抗</a></li><li><a>網絡</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/8dce33e7.html alt=理解生成對抗網絡，一步一步推理得到GANs（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/bee194d6fbec4d6f82e82998def3f7a3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8dce33e7.html title=理解生成對抗網絡，一步一步推理得到GANs（一）>理解生成對抗網絡，一步一步推理得到GANs（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/598f7dc3.html alt=網絡技術入門，必須瞭解的七層模型，原來這麼回事，一分鐘瞭解下 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/598f7dc3.html title=網絡技術入門，必須瞭解的七層模型，原來這麼回事，一分鐘瞭解下>網絡技術入門，必須瞭解的七層模型，原來這麼回事，一分鐘瞭解下</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cd1b5612.html alt=生成對抗網絡（GAN）的數學原理全解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/683f230be4bf47319263888f821593ee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cd1b5612.html title=生成對抗網絡（GAN）的數學原理全解>生成對抗網絡（GAN）的數學原理全解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1ba82a0a.html alt=看懂帶寬和吞吐量，瞭解如何充分利用網絡 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/251396698b8f41729aa1386cd14516d2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1ba82a0a.html title=看懂帶寬和吞吐量，瞭解如何充分利用網絡>看懂帶寬和吞吐量，瞭解如何充分利用網絡</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/08dfb7c3.html alt=瞭解十大黑客網絡攻擊方式：以防被黑不自知 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/c911852c1e504dbdb74a7a736affb08f style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/08dfb7c3.html title=瞭解十大黑客網絡攻擊方式：以防被黑不自知>瞭解十大黑客網絡攻擊方式：以防被黑不自知</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ea1bb612.html alt=光纜——未來網絡主導 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e75c1afe12354a93bad8495ad1057693 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ea1bb612.html title=光纜——未來網絡主導>光纜——未來網絡主導</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5010a4b6.html alt=兩分鐘瞭解低損耗電纜結構 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9af84f52bbed4ee39f3825e0f43e619b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5010a4b6.html title=兩分鐘瞭解低損耗電纜結構>兩分鐘瞭解低損耗電纜結構</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bdc59733.html alt="網絡詞名場面是什麼意思 名場面是什麼梗" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bdc59733.html title="網絡詞名場面是什麼意思 名場面是什麼梗">網絡詞名場面是什麼意思 名場面是什麼梗</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cae5a51a.html alt=「施工技巧」詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/decf8edb02a34404b92b86681378575f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cae5a51a.html title=「施工技巧」詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口>「施工技巧」詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/47bcd6a6.html alt=詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dcdae811e636496d948cf5a745f470fc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/47bcd6a6.html title=詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口>詳細瞭解光纜、終端盒、尾纖的接法和光纖各種接口</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a002ca18.html alt=王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/26add5cdc08e4214800b25e21b623eb1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a002ca18.html title=王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯>王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8aab963e.html alt=Python手繪圖瞭解一下！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/746c9e6e214b48b2a0215fc9e151cdc8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8aab963e.html title=Python手繪圖瞭解一下！>Python手繪圖瞭解一下！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c90e11f6.html alt=「瞭解」房屋的層高和淨高怎麼算？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1526054178152a496189726 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c90e11f6.html title=「瞭解」房屋的層高和淨高怎麼算？>「瞭解」房屋的層高和淨高怎麼算？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html alt=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/65c4000bda98898dcdbb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html title=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼>谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2db74f7c.html alt=瞭解鍋爐循環泵與換熱站循環泵的佈置 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1533630871099dca28f1fe7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2db74f7c.html title=瞭解鍋爐循環泵與換熱站循環泵的佈置>瞭解鍋爐循環泵與換熱站循環泵的佈置</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>