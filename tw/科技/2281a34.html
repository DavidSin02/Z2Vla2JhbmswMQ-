<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Lucene集成IK Analyzer中文分詞器 | 极客快訊</title><meta property="og:title" content="Lucene集成IK Analyzer中文分詞器 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/bb5b16ad480f4e5f817c222f9699112b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2281a34.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2281a34.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="Lucene集成IK Analyzer中文分詞器"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/2281a34.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Lucene集成IK Analyzer中文分詞器</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right>IK Analyzer</h1><p>IK Analyzer是一個開源的，基於java語言開發的輕量級的中文分詞工具包。從2006年12月推出1.0版開始， IKAnalyzer已經推出了4個大版本。最初，它是以開源項目Luence為應用主體的，結合詞典分詞和文法分析算法的中文分詞組件。從3.0版本開始，IK發展為面向Java的公用分詞組件，獨立於Lucene項目，同時提供了對Lucene的默認優化實現。在2012版本中，IK實現了簡單的分詞歧義排除算法，標誌著IK分詞器從單純的詞典分詞向模擬語義分詞衍化。</p><p><strong>IK Analyzer 2012特性:</strong></p><ul><li>1.採用了特有的“正向迭代最細粒度切分算法“，支持細粒度和智能分詞兩種切分模式；</li><li>2.在系統環境：Core2 i7 3.4G雙核，4G內存，window 7 64位， Sun JDK 1.6_29 64位 普通pc環境測試，IK2012具有160萬字/秒（3000KB/S）的高速處理能力。</li><li>3.2012版本的智能分詞模式支持簡單的分詞排歧義處理和數量詞合併輸出。</li><li>4.採用了多子處理器分析模式，支持：英文字母、數字、中文詞彙等分詞處理，兼容韓文、日文字符</li><li>5.優化的詞典存儲，更小的內存佔用。支持用戶詞典擴展定義。特別的，在2012版本，詞典支持中文，英文，數字混合詞語。</li></ul><p>地址：https://code.google.com/archive/p/ik-analyzer/</p><h1 class=pgc-h-arrow-right>與Lucene集成</h1><p>IK分詞器最先作為lucence上使用而開發，主要用於對中文的分詞，後來發展成獨立的分詞組件，目前只提供到lucence 4.0版本的支持，我們在使用4.0以後的版本的時候需要簡單的集成一下。</p><p>IK需要集成一因為lucence4.0後，Analyer的createComponents方法的參數改變了。</p><p>1.添加依賴：</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;com.janeluo&lt;/groupId&gt;    &lt;artifactId&gt;ikanalyzer&lt;/artifactId&gt;    &lt;version&gt;2012_u6&lt;/version&gt;        &lt;exclusions&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-core&lt;/artifactId&gt;       &lt;/exclusion&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;       &lt;/exclusion&gt;       &lt;exclusion&gt;          &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;          &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt;       &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--lucene-queryparser 查詢分析器模塊 --&gt;    &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;    &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;    &lt;version&gt;7.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>2.因為lucence4.0後，Analyer的createComponents方法的參數改變了。</p><pre><code>protected abstract Analyzer.TokenStreamComponents createComponents(String var1);</code></pre><p>需要將org.apache.lucene.analysis的類IKAnalyzer，IKTokenizer拷貝修改：</p><pre><code>import org.apache.lucene.analysis.Analyzer;public class IKAnalyzer4Lucene7 extends Analyzer {	private boolean useSmart = false;	public IKAnalyzer4Lucene7() {		this(false);	}	public IKAnalyzer4Lucene7(boolean useSmart) {		super();		this.useSmart = useSmart;	}	public boolean isUseSmart() {		return useSmart;	}	public void setUseSmart(boolean useSmart) {		this.useSmart = useSmart;	}	@Override	protected TokenStreamComponents createComponents(String fieldName) {		IKTokenizer4Lucene7 tk = new IKTokenizer4Lucene7(this.useSmart);		return new TokenStreamComponents(tk);	}}</code></pre><pre><code>import java.io.IOException;import org.apache.lucene.analysis.Tokenizer;import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;import org.apache.lucene.analysis.tokenattributes.TypeAttribute;import org.wltea.analyzer.core.IKSegmenter;import org.wltea.analyzer.core.Lexeme;public class IKTokenizer4Lucene7 extends Tokenizer {	// IK分詞器實現	private IKSegmenter _IKImplement;	// 詞元文本屬性	private final CharTermAttribute termAtt;	// 詞元位移屬性	private final OffsetAttribute offsetAtt;	// 詞元分類屬性（該屬性分類參考org.wltea.analyzer.core.Lexeme中的分類常量）	private final TypeAttribute typeAtt;	// 記錄最後一個詞元的結束位置	private int endPosition;	/**	 * @param in	 * @param useSmart	 */	public IKTokenizer4Lucene7(boolean useSmart) {		super();		offsetAtt = addAttribute(OffsetAttribute.class);		termAtt = addAttribute(CharTermAttribute.class);		typeAtt = addAttribute(TypeAttribute.class);		_IKImplement = new IKSegmenter(input, useSmart);	}	/*	 * (non-Javadoc)	 * 	 * @see org.apache.lucene.analysis.TokenStream#incrementToken()	 */	@Override	public boolean incrementToken() throws IOException {		// 清除所有的詞元屬性		clearAttributes();		Lexeme nextLexeme = _IKImplement.next();		if (nextLexeme != null) {			// 將Lexeme轉成Attributes			// 設置詞元文本			termAtt.append(nextLexeme.getLexemeText());			// 設置詞元長度			termAtt.setLength(nextLexeme.getLength());			// 設置詞元位移			offsetAtt.setOffset(nextLexeme.getBeginPosition(),					nextLexeme.getEndPosition());			// 記錄分詞的最後位置			endPosition = nextLexeme.getEndPosition();			// 記錄詞元分類			typeAtt.setType(nextLexeme.getLexemeTypeString());			// 返會true告知還有下個詞元			return true;		}		// 返會false告知詞元輸出完畢		return false;	}	/*	 * (non-Javadoc)	 * 	 * @see org.apache.lucene.analysis.Tokenizer#reset(java.io.Reader)	 */	@Override	public void reset() throws IOException {		super.reset();		_IKImplement.reset(input);	}	@Override	public final void end() {		// set final offset		int finalOffset = correctOffset(this.endPosition);		offsetAtt.setOffset(finalOffset, finalOffset);	}}</code></pre><p>Ik中默認的停用詞很少，我們往往需要擴展它。可從網址： https://github.com/cseryp/stopwords 下載一份比較全的停用詞。</p><p>Ik中停用詞的擴展步驟：</p><p>1、在類目錄下創建IK的配置文件：IKAnalyzer.cfg.xml</p><p>2、在配置文件中增加配置擴展停用詞文件的節點：</p><p>&lt;entry key=“ext_stopwords”>my_ext_stopword.dic&lt;/entry></p><p>如有多個，以“;”間隔</p><p>3、在類目錄下創建我們的擴展停用詞文件 my_ext_stopword.dic</p><p>4、編輯該文件加入停用詞，一行一個</p><p>擴展 IKAnalyzer的詞典：</p><p>每年都有很多的新詞產生，往分詞器的詞典中添加新詞的步驟：</p><p>1、在類目錄下IK的配置文件：IKAnalyzer.cfg.xml 中增加配置擴展詞文件的節點：</p><p>&lt;entry key="ext_dict">ext.dic&lt;/entry></p><p>如有多個，以“;”間隔</p><p>2、在類目錄下創建擴展詞文件 ext.dic</p><p>4、編輯該文件加入新詞，一行一個</p><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;  &lt;properties&gt;  	&lt;comment&gt;IK Analyzer 擴展配置&lt;/comment&gt;	&lt;!--用戶可以在這裡配置自己的擴展字典 --&gt;	&lt;entry key="ext_dict"&gt;ext.dic&lt;/entry&gt; 		&lt;!--用戶可以在這裡配置自己的擴展停止詞字典--&gt;	&lt;entry key="ext_stopwords"&gt;my_ext_stopword.dic&lt;/entry&gt;&lt;/properties&gt;</code></pre><p><strong>ext_dict：</strong>字典，新詞：比如奧利給</p><p><strong>ext_stopwords</strong>：停用詞：的，地，這</p><p>測試代碼：</p><pre><code>public class IkAnalyzerTestDemo {   private static void doToken(TokenStream ts) throws IOException {      ts.reset();      CharTermAttribute cta = ts.getAttribute(CharTermAttribute.class);      while (ts.incrementToken()) {         System.out.print(cta.toString() + "|");      }      System.out.println();      ts.end();      ts.close();   }   public static void main(String[] args) throws IOException {      String etext = "Don't be afraid of any difficulty we encounter. Smile at it. " +            "The best way to eliminate fear is to face fear. Persistence is the victory. Come on, Ollie!";      String chineseText = "我們遇到什麼困難，也不要怕，微笑著面對它，消除恐懼的最好方法就是面對恐懼，堅持才是勝利，加油，奧利給！ ";      // IKAnalyzer 細粒度切分      try (Analyzer ik = new IKAnalyzer4Lucene7();) {         TokenStream ts = ik.tokenStream("content", etext);         System.out.println("IKAnalyzer中文分詞器 細粒度切分，英文分詞效果：");         doToken(ts);         ts = ik.tokenStream("content", chineseText);         System.out.println("IKAnalyzer中文分詞器 細粒度切分，中文分詞效果：");         doToken(ts);      }      // IKAnalyzer 智能切分      try (Analyzer ik = new IKAnalyzer4Lucene7(true);) {         TokenStream ts = ik.tokenStream("content", etext);         System.out.println("IKAnalyzer中文分詞器 智能切分，英文分詞效果：");         doToken(ts);         ts = ik.tokenStream("content", chineseText);         System.out.println("IKAnalyzer中文分詞器 智能切分，中文分詞效果：");         doToken(ts);      }   }}</code></pre><div class=pgc-img><img alt="Lucene集成IK Analyzer中文分詞器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bb5b16ad480f4e5f817c222f9699112b><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Lucene</a></li><li><a>IK</a></li><li><a>Analyzer</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/e3c80a1.html alt=Lucene（全文檢索）進階-第二篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/37d9000385d3ea9c9c67 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e3c80a1.html title=Lucene（全文檢索）進階-第二篇>Lucene（全文檢索）進階-第二篇</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>