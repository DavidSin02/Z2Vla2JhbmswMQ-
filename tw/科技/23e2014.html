<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析 | 极客快訊</title><meta property="og:title" content="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/6f70b8b7cd0f4dad93aced78cc14ffcf"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/23e2014.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/23e2014.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/23e2014.html><meta property="article:published_time" content="2020-10-29T20:58:14+08:00"><meta property="article:modified_time" content="2020-10-29T20:58:14+08:00"><meta name=Keywords content><meta name=description content="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/23e2014.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1 class=ql-align-center><strong>簡介</strong></h1><hr><p class=ql-align-justify><strong><em>MachineLearning Yearning</em></strong>Sharing 是北京科技大學“機器學習研討小組”旗下的文獻翻譯項目，其原文由Deep Learning.ai 公司的吳恩達博士進行撰寫。本部分文獻翻譯工作旨在研討小組內部交流，內容原創為吳恩達博士，學習小組成員只對文獻內容進行翻譯，對於翻譯有誤的部分，歡迎大家提出。歡迎大家一起努力學習、提高，共同進步！</p><blockquote><strong>【關注微信公眾號：《人工智能前沿講習班》，回覆“MLY”，獲取完整版PDF電子書】</strong></blockquote><h1 class=ql-align-center><strong>致謝</strong></h1><hr><p class=ql-align-justify>Deep Learning.ai公司</p><p class=ql-align-justify>吳恩達（原文撰稿人）</p><p class=ql-align-justify>陸順（1-5章）</p><p class=ql-align-justify>樑爽（6-10章）</p><p class=ql-align-justify>鄭燁（11-15章）</p><p class=ql-align-justify>吳晨瑤（16-20章）</p><p class=ql-align-justify>玉巖（21-25章）</p><p class=ql-align-justify>陳波昊（25-30章）</p><p class=ql-align-justify>翟昊（31-35章）</p><p class=ql-align-justify>高宏宇（36-40章）</p><p class=ql-align-justify>丁韓旭（41-45章）</p><p class=ql-align-justify>李湯睿（46-50章）</p><p class=ql-align-justify>馬聰 （整體彙總）</p><p class=ql-align-justify>北京科技大學“機器學習研討小組”</p><p class=ql-align-justify>人工智能前沿學生論壇（FrontierForum of Artificial Intelligence）</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6f70b8b7cd0f4dad93aced78cc14ffcf><p class=pgc-img-caption></p></div><h1 class=ql-align-center><strong>13、快速的建立你的初始系統並不斷迭代</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：鄭燁</p><p class=ql-align-justify>你想要完成一個新的垃圾短信過濾系統，你的團隊提出了以下想法：</p><p class=ql-align-justify>收集大量的垃圾郵件作為建立訓練數據。例如，故意將一些郵件地址暴露給已知的垃圾郵件發送源，以便自動獲取它們發來的大量垃圾郵件。</p><p class=ql-align-justify>選擇好的特徵用於識別郵件內容。</p><p class=ql-align-justify>選擇特徵用於識別垃圾郵件的標題，來源等等</p><p class=ql-align-justify>即使我之前在這個問題上有著豐富的經驗，我還是很難選擇應該選擇哪個想法，這對於小白來說當然更加使他們迷茫。</p><p class=ql-align-justify>所以不要想著一開始就設計一個完美的系統，而是快速的建立一個基礎的系統，然後你將迅速找到你進一步改進的方向。</p><h1 class=ql-align-justify><strong>14、錯誤分析：回頭看看你的驗證集</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：鄭燁</p><p class=ql-align-justify>當你使用你開發的貓咪分類app時，你發現一些狗狗被誤分類為了貓咪，尤其是當那些狗長得和貓很像的時候！也就是說把狗誤分類為貓是影響系統精度的一部分。</p><p class=ql-align-justify>此時團隊中有成員提議將現有模型和別的第三方的狗的分類器進行結合來解決這種情況，但是整個調整可能需要一個月的時間，那你應該讓他們這麼做嗎？</p><p class=ql-align-justify>在花費一個月時間之前，我建議你評估一下這麼做會給系統帶來多少準確率的提升，也就是評估一下對於狗的誤分類情況到底多大程度的影響了性能。這樣你可以更加合理的分配時間和設定努力的方向。</p><p class=ql-align-justify>具體而言，你可以：</p><p class=ql-align-justify>1、從驗證集中得到100個當前系統分類錯誤的樣本</p><p class=ql-align-justify>2、人工的檢查這些樣本，看一下有多少錯誤分類是將狗分類成了貓</p><p class=ql-align-justify>這個過程就叫做錯誤分析。如果你發現只有5%的誤分類樣本是狗，那麼無論你怎麼提升你的算法在狗這一類樣本上的性能，你也最多隻能避免這5%的錯誤。換句話說，你這麼做最多隻有5%的性能收益。因此，假設你的系統目前分類正確率為90%，那麼這個提升只能最多把準確率提高到90.5%，但你卻會為此付出一個月的寶貴時間。</p><p class=ql-align-justify>反之，如果你發現有50%的誤分類都是來源於狗的樣本，那麼你就可以非常有把握的改進這一點來大大提升系統準確率。這將能夠使得準確率最多從90%提升到95%。</p><p class=ql-align-justify>誤差分析可以幫助你分析出哪個改進方向能夠帶來更多的性能提升。我見過很多工程師不願意做誤差分析，他們總是寧願埋頭鑽進一個問題中努力解決它，而不是先評估一下是否值得花時間這麼做，這恰好是一個很常見的錯誤。這會導致你的團隊努力了很久卻發現只帶來了一點點的提升。</p><p class=ql-align-justify>手動的檢查100張圖片並花費不了你太長時間，卻能大大節省你寶貴的研發時間。</p><p class=ql-align-justify>錯誤分析指的是查看你的算法在驗證集上犯錯誤的具體情況，從而把握錯誤的原因。它可以幫助你以及啟發你分析項目下一步的努力方向。</p><h1><strong>15、進行錯誤分析時並行的評估你的不同想法</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：鄭燁</p><p class=ql-align-justify>你的團隊會有很多改進貓咪分類檢測系統的想法：</p><p class=ql-align-justify>解決把狗誤分類為貓的問題；</p><p class=ql-align-justify>解決把一些大型貓科動物（如獅子、老虎）分類為貓咪的問題；</p><p class=ql-align-justify>提升在識別模糊圖像時的性能等等</p><p class=ql-align-justify>你可以有效的並行分析這些想法。我通常會建立一個表格，通過進行對100個驗證集樣本進行錯誤分析時填寫它。我還記下了關於一些具體樣本的備註。為了說明這個過程，讓我們看一下你用從一個小的驗證集獲取的四個樣本生成的表格：</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d0c39f064cd84de9b9834eca7cfdfd91><p class=pgc-img-caption></p></div><p class=ql-align-justify>例如圖片3即是將大貓分為了貓，也是屬於模糊圖片。</p><p class=ql-align-justify>當然你在設定好這個表格後進行人工查看樣本的過程中也會發現一些新的錯誤類型，例如你會發現很多錯誤是各種照片app自帶的濾鏡導致的，那麼你就可以在表格中新增加一個引起錯誤的類別。這同時也在啟發你尋找下一步改進的方向。</p><p class=ql-align-justify>這樣做的好一個不斷迭代的過程，開始的時候不必要擔心你想的初始錯誤類別不夠全面，只需要在檢查的過程中不斷完善即可。</p><p class=ql-align-justify>假設你在100個驗證集樣本上進行了錯誤分析，結果如下：</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/28bfbcd111b94e899c0cfca619b48fb9><p class=pgc-img-caption></p></div><p class=ql-align-justify>你現在會清晰的認識到解決狗的誤分類問題最多隻能提升8%的準確率。而解決大貓誤分類和圖像模糊問題可以大大提升性能。因此，你應該優先集中精力與解決後兩種類別的錯誤。如果你的團隊有足夠的人手，那麼你可以並行的解決它們。</p><p class=ql-align-justify>錯誤分析不存在數學上的理論證明告訴你哪個是優先級最高的任務，你必須結合自身的期望進度來調整具體的工作方向。</p><h1 class=ql-align-center><strong>16、清理誤標記的驗證集和測試集樣本</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：吳晨瑤</p><p class=ql-align-justify>在錯誤分析中，你可能注意到你的驗證集中有一些樣本是被錯誤標記的。我這裡指的“誤標記”是指這些圖片在算法處理之前就已經被貼標人員錯誤標記了。即，樣本(x,y)的類標籤有一個不正確的值y。舉個例子，可能有些圖片不是貓卻被錯誤標記成了含有貓，反之亦然。如果你懷疑錯誤標記的這一部分圖像很重要，就加一個類別去跟蹤這部分被誤標記的樣本：</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f416f36e062a49818093965eb07113bf><p class=pgc-img-caption></p></div><p class=ql-align-justify>你應該在你的驗證集中糾正這些標記嗎？別忘了驗證集的作用是要幫助你快速評價你的算法，這樣你就可以知道算法A和B哪個更好。如果驗證集誤標記的這一部分阻礙了你做出判斷的能力，那麼花時間去改正這些驗證集中被誤標記的標籤就是值得的。</p><p class=ql-align-justify>舉個例子，假設你的分類器的性能是：</p><ul><li class=ql-align-justify>驗證集的總體精度…………………………………………….90%(10%總誤差)</li><li class=ql-align-justify>誤標記樣本造成的誤差…………………………………….0.6%(6%的驗證集誤差)</li><li class=ql-align-justify>其他因素造成的誤差………………………………………..9.4%(94%的驗證集誤差)</li></ul><p class=ql-align-justify>這裡，誤標記造成的0.6%的誤差可能與你可以改進的9.4%的誤差相比不值一提。雖然手動改正驗證集中的誤標記圖像沒有壞處，但是這樣不會起到關鍵性的作用：不知道你的系統總誤差是10%還是9.4%沒什麼不好的。</p><p class=ql-align-justify>假設你繼續改進你的貓分類器，然後達到了下述性能：</p><ul><li class=ql-align-justify>驗證集的總體精度…………………………………..……….98%(2.0%總誤差)</li><li class=ql-align-justify>誤標記樣本造成的誤差…………………………………….0.6%(30%的驗證集誤差)</li><li class=ql-align-justify>其他因素造成的誤差………………………………………..1.4%(70%的驗證集誤差)</li></ul><p class=ql-align-justify>30%的誤差歸因於誤標記的驗證集圖像，這給你的準確性估計附加了顯著誤差。現在提升驗證集標籤的質量就變得值得了。處理誤標記的樣本有助於判斷分類器的誤差是更接近1.4%還是2% —— 一個顯著的相對差異。</p><p class=ql-align-justify>開始容忍一些誤標記的驗證集/測試集很常見。只是在你的系統有所改進之後你會改變主意，因為系統的改進使得誤標記樣本部分造成的錯誤率相對於總誤差集來說有所增長。</p><p class=ql-align-justify>最後一章解釋瞭如何通過改進算法去改進錯誤類別，比如狗、大貓和模糊。在本章中你已經瞭解到你也可以使用誤標記的類別—— 通過改進數據的標籤。</p><p class=ql-align-justify>無論你採用哪種流程去改正驗證集的標籤，記住也要在測試集中採用同一流程，這樣你的驗證集和測試集才可以繼續從同一分佈中提取。將驗證集和測試集一起改正可以避免我們在第六章中討論過的問題。當你的團隊優化驗證集性能時，卻只能發現他們一直在判斷一個基於不同數據集的不同標準。</p><p class=ql-align-justify>如果你決定提升標籤質量，要複核你的系統誤分類和正確分類兩個部分的樣本標籤。原始標籤和你的學習算法在一個樣本上同時出現錯誤也是有可能的。如果你只是改正了你的系統誤分類的樣本標籤，你可能會把偏差引到你的評價中。如果你有1000個驗證集樣本，而且你的分類器有98%的精確性，檢查20個誤分類的樣本要比檢查980個正確分類的樣本要容易。因為在實踐中僅僅核實誤分類的樣本要更加容易，偏差確實會蔓延到一些驗證集。如果你只對開發一個產品或應用感興趣這個偏差是可以被接受的。但是如果你是計劃在學術論文中使用這個結果或者需要測試集精度的完全無偏度量，這就會是一個問題。</p><h1 class=ql-align-center><strong>17、如果你有一個大驗證集，分割成兩個子集，只有一個是你查看的</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：吳晨瑤</p><p class=ql-align-justify>假設你有一個含5000個樣本且錯誤率為20%的大驗證集。因此，你的算法在誤分類1000個左右的驗證圖像。因為手動檢查1000個圖像要花費很長的時間，所以我們可能會決定不要在錯誤分析中將他們全部用上。</p><p class=ql-align-justify>在這種情況下，我會明確地將驗證集分割成兩個子集，其中一個是你查看的，而另一個不是。你會迅速的過擬合你手動查看的部分。你可以使用非手動查看的這一部分去調整參數。</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/159c406ce1f447149281f065b389c445><p class=pgc-img-caption></p></div><p class=ql-align-justify>讓我們繼續上面我們的算法在誤分類5000個驗證集樣本中的1000個的這個例子。假設在錯誤分析中我們想手動驗證大概100個錯誤(錯誤的10%)。你應該隨機選擇驗證集中的10%然後把它們放置在我們叫做<strong>眼球驗證集</strong>的這個地方以提醒自己我們正在用我們的眼睛查看它們。(在一個語音識別的項目中，你會聽音頻剪輯。這種情況作為替代你可能會管這個集合叫耳朵驗證集。)這個眼球驗證集就這樣有了500個樣本，而且我們期待我們的算法會誤分類100個。</p><p class=ql-align-justify>第二個驗證集的子集我們稱為<strong>黑箱驗證集</strong>，它會含有剩下的4500個樣本。你可以使用黑箱驗證集，通過衡量他們的錯誤率來自動評價分類器。你也可以用它來選擇算法或者調整超參數。然而，你應該避免用你的眼睛查看它們。我們用“黑箱”這個術語是因為我們只是要用這個子集的數據來得到分類器的“黑箱”評價。</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b41b739248064455acda75c43c6229ca><p class=pgc-img-caption></p></div><p class=ql-align-justify>為什麼我們要明確地將驗證集分成眼球和黑箱驗證集呢？由於你將獲得關於眼球驗證集中樣本的直覺，你將開始更快地過擬閤眼球驗證集。如果你發現眼球驗證集的性能比黑箱驗證集的性能要提升的更加迅速，那麼你已經過擬閤眼球驗證集了。這種情況下，你可能需要丟棄它然後找到一個新的眼球驗證集。這將通過把黑箱驗證集的樣本轉移到眼球驗證集中或者獲得新的被標記的數據來得到。</p><p class=ql-align-justify>明確地將你的驗證集分成眼球和黑箱驗證集會讓你發現，你手動分析錯誤的過程是什麼時候導致你數據中眼球的部分過擬合的。</p><h1><strong>18、眼球和黑箱驗證集應該要多大？</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：吳晨瑤</p><p class=ql-align-justify>你的眼球驗證集需要足夠大才能給你一個對算法主要錯誤類別的感受。如果你在進行的是一個人類做的更好的工作(比如在圖片中識別貓)，這裡是一些粗略準則：</p><ul><li class=ql-align-justify>當你的分類器產生了10個錯誤時，眼球驗證集會被認為非常小。只有10個錯誤會讓正確評估不同錯誤分類的影響變得十分困難。但是如果你只有非常少的樣本而且不足以支持你將更多樣本放入眼球驗證集中的這種情況，這樣總比沒有好並且這會在項目優化中有所幫助。</li><li class=ql-align-justify>如果你的分類器在眼球驗證樣本中得到了20個左右的錯誤，你可以得到一個對主要誤差來源的粗略感受。</li><li class=ql-align-justify>有大約50個樣本的話，你會得到一個對主要誤差來源的不錯的感受。</li><li class=ql-align-justify>有大約100個樣本的話，你會得到一個非常不錯的對主要誤差來源的感受。我曾見過有人甚至手動分析更多的錯誤——有時會有500個這麼多。只要你有足夠的數據，這樣並沒有什麼壞處。</li></ul><p class=ql-align-justify>如果你的分類器有5%的錯誤率。為確保你在眼球驗證集中有100個左右的誤標記樣本，眼球驗證集得有大約2000個樣本(因為0.05*2000 = 100)。你的分類器錯誤率越小，你的眼球驗證集就需要越大，以得到足夠大的錯誤集來分析。</p><p class=ql-align-justify>如果你在進行一個人類甚至都做不好的任務時，檢測眼球驗證集的訓練就不會有什麼幫助。因為我們很難理解為什麼這個算法不能正確的將某個樣本進行分類。這種情況下，你可以省略眼球驗證集。我們將在之後的章節中來討論這種問題的指導原則。</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b41b739248064455acda75c43c6229ca><p class=pgc-img-caption></p></div><p class=ql-align-justify>那黑箱驗證集又如何呢？我們之前說1000-10000個左右的驗證集很常見。換個更好的說法，儘管擁有更多的數據沒有什麼害處，一個擁有1000-10000個樣本的黑箱驗證集經常會提供足夠的數據來調整超參數和選擇模型。一個擁有100個樣本的黑箱驗證集會很小但是依然有用。</p><p class=ql-align-justify>如果你有一個小的驗證集，那麼你可能沒有足夠的數據來將驗證集分成兩個大到足夠服務於各自目的的眼球驗證集和黑箱驗證集。相反，你的整個驗證集可能會被用作眼球驗證集—— 即，你要手動檢測所有的驗證集數據。</p><p class=ql-align-justify>在眼球驗證集和黑箱驗證集中，我認為眼球驗證集更加重要(假定你正在解決的問題人類可以很好地處理而且檢測樣本會幫助你獲得直覺)。如果你只有一個眼球驗證集，你可以把誤差分析，模型選擇和超參數的調整都用這個集合來進行。只有一個眼球驗證集的缺點是過擬合驗證集的風險會更大。</p><p class=ql-align-justify>如果你可以獲得足夠的數據，眼球驗證集的尺寸將主要取決於你有時間手動分析多少個樣本。比如說，我幾乎沒有見過任何人手動分析了1000個以上的錯誤。</p><h1 class=ql-align-center><strong>19、重要結論：基本錯誤分析</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：吳晨瑤</p><ul><li class=ql-align-justify>如果你開始了一個新的項目，尤其是如果你在這個領域中還不是專家，很難正確猜測最有前途的方向。</li><li class=ql-align-justify>所以不要從設計和打造一個完美的系統開始。而是儘可能快地建造和訓練一個基本的系統—— 可能就在幾天之內。然後用錯誤分析來幫助你找到最有潛力的方向而且從這裡開始迭代改進你的算法。</li><li class=ql-align-justify>通過人工檢查約100個驗證集樣本進行誤差分析，該算法對主要類別錯誤進行分析和計數。使用這些信息來劃分致力於不同類型錯誤修復的優先順序。</li><li class=ql-align-justify>考慮將驗證集分成一個你將手動檢測的眼球驗證集和一個你將不會手動檢測的黑箱驗證集。如果眼球驗證集展現出的性能優於黑箱驗證集，那麼你已經過擬閤眼球驗證集了，你應該考慮為它增添更多的數據。</li><li class=ql-align-justify>眼球驗證集需要足夠大以保證你的算法可以有足夠多錯誤分類的樣本來給你分析。一個擁有1000-10000個樣本的黑箱驗證集對很多應用來說都會是充足的。</li><li class=ql-align-justify>如果你的驗證集按這種方式分割不夠大的話，就用一個眼球驗證集來手動進行錯誤分析、模型選擇以及超參數調整。</li></ul><h1 class=ql-align-center><strong>20、偏差和方差：兩大錯誤來源</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：吳晨瑤</p><p class=ql-align-justify>假設你的訓練、驗證和測試集全部來自同一分佈。那麼你應該總是要嘗試得到更多的訓練數據，因為只有這樣才可以提高性能，對嗎？</p><p class=ql-align-justify>雖然擁有更多的數據沒什麼壞處，但不幸的是它不會總是像你期望的那麼有用。得到更多數據的工作可能是在浪費時間。所以，你如何決定什麼時候去增加數據，什麼時候不用這麼麻煩呢？</p><p class=ql-align-justify>機器學習有兩大主要錯誤來源：偏差和方差。理解它們會幫助你判斷增加數據或採用其他策略來提升性能是否在很好地利用時間。</p><p class=ql-align-justify>假設你希望建一個有5%錯誤率的貓分類器。此時，你的訓練集有15%的錯誤率，你的驗證集有16%的錯誤率。這種情況，增加訓練數據可能不會有太大幫助。你需要把注意力放在其他改變上。實際上，往你的訓練集中增加更多樣本只會讓你的算法更難在訓練集上有很好的效果。(在之後的章節中我們會解釋原因)</p><p class=ql-align-justify>如果你的訓練集錯誤率為15%(或者說85%的正確率)，但是你的目標是5%的錯誤率(95%的正確率)，那麼首先要解決的問題是提升你的算法在訓練集上的性能。你的驗證/測試集的性能通常比訓練集的性能要差。所以如果你的算法對見過的樣本準確率為85%，就絕不可能對沒見過的樣本得到95%的準確率。</p><p class=ql-align-justify>假設和上面一樣你的算法在驗證集上有16%的錯誤率(84%準確率)。我們把16%的錯誤分成兩個部分：</p><p class=ql-align-justify>算法在訓練集上的錯誤率。在這個例子中是15%。我們非正式地將之看作算法的<strong>偏差</strong>。</p><ul><li class=ql-align-justify>這個算法在驗證集 (或測試集)上的表現比在訓練集上的要差多少。在這個例子中，驗證集上的表現比訓練集要差1%。我們非正式地將之看作算法的方差<sup>1</sup>。</li><li class=ql-align-justify>對學習算法的一些改變可以解決誤差的第一個組成部分– 偏差 – 並提高其在訓練集上的性能。一些算法的改變可以解決第二個組成部分– 方差 – 並幫助其更好地從訓練集泛化到驗證/測試集<sup>2</sup>。為選擇更有潛力的改變，理解這兩個錯誤成分中哪一個更緊迫更需要被解決是非常有用的。</li></ul><p class=ql-align-justify>培養關於偏差和方差的良好直覺可以幫助你選擇對你的算法更有效的變化。</p><p class=ql-align-justify>1、統計學領域對偏差和方差有更正式的定義，這是我們無需擔心的。大致上，偏差是當你有一個很大的訓練集時你的算法的錯誤率。方差是在這個背景下，測試集相比訓練集的表現要差多少。當你的誤差度量是均方誤差時，你可以寫出指定這兩個量的公式，並證明總誤差＝偏差+方差。但是對我們來說目的是決定如何對一個機器學習問題作出改進，在這裡給出的對偏差和方差不太正式的定義已經足夠了。</p><p class=ql-align-justify>2、也有一些方法通過對系統結構作出巨大改變，可以同時減少偏差和方差。但是這些往往難以識別和實施。</p><h1 class=ql-align-center><strong>21、偏差和方差示例</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：玉巖</p><p class=ql-align-justify>考慮我們為貓分類的任務，一個“理想的”分類器（就像人類）有可能在這項任務中表現得非常出色。</p><p class=ql-align-justify>假設你的運算程序按照下面的設定運行：</p><ul><li class=ql-align-justify>訓練誤差=1%</li><li class=ql-align-justify>開發集誤差=11%</li></ul><p class=ql-align-justify>它存在什麼問題呢？採用前面章節的定義，我們估計偏差率為1%，方差為10%（=11%-1%）。因此，它具有<strong>高方差</strong>。雖然這個分類器具有很低的訓練誤差，但是它不能推廣到設備端。這也叫做<strong>過擬合</strong>。</p><p class=ql-align-justify>現在，考慮下面這種情況：</p><ul><li class=ql-align-justify>訓練誤差=15%</li><li class=ql-align-justify>設備誤差=16%</li></ul><p class=ql-align-justify>我們估計偏差率在15%，方差為1%。這個分類器擬合訓練端的效果不好，會產生15%的誤差，但是它在設備端的誤差僅僅比訓練誤差高了一點點。這個分類器因此具有<strong>高偏差</strong>，但是低方差。我們稱這種運算程序為<strong>欠擬合</strong>。</p><p class=ql-align-justify>現在，考慮這種：</p><ul><li class=ql-align-justify>訓練誤差=15%</li><li class=ql-align-justify>設備誤差=30%</li></ul><p class=ql-align-justify>我們估計偏差率在15%，方差為15%。這個分類器具有<strong>高偏差和高方差</strong>：它在訓練端表現不佳，因此具有高的偏差率，而它在設備端的表現甚至更差，因此它也具有高的方差。由於這種分類器同時具備過擬合和欠擬合的特點，所以過擬合/欠擬合術語很難用在它身上。</p><p class=ql-align-justify>最後，看看這個：</p><ul><li class=ql-align-justify>訓練誤差=0.5%</li><li class=ql-align-justify>設備誤差=1%</li></ul><p class=ql-align-justify>這個分類器表現不錯，因為它具有低偏差和低方差。達到了這麼出色的表現真是可喜可賀！</p><h1 class=ql-align-center><strong>22、與最佳誤差率對比</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：玉巖</p><p class=ql-align-justify>在我們對貓進行識別的例子中，“理想的”誤差率——就是說，一個可以通過“最佳”分類器實現的誤差率——幾乎為0。一個看著圖片的人幾乎任何時候都能夠識別出圖片裡是否有一隻貓；因此，我們有理由希望機器也能做得這樣出色。</p><p class=ql-align-justify>其他的問題更加困難。比方說，假設你正在建立一個語言識別系統，發現14%的聲音文件有許多背景噪聲或者太難以理解以至於甚至一個人都無法識別講了些什麼。這種情況下，甚至“最佳”語言識別系統都可能有14%的誤差。</p><p class=ql-align-justify>假設在這個語言識別問題上，你的運算程序達到了：</p><ul><li class=ql-align-justify>訓練誤差=15%</li><li class=ql-align-justify>開發集誤差=30%</li></ul><p class=ql-align-justify>訓練端的表現已經和最佳誤差率14%非常接近了。因此，偏差率或者訓練端的表現方面並沒有很大的提升空間。但是，這個算法不能推廣到設備端；因此對因為方差而產生的誤差的進步空間還很大。</p><p class=ql-align-justify>這個例子與前面章節提到的第三個例子很相似，在那個例子中訓練誤差也是15%而且設備誤差也是30%。如果最佳誤差率是~0%，那麼一個15%的訓練誤差會給提升留出很大的空間。這也暗示我們使偏差率減小的變化可能會富有成效。但是如果最佳誤差率是14%，那麼相同的訓練端表現告訴我們，分類器偏差率的提升空間很小。</p><p class=ql-align-justify>對於最佳誤差率和0相差很多的問題，這裡有一個對算法誤差更加細化的分解。繼續我們上面講到的識別案例，總設備端誤差30%可以被分解為下面這些（相似的分析也可以用於測試設備誤差）：</p><ul><li class=ql-align-justify>最佳誤差率（“無法避免的偏差”）：14%。假設我們認定，即使以或許世界上最好的語言識別系統，我們仍然會得到14%的誤差。我們可以認為這是“不可避免的”一部分學習算法偏差。</li><li class=ql-align-justify>可避免偏差：1%。這被算作訓練誤差和最佳誤差率之間的差別。</li><li class=ql-align-justify>方差：15%。設備誤差和訓練誤差的差別。</li></ul><p class=ql-align-justify>把它和我們之前的定義聯繫起來，偏差率和可避免偏差有下面的關係：</p><p class=ql-align-justify>偏差率=最佳誤差率（“不可避免偏差”）+可避免偏差</p><p class=ql-align-justify>“可避免偏差”反映了你的算法在訓練端的表現比“最佳分類器”差了多少。</p><p class=ql-align-justify>方差的概念和之前的保持一致。理論上，我們總可以將方差減少到0通過大量的訓練端的訓練。因此，有足夠多的數據，所有的方差都是“可避免的”，所以像“不可避免方差”這種東西是不存在的。</p><p class=ql-align-justify>再看一個例子，最佳誤差率是14%，此外我們有：</p><ul><li class=ql-align-justify>訓練誤差=15%</li><li class=ql-align-justify>設備誤差=16%</li></ul><p class=ql-align-justify>然而在前面的章節中，我們稱它為高偏差率分類器，現在我們會說來自可避免偏差的誤差為1%，來自方差的誤差為1%。所以，這個算法已經做得不錯了，可提升空間不大了。僅僅比最佳誤差率多了2%。</p><p class=ql-align-justify>我們從這些例子中看到，知道最佳誤差率對於引導我們下面的步驟很有幫助。在統計學中，最佳誤差率也叫做<strong>貝葉斯誤差率</strong>，或者貝葉斯率。</p><p class=ql-align-justify>我們怎麼知道最佳誤差率是多少呢？對於人類能夠做得很好的任務，比如識別圖片或者採集聲音片段，你可以要求一個人提供分類結果，然後相比訓練端檢測人類分類的準確性。這能夠提供一個最佳誤差率的估計值。如果你正在研究一個即使人類都難以解決的任務（例如，預測哪部電影將被推薦，或者哪條廣告將被展示給用戶），最佳誤差率很難被估計出來。</p><p class=ql-align-justify>在“與人類水平的表現對比”的部分（33章到35章），我將會更加細緻地討論對比一個學習算法的表現和人類水平的表現的過程。</p><p class=ql-align-justify>在前面幾章，你學到了如何通過觀測訓練端和設備端的錯誤率估計可避免/不可避免偏差，以及方差。下一章將會討論你能夠如何在這種分析中使用你的洞察力來決定減少偏差和減少方差技術的優先次序。根據你的項目當前的問題是高（可避免的）偏差還是高的方差，你應當採用的技術是有很大區別的。繼續讀下去吧！</p><h1 class=ql-align-center><strong>23、定位偏差和方差</strong></h1><hr class=ql-align-justify><p class=ql-align-right>分享人：玉巖</p><p class=ql-align-justify>在這裡，針對定位偏差方差的任務有一個最簡單的公式：</p><ul><li class=ql-align-justify>如果你有高可避免偏差，增加你的模型大小（例如，通過添加層數或神經元來增加你的神經網絡的大小）。</li><li class=ql-align-justify>如果你的方差高，添加數據到你的訓練端。</li></ul><p class=ql-align-justify>如果你能夠增加神經網絡大小並無限制增加訓練數據，算法很可能在很多學習問題上做得出色。</p><p class=ql-align-justify>在練習中，增加模型大小將最終導致你遇到計算問題，因為訓練大的模型速度慢。你可能要竭盡所能去獲得更多的訓練數據。（即使在網上，貓的圖片數量也是有限的）</p><p class=ql-align-justify>不同的模型結構——例如，不同的神經網絡結構——對於你的問題會有不同數量的偏差率/方差。許多最近的深度學習研究發展了許多革新的模型結構。因此，如果你正在使用神經網絡，學術文獻會是你靈感的重要來源。Github上面還有許多很棒的開源的實現。但是嘗試新結構的結果相比於簡單形式的增加模型大小和添加數據會更難預測。</p><p class=ql-align-justify>增加模型大小通常會減少偏差率，但是它還會增加方差以及過擬合的風險。但是，這個過擬合的問題通常只會在你沒有使用規範化的情況下出現。如果你的設計包含了良好的規範化方法，那麼你能夠安全的增加模型的尺寸而不會提高過擬合的風險。</p><p class=ql-align-justify>假設你正在應用深度學習，使用L2規範化或者中途退出，使用在設備端表現最好的規範化係數。如果你增加了模型大小，通常你的表現會不變或者提升；不會明顯的變糟糕。唯一可能阻止你使用更大的模型的原因就是增加計算花銷了。</p><h1>24、偏差率與方差的權衡</h1><hr><p class=ql-align-right>分享人：玉巖</p><p>你可能聽說過“偏差率與方差的權衡”。在你能夠在學習算法裡進行的調整中，有一些能夠減少偏差率誤差但是需要以增加方差作為代價，反過來也是。這就在偏差率和方差之間創造了一個“權衡”。</p><p>比如，增加模型的大小——增加神經元/層數在一個神經網絡中，或者添加輸入特徵——通常減少偏差率但是會增加方差。另一方面，增加規範化會增加偏差率但能減少方差。</p><p>在現代，我們經常能夠得到大量的數據，並且能夠使用非常大的神經網絡（深度學習）。因此，權衡就比較少了，現在有更多的選擇能夠減少偏差率而不會損失方差，反過來也是。</p><p>例如，你通常可以增加神經網絡的大小並調整規範化方法來減少偏差率而不會明顯地增加方差。通過添加訓練數據，你通常還能減少方差而不影響偏差率。</p><p>如果你為你的任務選擇了一個非常合適的模型結構，你有可能會同時減少片利率和方差。選擇這樣一個模型是非常難的。</p><p>在接下來幾章，我們討論定位偏差率和方差的其它詳細的技術。</p><h1>25、減少可避免偏差的技術</h1><hr><p class=ql-align-right>分享人：玉巖</p><p>如果你的學習算法被很高的可避免偏差所困擾，你可能要嘗試下面這些技術：</p><ul><li><strong>增加模型大小</strong>（例如神經元/層數量）：這項技術減少偏差率，因為它允許你更好的適應訓練端。如果你發現這會增加方差，那麼使用規範化方法吧，這通常會消除方差的增長。</li><li><strong>基於對錯誤分析的洞察調整輸入特徵</strong>：你的錯誤分析啟發你創造另外的特點，這些特點有助於算法消除特定種類錯誤。（我們會在之後的章節中討論這個。）這些新特點能夠同時幫助到偏差率和方差。理論上，添加更多的特徵可能會增加方差；但是如果你發現這造成了問題，那就使用規範化方法，它通常會消除掉方差的增長。</li><li><strong>減少或消除規範化方法</strong>（L2規範化，L1規範化，中途退出）：這將減少可避免偏差率，但是會增加方差。</li><li><strong>調整模型結構</strong>（例如神經網絡結構）目的是使其對於你的問題會更加合適：這項技術會同時影響偏差率和方差。</li></ul><p>一個不怎麼有幫助的方法：</p><ul><li><strong>添加更多的訓練數據</strong>：這項技術幫助解決方差問題，但它通常對偏差率沒有顯著影響。</li></ul><h1>26、在訓練集上的誤差分析</h1><hr><p class=ql-align-right>分享人：陳波昊</p><p>在驗證或測試集上出色地進行實際應用前，我們必須保證我們的算法在訓練集上有優異的表現。</p><p>除了前面描述的解決高偏置的技術之外，我有時也會在訓練數據上進行誤差分析。誤差分析過程遵循的規範同在眼球驗證集上進行的類似。當你的算法存在較高的偏差，或者說，算法並不適應訓練集時，這是非常有用的。</p><p>例如，假設你正在為某些應用建立一個演講識別系統，為此已經從志願者處收集了大量的音頻片段作為訓練集。如果你的系統在訓練集上工作得並不好，你或許會考慮聽一些你的系統工作較差的音頻片段，來理解導致訓練誤差的音頻中存在的問題，並進行分類。就像驗證集的誤差分析一樣，你可以以不同的類別統計這些錯誤。</p><div class=pgc-img><img alt="吳恩達《ML Yearning》｜基礎的誤差分析& 偏差、方差分析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/00c6fd979a8446e29e8eb31904bcc004><p class=pgc-img-caption></p></div><p>從這個例子中，你可能會發現算法尤其不擅長處理含有很多背景噪聲的數據實例。因此，我們應該更關注一些對含有背景噪聲的訓練實例有更好適應性的處理方法。</p><p>你也可以進行二次確認。將音頻片段轉錄，並將轉錄後相同內容的音頻輸入算法。如果經過這個過程後，背景噪聲強烈到無論哪個人類都不能明白音頻的內容，那麼可能識別這些音頻的任務對算法而言太過苛求了。我們將在稍後部分討論將算法和人類表現進行比較的好處所在。</p><h1>27、關於減少方差的技術</h1><hr><p>分享人：陳波昊</p><p>如果你的學習算法有較高的方差，或許你可以嘗試以下的方法：</p><ul><li><strong>添加更多的訓練數據</strong>：只要有足夠的算力和數據作為支撐，這個是最簡單也最可靠的解決方法。</li><li><strong>正則化</strong>（L2正則化，L1正則化，丟失）：這種技術能夠減少方差，但會增加偏差。</li><li><strong>添加早期停止</strong>（即：基於驗證集上的誤差，較早地停止梯度下降）：這種技術同樣會減少方差並增加偏差。早期停止方法的表現非常像正則化方法，有些作者稱其為正則化技術。</li><li><strong>選擇特徵來減少輸入特徵的數目或種類</strong>：這種技術可能有助於解決方差問題，但同樣會增加偏差。在稍稍減少特徵的輸入時（比如從1000個特徵減少到900個），這種技術對於減小方差的表現並不明顯。在明顯減少的情況下（比如從1000個減少到100個，十倍的差異），只要你沒有排除太多有用的特徵，就更有可能會產生顯著的影響。在現代深度學習過程中，由於數據足夠，這種技術逐漸不被採用。我們現在更傾向於給算法全部的特徵，並讓算法自己選擇出哪些特徵是有用的。但當我們的訓練數據集太小，不能支持大量的訓練時，選擇特徵這個方法就會非常有用。</li><li><strong>減小模型大小</strong>（如減小神經元個數或者網絡層數）：謹慎使用這個方法。這個技術可以減少方差，同時可能會增加偏差。但是，我不建議使用這個方法減小方差。添加正則化可以給出更好的分類性能。減小模型大小的優點在於減小計算成本，因此可以提高模型的訓練速度。如果提高訓練速度非常有效，那麼一定要考慮減小模型大小。但如果你的目標是減少方差，並且你也並不關心計算成本，則可以考慮引入正則化方法來替代該方法。</li></ul><p>以下附加兩條策略，是在前面的章節中討論偏差時提到的：</p><ul><li><strong>根據誤差分析後的結論修改輸入特徵</strong>：誤差分析可以促使你構造一些附加特徵，從而幫助算法解決特殊類別的誤差。這些新加入的特徵可以同時解決偏差和方差的問題。在理論上，添加特徵可能會增加方差；但當遇到這種情況下，使用正則化方法通常會消除方差的增加過程。</li><li><strong>修改模型的結構</strong>（如神經元網絡的結構）：這種方法更適合你的問題：它可以同時改善偏差和方差。</li></ul><blockquote><p><strong>【關注微信公眾號：《人工智能前沿講習班》，回覆“MLY”，獲取完整版PDF電子書】</strong></p></blockquote></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>吳恩達</a></li><li><a>ML</a></li><li><a>Yearning</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/059e7a6.html alt="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f6a60d9d13f84286a71f27b8edb150f1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/059e7a6.html title="吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比">吳恩達 ML Yearning 關於學習曲線的分析&與人類級別的表現對比</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f564827a.html alt="吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dfa0587764f14afb8ccfd7a33796cd74 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f564827a.html title="吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)">吳恩達深度學習筆記(108)-序列模型介紹(Sequence Models)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/efabb5bb.html alt=吳恩達深度學習筆記(106)-風格遷移網絡講解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/01def15aa8654252990f709965d5b769 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/efabb5bb.html title=吳恩達深度學習筆記(106)-風格遷移網絡講解>吳恩達深度學習筆記(106)-風格遷移網絡講解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3605c009.html alt="吳恩達深度學習筆記(67)-遷移學習（Transfer learning)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f00ccb946c7a451aa25adba4b28799e5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3605c009.html title="吳恩達深度學習筆記(67)-遷移學習（Transfer learning)">吳恩達深度學習筆記(67)-遷移學習（Transfer learning)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9819f021.html alt="吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d934f6fbf66144dca95cbb6ce8223d62 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9819f021.html title="吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）">吳恩達深度學習筆記(89)-遷移學習（Transfer Learning）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f60a5385.html alt=吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e2a9b89ccb4a4ad58614763e86e85e0a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f60a5385.html title=吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5)>吳恩達老師課程筆記系列第23節-Octave教程之for，while，if(5)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b64e226d.html alt=AI和ML在網絡安全中的用例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2ecb2e5d786743a688e69abfd136a5a0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b64e226d.html title=AI和ML在網絡安全中的用例>AI和ML在網絡安全中的用例</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/1ebabf70.html alt=ML基礎：協方差矩陣 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a8ebdba18ae5461a8e462d5fcce85ee4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/1ebabf70.html title=ML基礎：協方差矩陣>ML基礎：協方差矩陣</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/78490c4c.html alt=吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/08fb5feee25546a993820104d81c965a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/78490c4c.html title=吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2)>吳恩達老師課程筆記系列第十二節-線性代數之矩陣乘法，性質(2)</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/31a4d4f2.html alt="吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/c34f86938ddb484298ca8e0a20494ff2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/31a4d4f2.html title="吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)">吳恩達深度學習筆記(38)-優化算法(Optimization algorithms)</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/ebed9a9e.html alt=為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3c8b122558234a6fa193f00f54ae1b1f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/ebed9a9e.html title=為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法>為ML帶來拓撲學基礎，Nature子刊提出拓撲數據分析方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d9e4144e.html alt=吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/78ac000683f4faa986fc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d9e4144e.html title=吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野>吳恩達專訪LeCun：即便在神經網絡的寒冬，我也堅信它終會重回公眾視野</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/99e43ab.html alt=「ML」一文詳盡系列之CatBoost class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f2a5caed2d82451b8d9e0b0f1135f42f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/99e43ab.html title=「ML」一文詳盡系列之CatBoost>「ML」一文詳盡系列之CatBoost</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b3820d4.html alt=「ML」深入理解CatBoost class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f7e6e06fe4c243baa728efbdb3621da6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b3820d4.html title=「ML」深入理解CatBoost>「ML」深入理解CatBoost</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/72a9b3c.html alt=吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b64cd54d8477428589d89e078a3e37b4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72a9b3c.html title=吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹>吳恩達深度學習筆記(28)-網絡訓練驗證測試數據集的組成介紹</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>