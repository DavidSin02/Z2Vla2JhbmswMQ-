<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>NLP.TM「3」 | 句法分析綜述 | 极客快訊</title><meta property="og:title" content="NLP.TM「3」 | 句法分析綜述 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/10a5dea7ca4b4fbcbedca5e8a17700bd"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/2f4b2d5.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/2f4b2d5.html><meta property="article:published_time" content="2020-10-29T21:05:58+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:58+08:00"><meta name=Keywords content><meta name=description content="NLP.TM「3」 | 句法分析綜述"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/2f4b2d5.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>NLP.TM「3」 | 句法分析綜述</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p>大家好，我是叉燒，近期剛登陸頭條號，這是我在NLP.TM項目下的第三篇文章，主要講的是句法分析。目前我正在整理的是自己微信公眾號（CS的陋室）的文章，部分可能會比較稍微陳舊，但是並不影響大家對重要概念的理解~</p><p>微信公眾號：CS的陋室</p><p>知乎：機智的叉燒</p></blockquote><h1>1 什麼是句法分析</h1><p class=ql-align-justify>按照百度百科的解釋就是<strong>指對句子中的詞語語法功能進行分析</strong>，例如“我來晚了”中，“我”是主語，“來”是謂語，“晚了”就是補語。這塊內容其實在語言學等領域已經有比較深入的研究，但是隨著數據的逐漸增多，這種分析就需要利用計算機自動化，句法分析就是這樣誕生的。</p><p class=ql-align-justify>那麼句法分析到底有什麼用呢？句法分析的結果是一句話的句子成分分析，其實就可以用來做知識發現和挖掘，例如“張三是李四的兒子”，通過句法分析，能夠知道主謂賓等關係，能夠抽取具體的消息，例如這裡能夠獲取一個關係——張三和李四是父子關係，根據這些知識，無論是做知識圖譜，還是做問答機器人等，都有大的作用，可見，句法分析是知識抽取的重要基礎。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/10a5dea7ca4b4fbcbedca5e8a17700bd><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><h1>2 句法分析的評價指標</h1><p class=ql-align-justify>要深入研究句法分析，首先要知道，什麼樣的句法分析算是好的句法分析，所以句法分析方法的評價是首要思考的問題，目前進行句法分析，主要是用依存句法分析，其具體的評價指標有下面5種。</p><ul><li class=ql-align-justify><strong>無標記依存正確率(UAS)：</strong> 所有詞中找到正確的頭詞所佔的百分比，對於沒有頭詞的根節點，只要根節點是對的，也將這個根節點算作其中(Nivre et al., 2004)</li><li class=ql-align-justify><strong>根正確率(RA)：</strong> 所有句子中找到正確根的句子所佔的百分比(Yamada and Matsumoto, 2003)</li><li class=ql-align-justify><strong>完全匹配率(CM)：</strong> 所有句子中無標記依存結構完全正確的句子所佔的百分比(Yamada and Matsumoto, 2003)</li><li class=ql-align-justify><strong>帶標記依存正確率(LAS)：</strong> 所有詞中找到正確的頭詞並分配到正確標記的詞所佔的百分比，對於沒有頭詞的根節點，只要根節點是對的，也將這個根節點算作其中(Nivre et al., 2004)</li><li class=ql-align-justify><strong>標記正確率(LA)：</strong> 所有詞中依存標記正確的詞所佔的百分比，只要根節點是對的，也將這個根節點算作其中(Nivre et al., 2004)</li></ul><h1>3 對現行方法的簡單評價</h1><p class=ql-align-center>首先看看英文的，英文畢竟是目前自然語言處理的主力和焦點，而且英語具有相對嚴禁的語法結構。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5eef8f1339d5417588e43b87d0f61c90><p class=pgc-img-caption></p></div><p class=ql-align-justify>本身UAS的定義相比CM，就較弱，而且USA是無監督的方法，所以會比CM的正確率高很多。從CM看來，正確率不足50%，其實並不高，可見依存句法分析任重道遠。</p><p>然後看中文，中文的自然語言處理相對比較難，一方面是中文本身的語法特性，另一方面中文分詞的時候本就有誤差，再進行句法分析會產生誤差疊加。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b609571102c741b881003b9240578567><p class=pgc-img-caption></p></div><p class=ql-align-justify>可以明顯地看到，UAS和CM相比英文會更加低，說明中文的難度會比英文高，目前的潛力仍比較強。</p><p class=ql-align-justify>綜上所述，目前雖然已經有比較豐富的方法，但是準確度還有比較大的上升空間。</p><h1>4 句法分析的主要方法</h1><p class=ql-align-justify>糾結了很久，想了要怎麼寫，要是詳細些，這就不是公眾號，是書了，要是不詳細寫，又怕你們罵我，於是我想了一個比較中和的方案，那就是我弄綜述，參考文獻給你們，有興趣的你們自己去看，你們覺得怎麼樣？</p><p class=ql-align-justify>句法分析，尤其針對依存句法分析，主要有基於動態規劃，基於決策，基於融合的方法，當然還有一些擴展性的方法。</p><p class=ql-align-justify><strong>基於動態規劃的方法</strong></p><p class=ql-align-justify>基於動態規劃的方法，其實就是直接對依存樹進行分析。早期，採用的方法是將依存圖中的節點看作短語結構中的節點，從而可以應用上下文無關文法中成熟的CKY算法(Gaifman, 1965)，然而時間複雜度非常可怕地達到了O(n5)，後來提出了雙詞彙語法，其方法主要分為產生式方法(Eisner, 1996)和判別式方法(McDonald et al., 2005; McDonald, 2006)，成功地將複雜度降低到O(n3)。</p><p class=ql-align-justify>生成式和判別式和機器學習裡面的生成和判別相同，生成式方法採用聯合概率模型生成一系列依存句法樹並賦予其概率分值，然後採用相關算法找到概率打分最高的分析結果作為最後的輸出，說白了就是<strong>把概率分佈求出來</strong>，然後根據概率分佈進行下一步的分析和決策，在句法分析中將詞與詞之間的依存關係看作是成分結構，用類似於短語結構句法分析的方法來獲取依存關係，其優點是能夠得到每種決策的概率關係，<strong>決策更加全面</strong>，但是缺點是畢竟在相同的信息下，<strong>相比判別式整體決策精度可能會下降</strong>，其信息消耗花在進行計算概率分佈上太多，導致最後拍板的時候受到約束。</p><p class=ql-align-justify>判別式將依存分析看作是在一個依存圖上尋找最大生成樹(MST)的問題，該生成樹滿足上述三個約束條件：連通、單一父節點、無環，<strong>並不需要求概率分佈</strong>，相比生成式，其優點是<strong>操作更為簡單</strong>，可以運用更多的機器學習方法，<strong>而且出現下溢的情況更少</strong>（計算機在計算10的負好多次方的時候會出現下溢情況，精度會大大下降），<strong>複雜度相對較低，最終精度偏高</strong>。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9694f5f7546b470fb9e1d45d7778ea4b><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>基於決策的方法</strong></p><p class=ql-align-justify>基於決策的方法把分析過程看成是分析序列，建立詞之間的聯繫，Covington(2001) 將決策的過程從句子的左端開始，逐個接受每個詞，並嘗試連接每個詞與先前的詞並將其作為頭詞或依存詞，這種算法簡單易懂，但是窮舉法計算低效而且受到語料庫約束較大；Yamada和Matsumoto(2003)通過將關係分為<strong>左依存、右依存和無依存</strong>三種情況進行動作分析從而得到句法結構；Nivre和Scholz(2004)在Yamada和Matsumoto(2003)的基礎上提出新的數據結構和動作分析方法，依存句法分析器主要由一個三元組構成，其中S表示一個棧結構， I表示剩餘輸入詞序列， A表示在當前分析狀態下所得到的依存關係集合，將動作從原來的3個升級為<strong>Left-arc, right-arc, reduce, shift</strong>四個。</p><p class=ql-align-justify><strong>從整體而言，基於決策的方法模型直觀清晰，但是決策過程是貪婪的，局部的，精度收到很大限制，誤差還會傳遞，所以仍存在較大問題。</strong></p><p class=ql-align-justify><strong>基於融合的方法</strong></p><p class=ql-align-justify>機器學習中有基本的支持向量機、決策樹等優秀的方法，但是卻各有問題，於是提出了bagging，而基於融合的方法，<strong>將上述兩個方法的優點結合</strong>。</p><p class=ql-align-justify><strong>基於搜索策略融合的方法(Duan et al., 2007)認為整個決策式依存句法分析過程可以看作是馬爾科夫鏈。</strong>在每一步分析中會有若干個候選分析動作。句法分析的目標是在馬爾科夫假設下尋找最有可能的分析動作序列，這樣既可以利用豐富的上下文特徵，又從全局的視角對決策動作建模，而算法的複雜度介於決策式方法和動態規劃方法之間。按照他的說法進行實驗得到的精度是這樣的，可見優化了不少。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b6e4b444b0a4419fb318c63fc52dece0><p class=pgc-img-caption></p></div><p class=ql-align-justify>基於特徵的融合方法(Nivre and McDonald, 2008)在McDonald和Nivre(2007)的“<strong>不同的句法分析器產生不同的錯誤</strong>”觀點下提出兩種思路，如下圖所示（符號太複雜所以我就截圖了）：</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a6ff7f551092408cb8f99d969d1291b9><p class=pgc-img-caption></p></div><p class=ql-align-justify>最後還有基於模型的融合方法，Zhang和Clark(2008)將<strong>動態規劃的方法和決策的方法</strong>進行加權組合。</p><p class=ql-align-justify><strong>擴展性工作</strong></p><p class=ql-align-justify>受限於樹庫規模較小，尤其是有標註的材料太少，所以句法分析的性能一直受到嚴重限制，目前有部分學者開始在有限的標註材料和較多的無標註材料下，使用半監督或者無監督的方法。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8eaead283415490191cb643cc4c85ba0><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><h1><strong>5 面臨的挑戰</strong></h1><p class=ql-align-justify>前人尚且已經在句法分析上有豐碩的成果，但是下面幾個方面仍有巨大的研究價值和研究潛力。</p><ul><li class=ql-align-justify>句法分析的<strong>準確度</strong>仍十分有限；</li><li class=ql-align-justify>句法分析的<strong>評價指標</strong>是否合理目前尚無定論，CoNLL仍有一些問題，而且有人針對多個角度，例如語種等，有無更加靈活的機制；</li><li class=ql-align-justify>句法分析的<strong>魯棒性</strong>仍不夠高，和評價指標的<strong>靈活性</strong>類似；</li><li class=ql-align-justify>句法分析的<strong>速度</strong>，目前仍無法投入大數據的實現，然而速度和精度的兩大矛盾體的存在性導致兩者相互制約；</li><li class=ql-align-justify>運用在互聯網中的研究仍處起步階段，主要針對<strong>句法分析的下游技術</strong>，面向信息抽取的句法分析，面向社區問答的句法分析等；</li><li class=ql-align-justify>句法分析並不是上游技術，<strong>需要依賴分詞、詞性標註等關鍵技術</strong>，這些技術同樣具有較大誤差等問題，於是誤差的傳遞下句法分析的性能受到較大約束。</li></ul><h1><strong>6 小結</strong></h1><p class=ql-align-justify>句法分析不是我的主要研究重點，也沒太關注過這個重點，經過一些相關材料的閱讀和學習，感覺還是有很大的研究空間，後續可能會有一些深入的閱讀，擴充自己的知識面，也讓自己應對各種問題多了一把新的有力武器。</p><div class=pgc-img><img alt="NLP.TM「3」 | 句法分析綜述" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4203d126b9914767b8e5471dc416feca><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>參考文獻</strong></p><ul><li class=ql-align-justify>[1] M. Bansal and D. Klein. 2011. Web-scale Features for Full-Scale Parsing. In ACL-HLT.</li><li class=ql-align-justify>[2] W. Chen, J. Kazama, K. Uchimoto and K. Torisawa. 2009. Improving Dependency Parsing with Subtrees from Auto-Parsed Data. In EMNLP.</li><li class=ql-align-justify>[3] J. Eisner. 1996. Three new probabilistic models for dependency parsing: an exploration. In COLING.</li><li class=ql-align-justify>[4] J. Hall, J. Nivre and J. Nilsson. 2006. Discriminative classifier for deterministic dependency parsing. In ACL.</li><li class=ql-align-justify>[5] L. Huang, W. Jiang and Q. Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In EMNLP.</li><li class=ql-align-justify>[6] T. Koo, X. Carreras and M. Collins. 2008. Simple semi-supervised dependency parsing. In ACL.</li><li class=ql-align-justify>[7] R. McDonald, K. Crammer, and F. Pereira. 2005. On-line large-margin training of dependency parsers. In ACL.</li><li class=ql-align-justify>[8] J. Nivre and R. McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In ACL.</li><li class=ql-align-justify>[9] W. Jiang and Q. Liu. Dependency parsing and projection based on word-pair classification. In ACL, 2010.</li><li class=ql-align-justify>[10] Y. Zhang and S. Clark. 2008. A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search. In EMNLP.</li><li class=ql-align-justify>[11] H. Zhao, Y. Song, C. Kit and G. Zhou. 2009. Cross language dependency parsing using a bilingual lexicon. In ACL.</li><li class=ql-align-justify>[12] G. Zhou, J. Zhao, K. Liu and L. Cai. 2011. Exploiting web-derived selectional preference to improve statistical dependency parsing. In ACL-HLT.</li><li class=ql-align-justify>[13] R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. Bootstrapping parsers via syntactic projection across parallel texts. In NLE, 2005.</li><li class=ql-align-justify>[14] D. Klein and C. Manning. Corpus based induction of syntactic structures: Models of dependency and constituency. In ACL, 2004.</li><li class=ql-align-justify>[15] J. Nivre and M. Scholz. Deterministic dependency parsing of english text. In COLING, 2004.</li><li class=ql-align-justify>[16] J. M. Eisner. Three new probabilistic models for dependency parsing: an exploration. In COLING, 1996</li><li class=ql-align-justify>[17] K. Ganchev, J. Gillenwater, and B. Taskar. Dependency grammar induction via bitext projection constraints. In ACL, 2009.</li><li class=ql-align-justify>[18] R. McDonald and J. Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. IN EMNLP.</li><li class=ql-align-justify>[19] J. Nivre and R. McDonald. 2008. Integrating graph-based and transition-based dependency parsing. In ACL.</li><li class=ql-align-justify>[20] L. Huang and K. Sagae. 2011. Dynamic programming for linear-time incremental parsing. In ACL. T. Koo and M. Collins. 2010. Efficient third-order dependency parsers. In ACL.</li><li class=ql-align-justify>[21] K. Hayashi, T. Watanabe, M. Asahara, and Y. Matsumoto. Third-order variational reranking on packed-shared dependency forests. In EMNLP.</li><li class=ql-align-justify>[22] 段湘煜. 基於分析動作建模的依存句法分析. 中國科學院自動化研究所博 士論文， 2008年</li><li class=ql-align-justify>[22] 鑑萍. 依存句法分析方法研究與系統實現. 中國科學院自動化研究所博士 論文， 2010年</li><li class=ql-align-justify>[23] 宗成慶. 統計自然語言理解. 清華大學出版社， 2008年</li></ul></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>NLP</a></li><li><a>TM</a></li><li><a>句法分析</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/33d04d4d.html alt=2020年各大頂會NLP、ML優質論文分類整理分享 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fb47112700b049aa88994c8949ec9403 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/33d04d4d.html title=2020年各大頂會NLP、ML優質論文分類整理分享>2020年各大頂會NLP、ML優質論文分類整理分享</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7a11c4af.html alt=圖解BERT（NLP中的遷移學習） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b29b82aef73748bd9fc0a049212fba09 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7a11c4af.html title=圖解BERT（NLP中的遷移學習）>圖解BERT（NLP中的遷移學習）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/30177cc2.html alt=NLP中的遷移學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1534906754727755a6a6964 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/30177cc2.html title=NLP中的遷移學習>NLP中的遷移學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45cbe488.html alt=NLP基礎-通用句子向量漫談 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/db54188d47524055b7a45d90aed407ac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45cbe488.html title=NLP基礎-通用句子向量漫談>NLP基礎-通用句子向量漫談</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/760de6b8.html alt=NLP領域中的遷移學習現狀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RayMFst8jYuQgG style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/760de6b8.html title=NLP領域中的遷移學習現狀>NLP領域中的遷移學習現狀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html alt="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RdGewJX7BKaFVS style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html title="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習">ACL 2019 | 南大NLP，知識庫問答中的表示映射學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a73c5785.html alt="「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8cc2bb8a2c0f4d529fd624f5df2fc70c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a73c5785.html title="「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）">「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ff8d4ec0.html alt=近53種NLP中文語料庫，你一定用得到 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4baf47697c7f46c3bd15d310e7b9005c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ff8d4ec0.html title=近53種NLP中文語料庫，你一定用得到>近53種NLP中文語料庫，你一定用得到</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a33d5f8c.html alt=NLP最新科研福利！MSRA開源學術界最全面語義分析數據集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/ccdfe908755e4dd99f59e788131374bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a33d5f8c.html title=NLP最新科研福利！MSRA開源學術界最全面語義分析數據集>NLP最新科研福利！MSRA開源學術界最全面語義分析數據集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02a71e69.html alt=NLP任務中的文本預處理步驟、工具和示例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RqSgmP9HojtMNK style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02a71e69.html title=NLP任務中的文本預處理步驟、工具和示例>NLP任務中的文本預處理步驟、工具和示例</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html alt=一文讓你入門NLP自然語言處理，看不懂你來找我 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/e0409d62-8a85-4eee-848a-f939a843c1db style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html title=一文讓你入門NLP自然語言處理，看不懂你來找我>一文讓你入門NLP自然語言處理，看不懂你來找我</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html alt="機器不學習：NLP系列3 自然語言理解-意圖分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1534769000731dd06801b0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html title="機器不學習：NLP系列3 自然語言理解-意圖分類">機器不學習：NLP系列3 自然語言理解-意圖分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html alt="自然語言處理 NLP 發展簡史" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a09ec23681e48f5952e8b830fbca5bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html title="自然語言處理 NLP 發展簡史">自然語言處理 NLP 發展簡史</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>