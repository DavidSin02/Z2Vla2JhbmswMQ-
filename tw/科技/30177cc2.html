<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>NLP中的遷移學習 | 极客快訊</title><meta property="og:title" content="NLP中的遷移學習 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/1534906754727755a6a6964"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/30177cc2.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/30177cc2.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="NLP中的遷移學習"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/30177cc2.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>NLP中的遷移學習</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>摘要</strong>： 遷移學習正在各個領域大展拳腳，NLP領域正在受到衝擊！</p><p>在我們之前的文章中，我們展示瞭如何使用CNN與遷移學習為我們自己創建圖片構建分類器。今天，我們介紹NLP中遷移學習的最新趨勢，並嘗試進行分類任務：將亞馬遜評論的數據集分類為正面或負面。</p><p>NLP中的遷移學習理念在fast.ai課程中得到了很好的體現，我們鼓勵你查看論壇。我們這裡的參考文件是 Howard，Ruder，“用於文本分類的通用語言模型微調”。</p><p><strong>什麼是遷移學習？</strong></p><p>計算機視覺是一個使用遷移學習而取得巨大進步的領域。它具有數百萬參數的高度非線性模型需要大量數據集進行訓練，並且通常需要數天或數週才能進行訓練，只是為了能夠將圖像分類為包含狗或貓！</p><div class=pgc-img><img alt=NLP中的遷移學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1534906754727755a6a6964><p class=pgc-img-caption></p></div><p>隨著ImageNet的挑戰，團隊每年都參與競爭，以設計出最佳的圖像分類器。已經觀察到這些模型的隱藏層能夠捕獲圖像中的一般知識（邊緣、某些形式、樣式......）。因此，每次我們想要改變任務時，沒有必要從頭開始重新訓練模型。</p><p>讓我們以VGG-16模型為例（Simonyan、Karen和Zisserman·“用於大規模圖像識別的非常深的卷積網絡。”（2014））</p><div class=pgc-img><img alt=NLP中的遷移學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15349067547998f870d4578><p class=pgc-img-caption></p></div><p>這種架構比較複雜、層數多、參數數量多。作者聲稱使用4個強大的GPU訓練了為3周時間。</p><p>遷移學習的想法是，由於中間層被認為是學習圖像的一般知識，我們可以將它們用作當成比較全面的特徵！我們將下載一個預先訓練好的模型（在ImageNet任務上訓練數週），刪除網絡的最後一層（完全連接的層，在ImageNet挑戰的1000個類上投射功能），添加put而不是我們選擇的分類器，適合我們的任務（如果我們有興趣對貓和狗進行分類，則為二元分類器），最後僅訓練我們的分類層。並且因為我們使用的數據可能與之前訓練過的模型數據不同，我們也可以進行微調步驟，這樣我們就能在相當短的時間內訓練所有層。</p><p>除了更快地進行訓練之外，遷移學習特別有趣，因為僅在最後一層進行訓練使我們僅使用較少的標記數據即可，而端對端訓練整個模型則需要龐大的數據集。標記數據很昂貴，並且非常需要建立高質量模型而不需要大數據集。</p><p><strong>那麼NLP中的遷移學習呢？</strong></p><p>NLP深度學習的進展不像計算機視覺那樣成熟。雖然可以想象機器能夠學習邊緣、圓形、正方形等形狀，然後使用這些知識做其他事情，但對於文本數據來說這些並不簡單。</p><p>最初流行的在NLP中遷移學習是由嵌入模型這個詞（由word2vec和GloVe廣泛推廣）帶來的。這些單詞矢量表示利用單詞的上下文，將它們表示為向量，其中相似的單詞應具有相似的單詞表示。</p><p>在這個圖中，來自word2vec論文，我們看到該模型能夠學習國家與其首都城市之間的關係。</p><div class=pgc-img><img alt=NLP中的遷移學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15349067547691ac7288367><p class=pgc-img-caption></p></div><p>包括預先訓練的單詞向量已經顯示出在大多數NLP任務中改進度量，因此已經被NLP社區廣泛採用，被用來尋找甚至更好的單詞/字符/文檔表示。與計算機視覺一樣，預訓練的單詞向量可以被視為特徵化函數，轉換一組特徵中的每個單詞。</p><p>但是，單詞嵌入僅代表大多數NLP模型的第一層。之後，我們仍然需要從頭開始訓練所有RNN / CNN /自定義層。</p><p><strong>用於文本分類的語言模型微調</strong></p><p>今年早些時候霍華德和羅德提出了ULMFit模型，以此來進一步提升了遷移學習在NLP的應用。</p><p>他們正在探索的想法是基於<strong>語言模型</strong>。語言模型是一種能夠根據已經看到的單詞預測下一個單詞的模型（想想你的智能手機在你發短信時為你猜測下一個單詞）。就像圖像分類器通過對圖像分類來獲得圖像的內在知識一樣，如果NLP模型能夠準確地預測下一個單詞，那麼說明它已經學到了很多關於自然語言結構。這些知識應提供良好的初始化，然後可以在自定義任務上進行訓練！</p><p>ULMFit建議在非常大的文本語料庫（例如維基百科）上訓練語言模型，並將其用作任何分類器的主幹！由於你的文本數據可能與維基百科的編寫方式不同，因此你需要微調語言模型的參數以將這些差異考慮在內。然後，我們將在此語言模型的頂部添加分類器層，並僅訓練此層！</p><p><strong>ULMfit paper</strong></p><p>讓人驚訝的結果是，使用這種預訓練的語言模型使我們能夠在更少標記的數據上訓練分類器！雖然未標記的數據在網絡上幾乎是無限的，但標記數據非常昂貴且耗時。</p><p>以下是他們從IMDb情緒分析任務中報告的結果：</p><div class=pgc-img><img alt=NLP中的遷移學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153490675478635a16290e4><p class=pgc-img-caption></p></div><p>雖然只有100個示例，它們能夠達到與使用20k示例從頭開始訓練時模型達到的相同錯誤率！</p><p>此外，他們還提供了代碼，以你選擇的語言預先訓練語言模型。由於維基百科存在很多的語言中，因此我們可以使用維基百科數據快速從一種語言遷移到另一種語言。眾所周知，公共標籤數據集更難以使用英語以外的語言進行訪問。在這裡，你可以對未標記數據上的語言模型進行微調，花幾個小時手動註釋幾百/千個數據點，並使分類器頭部適應你預先訓練的語言模型來執行你的任務！</p><p><strong>遊樂場與亞馬遜評論</strong></p><p>為了改變這種方法的不足之處，我們使用為其論文中的公共數據集上進行了嘗試。我們在Kaggle上找到了這個數據集：它包含4百萬條關於亞馬遜產品的評論，並用積極或消極的情緒標記它們。我們將針對ULMfit的fast.ai課程調整將亞馬遜評論分類為正面或負面。我們發現只需要1000個數據點，該模型就能夠匹配通過在完整數據集上從頭開始訓練FastText模型獲得的準確度分數。僅使用100個標記示例，該模型仍然能夠獲得良好的性能。</p><div class=pgc-img><img alt=NLP中的遷移學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1534906754864b5d899b3fe><p class=pgc-img-caption></p></div><p>要重現此實驗，你可以使用此筆記本，建議使用GPU來運行微調和分類部分。</p><p><strong>NLP中的無監督與監督學習，圍繞意義進行討論</strong></p><p>使用ULMFit，我們使用了無監督和監督學習。訓練無監督的語言模型是“便宜的”，因為你可以在線訪問幾乎無限的文本數據。但是，使用監督模型很昂貴，因為你需要對數據進行標記。</p><p>雖然語言模型能夠從自然語言的結構中捕獲大量相關信息，但尚不清楚它是否能夠捕獲文本的含義，即“發送者打算傳達的信息或概念”。</p><p>你可能已經關注了NLP中非常有趣的Twitter主題。在這個帖子中，艾米莉·本德利用“泰國房間實驗”對她進行了反對意義捕獲的論證：想象一下，你在一個巨大的圖書館裡得到了所有泰國文學的總和。假設你還不懂泰語，你就不會從中學到任何東西。</p><p>所以我們可以認為語言模型學到的更多是語法而不是意義。然而，語言模型比僅僅預測語法相關的句子更好。例如，“我要吃來這臺電腦”和“我討厭這臺電腦”兩者在語法上都是正確的，但一個好的語言模型應該能夠知道“我討厭這臺電腦”應該比另外一句更“準確”。所以，即使我看過整個泰語維基百科，我也無法用泰語寫作，但很容易看出語言模型確實超越了簡單的語法/結構理解。</p><p>我們不會在這裡進一步探討意義的概念（這是一個無窮無盡且引人入勝的話題/辯論），如果你有興趣，我們建議你看下Yejin Choi在ACL 2018的演講中是如何探討這一主題的。</p><p><strong>NLP中遷移學習的未來</strong></p><p>ULMFit取得的進展推動了NLP遷移學習的研究。對於NLP來說，這是一個激動人心的時刻，因為其他微調語言模型也開始出現，特別是FineTune Transformer LM。我們還注意到，隨著更好的語言模型的出現，我們甚至可以改善這種知識遷移。</p><p>以上為譯文。</p><p>本文由阿里云云棲社區組織翻譯。</p><p><strong>文章原標題《</strong>transfer-learning-in-nlp<strong>》，</strong></p><p><strong>作者：</strong>PETER MARTIGNY<strong>譯者：虎說八道，審校：。</strong></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>NLP</a></li><li><a>移學習</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/760de6b8.html alt=NLP領域中的遷移學習現狀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RayMFst8jYuQgG style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/760de6b8.html title=NLP領域中的遷移學習現狀>NLP領域中的遷移學習現狀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/33d04d4d.html alt=2020年各大頂會NLP、ML優質論文分類整理分享 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fb47112700b049aa88994c8949ec9403 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/33d04d4d.html title=2020年各大頂會NLP、ML優質論文分類整理分享>2020年各大頂會NLP、ML優質論文分類整理分享</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7a11c4af.html alt=圖解BERT（NLP中的遷移學習） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b29b82aef73748bd9fc0a049212fba09 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7a11c4af.html title=圖解BERT（NLP中的遷移學習）>圖解BERT（NLP中的遷移學習）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45cbe488.html alt=NLP基礎-通用句子向量漫談 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/db54188d47524055b7a45d90aed407ac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45cbe488.html title=NLP基礎-通用句子向量漫談>NLP基礎-通用句子向量漫談</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html alt="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RdGewJX7BKaFVS style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html title="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習">ACL 2019 | 南大NLP，知識庫問答中的表示映射學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a73c5785.html alt="「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8cc2bb8a2c0f4d529fd624f5df2fc70c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a73c5785.html title="「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）">「NLP 必備知識點」自然語言理解 NLU（概念+應用+3種實現方式）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ff8d4ec0.html alt=近53種NLP中文語料庫，你一定用得到 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4baf47697c7f46c3bd15d310e7b9005c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ff8d4ec0.html title=近53種NLP中文語料庫，你一定用得到>近53種NLP中文語料庫，你一定用得到</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a33d5f8c.html alt=NLP最新科研福利！MSRA開源學術界最全面語義分析數據集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/ccdfe908755e4dd99f59e788131374bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a33d5f8c.html title=NLP最新科研福利！MSRA開源學術界最全面語義分析數據集>NLP最新科研福利！MSRA開源學術界最全面語義分析數據集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02a71e69.html alt=NLP任務中的文本預處理步驟、工具和示例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RqSgmP9HojtMNK style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02a71e69.html title=NLP任務中的文本預處理步驟、工具和示例>NLP任務中的文本預處理步驟、工具和示例</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html alt=一文讓你入門NLP自然語言處理，看不懂你來找我 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/e0409d62-8a85-4eee-848a-f939a843c1db style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html title=一文讓你入門NLP自然語言處理，看不懂你來找我>一文讓你入門NLP自然語言處理，看不懂你來找我</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html alt="機器不學習：NLP系列3 自然語言理解-意圖分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1534769000731dd06801b0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html title="機器不學習：NLP系列3 自然語言理解-意圖分類">機器不學習：NLP系列3 自然語言理解-意圖分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html alt="自然語言處理 NLP 發展簡史" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a09ec23681e48f5952e8b830fbca5bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html title="自然語言處理 NLP 發展簡史">自然語言處理 NLP 發展簡史</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>