<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>用於圖像降噪的卷積自編碼器 | 极客快訊</title><meta property="og:title" content="用於圖像降噪的卷積自編碼器 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/449c17c702f54ceca0b90a4ddcc4a0bb"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/372c161.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/372c161.html><meta property="article:published_time" content="2020-10-29T21:05:26+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:26+08:00"><meta name=Keywords content><meta name=description content="用於圖像降噪的卷積自編碼器"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/372c161.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>用於圖像降噪的卷積自編碼器</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/449c17c702f54ceca0b90a4ddcc4a0bb><p class=pgc-img-caption></p></div><p>這篇文章的目的是介紹關於利用自動編碼器實現圖像降噪的內容。</p><p>在神經網絡世界中，對圖像數據進行建模需要特殊的方法。其中最著名的是卷積神經網絡(CNN或ConvNet)或稱為卷積自編碼器。並非所有的讀者都瞭解圖像數據，那麼我先簡要介紹圖像數據(如果你對這方面已經很清楚了，可以跳過)。然後，我會介紹標準神經網絡。這個標準神經網絡用於圖像數據，比較簡單。這解釋了處理圖像數據時為什麼首選的是卷積自編碼器。最重要的是，我將演示卷積自編碼器如何減少圖像噪聲。這篇文章將用上Keras模塊和MNIST數據。Keras用Python編寫，並且能夠在TensorFlow上運行，是高級的神經網絡API。</p><h1 class=pgc-h-decimal data-index=01>瞭解圖像數據</h1><p>如圖(A)所示，圖像由“像素”組成。在黑白圖像中，每個像素由0到255之間的數字表示。如今大多數圖像使用24位彩色或更高的顏色。一幅RGB彩色圖像表示一個像素的顏色由紅色、綠色和藍色組成，這三種顏色各自的像素值從0到255。RGB色彩生成器(如下所示)表明，RGB色彩系統利用紅綠藍，組合成各種顏色。因此，一個像素由含三個值的RGB(102、255、102)構成，其色號為＃66ff66。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/195b9ccf0c544c479d8db9e4394a6a22><p class=pgc-img-caption></p></div><p>寬800像素，高600像素的圖像具有800 x 600 = 480,000像素，即0.48兆像素(“兆像素”等於100萬像素)。分辨率為1024×768的圖像是一個由1,024列和768行構成的網格，共有1,024×768 = 0.78兆像素。</p><p><br></p><h1 class=pgc-h-decimal data-index=02>MNIST</h1><p>MNIST數據庫是一個大型的手寫數字數據庫，通常用於訓練各種圖像處理系統。Keras的訓練數據集具備60,000條記錄，而測試數據集則包含了10,000條記錄。每條記錄共有28 x 28個像素。</p><pre><code>from keras.layers import Input, Densefrom keras.models import Modelfrom keras.datasets import mnistimport numpy as np(x_train, _), (x_test, _) = mnist.load_data()</code></pre><p>它們看起來怎麼樣？我們用繪圖庫及其圖像功能imshow()展示前十條記錄。</p><pre><code>import matplotlib.pyplot as pltn = 10  # 顯示的記錄數plt.figure(figsize=(20, 4))for i in range(n):    # 顯示原始圖片    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ec254e1e581044bca7b1428f4abb30b0><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=03>圖像數據的堆疊，用於訓練</h1><p>如果要讓神經網絡框架適用於模型訓練，我們可以在一列中堆疊所有28 x 28 = 784個值。第一條記錄的堆疊列如下所示(使用x_train[1].reshape(1,784))：</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2e7def5cde704a7096ff484ddcf476c0><p class=pgc-img-caption></p></div><p>然後，我們可以使用標準的神經網絡訓練模型，如圖(B)所示。數值為784的每個值都是輸入層中的一個節點。且慢！堆疊數據會丟失很多信息嗎？答案是肯定的。圖像中的空間關係被忽略了。這使得大量的信息丟失。那麼，我們接著看卷積自編碼器如何保留空間信息。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/21d723e025554871897ffaa6776dbb5d><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=04>為什麼圖像數據首選卷積自編碼器？</h1><p>可以看到，數據切片和數據堆疊會導致信息大量丟失。卷積自編碼器放棄堆疊數據，使圖像數據輸入時保持其空間信息不變，並在卷積層中以溫和的方式提取信息。圖(D)演示了將平面2D圖像先提取到一個厚的正方體(Conv1)，再提取到一個長方體(Conv2)和另一個長度更長的長方體(Conv3)。此過程旨在保留數據中的空間關係。這是自動編碼器的編碼過程。中間部分是一個完全連接的自動編碼器，其隱藏層僅由10個神經元組成。然後就是解碼過程。三個立方體將會展平，最後變成2D平面圖像。圖(D)的編碼器和解碼器是對稱的。實際上，編碼器和解碼器不要求對稱。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a98f303752284817979d2b053c5c2397><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=05>卷積自編碼器如何工作？</h1><p>上面的數據析取似乎很神奇。數據析取究竟是如何進行的？這包括以下三層：卷積層，線性整流層和池化層。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3a2e2517a152487fa23d404fa1b2f177><p class=pgc-img-caption></p></div><p><strong>1. 卷積層</strong></p><p>卷積步驟會生成很多小塊，稱為特徵圖或特徵，如圖(E)的綠色、紅色或深藍色的正方形。這些正方形保留了輸入圖像中像素之間的關係。如圖(F)所示，每個特徵掃描原始圖像。這一產生分值的過程稱為卷積。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a71367f093564fc19f673f9b730e6d5e><p class=pgc-img-caption></p></div><p>掃描完原始圖像後，每個特徵都會生成高分值和低分值的濾波圖像，如圖(G)所示。如果匹配完美，那塊正方形的得分就高。如果匹配度低或不匹配，則得分低或為零。例如，原始圖像有四個區域與紅色方塊完全匹配，那麼這四個區域的得分都很高。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/53ebff749bcb427ca54aace48d69eae1><p class=pgc-img-caption></p></div><p>過濾器越多，模型可以提取的特徵就越多。但是，特徵越多，訓練時間也就越長。因此，最好還是選擇最少的過濾器提取特徵。</p><p><strong>1.1 填充</strong></p><p>特徵如何確定匹配項？一種超參數是填充，有兩種選擇：(i)用零填充原始圖像以符合該特徵，或(ii)刪除原始圖像中不符的部分並保留有效部分。</p><p><strong>1.2步長</strong></p><p>卷積層的另一個參數：步長。步長是輸入矩陣上移動的像素個數。當步長為1時，過濾器一次移動1個像素。在Keras代碼中，我們將其視為超參數。</p><p><strong>2.線性整流步驟</strong></p><p>線性整流單位(ReLU)的步驟與典型的神經網絡相同。它將所有的負值校正為零，確保數學運算正確。</p><p><strong>3.最大池化層</strong></p><p>池化會縮小圖像尺寸。在圖(H)中，一個2 x 2的窗口(稱為池的大小)掃描每個濾波圖像，並將該2 x 2窗口的最大值劃分給新圖像中大小為1 x 1的正方形。如圖(H)所示，第一個2 x 2窗口的最大值分數高(用紅色表示)，因此高分劃分給1 x 1正方形。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/42a6b7719785484680fc439b44ad1194><p class=pgc-img-caption></p></div><p>除了採用最大值之外，其他不常用的池化方法還包括“平均池化”(取平均值)或“總和池化”(總和)。</p><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2a20f1a81aa47d89cec2aab83058352><p class=pgc-img-caption></p></div><p>池化後，會生成新的更小的濾波圖像。現在我們拆分這個濾波圖像，然後堆疊為一列，如圖(J)所示。</p><h1 class=pgc-h-decimal data-index=06>Keras模型</h1><p>以上三層是卷積神經網絡的構建塊。Keras具有以下兩個功能：</p><p>• Conv2D(filters, kernelsize, activation = 'reLu', strides=1)：核尺寸(kernelsize)是2D卷積窗口的高度和寬度。圖(E)使用的是2×2正方形，所以例子中核尺寸將為(2,2)。步長是輸入矩陣上移動的像素個數。我們一次將濾鏡移動了1個像素，所以步長為1。</p><p>• MaxPooling2D(pool_size=(2,2))：在圖(H)中，我們使用2×2窗口作為池的大小。因此，我們將在以下代碼中使用(2,2)。</p><p>你可以在卷積自編碼器中構建許多卷積層。在圖(E)中，在編碼部分有三層，分別標記為Conv1，Conv2和Conv3。因此，我們要進行相應的構建。</p><p>• 下面的代碼input_img = Input(shape=(28,28,1)表明輸入的2D圖像為28 x 28。</p><p>• 然後，它構建了Conv1，Conv2和Conv3。</p><p>• 請注意，Conv1在Conv2內部，而Conv2在Conv3內部。</p><p>• 要是過濾器無法適應輸入圖像，填充將指定下一步該做什麼。padding='valid'表示過濾器不符合，圖像的一部分將被丟棄；padding='same'用零填充圖片以適應圖片。</p><pre><code>from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2Dfrom keras.models import Model# 編碼過程input_img = Input(shape=(28, 28, 1))  ############# 編碼 ############## Conv1 #x = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)x = MaxPooling2D(pool_size = (2, 2), padding='same')(x)# Conv2 #x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)x = MaxPooling2D(pool_size = (2, 2), padding='same')(x) # Conv 3 #x = Conv2D(filters = 8, (3, 3), activation='relu', padding='same')(x)encoded = MaxPooling2D(pool_size = (2, 2), padding='same')(x)# 注意:# padding 是一個超參數，值'valid' or 'same'. # "valid" 意味不需要填充 # "same" 填充輸入，使輸出具有與原始輸入相同的長度。 </code></pre><p>然後，解碼過程繼續。因此，下面解碼部分已全部完成編碼和解碼過程。</p><pre><code>############# 解碼 ############## DeConv1x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)x = UpSampling2D((2, 2))(x)# DeConv2x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)x = UpSampling2D((2, 2))(x)# Deconv3x = Conv2D(16, (3, 3), activation='relu')(x)x = UpSampling2D((2, 2))(x)decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)</code></pre><p>該Keras API需要模型和優化方法的聲明：</p><p>•• Model (inputs= inputimg,outputs= decoded)：在解碼給定輸入數據inputimg的情況下，模型包括計算輸出所需的所有層。compile(optimizer='adadelta',loss='binary_crossentropy')：優化程序會像漸變梯度一樣執行優化操作。最常見的是隨機梯度下降(SGD)，自適應梯度(Adagrad)和Adadelta(Adadelta是Adagrad的擴展)。有關詳細信息，請參見Keras優化器文檔。損失函數可以查找Keras損失文檔。</p><pre><code># 聲明模型autoencoder = Model(input_img, decoded)autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')</code></pre><p>下面，我使用xtrain作為輸入和輸出來訓練模型。batchsize是樣本量和epochs是迭代的次數。我指定shuffle=True打亂訓練數據。</p><pre><code># 訓練模型autoencoder.fit(x_train, x_train,                epochs=100,                batch_size=128,                shuffle=True,                validation_data=(x_test, x_test)               )</code></pre><p>我們可以打印出前十張原始圖像和相同十張圖像的預測。</p><pre><code>decoded_imgs = autoencoder.predict(x_test)n = 10plt.figure(figsize=(20, 4))for i in range(n):    # 顯示原始圖像    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)    # 顯示重構後的圖像    ax = plt.subplot(2, n, i+1+n)    plt.imshow(decoded_imgs[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d078b828049d41ea94dfc597618b2048><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=07>如何構建圖像降噪卷積自編碼器？</h1><p>圖像降噪的想法是訓練一個模型，輸入噪聲數據，並輸出它們各自清晰的數據。這是與上述模型的唯一區別。首先讓我們向數據添加噪音。</p><pre><code>noise_factor = 0.4x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) x_train_noisy = np.clip(x_train_noisy, 0., 1.)x_test_noisy = np.clip(x_test_noisy, 0., 1.)</code></pre><p>前十張噪聲圖像如下所示：</p><pre><code>n = 10plt.figure(figsize=(20, 2))for i in range(n):    ax = plt.subplot(1, n, i+1)    plt.imshow(x_test_noisy[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ff15067ea85349fa8000e246a8333ed3><p class=pgc-img-caption></p></div><p>然後，我們訓練模型時將輸入噪聲數據，輸出乾淨的數據。</p><pre><code>autoencoder.fit(x_train_noisy, x_train,                epochs=100,                batch_size=128,                shuffle=True,                validation_data=(x_test_noisy, x_test)               )</code></pre><p>最後，我們打印出前十個噪點圖像以及相應的降噪圖像。</p><pre><code>decoded_imgs = autoencoder.predict(x_test)n = 10plt.figure(figsize=(20, 4))for i in range(n):    # 顯示原始圖像    ax = plt.subplot(2, n, i + 1)    plt.imshow(x_test_noisy[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)    # 顯示重構後的圖像    ax = plt.subplot(2, n, i+1+n)    plt.imshow(decoded_imgs[i].reshape(28, 28))    plt.gray()    ax.get_xaxis().set_visible(False)    ax.get_yaxis().set_visible(False)plt.show()</code></pre><div class=pgc-img><img alt=用於圖像降噪的卷積自編碼器 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d6bde239b4cc4b5ba7860153e712b46b><p class=pgc-img-caption></p></div><h1 class=pgc-h-decimal data-index=08>是否可以使用任何經過訓練的CNN代碼嗎？</h1><p>可以的。如果你有興趣學習代碼，Keras提供了幾個經過預訓練的CNN，包括Xception，VGG16，VGG19，ResNet50，InceptionV3，InceptionResNetV2，MobileNet，DenseNet，NASNet和MobileNetV2。值得一提的是，你可以出於研究目的付錢或下載此大型圖像數據庫ImageNet。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>卷積</a></li><li><a>自編</a></li><li><a>碼器</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/e6e28dd8.html alt=時域卷積網絡TCN詳解：使用卷積進行序列建模和預測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d7a0cea6243e43c4bf1756bbc29f76c2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e6e28dd8.html title=時域卷積網絡TCN詳解：使用卷積進行序列建模和預測>時域卷積網絡TCN詳解：使用卷積進行序列建模和預測</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3a379791.html alt="自編微積分教材-第一章 微積分漫談（1）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/223bb7eb7f274e64a54ed5297dbc6fb2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3a379791.html title="自編微積分教材-第一章 微積分漫談（1）">自編微積分教材-第一章 微積分漫談（1）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/1d41d9b8.html alt=息烽群眾自編自導自演“掃黑除惡”小品《賣肉》 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RLGL4aB8qMOFTP style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/1d41d9b8.html title=息烽群眾自編自導自演“掃黑除惡”小品《賣肉》>息烽群眾自編自導自演“掃黑除惡”小品《賣肉》</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fad2f616.html alt=開源聲碼器WORLD在語音合成中的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9af3e2468bf747759f17a5d188fed2ec style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fad2f616.html title=開源聲碼器WORLD在語音合成中的應用>開源聲碼器WORLD在語音合成中的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/84db2df.html alt=一文搞懂光電編碼器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/689b3d49385f4bcfa664af8bde9fdc16 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/84db2df.html title=一文搞懂光電編碼器>一文搞懂光電編碼器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0530174.html alt=圖解光電編碼器的工作原理，以及定位功能的實現 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fadb3c1ed36e4f5c90f631dc567cf8a0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0530174.html title=圖解光電編碼器的工作原理，以及定位功能的實現>圖解光電編碼器的工作原理，以及定位功能的實現</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8445500.html alt=【一文讀懂】磁編碼器的前世今生 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8a54579c5828483983cdb7b1a3d0fd02 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8445500.html title=【一文讀懂】磁編碼器的前世今生>【一文讀懂】磁編碼器的前世今生</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/95ed377.html alt=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/90096e117f23408880d5dc3a760d72f5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/95ed377.html title=U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文）>U-Net:卷積網絡用於生物醫學圖像分割（2015年經典論文）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/915b745.html alt=深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1528704399761722b85d065 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/915b745.html title=深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索>深度｜卷積神經網絡十五問：CNN與生物視覺系統的研究探索</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/62e8881.html alt=拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/feef6487a74040428c66119cc454abae style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/62e8881.html title=拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界>拉格朗日對偶模型的臆想剖析-卷積小白的隨機世界</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>