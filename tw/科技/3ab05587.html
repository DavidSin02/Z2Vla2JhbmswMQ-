<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>菜鳥必備的循環神經網絡指南（附鏈接） | 极客快訊</title><meta property="og:title" content="菜鳥必備的循環神經網絡指南（附鏈接） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/b4554f16bed74f61ad7cc35a9bd92154"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3ab05587.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3ab05587.html><meta property="article:published_time" content="2020-11-14T21:01:36+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:36+08:00"><meta name=Keywords content><meta name=description content="菜鳥必備的循環神經網絡指南（附鏈接）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/3ab05587.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>菜鳥必備的循環神經網絡指南（附鏈接）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b4554f16bed74f61ad7cc35a9bd92154><p class=pgc-img-caption></p></div><p class=ql-align-justify>作者：Victor Zhou</p><p class=ql-align-justify>翻譯：王雨桐</p><p class=ql-align-justify>校對：吳金迪</p><p class=ql-align-justify>本文約<strong>3800字</strong>，建議閱讀15分鐘。</p><p class=ql-align-justify>本文將介紹最基礎的循環神經網絡（Vanilla RNNs）的概況，工作原理，以及如何在Python中實現。</p><p class=ql-align-justify>循環神經網絡（RNN）是一種專門處理序列的神經網絡。由於在處理文本時十分高效，它經常用於自然語言處理(NLP)。在接下來的文章中，我們將探討RNN是什麼，瞭解它的工作原理，並使用Python從零開始構建一個真正的RNN（僅使用numpy）。</p><p class=ql-align-justify>在另一篇文章中，我介紹了一些神經網絡的基本知識。本文對基礎部分不做過多介紹，如有需要，建議先閱讀基礎文章。</p><p class=ql-align-justify>附鏈接：</p><p class=ql-align-justify>https://victorzhou.com/blog/intro-to-neural-networks/</p><p class=ql-align-justify>讓我們開始吧！</p><p class=ql-align-justify><strong>1. 為什麼要用RNNs?</strong></p><p class=ql-align-justify>關於原始的神經網絡（同樣對於CNNs）的一個問題是它們只能使用預定大小的輸入和輸出：它們採用固定大小的輸入並生成固定大小的輸出。相比之下，RNNs可以將可變長度序列作為輸入和輸出。以下是RNN的示例：</p><p class=ql-align-justify></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/39008dd8c44a4284bf0ee932ae7630c1><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-center>紅色為輸入，綠色為RNN本身，藍色為輸出。來源：Andrej Karpathy</p><p class=ql-align-justify>這種處理序列的能力使RNN表現優異。例如：</p><ul><li class=ql-align-justify>機器翻譯（例如Google翻譯）使用“多對多”RNN。原始文本序列被送入RNN，隨後RNN將翻譯的文本作為輸出。</li><li class=ql-align-justify>情感分析（例如，這是一個積極的還是負面的評論？）通常是使用“多對一”RNN。將要分析的文本送入RNN，然後RNN產生單個輸出分類（例如，這是一個積極的評論）。</li></ul><p class=ql-align-justify>在本文後面，我們將從零開始構建“多對一”RNN，並完成基本的情感分析。</p><p class=ql-align-justify><strong>2. 如何使用RNNs</strong></p><p class=ql-align-justify>讓我們來看看“多對多”RNN吧！</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5d012a4a16164ce49e1e3f73fc91f195><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5a95e60f52204c29bd048e09bd58e23a><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><ol><li class=ql-align-justify>基於之前的隱藏狀態和下一個輸入，我們可以得到下一個隱藏狀態。</li><li class=ql-align-justify>通過計算, 我們可以得到下一個輸出 。</li></ol><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/726a90ff59bd4714810755a61d671341><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-center>多對多 RNN</p><p class=ql-align-justify>這就是使RNN循環的過程：每一步都會使用相同的權重。 更具體地說，典型的原始RNN僅使用3組權重就能完成計算：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c0c735105cf84822a817035c0bff279e><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>此外， 我們還要在RNN中引入兩個偏移量：</p><p class=ql-align-justify>我們用矩陣表示權重，用向量表示偏差。這3個權重和2個偏差就構成了整個RNN！</p><p class=ql-align-justify>以下是將所有內容組合在一起的公式：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2ff73edfcaca4a359c0267ca8231ffab><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>不要略過這些方程式。 停下來一分鐘看看它。 另外，要時刻牢記權重是矩陣，其他變量是向量。</p><p class=ql-align-justify>我們在矩陣乘法中應用所有的權重，並將偏差添加到所得結果中。然後我們將tanh作為第一個等式的激活函數（也可以使用其他激活，如sigmoid）。</p><p class=ql-align-justify><strong>3. 問題</strong></p><p class=ql-align-justify>接下來我們將從零開始應用RNN來執行簡單的情感分析任務：確定給定的文本的情感是正向的還是負向的。</p><p class=ql-align-justify>以下是我為本文整理的數據集中的一些示例：</p><p class=ql-align-justify>附數據集鏈接：</p><p class=ql-align-justify>https://github.com/vzhou842/rnn-from-scratch/blob/master/data.py</p><p class=ql-align-justify></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/598b612ed3fb434eaf198dd9e7c1d94b><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>4. 計劃</strong></p><p class=ql-align-justify>由於這是一個分類問題，我們將使用“多對一”RNN。這和我們之前討論過的“多對多”RNN類似，但不同的是它只使用最終隱藏狀態輸出一個y：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d4b8424e273348c88360d90142a476d6><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-center>多對一 RNN</p><p class=ql-align-justify>每個都是一個表示文本中單詞的向量。輸出的y向量將包含兩個數字，一個表示積極態度，另一個表示消極態度。我們將應用Softmax將這些值轉換為概率，並最終在積極/消極之間做出決定。</p><p class=ql-align-justify>讓我們開始實現RNN吧！</p><p class=ql-align-justify><strong>5. 預處理</strong></p><p class=ql-align-justify>前文提到的數據集由兩部分組成。</p><pre class=ql-align-justify>data.pytrain_data = { 'good': True, 'bad': False, # ... more data} test_data = { 'this is happy': True, 'i am good': True, # ... more data}True=積極，False=消極</pre><p class=ql-align-justify>我們必須進行一些預處理才能將數據轉換為可用的格式。首先，我們構建詞彙表，用來存放數據中出現的詞彙：</p><pre class=ql-align-justify>main.pyfrom data import train_data, test_data # Create the vocabulary.vocab = list(set([w for text in train_data.keys() for w in text.split(' ')]))vocab_size = len(vocab)print('%d unique words found' % vocab_size) # 18 unique words found</pre><p class=ql-align-justify>現在，vocab這個列表中包含了所有的單詞，這裡是指至少在一個訓練樣本中出現的單詞。接下來，為了表示詞彙表中的每個單詞，我們將設定一個整數索引。</p><pre class=ql-align-justify>main.py# Assign indices to each word.word_to_idx = { w: i for i, w in enumerate(vocab) }idx_to_word = { i: w for i, w in enumerate(vocab) }print(word_to_idx['good']) # 16 (this may change)print(idx_to_word[0]) # sad (this may change)</pre><p class=ql-align-justify>我們現在可以用相應的整數索引表示任何給定的單詞！這是必要的步驟，因為RNN無法理解單詞，所以我們必須給它輸入數字。</p><p class=ql-align-justify>最後，回想一下RNN的每個輸入是一個向量。我們將使用獨熱編碼，其中包含除了單個一之外的所有零。每個獨熱向量中的“1”將位於單詞的相應整數索引處。</p><p class=ql-align-justify>由於我們的詞彙表中有18個唯一的單詞，每個將是一個18維的單熱矢量。</p><pre class=ql-align-justify>main.pyimport numpy as np def createInputs(text): ''' Returns an array of one-hot vectors representing the words in the input text string. - text is a string - Each one-hot vector has shape (vocab_size, 1) ''' inputs = [] for w in text.split(' '): v = np.zeros((vocab_size, 1)) v[word_to_idx[w]] = 1 inputs.append(v) return inputs</pre><p class=ql-align-justify>隨後，我們將用createInputs（）來生成輸入向量，並傳入到RNN中。</p><p class=ql-align-justify><strong>6. 向前傳播階段</strong></p><p class=ql-align-justify>是時候開始實現我們的RNN了！我們首先將初始化RNN需要的3個權重和2個偏移量：</p><pre class=ql-align-justify>rnn.pyimport numpy as npfrom numpy.random import randn class RNN: # A Vanilla Recurrent Neural Network.  def __init__(self, input_size, output_size, hidden_size=64): # Weights self.Whh = randn(hidden_size, hidden_size) / 1000 self.Wxh = randn(hidden_size, input_size) / 1000 self.Why = randn(output_size, hidden_size) / 1000  # Biases self.bh = np.zeros((hidden_size, 1)) self.by = np.zeros((output_size, 1))</pre><p class=ql-align-justify>注意：我們除以1000以減少權重的初始方差。儘管這不是初始化權重的最佳方法，但它很直觀，適用於這篇文章。</p><p class=ql-align-justify>我們使用np.random.randn（），基於標準正態分佈初始化權重。</p><p class=ql-align-justify>接下來，讓我們實現RNN前向傳播。 還記得我們之前看到的這兩個方程嗎?</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9673d7c35e234318ad42304ae8c9683e><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>以下是在代碼中的實現：</p><pre class=ql-align-justify>rnn.pyclass RNN: # ...  def forward(self, inputs): ''' Perform a forward pass of the RNN using the given inputs. Returns the final output and hidden state. - inputs is an array of one hot vectors with shape (input_size, 1). ''' h = np.zeros((self.Whh.shape[0], 1))  # Perform each step of the RNN for i, x in enumerate(inputs): h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)  # Compute the output y = self.Why @ h + self.by  return y, h</pre><p class=ql-align-justify></p><p class=ql-align-justify>這很簡單吧？ 請注意，因為沒有之前的h可以使用，我們在第一步中將h初始化為零向量。</p><p class=ql-align-justify>讓我們來試試吧：</p><pre class=ql-align-justify>main.py# ... def softmax(xs): # Applies the Softmax Function to the input array. return np.exp(xs) / sum(np.exp(xs)) # Initialize our RNN!rnn = RNN(vocab_size, 2) inputs = createInputs('i am very good')out, h = rnn.forward(inputs)probs = softmax(out)print(probs) # [[0.50000095], [0.49999905]]</pre><p class=ql-align-justify>如果需要複習Softmax相關知識，可以通過鏈接閱讀相關的快速解釋。</p><p class=ql-align-justify>附鏈接：</p><p class=ql-align-justify>https://victorzhou.com/blog/softmax/</p><p class=ql-align-justify>我們的RNN可以成功運行，但它看起來不是很有用。 看來我們得作出一些改變......</p><p class=ql-align-justify><strong>7. 反饋階段</strong></p><p class=ql-align-justify>為了訓練RNN，首先我們需要一個損失函數。我們將使用交叉熵損失函數，它通常與Softmax結合。 計算公式如下：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c23f0bbb55a7402fa9b59e2b56c1d419><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a142d7dfe7eb4e77a350206c92e8b0a4><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/85903da4a2994065a288efda25173e86><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>現在我們有了損失函數，我們將使用梯度下降來訓練RNN模型，以儘量減少損失。 這意味著我們現在要做一些梯度相關的計算！</p><p class=ql-align-justify>以下部分需要一些多變量微積分的基本知識，你可以選擇跳過這部分。即使你不太瞭解，我也建議你大概瀏覽一下。推導出結果後，我們將逐步完成代碼，淺層次的理解也會有所幫助。</p><p class=ql-align-justify>如果想要深入瞭解本節，可以閱讀我在“神經網絡介紹”一文中的“訓練神經網絡”部分。 此外，本文的所有代碼都在Github上，你也可以在Github上關注我。</p><p class=ql-align-justify>附Github鏈接：</p><p class=ql-align-justify>https://github.com/vzhou842/rnn-from-scratch</p><p class=ql-align-justify><strong>7.1定義</strong></p><p class=ql-align-justify>首先，我們要明確一些定義：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4dcf72c26932453fa4d8f8176a0bb807><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify><strong>7.2 準備</strong></p><p class=ql-align-justify>接下來，我們需要編輯向前傳播階段並緩存一些數據，以便在反饋階段使用。在我們處理它的同時，我們還將為我們的反饋階段設置框架。大致如下所示：</p><pre class=ql-align-justify>rnn.pyclass RNN: # ...  def forward(self, inputs): ''' Perform a forward pass of the RNN using the given inputs. Returns the final output and hidden state. - inputs is an array of one hot vectors with shape (input_size, 1). ''' h = np.zeros((self.Whh.shape[0], 1))  self.last_inputs = inputs self.last_hs = { 0: h } # Perform each step of the RNN for i, x in enumerate(inputs): h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh) self.last_hs[i + 1] = h # Compute the output y = self.Why @ h + self.by  return y, h  def backprop(self, d_y, learn_rate=2e-2):''' Perform a backward pass of the RNN. - d_y (dL/dy) has shape (output_size, 1). - learn_rate is a float. ''' pass</pre><p class=ql-align-justify><strong>7.3 梯度</strong></p><p class=ql-align-justify>現在開始是數學登場的時候啦！我們要開始計算</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e8656aa08fcf4ed3a785df089ce8d15f><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>通過鏈式法則計算的過程就作為練習吧，結果如下：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6610a11d321e46aea59280da55d1b866><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/64e6c5394ee1459c807d7327b40260f6><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><pre class=ql-align-justify>main.py# Loop over each training examplefor x, y in train_data.items(): inputs = createInputs(x) target = int(y)  # Forward out, _ = rnn.forward(inputs) probs = softmax(out)  # Build dL/dy d_L_d_y = probs d_L_d_y[target] -= 1 # Backward rnn.backprop(d_L_d_y)</pre><p class=ql-align-justify>接下來，讓我們完成和的梯度計算，這僅用於將最終隱藏狀態轉換為RNN的輸出。 我們有：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c4630bfcedea4ea5b98ed3a0adcd367e><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>是最終的隱藏狀態。因此，</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/258eb18514514300b33fb40039dedda3><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify>同樣的，</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/158b93f866f743dfab89d5c77d33f5e6><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>我們現在可以開始應用backprop（）！</p><pre class=ql-align-justify>rnn.pyclass RNN: # ...  def backprop(self, d_y, learn_rate=2e-2): ''' Perform a backward pass of the RNN. - d_y (dL/dy) has shape (output_size, 1). - learn_rate is a float. ''' n = len(self.last_inputs)  # Calculate dL/dWhy and dL/dby.d_Why = d_y @ self.last_hs[n].T d_by = d_y</pre><p class=ql-align-justify>提示：我們之前在forward（）中創建了self.last_hs。</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c81850133da148aaab981c92a9f03c31><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/afb8337efc014c368d19ab6ee83e72bd><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>因為改變將影響每一個，這一切都會影響y和最終L。為了計算的梯度, 我們需要所有時間步長的反向傳播，這稱為反向傳播時間（BPTT）：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a113ecd4ea9e42e5913993d09a41539e><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/aa759978510e4839ab7f608178c12669><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><pre class=ql-align-justify>rnn.pyclass RNN: # …  def backprop(self, d_y, learn_rate=2e-2):‘’’Perform a backward pass of the RNN.- d_y (dL/dy) has shape (output_size, 1).- learn_rate is a float.‘’’n = len(self.last_inputs) # Calculate dL/dWhy and dL/dby.D_Why = d_y @ self.last_hs[n].Td_by = d_y # Initialize dL/dWhh, dL/dWxh, and dL/dbh to zero.D_Whh = np.zeros(self.Whh.shape)d_Wxh = np.zeros(self.Wxh.shape)d_bh = np.zeros(self.bh.shape) # Calculate dL/dh for the last h.d_h = self.Why.T @ d_y # Backpropagate through time.For t in reversed(range(n)): # An intermediate value: dL/dh * (1 – h^2) temp = ((1 – self.last_hs[t + 1] ** 2) * d_h)  # dL/db = dL/dh * (1 – h^2) d_bh += temp # dL/dWhh = dL/dh * (1 – h^2) * h_{t-1} d_Whh += temp @ self.last_hs[t].T # dL/dWxh = dL/dh * (1 – h^2) * x d_Wxh += temp @ self.last_inputs[t].T # Next dL/dh = dL/dh * (1 – h^2) * Whh d_h = self.Whh @ temp # Clip to prevent exploding gradients.For d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]: np.clip(d, -1, 1, out=d) # Update weights and biases using gradient descent.Self.Whh -= learn_rate * d_Whhself.Wxh -= learn_rate * d_Wxhself.Why -= learn_rate * d_Whyself.bh -= learn_rate * d_bhself.by -= learn_rate * d_by</pre><p class=ql-align-justify>補充一些注意事項：</p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4919e750049140fd83b3b807bcbbe5ab><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>好啦！我們的RNN已經完成啦。</p><p class=ql-align-justify><strong>8. 高潮</strong></p><p class=ql-align-justify>終於等到了這一刻 - 讓我們測試RNN吧！</p><p class=ql-align-justify>首先，我們將編寫一個幫助函數來處理RNN的數據：</p><pre class=ql-align-justify>main.pyimport random def processData(data, backprop=True): ''' Returns the RNN's loss and accuracy for the given data. - data is a dictionary mapping text to True or False. - backprop determines if the backward phase should be run. ''' items = list(data.items()) random.shuffle(items)  loss = 0 num_correct = 0  for x, y in items: inputs = createInputs(x) target = int(y)  # Forward out, _ = rnn.forward(inputs) probs = softmax(out)  # Calculate loss / accuracy loss -= np.log(probs[target]) num_correct += int(np.argmax(probs) == target)  if backprop: # Build dL/dy d_L_d_y = probs d_L_d_y[target] -= 1  # Backward rnn.backprop(d_L_d_y)  return loss / len(data), num_correct / len(data)現在，我們可以完成一個訓練的循環：main.py# Training loopfor epoch in range(1000): train_loss, train_acc = processData(train_data)  if epoch % 100 == 99: print('--- Epoch %d' % (epoch + 1)) print('Train:\tLoss %.3f | Accuracy: %.3f' % (train_loss, train_acc))  test_loss, test_acc = processData(test_data, backprop=False) print('Test:\tLoss %.3f | Accuracy: %.3f' % (test_loss, test_acc))</pre><p class=ql-align-justify>運行 main.py應該會得到如下輸出：</p><pre class=ql-align-justify>--- Epoch 100Train: Loss 0.688 | Accuracy: 0.517Test: Loss 0.700 | Accuracy: 0.500--- Epoch 200Train: Loss 0.680 | Accuracy: 0.552Test: Loss 0.717 | Accuracy: 0.450--- Epoch 300Train: Loss 0.593 | Accuracy: 0.655Test: Loss 0.657 | Accuracy: 0.650--- Epoch 400Train: Loss 0.401 | Accuracy: 0.810Test: Loss 0.689 | Accuracy: 0.650--- Epoch 500Train: Loss 0.312 | Accuracy: 0.862Test: Loss 0.693 | Accuracy: 0.550--- Epoch 600Train: Loss 0.148 | Accuracy: 0.914Test: Loss 0.404 | Accuracy: 0.800--- Epoch 700Train: Loss 0.008 | Accuracy: 1.000Test: Loss 0.016 | Accuracy: 1.000--- Epoch 800Train: Loss 0.004 | Accuracy: 1.000Test: Loss 0.007 | Accuracy: 1.000--- Epoch 900Train: Loss 0.002 | Accuracy: 1.000Test: Loss 0.004 | Accuracy: 1.000--- Epoch 1000Train: Loss 0.002 | Accuracy: 1.000Test: Loss 0.003 | Accuracy: 1.000</pre><p class=ql-align-justify>我們自己製造的RNN也不錯。</p><p class=ql-align-justify>想親自嘗試或修補這些代碼？你也可以在Github上找到。</p><p class=ql-align-justify>附鏈接：</p><p class=ql-align-justify>https://github.com/vzhou842/rnn-from-scratch</p><p class=ql-align-justify><strong>9. 總結</strong></p><p class=ql-align-justify>本文中，我們完成了迴歸神經網絡的演練，包括它們是什麼，它們如何工作，為什麼它們有用，如何訓練它們以及如何實現它們。不過，你還可以做更多的事情：</p><ul><li class=ql-align-justify>瞭解長短期記憶網絡（LSTM），這是一個更強大和更受歡迎的RNN架構，或關於LSTM的著名的變體--門控循環單元（GRU）。</li><li class=ql-align-justify>通過恰當的ML庫（如Tensorflow，Keras或PyTorch），你可以嘗試更大/更好的RNN。</li><li class=ql-align-justify>瞭解雙向RNN，它可以處理前向和後向序列，因此輸出層可以獲得更多信息。</li><li class=ql-align-justify>嘗試像GloVe或Word2Vec這樣的Word嵌入，可用於將單詞轉換為更有用的矢量表示。</li><li class=ql-align-justify>查看自然語言工具包（NLTK），這是一個用於處理人類語言數據的Python庫</li></ul><p class=ql-align-justify><br></p><p class=ql-align-justify>原文標題：</p><p class=ql-align-justify>An Introduction to Recurrent Neural Networks for Beginners</p><p class=ql-align-justify>原文鏈接：</p><p class=ql-align-justify>https://victorzhou.com/blog/intro-to-rnns/</p><p class=ql-align-right>編輯：於騰凱</p><p class=ql-align-right>校對：楊學俊</p><p class=ql-align-justify><strong>譯者簡介</strong></p><div class=pgc-img><img alt=菜鳥必備的循環神經網絡指南（附鏈接） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/73b93b6bac1f4de6babdd47b1b33bf2f><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>王雨桐</strong>，UIUC統計學在讀碩士，本科統計專業，目前專注於Coding技能的提升。理論到應用的轉換中，敬畏數據，持續進化。</p><p class=ql-align-center><strong>— 完 —</strong></p><p class=ql-align-justify>關注清華-青島數據科學研究院官方微信公眾平臺“<strong>THU數據派</strong>”及姊妹號“<strong>數據派THU</strong>”獲取更多講座福利及優質內容。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>菜鳥</a></li><li><a>必備</a></li><li><a>循環</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f0ff6432.html alt=鋼結構必備知識38問 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f0ff6432.html title=鋼結構必備知識38問>鋼結構必備知識38問</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bb258a5a.html alt=鋼結構必備知識38問，你的晉級之路！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1535975955779bcac330762 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bb258a5a.html title=鋼結構必備知識38問，你的晉級之路！>鋼結構必備知識38問，你的晉級之路！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/32c82df2.html alt=熱水鍋爐房循環水泵選型建議 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/32c82df2.html title=熱水鍋爐房循環水泵選型建議>熱水鍋爐房循環水泵選型建議</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b4e33540.html alt="收藏 | 這些航測必備的知識點你瞭解嗎？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b4e33540.html title="收藏 | 這些航測必備的知識點你瞭解嗎？">收藏 | 這些航測必備的知識點你瞭解嗎？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02e1ffd2.html alt=臨床必備的石膏固定技術，你get了嗎？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/260a4e82375e46b29f0d7e4ebc7c2a01 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02e1ffd2.html title=臨床必備的石膏固定技術，你get了嗎？>臨床必備的石膏固定技術，你get了嗎？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/55165a07.html alt=老電工必備的六個基礎電路圖 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/23e99e5693c54df2955e819bb96bc0f5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/55165a07.html title=老電工必備的六個基礎電路圖>老電工必備的六個基礎電路圖</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/640ad953.html alt=電工必備：22個經典電路圖，老電工：都看懂就可以去考高級電工了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1537327298284fedcbce28b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/640ad953.html title=電工必備：22個經典電路圖，老電工：都看懂就可以去考高級電工了>電工必備：22個經典電路圖，老電工：都看懂就可以去考高級電工了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc667d44.html alt=不可不知！每個機床行家必備的軸承選型資料 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/887afde1-3463-49ab-958a-3d03ef126152 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc667d44.html title=不可不知！每個機床行家必備的軸承選型資料>不可不知！每個機床行家必備的軸承選型資料</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2c2d0ac7.html alt=工程造價必備：16套造價基礎講義+計量計價+識圖，輕鬆學造價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/eb9fa13af6284a158f15a13aec98fef2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2c2d0ac7.html title=工程造價必備：16套造價基礎講義+計量計價+識圖，輕鬆學造價>工程造價必備：16套造價基礎講義+計量計價+識圖，輕鬆學造價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/66d69fa2.html alt=懶人必備！小米有品上架和麵機：智能醒面 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RU85Fe4Gpp7qW8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/66d69fa2.html title=懶人必備！小米有品上架和麵機：智能醒面>懶人必備！小米有品上架和麵機：智能醒面</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b85ef9fc.html alt=科研必備“武器”之BOD分析儀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0574d78d5cc147668c9eefa86e773322 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b85ef9fc.html title=科研必備“武器”之BOD分析儀>科研必備“武器”之BOD分析儀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/48532629.html alt=循環⽔養殖指標-溶解氧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/56d1472f673a48fcb736dca88bf7b39c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/48532629.html title=循環⽔養殖指標-溶解氧>循環⽔養殖指標-溶解氧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1d9a5540.html alt=循環流化床鍋爐耐磨耐火材料都有哪些？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/85eb71ea22e548ff81c68a4c0216f09a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1d9a5540.html title=循環流化床鍋爐耐磨耐火材料都有哪些？>循環流化床鍋爐耐磨耐火材料都有哪些？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f833cb1e.html alt="技術 | 淺談循環流化床鍋爐大修時的防磨處理" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f833cb1e.html title="技術 | 淺談循環流化床鍋爐大修時的防磨處理">技術 | 淺談循環流化床鍋爐大修時的防磨處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/80eda0c9.html alt=工業循環冷卻水處理（三） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a8094522823a4a4fab20b39b9c4a062c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/80eda0c9.html title=工業循環冷卻水處理（三）>工業循環冷卻水處理（三）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>