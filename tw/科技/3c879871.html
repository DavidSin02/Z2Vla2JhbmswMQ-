<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>一文帶你讀懂 WaveNet：谷歌助手的聲音合成器 | 极客快訊</title><meta property="og:title" content="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/RFTJWBc7VmMmLL"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c879871.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/3c879871.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/3c879871.html><meta property="article:published_time" content="2020-10-29T21:10:03+08:00"><meta property="article:modified_time" content="2020-10-29T21:10:03+08:00"><meta name=Keywords content><meta name=description content="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/3c879871.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>一文帶你讀懂 WaveNet：谷歌助手的聲音合成器</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>本文為 AI 研習社編譯的技術博客，原標題 ：</p><p>WaveNet: Google Assistant’s Voice Synthesizer</p><p>作者 | <em>Janvijay Singh</em></p><p>翻譯 | 醬番梨、王立魚、莫青悠、Disillusion</p><p>校對、整理 | 菠蘿妹</p><p>原文鏈接：</p><p>https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1</p></blockquote><p><strong>一文帶你讀懂 WaveNet：谷歌助手的聲音合成器</strong></p><p><em>有沒有想過有可能使機器合成的人類聲音幾乎和人類本身的聲音一樣自然？ WaveNet使其成為可能。</em></p><p></p><h2><strong>語音合成. 波音拼接合成. 參數合成. 深度學習.</strong></h2><p>機器合成擬人化語音（文語轉換）的想法已經存在很長時間了。在深度學習出現之前，存在兩種主流的建立語音合成系統的方式，即波音拼接合成和參數合成。</p><p>在波音拼接合成的文語轉換中，它的思路就是通過收集一個人的一長列句子的發聲錄音，將這些錄音切割成語音單元，嘗試著將那些和最近提供的文本相匹配的語音單元進行拼接縫合，從而生成這文本對應的發聲語音。通過波音拼接合成產生的語音，對於那些文本已經存在於用於初始收集的錄音之中的部分，文語轉換後的語音聽上去比較自然，但是那些初次遇見的文本，就會聽上去有些異樣。除此之外，修飾聲音要求我們對整個新錄音集進行操作。反之在參數合成的文語轉換中，它的思路是通過參數物理模型（本質上來說就是一個函數）來模擬人類的聲道並使用記錄的聲音來調整參數。通過參數合成文語轉換生成的聲音聽上去沒有通過音波結合文語轉換生成的聲音那麼自然，但是這種方式更容易通過調整某些模型中的參數來修飾聲音。</p><p>近日來，隨著WavNet的面世，對我們來說以端對端（來自聲音記錄本身）的方式來生成未處理的聲音樣本成為可能，可以簡單的修飾聲音，更重要的是和現存的語音處理方式相比，得到的聲音明顯的更加自然。所有的一切都要感謝深度學習的出現。</p><p></p><h2><strong>為什麼WaveNet會讓人如此的激動？</strong></h2><p>為了能夠描繪出WaveNet和現存的語音合成方法的區別，採用了主觀5分平均意見分法（MOS）測試進行統計。在平均意見分測試中，提供給對象（人）從各個聲音合成系統中合成的聲音樣本，並被要求以5分制來評估樣本的自然度（1:很差 2:較差 3:一般 4:好 5:優秀）。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RFTJWBc7VmMmLL><p><em>用於主觀5分平均意見分法的聲音樣本分別從基於長短期記憶-循環神經網絡（LSTM-RNN）的參數合成，基於隱馬爾可夫模型（HMM）的語音單元集的波音拼接合成，和基於WaveNet的語音合成得到的。</em></p><p>從柱狀圖中可以清晰看到，WaveNet在5分制中得到了大概4.0分左右，很明顯是優於其他的系統基線的，並且非常接近真實的人類聲音。查閱了DeepMind’s blog 可以認識到在合成的語音的自然度方面這些方法的區別所在。除了能夠輸出合成的語音樣本，WaveNet能夠輕鬆的適應各種各樣的語音特性，如：文本，發言者特性等，來生成滿足我們需求的聲音。這使它更加的令人感到激動。</p><p></p><h2><strong>WaveNet. 生成式模型.</strong></h2><p>生成式模型。這是指什麼呢？給出的一般的未標記的數據點，一個生成式模型會嘗試去學習什麼樣的概率分佈可以生成這些數據點，目的是為了通過利用學習分佈來產生新的數據點（與輸入數據點相似）。生成式模型可以通過不同的方式對概率分佈建模，隱式（具有可處理或近似密度）或者顯式。當我們說一個生成式模型是顯式建模模型的話，意味著我們明確的定義概率分佈並嘗試去適配每一個輸入的未標記數據點。與它形成對比，一個隱式生成式模型學習一個概率分佈，可以直接取樣新數據點而不需要明確的定義。GANs（生成對抗網絡），目前深度學習領域的聖盃，就屬於隱式生成式模型。然而，WaveNet和它的表親Pixel CNNs/RNNs（像素卷積神經網絡模型/遞歸神經網絡模型） 都屬於顯示生成式模型。</p><p>WaveNet如何明確的建立概率分佈模型？WaveNet試圖對一個數據流X的聯合概率分佈建立模型，對數據流X中的每一個元素Xt的條件概率求乘積。因此對於一段未處理音波X = {X1, X2, X3 … XT}，構建的聯合概率函數如下：</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWBsGNx8oFJ><p>每一個樣本Xt 因此而受限於所有的先前時間步長的樣品。在一個時間步長上的觀察結果取決於先前時間步長的觀察結果（這就是我們試圖使用每一個條件分佈項去構建的模型），這看上去難道不像是一個時間序列預測模型嗎？事實上，WaveNet是一個自動迴歸模型。</p><p>我們要如何去對這些條件分佈項進行建模呢？RNs（遞歸神經網絡模型）或者LSTMs（長短記憶網絡模型）作為強有力的非線性時序模型是最顯而易見的選擇。事實上，像素遞歸神經網絡使用同樣的思路來生成與輸入的圖像相似的合成圖像。我們可以使用這種思路來生成合成語音嗎？語音是從至少16KHZ的頻率取樣，這意味著，每秒的音頻至少有16000個樣本。RNNs（遞歸神經網絡）或者LSTMs（長短記憶網絡）還未曾對如此長（大約10000時間步長序列）的時間依賴性進行建模，他們目前能建模的最長時間依賴性是100時間步長序列，因此這兩種模型並不能很好的適用於語音合成。我們能否適用CNN（卷積神經網絡）來處理呢？等一下，CNNs（卷積神經網絡模型）？如何做到呢？相似的思路已經被使用於像素卷積神經網絡模型中了。</p><p></p><h2><strong>卷積神經網絡模型. 因果卷積. 膨脹卷積.</strong></h2><p>為什麼我們要嘗試使用CNNs（卷積神經網絡模型）？CNNs（卷積神經網絡模型）訓練速度與RNNs（遞歸神經網絡模型）或者LSTMs（長短記憶網絡模型）相比是典型地更快速，尤其是應用於長的一維序列，因為與每一個掩模或過濾器的卷積位置相關的操作可以以一個並行，獨立的方式進行。更快的訓練速度。聽上去很棒！自迴歸（一個時間步長的輸出是隻依賴於先前時間步長的輸出而與未來時間步長的輸出無關）的性能如何呢？因果卷積在此轉化成行動。一維因果卷積可以輕易的通過左填充輸入的一維序列來執行，在這裡通過為卷積補充適量的0來得到一個可用的卷機。與RNNs（遞歸神經網絡模型）和LSTMs（長短記憶網絡模型）相比，因果卷積可以允許我們去對長的多的時間依賴性（也允許我們指定回看長度）進行建模。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWC54Apxd3i><p><em>因果卷積確保模型不會違反我們對數據構建的模型的規則</em></p><p>很好！我們已經可以輕易地處理自迴歸違規的問題。但是關於管理幾千個樣本序列的回看長度的問題呢（例如我們的模型在當前時間步長上畫一個關於輸出的卷機之前，回看至少一秒的音頻）？ 能想到的最簡單實現的方式就是將過濾器的規格增加到足夠可以回看適當長度，但是這種方式真的有效嗎？ 我認為這種做法會使模型減少非線性，這會導致模型難以學習複雜的暫時依賴性，從而限制了模型的性能。你想到的下一個想法可能是增加神經網絡的層數 。這種方法可能有效。但是計算上是不可能的，因為對輸出中的一個時間步長內的接受域大小或者回看長度，隨模型中的隱藏層數線性增長，而對於我們計算上來說是不希望有一個有著幾千個隱藏層的模型。現在我們要考慮的是限制隱藏層的數量、過濾器的大小和增加回看長度？我們將如何做到呢？膨脹卷積將會幫助我們。</p><p>膨脹卷積嘗試通過將過濾器應用在超過它本身長度的區域上和按特定步驟跳過輸入值的方式，來增加回看長度或者接受域大小。 這等同於一個卷積使用通過0來擴充原過濾器得到更大的過濾器但是顯然這種方式更加有效。在WaveNet中，多重膨脹卷積層一個個疊放來通過極少的層來獲得極大的接受域。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWCJEZMkStz><p><em>膨脹因果卷積層堆：加倍每層的膨脹因子會使接受域以 O(2^n)倍增。</em></p><p></p><h2><strong>Softmax（柔性最大傳輸函數）分佈. Mu-law 壓縮.</strong></h2><p>為了對條件概率見面，WaveNet採用softmax分佈（分類分佈）來替代其他的混合模型，分類分佈沒有對它的形狀進行假設，因此而更加靈活，更容易對任意分佈建模。 未處理音頻被作為16位整數值（-32,768...32,767）存儲，使用一個softmax層輸出概率分佈需要我們的模型在一個時間步長上輸出65,5535個數值。這會拉慢模型表現嗎？這確實會。我們可以做什麼來改善呢？減少位深度會起到作用。如果我們使用線性位深度減少（除以256）對低振幅樣本的影響會比對高振幅樣本的影響更大。 考慮一個初始值是32767的16位樣本，可取的最大正數值。轉化為8位，樣本值變為127（32767/256 = 127餘255），舍入誤差是255/32768。 這是一個小於1%的量化誤差。但是將這個誤差與最小量級的16位樣本，那些取值在0與255之間的樣本，獲得的量化誤差相比較。當最小量級的16位樣本簡化成8位的時候，轉化後的值會接近於0，誤差是100%。所以使用線性位深度縮減方法舍入，對低振幅樣本的影響會比對高振幅樣本的影響更大。 如果我們可以重新分配樣本數值，更多的量化等級在較低的振幅，少量的量化等級在較高的振幅，就可以減少量化誤差。這就是在WaveNet中使用Mu-law分佈（非線性量化）來代替使用簡單的線性量化的原因。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RFTJWNmIXXsJpA><p><em>執行Mu-law壓縮的表達式比使用線性量化的可以等到更優的重構輸出（更接近與原音頻） 。</em></p><p>在上面的表達式中，−1</p><p></p><h2><strong>選通激活函數. 跳躍連接和殘差連接.</strong></h2><p>非線性激活函數對於任何一個學習輸出與輸入之間的複雜關係的深度學習模型來說都是要素之一。RELU（線性單元）最初在WaveNet中被使用，但是在執行實驗後發現，對於WaveNet來說，使用一個非線性的tan-hyperbolic（tanh）函數選通sigmoid （S型）函數的激活函數效果更好。</p><p><em>在WaveNet中使用的選通激活函數表達式</em></p><p>在上面的表達式中，W 表示可許阿西過濾器，* 表示卷積算子，⊙表示同或數學運算符。殘差連接，不斷疊加底層和它上層的輸出，跳躍連接，直接將底層輸出疊加到輸出層，這兩者已經證實在減少神經網絡與訓練深層網絡的收斂時間方面是有效的。因此，如下圖所示，殘差連接已經在WaveNet的架構中被使用。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RFTJWOGARmAhg4><p><em>WaveNet架構：選通激活函數，跳躍連接，殘差連接</em></p><p></p><h2><strong>調節. 本地. 全局.</strong></h2><p>現在還沒有講到，我們如何根據演講者身份，相應文本等各種功能來調節輸出語音。WaveNet的輸出語音可以通過兩種方式進行調節：（1）全局調節，（2）單個特徵偏置輸出所有時間步驟，如說話者的身份或局部調節，具有多個特徵，實際上是不同的時間序列特徵，其在不同時間步驟偏置輸出，如語音的基礎文本。如果我們更正式地表達這一點，那麼這將意味著在實際模型中在條件分佈術語（本地條件中的Ht和全局調節中的H）中引入新參數。</p><p><em>在引入條件輸入之後修改條件分佈項</em></p><p>在本地調節中，調節輸入的時間序列可能具有比音頻更短的長度，並且對於局部調節，要求兩個時間序列必須具有相同的長度。為了匹配長度，我們可以使用轉置的CNN（一種可學習的上採樣方案）或其他上採樣方案來增加調節輸入的長度</p><p><em>引入偏差項h後的表達式</em></p><p>在上面的表達式中，V是可學習的線性投影，其基本上用於兩個目的變換h以校正尺寸並學習偏置輸出的正確權重。</p><p></p><h2><strong>很棒的模型. 快速的訓練. 緩慢的推理？</strong></h2><p>WaveNet的架構，無論我們到目前為止討論了什麼，都很好地捕獲了複雜的時間依賴性和條件。除此之外，高度並行化使訓練變得非常迅速。但是推理呢？由於時間步長的輸出依賴於前一個時間步長的輸出，所以對新音頻的採樣本質上是連續的。產生1秒的輸出大約需要1分鐘的GPU時間。如果谷歌將這個模型部署到他們的助手上，那麼對於像“嘿谷歌!天氣怎麼樣?”這樣簡單的問題也得花上幾個小時來思考。那麼他們是如何縮短推理時間的呢？IAF就是答案。</p><p></p><h2><strong>規範化流程 IAF</strong></h2><p>什麼是規範化流程？規範化流程是一系列轉換的過程，可以學習從從簡單概率密度（如高斯）到豐富的複雜分佈的映射（雙射）。設想一下，如果你從概率分佈q（z）和概率分佈q（x）中採樣中得到足夠多的點，那麼這個規範化流程可以用來學習轉換過程，也就是從q（x）採樣的點映射到其在分佈q中的相應映射（Z）的過程。這個過程如何完成的？讓我們先考慮有一個轉換f，f是一個一個可逆和平滑的映射。如果我們使用此映射來轉換具有分佈q（z）的隨機變量z，那麼，我們得到的隨機變量z'= f（z）具有分佈q（z'）：</p><p>為了向你更加直觀地介紹，我們是如何為變換後的隨機變量的分佈得出這個表達式，請查看Eric Jang的這篇博客文章。一個轉換是否足夠？實際上，我們可以通過組合幾個簡單的變換，並連續應用上述表達式來構造任意複雜的密度。通過將分佈q0通過K變換鏈fk連續變換隨機變量z0而獲得的密度qK（z）是：</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWW03qqYhr0><p>這些變換中的每一個都可以使用矩陣乘法（具有可學習的值）輕鬆建模，然後是非線性，例如ReLU。然後，通過優化在變換的概率分佈qK（z）下從q（x）採樣的點的似然性（對數似然），使用任何您喜歡的優化算法來更新變換的可學習參數。這將使分佈qK（z）與q（x）非常相似，從而學習從q（z）到q（x）的適當映射。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RFTJWWC5NrRq1B><p><em>經過一系列可逆變換的分佈流</em></p><p>規範化流程的想法如何幫助我們快速推理？請記住，WaveNet是一個生成模型，它除了嘗試學習可能產生訓練數據的概率分佈之外，什麼都不做。因為它是一個明確定義的生成模型（具有易處理的密度），我們可以很容易地學習一個可以映射簡單點的轉換，像Gaussian這樣的分佈到WaveNet學習的複雜分類分佈。如果學習到的具有快速推理方案的規範化流程，我們可以輕鬆地對WaveNet中的慢推理問題進行排序。 IAF（反向自迴歸流）可以很好地適應這種想法。 在IAF中，我們的想法是首先從z~Logistic（0，I）中抽取隨機樣本，然後將以下變換應用於繪製的樣本。</p><p><em>zt上的簡單縮放和移位變換，其中縮放因子（s）和移位因子（μ）通過使用可學習參數（θ）和來自先前時間步長的輸入樣本z中的值來計算</em></p><p>為了輸出時間步長xt的正確分佈，逆自迴歸流 基於噪聲輸入z1到zt-1的序列，可以隱含地推斷它之前的time-step x1到xt-1的序列。噪聲輸入序列可以在給定zt的情況下並行輸出所有xt。下面的圖片會讓事情變得更加清晰（注意改變記譜法）。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWWdIS7JCXf><p><em>在逆自迴歸流中，可以並行計算不同時間步的輸出，因為時間步的輸出不依賴於先前時間步的輸出</em></p><p>太棒啦！ IAF具有快速推理方案（甚至可以並行計算條件概率），但它們訓練較慢。為什麼比較慢呢？因為如果你給我們一個新的數據點並要求評估密度，我們需要恢復u，這個過程固有的順序很慢。 Parallel WaveNet利用這一事實，提出了使用簡單的WaveNet（教師WaveNet）培訓IAF（學生WaveNet）的概念。</p><p></p><h2><strong>並行. 更快. WaveNet.</strong></h2><p>與WaveNet差不多，我們的想法是利用IAF具有快速推理方案的特性。因此，在第一階段，我們訓練出一個簡單的WaveNet模型（我們稱之為教師培訓）。在第二階段，我們凍結教師WaveNet的權重，並利用它來訓練IAF（Student Distillation）。我們的想法是先從z~Logistic（0，I）中抽取一個隨機樣本，然後以並行方式傳遞給IAF。這將為我們提供轉換分佈和相關條件概率的要點。我們的想法是通過簡單的教師WaveNet將這一點轉換為轉換後的分佈，這將產生關於已經訓練過的教師WaveNet的條件概率。然後我們嘗試最小化從任一模型接收的條件概率之間的KL-差異。這將允許IAF（學生WaveNet）學習與其教師幾乎相似的概率分佈，並且結果驗證了這一事實，因為從教師和學生WaveNet收到的輸出之間的5級MOS分數幾乎可以忽略不計。</p><img alt="一文帶你讀懂 WaveNet：谷歌助手的聲音合成器" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RFTJWbFHHFjIhX><p><em>Parallel WaveNet的培訓程序</em></p><p>部署的速度是否足夠快？是的。實際上，它能夠以比實時快20倍的速度生成語音樣本。但是仍然存在一個問題，每當我們需要重新訓練我們的模型時，我們首先會訓練WaveNet教師然後訓練學生WaveNet。此外，學生WaveNet的表現在很大程度上取決於教師WaveNet的培訓情況。但總的來說，進行部署是件好事。</p><p><strong>“理論是廉價的，請給我代碼。（實踐出真知）”</strong></p><p>在網上有許多的關於簡單的WaveNet的實踐可以使用，但是關於並行實踐目前還沒有找到。</p><p>1.Keras實踐</p><p>2.PyTorch實踐</p><p>3.TensorFlow實踐（這是目前網上可被使用的實踐中被引用借鑑最多的）</p><p><strong>參考文獻：</strong></p><ol><li><p>Audio Companding.</p></li><li><p>Convolutional Layers in NLP tasks.</p></li><li><p>Dilated Convolutions.</p></li><li><p>Normalising Flows: Tutorial by Eric Jang - Part 1, Part 2. Variational Inference with Normalizing Flows (Paper).</p></li><li><p>Deep Voice: Real-time Neural Text-to-Speech (Paper): Appendix is pretty useful to understand WaveNet.</p></li><li><p>WaveNet: A generative model for raw audio (Paper).</p></li><li><p>Parallel WaveNet: Fast High-Fidelity Speech Synthesis (Paper).</p></li><li><p>PixelCNN, Wavenet & Variational Autoencoders — Santiago Pascual — UPC 2017.</p></li></ol><p>想要繼續查看該篇文章相關鏈接和參考文獻？</p><p>長按鏈接點擊打開或點擊【一文帶你讀懂WaveNet：谷歌助手的聲音合成器】：</p><p>https://ai.yanxishe.com/page/TextTranslation/1228</p><p><strong>AI研習社每日更新精彩內容，觀看更多精彩內容：雷鋒網雷鋒網雷鋒網</strong></p><p></p><h3>使用樹莓派和Python實現目標檢測</h3><h3>傑出數據科學家的關鍵技能是什麼？</h3><h3>初學者怎樣使用Keras進行遷移學習</h3><h3>如果你想學數據科學，這 7 類資源千萬不能錯過</h3><p><strong>等你來譯：</strong></p><p></p><h3>深度學習目標檢測算法綜述</h3><h3>一文教你如何用PyTorch構建 Faster RCNN</h3><h3>高級DQNs：利用深度強化學習玩吃豆人遊戲</h3><h3>用於深度強化學習的結構化控制網絡 （ICML 論文講解）</h3></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>WaveNet</a></li><li><a>聲音</a></li><li><a>合成器</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca8037a5.html alt="1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/85515822d72a46eda621433ce5df7dfd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca8037a5.html title="1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom">1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html alt=聲音錄製，用軟件算法模擬硬件也能出專業效果 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15374046796064ae0d9cd60 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html title=聲音錄製，用軟件算法模擬硬件也能出專業效果>聲音錄製，用軟件算法模擬硬件也能出專業效果</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8c6ba3d5.html alt=聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/6f35099874d14909bcbded3a8e7d8a8e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8c6ba3d5.html title=聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？>聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e7cc472b.html alt=快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RMb7ATOIoTL1Cm style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e7cc472b.html title=快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！>快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/46550ad1.html alt=障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15345657066257a9443fa45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/46550ad1.html title=障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色>障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b792d28f.html alt=露珠滴落的聲音，像一首搖籃曲 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/402dd6727b364918b84928933b8154b7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b792d28f.html title=露珠滴落的聲音，像一首搖籃曲>露珠滴落的聲音，像一首搖籃曲</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3fa5a492.html alt="票房破9億！國產《哪吒》火了 他的聲音竟來自這位小姐姐" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RXf10IJ3IyW9Vs style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3fa5a492.html title="票房破9億！國產《哪吒》火了 他的聲音竟來自這位小姐姐">票房破9億！國產《哪吒》火了 他的聲音竟來自這位小姐姐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2c6d665.html alt=如何保護好嗓子？掌握這6個小訣竅，讓你的聲音變得更“動聽” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/2096fec6-322c-4cac-942e-cfa9c0ac5c46 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2c6d665.html title=如何保護好嗓子？掌握這6個小訣竅，讓你的聲音變得更“動聽”>如何保護好嗓子？掌握這6個小訣竅，讓你的聲音變得更“動聽”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3f5b6440.html alt=追求聲音的極致：詳解著名房間聲場自動校準系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/6950/8391092992 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3f5b6440.html title=追求聲音的極致：詳解著名房間聲場自動校準系統>追求聲音的極致：詳解著名房間聲場自動校準系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9cc78929.html alt=如何讓聲音不打架——詳解“均衡器”的使用方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RtWUkr5HBKPEpZ style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9cc78929.html title=如何讓聲音不打架——詳解“均衡器”的使用方法>如何讓聲音不打架——詳解“均衡器”的使用方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1909a26b.html alt=【智庫聲音】美軍未來電子戰能力建設淺析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/SF9bBi1BWwD69v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1909a26b.html title=【智庫聲音】美軍未來電子戰能力建設淺析>【智庫聲音】美軍未來電子戰能力建設淺析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/53aaefa7.html alt="隨身聲音再進化：SONY 索尼 PHA-1A 耳機放大器" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6332/1401310711 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/53aaefa7.html title="隨身聲音再進化：SONY 索尼 PHA-1A 耳機放大器">隨身聲音再進化：SONY 索尼 PHA-1A 耳機放大器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3a839913.html alt=如何無損壓縮聲音？GoldWave常識普及來了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7c0d386bb738480aa71cd86948c3395d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3a839913.html title=如何無損壓縮聲音？GoldWave常識普及來了>如何無損壓縮聲音？GoldWave常識普及來了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4b3b7e26.html alt=「發｜聲音」鄒忠平：推動中國特大型高爐技術站上世界之巔 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/70aca99c3e9f48369f3d01a1995cf199 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4b3b7e26.html title=「發｜聲音」鄒忠平：推動中國特大型高爐技術站上世界之巔>「發｜聲音」鄒忠平：推動中國特大型高爐技術站上世界之巔</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4420c981.html alt=「兩會聲音」組建我國涉核領域國家級重點實驗室勢在必行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RcbTx0w16HIwoa style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4420c981.html title=「兩會聲音」組建我國涉核領域國家級重點實驗室勢在必行>「兩會聲音」組建我國涉核領域國家級重點實驗室勢在必行</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>