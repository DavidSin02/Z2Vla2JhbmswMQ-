<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>NLP基礎-通用句子向量漫談 | 极客快訊</title><meta property="og:title" content="NLP基礎-通用句子向量漫談 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/db54188d47524055b7a45d90aed407ac"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/45cbe488.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/45cbe488.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="NLP基礎-通用句子向量漫談"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/45cbe488.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>NLP基礎-通用句子向量漫談</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1><strong>背景</strong></h1><p>​ 近期業務需要使用文本上下文語義特徵，而將文本進行編碼和表徵是NLP最核心的技術之一，於是調研了表徵文本的相關技術，總結如下, 以饗後人。</p><p>混沌未開</p><p>​ 在word2vec誕生之前，NLP中並沒有一個統一的方法去表示一段文本。從one-hot表示一個詞到用bag-of-words來表示一段文本，從k-shingles把一段文本切分成一些文字片段到漢語中用各種序列標註方法將文本按語義進行分割，從tf-idf中用頻率的手段來表徵詞語的重要性到text-rank中借鑑了page-rank的方法來表徵詞語的權重，從基於SVD純數學分解詞文檔矩陣的LSA，到pLSA中用概率手段來表徵文檔形成過程並將詞文檔矩陣的求解結果賦予概率含義，再到LDA中引入兩個共軛分佈從而完美引入先驗，句子表徵走過了漫長的黑暗時期。</p><p>一絲曙光</p><p>​ 2003年Bengio的經典論文《A Neural Probabilistic Language Model》打開了一絲曙光， 經網絡語言模型（NNLM）的第一層參數當做詞的分佈式表徵時，能夠很好的獲取詞語之間的相似度，從而構造句子表徵。自NNLM於2003年被提出後，後面又出現了很多類似和改進的工作，諸如LBL, C&W和RNNLM模型等等，這些方法主要從兩個方面去優化NNLM的思想，其一是NNLM只用了左邊的n-1個詞，如何利用更多的上下文信息便成為了很重要的一個優化思路（如Mikolov等人提出的RNNLM）；其二是NNLM的一個非常大的缺點是輸出層計算量太大，如何減小計算量使得大規模語料上的訓練變得可行，這也是工程應用上至關重要的優化方向（如Mnih和Hinton提出的LBL以及後續的一系列模型）。</p><p>​ 2013年， Tomas Mikolov 於論文《Efficient estimation of word representations in vector space》提出CBOW和Skip-gram模型，模型使用了Hierarchical Softmax或者Negative Sampling等優化方法， 並開源成為word2vec工具。其後又出現了考慮詞共現的GloVe， 基於監督訓練信號的fastText。至此為止，大多數NLP任務均為先預訓練詞向量，然後對詞向量求均值獲得句子表徵 （通過監督信號使用TextCNN/RNN等也可以獲得任務相關句子表徵，本文只探討通用句子表徵）。</p><p>​ 除了簡單的求平均之外， 在word2vec開源隨後的第一年，即2014年，Mikolov在他和另一位作者合作的一篇論文《Distributed Representations of Sentences and Documents》中，提出了可以借鑑word2vec思想的兩種結構：PV-DM和PV-DBOW，分別對應word2vec中的CBOW和Skip-gram。 2015年，多倫多大學的Kiros等人提出了一個很有意思的方法叫Skip-thoughts，同樣也是借鑑了Skip-gram的思想。Skip-thoughts直接在句子間進行預測，也就是將Skip-gram中以詞為基本單位，替換成了以句子為基本單位，具體做法就是選定一個窗口，遍歷其中的句子，然後分別利用當前句子去預測和輸出它的上一句和下一句。2018年，Google Brain在Skip-thoughts的基礎上將這一思想做了進一步改進，把Skip-thoughts的生成任務改進成為了一個分類任務，具體說來就是把同一個上下文窗口中的句子對標記為正例，把不是出現在同一個上下文窗口中的句子對標記為負例。 此外，在ICLR 2017 上論文《A Simple but Tough-to-Beat Baseline for Sentence Embeddings》是一個很好句子表徵算法，算法的大致描述如下：選擇一個流行的詞嵌入方法，通過詞向量的線性的加權組合對一個句子進行編碼，並且刪除共有的部分（刪除它們的第一個主成分上的投影）。</p><p>​ 除了Skip-thoughts和Quick-thoughts這兩種不需要人工標記數據的模型之外，2017年Facebook提出的InferSent框架，先設計一個模型在斯坦福的SNLI數據集上訓練，之後將訓練好的模型當做特徵提取器獲得句子向量， 此外2018年ICLR論文《Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning》提出了利用四種不同的監督任務來聯合學習句子的表徵, Google 在 《Universal Sentence Encoder》利用Transformer和DAN提取通用句子表徵。</p><p>​ 對中文而言, 騰訊於NAACL2018發表論文《Directional Skip-Gram: Explicitly Distinguishing Left and Right Context for Word Embeddings》對Skipgram增加詞共現和方向信息(窗口中詞在左邊還是右邊)， 併發布號稱最大的中文詞向量。作為類比推理論文《Analogical Reasoning on Chinese Morphological and Semantic Relations》的副產品，學者們也發佈了100+各種中文語料各種模型預訓練的詞向量。此外，也有螞蟻的同學發表在AAAI2018的高分論文《cw2vec: Learning Chinese Word Embeddings with Stroke n-gram Information》，提出基於筆畫的詞向量訓練方法見一筆一畫之間的奧祕，針對此方法也有不同聲音見是否需要一筆一畫。 類似的, 香儂科技發表論文《Glyce: Glyph-vectors for Chinese Character Representations》提出在深度學習的框架下使用中文字形信息。 然而 針對此方法也有很多不同的聲音。</p><p>​ 詞向量，句子表徵五花八門，是不是最新的就是最好的呢，如何選擇呢，Facebook 在EMNLP2018 發表論文《Dynamic Meta-Embeddings for Improved Sentence Representations》允許NLP模型動態選擇在給定環境中表現最佳的字嵌入算法 (其實這個算法並不能)。</p><p>巨人肩膀</p><p>ELMo</p><p>​ AllenNLP發表論文《Deep contextualized word representations》（NAACL2018 best paper）首次提出了ELMo，ELMo的基本框架便是2-stacked biLSTM + Residual的結構，不過和普通RNN結構的不同之處在於，ELMo借鑑了2016年Google Brain的Rafal Jozefowicz等人發表的一篇論文《Exploring the Limits of Language Modeling》，其主要改進在於輸入層和輸出層不再是word，而是變為了一個char-based CNN結構。ELMo並沒有本質上的創新，連模型也基本是引用和拼接別人的工作。</p><p>ULMFit</p><p>​ ELMo同期，有另一個來自FastAI的非常驚豔的工作。在論文《Universal Language Model Fine-tuning for Text Classification》中，他們提出了ULMFit結構，基本的思路也是預訓練完成後去具體任務上進行finetune。ULMFit主要可以分為三個階段，分別是在大規模語料集上先預訓練，然後再將預訓練好的模型在具體任務的數據上重新利用語言模型來finetune一下（這是第一次finetune，叫做LM finetune），爾後再根據具體任務設計的一個模型上，將預訓練好的模型當做這個任務模型的多層，再一次finetune。所使用的模型也非原始的LSTM而是AWD-LSTM。此方法來自Salseforce 論文《Regularizing and Optimizing LSTM Language Models》。</p><p>GPT1.0</p><p>​ OpenAI於2018年6月發佈論文《Improving Language Understanding by Generative Pre-Training》,核心思想為: 1) 預訓練階段採用“單向語言模型”作為訓練任務，把語言知識編碼到Transformer裡。2) 在第一階段訓練好的模型基礎上，通過Finetuning來做具體的NLP任務。GPT 1.0本身效果就很好，因為不會PR，默默無聞。</p><div class=pgc-img><img alt=NLP基礎-通用句子向量漫談 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/db54188d47524055b7a45d90aed407ac><p class=pgc-img-caption></p></div><p>BERT</p><p>​ 獲得NAACL2019 best paper的BERT模型不亞於NLP的明星， BERT站在無數巨人之上， 具有以下特點1）利用了真雙向的Transformer2）改進了普通語言模型成為完形填空式的Mask-LM3）利用Next Sentence Prediction任務學習句子級別信息4）進一步完善和擴展了GPT中設計的通用任務框架。由於BERT模型過於龐大，針對BERT訓練出現了若干優化方案 1） 谷歌的LAMB 優化器將 BERT 預訓練的批量大小擴展到 64K，且不會造成準確率損失。2 ）阿里雲的Perseus-BERT, 採用統一分佈式通信框架、混合精度、XLA編譯器優化等技術。</p><div class=pgc-img><img alt=NLP基礎-通用句子向量漫談 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8b7083b20dcf41db9d1c217dab77f447><p class=pgc-img-caption></p></div><p>GPT2.0</p><p>​ 號稱能續寫紅樓夢後40回， OpenAI （CloseAI）發佈的GPT2.0 模型。 本質上，GPT2.0做了兩件事。首先把Transformer模型參數擴容，其次找更大數量的無監督訓練數據。同BERT相比，最大的差異在於它是單向的。</p><div class=pgc-img><img alt=NLP基礎-通用句子向量漫談 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5545d442c5994dd5b1bcc6a0202f1b39><p class=pgc-img-caption></p></div><p>MT_DNN</p><p>​ 微軟的MT-DNN 通過整合BERT擴展了微軟在 2015 年提出的多任務深度神經網絡模型。MT-DNN 模型較低層在所有任務中共享，而頂層是針對任務特定的。首先，輸入 X（一個句子或一對句子）在 l_1 層中被表示為嵌入向量序列，每個單詞都對應一個嵌入向量序列。然後，基於變換器的編碼器捕獲每個單詞的上下文信息，並在 l_2 層中生成共享的上下文嵌入向量。最後，額外的特定任務層針對每個任務生成特定任務表示，隨後是分類、相似性評分或相關性排序所必需的操作。MT-DNN 使用 BERT 將其共享層初始化，然後通過 MTL 對其進行優化。一句話來說，MT_DNN就是多任務學習加BERT。</p><div class=pgc-img><img alt=NLP基礎-通用句子向量漫談 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/cddd401bd08641a893856f9426bc8202><p class=pgc-img-caption></p></div><p>ERINE</p><p>​ 百度改進了BERT，提出ERNIE模型通過建模海量數據中的實體概念等先驗語義知識，學習真實世界的語義關係。具體來說，ERNIE模型通過對詞、實體等語義單元的掩碼，使得模型學習完整概念的語義表示。相較於 BERT 學習原始語言信號，ERNIE直接對先驗語義知識單元進行建模，增強了模型語義表示能力。ERINE實際效果（中文問答）也比BERT稍好。</p><div class=pgc-img><img alt=NLP基礎-通用句子向量漫談 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/23e08ebce2a2485298d25298f93d46cd><p class=pgc-img-caption></p></div><p>其他</p><p>2018年至今NLP領域產出了非常多成果。 如谷歌針對超長上下文句子的Tranformer XL， 斯坦福和谷歌的新型自訓練算法 Cross-View Training (CVT)，結合了預訓練詞向量和自訓練算法。Facebook提出跨語言預訓練模型XLM, 其實就是跨語言的BERT。 此外，引入圖像等跨模態數據也是增強句子表徵的一個方向。論文《Image-Enhanced Multi-Level Sentence Representation Net for Natural Language Inference》通過將圖像信息引入到自然語言推理中，利用額外補充的信息對句子語義進行增強，從而更加準確地理解句子語義。然而，此文章對圖像的利用、圖像的有效性分析等都值得改進。</p><p>小結</p><p>2018年以來NLP取得的諸多突破是站在巨人的肩膀依託海量的數據資源上取得的, MT_DNN 和ERINE是在BERT基礎上的進一步改進。以上預訓練模型標誌NLP進入ImageNet時代，帶來的優勢如下：</p><ol><li>近乎無限量的優質數據</li><li>無需人工標註，非監督/半監督</li><li>一次學習多次複用，多任務學習</li><li>學習到的表徵可在多個任務中進行快速遷移，遷移學習</li></ol><p>展望未來</p><p>機會與挑戰並存</p><ol><li>OOV (字級別不存在OOV)及新詞Embedding獲取。現實NLP場景中很可能會由於詞表不夠大出現OOV或新詞不在詞表中，如何獲取此類詞的Embedding進而獲取句子表徵仍然是一個值得研究的問題，現有的方案多采用隨機初始化或語義相近的字向量拼接加噪聲等方式，也許可以通過挖掘詞之間的關聯結合GCN等方式。</li><li>很多詞在不同的場景或不同的時間會有不同的含義，甚至相同的上下文下，相同的詞在不同的時間都具有不同的含義，也會影響句子都表徵，詞表徵的演化也是一個挑戰，也許可以對句子加入時間編碼。</li><li>Finetune真的是萬能的嗎，從零開始訓練句子表徵也許也不錯。 現實NLP問題，有監督的模型大多都比非監督模型效果好，那是否真的需要預訓練呢？ 從零開始訓練是否就一定比Finetune差呢，在CV領域何愷明發表論文《Rethinking ImageNet Pre-training》質疑ImageNet 預訓練， NLP又是怎麼樣呢？</li><li>句子表徵缺乏常識信息，ERNIE在某些程度加入了額外的信息，如何更加顯式的加入語義/句法等信息（BERT等模型隱式得到了語義語法信息）降低模型訓練成本 （預訓練和Finetune成本非常高）仍是嚴峻挑戰。</li><li>新模型複雜模型並不定是最優的，某些簡單的模型如GLoVe在一些特殊的任務中可以獲得媲美於BERT的效果，no free lunch， 對不同的問題需要使用相應的句子表徵，Meta-Embedding也許是解決之道。</li></ol><p>未來方向</p><ol><li>引入領域知識、語法句法知識、業務知識、常識，訓練更好的句子表徵。領域知識包含知識圖譜等結構化數據，給定一個知識圖譜和一個自然語言問題，如何將該問題轉化為機器能夠理解和執行的語義表示，受到了來自全世界研究者的廣泛關注和深入探索。</li><li>Meta-learning。對於低資源的語言或長尾問題，樣本稀缺，Meta-learning作為解決Few-shot問題的方法之一已在CV領域取得了諸多進展，而在NLP領域仍存在廣闊的空間。</li><li>圖神經網絡。圖作為一個可推理，研究人員開始研究如何將卷積神經網絡遷移到圖數據上，湧現出ChevNet、MoNet、GCN、GAT等一系列方法，在基於圖的半監督分類和圖表示學習等任務中表現出很好的性能。句子本身是具有語法結構信息的，基於圖神經網絡的句子表徵已經在一些特定的任務如事件抽取、關係抽取取得了不錯的效果，是否有進一步的擴展空間值得研究。</li><li>多模態。嬰兒在掌握語言功能前，首先通過視覺、聽覺和觸覺等感官去認識並瞭解外部世界。語言並不是人類在幼年時期與外界進行溝通的首要手段。因此，構建通用人工智能也應該充分地考慮自然語言和其他模態之間的互動，並從中進行學習，這就是多模態學習。</li><li>可解釋性。詞、句子表徵一直都是大黑盒，雖然存在一些學者對向量維度進行可解釋信性研究，然而如何平衡可解釋和性能，如何將NLP模型預測結果解釋給客戶是一個方向。</li></ol><p>P.S.</p><p>本文未覆蓋任務相關句子表徵訓練，NLP方法太多，有所遺漏見諒</p><p>有用的github鏈接: https://github.com/Separius/awesome-sentence-embedding</p><p>中文詞向量:https://github.com/Embedding/Chinese-Word-Vectors</p><p>BERT:https://github.com/google-research/bert/</p><p>ERINE: https://github.com/PaddlePaddle/LARK/tree/develop/ERNIE</p><p>Tencent word embedding: https://ai.tencent.com/ailab/nlp/embedding.html</p><p>MT_DNN: https://github.com/namisan/mt-dnn</p><p>感謝師兄: 王俞霖</p><p>感謝團隊成員: 賈強槐、 楊起騰、張衛星、董良、高楓、</p><p>感謝各位老闆: 華能威、王祥志</p><p>參考文獻:</p><ol><li>https://zhuanlan.zhihu.com/p/50443871</li><li>Rethinking ImageNet Pre-training</li><li>Dynamic Meta-Embeddings for Improved Sentence Representations</li><li>Improving Language Understanding by Generative Pre-Training</li><li>Directional Skip-Gram: Explicitly Distinguishing Left and Right Context for Word Embeddings</li><li>Analogical Reasoning on Chinese Morphological and Semantic Relations</li><li>Image-Enhanced Multi-Level Sentence Representation Net for Natural Language Inference</li><li>Efficient estimation of word representations in vector space</li><li>A Neural Probabilistic Language Model</li><li>Universal Sentence Encoder</li><li>Universal Language Model Fine-tuning for Text Classification</li></ol><p>轉自：https://yq.aliyun.com/articles/700006?spm=a2c4e.11155435.0.0.dad0283bzo6SFr</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>NLP</a></li><li><a>基礎</a></li><li><a>漫談</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/cca53f5.html alt=NLP學習（一）—基礎篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bbd1c98e4e784228b81dcf6c82b7a500 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cca53f5.html title=NLP學習（一）—基礎篇>NLP學習（一）—基礎篇</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/aa09268.html alt=漫談品牌的生理和心理基礎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RiEkWhWFpkZDp3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/aa09268.html title=漫談品牌的生理和心理基礎>漫談品牌的生理和心理基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d006e47.html alt=鋼結構設計基礎知識問答 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/63b48928-d7cd-4346-b80f-4f77015517c1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d006e47.html title=鋼結構設計基礎知識問答>鋼結構設計基礎知識問答</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/775df7fb.html alt=素描五官基礎知識，學素描的同學可參考 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/99b7762898d34e2f9a667c431fc7da6b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/775df7fb.html title=素描五官基礎知識，學素描的同學可參考>素描五官基礎知識，學素描的同學可參考</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c480db6b.html alt=梯度，散度，旋度的重要基礎：對向量場的詮釋 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/c8ce2cc3bb0f4a5da0dcbc0a881f9617 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c480db6b.html title=梯度，散度，旋度的重要基礎：對向量場的詮釋>梯度，散度，旋度的重要基礎：對向量場的詮釋</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6fe27eab.html alt="前端 | HTML入門基礎知識-網頁" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e7a0b61194f445b8b9e5ae330961d2ea style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6fe27eab.html title="前端 | HTML入門基礎知識-網頁">前端 | HTML入門基礎知識-網頁</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/40b3969a.html alt=專業音頻基礎概念｜數字音頻是如何工作的？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3684bfc4e93447a5bdfd6d573beec22c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/40b3969a.html title=專業音頻基礎概念｜數字音頻是如何工作的？>專業音頻基礎概念｜數字音頻是如何工作的？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad3faa79.html alt=立體聲系統基礎篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15288739589536026ad6bae style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad3faa79.html title=立體聲系統基礎篇>立體聲系統基礎篇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/18bd39d8.html alt=齒輪基礎知識 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b8e178319e2c4b88a1865f903306a26b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/18bd39d8.html title=齒輪基礎知識>齒輪基礎知識</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3555f615.html alt=流體粘度傳感器的基礎知識與應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7f6d9f85a08146e5a84877ef92c212d7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3555f615.html title=流體粘度傳感器的基礎知識與應用>流體粘度傳感器的基礎知識與應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/000afa08.html alt="Spring Boot 2.x基礎教程：Swagger接口分類與各元素排序問題詳解" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/daa2cfd29ec34306a4be6f3f257b824b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/000afa08.html title="Spring Boot 2.x基礎教程：Swagger接口分類與各元素排序問題詳解">Spring Boot 2.x基礎教程：Swagger接口分類與各元素排序問題詳解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c6e14bc6.html alt=SQL基礎知識——事務 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/773e21df09dc4e3e8403a0a62994039d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c6e14bc6.html title=SQL基礎知識——事務>SQL基礎知識——事務</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9552c1b8.html alt="軟件開發中數據庫必備基礎01 - 圖解事務基礎" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4e00ac778db451792b955bde23add02 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9552c1b8.html title="軟件開發中數據庫必備基礎01 - 圖解事務基礎">軟件開發中數據庫必備基礎01 - 圖解事務基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c4961ebc.html alt=監控攝像頭基礎知識，學會自己也知道如何選擇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/98be6b1a1ad6410ea61d5fc243b44939 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c4961ebc.html title=監控攝像頭基礎知識，學會自己也知道如何選擇>監控攝像頭基礎知識，學會自己也知道如何選擇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a12da43e.html alt="金屬材料學 一些基礎知識" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/50ac00002279849cb698 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a12da43e.html title="金屬材料學 一些基礎知識">金屬材料學 一些基礎知識</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>