<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020 | 极客快訊</title><meta property="og:title" content="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/0bb8a9cd55044bdf977af7b06f301807"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/463eb195.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/463eb195.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/463eb195.html><meta property="article:published_time" content="2020-11-14T21:01:56+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:56+08:00"><meta name=Keywords content><meta name=description content="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/463eb195.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>本文部分內容源自清華大學計算機系在讀博士豈凡超在AI科技評論發佈的：話到嘴邊卻忘了？這個模型能幫你 | AAAI 2020。會議之眼參考論文對模型框架、背景知識以及數據來源、評測部分進行了補充。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0bb8a9cd55044bdf977af7b06f301807><p class=pgc-img-caption>豈凡超</p></div><p><br></p><p><strong>論文簡介和摘要</strong></p><p>《Multi-channelReverse Dictionary Model》是由清華大學、華為諾亞方舟合作的論文。該論文已經被AAAI 2020錄用。</p><p><br></p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/0ad9f8a0788f43b48f793b5d6bedab6c><p class=pgc-img-caption></p></div><p><br></p><p>該文關注反向詞典問題——即給定對某個詞語的描述，希望得到符合給定描述的詞語。該文提出了一種受到人的描述→詞的推斷過程啟發的多通道模型，在中英兩種語言的數據集上都實現了當前最佳性能（state-of-the-art），甚至超過了最流行的商業反向詞典系統。此外，基於該文提出的模型，論文作者還開發了在線反向詞典系統，包含首次實現的中文、中英跨語言反向查詞功能。</p><p><br></p><pre><code>論文地址：https://arxiv.org/abs/1912.08441代碼和數據地址：https://github.com/thunlp/MultiRDweb端萬詞王地址：https://wantwords.thunlp.org/</code></pre><p><br></p><p><strong>網站簡介</strong></p><p><br></p><p>基於論文所提模型的在線反向詞典系統——萬詞王（WantWords）：https://wantwords.thunlp.org/。該系統不僅支持英文、中文反向查詞，還支持英漢、漢英跨語言反向查詞，能夠顯示候選詞的詞性、定義等基本信息，且支持按照詞性、單詞長度、詞形等對候選詞進行篩選，助你更快找到你想要的詞。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/67b5abe10cd84714a124929c2da0f9f3><p class=pgc-img-caption>圖1 萬詞王示例</p></div><p><br></p><p><strong>研究背景</strong></p><p><br>反向詞典顧名思義，以對目標詞語義的描述為輸入，輸出目標詞以及其他符合描述的詞語。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/368e93dd041b41dbbb5f087a8281bbf4><p class=pgc-img-caption>圖2 反向詞典示例</p></div><p><br>反向詞典有重要的實用價值，其最大的用處在於解決舌尖現象（Tip of the tongue），即話到嘴邊說不出來的問題——頻繁寫作的人，如作家、研究人員、學生等經常會遇到這種問題。<br>此外，反向詞典也可以為掌握詞彙不多的新語言學習者提供幫助，讓他們學習、鞏固尚不十分了解的詞語。<br>最後，反向詞典還可以幫助選詞性命名不能（wordselection anomia）的患者——他們知道想說的詞語的意思但無法主動說出來。<br>反向詞典同樣具有自然語言處理研究價值，比如可以用於評測句子表示學習模型，輔助解決問答、信息檢索等包含文本到實體映射的任務。</p><p><br></p><p><strong>相關工作進展</strong></p><p><br>現在已經有一些投入使用的商業化反向詞典系統，其中最著名、最流行的是OneLook（https://www.onelook.com/thesaurus/），但其背後的實現原理尚不得知。<br>在學術研究領域，目前有兩類反向詞典實現方法：<br>第一類為基於句子匹配的方法，該方法在數據庫中存儲足夠多的詞語及其定義，當進行反向詞典查詢時，在數據庫中檢索與輸入描述最相似的定義並返回所對應的詞語。然而反向詞典的輸入描述非常多變，往往與已存儲的詞典定義有巨大差別，這種方法很難解決這一問題。<br>另一類基於神經語言模型的方法由Bengio等人提出，該方法使用神經語言模型作為編碼器將輸入描述編碼到詞向量空間，返回與之最近的詞向量對應的詞語。近年來有很多反向詞典研究基於這種方法，儘管這種方法避免了第一類方法面臨的輸入描述多變導致的性能較差的問題，然而該方法對低頻詞的處理效果不甚理想。</p><p><br></p><p><strong>模型搭建</strong></p><p><br>作者首先搭建了模型的基本框架，其實質上類似於由句子編碼器和分類器組成的句子分類模型。作者選擇了1997年發佈的雙向 LSTM（BiLSTM）作為句子編碼器，該編碼器將輸入語句編碼為向量。而由於句子中的不同單詞對句子而言代表的重要性不同，例如，在定義語句中，屬詞比修飾語更重要， 因此，作者將注意力機制（Bahdanau，Cho和Bengio 2015）也整合到了基本框架中。這僅僅是剛開始。<br>人的描述到詞的推斷過程如圖3所示，當人看到“road where cars go very quickly without stopping”這條描述時，除了直接猜目標詞以外，還可以推斷出目標詞應具有的一些特徵，比如詞性應為名詞，詞的類型應為實體，以及大概率具有“way”這個詞素。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5d3932f7af074771a9724bb416b37f12><p class=pgc-img-caption></p></div><p>圖3 人的描述→詞的推斷過程<br>受此啟發，該文的模型在對描述編碼後直接進行詞預測的基礎上，額外增加了四個特徵預測器。該文將每個特徵視作一個信息通道，四個通道可分為兩類：</p><p><br></p><p>1）內部通道，該類通道預測詞本身的特徵，包括詞性（part-of-speech）和詞素（morpheme）；<br>2）外部通道，該類通道預測外部知識庫提供的詞的特徵，包括詞類（word category）和義原（sememe）。其中詞類信息可由WordNet或同義詞詞林提供，義原由知網（HowNet）提供。</p><p><br></p><p>四個特徵彙總</p><blockquote><p>詞性：（part-of-speech，Pos）</p><p>詞素：（morpheme，Mor）</p><p>詞類：（word category，Cat）</p><p>義原：（sememe，Sem）</p></blockquote><p><br></p><p>三個數據庫彙總</p><blockquote><p>wordnet：WordNet是由Princeton大學的心理學家，語言學家和計算機工程師聯合設計的一種基於認知語言學的英語詞典。它不是光把單詞以字母順序排列，而且按照單詞的意義組成一個“單詞的網絡”。</p><p><br></p><p>同義詞詞林：是梅家駒等人於1983年編纂而成，年代較為久遠，對於目前的使用不太適合，哈工大實驗室基於該詞林進行擴展，完成了詞林擴展版。下載地址：</p><p>https://www.ltp-cloud.com/download/</p><p><br></p><p>HowNet：是董振東先生、董強先生父子畢數十年之功標註的大型語言知識庫，主要面向中文（也包括英文）的詞彙與概念。HowNet 秉承還原論思想，認為詞彙/詞義可以用更小的語義單位來描述。這種語義單位被稱為「義原」（Sememe），顧名思義就是原子語義，即最基本的、不宜再分割的最小語義單位。在不斷標註的過程中，HowNet 逐漸構建出了一套精細的義原體系（約 2000 個義原）。HowNet 基於該義原體系累計標註了數十萬詞彙/詞義的語義信息。在 NLP 領域知識庫資源一直扮演著重要角色，在英語世界中最具知名度的是 WordNet，採用同義詞集（synset）的形式標註詞彙/詞義的語義知識。HowNet 採取了不同於 WordNet 的標註思路，可以說是我國學者為 NLP 做出的最獨具特色的傑出貢獻。HowNet 在 2000 年前後引起了國內 NLP 學術界極大的研究熱情，在詞彙相似度計算、文本分類、信息檢索等方面探索了 HowNet 的重要應用價值，與當時國際上對 WordNet 的應用探索相映成趣。</p></blockquote><p><br></p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/608e03f206c14b7b9eeaba408a31f29f><p class=pgc-img-caption>圖4 文中的多通道反向詞典模型圖</p></div><p>圖4為該文所提模型的圖示。該模型以基於注意力機制的雙向LSTM對輸入定義或描述進行編碼得到句子表示，除了用該句子表示直接預測目標詞之外，還對目標詞的詞性（POS）和詞類（category）進行預測。而對於另外兩個特徵詞素（morpheme）和義原（sememe）的預測，則採用了不同的方法。</p><p><br></p><p>考慮到詞的詞素或義原和詞的描述/定義中的詞存在一種局部語義對應關係—如圖3中的例子中“expressway”的“express-”與“quickly”、“-way”與“road”分別對應，且義原也有類似的對應關係——因此對於這兩個特徵的預測，該文用每個詞的隱狀態（hidden state）分別預測，然後對預測分數做max-pooling來得到預測分數。這些特徵的預測分數會按一定比例加到符合該特徵的詞語的預測分數上，得到最終的詞語預測分數。</p><p><br></p><p><strong>評測部分</strong></p><p><br>1.評測數據集</p><p>該文在英文、中文多個數據集上進行了實驗。對於英文實驗，該文使用了前人工作都使用的來自多個英文詞典的定義數據集作為訓練集，測試集則有3個：</p><p><br></p><p>1）見過的詞典定義（Seen Definition），由一部分訓練集中出現的詞典定義構成，這一數據集主要測試模型對以往信息的回憶能力；</p><p><br></p><p>2）沒見過的詞典定義（Unseen Definition）,由未在訓練集中出現的詞典定義構成；</p><p><br></p><p>3）人工構造的描述（Description）數據集，該數據集包括人根據給定的詞語寫出的描述，是最貼合反向詞典應用實際的數據集。</p><p><br></p><p>2.用於比較的模型1）OneLook，最流行的商業反向詞典系統，使用2.0版本；<br>2）3）具有等級損失的BOW和RNN（Hill等人，2016），都是基於NLM的，而前者使用的是詞袋模型，而後者使用LSTM；<br>4）RDWECI（Morinaga和Yamaguchi 2018），其中包含類別推斷，是BOW的改進版本；<br>5）SuperSense（Pilehvar 2019），BOW的改進版本，使用預訓練的有義嵌入來替代目標詞嵌入；<br>6）MS-LSTM（Kartsaklis，Pilehvar和Collier 2018），RNN的改進版本，它使用基於圖的WordNet同義詞集嵌入和多義LSTM來根據描述和聲明來預測同義詞集產生最優性能；<br>7）BiLSTM，作者的多通道模型的基本框架。<br>3.評測參數1）目標詞的中位等級（median rank，越低越好）；<br>2）目標詞出現在頂部的準確性1/10/100（acc @ 1/10/100，越高越好）；<br>3）目標詞的排名標準差（rank variance，越低越好）。<br>4.評測結果1列表1展示了三個測試集對模型的預測效果，其中“ Mor”，“ Cat”和“ Sem”分別表示詞素，詞類和語素預測詞。（OneLook的性能在Unseen Definition上沒有意義，因為作者不能從其定義的庫中排除數據，因此作者沒有列出相應的結果。）</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/82dffc149ad341dfa09df2499a2c2f1e><p class=pgc-img-caption>表1 反向詞典性能評估比較</p></div><p><br>除OneLook，作者的多通道模式在Unseen Definition和Description數據集上有更好的性能。 在以下情況下，OneLook明顯優於作者的模型：測試集是SeenDefinition， 由於輸入詞典定義已經存在，因此可以預先得到此結果存並儲在OneLook數據庫中，簡單的文本匹配就可以輕鬆處理這種情況。但是，反向詞典的輸入查詢實際上不能是確切的詞典定義。 在Description測試集上，多通道模型可實現更好的整體性能。儘管OneLook的效果在acc @ 1上更好，但在實際應用中價值有限，因為人們往往從整個列表中選擇合適的詞語，而不是隻選擇列表中的第一個詞語，更不用說OneLook的acc @ 1只有0.33。 MS-LSTM在Seen Definition和Description測試集的表現效果天壤之別，表示它的泛化能力和實用效果很差。 不論增強什麼通道變量時，作者的多通道模型效果都要比最初的多通道模型效果要好，這證明了特徵融合的潛力。 2016年，Hill等人發現BOW性能優於RNN, 而與RNN同樣基於LSTM的多通道模型效果又遠遠超過了RNN和BOW，證明了RNN模型中雙向編碼的重要性，並且顯示了RNN模型的潛力。<br>5.評測結果2在反向詞典的實際應用中，除描述外，可能還會有關於目標詞的額外信息。例如，作者可能會記得作者忘記的單詞的首字母，或者在填字遊戲中已知目標單詞的長度。在本小節中，作者使用目標詞的先驗知識（包括POS標籤，首字母和字長。更具體地說，作者從模型的前1,000個結果中提取滿足給定先驗知識的單詞，然後重新評估性能。結果示於表2）。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/a3a77ccbabdf4c48a6c0f13fdbab827c><p class=pgc-img-caption>表1 基於先驗知識的反向詞典性能評估比較</p></div><p>作者可以發現，任何先驗知識都會或多或少地改善作者模型的性能，這是預期的結果。但是，首字母和單詞長度信息帶來的性能提升比POS標籤信息帶來的性能提升要大得多。可能的原因如下。對於POS標籤，已經在作者的多通道模型中進行了預測，因此帶來的改進是有限的，這也表明作者的模型在POS標籤預測中可以做得很好。對於首字母和單詞長度，很難根據定義或描述來預測它們，因此在作者的模型中沒有考慮。因此，它們可以過濾掉許多候選對象並顯著提高性能。 給出了英文數據集上的實驗結果，可以發現每個特徵預測器的增加都會提高模型的效果，而包含所有特徵的多通道模型得到了最好的性能，不但超過了此前最佳模型（state-of-the-art） MS-LSTM，而且在真實數據集Description上甚至超過了最流行的反向詞典系統OneLook。<br>6.評測結果3圖5顯示了所有在acc@10的評測標準上，具有不同數量語義的單詞上建立模型。很顯然所有模型的性能都會隨著sense數量增加而遞減，這意味著這表明多義詞是反向詞典任務中的一個難點。但是作者的模型表現出了出色的魯棒性，即使是在最多義的單詞上，性能依舊棒棒的。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b3ef43b0e01c49f891d0615f1c88b997><p class=pgc-img-caption></p></div><p>圖6顯示了所有模型在單詞頻率排名的變化模型表現的效果。作者發現對於所有反向詞典模型，最頻繁和最不頻繁的單詞都難以預測。最不常用的詞通常具有較差的嵌入，這可能會損害基於NLM的模型的性能。另一方面，對於最常用的單詞，儘管它們的嵌入效果更好，但它們通常是多義詞。作者分別計算所有排名的平均語義數目。排名第一的單詞的平均語義數要大得多，這說明了它的性能不佳。而且，作者的該模型還展示了出色的魯棒性。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c7bd3aff25ce471188f422066356e7f8><p class=pgc-img-caption></p></div><p><br>圖7顯示了查詢長度對反向詞典性能的影響。當輸入查詢只有一個單詞時，模型性能非常差，尤其是作者的多通道模型。這很容易解釋，因為從輸入查詢中提取的信息太有限了。在這種情況下，輸出查詢詞的同義詞可能是更好的選擇。</p><div class=pgc-img><img alt="清華華為發佈“萬詞王”反向詞典系統，入選AAAI 2020" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/375077d6e924429c84bd8752e37e2a47><p class=pgc-img-caption></p></div><p><br></p><p><strong>總結和討論</strong></p><p><br>本文中，作者提出了一種多通道反向詞典模型，該模型結合了多個預測變量，可以根據給定的輸入查詢預測目標詞的特徵。實驗結果和分析表明，作者的模型達到了最先進的性能，並且還具有出色的魯棒性。<br></p><p>將來，作者將嘗試將作者的模型與文本匹配方法結合起來，以更好地處理極端情況，例如，單字輸入查詢。另外，作者正在考慮將模型擴展到跨語言反向詞典任務。此外，作者將探討將模型轉移到相關任務（如問題回答）的可行性。PS: 後續更多學習資料免費分享！敬請期待~會議之眼現已推出小程序</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>清華華為</a></li><li><a>萬詞</a></li><li><a>詞典</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/9992313a.html alt=文學描寫詞典-場面篇-家庭類-聚餐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9992313a.html title=文學描寫詞典-場面篇-家庭類-聚餐>文學描寫詞典-場面篇-家庭類-聚餐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6bd93fce.html alt=文學描寫詞典-場面篇-習俗類 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6bd93fce.html title=文學描寫詞典-場面篇-習俗類>文學描寫詞典-場面篇-習俗類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ebed7de0.html alt=音頻軟件常用詞彙詞典(g-p) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/49902125d6f0482e897e57cb3f5030b3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ebed7de0.html title=音頻軟件常用詞彙詞典(g-p)>音頻軟件常用詞彙詞典(g-p)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/34f74968.html alt=網易有道詞典交互策略思考 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/S2GNhOXIpK3Dbt style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/34f74968.html title=網易有道詞典交互策略思考>網易有道詞典交互策略思考</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ed82de99.html alt="「AI 小白詞典」語音合成（Text to Speech｜TTS）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/34a08f1d8dbf4afc830ea6829bf1bf97 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ed82de99.html title="「AI 小白詞典」語音合成（Text to Speech｜TTS）">「AI 小白詞典」語音合成（Text to Speech｜TTS）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/36d2d4d.html alt=昆明話詞典，麻麻再也不用擔心我聽不懂昆明話了！昆明人都收藏了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/09f604c52e9a48489958a2ebdd11dab9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/36d2d4d.html title=昆明話詞典，麻麻再也不用擔心我聽不懂昆明話了！昆明人都收藏了>昆明話詞典，麻麻再也不用擔心我聽不懂昆明話了！昆明人都收藏了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9400013.html alt="區塊鏈詞典 | 公鑰與地址" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/2e5e718416144f63b25ad646fe1febf8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9400013.html title="區塊鏈詞典 | 公鑰與地址">區塊鏈詞典 | 公鑰與地址</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>