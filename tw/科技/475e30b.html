<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>圖神經網絡火了？談下它的普適性與侷限性 | 极客快訊</title><meta property="og:title" content="圖神經網絡火了？談下它的普適性與侷限性 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/467e2fd371934dceb8ed07b01cc7e921"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/475e30b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/475e30b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/475e30b.html><meta property="article:published_time" content="2020-10-29T21:05:29+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:29+08:00"><meta name=Keywords content><meta name=description content="圖神經網絡火了？談下它的普適性與侷限性"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/475e30b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>圖神經網絡火了？談下它的普適性與侷限性</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>選自arXiv</p><p><strong>作者：Andreas Loukas</strong></p><p><strong>機器之心編譯</strong></p><p><strong>參與：韓放、張倩</strong></p><blockquote><p>圖神經網絡（GNN）是一類基於深度學習的圖域信息處理方法。由於具有較好的性能和可解釋性，GNN 已成為一種廣泛應用的圖分析方法。然而，再好的方法都存在一定的侷限。來自洛桑聯邦理工學院的研究者在 arXiv 上發表了一篇論文，指出了圖神經網絡在消息傳遞分佈式系統中的圖靈普適性和侷限性。</p></blockquote><p>本文得出了兩個重要結論：</p><p>1. 在足夠的深度、寬度、節點獨立性和層表達條件下，GNN 是圖靈普適（Turing universal）的；</p><p>2. 當 GNN 的深度和寬度受到限制時，它們的能力會大大降低。</p><div class=pgc-img><img alt=圖神經網絡火了？談下它的普適性與侷限性 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/467e2fd371934dceb8ed07b01cc7e921><p class=pgc-img-caption></p></div><p><strong>為什麼要研究 GNN 的侷限性</strong></p><p>機器學習中的一個基本問題是確定模型可以學習和不能學習的內容。在深度學習中，大量的研究工作都取得了正面的結果。例如，眾所周知，具有足夠深度和寬度的前饋神經網絡可以逼近任何通用函數 。</p><p>最近，我們看到了研究圖神經網絡普適性的第一批結果，這些神經網絡以圖作為輸入。針對層是線性的且輸入排列是等變的深層網絡，Maron 等人得出了一個不變量函數的通用近似定理。Keriven 和 Peyr'E也證明了等變函數的普適性，儘管這一次是在一個特定的淺層體系結構下。擴展到深集，Xu 等人還證明了由和聚集器組成的單圖神經網絡層的普適性，該結果後來由 Seo 等人擴展。這些研究從函數層面探究了 GNN 模型能學到什麼，即 GNN 的普適性。</p><p>研究 GNN 的普適性使我們能夠在有限的範圍內把握模型的能力。理論上，只要有足夠的數據和正確的學習算法，一個普適的網絡就可以解決它所面臨的任何任務。然而，這些結果帶來的洞察也可能是有限的。知道一個足夠大的網絡可以用來解決任何問題，並不能在實踐中指導神經網絡設計。當然也不能保證該網絡能夠在給定的學習算法（如隨機梯度下降）下解決給定的任務。</p><p>然而，通過研究模型的侷限性通常更容易獲得對模型的洞察。畢竟，網絡所不能學到的關於特定特徵的知識在應用時獨立於訓練過程。此外，通過幫助我們理解與模型相關的任務的難度，不可能性結果（impossibility result）有助於得出關於如何選擇模型超參數的實用建議。</p><p>以圖分類問題為例。訓練一個圖分類器需要識別是什麼構成了一個類，即在同一個類而非其他類中找到圖共享的屬性，然後決定新的圖是否遵守所學習到的屬性。然而，如果可以通過一定深度的圖神經網絡（且測試集足夠多樣化）證明上述決策問題是不可能的，那麼我們可以確定，同一個網絡將不會學習如何正確地對測試集進行分類，這與使用了什麼學習算法無關。因此，在進行實驗時，我們應該把重點放在比下限更深的網絡上。</p><p><strong>本文兩大結論</strong></p><p>本文研究了圖神經網絡的計算能力侷限。作者沒有聚焦於特定的架構，這裡所考慮的網絡屬於消息傳遞框架的範疇。選擇該模型是因為它足夠通用，能夠涵蓋幾個最先進的網絡，包括 GCN、Chebynet、門控圖神經網絡、分子指紋、相互作用網絡、分子圖卷積等。本文提出的不可能性陳述（impossibility statement）源於一種新的技術，它能使理論計算機科學的成果重新定位。這將引出涉及圖的一系列決策、優化和估計問題的下界。值得注意的是，這些問題中的一些被認為是不可能的，除非 GNN 的深度和寬度的乘積超過了圖的大小；即使對於看起來很簡單的任務或在考慮近似值時，這種依賴性仍然很強。</p><p>具體來講，本文主要得出了兩大結論。</p><p><strong>GAN 在什麼情況下具有圖靈普適性</strong></p><p>如果滿足一定的條件，GNN 就可以在其輸入上計算任何可由圖靈機計算的函數。這個結果不同於最近的普適性結果，後者考慮了在特定的函數類（不變和等變）和特定的體系結構上的近似（而不是可計算性）。這一主張遵循一種直接的方式，即建立 GNN 與 LOCAL的圖靈等價，這是分佈式計算中的一個經典模型，本身就是圖靈通用模型。簡而言之，如果滿足以下四個強條件，GNN 就被證明是圖靈普適的：（i）有足夠的層；（ii）所述層有足夠的寬度；（iii）節點之間互相獨立；（iv）每層計算的函數具有足夠的表現力。</p><p><strong>哪些情況下 GNN 學習能力會下降</strong></p><p>為了瞭解更多，作者研究了對不使用讀出函數的 GNN 的深度 d 和寬度 w 進行限制的含義。具體來說，當乘積 dw 受到限制時，GNN 的能力會大打折扣。該分析依賴於一個新的引理，該引理能夠將不可能性結果從 LOCAL 轉換到 GNN。這種方法的主要好處是，它允許我們重新使用從理論計算機科學到圖神經網絡設置的幾個重要下界。</p><p>設 G 為神經網絡的輸入。本文給出了以下問題的下界：</p><ul><li>檢測 G 是否包含特定長度的循環；</li><li>驗證給定的 G 子圖是否連接，是否包含循環，是否為生成樹，是否為二分體，是否為一條簡單的路徑，是否對應於 G 的割或哈密頓循環；</li><li>近似兩個頂點之間的最短路徑，最小割和最小生成樹；</li><li>找到最大獨立集、最小頂點覆蓋或 G 的著色；</li><li>計算或近似 G 的直徑和周長；</li></ul><div class=pgc-img><img alt=圖神經網絡火了？談下它的普適性與侷限性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/50b1a119fe894924b88a0462d31fd013><p class=pgc-img-caption></p></div><p><em>表 1：主要結果總結。</em></p><div class=pgc-img><img alt=圖神經網絡火了？談下它的普適性與侷限性 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ea67f91559224bea9718d3cc6ae8a703><p class=pgc-img-caption></p></div><p><em>圖 1：給出下界的圖例。</em></p><p><em>論文鏈接：https://arxiv.org/abs/1907.03199</em></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>圖神經</a></li><li><a>網絡火</a></li><li><a>談下</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/d76edba1.html alt=Transformers是一種圖神經網絡 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6f96ef1cefa442138d3480deb3dff8f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/d76edba1.html title=Transformers是一種圖神經網絡>Transformers是一種圖神經網絡</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/54b66f71.html alt=為什麼說Transformer就是圖神經網絡？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RqSgmP9HojtMNK style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/54b66f71.html title=為什麼說Transformer就是圖神經網絡？>為什麼說Transformer就是圖神經網絡？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03a3050.html alt="圖神經網絡概述第三彈：來自IEEE Fellow的GNN綜述" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4b5d8378a8e746f9bd96bb031b90e2f1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03a3050.html title="圖神經網絡概述第三彈：來自IEEE Fellow的GNN綜述">圖神經網絡概述第三彈：來自IEEE Fellow的GNN綜述</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>