<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>自然語言處理中的語言模型簡介 | 极客快訊</title><meta property="og:title" content="自然語言處理中的語言模型簡介 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/49d71ab7.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/49d71ab7.html><meta property="article:published_time" content="2020-11-14T21:00:20+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:20+08:00"><meta name=Keywords content><meta name=description content="自然語言處理中的語言模型簡介"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/49d71ab7.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>自然語言處理中的語言模型簡介</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3><p class=pgc-img-caption></p></div><p>在這篇文章中，我們將討論關於語言模型（LM）的所有內容</p><ul><li>什麼是LM</li><li>LM的應用</li><li>如何生成LM</li><li>LM的評估</li></ul><h1 class=pgc-h-arrow-right>介紹</h1><p>NLP中的語言模型是計算句子（單詞序列）的概率或序列中下一個單詞的概率的模型。即</p><p>句子的概率：</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/710e41018bc9434f9dc011c0e3f58057><p class=pgc-img-caption></p></div><p>下一個單詞的概率：</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/edf6a5f137994fca81f11191da4a9183><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>語言模型 v/s 字嵌入</h1><p>語言模型常常與單詞嵌入混淆。主要的區別在於，在語言模型中，單詞順序很重要，因為它試圖捕捉單詞之間的上下文，而在單詞嵌入的情況下，只捕捉語義相似度(https://en.wikipedia.org/wiki/Semantic_similarity) ，因為它是通過預測窗口中的單詞來訓練的，而不管順序如何。</p><h1 class=pgc-h-arrow-right>語言模型的應用</h1><p>語言是NLP的主要組成部分，在很多地方都有使用，比如，</p><ul><li>情感分析</li><li>問答</li><li>總結</li><li>機器翻譯</li><li>語音識別</li></ul><h1 class=pgc-h-arrow-right>生成語言模型</h1><p>有不同的方法來生成語言模型，讓我們逐一查看它們。</p><h1 class=pgc-h-arrow-right>使用N-grams</h1><p>N-grams(https://en.wikipedia.org/wiki/N-gram) 是給定語料庫中N個單詞的序列。對於“I like pizza very much”這句話，bigram將是 ‘I like’, ‘like pizza’, ‘pizza very’ 和 ‘very much’。</p><p>比方說，我們有一個句子‘students opened their’，我們想找到它的下一個單詞，比如w。使用4-gram，我們可以用下面的方程來表示上面的問題，這個方程返回‘w’是下一個單詞的概率。</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/07144ecba5b14d5ea4e08240077f7d7c><p class=pgc-img-caption></p></div><p>這裡，count(X)表示X出現在語料庫中的時間。</p><p>對於我們的LM，我們必須計算並存儲整個語料庫中的所有n-grams，隨著語料庫越來越大，這需要大量的存儲空間。假設，我們的LM給出了一個單詞列表，以及它們成為下一個單詞的概率，現在，我們可以抽樣從給定列表中選擇一個單詞。</p><p>可以看出，對於一個N-gram，下一個單詞總是取決於句子的最後N-1個單詞。因此，當我們添加更多的單詞時，句子的上下文和依賴關係就會丟失。</p><p><em>“Today the price of gold per ton,while production of shoe lasts and shoe industry,the bank intervened just after it considered and rejected an IMF demand to rebuild depleted European stocks, sept 30th end primary 76 cts a share.’’</em></p><p>上面的文字是用商業和金融新聞語料庫中的N-grams（N=3）生成的，它符合語法知識但不連貫，因為我們只考慮最後兩個單詞來預測下一個單詞。</p><p>這種方法也容易受到稀疏性問題的影響，當單詞“w”在給定的句子之後從未出現，就會出現稀疏性問題，因此“w”的概率始終為0。</p><h1 class=pgc-h-arrow-right>使用神經網絡</h1><p>為了使用神經網絡生成LM，我們考慮使用一個固定的窗口，即每一次的單詞數都固定。如下圖所示，然後以獨熱向量的形式表示單詞，並與詞嵌入向量相乘，連接以創建矩陣e。然後將該矩陣展平並通過隱藏層。最後使用softmax函數輸出。</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bf571ea800ae49f4b705094ae98ae396><p class=pgc-img-caption></p></div><p>該方法解決了稀疏性問題，與N-grams相比不需要太多存儲空間，但也存在一些自身的問題。由於神經網絡使用固定的輸入窗口，因此由該模型生成的文本長度是固定的，因此使用起來不太靈活。隨著窗口大小的增大，模型的大小也隨之增大，從而變得效率低下。</p><h1 class=pgc-h-arrow-right>使用長-短期記憶網絡（LSTM）</h1><p>為了解決固定輸入長度問題，我們使用遞歸神經網絡（RNNs）。正如我們在N-grams方法中看到的，N-grams方法缺少長期依賴。如果我們使用vanilla-RNNs（https://medium.com/@apiltamang/unmasking-a-vanilla-rnn-what-lies-beneath-912120f7e56c） ，由於RNNs中的梯度消失，我們仍然會有相同的長期依賴問題。然而，一種稱為LSTM的特殊RNN解決了上述問題。</p><p>LSTMs能夠學習長期依賴關係。它們是由Hochreiter&Schmidhuber（1997）（http://www.bioinf.jku.at/publications/older/2604.pdf） 提出的，並在隨後的工作中被許多人改進和推廣。</p><p>所有的RNNs都是由一系列重複的神經網絡模塊組成的。在標準RNN中，這個重複模塊將有一個非常簡單的結構，比如一個單一的tanh層。在LSTMs中，重複模塊具有不同的結構。不是隻有一個神經網絡層，而是有四個，以一種非常特殊的方式相互作用。請在此處詳細閱讀LSTMs(https://colah.github.io/posts/2015-08-Understanding-LSTMs/)。</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0daf738c451e45a993ff241398e5931f><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cac19839e1134b2d9cadd4773c24d571><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>語言模型的評估</h1><p>我們需要對模型進行評估，以改進它或將其與其他模型進行比較。困惑度被用來評估語言模型。它是一種測量概率模型預測測試數據的能力。</p><p>我們衡量我們的模型有多低的困惑度，低困惑度意味著模型生成了連貫、結構良好的句子，而高困惑度則表示不連貫和混亂的句子。因此，低困惑度是好的，高困惑度是壞的。</p><p>從數學上講，困惑度是測試集的反概率，由單詞數規範化。</p><p>LM的困惑度：</p><div class=pgc-img><img alt=自然語言處理中的語言模型簡介 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3b06f9161d644df090ab685ffea27a2c><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>結論</h1><p>語言模型是NLP的重要組成部分，可以用於許多NLP任務。我們看到了如何創建自己的語言模型，以及每種方法都會出現什麼問題。我們得出的結論是，LSTM是製作語言模型的最佳方法，因為它考慮並處理了長期依賴問題。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>語言</a></li><li><a>處理</a></li><li><a>簡介</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/782e2e6.html alt=人工智能與自然語言處理簡介：AI三大階段、NLP技術與應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8f08141431684b78a58bfb91640cf6f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/782e2e6.html title=人工智能與自然語言處理簡介：AI三大階段、NLP技術與應用>人工智能與自然語言處理簡介：AI三大階段、NLP技術與應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html alt=第12屆自然語言處理和知識工程國際會議將在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html title=第12屆自然語言處理和知識工程國際會議將在西華大學舉行>第12屆自然語言處理和知識工程國際會議將在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html alt=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/4e62000034a58600d55e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html title=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行>第12屆自然語言處理與知識工程國際學術會議在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html alt=你對自然語言處理了解多少呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/150674bcc0e44efcae3427c70ad2f072 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html title=你對自然語言處理了解多少呢？>你對自然語言處理了解多少呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html alt=自然語言處理中的深度學習：評析與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html title=自然語言處理中的深度學習：評析與展望>自然語言處理中的深度學習：評析與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html alt=自然語言處理的十大應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dea6cbd6fbef4e9c935b6f56cb9b0097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html title=自然語言處理的十大應用>自然語言處理的十大應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html alt=人工智能之自然語言處理初探 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S4bjUwAFhO20v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html title=人工智能之自然語言處理初探>人工智能之自然語言處理初探</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html alt=人工智能的研究熱點：自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5fdd13a7-6c6d-45d6-9fcd-2829793b5dd3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html title=人工智能的研究熱點：自然語言處理>人工智能的研究熱點：自然語言處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html alt=什麼是自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/64bcc3b1fb8a4f9ca59d452035ca25cb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html title=什麼是自然語言處理>什麼是自然語言處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1f73ce58.html alt=復旦大學黃萱菁：自然語言處理中的表示學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/77184e60d8e74b9da944a638e38aedfa style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1f73ce58.html title=復旦大學黃萱菁：自然語言處理中的表示學習>復旦大學黃萱菁：自然語言處理中的表示學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/84eef54a.html alt=有關自然語言處理的深度學習知識有哪些？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b6e6ac2f1c1948158c7edbe790f52b66 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/84eef54a.html title=有關自然語言處理的深度學習知識有哪些？>有關自然語言處理的深度學習知識有哪些？</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>