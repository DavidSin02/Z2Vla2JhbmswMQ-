<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習 | 關於參數模型與非參數模型研究 | 极客快訊</title><meta property="og:title" content="機器學習 | 關於參數模型與非參數模型研究 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/68b4f4157bf646db9ce418d00bef8ec8"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4a3f34b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4a3f34b.html><meta property="article:published_time" content="2020-10-29T20:59:30+08:00"><meta property="article:modified_time" content="2020-10-29T20:59:30+08:00"><meta name=Keywords content><meta name=description content="機器學習 | 關於參數模型與非參數模型研究"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/4a3f34b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習 | 關於參數模型與非參數模型研究</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>關注並標星<strong>索信達</strong></p><p>每天打卡閱讀</p><p>更快走進金融人工智能世界</p><p>━━━━━━</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/68b4f4157bf646db9ce418d00bef8ec8><p class=pgc-img-caption></p></div><p>我們是索信達集團旗下的金融人工智能實驗室團隊，微信公眾號（datamargin)將不定期推送原創AI科學文章。我們的作品都是由實戰經驗豐富的AI科學技術人員或資深顧問精心準備，志在分享結合實際業務的理論應用和心得體會。</p><p><strong>文 | 索 信 達 Yvonne Yang</strong></p><p><strong>引言</strong></p><p>在大數據時代，我們常常面臨成萬上億的數據，伴隨著的是高維度的變量，當今很多學術和技術領域都致力於解決針對大數據的模型構造，例如神經網絡、深度學習。但對於金融和商業領域，變量是如何影響響應變量的（可解釋性）、模型是否可靠等因素尤為重要，特別是當我們的數據集只包含了屈指可數的幾個變量，那麼特徵變量的選取應更嚴謹，變量與響應變量間關係的量化也是重要的指標，此時可以運用更為精細的模型探索方法。廣義線性模型和廣義加性模型分別由線性模型和加性模型推廣而來，能更廣泛地應用於不同分佈的數據，並輔以似然比檢驗逐步優化模型。本文將從參數模型和非參數模型的角度，以廣義線性模型和廣義加性模型為例，配以相應的案例，對模型探索以及優化方法進行簡要介紹。<strong>1. 參數迴歸模型1.1 傳統線性模型</strong></p><p>統計學中，參數模型是一類可以通過結構化表達式和參數集表示的模型。為確定兩種或兩種以上變量之間的定量關係，我們希望通過手中已有的數據去“擬合”出一個“線性方程”，眾所周知的經典線性迴歸模型（Linear Regression Model）就屬於參數模型,</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/59585a91590e4e128d2e03881714bf5d><p class=pgc-img-caption></p></div><p>它要求響應變量y是實值的且連續的，用於我們通常所說的“迴歸問題”。</p><p><strong>1.2 廣義線性模型</strong></p><p><strong>1.2.1 模型介紹</strong></p><p>日常生活中的許多問題的數據形式並不符合“連續”這個要求，並且面臨很多“分類問題“，即該把某對象預測為屬於哪一類，這時傳統的線性迴歸模型便顯得約束過於強而導致應用範圍的狹窄。此外，對於一些較為特殊的分佈，如偏態分佈和常為重尾分佈的金融數據，該如何選擇模型呢？廣義線性模型（Generalized Linear Model）應運而生，它將線性迴歸的思想推廣到探索多種形式的響應變量和迴歸變量之間的關係。其向量形式為：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d75fae472b4349e1ba97f70ea8aed677><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/099d91661383417790d7aca519fe8f1e><p class=pgc-img-caption></p></div><p>被稱為連接函數（link function），滿足平滑（簡單來說，圖像光滑）且可逆（反函數存在的函數是可逆的）的條件，</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5067e9e4e6bf4b74a980a16bcb1700f0><p class=pgc-img-caption></p></div><p>為給定樣本下Y的分佈。</p><p>可以看到，當y為連續變量並且我們選擇</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/416fff4d8ae7440aa4393a3666aad2e1><p class=pgc-img-caption></p></div><p>作為y|x 的分佈，連接函數取恆等函數</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f88fc77c3a0d44758c714a4d0855a900><p class=pgc-img-caption></p></div><p>時，它恰好是傳統的線性迴歸模型；邏輯迴歸也是其特例，連接函數為</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6fa859fb3f08426bb0fdf214d03190c7><p class=pgc-img-caption></p></div><p>；而當y為離散值且選擇分佈為</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5b75f0ad01124bc39478a6de6944b68e><p class=pgc-img-caption></p></div><p>，連接函數為</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/8cac69e4ef9d4fc7bd8e4dd6c5963fed><p class=pgc-img-caption></p></div><p>時，模型變為：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/47617290b8b14ba1b182f696e9d38d49><p class=pgc-img-caption></p></div><p>恰好是泊松迴歸模型。可以見得，以上常見模型都是廣義線性模型的一種特殊形式，廣義線性模型通過連接函數將模型變得更靈活而具有普適性。</p><p><strong>1.2.2 分佈選擇</strong></p><p>分佈的選擇依賴於給定樣本中y值的分佈，y的分佈觀察可利用直方圖和核密度估計（kernel density estimator）。特別的，對於均值與方差相差甚遠的離散響應變量y，選擇Poisson分佈不再是一個明智的選擇（因為服從Poisson分佈的隨機變量均值與方差應相等），因此可嘗試用負二項分佈。</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dd7ae6f1780647c296c91e21785a60e1><p class=pgc-img-caption></p></div><p>圖1. 幾種常見分佈</p><p><strong>1.2.3 連接函數</strong></p><p>對於連接函數的選擇，此處引入指數族分佈的概念：概率密度函數（p.d.f.）或者概率質量函數（p.m.f.）能化成如下形式的分佈，被稱為指數族分佈，</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/58d167c30de640b398999f55ac5d1e3a><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1c197a86bc514632bacc99f5c612b2e6><p class=pgc-img-caption></p></div><p>是自然參數，</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/48d7d62131f148919cf068a3bd56df21><p class=pgc-img-caption></p></div><p>是尺度參數，且滿足條件：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5a5571e38d1746c2acf3fd2dffa5bf81><p class=pgc-img-caption></p></div><p>以下給出一些常見的指數族分佈及其標準連接函數（canonical link function）：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5aeea9113ece47d0af6dc765fc9fc40e><p class=pgc-img-caption></p></div><p>為簡化得到係數</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db16078c6bd649b1932e2b8812f60ee8><p class=pgc-img-caption></p></div><p>的數學計算，通常我們選擇標準連接函數，特別地，對於要求y值大於0的響應變量，可以選擇連接函數</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2cb2ae1b56e74705addda4901907669f><p class=pgc-img-caption></p></div><p>，以保證預測值仍然滿足大於0。</p><p><strong>1.2.4 模型優化之似然比檢驗</strong></p><p>對於參數不顯著的項(例如X1)，說明其對於目標變量的影響不顯著，可是去掉之後模型是否顯著變好，有時用肉眼無法甄別，此時可藉助似然比檢驗。我們希望檢驗一個更“小”的模型是否可行，此處假設設定為 ：</p><p>原假設：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d75c111823eb4e5a861711f33315a9b6><p class=pgc-img-caption></p></div><p>備擇假設：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e2a4d0e961684486a98548fec297c699><p class=pgc-img-caption></p></div><p>若</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/526a194d832d4a9ebf713e0f7bb554c4><p class=pgc-img-caption></p></div><p>，p值小於顯著性水平時，拒絕原假設，認為X1去掉模型效果將顯著變差。<strong>1.3 示例</strong></p><p>例如在一個案例中（數據來自：https://www.kaggle.com/mirichoi0218/insurance），我們要探索保險公司給付的保費（charges）與年齡、性別、bmi、地區、抽菸習慣、小孩數量之間的函數關係，目標變量charges為連續變量，下圖為核密度估計曲線，發現其近似Gamma分佈，因此可選擇Gamma分佈與其標準連接函數</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5ec3cf9894604ea9a024e8419ff9f9b0><p class=pgc-img-caption></p></div><p>.</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/64928b28c4b9427fa7542bee0caa61b0><p class=pgc-img-caption></p></div><p>圖2: 目標變量charges分佈</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e5f467c37fae4667b4a233f12a29d568><p class=pgc-img-caption></p></div><p>圖3: gamma分佈圖（來自：Wikipedia）</p><p>對於上圖中的數據集，當模型優化至此步，發現不顯著項（p值大於0.05）大部分與region（地域）有關（如左圖所示）。去掉region這一項後，重新擬合模型，在參數顯著性上有所提升，然而AIC略微上升（如右圖所示）：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/937f567d69c448599ebe5bd7a96c5cd3><p class=pgc-img-caption></p></div><p>圖4: 模型結果輸出-優化前（左）優化後（右）</p><p>看起來小小犧牲AIC能換來參數顯著性的提高，那麼把地域特徵去除真的能達到優化模型的效果嗎？我們希望檢驗一個更“小”的模型是否可行，當顯著性水平設為</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/52baaf7ba7c84bd2a3384b28af8185d2><p class=pgc-img-caption></p></div><p>時，根據如下輸出結果，p值為0.3989，不拒絕原假設，認為“地區（region）”可從模型中移除，至此模型優化結束。似然比檢驗能更客觀地告訴我們某一特徵能否從模型中移除。</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/db96ba17f46d4a1a93c55762073aba5c><p class=pgc-img-caption></p></div><p>圖5: 似然比檢驗結果</p><p><strong>2.非參數迴歸模型</strong></p><p><strong>2.1 非參數模型</strong></p><p>參數模型與非參數模型的區別在於：參數模型預先設定了模型的形式，後通過最小化score function求得參數，而非參數模型不對隨機變量預先假設任何模型形式，預測器的構建都依賴於數據，可以自由地從數據中學習出模型，具有極大的靈活性。在構造目標函數時，非參的方法尋找合適的訓練數據，同時保留一些對數據的泛化能力， 因此，這些非參方法能夠擬合大多數的函數形式。例如K近鄰算法就是典型的非參模型，對於一個新的數據實例x，該算法尋找離x最鄰近的K個樣本，以“多數取勝”策略來確定x的類別。</p><p>受限於先驗模型的形式，參數模型有時無法全面地捕捉到數據樣本的特徵，且有時模型形式難以預先確定。對於迴歸問題而言，常用的非參數迴歸方法有局部多項式迴歸（polynomial regression）和樣條迴歸（spline regression）。對於p個變量的迴歸問題，非參數方法能得到最終的迴歸方程</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4fc6621eb4d249c4a286c424c867feab><p class=pgc-img-caption></p></div><p>，或向量表示為</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/221a5a8d32934051bffe72fa35650da0><p class=pgc-img-caption></p></div><p>.</p><p><strong>2.2 從加性模型到廣義加性模型</strong></p><p>非參數迴歸的模型形式自由，完全由數據驅動，適應力強，但也有顯著的缺點，例如“高維詛咒”：當維數較高時，前述的兩種非參數迴歸方法開始變得不穩定且收斂減慢，同時最終的迴歸方程解釋性和可視化能力弱。解決維度問題的一種方法是利用加性模型（Additive Model）：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/077cf918906e4b95aeffe3654039a18a><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a38c55c87f8a4ba4beda9d4e6a19cec6><p class=pgc-img-caption></p></div><p>為單變量非參數方程。該方法相當於將1個p維變量的方程轉換成了p個單變量方程。</p><p>相似地，通過連接函數</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9b5c4b31bb904e86b3c1291faa535d1e><p class=pgc-img-caption></p></div><p>，可推廣到廣義加性模型（Generalized additive model）：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ee68aaad2e394be1a41c722bbad40673><p class=pgc-img-caption></p></div><p><strong>2.3 示例</strong></p><p>採用廣義加性模型，能克服非參數模型常有的解釋性弱和可視化能力差的問題，可以研究單個變量的非參數項。例如探究房價與10個變量的關係，採用樣條函數平滑每一個變量，變量顯著性如下圖所示：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9988fa2c8d764881a129dcfb4c834a95><p class=pgc-img-caption></p></div><p>圖6：GAM模型擬合結果</p><p>通過繪製部分預測圖，可以探索單個變量的效應，其中每幅圖橫軸為單一變量取值，縱軸為對應的</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/51190758ed2e414284379a07c58f0508><p class=pgc-img-caption></p></div><p>：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3a4acaf1490546cfa0378c1952d70a8a><p class=pgc-img-caption></p></div><p>圖7: 部分預測圖</p><p><strong>3. 半參數模型</strong></p><p><strong>3.1 模型介紹</strong></p><p>在非參數模型模型優化的過程中，有些變量呈現出強烈的線性性，對該變量</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/78ef7f89abb34a68b19818e20f6ea185><p class=pgc-img-caption></p></div><p>應用線性項</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/63c59424fd114a0b8ba4320b56553fa5><p class=pgc-img-caption></p></div><p>替代非線性項放入模型中。此時得到的是“半參數模型”，它同時含有線性項和非線性項，作為非參數模型和參數模型之間的一類模型，半參數模型既繼承了非參數模型的靈活性,又繼承了參數模型的可解釋性，可以進一步改善非參數模型的缺陷。半參數模型常具有以下的形式：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/40422354572845f9b0972f44bcbf803b><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e1766912bcba4a2ab255233077d36559><p class=pgc-img-caption></p></div><p>為線性項 ，</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0efd2a73032a4a12b6661e2c1a20af0e><p class=pgc-img-caption></p></div><p>為非線性項。</p><p><strong>3.2 示例</strong></p><p>在2.3示例中，非參數模型擬合後發現x5和x9的非參數項不夠顯著，進一步觀察部分預測圖發現變量x5對模型響應變量沒有貢獻（因為其縱軸刻度始終都在0附近），變量x8和x9表現出線性性（因為其部分預測圖近似直線），而其他變量表現出非線性性。據此移除變量x5，並將x8和x9的項替換為線性項，優化得到一個半參模型，所有項都是顯著的，結果如下所示：</p><div class=pgc-img><img alt="機器學習 | 關於參數模型與非參數模型研究" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4f31df53c85d45a69dc35a937f81827e><p class=pgc-img-caption></p></div><p>圖8: 優化後參數顯著性</p><p><strong>4. 小結</strong></p><p>傳統的參數模型(如線性迴歸)只能處理一些簡單的變量間呈現特定關係的數據，當面臨的問題更復雜的時候，變量關係說不清道不明，參數模型不一定能達到目標效果。非參數模型可以規避上述問題，具有更好的靈活性，並可通過廣義加性模型獲得更好的性能。此外，半參數模型是介於參數模型和非參數模型之間的一類，常由非參模型優化得來，兼具靈活性和可解釋性。</p><p>對於樣本量足夠大而變量數量不大的數據集，或者對一些需要追蹤指標變化原因的場景，這些統計模型及其優化方法或許能派上用場。其通過分佈選擇與連接函數推廣到更具有普適性的模型，並能利用統計方法去檢測變量的選擇是否具有合理性。無論是廣義線性模型和廣義加性模型，都能學習到一個既定的模型，通過變量參數或者部分預測圖去發現變量如何影響響應變量，同時對於新的數據集可以產生相應的預測值。</p><p>注：本文使用的分析工具為R語言， 有興趣的讀者可自行了解。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>參數</a></li><li><a>模型</a></li><li><a>機器</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html alt=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1530929302432561dc6cda6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html title=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價>機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html alt=「火爐煉AI」機器學習048-Harris檢測圖像角點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d756b20a1dbc4ab4b4f22d6b61be2043 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html title=「火爐煉AI」機器學習048-Harris檢測圖像角點>「火爐煉AI」機器學習048-Harris檢測圖像角點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bc93016e.html alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7804be8632614272aab014f77d8f40a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bc93016e.html title=人工智能時代，機器人真的能在對話中識別人的意圖嘛？>人工智能時代，機器人真的能在對話中識別人的意圖嘛？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html alt=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfDgA10IBHJqK9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html title=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？>AI也有偏見：你在機器“眼裡”是好人還是壞蛋？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html alt=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/519b968bf69146fda9bf55f89779d373 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html title=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質>基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/25bebf48.html alt=關於齒輪的參數及計算公式大全 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/54cfb37ea965443daf82a218b503ddbc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/25bebf48.html title=關於齒輪的參數及計算公式大全>關於齒輪的參數及計算公式大全</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html alt=如何減少焊接機器人出現焊接件變形的情況？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3a62de9fde6c4a09ac0950d5f16dea0a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html title=如何減少焊接機器人出現焊接件變形的情況？>如何減少焊接機器人出現焊接件變形的情況？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0e83a16d.html alt=聚四氟乙烯材料如何合理選取切削參數？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0e83a16d.html title=聚四氟乙烯材料如何合理選取切削參數？>聚四氟乙烯材料如何合理選取切削參數？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3d825106.html alt=記不住先收藏！結構設計參數中易踩的85個坑 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/12418666dc2f40db9e2a39a0903494e9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3d825106.html title=記不住先收藏！結構設計參數中易踩的85個坑>記不住先收藏！結構設計參數中易踩的85個坑</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d30ee216.html alt=功率電感：參數圖文對比與選型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dc7193bbd2b542d2ada80995bab5a82c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d30ee216.html title=功率電感：參數圖文對比與選型>功率電感：參數圖文對比與選型</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>