<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習入門：偏差和方差 | 极客快訊</title><meta property="og:title" content="機器學習入門：偏差和方差 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/e4d7bca8189b4528b0f564ee473d2a68"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/4b5cbda.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/4b5cbda.html><meta property="article:published_time" content="2020-10-29T20:58:14+08:00"><meta property="article:modified_time" content="2020-10-29T20:58:14+08:00"><meta name=Keywords content><meta name=description content="機器學習入門：偏差和方差"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/4b5cbda.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習入門：偏差和方差</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><br></p><p>偏差(bias):偏差衡量了模型的預測值與實際值之間的偏離關係。</p><p>方差（variance）：方差描述的是訓練數據在不同迭代階段的訓練模型中，預測值的變化波動情況（或稱之為離散情況）</p><p>我們這裡以線性迴歸為例進行介紹</p><p><br></p><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e4d7bca8189b4528b0f564ee473d2a68><p class=pgc-img-caption></p></div><p><br></p><p><strong>線性迴歸是一種機器學習算法，它主要用來預測定量目標。該算法根據線性方式建模的自變量來擬合包含預測數據點的直線或平面(或超平面)。</strong>首先，讓我們把這看作是最佳擬合線(為了更好地理解)。通常情況下，訓練集中的數據點並不是全部都在最佳擬合線上，這是非常有意義的，因為任何數據都不是完美的。這也就是為什麼我們首先要做預測，而不是隨便畫一條線的原因。</p><h1 class=pgc-h-arrow-right>理解偏差</h1><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f0361485726f4b998a13232917996be7><p class=pgc-img-caption></p></div><p><br></p><p>利用線性迴歸算法得到的線不能為了包含所有的訓練集數據點就過於彎曲，因此有時無法捕捉到準確的關係。這叫做偏差。在數學上，在線性迴歸方程中得到的截距是偏差。</p><p>我為什麼這麼說？</p><p>讓我解釋一下：這是一個隨機線性迴歸方程：</p><p>y = Intercept + Slope1*x1 + Slope2*x2</p><p>目標(y)在數據集中會有一些值，利用上面的公式可以計算出目標(y)的預測值。如果"截距"本身非常高並且很接近預測的y值，那麼這就意味著方程另外兩部分——自變量(x1和x2)的變化導致y的變化會很小。這意味著x1和x2所產生的方差值會很小，最終這將會導致建立一個欠擬合模型。欠擬合模型具有較低的R-squared（由自變量引起的目標方差量）。</p><p>欠擬合也可以通過首先考慮如何捕捉最佳擬合線/平面來理解。最佳擬合直線/平面捕捉目標和自變量之間的關係。如果這種關係被捕捉到一個非常高的範圍，它會導致低偏差，反之亦然。</p><p>既然我們瞭解了什麼是偏差，以及高偏差是如何導致欠擬合模型的，那麼對於一個健壯的模型，我們需要消除這種欠擬合。</p><p>在這樣一個場景中，我們創建了一條通過所有數據點的曲線，並且可以顯示自變量和因變量之間的現有關係，那麼模型中就不會存在偏差。</p><h1 class=pgc-h-arrow-right>理解方差</h1><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/20a0f5c7f5e54b4c84ceeba2c23be326><p class=pgc-img-caption></p></div><p><br></p><p>對訓練數據過度擬合的模型將導致一種新的現象，稱為"方差"。現在來考慮幾個模型：</p><p>模型1：高偏差（無法正確捕捉關係）</p><p>模型2：低偏差（在很大程度上捕捉關係）</p><p>驗證模型時的誤差測量：</p><p>Error = Actual Values — Predicted Values</p><p>在計算訓練數據(圖中還沒有測試數據)的誤差時，我們觀察到:</p><p>模型1:在訓練數據上對模型進行驗證，結果表明誤差較大</p><p>模型2:在訓練數據上對模型進行驗證，結果表明誤差較小</p><p>現在，讓我們引入訓練數據，來理解方差。</p><p>如果模型在訓練數據是過擬合的,那麼該模型"理解"和"認識"訓練數據的程度就會非常高,以至於它可能不利於對測試數據進行測試。因此當將測試數據用作該模型的輸入時，它將無法捕捉到一種關係。從更廣泛的角度來看，這意味著訓練數據和測試數據之間的擬合有很大的差異(因為在訓練數據上展示了完美的驗證，而在測試數據卻無法捕捉關係)。這種擬合差異被稱為"方差"，這種現象產生的原因是模型只能理解訓練數據，它對任何新的輸入數據不能很好地進行預測。</p><p>在測試數據上驗證上述模型時，我們注意到:</p><p>模型1：這裡也沒有正確地捕捉到關係，但是在訓練數據和測試數據之間沒有巨大的理解差距，所以方差很低</p><p>模型2：訓練數據和試驗數據之間存在巨大的理解差距，因此方差很大</p><h1 class=pgc-h-arrow-right>偏差和方差之間的權衡</h1><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8c5d2f129a704607a4529448ce2a02ae><p class=pgc-img-caption></p></div><p><br></p><p>現在我們知道偏差和方差都會給我們的預測模型帶來問題。那麼我們該如何著手解決這個問題呢?</p><p>在我們繼續之前，有幾個術語需要理解:</p><p>過度擬合：低偏差和高可變性-模型非常適合訓練數據，但是不適合測試數據，因為它只能很好地理解訓練數據</p><p>欠擬合：高偏差和低可變性-模型在使用訓練數據時無法捕捉關係，但由於它無論如何都沒有捕捉到關係，因此訓練數據和測試數據之間的理解差距不大，因此方差較小</p><p>回到解決方案，我們可以做以下工作，嘗試在偏差和方差之間建立一種平衡：</p><p><br></p><h1 class=pgc-h-arrow-right>1. 交叉驗證</h1><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6d46c9a4a54f43d39a4aac36c86a3849><p class=pgc-img-caption></p></div><p><br></p><p>通常，一個模型是建立在訓練數據上，並在相同的數據上進行測試。但還有一件事是人們更喜歡去做的，那就是在訓練數據的一部分數據上測試模型，這部分數據稱為驗證數據。</p><p><strong>那麼，什麼是交叉驗證？</strong></p><p>如前所述，模型驗證是對部分訓練數據進行的。因此，如果我們每次迭代都從訓練數據中選擇一組新的數據點來進行驗證，並對從這些數據集獲得的結果求平均值，那麼我們就是在進行交叉驗證。這是一種優化方法，主要用來了解模型在訓練數據上的行為，同時它也是一種瞭解是否存在過擬合的方法。</p><p><strong>交叉驗證的類型：</strong></p><p>K- fold CV:這裡的K表示我們需要將我們的訓練數據集分解成的集合的個數，然後用這K個集合進行模型驗證，對這K個集合得到的結果取平均值，從而得到一個最終的結果，這可能會避免過擬合。</p><p>Leave-One-Out CV:Leave-One-Out CV的工作原理類似於K-Fold CV，但它將流程提升到了一個新的高度，因為它使用訓練數據中的每一個數據點來計算交叉驗證結果。這顯然很耗時，但絕對有助於避免過度擬合。</p><p>前向鏈接：在處理時間序列數據時，K-Fold-CV和Leave-One-Out-CV會產生問題，因為某些年份的數據很可能會有其他年份沒有的模式，因此使用隨機數據集進行交叉驗證是沒有意義的。事實上，現有的趨勢有可能被忽視，這並不是我們想要的。因此，在這種情況下，通常使用前向鏈接方法，其中我們形成的每個摺疊（用於交叉驗證）包含一個訓練集組，通過將連續一年的數據與上一個訓練集組相加並在測試集上進行驗證（該測試集只包含訓練組中使用的連續年份到最近一年的數據）。</p><h1 class=pgc-h-arrow-right>2. 正則化</h1><div class=pgc-img><img alt=機器學習入門：偏差和方差 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/f98779c243f94fefb601b0fa24e46e7a><p class=pgc-img-caption></p></div><p><br></p><p>正則化是一種技術，它通過附加在模型自變量上的β懲罰係數來減少偏差和方差。</p><h1 class=pgc-h-arrow-right>總結</h1><p>沒有完美的模型。必須用積極的方式利用模型不完美的地方，才能使它變得完美。一旦你能夠識別出你的模型中存在的偏差或可變性，你就可以做很多事情來改變它。您也可以嘗試特徵選擇和特徵轉換。您可以嘗試刪除一些過擬合變量。基於當時的可能性，可以做出決定，如果有可能的話，這個模型肯定會得到改進。</p><p><br></p><p>感謝您的閱讀!學習快樂!</p><p>支持我的寫作</p><p>作者：Shaurya Lalwani</p><p>deephub翻譯組：錢三一</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>入門</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/c75c54fc.html alt=機器學習入門第2章：SVM（支持向量機）—理論 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/db2b59aa64f64e189449ae9773356bed style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/c75c54fc.html title=機器學習入門第2章：SVM（支持向量機）—理論>機器學習入門第2章：SVM（支持向量機）—理論</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9b52b0.html alt=機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a6894d2d1ea64a8eb3bad2b892648639 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9b52b0.html title=機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼）>機器學習入門第1章：監督學習和樸素貝葉斯分類-第2部分（編碼）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2d4007c7.html alt=“黑客”入門學習之“Windows組策略” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ea21244d5f5c420ebef29650f3fafd1c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2d4007c7.html title=“黑客”入門學習之“Windows組策略”>“黑客”入門學習之“Windows組策略”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c914526c.html alt=新手入門PLC，掌握學習方法是關鍵 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15355275026304e8d787f10 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c914526c.html title=新手入門PLC，掌握學習方法是關鍵>新手入門PLC，掌握學習方法是關鍵</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>