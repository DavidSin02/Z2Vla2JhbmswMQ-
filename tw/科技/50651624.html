<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文 | 极客快訊</title><meta property="og:title" content="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/RXUxMxA90vXMZq"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50651624.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/50651624.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/50651624.html><meta property="article:published_time" content="2020-11-14T21:01:57+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:57+08:00"><meta name=Keywords content><meta name=description content="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/50651624.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>本文轉自騰訊AI Lab<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">微信</i>公眾號（tencent_ailab）</strong>，獲取更多騰訊AI Lab團隊技術乾貨，可<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">關注</i>其<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">微信</i>公眾號。本文將通過介紹入選NLP領域頂級學術會議 ACL 的論文，解讀騰訊 AI Lab 的重點研究方向：自然語言理解、對話系統和文本生成，以及機器翻譯等。</p><p>自然語言處理領域頂級會議 ACL 2019 將於 7 月 28 日– 8 月 2 日在意大利弗洛倫薩舉辦。此次騰訊 AI 共計入選 34 篇文章，含騰訊 AI Lab 20 篇、<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">微信</i>AI 9 篇、其他部門 5 篇（據內部不完全統計）。</p><p>這是騰訊 AI Lab 第三次參加 ACL，本次入選的論文涉及自然語言理解、對話系統和文本生成，以及機器翻譯等幾大重點研究方向，下面將以不嚴格的方式分組介紹。Lab 往年參會入選論文可見「 騰訊 AI 實驗室 」公眾號。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxMxA90vXMZq><p>ACL 大會期間，騰訊還將在弗洛倫薩舉辦 TAIC 學術交流大會，邀請騰訊 AI Lab 副主任俞棟博士等多位技術專家和業界領袖，共談前沿研究進展。歡迎您前來參加。</p><p><strong>時間：</strong>7月29日17:00-20:30</p><p><strong>地點：</strong>Sala della Scherma,Fortezza da Basso,Florence</p><p><strong>方向一：自然語言理解</strong></p><p>自然語言理解（Natural Language Understanding）的目標是賦予機器閱讀、消化和理解人類語言的能力，是人工智能數十年來致力完成的使命之一，也是自然語言處理研究者長期以來努力攻克的重點和難點之一。騰訊AI Lab長期以來在自然語言理解領域有著持續的投入，本次會議上展示的論文，主要圍繞詞的語義表示和知識的構建，希望在多語種、跨平臺的自然語言理解問題上有所突破。</p><p><strong>1. 社交媒體語言的主題感知神經關鍵詞生成</strong></p><p>Topic-Aware Neural Keyphrase Generation for Social Media Language</p><p>論文地址：https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>v.org/pdf/1906.03889.pdf</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxMxl8LahyfL><p>本文由騰訊AI Lab主導，與香港中文大學聯合完成。每天在社交媒體上有大量用戶生成的內容發佈。為了便於自動語言理解，我們研究關鍵詞預測，即從大量帖子中提取顯著信息。相比於大多數從源帖子中提取單詞以形成關鍵短語的現有方法，我們提出了基於序列到序列（seq2seq）的神經關鍵詞生成框架，使得不出現在帖子中的關鍵詞也可以被生成。此外，我們的模型有主題感知的特性，能對跨文本級的隱性主題表示進行聯合建模，這有助於緩解在社交媒體語言中廣泛存在的數據稀疏性。在從英文和中文社交媒體平臺收集的三個數據集的實驗表明，我們的模型明顯優於不利用隱性主題的基於抽取或生成的模型。進一步的討論表明，我們的模型能學習到有意義的主題，這也解釋了它在社交媒體關鍵詞生成中的優越性。</p><p><strong>2. 基於圖匹配神經網絡的跨語言知識庫實體對齊</strong></p><p>Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxMy7CzCFUTo><p>本文由騰訊AI Lab主導，與IBM T.J Waston Research Center、Amazon AWS合作完成。之前面向跨語言知識庫實體對齊的工作主要是基於從單語言知識庫中學習出來的實體表達，因此很難對齊在跨語言知識庫中具有不同事實性描述的實體。為了解決這個問題，本工作提出一個“實體主題圖”，即首先將實體在跨語言知識庫裡的事實抽取出來，各自形成一個子圖。然後將實體對齊的任務轉變成圖匹配的問題。同時我們提出一個圖匹配神經網絡算法，首先匹配兩個子圖裡面所有實體，再綜合實體匹配的結果生成一個圖匹配結果。實驗結果表明，通過這樣的方法，我們提出的模型可以更好地利用實體附近的上下文信息判斷實體匹配的結果。</p><p><strong>3. 用於專名識別的可靠性感知的動態特徵組合</strong></p><p>Reliability-aware Dynamic Feature Composition for Name Tagging</p><p>論文地址：</p><p>http://nlp.cs.rpi.edu/paper/featurecomposition2019.pdf</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxMyb7IefmVI><p>本文由騰訊AI Lab與RPI、UIUC合作完成。詞向量被廣泛運用於各種任務，然而受限於,詞頻的長尾分佈，其性能在整個詞彙表中並不一致。由於缺乏足夠的語境信息，稀有詞的向量表示通常不如普通詞的表示。通用的模型通常信任所有詞向量，而不考慮它們的可靠性，因此可能引入噪聲並損害其性能。由於專有名詞通常包含罕見和未知的詞語，因此該問題對於專名識別尤其重要。本文提出了一種新穎的可靠性感知的專名識別模型來解決這個問題。我們設計了一組基於字頻率的可靠性信號，以指示每個詞向量的質量。在可靠性信號的指導下，該模型能夠使用門控機制動態選擇和組合諸如詞向量和字符級表示之類的特徵。例如，如果輸入單詞為罕見詞/稀有詞，則模型較少依賴於其詞嵌入，併為其字符和上下文特徵分配較高權重。在OntoNotes 5.0上的實驗表明，我們的模型比基準模型提高了6.2%的F-score。在OntoNotes的六個文體的跨類型實驗中，我們的模型提升了大多數類型對上的性能，平均獲得2.3％的F-score絕對增益。</p><p><strong>方向二：對話系統和文本生成</strong></p><p>目前大多數對話系統是通過生成方法或基於檢索方法實現。隨著大數據和深度學習技術的發展，生成式對話系統及文本生成技術取得了巨大進展。最早的序列到序列（Seq2Seq）模型把對話回覆生成視為一個翻譯問題，學習對話上下文到其回覆的對齊關係。但生成回覆比翻譯語言要困難得多，這可能是在對話場景中，輸入與輸出之間並沒有嚴格的短語對齊關係，允許有大量看似合理的回覆同時存在。本次 ACL 會議中，騰訊AI Lab的工作討論了多個對話任務場景中的特性及問題，包括結合對話的句子功能、增強對話生成中的語料記憶能力以及提升對話回覆的語義可控性、多樣性、連貫性等問題。</p><p><strong>1. 短文本對話中的細粒度句子功能</strong></p><p>Fine-Grained Sentence Functions for Short-Text Conversation</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNIZFrax1e0><p>帶有細粒度句子功能的短文本對話句對。可以看到，對於不同句子功能的query（Yes-no/Wh-style疑問句）, 他們本身以及相應回覆的句子結構都大不相同。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNJ02psJNDb><p>三種細粒度疑問句的常見句子結構。x和y是代表內容詞的變量。句子中帶下劃線的單詞對應於句子結構中的單詞。</p><p>本文由騰訊AI Lab主導，與蘇州大學合作完成。句子功能（Sentence function）是一個重要的語言學特徵，該特徵在對話中能夠體現說話者的目的。已經有許多研究結果表明引入句子功能特徵改善對話模型的性能。但是，目前仍舊不存在一個帶有句子功能標註的大型對話數據。在這個工作中，我們構建了一個新的帶有句子功能標註的短文本對話數據集。在此數據集上我們訓練了分類網絡用於：(1) 確定新的大型短文本對話數據中句子的功能類別；(2) 根據測試輸入預測回覆文本可能的句子功能。我們在此基礎上搭建了基於檢索和生成的兩種對話模型。實驗結果表明使用句子功能特徵可以幫助這些對話模型提高生成回覆的性能。</p><p><strong>2. 學習如何抽象：一種記憶增強的對話生成模型</strong></p><p>Learning to Abstract for Memory-Augmented Conversational Response Generation</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxNJLFzryPfY><p>模型框架圖：本文致力於開放域閒聊對話，探究檢索式對話和生成式對話更好的結合方式。</p><p>本文由騰訊AI Lab主導，與香港科技大學合作完成。神經網絡生成模型存在諸如生成的回覆多樣性差、信息量不足等一些問題。一些研究者嘗試利用檢索系統去增強生成模型的效果，但是該方法受限於檢索系統的質量。在本文中，我們提出了一種記憶增強的生成模型，他可以對訓練語料進行抽象，並且把抽象出來的有用的信息存儲在記憶模塊中，以便輔助生成模型去生成回覆。具體來說，我們的模型會先對用戶輸入(query)-回覆(response)的聚對做聚類，接著抽取出每個類的共性，然後讓生成模型學習如何利用抽出的共性信息。實驗效果表面我們的模型可以大幅提升回覆生成的效果。</p><p><strong>3. 基於指代對齊和對話流建模的連續問題生成</strong></p><p>Interconnected Question Generation with Coreference Alignment and Conversation Flow Modeling</p><p>論文地址：https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>v.org/abs/1906.06893</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RXUxNJh7rSBtO9><p>本文研究了問答式對話這一場景中的連續問題生成，目標是生成具有對話性的問題Q1~10。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNKH9qznGbG><p>模型框架圖</p><p>本文由騰訊 AI Lab 主導，與香港中文大學合作完成。本文研究問答式對話這一場景中的連續問題生成。之前的工作是基於一句話（或一段話）生成問題，本工作的不同之處在於: （1）問題的對話性很強，對話中一半的問題利用指代關係依賴於歷史對話；（2）在一個連貫的對話中，不同輪之前的問題有著連貫的焦點轉移。我們提出了一個端到端的基於指代對齊和對話流建模的模型。指代對齊模塊顯式地將對話歷史中的實體名詞和生成問題中的相應的代詞對齊，使得問題能夠與歷史對話連貫。對話流模塊在對話的前幾輪<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">關注</i>文章前半部分的內容，並隨著對話的深入，逐漸轉移注意力到文章後面的部分。實驗表明我們提出的模型超過了基線系統的水平並能夠生成對話性強的問題。</p><p><strong>4. 基於多級解偶自注意力機制的對話回覆生成機制</strong></p><p>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</p><p>論文地址：https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>v.org/pdf/1905.1<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">286</i>6.pdf</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNfi1QglCH6><p>本文研究了對話回覆生成機制，目標是生成語義可控的對話回覆。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNgJ39tv7Vs><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNghCdEzEzT><p>模型框架圖</p><p>本文由騰訊AI Lab和加州大學Santa Barbara分校合作完成。本文主要解決用語義來控制對話回覆生成的問題。在用語義控制多領域大規模對話的生成的問題中，因為多種語義輸入的組合呈現指數增長，所以在實際解決時會面臨很大困難。本文針對這個問題，將一系列對話決策整合成一個多層的分級圖結構，並將這個結構整合到Transformer模型結構中，用於控制其對話文本生成過程。在大規模Multi-Domain-WOZ數據集上，我們提出的模型獲得了超過4個BLEU點的提升，同時人工評測也顯著超越其他基準方法。</p><p><strong>5. 訓練數據是否相互關聯？基於多個參考回覆的對話生成模型</strong></p><p>Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNh6336f9Cu><p>兩步生成架構示意圖：傳統模型從頭開始建模每個回覆（綠色標識），我們的方法首先建立多個回覆的共同特徵，然後在此基礎上對每個回覆進行建模。</p><p>本文由騰訊AI Lab與北京大學合作完成。現有的生成式模型往往會面臨通用回覆的問題，這是因為其未能很好地考慮到對話中自然存在的提問與回覆之間一對多的映射關係。對此，本文通過考慮多個參考回覆之間的相關性，提出了一種兩步式的對話生成模型，來分別建模多個回覆之間的共性與個性特徵。實驗結果顯示本文提出的方法可以生成多樣且合理的回覆，並且相較於基準模型在自動與人工評測指標下均有著更好的表現。</p><p><strong>方向三：機器翻譯</strong></p><p>機器翻譯是人工智能的終極目標之一，其中核心的語言理解和語言生成是自然語言處理的兩大基本問題，極具挑戰性。雖然神經網絡機器翻譯近幾年來取得了巨大進展，但是由於當前神經網絡的不可解釋性，無法保證原文內容完整傳遞到譯文，使得神經網絡翻譯模型存在譯文忠實度問題 (即“達而不信”) 。騰訊AI Lab專注於解決該核心問題，在ACL2019會議上發表的多篇論文，嘗試解釋當前主流Transformer模型核心的解碼器及注意力模型的建模能力，加強對神經網絡翻譯模型的理解，希望能啟發其他研究者對神經網絡翻譯模型的進一步改進。</p><p><strong>1. 神經機器翻譯中句子表示的利用</strong></p><p>Exploiting Sentential Context for Neural Machine Translation</p><p>論文地址：https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>v.org/pdf/1906.01268.pdf</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxNhM5kEXEXz><p>圖1 利用多層源語言句子表示的方法框架</p><p>本文由騰訊AI Lab獨立完成。本文針對“編碼器-解碼器”結構的神經機器翻譯模型提出一種利用源語言句子表示的方法。具體地，針對神經機器翻譯中的多層表示，分別提出源語言句子淺層表示和深層表示兩種具體的方法 (圖1)，並將該源語言句子表示集成至神經機器翻譯解碼器中以指導目標語言句子的生成。實驗表明，在多個翻譯數據集上，該方法可以取得比基準模型更好的翻譯性能。進一步分析表明，該方法可以增強編碼器對原句語言信息的建模能力。該論文是我們探索編碼器表示的第四個工作，前續工作通過深層表示融合及結構化建模，改進編碼器對原句的理解及表達能力。</p><p><strong>2. 評估自注意力網絡的詞序學習能力</strong></p><p>Assessing the Ability of Self-Attention Networks to Learn Word Order</p><p>論文地址：https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>v.org/pdf/1906.00592.pdf</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxNzn4CU7WDJ><p>圖1 單詞重排序檢測任務 (WRD)</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxO0738bELYX><p>表1 翻譯 (Translation) 及WRD準確率 (Detection) 。"En=>De Enc."和"En=>Ja Enc."指對應雙語語料訓練的NMT模型的編碼器，"WRD Enc."指在WRD單語數據上訓練的編碼器。"- Pos_Emb"指去除SAN模型中的詞語位置編碼。</p><p>本文由騰訊 AI Lab 主導，與澳門大學合作完成。自注意力網絡(SAN)由於其高並行化和在機器翻譯等NLP任務上的出色表現而受到廣泛<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">關注</i>。由於缺乏諸如遞歸神經網絡(RNN)之類的遞歸結構，SAN被認為在序列建模時學習詞序信息的能力較弱。然而，這種推測既沒有得到經驗上的驗證，也無法解釋為何在"缺乏位置信息"的情況下基於SAN的機器翻譯模型依然表現出色。為此，我們提出了一種全新的單詞重新排序檢測任務 (圖1)，用來量化SAN和RNN結構的詞序信息的捕獲能力。具體地，我們將一個單詞隨機移動到另一個位置，並檢驗特定模型是否能夠檢測出原始位置和<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">插入</i>位置。實驗結果 (表1) 表明：1) 即使引入位置編碼 (position encoding) ，SAN在單詞重排序檢測任務中難以學習好詞序信息; 2) 但是在機器翻譯任務中，SAN可以比RNN可以更好地捕獲詞序信息，其中位置編碼起著至關重要的作用。儘管遞歸結構使模型在學習詞序方面更普遍有效，但學習目標在機器翻譯等下游任務中更為重要。該論文是我們探索自注意力模型的第四個工作，前續工作改進了自注意力模型的局部建模能力和全局建模能力。</p><p><strong>3. 機器翻譯中的詞對齊</strong></p><p>On the Word Alignment from Neural Machine Translation</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxO0MBpYxBnN><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxO0aBJJF0wO><p>本文由騰訊AI Lab 主導，與香港中文大學、哈爾濱工業大學合作完成。在機器翻譯的研究中，注意力機制一直被認為是詞對齊，然而在多層複雜結構的神經機器翻譯模型裡，研究者發現編碼器-解碼器注意力機制可能不能做為一個有效的詞對齊模型。於是，本文提出了兩種與機器翻譯具體模型無關的獲取詞對齊的方法。實驗表明所提出的兩種方法獲得的詞對齊都遠好於注意力機制獲取的詞對齊（參見Table 1）。在論證了神經機器翻譯模型確實可以學到不錯的詞對齊之後，研究者試圖使用神經機器翻譯模型本身詞對齊去理解機器翻譯。通過在數據集上量化分析詞級別上的詞對齊錯誤對於翻譯錯誤的影響，本文論證了詞對齊錯誤會一定程度上導致翻譯的錯誤。通過將目標端的詞分為主要貢獻來自於源端(CFS)和目標端(CFT)，分析結果顯示，主要貢獻來自於源端的詞的詞對齊錯誤對翻譯錯誤的影響佔主要部分（參見Table 2）。</p><p>注意力模型一直是神經網絡翻譯模型的核心組件，尤其是當前主流的Transformer模型甚至是純粹由注意力模型組成。在前續工作中，我們同樣對Transformer中自注意力模型及編碼器-解碼器注意力模型的具體實現方式–多頭注意力機制進行了探索，通過鼓勵其多樣性和信息融合方式，進一步增強注意力模型的表達能力。</p><p><strong>其他入選論文</strong></p><p><strong>1. 弱監督的時空域自然語句視頻定位</strong></p><p>Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video</p><p>本文由騰訊AI Lab主導，與香港大學合作完成。在本文中，我們討論了一個新的任務，即弱監督的時空域自然語句視頻定位。具體而言，給定自然句子和視頻，我們在視頻中定位時空片段，其在語義上對應於給定的句子，而不依賴於訓練期間的任何時空的標註。首先，我們從視頻中提取一組稱為實例的時空片段。然後，我們使用我們新提出的注意交互模塊對這些實例和句子進行編碼，這可以利用它們的細粒度關係來表徵它們的匹配行為。除了排名損失之外，還引入了一種新的多樣性損失來訓練我們注意交互模塊，以加強可靠的實例-句子對的匹配行為，並懲罰不可靠的實例-句子對。我們還根據ImageNet視頻對象檢測數據集提供了一個名為VID-sentence的數據集，作為我們任務的基準數據集合。大量實驗的結果證明了我們的模型優於基線方法。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxO0oCQQZiFd><p><strong>2. 多句子壓縮的無監督重寫器</strong></p><p>Unsupervised Rewriter for Multi-Sentence Compression</p><p>本文由騰訊AI Lab主導，與東京大學合作完成。多句壓縮（MSC）旨在根據多個輸入句子生成一個語法正確的壓縮句，同時保留其關鍵信息。之前的工作大多是利用基於提取的詞圖的方法。之後的一些工作進一步利用詞彙替換產生抽象的壓縮句子。但是，當前的方法存在兩個不足。首先，簡單地連接多個句子中的片段的詞圖方法可能會產生生硬或不合語法的壓縮句。其次，在不考慮上下文信息的詞彙替換通常也會導致不恰當的壓縮句子。因此，為了解決上述問題，我們提出了一種用於多句子壓縮的神經重寫器，並且不需要任何平行語料庫。實驗結果表明，我們的方法在自動評價指標上取得了可比較的結果，並且在人類評價上面提升了壓縮句子的語法正確性。此外，我們也構建了大約<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">140</i>,000個（多句子，壓縮句）對的平行語料庫，以便用於未來的研究。</p><p><strong>3. 利用多頭注意力機制建模數學應用題內在聯繫</strong></p><p>Modeling Intra-Relation in Math Word Problems with Different Functional Multi-Head Attentions</p><p>本文由騰訊AI Lab與電子科技大學、新加坡管理大學合作完成。本文針對數學應用題的自動求解提出了一種分組注意力機制，來分別提取數學應用題中的全局特徵、數字相關特徵、數字對相關特徵和問題相關特徵。實驗結果表明，該方法的性能明顯優於現有的先進方法，在多個數據集上均取得了更好的解題準確率。</p><p><strong>4. 低資源命名實體識別中的雙重對抗神經網絡遷移學習</strong></p><p>Dual Adversarial Neural Transfer for Low-Resource Named Entity Recognition</p><p>本文由騰訊AI Lab/Robotics X與新加坡A*STAR，MIT合作完成。本文提出一種新的神經網路遷移學習算法，稱為雙重對抗傳輸網絡（DATNet），用於解決低資源命名實體識別問題。具體地，本文研究了DATNet的兩種變體，即DATNet-F和DATNet-P，以探索高資源和低資源之間的有效特徵融合。為了解決有噪聲的和不平衡的訓練數據，我們提出了一種新穎的一般性的資源對抗鑑別器（GRAD）。此外，採用對抗訓練來推動模型泛化。在實驗中，我們檢查DATNet中不同組件對跨域和跨語言應用的影響，並表明可以獲得顯著的改進，特別是對於低資源數據，而不增加任何額外的手工製作的特徵和預先訓練的語言模型。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RXUxOCDA7ZfAOL><p><strong>5. 關於對話上文和用戶聊天曆史對用戶重回對話行為的研究</strong></p><p>Joint Effects of Context and User History for Predicting Online Conversation Re-entries</p><p>本文由騰訊AI Lab與香港中文大學、美國東北大學合作完成。隨著網絡世界的持續膨脹，人與人之間的交互如今在觀點的形成和變化方面扮演著愈發重要的角色。為了幫助用戶更好地參與到線上對話當中，我們研究了一個有挑戰性的問題：用戶重回對話的行為預測。我們假設對話的上文和用戶過去的聊天曆史都能夠影響他們對於一個對話的持續性興趣。特別地，我們提出了一個神經網絡的框架，這個網絡共有三個主要層，每一層分別建模對話上文、用戶討論興趣、以及他們之間的關係以預測一個用戶是否會重回一個對話。我們在兩個大規模的數據集上做了實驗分析，這兩個數據集分別收集自Twitter和Re<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">dd</i>it。實驗結果分析顯示用雙向注意力機制建模對話上文和用戶聊天曆史在Twitter上能夠取得61.1的F1，超過了之前最好模型的結果。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RXUxOCa9RnBIxg><p><strong>6. 一個大規模可用於生成一致性摘要式文摘的專利數據集</strong></p><p>BigPatent: A large-Scale Dataset for Abastractive and Coherent Summarization</p><p>本文由騰訊AI Lab與美國東北大學合作完成。當前大部分存在的文摘數據集都是來源於新聞領域。在這類摘要中，大部分摘要需要的內容都是會集中在文章的開頭。而當文摘需要理解文章的全局信息，或者文摘需要高壓縮率的時候，這類數據集的這種缺點就顯而易見了。在這個工作中，我們發佈了一個新的數據集，包含了一百三<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">十萬</i>的美國專利文檔以及對應的摘取式摘要。和現在研究領域常用的文摘數據相比，我們新發布的數據有如下的特點：1.文摘有豐富的結構化信息和重複的命名實體。2. 文章中重要的信息分散在文章的不同位置。3. 在提供的文摘中存在大量簡短的抽取式摘要。在論文的最後，我們在新發布的數據上實驗了一些基礎模型來揭示該數據集上做文摘會遇到的新挑戰。</p><p><strong>7. 基於預訓練Transformer模型的多關係抽取器</strong></p><p>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</p><p>本文由騰訊AI Lab與IBM T.J Waston Research Center合作完成 。多關係抽取任務中，目前的方法大多需要對目標的段落/句子進行多次(multiple-pass)編碼操作，成本高且對長段落和大數據集應用效果差。本文的方法可以對一個段落中的多關係抽取任務，只進行一次段落編碼（one-pass），從而緩解上述問題。此外，本文結合預訓練語言模型BERT，針對Relation Classification任務的特點提出了兩種抽取entity-aware信息的策略。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RXUxOCt3XCT9qs><p><strong>8. 基於知識的代詞指代消解</strong></p><p>Knowledge-aware Pronoun Coreference Resolution</p><p>本文由騰訊AI Lab與香港科技大學合作完成。代詞的指代消解需要外部知識，尤其是對於某些特定的領域，比如醫藥領域。在本文中，我們探索如何構建神經網絡利用多種外部知識。為了保證我們的模型有足夠的泛化能力，我們直接將外部知識組織成三元組的形式。在外部知識中，有些知識在特定的上下文中並沒有幫助，為此我們提出了一個面向知識的注意力機制，根據不同的上下文選擇合適的知識進行指代消解。在兩個評測數據集上的結果表明我們的方法是有效地，並且顯著地超過基線方法。同時，由於我們的方法學會了如何利用外部知識，而不只是過擬合在某個訓練集合上，所以我們的方法在跨領域的指代消解任務裡，也顯著超過了基線方法。</p><p><strong>9. 面向領域遷移的訓練數據選擇方法</strong></p><p>Reinforced Training Data Selection for Domain Adaptation</p><p>本文由騰訊AI Lab與香港科技大學、蒙德利爾大學合作完成。強監督學習模型通常會遇到領域遷移的問題。為了解決這個問題，訓練數據的選擇通常被認為是一個解決領域遷移問題的方法。傳統的方法通常需要一個預先設置的閾值，然而這個閾值通常並不容易設置，而且在不同的任務中通常也不一樣。為了解決這個問題，我們提出了一個強化學習框架，同時學習選擇訓練數據和利用訓練數據。我們設計了一個選擇分佈生成器，在強化學習過程中不斷根據獎勵函數進行更新。在POS tag標註，依存關係分析和情緒分析的任務中的實驗結果表明我們的方法不僅在數據選擇任務中有效，也可以泛化到不同的NLP任務中。</p><img alt="ACL 2019 | 騰訊AI Lab解讀三大前沿方向及20篇入選論文" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RXKBxDD2KLAPSG></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ACL</a></li><li><a>2019</a></li><li><a>騰訊</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html alt="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RdGewJX7BKaFVS style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f34d1055.html title="ACL 2019 | 南大NLP，知識庫問答中的表示映射學習">ACL 2019 | 南大NLP，知識庫問答中的表示映射學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3afbc841.html alt="ACL 2019全程回顧：自然語言處理趨勢及NLP論文乾貨解讀" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7dbbb4efa0b54543b7e50bce7e3d01cb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3afbc841.html title="ACL 2019全程回顧：自然語言處理趨勢及NLP論文乾貨解讀">ACL 2019全程回顧：自然語言處理趨勢及NLP論文乾貨解讀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/87ed15b.html alt="ACL 2019論文｜為知識圖譜添加注意力機制" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RVvkOoB1KZNTom style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/87ed15b.html title="ACL 2019論文｜為知識圖譜添加注意力機制">ACL 2019論文｜為知識圖譜添加注意力機制</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html alt=2019年土木畢業生要知道的那些事 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html title=2019年土木畢業生要知道的那些事>2019年土木畢業生要知道的那些事</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html alt=2019年度《特種鑄造及有色合金》優秀論文結果公佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/137c70000b816835d80bf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html title=2019年度《特種鑄造及有色合金》優秀論文結果公佈>2019年度《特種鑄造及有色合金》優秀論文結果公佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html alt=2019年度《特種鑄造及有色合金》網絡評選結果出爐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/66c26cbe459a4361b1d501e4bbac6c88 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html title=2019年度《特種鑄造及有色合金》網絡評選結果出爐>2019年度《特種鑄造及有色合金》網絡評選結果出爐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html alt=金川集團公司2019年全國合金鑄造行業商洽會舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html title=金川集團公司2019年全國合金鑄造行業商洽會舉行>金川集團公司2019年全國合金鑄造行業商洽會舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html alt="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html title="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班">2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html alt=2019年最爆笑的120個名場面合集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dc6fcd05f35e499a9ef7a2d19ff9c66b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html title=2019年最爆笑的120個名場面合集>2019年最爆笑的120個名場面合集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html alt=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a08cc2f25cb41c5be515de0d79879a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html title=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝>《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html alt="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/Rk8ZSn39iz0Be8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html title="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法">2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/75735682.html alt=不愧是騰訊！光靠遊戲一天血賺4.6億人民幣，你貢獻了多少？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/cc290697431a45ef916ee0c90f6ad0f6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/75735682.html title=不愧是騰訊！光靠遊戲一天血賺4.6億人民幣，你貢獻了多少？>不愧是騰訊！光靠遊戲一天血賺4.6億人民幣，你貢獻了多少？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html alt=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/f8d17716-f3b8-4c6d-8eb7-f482334ad491 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html title=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！>2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html alt=2019年正在流行的16個網頁設計趨勢 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RPgQdSQEjBTN6Z style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html title=2019年正在流行的16個網頁設計趨勢>2019年正在流行的16個網頁設計趨勢</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5aff079a.html alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1528975110519ee64a67c03 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5aff079a.html title="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析">ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>