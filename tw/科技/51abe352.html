<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>視覺交通仿真研究：自動駕駛中的模型，評估和應用 | 极客快訊</title><meta property="og:title" content="視覺交通仿真研究：自動駕駛中的模型，評估和應用 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/12df25dc0418499f8f6eb033f4074160"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51abe352.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51abe352.html><meta property="article:published_time" content="2020-11-14T21:02:04+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:04+08:00"><meta name=Keywords content><meta name=description content="視覺交通仿真研究：自動駕駛中的模型，評估和應用"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/51abe352.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>視覺交通仿真研究：自動駕駛中的模型，評估和應用</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>來源：自動駕駛測試驗證技術創新論壇</strong></p><p style=text-align:justify><br></p><p style=text-align:justify><strong>1引言</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>近年來，視覺流量吸引了許多研究社區的關注，包括但不限於計算機遊戲，城市可視化，城市規劃和自動駕駛。在虛擬現實，遊戲和動畫中，城市場景必不可少，這些場景不可避免地涉及到大量的車輛行駛。為了控制單個車輛的運動，一種簡單的解決方案是使用關鍵幀方法。但是，在大型交通場景中使用關鍵幀方法模擬交通擁堵，頻繁變道和行人與車輛的交互作用，不僅需要複雜的設計和動畫師的反覆調整，而且所產生的車輛運動也很少符合物理定律。因此，有效地模擬大規模流量已成為計算機圖形學中越來越必要的主題。此外，由於道路網絡可視化工具（如OpenStreetMap，ESRI和Google Maps）的普及，將實時交通流納入虛擬道路網絡已變得至關重要。然而，很難訪問車輛的實際軌跡並將其實時地整合到虛擬應用程序中。這些趨勢激發了對數據驅動的流量模擬[WSLL15]的研究努力。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了上述在動畫和可視化中的應用之外，交通模擬在交通研究中還具有廣泛的應用。交通仿真軟件包，例如VISSIM [PTV11]，TSIS [TSI18]和PARAMICS [PAR18]，是研究人員研究交通網絡性能的有效工具。基於虛擬現實的駕駛培訓計劃通過產生現實的交通環境[VRd18，LWX * 18]幫助新駕駛員提高了駕駛技能。交通模擬還可以用作生成各種交通條件以訓練和測試自動駕駛車輛的有效工具[SAMR18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>此外，車輛交通量的增加和複雜道路網絡導致了許多與交通有關的問題，例如交通擁堵，事件管理，信號控制和網絡設計優化。使用基於分析模型的傳統工具很難解決這些問題[SHVDWVW16]。因此，已經嘗試使用先進的計算技術對交通的建模，模擬和可視化進行許多研究工作，以分析交通管理的交通狀況[PBH12，WLY * 13，WYL * 14]或協助城市發展中的交通重建[ GDGAVU14]。</p><p style=text-align:justify><br></p><p style=text-align:justify>交通模擬的主要重點是回答以下問題：給定道路網絡，行為模型和初始車輛狀態，交通將如何演變？關於交通流的建模和仿真，有大量的數學描述，可以大致分為宏觀模型[SWML10]，微觀模型[SJ12]和介觀模型[SWL11]。儘管宏觀方法將車輛的收集視為連續流動，但微觀方法卻在周圍車輛的影響下為每個車輛的動力學建模。相比之下，介觀模型結合了微觀模型和宏觀模型的優勢，可以模擬不同細節級別的流量。另外，道路網絡的生成和表示也是交通仿真中的一個基本問題。</p><p style=text-align:justify><br></p><p style=text-align:justify>儘管前面提到的交通模型可以有效地捕獲高層交通狀況，但是所得的模擬結果通常與街道上的真實交通情況並不相似。隨著先進的傳感硬件和計算機視覺技術的發展，以視頻，LiDAR和GPS傳感器形式的經驗性交通流數據集變得越來越可用。這種現象產生了數據驅動的交通動畫技術。示例工作包括從現有道路傳感器[SVDBLM11，WSL13，LWL17]獲取的時空數據重構交通流，從有限的軌跡樣本[CDR * 18]合成新的交通流以及通過從交通監控數據集中學習行為模式和個人特徵[CSJ13，BMWD16]。</p><p style=text-align:justify><br></p><p style=text-align:justify>儘管在交通模擬和動畫方面取得了重大進展，但迄今為止，如何衡量模擬交通的真實性仍未得到充分探索。此外，在基於模型的交通仿真和數據驅動的動畫方法中，始終要關注基於仿真交通與現實交通之間的相似性進行模型驗證。為了解決這些問題，當前的方法包括使用主觀用戶評估並將客觀評估指標納入度量[CDX * 18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>通過各種交通模擬和動畫技術的虛擬交通也已應用於自動駕駛培訓。自動駕駛有可能改變我們的交通系統。但是，最近的測試失敗強調了在模擬環境中對這些自動化機器的培訓，然後再將其部署到現實世界中[BNP * 18，LWL19，LPZ * 19]。</p><p style=text-align:justify><br></p><p style=text-align:justify>當前，通常在虛擬環境[WEG * 00，DRC * 17，apo18]中使用具有預定行為的單個干擾道路用戶（例如，車輛，行人或自行車）來測試自動駕駛車輛的性能。在模擬的交通流中進行訓練，並在各種道路使用者之間進行豐富的交互，自動駕駛汽車可以潛在地獲得處理複雜城市環境中複雜交通狀況的能力。此外，交通模擬和動畫還可以受益於為自動駕駛汽車開發的基於學習的運動計劃和決策算法。具體來說，隨著收集的駕駛數據集數量的增加，由此產生的精確交通仿真可以從更準確的交通語義上豐富自動駕駛汽車的運動計劃和決策。</p><p style=text-align:justify><br></p><p style=text-align:justify>為了實現安全的無人駕駛，需要具有逼真的交通流量和複雜交通狀況的高保真駕駛模擬器。這樣的模擬器可以以有效且可再現的方式產生關鍵的訓練環境。由於交通模擬在自動駕駛研究中變得至關重要，因此在本次調查中，我們將特別從三個方面描述自動駕駛的最新發展：數據採集，運動計劃和測試模擬。</p><p style=text-align:justify><br></p><p style=text-align:justify>組織。本調查的其餘部分安排如下。第2節介紹了三類基於模型的交通模擬方法，併為道路網絡的過程建模和幾何表示提供了不同的代表性方法。第3節概述了基於不同數據採集方法的各種數據驅動動畫技術。第4節研究了動畫方法的驗證和生成的虛擬流量的評估。第5節介紹了最近在數據採集，運動計劃以及將虛擬交通用於自動駕駛研究方面的工作。最後，第6節和第7節在總結本調查的基礎上，討論了現有研究的當前狀態以及我們對未來研究方向的看法。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2基於模型的交通模擬</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通模擬中的一個重要組成部分是描繪各個細節級別的車輛運動。交通流建模和仿真的早期研究可以追溯到1950年代，當時分別提出了宏觀交通模型和微觀交通模型[Pip53，LW55]。經過多年的發展，交通模擬技術有三種通用類型[VWKVLVH15，FSS18]（如圖2所示），即宏觀（2.1節），微觀（2.2節）和中觀（2.3節）。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/12df25dc0418499f8f6eb033f4074160><p class=pgc-img-caption></p></div><p style=text-align:center>圖1</p><p style=text-align:justify><br></p><p style=text-align:justify>通過各種交通模擬和動畫方法生成的交通流：（a）Chao等人在高速公路網絡上的綜合交通流。[CDR * 18]，（b）來自沈和金的信號交叉路口的密集交通場景[SJ12]，（c）使用來自Wilkie等人的道路傳感器數據重建虛擬交通流。[WSL13]，（d）使用Li等人的GPS數據重建的城市規模交通。[LWL17]，以及（e）用於自動駕駛測試的異構交通仿真[CJH * 19]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0d559a8841e5449e9e242d010c239785><p class=pgc-img-caption></p></div><p style=text-align:center>圖2</p><p style=text-align:justify><br></p><p style=text-align:justify>本次調查介紹了交通模擬和動畫組件的架構。首先，傳統交通模擬和動畫的組成部分：道路網絡生成（第2.4節）；交通數據獲取（第3.1節）；基於模型的仿真（第2節）；數據驅動的動畫（第3.2節）; 以及驗證和評估（第4節）。第二，自動駕駛研究的組成部分：自動駕駛培訓數據集（第5.1節）；運動計劃和決策方法。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89cbce8e99f449d9b226b7606c30f8f7><p class=pgc-img-caption></p></div><p style=text-align:center>圖3</p><p style=text-align:center><br></p><p style=text-align:justify>基於模型模擬的詳細程度對基於模型的交通模擬方法進行分類。在這裡，LWR和ARZ分別指的是Lighthill.Whitham.Richards [LW55，Ric56]和Aw.Rascle.Zhang [AR00，Zha02]提出的兩種流行的宏觀交通模型。</p><p style=text-align:justify><br></p><p style=text-align:justify>交通流量可以被視為人群流量的一種：流量中的車輛具有相似的目標和行為規則，在保持個人駕駛特性的同時與鄰居互動。在計算機圖形學中，人群模擬一直是重要的研究領域，支持對集體行為和動力學的研究[PAB08，ZCC * 10]。可以通過宏觀方式（以犧牲單個個體的實際運動為代價對人群進行整體建模）[NGCL09]或微觀方式（將群體作為個體個體的運動集合進行建模）來實現人群模擬[WLP16] 。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.1宏觀方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>宏觀方法也稱為連續體方法，它以較低的詳細程度描述車輛的行為和相互作用：交通流由速度，流量，密度等方面的連續體表示。宏觀方法主要用於在道路上進行有效的交通模擬大型道路網絡，著重於再現以集體量（例如流量密度和交通流量）衡量的綜合行為。</p><p style=text-align:justify><br></p><p style=text-align:justify>Lighthill和Whitham [LW55]和Richards [Ric56]開發了一種早期的一階宏觀模型，稱為LWR模型。他們的模型假設交通流率僅取決於描述交通密度關係的交通密度。</p><p style=text-align:justify><br></p><p style=text-align:justify>該模型基於一維可壓縮氣體動力學與單車道上交通流演變之間的相似性，建立了用於對交通流進行建模的非線性標量守恆定律。本質上，LWR模型描述了具有低分辨率細節的大規模交通流的運動。它的侷限性之一是無法在非平衡條件下（例如走走停停的波浪）模擬車輛的運動。</p><p style=text-align:justify><br></p><p style=text-align:justify>後來，Payne [Pay71]和Whitham [Whi74]提出了一個連續的二階交通流模型，該模型被稱為Payne-Whitham（PW）模型。儘管一階模型假定存在固定的平衡狀態，但是二階模型引入了一個第二個微分方程來描述交通速度動力學。作為限制，PW模型可能會引入負速度，並且從車輛動力學生成的信息傳播的速度可能快於車速，這意味著駕駛員可能會受到其後續車輛的影響。Aw and Rascle [AR00]和Zhang [Zha02]提出了對PW模型的修改，以消除其非物理行為。具體來說，Aw和Rascle [AR00]引入了壓力項，以確保沒有任何信息能比汽車的速度更快地傳播。張[Zha02]，類似地，提出了對PW模型的動量方程的修改，以處理向後傳播的交通。生成的模型稱為Aw-Rascle-Zhang（ARZ）模型，自[Ras02，GP06，LMHS07，MR07]以來已進行了深入研究。Mammar等。[MLS09]表明，ARZ模型在數值上比LWR模型更適合現實世界的數據。</p><p style=text-align:justify><br></p><p style=text-align:justify>為了產生詳細的3D動畫和交通流的可視化，Sewall等人。[SWML10]提出了一種連續交通仿真模型，用於在大型道路網絡上生成現實的交通流。他們通過引入新的車道變換模型併為每輛車使用離散表示，使單車道ARZ模型適應多車道交通。如圖4所示，通過將每個車道離散化為多個像元來模擬交通流。為了更新每個像元的狀態，將空間離散化的有限體積方法[LeV02]與Riemann求解器結合使用來求解ARZ方程。為了模擬車道合併和換道行為，Sewall等人。通過將車輛表示為“小車”，將連續動力學與離散的車信息結合起來。這些“迴轉”是由潛在的連續流驅動的。</p><p style=text-align:center><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c1cf3ee36c6f40d980426e8419d19be7><p class=pgc-img-caption></p></div><p style=text-align:center>圖4</p><p style=text-align:center><br></p><p style=text-align:justify>宏觀交通仿真方法的插圖[SWML10]。每個泳道分為離散的單元格。在給定的時間步長，通過求解ARZ方程更新每個像元的狀態，然後使用這些解決方案更新每個車道中每個車輛的狀態。</p><p style=text-align:justify><br></p><p style=text-align:justify>總之，宏觀交通模型是模擬大規模交通的有效工具。但是，此類技術僅限於高速公路網絡，因此不適合模擬由單個汽車之間的豐富交互組成的街道級交通。此外，由於這些模型沒有對車輛的車道合併行為進行建模，因此它們無法處理車道轉換過程中的密度傳遞。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.2微觀方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>微觀模型可產生高細節的車輛運動：每輛車輛都被視為滿足某些控制規則的離散主體。已經針對特定的城市交通模擬開發了許多微觀模型，這歸因於它們在建模代理的異構行為，各種道路拓撲以及周圍車輛之間的相互作用方面的靈活性。</p><p style=text-align:justify><br></p><p style=text-align:justify>微觀模型的早期例子包括細胞自動機模型[NS92]和跟車模型[Pip53，HG63]。元胞自動機模型中車輛的運動由預先指定的時間，空間和狀態變量中的演化規則描述。具體而言，將道路離散為多個單元，然後模型確定車輛何時從當前單元移至下一個單元。由於其簡單性，元胞自動機模型的計算效率很高，並且可以在大型道路網絡[KSSS04]上模擬大量車輛。但是，由於其離散性，生成的虛擬流量只能重現有限數量的真實流量行為。</p><p style=text-align:justify><br></p><p style=text-align:justify>相比之下，由Pipes [Pip53]和Reuschel [Reu50]首次引入的跟車模型可以以計算為代價生成逼真的駕駛行為和詳細的車輛特性。他們假設交通流由分散的微粒[SZ14]組成，並對汽車之間的詳細交互進行建模。這些模型通過基於刺激響應框架的連續時間微分方程表示每輛汽車的位置和速度：urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0001，其中刺激與領先車輛的位置和速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>在過去的幾十年中，通過對主題車輛對其前部車輛的響應進行建模，已經開發了許多跟車模型的變體和擴展。最佳速度模型（OVM）[BHN * 95]和智能駕駛模型（IDM）[TH02]是兩個著名的例子。在OVM模型中，假定目標車輛保持其最佳速度。它的加速度取決於它的速度和前車的最佳速度之間的差。在IDM模型中，車輛的加速度或減速度是根據其當前速度以及相對於其前部車輛的相對速度和位置來計算的。車輛特定的參數使IDM模型能夠模擬各種車輛類型和駕駛方式。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了模擬單車道上的交通流外，還研究了多車道模擬[SN03，Dav04，THG05，HNT07]。一個示例是修改後的最佳速度模型[Dav04]，該模型用於模擬雙車道高速公路和帶匝道的單車道高速公路上的交通。另一個示例是兩車道交通模型[THG05]，該模型用於模擬交通橫向影響。</p><p style=text-align:justify><br></p><p style=text-align:justify>為了生成詳細的交通模擬，Shen和Jin [SJ12]提出了一種增強的IDM以及連續的換道技術。他們的技術可以產生順暢的加/減速策略和靈活的變道行為的交通流。該模型修改了原始IDM模型，使其更適合信號化城市道路網。具體而言，加速過程分為描述駕駛員意圖達到其期望速度的自由道路加速項和描述駕駛員保持與其附近車輛的安全距離的意圖的減速項。通過添加激活控制控制部分來修改減速項，該激活控制控制部分用於對停止的車輛產生更平穩的反應。此外，該模型將城市道路上的換車行為分為兩種情況：自由車道變更和命令式車道變更，併為這兩種情況提供了靈活的連續模型。</p><p style=text-align:justify><br></p><p style=text-align:justify>自由行車道經常在相對自由的道路條件下發生。此行為由Kesting等人的雙通道MOBIL模型建模。[KTH07]。當目標車輛由於某些強制性因素（例如到達車道盡頭或在十字路口轉彎）而需要換道動作時，將應用強制性換道，而目標車輛與其前導車輛之間的間隙可能不足以免費變道（圖5）。陸等人。[LCX * 14]擴展了全速差模型[JWZ01]，以處理鄉村交通模擬中的近車制動情況。後來，Lu等。還在交通仿真中引入了個性模型[LWX * 14]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/849ef27cc8a74b9ebfcfd13bc2dc2922><p class=pgc-img-caption></p></div><p style=text-align:center>圖5</p><p style=text-align:center><br></p><p style=text-align:justify>車輛必須更改其車道的情況[SJ12]：（a）到達當前車道的盡頭，（b）事故車輛出現在當前車道的前面，並且（c）引導標誌出現在交叉路口。</p><p style=text-align:justify><br></p><p style=text-align:justify>與模擬車道（標誌性或多個）上的交通相比，模擬交叉路口的交通更為困難。Doniec等。[DMPE08]通過將交叉路口交通視為多主體協調任務，提出了一種用於交通模擬的多主體行為模型。具體來說，首先，每輛車都會感知周圍的交通並做出決定；其次，引入了一種預測算法來生成仿真車輛的預測能力。Wang等。[WXZ * 18]引入了影子流量的概念，用於在流量模擬中以統一的方式對流量異常進行建模。Chao等。[CDJ15]設計了一個基於規則的流程，以在混合交通模擬中對車輛與人的交互進行建模。</p><p style=text-align:justify><br></p><p style=text-align:justify>總之，由於微觀交通模型旨在描述特定的車輛行為，因此它們可用於模擬連續車道和交叉路口的交通。瓶頸通常是計算成本，尤其是在需要大規模仿真時。</p><p style=text-align:justify><br></p><p style=text-align:justify>2.2.1混合方法</p><p style=text-align:justify><br></p><p style=text-align:justify>儘管連續方法（即宏觀模型）優於大型交通模擬和基於代理的技術（即微觀模型）優於單個車輛的建模，Sewall等人。[SWL11]結合了這兩種類型的方法，並提出了一種混合方法。他們的方法使用基於代理的模型來模擬感興趣區域中的流量，而其餘區域使用連續體模型來模擬流量（請參見圖6）。通過在兩種建模方法之間自動動態切換，他們的方法可以根據用戶的喜好在不同詳細程度下模擬流量。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/996af7e0366340948c502cda13ca5854><p class=pgc-img-caption></p></div><p style=text-align:center>圖6</p><p style=text-align:justify><br></p><p style=text-align:justify>混合交通仿真方法[SWL11]的說明。黃色邊界框內的流量使用基於代理的技術進行模擬，而其餘流量使用連續性技術進行模擬。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.3介觀方法</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>介觀模型是宏觀和微觀方法之間的中間方法。介觀模型的核心思想是使用概率分佈函數[HB01c]以聚合的方式描述交通流動態，同時代表單個駕駛員的行為。介觀模型可分為三類：聚類模型，車距分佈模型和氣體動力學模型[FSS18]。集群模型通過描述具有相同屬性的車輛組來表示交通流的動態[KMLK02，MKL05]。車距分佈模型集中在時間車距的統計屬性上。在介觀方法中，最著名的模型是氣體動力學模型，其中繪製了氣體動力學和交通動力學之間的類比。[PA60，THH99，HHST01，HB01a]。</p><p style=text-align:justify><br></p><p style=text-align:justify>在運輸工程中，氣體動力學模型通常不用於模擬，但在推導其他連續體模型時仍保持其作用[Hel01]。例如，Hoogendoorn和Bovy [HB00，HB01b]基於氣體動力學模型推導了一個多類多車道連續流交通模型。氣體動力學模型也是許多宏觀模型的基礎，例如自適應巡航控制策略[DNP15]。動力學理論還被用來推導出車輛交通的數學模型[FT13]，其中放寬了對車輛連續分佈的空間位置和速度的假設。在計算機圖形學中，由於大量未知參數以及複雜的微分或積分項，介觀模型很少用於交通仿真中，這限制了仿真和動畫效果。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>2.4道路網的產生</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通模擬是車輛與道路網絡之間相互作用的一種形式。基礎道路網絡的獲取和建模是重要但具有挑戰性的方面。現實世界道路網絡的數字表示已越來越多，但是這些數據通常不能直接用於模擬交通。基於宏觀和微觀建模方法的交通模擬是在形成車道的道路網絡上進行的。道路網絡包含許多功能，例如車道，交叉路口，合併區域和坡道。已經提出了許多方法用於道路網絡的過程建模和幾何表示。</p><p style=text-align:justify><br></p><p style=text-align:justify>教區等。[PM06]提出了一個名為CityEngine [cit18]的系統，它使用基於L系統的程序方法來生成道路網絡（圖7a）。以地圖圖像為輸入，該系統可以生成一組高速公路和街道，將土地分為很多部分，併為各個分配區的建築物構建適當的幾何形狀。後來，許多研究人員改進了基於CityEngine [CEW * 08，BN08，GPMG10]的道路網絡生成模型。例如，Sun等。[SYBG02]提出了基於模板的道路網絡生成模型。具有更大的靈活性，用戶可以使用Chen等人的自動道路網絡生成模型直接編輯道路網絡。[CEW * 08]。最近，西田等人。[NGDA16]展示了一種交互式道路設計系統，該系統使用了從示例道路網絡中提取的補丁和統計信息。哈特曼等。[HWWK17]提出了一種基於示例的方法，用於使用生成對抗網絡（GAN）來綜合道路網絡。他們使用二進制圖像表示道路網補丁。因為這些方法是為構建虛擬場景而設計的，所以它們通常無法為交通仿真提供必要的信息，例如車道到車道的連接和鄰接。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2270e83a07604a3fb4865fe8f261ff44><p class=pgc-img-caption></p></div><p style=text-align:center>圖7</p><p style=text-align:justify><br></p><p style=text-align:justify>使用（a）CityEngine [cit18]和（b）Wilkie等人的技術創建的道路網絡。[WSL12]。</p><p style=text-align:justify><br></p><p style=text-align:justify>提出了幾種用於交通仿真的道路建模技術。Yang和Koutsopoulos [YK96]使用節點，鏈接，路段和車道來描述道路網絡的語義。他們的模型已經整合到交通仿真軟件MITSIM [BAKY02]中。在此模型中，路段表示一組具有相同幾何折線的車道，而鏈接則表示路段的集合。矢量數據存儲在段的數據結構中。所存儲的信息包括分段弧的起點/終點和曲率。節點用於描述相交。在此，必須將節點作為輸入數據提供給模型，並且僅用於描述鏈接是否已連接。不考慮交叉點每個方向上的鏈接之間的衝突關係。在VISSIM [PTV11]中，採用交通仿真軟件，鏈接和連接器來描述道路網絡的拓撲結構，這有助於呈現具有更復雜幾何形狀的道路。但是，VISSIM中的道路網絡僅由連續的路段組成，因此很難處理交叉路口不同方向之間的衝突。同樣，其他道路網絡表示模型[Par03，BC05，SWL11，SJ12]也已可用。最近，Cura等人。[CPP18]使用真實的地理信息系統（GIS）數據生成了一個連貫的街道網絡模型，其中包含拓撲交通信息，路面和街道對象。該系統可以提供車道和車道互連作為交通模擬所需的基本幾何信息。但是，他們使用車道作為基本單位來定義和組織道路網絡，而忽略了道路網絡的矢量數據。值得一提的是，為了促進不同駕駛模擬器之間的數據交換，提出了一種名為OpenDRIVE [DG06]的開放數據格式，以標準化邏輯道路描述。</p><p style=text-align:justify><br></p><p style=text-align:justify>為了改善車輛運動的可視化，Wilkie等人。[WSL12]提出了一種新穎的道路網絡模型（圖7b），用於將低詳細信息GIS數據自動轉換為高詳細功能道路網絡進行仿真。可以使用此模型生成以車道為中心的拓撲結構和弧形道路表示。該模型基於車道定義了一個交叉點。在模擬中，交叉路口通過交通信號和預定的移動優先級進行管理。生成的道路網絡庫[WSLL15]可在http://gamma.cs.unc.edu/RoadLib/中找到。該模型激發了更多基於車道的仿真技術，例如Mao等。[MWDW15]在Frenet框架下基於道路軸對車道進行建模，以簡化複雜的交通模擬。</p><p style=text-align:justify><br></p><p style=text-align:justify>值得一提的是，取決於應用程序，不同詳細級別的交通模擬需要有關基礎道路網絡的不同信息。通常，宏觀交通模擬需要較少的路網細節-主要是需要幾何信息，以便可以對交通流的密度和速度的傳播進行建模。相比之下，微觀交通模擬會輸出單個車輛的詳細運動，因此通常需要有關路網的更多信息。這些信息包括車道（而不是道路）分離和連接，交通信號邏輯，交叉路口和坡道的移動優先級等。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3數據驅動的交通模擬</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>在本節中，我們探討了現實交通數據的獲取（第3.1節）以及用於交通重建和綜合的各種數據驅動方法（第3.2節）。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3.1交通數據採集</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>交通傳感器有幾種形式[LBH * 10，Led08]。僅舉幾個例子，一個固定的傳感器是感應環路檢測器，通常放置在高速公路和主要道路上，以記錄每輛經過的車輛的屬性。另一個固定傳感器是攝像機，它也用於監視流量。除了固定傳感器之外，移動傳感器也無處不在：手機和GPS設備用於記錄車輛的速度及其位置。</p><p style=text-align:justify><br></p><p style=text-align:justify>自從1960年代初推出[AKH * 12，KMGK06]以來，感應環路檢測器已成為使用最多的傳感器。它可以檢測車輛的通過或到達某個點，例如，接近交通信號燈或高速公路交通。絕緣的導電迴路安裝在人行道中。通過或停在檢測區域內的車輛會降低環路的電感。然後，電子單元將該事件感測為頻率降低，並向控制器發送脈衝以表示車輛通過或存在。該道路傳感器通常可以跟蹤通過時間，車道ID和車輛速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>攝像機作為道路傳感器，也已得到廣泛部署。一個示例是下一代仿真（NGSIM）程序[NGS18]，其中沿道路安裝了攝像頭，以每秒10幀的速度捕獲交通數據。結果數據集包含詳細的車輛軌跡。表1列出了四種流行的NGSIM數據集，包括道路長度，道路類型，記錄時間和車輛數量。圖8顯示了在美國101高速公路上收集數據的示例：八個同步攝像機安裝在與高速公路相鄰的36層建築物的頂部，記錄通過研究區域的車輛。為了處理捕獲的大量數據，開發了NGSIM-VIDEO [NGS18]以從圖像中自動提取車輛軌跡。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9cb671ebd7d64d6fb53a542486981349><p class=pgc-img-caption></p></div><p style=text-align:center>圖8</p><p style=text-align:center><br></p><p style=text-align:justify>在美國101號高速公路上安裝了8個攝像機。右圖顯示了安裝在俯瞰高速公路的建築物頂部的攝像機。</p><p style=text-align:justify><br></p><p style=text-align:justify>表1.四個選定的NGSIM數據集[NGS18]</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1a14532716044445a4f1ed4b1d2fed7b><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:justify>儘管傳統的通過道路傳感器收集交通數據的方法通常比較昂貴，但諸如GPS報告之類的移動數據已變得越來越可用，並已用於估算城市範圍內的交通狀況[AA06，LNWL17]。出租車和共享乘車服務（例如Uber和Lyft）系統地為其車隊配備了這些設備。汽車的位置，速度和方向等屬性將發送到中央處理中心。處理後，有用的信息（例如交通狀況和替代路線）將廣播給道路上的駕駛員[TEBH98]。當前公共可用的GPS數據集包括Mobile Century [HWH * 10]，T-Drive [tdr19]，GeoLife [geo19]和Uber Movement [ube17]。儘管很有前途，除了固有噪聲外，GPS數據通常還包含較低的採樣率，這意味著兩個連續點之間的時間差可能很大（例如，大於60 s），並且表現出時空稀疏性，這意味著數據可能稀疏。某些時間段和區域。因此，為了在重建交通動態中使用GPS數據，需要幾個處理步驟[LNWL17，LJCL18]。</p><p style=text-align:justify><br></p><p style=text-align:justify>除了單車數據之外，還付出了很多努力來收集互聯車輛的交通數據[HL08，RMR14]。例如，安全試點模型部署（SPMD）計劃於2012年在美國密歇根州的安阿伯市啟動。大約3000輛汽車配備了GPS天線和DSRC（專用短程通信）設備。每輛車向附近的車輛和路邊單位廣播基本安全消息，包括其位置和速度。這些聯網車輛數據為改善智能交通系統應用以及詳細的多車道交通模擬和動畫提供了機會。由於此類數據可以以較高的頻率（例如10 Hz [BS15]）進行採樣，這可能會導致存儲和通信系統的可觀成本，因此通常通過下采樣但信息保留的技術[MOH * 14，LLP19]。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>3.2交通重建與綜合</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>Van Den Berg等人首先介紹了創建與現實世界條件相對應的交通量的數字表示形式。[SVDBLM11]。在他們的工作中，從交通傳感器提供的時空數據重建並可視化連續的交通流。如圖9所示，傳感器（A，B和C點）以200–400 m的間隔放置在道路上。對於特定車輛i，傳感器A提供元組urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0002作為數據輸入，其中urn：x-wiley：01677055：media：cgf13803：cgf13803-math- 0003分別是通過時間，車道id和車輛i的速度（對於點B和C類似）。任務是計算在給定時間，給定速度和給定速度下開始和到達給定車道的道路上車輛i的軌跡（圖9中的藍色曲線）。該方法首先離散化可能的狀態時空，並將車輛的運動限制為預先計算的路線圖。然後，它為路線圖中的每輛車搜索一條最佳軌跡，該軌跡使換道次數和加速/減速量最小化，並使其與其他車輛的距離最大化，從而獲得平穩逼真的運動。對於多輛車輛，基於優先級的多機器人路徑規劃算法[VDBO07]用於計算車輛的軌跡。但是，基於優先級的多主體路由規劃算法非常耗時，隨著搜索空間中離散化分辨率的提高，這種方法很快變得難以處理。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b0cf77aedf1844f48a0080b7f126e0fd><p class=pgc-img-caption></p></div><p style=text-align:center>圖9</p><p style=text-align:justify><br></p><p style=text-align:justify>根據從公路傳感器獲取的時空數據重建交通的插圖。對於車輛i，傳感器提供向量urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0004作為數據輸入，其中urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0005是分別經過A點時（與B點和C點類似），通過時間，車道ID和車輛i的速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>出於通過道路傳感器測量值重建交通流量的相同目標，Wilkie等人。[WSL13]引入了一種實時技術，該技術通過將稀疏傳感器測量的宏觀狀態估計與基於代理的交通模擬系統集成在一起，來重構單個車輛的真實運動。如圖10所示，此方法具有交通狀態估計階段的功能，其中使用卡爾曼平滑器（EnKS）[Eve03]和連續交通模擬器的集合來創建整個道路網絡上速度和密度場的估計。然後，將狀態估計值用於驅動基於代理的交通模擬模型，以產生各個車輛的詳細運動。最後，輸出是與傳感器測量的原始交通信號一致的2D交通流。與Sewall等人的交通重建工作相比。[SVDBLM11]，此方法顯示了更高的靈活性和更低的計算成本。但是，除了各個車輛的匹配之外，該估計方法在本質上是宏觀的。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2019fbbf876b4c35a9b71e0f5a20c003><p class=pgc-img-caption></p></div><p style=text-align:center>圖10</p><p style=text-align:justify><br></p><p style=text-align:justify>管道的交通流量重建算法[WSL13]。該算法集成了一個有效的狀態估計方法，該方法使用Ensemble Kalman濾波器和連續交通仿真來有效地重構交通。使用基於代理的交通模擬可以直觀顯示結果，從而為單個車輛產生逼真的運動。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Li等人。[LWL17]提出了一種從GPS數據重建城市規模交通的方法。為了解決數據覆蓋範圍不足的問題，此方法以GIS地圖和GPS數據為輸入，並使用兩階段過程來重構城市規模的交通。在初始交通重建的第一階段，使用統計學習結合優化，地圖匹配和行程時間估算技術，從稀疏的GPS數據中重建並逐步完善各個路段的流量條件。在動態數據完成的第二階段，引入了基於元模型的仿真優化以有效地完善第一階段的重建結果，同時還引入了微觀模擬器，可以在數據覆蓋範圍不足的區域動態內插丟失的數據。為了確保重建的交通正確，該方法針對第一階段的城市邊界（交通）約束和重建的交通流量進一步優化了模擬。這是通過基於元模型的公式所計算出的交通流量的誤差近似值來實現的。</p><p style=text-align:justify><br></p><p style=text-align:justify>儘管上述流量重構技術專用於在相同情況下使用稀疏輸入數據預測完整的流量，但是還有其他數據驅動的流量合成方法，旨在從有限的流量軌跡樣本中生成新的流量。Chao等。[CDR * 18]使用一組有限的車輛軌跡作為輸入樣本，通過紋理合成和交通行為規則的融合來合成新的車輛軌跡。示例（輸入）車輛軌跡集包含有關車道數量和流量密度的各種交通流量段。如圖11所示，通過將交通流的時空信息作為2D紋理，可以將新交通流的生成公式化為紋理合成過程，這可以通過最小化新開發的交通紋理能量度量來有效解決。具體來說，交通紋理中的每個紋素在特定幀處編碼車輛的狀態，包括其速度，位置以及與其相鄰車輛的動態關係。交通紋理能量度量測量合成交通流與給定交通流樣本之間的相似性。通過在輸入交通流量樣本中找到最匹配的紋理元素，可以確定合成交通流量中的每輛車速度。合成的輸出不僅可以捕獲輸入交通流的時空動態，還可以確保交通特徵，例如車輛之間的安全距離和換道規則。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b937e65adc154927839e408ebd4fca93><p class=pgc-img-caption></p></div><p style=text-align:center>圖11</p><p style=text-align:justify><br></p><p style=text-align:justify>一組兩車道軌跡[CDR * 18]的紋理比喻。從概念上講，軌跡集的時空信息可以看作是2D紋理，並且每個交通紋理元素都可以在特定幀上編碼車輛的狀態，包括其運動信息以及與相鄰車輛的位置關係。</p><p style=text-align:justify><br></p><p style=text-align:justify>研究人員還沒有使用基於從道路傳感器獲取的數據來重建虛擬交通，也沒有從現有的軌跡數據中合成新的交通流，而是使用機器學習算法來學習車輛的詳細運動特性，包括縱向的加速/減速以及車道。變更過程。Chao等。[CSJ13]提出了一種基於視頻的方法，用於從交通動畫視頻中學習駕駛員的特定駕駛特性。這種方法將對每個車輛的獨特駕駛習慣的估計公式化為尋找微觀駕駛模型的最佳參數集的問題，這可以使用自適應遺傳算法解決。獲悉的特徵可用於在給定視頻中高精度地重現交通流，也可應用於任何基於代理的交通模擬系統。Bi等。[BMWD16]從車輛軌跡數據中學習變道特性。如圖12所示，此方法首先從預先收集的車輛軌跡數據集中提取與換道任務最相關的特徵。然後，將提取的特徵用於對變道決策過程進行建模，並估計變道執行過程。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a01a9b09fdb94762b7e1807a62679d4e><p class=pgc-img-caption></p></div><p style=text-align:center>圖12</p><p style=text-align:justify><br></p><p style=text-align:justify>數據驅動車道變換模型[BMWD16]的管道插圖。預處理步驟從預先收集的交通數據集中提取最相關的功能。然後，決策模塊可以推斷目標車輛是否應執行車道變換以及應更改為目標車道/間隙。最後，執行模塊計算所涉及車輛的詳細軌跡，以完成換道任務。</p><p style=text-align:justify><br></p><p style=text-align:justify>上述工作的重點是模擬高速公路或大型城市網絡上的車輛。最近，Bi等人。[BMWD19]提出了一個基於深度學習的交叉路口交通仿真框架。為了描述對車輛與環境相互作用的視覺感知，建立了一個稱為網格圖的網格座標系統，以對與行人混合的異構車輛之間的相互作用進行編碼。如圖13所示，在網格地圖上滑動具有五個通道的窗口可以為每個車輛生成一個環境矩陣。環境矩陣捕獲車輛和車輛周圍的行人的速度和位置。除了環境矩陣外，還基於收集到的交叉路口數據集採用車輛身份來描述當前的車輛狀態。然後，使用卷積神經網絡和遞歸神經網絡來學習交叉路口的車輛軌跡模式。除了模擬交叉路口交通外，它還可通過為車輛提供新的目的地和駕駛環境來更改現有的交叉路口交通動畫。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/af62414c83f444d78c6c5f523627422f><p class=pgc-img-caption></p></div><p style=text-align:center>圖13</p><p style=text-align:justify><br></p><p style=text-align:justify>交叉路口交通仿真中的環境矩陣圖[BMWD19]。對於車輛A，使用大小為31×31的窗口描述周圍區域。一個包含五個通道的環境矩陣（urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0006）。urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0007（或urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0008）可視化車輛B和C的速度。urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0009表示行人和騎自行車的人數。Φ和χ分別表示車輛A可行駛的區域和從無人機的角度看的可見區域。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>4驗證與評估</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>廣義上講，可以執行兩種類型的虛擬流量評估：視覺和統計[TK04]。在視覺驗證中，並排顯示實際流量和模擬流量的圖形表示，以確定它們是否可以區分[SVDBLM11，CSJ13]。在Chao等人的工作中。[CDR * 18]，研究人員通過三種不同方法對生成的流量進行成對比較，進行了用戶研究[KS40] ：( 1）真實性（即NGSIM流量數據），（2）基於紋理的建議流量合成方法[CDR * 18]和（3）IDM模型[SJ12]的最新發展之一。對於每個測試場景，分別使用上述三種不同方法生成三種不同的交通流動畫。如圖14（a）所示，要求參與者在兩個動畫剪輯對中選擇更真實的一個。此外，如果參與者無法確定哪個剪輯更具視覺吸引力，則可以選擇“不確定”選項。為了平衡視覺刺激的順序，根據威廉姆斯設計的拉丁方[Wil49]顯示配對。此用戶研究的實驗結果如圖14（b）所示。除了計算票數外，研究人員還執行了單樣本t檢驗和配對樣本t檢驗，並計算了相應的p值以量化投票結果的統計顯著性。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/53bac5e9c37e40d49ef65d26b6af46c1><p class=pgc-img-caption></p></div><p style=text-align:center>圖14<br></p><p style=text-align:justify>駕駛員視野研究（a）和實驗結果（b）的快照[CDR * 18]。左側的黑框和右側的白框表示參與者使用相應方法對結果進行投票的總次數。中間的灰色框表示“不確定的選擇”（即，在感知上等效）。符號*表示根據具有urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0010的兩尾獨立一樣本t檢驗得出的統計顯著性。</p><p style=text-align:justify><br></p><p style=text-align:justify>由於主觀用戶研究不可避免地耗時且容易出錯，因此通過定量和客觀措施進行的統計驗證不僅可以用於測量各種模擬交通流的真實性，而且可以以一致的方式客觀地比較不同交通模擬模型的性能。對於交通模擬和動畫技術，由於交通的隨機性，通常不執行直接軌跡比較。取而代之的是比較平均速度和流量隨時間變化的情況（例如，Sewall等人的圖15 [SWL11]）。在更詳細的級別上，還使用了特定的運動參數（包括速度，加速度和車輛間隙）來驗證交通模擬技術的有效性[CSJ13，BMWD16]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/425669a0ff4245ed8dbe27f341f020f8><p class=pgc-img-caption></p></div><p style=text-align:center>圖15</p><p style=text-align:center><br></p><p style=text-align:justify>基於代理的（微觀）模擬，連續體（宏觀）模擬，我們的混合模擬技術和101號高速公路上的實際NGSIM數據之間的比較。這些圖顯示了以15s為間隔記錄的密度，速度和通量，這些時間間隔集中在顯示的時間高速公路盡頭的傳感器（從起點開始urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0011）[SWL11]。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Chao等人。[CDX * 18]引入了一種通用的，基於字典的學習方法，以定量和客觀地測量交通軌跡數據的保真度。首先，從預先收集的地面交通數據離線構建表徵現實交通行為常見模式的交通模式字典。中間學習錯誤設置為基於字典的流量表示的基準。藉助構建的字典，可以通過將輸入（模擬）流量的基於字典的重構誤差與基準字典誤差進行比較，來評估輸入（模擬）流量的真實性。如圖17所示，此方法包括四個階段：（1）提取時空交通流特徵；（2）從現實交通數據中學習字典（即構建交通模式字典），（3）基於字典的任何輸入交通流量數據的重建，以及（4）基於重建誤差的定量度量的計算。該評估指標可以穩固地應用於任何模擬交通流量。圖16顯示了幾種不同交通數據的評估結果。保真度分數的範圍設置為[0..10]。如果模擬的流量更接近真實（訓練）流量數據集，則保真度得分將具有較小的值，反之亦然。</p><p style=text-align:center><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5596430e9af24ff396ed8bba279e14a0><p class=pgc-img-caption></p></div><p style=text-align:center>圖16</p><p style=text-align:center><br></p><p style=text-align:justify>IDM模型[SJ12]使用三個不同的參數集（（b）–（d））生成的三個虛擬流量之間的保真度度量比較。模擬器的初始流量狀態設置為與實際流量（a）相同的值。使用白色圓圈突出顯示了模擬流量與真實世界地面真實情況之間的差異。對於基於字典的保真度評估，度量值越小表示虛擬流量的保真度越高[CDX * 18]。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/31379edfb232496d96232fa98440c890><p class=pgc-img-caption></p></div><p style=text-align:center>圖17</p><p style=text-align:justify><br></p><p style=text-align:justify>虛擬流量的基於字典的保真度度量的管道[CDX * 18]。藍色框顯示了系統的待評估輸入，其中包含實際流量數據集和模擬數據。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5在自動駕駛中的應用</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>無人駕駛汽車具有釋放人們駕駛汽車的潛力，從而提高了他們在旅途中的生產率，提高了當前交通運輸系統的安全性和效率，並將交通運輸轉化為隨時隨地可供任何人使用的公用事業。在本節中，我們將描述自動駕駛的最新發展，包括自動駕駛訓練數據的收集（第5.1節），基於深度學習的運動計劃方法（第5.2節）和自動駕駛模擬（第5.3節）。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.1自動駕駛數據集</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>收集第3.1節中提到的交通數據集，以進行交通流重建和虛擬交通動畫。這些數據集對於建立自動駕駛系統可能沒有用。知道訓練數據對於自動駕駛至關重要，因此，我們以不同交通狀況下的第一眼視頻，LiDAR數據和GPS信息的形式調查了現有的駕駛數據集（如下所述）。這些數據集促進了自動駕駛系統的開發和各種駕駛行為的學習。</p><p style=text-align:justify><br></p><p style=text-align:justify>Jain等。[JKR * 15]從10位駕駛員那裡收集了1180英里自然高速公路和城市駕駛行為的多樣化數據集。記錄了汽車內外的視頻片段，GPS報告和速度測量結果。</p><p style=text-align:justify><br></p><p style=text-align:justify>comma.ai [SH16]數據集是一個公共數據集，其中包含約7.25小時的高速公路行駛數據。數據集已分為11個視頻剪輯。發行的視頻分辨率為160×320。還記錄了來自多個傳感器的速度，轉向角，GPS報告，陀螺儀和IMU。</p><p style=text-align:justify><br></p><p style=text-align:justify>伯克利DeepDrive視頻數據集（BDDV）[GKB * 16]由真實的駕駛視頻和GPS / IMU數據組成。記錄了各種駕駛情況，例如美國幾個主要城市的城市，高速公路，城鎮和農村地區。BDDV包含超過1萬小時的儀表板攝像機視頻流。</p><p style=text-align:justify><br></p><p style=text-align:justify>LiDAR視頻數據集（LiVi Set）[CWL * 18]包括來自Velodyne激光掃描儀的大規模高質量點雲和來自儀表板相機的圖像。Velodyne激光掃描儀在水平360度和垂直−30.67至+10.67度的角度收集點雲。點雲數據的總量約為1TB。密度約為每秒70萬個點。通過儀表板攝像機錄製了約15G的視頻剪輯。記錄軟件工具包遠程連接到車輛控制器，以便從車載傳感器獲取速度。該數據集涵蓋各種交通狀況，包括主幹道，主要道路，山區道路，學區和特殊的旅遊路線。</p><p style=text-align:justify><br></p><p style=text-align:justify>本田研究所的駕駛數據集（HDD）[RCMS18]包括舊金山灣區的104個小時的駕駛數據。包括各種交通場景。經過後期處理的數據集的總大小約為150GB和104個視頻小時。</p><p style=text-align:justify><br></p><p style=text-align:justify>Drive360 [HDVG18]包含來自八個環視攝像機的60小時駕駛視頻。通過車輛的CAN總線記錄了低水平的駕駛操作（例如轉向角和速度控制）。數據具有高時間分辨率，360度視野覆蓋，逐幀同步和各種路況。</p><p style=text-align:justify><br></p><p style=text-align:justify>其他一些沒有駕駛行為的數據集也可能有助於自動駕駛中的視覺語義理解和基於視覺的控制。使用Foru高分辨率攝像機，Velodyne激光掃描儀和定位系統記錄KITTI數據集[GLSU13，GLU12]。該數據集包含289個立體和光流圖像對，urn：x-wiley：01677055：media：cgf13803：cgf13803-math-0012長度的立體視覺測距序列，以及在雜亂環境中捕獲的200k以上3D對象註釋。該數據集用於立體，光流，視覺測距/ SLAM（同時定位和製圖）和3D對象檢測的任務。</p><p style=text-align:justify><br></p><p style=text-align:justify>Cityscape數據集[COR * 16]包含記錄在50個城市街道上的大量不同的立體聲視頻序列。這些圖像中總共有5000張具有高質量的像素級註釋。20,000張其他圖像帶有粗略註釋。數據集捕獲了不同季節的不同街道場景。</p><p style=text-align:justify><br></p><p style=text-align:justify>牛津RobotCar數據集[MPLN17]包含1000多公里的行駛數據，其中包括從六個攝像頭收集的近2000萬張圖像，以及來自多種天氣條件（包括大雨，臨近，直射陽光和大雪）的LIDAR和GPS數據。由於此數據集的記錄時間跨度為一年，因此某些道路和建築物可能會發生變化。Udacity [Uda]的另一個數據集包括通過CAN總線進行的低級駕駛操作。</p><p style=text-align:justify><br></p><p style=text-align:justify>城市環境的基於視覺的語義分割對於自動駕駛至關重要。已經提出了各種數據集[RSM * 16，TKWU17，WU18]，包括語義分割的各種合成駕駛或街道場景，有助於語義理解和基於視覺的控制。表2顯示了不同的自動駕駛數據集的詳細比較。</p><p style=text-align:justify><br></p><p style=text-align:justify>表2.各種自動駕駛數據集的比較。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3229002bdbc84f2aa9696b23c256df09><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7d607b3ba3e247b69da6017b54b4d8cd><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:justify>值得注意的是，自動駕駛數據集也可以有助於交通模擬和動畫。具體而言，首先，可以使用車輛軌跡來校準交通仿真模型；其次，大規模交通數據集可以豐富數據驅動的交通綜合方法。第三，虛擬流量的評估可以受益於各種現實流量數據集。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.2運動計劃和決策</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>運動計劃和決策對於自主代理在其環境中導航至關重要。在本節中，我們回顧了幾種基於學習的自動駕駛汽車和其他智能代理的運動計劃方法和決策算法。我們建議感興趣的讀者閱讀其他評論文章，包括[KQCD15，PČY* 16，SAMR18]，以供進一步閱讀。</p><p style=text-align:justify><br></p><p style=text-align:justify>Pomerleau [Pom89]引入了ALVINN（神經網絡中的自主陸地車輛），該技術開創了端到端自主導航方法。ALVINN將來自攝像機和激光測距儀的圖像用作導航車輛的輸入。Chen et al並沒有採用介導的感知來推動決策者的行為和使用迴歸方法來反映行為。[CSKX15]映射了基於圖像的直接感知駕駛中的幾種收費指標。基於帶有標籤的賽車視頻遊戲TORCS的屏幕截圖，可以訓練深度卷積神經網絡（CNN）。該方法已在車載智能手機視頻和KITTI數據集[GLSU13]中進行了測試。</p><p style=text-align:justify><br></p><p style=text-align:justify>隨著各種獲取的交通數據集和高級計算設備的發展，多年來，已經開發了更多的用於自動駕駛的端到端深度學習框架。Bojarski等。[BDTD * 16]使用CNN（稱為PilotNet [BYC * 17]）從前置攝像頭獲取原始像素作為輸入，以產生轉向行為。該框架功能強大，無需手動分解和語義抽象即可實現道路跟蹤。Gurghian等。[GKB * 16]提出了端到端的深層CNN，可直接估算車輛的車道位置。輸入圖像來自側面安裝的向下攝像頭，與帶前置攝像頭的圖像相比，該圖像提供了更好的視圖，可進行車道標記。</p><p style=text-align:justify><br></p><p style=text-align:justify>後來，徐等人。[XGYD17]使用基於大規模眾包車輛動作數據的FCN-LSTM框架來學習通用車輛動作。這種方法採用了一種新的範例來從未校準的源中學習模型。訓練後，它可以產生離散的動作（例如，筆直，停止，左轉和右轉）或連續的動作（例如，車道跟隨和轉向控制）來導航自動駕駛車輛。Chen等人的工作並非基於交通視頻數據學習自動駕駛模型。[CWL * 18]證明了諸如LiDAR點雲和視頻記錄之類的額外信息對於自動駕駛很有用。</p><p style=text-align:justify><br></p><p style=text-align:justify>倫茨等。[LDLK17]專注於高速公路入口處的車輛運動。他們使用部分可觀察的馬爾可夫決策過程訓練了一個深層神經網絡來預測車輛運動。Kuefler等。[KMWK17]採用“生成對抗模擬學習”來學習駕駛行為。這種方法克服了級聯錯誤的問題，並且可以產生逼真的駕駛行為。Hecker等。[HDVG18]通過將來自周圍360度全景攝像機的信息集成到路線規劃器中，學習了一種新穎的端到端駕駛模型。此方法中使用的網絡將傳感器輸出直接映射到低級駕駛操作，包括轉向角和速度。金等。[KRD * 18]通過引入紮實的內省式解釋模型，為自動駕駛引入了一種端到端，可解釋的駕駛方法。該模型由兩部分組成：第一部分是基於CNN的視覺注意機制，該機制將圖像映射到駕駛行為，第二部分是基於注意的視頻到文本模型，用於對模型動作進行文字說明。楊等。[YLWX18]利用在CARLA和TORCS中收集的虛擬交通數據來預測車輛行為，稱為DU-drive（圖18）。Maqueda等。[MLG * 18]提出了一種深度神經網絡方法來預測車輛的轉向角。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/df24bd5e6e164d4ab2c017996ae12cd9><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:center>圖18</p><p style=text-align:justify><br></p><p style=text-align:justify>DU-Drive [YLWX18]的體系結構。該模型與條件GAN密切相關。生成器網絡G將真實圖像轉換為虛擬圖像，通過預測器網絡P從中預測車輛命令。鑑別器網絡D將偽虛擬圖像與真實虛擬圖像區分開。對抗目標和預測目標都驅動生成器G產生可產生最佳預測結果的虛擬表示。</p><p style=text-align:justify><br></p><p style=text-align:justify>近年來，強化學習也已經適應自動駕駛。Abbeel等。[ADNT08]提出了一種有效的算法，可在全球導航和生成車輛軌跡的本地計劃之間進行折衷。銀等。[SBS13]為自動導航系統提出了適當的耦合成本函數，以平衡不同的偏好，包括應該在哪裡駕駛以及如何駕駛汽車。Lillicrap等。[LHP * 15]採用深層的Q學習算法，以實施行為準則，無模型的系統，該系統學習一種策略來引導車輛在模擬駕駛環境中保持在賽道上。Kuderer等。[KGB15]提出了一種基於特徵的逆強化學習方法，用於學習自動駕駛的各個駕駛方式。沃爾夫等。[WHW * 17]提出了一個深度Q網絡，用於在3D物理模擬中操縱車輛。在這種方法中，車輛的目標是跟隨車道完成任意路線上的圈速，基於動作的獎勵功能是由在實際單詞增強學習場景中的潛力所激發的。潘等人。[PYWL17]使用新穎的現實翻譯網絡在虛擬環境中訓練自動駕駛模型，然後在現實環境中使用它。在此虛擬現實增強學習框架中，來自虛擬環境的圖像首先被分割為場景解析表示，然後轉換為合成圖像。樑等。[LWYX18]提出了一種通用的可控模仿強化學習方法，以緩解大型連續動作空間的低探索效率。基於直接來自CARLA模擬器的視覺輸入，可以實現高成功率的自動駕駛。</p><p style=text-align:justify><br></p><p style=text-align:justify>為了在複雜的交通環境中高效安全地駕駛車輛，自動駕駛汽車需要預測周圍車輛的運動。車輛和行人之間的相互作用應準確表示[LVL14]。軌跡預測的任務可以分為幾類：基於物理的，基於機動的和交互感知的模型。此外，已經完成了大量基於深度學習的工作，用於人類軌跡預測[AGR * 16，VMO18，GJFF * 18，MA18，SKS * 19，XPG18，HST * 18]。在這裡，我們將注意力集中在使用深度神經網絡的車輛軌跡預測上。</p><p style=text-align:justify><br></p><p style=text-align:justify>李等人。[LCV * 17]提出了一個深度隨機IOC RNN編碼器-解碼器框架，以預測動態場景中交互主體的未來距離，該距離可以在駕駛場景中產生準確的車輛軌跡。金等。[KKK * 17]提出了一種基於LSTM的概率車輛軌跡預測方法，該方法使用佔用柵格圖來表徵駕駛環境。Deo和Trivedi [DT18]採用卷積社交池網絡來預測高速公路上的車輛軌跡。整個網絡包括LSTM編碼器，卷積社交池層和基於機動的解碼器。具體來說，它首先使用LSTM編碼器基於軌道歷史記錄來學習車輛動力學。然後，它使用卷積社交池層來捕獲所有車輛軌跡的相互依賴關係，最後，它訓練基於機動的LSTM解碼器來預測未來車輛軌跡的分佈。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>5.3自動駕駛仿真</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>儘管機器學習方法的發展極大地促進了自動駕駛中的運動計劃和決策制定，但現實世界的數據量仍然不足以覆蓋許多複雜的交通場景，因此限制了自動駕駛系統學習各種駕駛策略的能力，而且重要的是，在危險情況下的恢復行動。出於安全考慮，這使得無人駕駛汽車始終採用最保守，最無效率的決策。據報道，自動駕駛汽車已造成一些致命事故。這些觀察結果刺激了高保真駕駛模擬器的發展，它可以作為替代和有效的工具，為訓練自動駕駛汽車提供各種交通狀況。此外，模擬器可以在自動駕駛汽車部署到現實世界之前對其進行全面而徹底的安全測試[ARB * 15，APPI11，LF09]。</p><p style=text-align:justify><br></p><p style=text-align:justify>實際上，自自動駕駛研究的早期以來，仿真已用於訓練駕駛模型[Pom89]。後來，賽車模擬器已用於評估各種駕駛方法。例如，Chen等。[CSKX15]使用TORCS [WEG * 00]評估提出的用於自動駕駛的直接感知模型。最近，研究人員[RVRK16，JRBM * 17，RHK17]利用俠盜獵車手V（GTA V）來得出自動駕駛策略，從而獲得與可手動繪製的真實世界圖像得出的控制策略相當的性能。</p><p style=text-align:justify><br></p><p style=text-align:justify>CARLA [DRC * 17]作為一種開放源代碼模擬器，已經被開發來支持自動駕駛城市駕駛模型的開發，培訓和驗證。該仿真平臺支持靈活設置傳感器套件，並提供可用於訓練駕駛策略的信號。信號包括GPS座標，速度，加速度/減速度以及有關碰撞的詳細數據。可以指定各種環境因素，包括天氣和一天中的時間（圖19）。通過這些設置，CARLA已用於研究許多自動駕駛方法的性能，包括經典的模塊化方法，通過模仿學習的端到端訓練模型以及通過強化學習的端到端訓練模型。</p><p style=text-align:justify><br></p><div class=pgc-img><img alt=視覺交通仿真研究：自動駕駛中的模型，評估和應用 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/486c71afd9ae49b79446a137dd58e0c5><p class=pgc-img-caption></p></div><p style=text-align:justify><br></p><p style=text-align:center>圖19</p><p style=text-align:justify><br></p><p style=text-align:justify>CARLA Simulator [DRC * 17]中的街道交通，在三種天氣情況下以第三人稱視角顯示。從左上方順時針方向：晴天，白天下雨，下雨後不久的白天和晴朗的日落。</p><p style=text-align:justify><br></p><p style=text-align:justify>最佳等。[BNP * 18]介紹了AutonoVi‐Sim，這是一個用於自動駕駛數據生成和駕駛策略測試的高保真模擬平臺。AutonoVi‐Sim是高級可擴展模塊的集合。與CARLA相似，它還支持車輛傳感器系統的規範以及日間時間和天氣條件的變化，以及非車輛參與者（如騎自行車的人和行人）的活動。</p><p style=text-align:justify><br></p><p style=text-align:justify>此外，最近的幾個項目尋求構建仿真平臺來訓練端到端駕駛系統，並提供豐富的虛擬交通場景，以測試自動駕駛。一個示例項目是Apollo [apo18]，其中包含了來自實際流量和虛擬流量的大量駕駛數據。Apollo的目標是為自動駕駛系統的開發創建強大的虛擬閉環：從算法到評估，再到更新算法。阿波羅（Apollo）的侷限性在於，虛擬路況數據是使用特定且定義明確的障礙物和交通信號手動創建的，這些障礙物和交通信號不如實際交通情況現實且複雜。</p><p style=text-align:justify><br></p><p style=text-align:justify>最近，Li等人。[LPZ * 19]開發了一個模擬框架AADS，它可以通過模擬交通流量來增強真實圖像，以生成逼真的圖像。利用來自LiDAR和攝像頭的數據，該框架可以將基於實際車輛軌跡的模擬交通流組合到後臺。可以將合成圖像更改為不同的視點，並對其進行充分註釋，以準備用於自動駕駛系統的開發和測試。該框架旨在克服手動開發虛擬環境的負擔以及使用虛擬圖像訓練自動駕駛汽車的性能下降。</p><p style=text-align:justify><br></p><p style=text-align:justify>Li等人開發的另一個框架。ADAPS [LWL19]則採用了不同的觀點-能夠從事故中學習自動駕駛。該框架包含兩個仿真平臺。第一個模擬平臺以3D運行，用於測試學習的策略並模擬事故。第二個仿真平臺以2D模式運行，用於分析第一個仿真平臺中發生的事故，並通過提供替代的安全軌跡來解決事故。然後，根據安全軌跡生成大量帶註釋的數據，以訓練和更新控制策略。與以前的技術（例如DAGGER [RGB11]）相比，ADAPS還代表了一種更有效的在線學習機制，該技術可以大大減少得出魯棒控制策略所需的迭代次數。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>6討論</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>在本節中，我們討論了潛在的未來研究方向。</p><p style=text-align:justify><br></p><p style=text-align:justify>首先，交通仿真模型應該能夠對儘可能多的複雜交通行為進行建模，同時保持計算效率。但是，對於現有的微觀交通模型，車輛的每種行為（例如加速/減速和換道）都可以單獨建模和控制。此外，微觀交通模型更側重於車輛的前向運動，這在某種程度上受到侷限，從而忽略了換道行為和一般的車輛橫向運動。此外，由於根據汽車遵循規則，車輛的運動主要受其領先車輛的影響，因此所得的模擬很少會涉及視場中的其他車輛來計算加速度/減速度。為了模擬更現實的交通流，有必要開發一個統一的，可擴展的模擬框架，以應對豐富的車輛行為，包括加速/減速，停留在車道，改變車道以及與非車輛交通參與者（例如行人和騎自行車的人）互動。</p><p style=text-align:justify><br></p><p style=text-align:justify>其次，儘管進行了許多成功的演示，但當前的數據驅動交通動畫方法無法處理車輛與其他移動物體（例如行人）之間的平凡互動。主要原因之一是要同時獲取車輛，行人和環境因素的大規模時空數據是一項艱鉅的任務。對於交通重建，通常在計算中分別使用公路傳感器和GPS數據（兩種交通數據）。同時，交通重建的準確性受到可用數據的限制。因此，結合各種數據源，例如道路傳感器，視頻流和GPS軌跡，有可能提高重建精度。</p><p style=text-align:justify><br></p><p style=text-align:justify>第三，關於虛擬流量保真度的評估，基於字典的度量標準[CDX * 18]提供了可行的解決方案。但是，作為數據驅動方法的常見問題，交通數據的質量和組成對所生成的字典具有直接而實質的影響，因此會影響評估結果。此外，該框架還提取了每輛車的加速度，速度，相對速度和與前車的間隙距離，以描述車輛的瞬時狀態。為了更好地捕獲用於字典學習的交通模式，還應考慮並提取交通流量的更多功能，包括車輛運動學約束，道路限制和駕駛員特徵。對於宏觀交通仿真，有必要開發保真度度量標準，以總的方式衡量交通流量，包括流量密度和速度。</p><p style=text-align:justify><br></p><p style=text-align:justify>最後，對於自動駕駛，解決自動駕駛車輛與其他道路使用者之間的相互作用仍然是一個挑戰。現有的模擬器認為兩方之間的相互影響較小。舉個例子，在Apollo模擬平臺[apo18]和[BNP * 18]的工作中，兩種模擬都實現了兩種非車輛交通參與者：行人和騎自行車的人。但是，這些非車輛代理的行為是預先定義的，因此它們無法實時響應車輛。此外，儘管在CARLA [DRC * 17]中引入了動態行人，但車輛和行人之間的交互仍以簡單，預先指定的方式處理：行人將在行進前檢查附近是否有車輛，然後繼續行進無需進一步檢查。</p><p style=text-align:justify><br></p><p style=text-align:justify><strong>7結論</strong></p><p style=text-align:justify><br></p><p style=text-align:justify>自將近60年以來，用於建模和模擬交通流的方法已經取得了長足的進步。在計算機圖形學中，近十年來提出了各種基於交通流模型的交通模擬技術。此外，隨著傳感技術的進步，已提出了許多數據驅動的方法來開發交通動畫和模擬。來自各種傳感器的交通數據量的增加也可以有助於自動駕駛算法的開發和測試。</p><p style=text-align:justify><br></p><p style=text-align:justify>在本報告中，我們調查了主要的交通模擬和動畫技術，重點是但不限於從計算機圖形學角度進行的討論。這些方法的子集專注於基於宏觀，微觀和介觀流動模型模擬交通流。其他方法利用收集的交通數據來重建交通，合成新的交通流或瞭解各種交通模式的特徵。還討論了虛擬流量的各種評估和驗證技術。</p><p style=text-align:justify><br></p><p style=text-align:justify>作為重要的應用，還介紹了使用交通模擬的自動駕駛技術的最新發展。特別是，我們專注於為自動駕駛開發創建的數據驅動方法，運動計劃技術，決策算法和模擬器。我們還探討了一些研究挑戰和未來方向。</p><p style=text-align:justify><br></p><p style=text-align:justify>總之，交通模擬和動畫將繼續發展和進步。許多令人興奮的應用程序和新穎的方法仍有待探索和開發。在自動駕駛研究方面，我們相信本次調查中討論的各種模型和應用將在未來幾年內激發有趣的研究主題。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>視覺</a></li><li><a>自動</a></li><li><a>駕駛中</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/da481398.html alt=視覺自動檢測設備的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/fa5be0f8896949beb733a22a602cac77 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/da481398.html title=視覺自動檢測設備的應用>視覺自動檢測設備的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/90d2a289.html alt=自動駕駛中車輛的如何使用點雲定位？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/56a108f6423b4886bade22f016a2053c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/90d2a289.html title=自動駕駛中車輛的如何使用點雲定位？>自動駕駛中車輛的如何使用點雲定位？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html alt=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1530929302432561dc6cda6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html title=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價>機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/403ada1f.html alt=航攝中如何掌控視覺差異 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6554/5338856107 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/403ada1f.html title=航攝中如何掌控視覺差異>航攝中如何掌控視覺差異</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html alt=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/519b968bf69146fda9bf55f89779d373 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html title=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質>基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html alt=方大九鋼檢測部推出生石灰自動取樣器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html title=方大九鋼檢測部推出生石灰自動取樣器>方大九鋼檢測部推出生石灰自動取樣器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html alt=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html title=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好>方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html alt=excel小技巧：自動求和，當新增數據時自動求和 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523970520159b755ba89ba style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html title=excel小技巧：自動求和，當新增數據時自動求和>excel小技巧：自動求和，當新增數據時自動求和</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1a697cad.html alt=視覺享受的進化!顯示技術的分類和演進 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1a697cad.html title=視覺享受的進化!顯示技術的分類和演進>視覺享受的進化!顯示技術的分類和演進</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html alt=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4e8a4e07bff64e6db5dcef502221fa45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html title=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀>37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html alt=「乾貨」自動噴水滅火系統三大報警閥組原理探索 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/46846030db1d42069626e2365af33521 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html title=「乾貨」自動噴水滅火系統三大報警閥組原理探索>「乾貨」自動噴水滅火系統三大報警閥組原理探索</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html alt=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html title=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求>「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html alt=新版自動噴水滅火系統規範：第六章-報警閥組 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15251639042140ad0c55a7b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html title=新版自動噴水滅火系統規範：第六章-報警閥組>新版自動噴水滅火系統規範：第六章-報警閥組</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html alt=消防自動噴淋糸統的溼式式報警閥組的工作原理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f728f8c921f4740983ffec87a508565 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html title=消防自動噴淋糸統的溼式式報警閥組的工作原理>消防自動噴淋糸統的溼式式報警閥組的工作原理</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>