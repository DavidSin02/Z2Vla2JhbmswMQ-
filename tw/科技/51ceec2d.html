<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>光流估計——從傳統方法到深度學習 | 极客快訊</title><meta property="og:title" content="光流估計——從傳統方法到深度學習 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/60d0e9a141b341f88113efb1751633e9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/51ceec2d.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/51ceec2d.html><meta property="article:published_time" content="2020-11-14T21:04:25+08:00"><meta property="article:modified_time" content="2020-11-14T21:04:25+08:00"><meta name=Keywords content><meta name=description content="光流估計——從傳統方法到深度學習"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/51ceec2d.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>光流估計——從傳統方法到深度學習</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1>1.摘要</h1><p>近年來，深度學習技術，作為一把利劍，廣泛地應用於計算機視覺等人工智能領域。如今時常見諸報端的“人工智能時代”，從技術角度看，是“深度學習時代”。光流估計是計算機視覺研究中的一個重要方向，然而，因為其不容易在應用中“顯式”地呈現，而未被大眾熟知。隨著計算機視覺學界從圖像理解轉向視頻理解，互聯網用戶從發佈圖片朋友圈轉向發佈短視頻，人們對視頻的研究和應用的關注不斷增強。光流估計作為視頻理解的隱形戰士，等著我們去尋找其蹤跡。 本文首先介紹了什麼是視頻光流估計；再介紹光流估計的算法原理，包括最為經典的Lucas-Kanade算法和深度學習時代光流估計算法代表FlowNet/FlowNet2；最後，介紹了視頻光流估計的若干應用。希望對光流估計的算法和應用有個較為全面的介紹。</p><h1>2.介紹</h1><p>光流，顧名思義，光的流動。比如人眼感受到的夜空中劃過的流星。在計算機視覺中，定義圖像中對象的移動，這個移動可以是相機移動或者物體移動引起的。具體是指，視頻圖像的一幀中的代表同一對象(物體)像素點移動到下一幀的移動量，使用二維向量表示。如圖2-1。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/60d0e9a141b341f88113efb1751633e9></div><p>圖2-1 光流示意圖</p><p>根據是否選取圖像稀疏點進行光流估計，可以將光流估計分為稀疏光流和稠密光流，如圖2，左圖選取了一些特徵明顯（梯度較大）的點進行光流估計和跟蹤，右圖為連續幀稠密光流示意圖。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/059b4a259ace4c1ba70525e5f7f35f4c></div><p>圖2-2 左圖 稀疏點光流，右圖 稠密光流</p><p>稠密光流描述圖像每個像素向下一幀運動的光流，為了方便表示，使用不同的顏色和亮度表示光流的大小和方向，如圖2-2右圖的不同顏色。圖2-3展示了一種光流和顏色的映射關係，使用顏色表示光流的方向，亮度表示光流的大小。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/188dc561625e4bd1b5a8108c4be29d94></div><p>圖2-3 稠密光流表示顏色空間</p><h1>3.算法</h1><p>最為常用的視覺算法庫OpenCV中，提供光流估計算法接口，包括稀疏光流估計算法cv2.calcOpticalFlowPyrLK()，和稠密光流估計cv2.calcOpticalFlowFarneback()。其中稀疏光流估計算法為Lucas-Kanade算法，該算法為1981年由Lucas和Kanade兩位科學家提出的，最為經典也較容易理解的算法，下文將以此為例介紹傳統光流算法。 對於最新的深度學習光流估計算法，FlowNet的作者於2015年首先使用CNN解決光流估計問題，取得了較好的結果，並且在CVPR2017上發表改進版本FlowNet2.0,成為當時State-of-the-art的方法。截止到現在，FlowNet和FlowNet2.0依然和深度學習光流估計算法中引用率最高的論文，分別引用790次和552次。因此，深度學習光流估計算法將以FlowNet/FlowNet2.0為例介紹。</p><h1>3.1 傳統算法 Lucas-Kanade</h1><p>為了將光流估計進行建模，Lucas-Kanade做了兩個重要的假設，分別是亮度不變假設和鄰域光流相似假設。</p><h1>3.1.1 亮度不變假設</h1><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5c340cafc3204017ad7774d00ef5d112></div><p>圖3-1-1 - Lucas-Kanade 亮度不變假設</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/dfic-imagehandler/0a562c4f-7ff6-4d65-90c5-cf9f032fd728></div><h1>3.1.2 鄰域光流相似假設</h1><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8fd029a2cf604c3caa3538142b23ab6e></div><p>圖3-1-2 - 領域光流相似假設</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/239df8bd8817499cb66fda43e67e79cb></div><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2e49591495ec4600965102af68c54e68></div><p>圖3-1-3 光流求解的孔徑問題</p><p>除了基於亮度不變假設和鄰域光流相似假設，為了解決圖像偏移較大的情況，Lucas-Kanade算法還藉助了圖像金字塔（Pyramid）的方式，在高層低分辨率圖像上，大的偏移將變為小的偏移。最終，Lucas-Kanade方法給出了一種求解稀疏（明顯特徵的角點）光流的方法。</p><h1>3.2 深度學習算法 FlowNet/FlowNet2.0</h1><p>ICCV2015提出的FlowNet是最早使用深度學習CNN解決光流估計問題的方法，並且在CVPR2017，同一團隊提出了改進版本FlowNet2.0。FlowNet2.0 是2015年以來光流估計鄰域引用最高的論文。</p><h1>3.2.1 FlowNet</h1><p>作者嘗試使用深度學習End-to-End的網絡模型解決光流估計問題，如圖3-2-1，該模型的輸入為待估計光流的兩張圖像，輸出即為圖像每個像素點的光流。我們從Loss的設計，訓練數據集和網絡設計來分析FlowNet。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/f50888b400ca420ea1f1b8a1f504badb></div><p>圖3-2-1 深度學習End-to-End 光流估計模型</p><p>對於Loss的設計，如果給定每個像素groundtruth的光流，那麼對於每個像素，loss可以定義為預測的光流（2維向量）和groundtruth之間的歐式距離，稱這種誤差為EPE(End-Point-Error)，如圖</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/748ff5bf3e3b43528a16f515ebbc047e></div><p>圖3-2-2 End Point Error</p><p>對於訓練數據集，由於稠密光流的groundtruth為圖像每個像素的光流值，人工標註光流值幾乎不可能。因此，作者設計了一種生成的方式，得到包括大量樣本的訓練數據集FlyingChairs。其生成方式為對圖像做仿射變換生成對應的圖像。為了模擬圖像中存在多種運動，比如相機在移動，同時圖像中的人或物體也在移動。作者將虛擬的椅子疊加到背景圖像中，並且背景圖和椅子使用不同的仿射變換得到對應的另一張圖，如圖3-2-3。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/821aa62d968049e5adadb7c99666b433></div><p>圖3-2-3 FlyingChairs數據集生成</p><p>對於深度網絡結構，該類網絡通常包括降維的encoder模塊和升維的decoder模塊。作者設計了兩種網絡,FlowNetSimple和FlowNetCorr(Correlation)。這兩種網絡的Encoder模塊不同，Decoder模塊相同。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a3ad39e84f644c189e2ef2283972278c></div><p>圖3-2-4 FlowNetSimple</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5ed6ab07346c445580d45ac9faf1b0f1></div><p>圖3-2-5 FlowNetCoor</p><p>FlowNetSimple簡單地將兩張圖排列到一起，即將兩張 H*W*3 圖，合併成 H*W*6的Tensor，作為CNN encoder的輸入（如圖3-2-4），這是最為簡單的將兩張圖的信息整合到一起的方式，也因此命名為FlowNetSimple。FlowNetCoor則先對兩張圖像分別進行卷積，獲得較為高層的feature後，再進行相關運算（引入人為定義的規則），將信息合併，如圖3-2-5。其中，相關運算借鑑了傳統視覺算法中，找圖像匹配的思想。如圖3-2-6，為了尋找上圖紅框椅子角在下圖中對應得位置，在下圖對應像素位置周圍依次滑動，做相關運算（即對應位置像素相乘求和）。得到的值越大，代表越相關，即圖像越接近。FlowNetCoor網絡中的相關運算類似，不同點是其不在圖像本身做相關，在卷積得到的FeatureMap上做相關運算，圖3-2-6上圖FeatureMap與下圖FeatureMap對應像素附近區域做相關，上圖(u,v)座標圖塊與下圖對應區域的鄰域內（綠框）滑動做相關運算，得到的值在輸出FeatureMap通道方向上依次排開，圖3-2-4中相關運算的輸出通道數為441，即下圖做相關運算的鄰域範圍為 21*21 。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15d8fa51b736404fa36919e7befc8efc></div><p>圖3-2-6 相關運算示意圖</p><p>兩種網絡的Decoder是一致的(見圖3-2-7)，其通過反捲積進行升維，各層反捲積運算的輸入包括三個部分，第一部分是上一層的反捲積輸出deconv*(高層語義信息)，第二部分來之Encoder相關層的FeatureMap conv*_1(低層局部信息),第三部分由前一層卷積的輸出coarse的光流flow*上採樣得到。從而融合了高層和低層的信息，也引入了coarse-to-fine(由粗到細)的機制。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dea2d6dc328e4ccc84c089df13b9c7d5></div><p>圖3-2-7 Decoder網絡結構</p><p>基於上述網絡和訓練集，作者基於深度學習設計的FlowNet在實時估計光流算法中取得了state-of-the-art的結果，但是依然比非實時的傳統方法效果要差。同時，作者對比了FlowNetS和FlowNetCoor，FlowNetCoor的效果更好，證實了人工加入的相關運算是有效的，也符合預期。</p><h1>3.2.2 FlowNet2.0</h1><p>FlowNet2.0是FlowNet團隊發表在CVPR2017的改進方法，該方法達到了state-of-the-art效果(包括非實時的傳統方法)，並且計算速度很快，達到實時的要求。FlowNet2.0的改進主要體現在兩個方面，一方面是通過堆疊多個FlowNet網絡，實現Coarse-to-Fine的效果；另一方面是解決FlowNet小偏移（Small Displacement)估計不準確的問題。 FlowNet2.0整體網絡結構如圖3-2-8，圖上方依次堆疊了FlowNetCoor+FlowNetS+FlowNetS。值得注意的是，後續FlowNet的輸入不僅僅是兩張圖片（圖1和圖2），還包括前一個網絡輸入的光流估計Flow，和一張Warped圖，再加一張亮度誤差(Brightness Error)。其中Warped圖為將估計的光流作用在圖2上，即為使用估計的每個像素偏移，偏移圖2的每一個像素，使其與圖1對齊。雖然作用了光流偏移，由於光流估計的不夠準確，Warped圖和圖1依然存在一定的偏差，圖1的亮度減去Warped圖的亮度，即可得到亮度誤差(BrightnessError)圖。最後，將所有的五項輸入堆疊成輸入的Tensor，輸入到後續的網絡中。 小偏移即光流偏移較小的情形，作者設計了適合小偏移的FlowNet-SD(Small-Displacement)，其修改FlowNet中卷積核和stride的大小，使其更適合小偏移。具體的變化為，將FlowNet中7x7和5x5的卷積和改為3x3的卷積核(更小的卷積和意味著更加精細的處理，因此更加適合小偏移估計的問題)，並且將stride=2改為stride=1。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/216eede6ad7f49a59d8dcc183755d025></div><p>圖3-2-8 FlowNet2.0 整體框圖</p><p>作者給出的FlowNet2.0實驗結果如圖3-2-9，其中給出了5種版本的FlowNet2,FlowNet2、FN2-CSS-ft-sd/FN2-css-ft-sd、FN2-ss、FN2-s， c/C代表Coor網絡，s/S代表Simple網絡，小寫(s,c)代表網絡參數較少（縮小了卷積和數量）的版本。FlowNet2是指FlowNet2的完整網絡(如圖3-2-8)，ft代表在真實數據集上進行了fine-tune，sd代表包含small-displacement模塊。因此，實驗結果表明FlowNet2達到了所有方法State-of-the-are結果（包括非實時的傳統方法），計算效率要比最好的傳統方法快兩個數量級，達到了實時的要求。並且根據不同的應用需求，不同速度和精度的要求，有不同的版本供選擇。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c019a86dfa1c477a85ff8cb2daf1c041></div><p>圖3-2-9 FlowNet2.0 對比結果</p><p><br></p><h1>4. 應用</h1><p>光流，從物理意義的角度看，描述了視頻中物體、對象在時間維度上的關聯性，從而建立了視頻中連續圖像之間的關聯關係。因此，最為直接而自然的應用就是視頻中物體的跟蹤，在物體跟蹤領域知名的TLD算法便藉助了光流估計，圖2中展示了在車輛上的特徵點光流跟蹤的效果。在視覺里程計和SLAM同步定位與建圖領域，光流可以作為圖像特徵點匹配的一種方式，比如知名的視覺慣性里程計開源算法VINS-Mono。英偉達也提供了基於其GPU的光流SDK,其中展示了利用光流進行視頻動作識別(video action recognition)和視頻插幀的應用，如圖4-1，4-2。</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/eed3803ab6b143b8840444e0deda7280></div><p>圖4-1 光流應用於動作識別</p><p><br></p><div class=pgc-img><img alt=光流估計——從傳統方法到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9e5beb605bb14183a3eafc244179341a></div><p>圖4-2 光流應用於視頻插幀</p><p><br></p><h1>5. 總結</h1><p>對於稀疏光流，本文提到的Lucas-Kanade是一種經典且有效的算法，對於稠密光流估計，傳統方法需要在精度和速度上做出取捨，而最新基於深度學習的FlowNet2算法可以實時取得state-of-the-art的精度。</p><h1>參考文獻</h1><p>[1] Ilg, Eddy, et al. "Flownet 2.0: Evolution of optical flow estimation with deep networks."Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.</p><p>[2] Dosovitskiy, Alexey, et al. "Flownet: Learning optical flow with convolutional networks."Proceedings of the IEEE international conference on computer vision. 2015.</p><p>[3] NVIDIA Optical Flow SDK https://developer.nvidia.com/opticalflow-sdk , Accessed at 2019/7/20</p><p>源自：https://zhuanlan.zhihu.com/p/74460341</p><p>聲明：部分內容來源於網絡，僅供讀者學習、交流之目的。文章版權歸原作者所有。如有不妥，請聯繫刪除。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>光流</a></li><li><a>估計</a></li><li><a>傳統</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/069f1a6d.html alt=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S44t6ohazkQ74 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/069f1a6d.html title=哈工大提出基於光流估計與光照不一致監督的人臉正向化模型>哈工大提出基於光流估計與光照不一致監督的人臉正向化模型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/17a36096.html alt=傳統廣播與數字廣播的區別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e39a9b4cac0347d8829c87ee93f86af4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/17a36096.html title=傳統廣播與數字廣播的區別>傳統廣播與數字廣播的區別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/903f1434.html alt=能力提升培訓第一場——傳統計算機視覺方法分析圖像 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/941f6c2fe7be4498b2d596bcac598104 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/903f1434.html title=能力提升培訓第一場——傳統計算機視覺方法分析圖像>能力提升培訓第一場——傳統計算機視覺方法分析圖像</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fd07a494.html alt=傳統彈簧vs彈性振動支撐，這些區別優勢你知道嗎？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/987773187efc4e049e033523176abc7f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fd07a494.html title=傳統彈簧vs彈性振動支撐，這些區別優勢你知道嗎？>傳統彈簧vs彈性振動支撐，這些區別優勢你知道嗎？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ba749b55.html alt=拳擊航母百姓擂臺賽即將開打！傳統武術氣功大師展現武者風範 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f5230c44062743cdba83cf1f195d0a0d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ba749b55.html title=拳擊航母百姓擂臺賽即將開打！傳統武術氣功大師展現武者風範>拳擊航母百姓擂臺賽即將開打！傳統武術氣功大師展現武者風範</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e732b9d0.html alt=牛力耕耙——正在消逝的傳統稻作文化之一 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/15301691435872af892e3ff style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e732b9d0.html title=牛力耕耙——正在消逝的傳統稻作文化之一>牛力耕耙——正在消逝的傳統稻作文化之一</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/72cd034a.html alt=中低壓電纜檢測儀與傳統的電纜故障測試儀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3c4b0760435c4113b4eb9ac06bf4f1f7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72cd034a.html title=中低壓電纜檢測儀與傳統的電纜故障測試儀>中低壓電纜檢測儀與傳統的電纜故障測試儀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/152271f6.html alt=傳統寓意裝飾紋——獸紋 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fea2183e029d48028e875009eafaf7eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/152271f6.html title=傳統寓意裝飾紋——獸紋>傳統寓意裝飾紋——獸紋</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a53befae.html alt=中央廚房|和麵機打破傳統，引領和麵醒面新時代！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/103122c58b5c4f21842f817332b78b56 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a53befae.html title=中央廚房|和麵機打破傳統，引領和麵醒面新時代！>中央廚房|和麵機打破傳統，引領和麵醒面新時代！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d71e8d76.html alt=科普｜當現代激光遇上傳統鍼灸，激光穴位治療儀瞭解一下 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/b4a231a0-5da5-4b2c-b4cb-9865d96d806f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d71e8d76.html title=科普｜當現代激光遇上傳統鍼灸，激光穴位治療儀瞭解一下>科普｜當現代激光遇上傳統鍼灸，激光穴位治療儀瞭解一下</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/94457a11.html alt=碳纖維複合芯導線較傳統鋼芯鋁導線具有何種優勢 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0ef202b54034444094a93f8e719e0e04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/94457a11.html title=碳纖維複合芯導線較傳統鋼芯鋁導線具有何種優勢>碳纖維複合芯導線較傳統鋼芯鋁導線具有何種優勢</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/16a1189b.html alt=飲料市場傳統勁旅節後率先跑出，看2020脈動如何超越自己 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/16a1189b.html title=飲料市場傳統勁旅節後率先跑出，看2020脈動如何超越自己>飲料市場傳統勁旅節後率先跑出，看2020脈動如何超越自己</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4bbcd5d1.html alt="傳統影像的完全顛覆，XD Fusion，華為影像系統的支點" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1a58b149c7564a83b5673ac22dc557af style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4bbcd5d1.html title="傳統影像的完全顛覆，XD Fusion，華為影像系統的支點">傳統影像的完全顛覆，XD Fusion，華為影像系統的支點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/76ab291e.html alt=揭祕內蒙古傳統風乾肉製作過程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/REiFdcWGoKRgRb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/76ab291e.html title=揭祕內蒙古傳統風乾肉製作過程>揭祕內蒙古傳統風乾肉製作過程</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/63ee75d2.html alt=統計學中的參數估計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/4aa6f1ede12d4cb28174fd2e927d80e8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/63ee75d2.html title=統計學中的參數估計>統計學中的參數估計</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>