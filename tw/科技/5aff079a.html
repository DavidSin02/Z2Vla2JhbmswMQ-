<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析 | 极客快訊</title><meta property="og:title" content="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/1528975110519ee64a67c03"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5aff079a.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5aff079a.html><meta property="article:published_time" content="2020-11-14T21:08:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:19+08:00"><meta name=Keywords content><meta name=description content="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/5aff079a.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1528975110519ee64a67c03><p class=pgc-img-caption></p></div><p>作者：陳波，孫樂，韓先培</p><hr><p><strong>ACL 2018</strong></p><p><strong>基於端到端語義圖生成的語義解析</strong></p><p><strong>Sequence-to-Action: End-to-End Semantic Graph Generation for Semantic Parsing</strong></p><p><strong>中國科學院軟件研究所</strong></p><p><strong>Chinese Academy of Sciences</strong></p><h1><br></h1><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511049938b44a2b0e><p class=pgc-img-caption></p></div><p><strong>1 引言</strong></p><p>傳統的語義解析器大部分都基於組合文法， 如組合範疇文法（CCG）、 基於依存的組合語義文法（DCS）。這些語義解析器都利用文法來組合結構， 利用詞典來進行語義落地，再利用特徵對候選解析結果打分排序。然而，在面向開放域的情況下， 一般很難設計文法， 更難學習到高質量、高覆蓋度的詞典，此外，要想設計出有效的特徵通常也很困難，並且模型的學習也不是端到端的。 為了解決上述問題，近年來語義解析領域內有兩個備受關注的技術發展路線：基於語義圖的方法，和基於序列-序列的方法。</p><p>基於語義圖的方法 利用語義圖來表示自然語言句子的語義（例如知識庫中的一個子圖），進而把語義解析轉化為語義圖匹配/生成的問題。 相比於邏輯表達式，語義圖與知識庫更加緊密相連，並且語義圖的結構與句子的句法結構具有很多的共同點。 同時，來自知識庫的結構約束和語義約束能夠很好的在解析的過程中加以利用。 基於語義圖的方法的最大挑戰在於如何去構建一個句子的語義圖。現階段，語義圖要麼是利用特定的模板，再加上模板匹配而來, 要麼從依存樹或者句法樹轉化而來，或者通過啟發式的算法。 這些方法都是基於人工設計的，或者啟發式的構建過程，這使得這些方法很難處理開放域條件下的複雜句子。</p><p>近年來，循環神經網絡（RNN）模型在序列-序列的問題上已經取得了很大的成功，如機器翻譯、AMR分析，這得益於這類模型擁有強大的表示能力和預測能力。 也有不少工作把序列-序列的模型應用到語義解析任務上來， 這些工作利用循環神經網絡模型把句子被解析成序列化的邏輯表達式。這樣一來不再需要特定的文法，也不需要學習高質量的詞典，更不需要定義有效的特徵，並且模型的學習是端到端的， 此外，注意力機制可以用來學習句子中的詞語與邏輯表達式中的謂詞之間的軟（soft）對齊。</p><p>在本文，我們提出了一種新的語義解析框架——Sequence-to-Action，該框架能夠同時利用到語義圖的強語義表示能力，以及循環神經網絡模型的強表示學習能力和序列預測能力。 具體地，我們把語義解析問題建模成一個端到端的語義圖生成的過程。如圖1中的例子所示，對於給定的句子“Which states border Texas”， 我們的模型會把它解析成一個動作序列：[add_variable:A, add_type:state, ...]。為了達到上述目標，首先我們需要設計一個動作集合， 包括添加節點動作，比如：添加-變量節點（add_variable）、添加實體節點（add_entity）和添加類別節點（add_type）， 和添加邊動作，如：添加-邊（add_edge），還有添加操作符動作，如：添加-最大操作符（add_argmax）、 添加-最小操作符（add_argmin）、添加-計數操作符（add_count）等，該動作集合能夠編碼語義圖的構建。 然後，我們設計一個循環神經網絡模型來生成動作序列，該動作序列用於構建句子所對應的語義圖。最後，我們還探究了在解碼的過程中加入句法約束條件和語義約束條件， 用來及時過濾解碼過程中的錯誤動作，進一步提高解析的準確度。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975110492e6396e07d7><p class=pgc-img-caption></p></div><p>圖1：我們方法的概覽，其右側是一個示例</p><p>之前基於語義圖的方法都使用人工設定的、或者啟發式的生成算法來構建語義圖，相比如他們的方法，我們的sequence-to-action模型能夠利用循環神經網絡模型來生成動作序列， 而動作序列可以用來構建語義圖，模型的訓練是端到端的（end-to-end）。這樣一個可以進行端到端學習的生成形式使得我們的方法更有有效，同時能夠適應到更多的不同的情形。</p><p>而相比如之前的基於序列-序列（Seq2Seq）的語義解析方法，我們的方法使用循環神經網絡模型來生成動作序列，而不是序列化的邏輯表達式。我們發現，我們所採用的動作編碼形式 能夠捕捉到更多的句法信息和語義信息，同時我們的編碼方式更加的緊湊。此外，我們可以加入句法約束條件和語義約束條件來進一步增強語義解析。例如，在Geo數據集中， 動作add_edge:next_to（關係：接壤）必須滿足如下語義約束條件：這條邊所對應的兩個節點的類別只能分別是state（類別：州）和state， 還必須滿足如下句法約束條件：邊next_to必須連接兩個節點，以構成一個有效的圖。</p><p>我們在三個公開數據集上進行了對比實驗，這三個數據集分別為：Geo ，Atis 和Overnight 。 實驗結果論證了我們方法的有效性：我們的方法在Atis和Overnight這兩個數據集上都取得了現階段最好的結果，在Geo數據集上也取得了很有競爭力的結果。</p><p>本文工作的主要貢獻可以總結為以下兩點：</p><p>1.我們提出了一個新的語義解析框架——Sequence-to-Action，該框架把語義解析問題建模成端到端的語義圖生成過程。這個新的框架能夠同時利用語義圖的語義表示能力和循環神經網絡模型的強序列預測能力。</p><p>2.我們設計了一個sequence-to-action的生成模型，和一個動作集合用來編碼語義圖的構建，還有一個循環神經網絡模型用來生成動作序列。此外，我們還利用句法和語義條件約束來進一步增強語義解析。 實驗結果也論證了我們方法的有效性。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511049938b44a2b0e><p class=pgc-img-caption></p></div><p><strong>2 端到端的語義圖生成方法</strong></p><p>給定一個句子</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975110477b2ef6f1957><p class=pgc-img-caption></p></div><p>，我們的sequence-to-action模型將生成一個動作序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751104543703c0bfa2><p class=pgc-img-caption></p></div><p>，該動作序列將用於構建句子所對應的語義圖。 圖2展示了一個例子。我們的模型中，由X生成Y的條件概率</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/152897511044811d2bf4e06><p class=pgc-img-caption></p></div><p>利用鏈式法則可以分解為如下形式：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15289751107036108778cc4><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511076025c8b5ead5><p class=pgc-img-caption></p></div><p>。</p><p>為了達到上述目標，我們需要：1）一個動作集合，該集合能夠編碼語義圖的構建；2）一個編碼器（encoder），該編碼器把自然語言句子X轉化為一個向量表示，和一個解碼器（decoder），該解碼器根據編碼器傳過來的向量表示來生成動作序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15289751107467e8a38fff2><p class=pgc-img-caption></p></div><p>。接著，我們將分別介紹這兩部分。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751109391e1ca2517e><p class=pgc-img-caption></p></div><p>圖2：例子展示：一個句子，以及該句子所對應的語義圖和用來構建該語義圖的動作序列</p><blockquote><p>2.1 用於語義圖構建的動作集</p></blockquote><p>通常，一個語義圖有如下幾個成分組成：節點（包括變量節點，實體節點和類別節點）、邊（對應到語義關係）和一些通用的操作符（如，最大操作符、最小操作符、計數操作符、求和操作符等）。 為了構建一個語義圖，我們設計了六種類型的動作，它們分別是：</p><p><strong>添加-變量節點（Add Variable Node:）</strong>這類動作表示往語義圖上添加一個變量節點。一般情況下，變量節點同時也是返回的節點（對應到疑問詞：which, what）， 但也有可能是一箇中間變量節點。我們使用如下形式來表示這類動作：add_variable:A，其中A是變量節點的標識ID。</p><p><strong>添加-實體節點（Add Entity Node:）</strong>這類動作表示往語義圖上添加一個實體節點。一個實體節點對應到知識庫中的一個實體。我們使用如下形式來表示這類動作：add_entity_node:texas。</p><p><strong>添加-類別節點（Add Type Node:）</strong>這類動作表示往語義圖上添加一個類別節點，如（state，city)）。我們使用如下形式來表示這類動作：add_type_node:state。 實際上，類別節點本來與變量節點和實體節點是不同的，一個類別節點其實是包括一個表示類別的節點，和一條邊，只是這條邊的值都是一樣的，都是類別Type，為了簡化一個類別節點， 我們才設計成上面的那樣子。</p><p><strong>添加-邊（Add Edge:）</strong>這類動作表示往語義圖上的兩個節點之間添加一條邊。一條邊對應到知識庫中的一個二元關係。我們使用如下形式來表示這類動作：add_edge:next_to。</p><p><strong>操作符動作（Operation Action:）</strong>這類動作表示往語義圖上加一個操作符。一個操作符可以是：最大（argmax）、最小（argmin）、 計數（count）、求和（sum）、否定（not）等（複雜的情況還有比較（compare），這裡我們先不考慮）。由於每一個操作符都有它的轄域， 為了表示一個操作符的轄域，我們定義為每一個操作符定義兩個動作：一個開始操作符，表示如：start_operation:most，一個結束操作符，表示如：end_operation:most。 這兩個操作符之間的動作序列所構成的語義子圖就是該操作符的轄域。在顯示的語義圖上，我們用一個圈來表示該操作符的轄域。</p><p><strong>參數動作（Argument Action:）</strong>由於上述的動作中有些類別的動作需要額外的參數信息，如，一條邊add_edge:next_to是連接的哪兩個節點。因此，我們分別為添加-類別節點（add_type）、 添加邊（add_edge）和操作符（operation）設計了參數動作，並且參數動作總是跟在它的主動作的後面。</p><p>對於添加-類別節點（add_type）動作，我們添加一個參數動作，這個參數動作用來表明該類別是用來約束哪個節點的這個參數可以是變量節點，可以是實體節點。這類動作可以表示為：arg:A。</p><p>對於添加邊（add_edge）動作，我們添加兩個參數動作：arg1_node和arg2_node，用來表示該邊連接哪兩個節點。這類動作可以表示為：arg1_node:A和arg2_node:B。</p><p>對於不同的操作符（operation），我們又設計了不同的參數，對於求和操作（operation:sum），我們添加3個參數動作：arg-for、arg-in和arg-return， 分別用來表明求和操作所作用的節點，所統計的因素和返回的結果（一般為一個變量節點）；對於計數操作（operation:count）， 我們添加兩個參數動作：arg-for和arg-return，分別用來表明所要計數的節點和返回的結果；對於最高級操作（operation:most），我們添加2兩個參數動作：均為arg-for， 用來表明所作用的兩個節點之間的邊，並且這兩個節點有先後順序。</p><p>我們可以看到每一個動作都同時建模了句法和語義信息，這使得模型在使用這種編碼形式的時候能夠捕捉到更多的信息，同時這些信息與知識庫保持著緊密的聯繫。另外，我們還發現使用動作序列的編碼形式比直接序列化邏輯表達式的形式 更加的緊湊（詳情參加4.3節）。</p><blockquote><p>2.2 詞語序列-動作序列的神經網絡模型</p></blockquote><p>基於上節介紹的動作編碼，這一節我們介紹我們用於把句子解析成動作序列的編碼-解碼（encoder-decoder）模型。具體地，類似於Jia and Liang (2016)所使用的循環神經網絡模型， 我們這裡也利用基於注意力機制的序列-序列的循環神經網絡模型。圖3展示了該模型的示例圖。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975110905c87045c8b8><p class=pgc-img-caption></p></div><p>圖3：基於注意力機制的用於生成動作序列的循環神經網絡模型，附帶一個添加約束條件的控制器</p><p><strong>編碼器（encoder）</strong>：編碼器負責使用雙向循環神經網絡把輸入的句子</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1528975111006a6e7fbee9a><p class=pgc-img-caption></p></div><p>轉化為包含上下文信息的向量表示序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111021fd8cc0944f><p class=pgc-img-caption></p></div><p>。首先，每一個詞</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111039c903d0715f><p class=pgc-img-caption></p></div><p>被映射成它的向量化表示，然後這些向量表示被輸入到兩個循環神經網絡：一個前向循環神經網絡（forward RNN）和一個後向循環神經網絡(backward RNN)。 最後我們遞歸使用如下計算方式來生成隱藏狀態的序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751110739a7d7c7411><p class=pgc-img-caption></p></div><p>：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111201726217c7d4><p class=pgc-img-caption></p></div><p>其中我們採用長短記憶時記憶網絡（LSTM）的形式來進行計算。最後，對於輸入句子的每個位置</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111235c472b5a171><p class=pgc-img-caption></p></div><p>，我們定義它的帶有上下文信息的向量化表示為：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15289751112940eb1ce312f><p class=pgc-img-caption></p></div><p>。</p><p><strong>解碼器（decoder）</strong>：我們使用經典的基於注意力機制的解碼器，該編譯器依次生成一個動作，構成動作序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111302d0ec16500a><p class=pgc-img-caption></p></div><p>。 在時間節點</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111345b08345dde7><p class=pgc-img-caption></p></div><p>，編譯器基於當前的隱藏狀態</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751113611a8a1c8926><p class=pgc-img-caption></p></div><p>生成動作</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751114992ce296e396><p class=pgc-img-caption></p></div><p>，接著基於</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751113611a8a1c8926><p class=pgc-img-caption></p></div><p>和</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751114992ce296e396><p class=pgc-img-caption></p></div><p>更新隱藏狀態，得到</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1528975111550d2c3ea5232><p class=pgc-img-caption></p></div><p>。這個編譯器是由如下計算公式形式化定義的：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111605adc7683939><p class=pgc-img-caption></p></div><p>其中歸一化後的注意力分數</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15289751116484e75a1ee29><p class=pgc-img-caption></p></div><p>定義了在輸入的詞上的概率分佈，詞上面的每一個概率值表示在時刻</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111345b08345dde7><p class=pgc-img-caption></p></div><p>在該詞上的注意力集中程度，概率值越大，表明注意力越集中在該詞上面。 另外，</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/152897511165306ab14c5c8><p class=pgc-img-caption></p></div><p>是未歸一化的注意力分數。</p><p>為了能夠在解碼的過程中加入約束條件，我們在模型中加入了一個控制器（controller），我們將在第3.3節詳細介紹該控制器。</p><p><strong>動作的向量表示</strong>：在上述解碼器中需要每一個動作的向量化表示（</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751114992ce296e396><p class=pgc-img-caption></p></div><p>）。如前面介紹的，每一個動作都包含兩部分：一部分是句法部分（如，add_edge），另一部分是語義部分 （如，next_to）。這樣一來，動作與動作可能會共享句法部分或者語義部分。如動作add_edge:next_to和動作add_edge:loc就共享了句法部分，而動作add_node:A和 動作arg_node:A就共享了句法部分。為了減少參數的數量，儘量是參數不稀疏，我們先讓每個句法部分和每個語義部分都單獨具有它的向量化表示，對於一個動作， 我們把它的句法部分和語義部分的向量串聯起來（concatenate）,組成該動作的向量化表示， 比如</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111672c7a208a27b><p class=pgc-img-caption></p></div><p>add_edge:next_to）=[</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/152897511180115cc132609><p class=pgc-img-caption></p></div><p>add_edge</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751118248192b4c27a><p class=pgc-img-caption></p></div><p>next_to）] 。其中動作的向量映射函數</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111924c3b3de7b5e><p class=pgc-img-caption></p></div><p>通過訓練學習而來。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511049938b44a2b0e><p class=pgc-img-caption></p></div><p><strong>3 帶約束條件的神經語義解析模型</strong></p><p>在這一節，我們將描述我們是如何利用sequence-to-action模型來建立一個語義解析器的。我們首先介紹我們如何訓練我們的模型，以及如何進行推理（inference），接著介紹如何在解碼的過程中加入句法約束條件和語義約束條件。</p><blockquote><p>3.1訓練</p></blockquote><p><strong>參數學習</strong> 我們模型的參數包括：循環神經網絡模型的參數</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111919e6f9f3a4b9><p class=pgc-img-caption></p></div><p>、</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975111991c6caff6c92><p class=pgc-img-caption></p></div><p>和</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1528975112016f053a7431a><p class=pgc-img-caption></p></div><p>，詞向量映射函數</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511209201a496875a><p class=pgc-img-caption></p></div><p>，和動作向量映射函數</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975111924c3b3de7b5e><p class=pgc-img-caption></p></div><p>。我們通過訓練語料來學習這些參數。 給定一個訓練樣例（句子X和它所對應的動作序列Y），我們最大化X由生成Y的似然估計。我們的目標函數如下（對其最大化）：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/152897511214405d2059286><p class=pgc-img-caption></p></div><p>我們使用標準的隨機梯度下降算法來更新參數。</p><p><strong>邏輯表達式到動作序列的轉換</strong> 現階段用於語義解析的語料大多都是以邏輯表達式來標註的。為了訓練我們的模型，我們需要得到句子的語義圖所對應的動作序列。 我們以語義圖作為中間表示把邏輯表達式轉換為動作序列（圖3展示了轉換的一個簡單流程圖）。具體地，首先我們利用深度優先的算法把邏輯表達式轉換成語義圖， 再使用相同的順序從語義圖生成動作序列。其中實體，變量和類別都是節點，關係是邊。其中作為中間表示的語義圖，我們是使用專門的數據結構來進行表示的，類似於函數-參數的形式， 邊是函數名，節點是函數的參數，語義圖上的一條邊和兩個節點對應到一組函數-參數的存儲結構，整個語義圖就對應到函數-參數的存儲結構的一個序列，並且是要考慮該序列的順序的。 一方面，我們可能需要句子利用句子的語義表示在知識庫上執行計算，得到信息來輔助訓練，另一方面由於語義圖的形式，和動作序列的形式都不容易直接理解，為了方便分析，我們也需要句子所對應的邏輯表達式， 我們使用相同的策略，再從動作序列轉換到邏輯表達式。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511227260f6ed52ca><p class=pgc-img-caption></p></div><p>圖4：邏輯表達式與動作序列之間相互轉換的流程簡介圖</p><p><strong>對於實體的處理機制</strong> 實體在語義解析中充當了十分重要的角色，之前的很多工作都直接使用手工實體詞彙， 當然也有使用實體鏈接技術來實現句子中實體的語義落地的。在Dong and Lapata (2016)的工作中， 他們使用預處理的方式，先利用字符串匹配的方法把實體都識別出來，由於實體容易帶來數據稀疏的問題（一般一個實體在語料中出現的次數會很少），他們用實體的類別和獨有ID來表示實體。 如Texas會表示為State0。在Jia and Liang (2016)的工作中，他們使用神經機器翻譯裡面經常使用的複製（Copying）機制來處理實體（他們還需要一個實體詞典）。 在本文中，我們都嘗試並實現兩種實體處理的機制，並在後面的實驗中比較了這兩種實體處理機制。</p><blockquote><p>3.2推導</p></blockquote><p>在測試的時候，給一個新的句子X，我們通過如下公式來得到它所對應的動作序列Y:</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511220573262d06d6><p class=pgc-img-caption></p></div><p>其中</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975112581d31137851a><p class=pgc-img-caption></p></div><p>的計算是利用[equation-5-1]計算而來。在解碼的時候，我們使用了柱搜索（beam search）。我們可以從最優動作序列</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751122691dba742230><p class=pgc-img-caption></p></div><p>得到相應的語義圖和邏輯表達式。</p><blockquote><p>3.3 在解碼中加入約束條件</p></blockquote><p>在解碼的時候，我們依次生成一個動作。顯然，動作與動作之間是有很強的關聯的，也就是說下一個動作與當前生成的語義子圖是有關聯的，有一些動作明顯是錯誤的，可以利用句法約束條件和語義約束條件來進行刷選。 已經有工作證明了句法和語義約束條件可以用來增強語義解析。在本文我們也利用句法和語義約束條件，具體的，我們設計了一個控制器，該控制器讀入已經生成的動作序列，並構建語義子圖， 然後利用如下的句法約束條件和語義約束條件來對動作進行過濾，把違背約束條件的動作濾掉。</p><p><strong>句法約束條件</strong> 句法約束條件是為了保證生成的動作序列可以構成一個連通的無環圖，這是因為語義圖一般是連通的，也是無環的。比如，沒生成一個添加邊的動作，該邊都必須有兩個不同的節點作為它的參數， 圖5中，作為下個動作的候選動作中第三個動作就是違背了這條約束規則，它的兩個參數節點是一樣的，會導致生成的圖有環，不符合語義圖的要求。這種類型的約束條件是領域無關的，並且是通用的。 我們在控制器中通過若干條規則來建模句法約束條件。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15289751124561875d02725><p class=pgc-img-caption></p></div><p>圖5：使用約束條件來過濾錯誤動作的示例</p><p><strong>語義約束條件</strong> 語義約束條件是為了保證生成的語義圖符合知識庫本體模板框架（schema）的約束。具體的，我們建模了兩類語義約束條件，一類是選擇約束（selectional preference）， 這種約束條件是確保生成的語義圖中邊的兩個參數（節點）的類型必須符合知識庫中本體模板框架（schema）中類型的約束。比如，在Geo數據集中，邊next_to（關係：接壤）的兩個節點參數的類型均是state（州）。 圖5中，作為下個動作的候選動作中第二個動作違背了這條約束規則，由於邊loc（關係：位於）的兩個參數節點類型可以分別是city（類別：城市）和state（類別：州），而例子中， 第一個參數節點（變量節點A）的類型是state（類別：州），而第二個參數節點（實體節點texas:st）的類型也是state（類別：州），這就違背了選擇約束。 第二類約束是類別不衝突約束條件，這種約束條件保證每個節點（可以是變量節點，也可以是實體節點）的類別不衝突，比如說一個節點的類型不能同時是city（類別：城市）和state（類別：州）。 圖5中，作為下個動作的候選動作中第一個動作違背了這條約束規則，由於這個動作是在實體節點texas:st加一個類別節點（city），而實體節點texas:st的類型已經是state（類別：州）了， 這就違背了節點的類型不衝突約束條件。語義約束條件是領域相關的，不過我們可以從知識庫中自動抽取出這類約束條件。在控制器中，我們同樣使用若干條規則來編碼語義約束條件。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511049938b44a2b0e><p class=pgc-img-caption></p></div><p><strong>4 實驗</strong></p><blockquote><p>4.1 實驗結果與分析</p></blockquote><p>對於我們的模型，我們有三種不同的設置，一種是最基本的sequence-to-action模型，沒有使用任何約束條件的——Seq2Act；第二種是加上語法約束條件的——Seq2Act (+C1)； 第三種是同時加上語法約束條件和語義約束條件的Seq2Act (+C1+C2)。我們沒有設置單獨加語義約束條件的，這是因為我們所使用的語義約束條件是在符合句法約束條件的基礎上添加的，如果一個語義圖不符合句法約束條件， 再來談語義約束條件是沒有意義的。在三個數據機上的結果分別在表1和表2中展示，兩個表格中帶*號的系統表示該系統有使用額外的語料或資源。從結果我們可以看到：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751121576e447a8d78><p class=pgc-img-caption></p></div><p>表1： Geo數據集和Atis數據集上的測試結果</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15289751121576e447a8d78><p class=pgc-img-caption></p></div><p>表2：在OVERNIGHT數據集上的測試結果</p><p>1）通過同時利用語義圖的語義表示能力和循環神經網絡模型的表示學習能力以及對序列問題的強預測能力，我們的方法（Seq2Act (+C1+C2)）在Atis數據集和Overnight數據集上都取得了當前最好的結果， 同時在Geo數據集上也取得了與最好成績不相上下的結果。具體的，在Geo數據集上，我們完整的模型Seq2Act (+C1+C2)在相同的設置條件下取得的結果（88.9的準確率）也是最好的，只落後於兩個系統， 一個是Liang et al. (2011)*，該系統有使用額外的人工定義的詞彙；另一個是Jia and Liang (2016)* ，該系統使用數據重組（data recombination）的方式對訓練語料進行了擴充。 在Atis數據集和Overnight數據集上，我們完整的模型分別取得了85.5和79.0（八個領域的平均準確率）的準確率，都是當前最好的結果，甚至比有利用額外訓練語料的Jia and Liang (2016)*結果要好。</p><p>2）相比之前的序列-序列（Seq2Seq）的模型中所使用的序列化邏輯表達式，我們所使用的動作序列編碼更加有效。在三個數據集上，我們最基本的系統Seq2Act的結果比Seq2Seq模型都要好。在Geo數據集上，Seq2Act的準確率是87.5， 而Seq2Seq模型中最好的結果是87.2；在Atis數據集，Seq2Act的準確率是84.6，與Seq2Seq模型中最好的結果一樣；在Overnight數據集上，Seq2Act的準確率是78.0，而Seq2Seq模型中最好的結果是77.5。 我們認為這是因為我們所採用的動作序列編碼更緊湊，另外能夠編碼更多的信息，特別是同時編碼句法信息和語義信息（這點與所使用的基於CCG的詞彙有點類似）。</p><p>3）句法約束條件能夠基於保證語義圖結構有效原則對候選動作進行刷選，及時過濾違背該約束的動作，這樣一來能夠有效提高語義解析的性能。在三個數據集上，有使用句法約束條件的系統Seq2Act (+C1)比最基本的系統Seq2Act都有所提高。</p><p>4）語義約束條件能夠進一步的提高語義解析的性能。在三個數據集上，我們完整的模型Seq2Act (+C1+C2)的結果都超過了Seq2Act和Seq2Act (+C1)的結果。我們認為這是因為我們利用選擇約束和類別不衝突約束，能夠在解碼的時候， 及時過濾掉違背這些約束條件的錯誤的動作候選，從而提高了最終結果是準確的可能性。</p><blockquote><p>4.2 詳細分析</p></blockquote><p><strong>對比兩種實體處理機制</strong> 在前面章節已經提到，我們實現了兩種實體處理機制，一種是基於替代（Replacing）的機制：把實體替換成實體的類別加上獨有的ID； 另一種是基於複製（Copying）的機制。為了對比兩種實體處理機制，我們用我們的完整模型分別利用兩種實體處理機制進行了對比實驗，實驗結果如表3所示。 我們可以看到在三個數據集上，基於Replacing的實體處理機制比基於Copying的實體處理機制的效果都好。我們認為這是因為Replacing是在預處理中處理的，能夠有效消除由實體帶來的稀疏問題； 而Copying是存在於訓練和測試中的，並且需要額外的Copying機制，詳情參見。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975112462970b5ba4f9><p class=pgc-img-caption></p></div><p>表3：在三個數據集上對比兩種實體處理機制的結果</p><p>對比線性化的邏輯表達式和動作序列 之前的Seq2Seq模型直接使用線性化的邏輯表達式作為目標端的序列，我們使用動作序列作為目標端的序列，表4中顯示了兩者的平均長度。我們可以看到， 動作序列比線性化的邏輯表達式更加的緊湊：相比線性化的邏輯表達式，動作序列更短，在三個數據集上，長度分別減少了35.5%、9.2%和28.5%。在Overnight數據集上，我們對8個領域分別統計，在進行平均。 這種更短/更緊湊的編碼方式能夠稍微減緩一下目標端長距離依賴的問題，並且也有利於學習自然語言句子與目標端的語義表示之間的對齊。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1528975112438012dc39d95><p class=pgc-img-caption></p></div><p>表4：在三個數據集上線性化邏輯表達式和動作序列的平均長度</p><blockquote><p>4.3 錯誤分析</p></blockquote><p>我們在錯誤的樣例上進行了錯誤分析，我們發現有兩類錯誤比較顯著，也應該引起我們的注意。我們在表5中展示了幾個錯誤樣例，每個例子由三部分組成：句子、正確的邏輯表達式和我們模型預測的邏輯表達式， 另外我們用紅顏色標記了錯誤的地方。這兩類錯誤如下：</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511260235b5c596f6><p class=pgc-img-caption></p></div><p>表5：錯誤分析樣例</p><p><strong>未出現/不正式的句法結構</strong> 有些測試樣例有沒有在語料中出現過的句法結構。表5的第一個例子中，句子的這種句法結構並不常見， 實體詞“Iowa”和關係詞“borders”都出現在疑問詞“how many”之前，正常的形式應該是：“How many states does Iowa border?”。 對於這種問題，我們可以嘗試利用句子重寫或者複述的方法把有不常見句法結構的句子轉換成有常見句法結構的句子。</p><p><strong>匹配遺漏（Under-Mapping）</strong>像我們所使用的基於注意力機制的循環神經網絡模型並沒有考慮對齊的歷史，當前的注意力分佈並沒有把之前的注意力分佈考慮進行， 這樣容易造成源端的有些詞語並沒有被注意力集中到，從而導致某些詞語沒有匹配到，出現匹配遺漏的情況，如表5中的第二個例子，“first class”就被忽略了，本來它是要映射到(class_type x first:cl)的。 這類問題在神經機器翻譯中也很常見，類似的，我們可以利用注意力覆蓋度的機制來處理這種問題。</p><div class=pgc-img><img alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/152897511049938b44a2b0e><p class=pgc-img-caption></p></div><p><strong>5 總結</strong></p><p>本文同時從語義落地和結構預測兩個方面來研究語義解析。針對現有語義解析方法過於依賴於高質量詞典、 特定文法和人工定義特徵的問題，我們提出了一種端到端語義圖生成的語義解析方法。該方法同時利用了語義圖的表示優勢， 和循環神經網絡模型的強序列預測能力。具體的，我們將語義解析問題轉換為自然語言句子序列到語義圖構建的動作序列的翻譯問題， 我們使用循環神經網絡模型來建模動作序列的生成。相比於傳統語義解析方法，該方法使用語義圖來表示句子的語義，不再需要特定文法； 相比於新興的語義解析方法，該方法使用動作序列來編碼語義圖的構建，循環神經網絡模型來建模動作序列的生成，該過程不再是啟發式， 是端到端的，同時在解析的過程中能夠考慮到動作與動作之間的相互聯繫，能夠方便地加入句法和語義約束條件，進一步提升語義解析的準確度。 最後，我們在三個公開數據集上進行了實驗，實驗結果論證了我們方法的有效性。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ACL</a></li><li><a>2018</a></li><li><a>軟件</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/4006546.html alt=軟件評測師2018年真題+詳解（上午+下午） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4006546.html title=軟件評測師2018年真題+詳解（上午+下午）>軟件評測師2018年真題+詳解（上午+下午）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/81e23745.html alt=2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/9ea544b278cc4007bf1ea7c686f4af6a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/81e23745.html title=2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高>2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c08f7fcf.html alt=寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c08f7fcf.html title=寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究>寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7e39f460.html alt=太好了！2018志願填報“模板”來了，三分鐘定位院校不求人 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15274780975837f1bb5470f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7e39f460.html title=太好了！2018志願填報“模板”來了，三分鐘定位院校不求人>太好了！2018志願填報“模板”來了，三分鐘定位院校不求人</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html alt=聲音錄製，用軟件算法模擬硬件也能出專業效果 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15374046796064ae0d9cd60 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html title=聲音錄製，用軟件算法模擬硬件也能出專業效果>聲音錄製，用軟件算法模擬硬件也能出專業效果</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f49d9179.html alt=2018年全國排化學中考複習二輪專項練習-物質的構成和分類 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7dc6eb7a4299414a920f1987a1809095 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f49d9179.html title=2018年全國排化學中考複習二輪專項練習-物質的構成和分類>2018年全國排化學中考複習二輪專項練習-物質的構成和分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9552c1b8.html alt="軟件開發中數據庫必備基礎01 - 圖解事務基礎" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4e00ac778db451792b955bde23add02 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9552c1b8.html title="軟件開發中數據庫必備基礎01 - 圖解事務基礎">軟件開發中數據庫必備基礎01 - 圖解事務基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7e00dfe5.html alt="2018年12月以來上海日照時數創歷史新低 明天陽光上線" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/REtv8O37mCho3I style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7e00dfe5.html title="2018年12月以來上海日照時數創歷史新低 明天陽光上線">2018年12月以來上海日照時數創歷史新低 明天陽光上線</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/77f10720.html alt=電子設計軟件公司Altium稱電子設計的銷售繼續保持暫停狀態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/67743491955d426094a06d714d9aefe4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/77f10720.html title=電子設計軟件公司Altium稱電子設計的銷售繼續保持暫停狀態>電子設計軟件公司Altium稱電子設計的銷售繼續保持暫停狀態</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/00241cd4.html alt="EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/8354687ee778482b91fcf358548742a1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/00241cd4.html title="EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化">EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8f16596d.html alt="EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化模塊" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RzUhNnv9Rg64Gv style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8f16596d.html title="EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化模塊">EmStat Pico：支持軟件運行的嵌入式小型電化學恆電勢器系統化模塊</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fb27fd8d.html alt=2018鹿邑交警那些事，哪些更能讓你記憶深刻 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/R69u2M5GcN8qci style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fb27fd8d.html title=2018鹿邑交警那些事，哪些更能讓你記憶深刻>2018鹿邑交警那些事，哪些更能讓你記憶深刻</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1d114e79.html alt=阿榮旗2018年度“清風乾部”公示名單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1d114e79.html title=阿榮旗2018年度“清風乾部”公示名單>阿榮旗2018年度“清風乾部”公示名單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8dbdc94b.html alt=2018年質量、環境和職業健康安全管理體系程序文件（全套） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1538011762616c2e5d2f7a7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8dbdc94b.html title=2018年質量、環境和職業健康安全管理體系程序文件（全套）>2018年質量、環境和職業健康安全管理體系程序文件（全套）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cef67581.html alt=農哈哈2018款六行玉米大豆旋耕播種機 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/6c3700014cf434fa998d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cef67581.html title=農哈哈2018款六行玉米大豆旋耕播種機>農哈哈2018款六行玉米大豆旋耕播種機</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>