<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？ | 极客快訊</title><meta property="og:title" content="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/S2C8F2A8wkrbVw"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/5d39767f.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/5d39767f.html><meta property="article:published_time" content="2020-10-29T21:12:20+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:20+08:00"><meta name=Keywords content><meta name=description content="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/5d39767f.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8F2A8wkrbVw><p><strong>作者 | JayLou婁傑</strong></p><p><strong>編輯 | 叢 末</strong></p><p><strong>1</strong></p><p><strong>前言</strong></p><p>在醫療、金融、法律等領域，高質量的標註數據十分稀缺、昂貴，我們通常面臨少樣本低資源問題。本文從「文本增強」和「半監督學習」這兩個角度出發，談一談如何解決少樣本困境。</p><p>正式介紹之前，我們首先需要思考什麼才是一種好的解決少樣本困境的方案？本文嘗試給出了三個層次的評價策略，我們希望採取相關數據增強或弱監督技術後：</p><p>1）在少樣本場景下，比起同等標註量的無增強監督學習模型，性能有較大幅度的提升；</p><p>2）在少樣本場景下，能夠達到或者逼近充分樣本下的監督學習模型性能；</p><p>3）在充分樣本場景下，性能仍然有一定提升；</p><p>基於此，本文首先總結了nlp中的文本增強技術，然後串講了近年來9個主流的半監督學習模型，最後主要介紹了來自Google提出的UDA（一種文本增強+半監督學習的結合體）。本文的組織結構為：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8F2lERLTIoD><p><strong>2</strong></p><p><strong>NLP中的文本增強技術總結</strong></p><p>談起文本增強技術，相信NLPer一定不會陌生，相關方法也是數不勝數。我們通常對標註數據集提供附加的感應偏置進行擴充，如何設計增強變換就變得至關重要。本文嘗試從一個新角度——是否條件增強，借鑑文獻<sup>[1]</sup>進行了總結歸納：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8F32FqgGUze><p>定義：既可以對標註數據進行增強（增強後標籤不發生變化），又可以針對無標註數據進行增強，不需要強制引入標籤信息。</p><p><strong>詞彙&短語替換</strong></p><ul><li><p><strong>基於詞典</strong>：主要從文本中選擇詞彙或短語進行同義詞替換，詞典可以採取 WordNet或哈工大詞林等。著名的<strong>EDA</strong>(Easy Data Augmentation)<sup>[2]</sup>就採用了這種方法。</p></li><li><p><strong>基於詞向量</strong>：在嵌入空間中找尋相鄰詞彙進行替換，我們所熟知的TinyBERT<sup>[3]</sup>就利用這種技術進行了數據增強。</p></li><li><p><strong>Masked LM</strong>：借鑑預訓練語言模型（如BERT）中的自編碼語言模型，可以啟發式地Mask詞彙並進行預測替換。</p></li><li><p><strong>TF-IDF</strong>：實質上是一種非核心詞替換，對那些low TF-IDF scores進行替換，這一方法最早由Google的UDA<sup>[4]</sup>提出:</p></li></ul><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8F3P986tbFq><p><strong>隨機噪音注入</strong></p><ul><li><p><strong>隨機插入</strong>：隨機插入一個詞彙、相應的拼寫錯誤、佔位符等，UDA<sup>[4]</sup>則根據Uni-gram詞頻分佈進行了採樣。</p></li><li><p><strong>隨機交換</strong>：隨機交換詞彙或交換shuffle句子。</p></li><li><p><strong>隨機刪除</strong>：隨機刪除(drop)詞彙或句子。</p></li></ul><p>注意：EDA<sup>[2]</sup>除了進行同義詞替換外，也同時採用上述三種隨機噪音注入。</p><p><strong>混合&交叉</strong></p><ul><li><p><strong>混合增強</strong>：起源於圖像領域的Mixup<sup>[5]</sup>，這是一種表示增強方法，借鑑這種思想，文獻<sup>[6]</sup>提出了wordMixup和sentMixup將詞向量和句向量進行Mixup。</p></li></ul><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8F3b6o1wCzx><p><strong>交叉增強</strong>：類似於“染色體的交叉操作”，文獻<sup>[7]</sup>將相同極性的文本進行交叉：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8FZA5kO1Txj><ul><li><p><strong>回譯</strong>：基於機器翻譯技術，例如從中文-英文-日文-中文；我們熟知的機器閱讀理解模型QANet<sup>[8]</sup>和UDA<sup>[4]</sup>都採用了回譯技術進行數據增強。</p></li><li><p><strong>句法交換</strong>：通過句法樹對文本句子進行解析，並利用相關規則進行轉換，例如將主動式變成被動式句子。</p></li><li><p><strong>對抗增強</strong>: 不同於CV領域利用GAN生成對抗進行數據增強<sup>[9]</sup>，NLP中通常在詞向量上添加擾動並進行對抗訓練，文獻<sup>[10]</sup>NLP中的對抗訓練方法FGM, PGD, FreeAT, YOPO, FreeLB等進行了總結。</p></li></ul><p>本節介紹的無條件增強方法，在對標註數據進行增強後標籤不發生變化，但可能會造成文本主旨發生發生變化（例如情感分析中，某一時刻將good 替換為了bad），帶來的噪音過大從而影響模型性能。因此，我們是否可以考慮引入標籤信息來引導數據生成呢</p><p>2、<strong toutiao-origin=span>條件增強</strong></p><p>定義：所謂條件增強（Conditional Data Augmentation），就是意味著需要強制引入「文本標籤」信息到模型中再產生數據。</p><p><strong>深度生成模型</strong>：既然條件增強需要引入標籤信息進行數據增強，那麼我們自然就會聯想到Conditional變分自編碼模型(CVAE)，文獻<sup>[11]</sup>就利用CVA進行增強。想生成一個高質量的增強數據，往往需要充分的標註量，但這卻與「少樣本困境」這一前提所矛盾。這也正是GAN或者CVAE這一類深度生成模型在解決少樣本問題時需要考慮的一個現狀。</p><p><strong>預訓練語言模型</strong>：眾所周知，BERT等在NLP領域取得了巨大成功，特別是其利用<strong>大量無標註數據</strong>進行了語言模型預訓練。如果我們能夠結合標籤信息、充分利用這一系列語言模型去做文本增強，也許能夠克服深度生成模型在少樣本問題上的矛盾。近來許多研究者對Conditional Pre-trained Language Models 做文本增強進行了有益嘗試：</p><p><strong>Contextual Augment</strong><sup>[12]</sup>：這是這一系列嘗試的開篇之作，其基於LSTM進行biLM預訓練，將標籤信息融入網絡結構進行finetune，是替換生成的詞彙與標籤信息兼容一致。</p><p><strong>CBERT</strong><sup>[13]</sup>：其主要思想還是借鑑了Contextual Augment，基於BERT進行finetune，將segment embedding轉換融入標籤指示的label embedding（如果標籤類別數目大於2類，則相應擴充），如下圖，替換good生成的funny與標籤positive兼容。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8FZY4wvB3wf><p><strong>LAMBADA</strong><sup>[14]</sup>：來自IBM團隊，其基於GPT-2將標籤信息與原始文本拼接當作訓練數據進行finetune（如下圖所示，SEP代表標籤和文本的分割，EOS是文本結束的標誌），同時也採用一個判別器對生成數據進行了過濾降噪。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8Fa19OyXzJp><p>在最近的一篇paper《Data Augmentation using Pre-trained Transformer Models》<sup>[15]</sup>中，根據不同預訓練目標對自編碼(AE)的BERT、自迴歸(AR)的GPT-2、Seq2Seq的BART這3個預訓練模型進行了對比。不同於CBERT，沒有標籤信息變為label embedding而是直接作為一個token&sub-token來於原文拼接。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8FaJ6Q3QeRj><p>如上圖所示，採樣原始標註數據的1%作為少樣本場景的設置，其發現BART表現最好，文中也做了相應對比實驗發現：</p><p>1）AE模型BERT在做文本增強後，容易被約束產生相似的文本序列，且擅長保存標籤信息。</p><p>2）AR模型GPT-2在做文本增強後，不受約束地生成文本，不擅長無法保留標籤信息。</p><p>3）Seq2Seq模型BART位於AE和AR之間，可以在多樣性和語義保真度之間取得良好的平衡。此外，BART可以通過更改跨度掩碼的長度來控制生成數據的多樣性。</p><p></p><h1 toutiao-origin=h2>3、總結與分析</h1><p>至此，我們介紹完了NLP中的文本增強技術，以<sup>[15]</sup>的實驗結果為例，我們可以發現文本增強技術可以滿足本文一開始給出的第一層次評價策略，即：<strong>在少樣本場景下，採用文本增強技術，比起同等標註量的無增強監督學習模型，性能會有較大幅度的提升</strong>。需要注意的是，上述相關文獻中，通常只針對標註數據進行文本增強。但我們是否可以充分利用領域相關的大量無標註數據解決少樣本困境呢？我們將在第2部分進行介紹。</p><p>除此之外，在實踐中我們也要去思考：</p><ul><li><p>是否存在一種文本增強技術，能夠達到或者逼近充分樣本下的監督學習模型性能？</p></li><li><p>在充分樣本下，採取文本增強技術，是否會陷入到過擬合的境地，又是否會由於噪音過大而影響性能？如何挑選樣本？又如何降噪？</p></li></ul><p><strong>3</strong></p><p><strong>半監督學習</strong></p><p>這一部分主要介紹如何結合大量無標註數據解決少樣本困境，相應的弱監督方法層出不窮，本文著眼於「<strong>半監督學習</strong>」，借鑑CV領域的9個主流方法進行介紹，包括：Pseudo-Label 、 Π-Model 、Temporal Ensembling、 Mean Teacher、 VAT 、 UDA 、MixMatch 、ReMixMatch 、 FixMatch。</p><p><strong toutiao-origin=span>1、為什麼要引入半監督學習？</strong></p><p>監督學習往往需要大量的標註數據，而標註數據的成本比較高，因此如何利用大量的無標註數據來提高監督學習的效果，具有十分重要的意義。這種利用少量標註數據和大量無標註數據進行學習的方式稱為<strong>半監督學習</strong>(Semi-Supervised Learning，<strong>SSL</strong>) 。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8Fal72Y5tif><p>如上圖所示，在同等的少量標註樣本下，半監督學習通常取得比監督學習較好的性能。進入深度學習時代以來，<strong>SSL如何在少量標註樣本下達到或超越大量標註樣本下監督學習的效果，SSL如何在大量標註樣本下也不會陷入到“過擬合陷阱”</strong>，是SSL研究者面臨的一個挑戰。</p><p>近年來，半監督深度學習取得了長足的進展，特別是在CV領域；相關的研究主要著力於如何針對未標註數據構建無監督信號，與監督學習聯合建模；簡單地講，就是<strong>如何在損失函數中添加針對未標註數據相關的正則項，使模型能夠充分利用大量的未標註數據不斷迭代，最終增強泛化性能</strong>，正如下圖所展示的那樣（來自文獻 [4] ）。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8G6cDajSuam><p><strong>2、半監督深度學習方法介紹</strong></p><p>總的來看，深度學習時代的半監督學習，主要針對未標註數據相關的<strong>正則化項</strong>進行設置，其通常有以下兩種：</p><p><strong>1）熵最小化（Entropy Minimization）：</strong>根據半監督學習的Cluster假設，決策邊界應該儘可能地通過數據較為稀疏的地方（低密度區），以能夠避免把密集的樣本數據點分到決策邊界的兩側。也就是模型通過對未標記數據預測後要作出低熵預測，即熵最小化：</p><p><strong>2）一致性正則（Consistency Regularization）：</strong>對於未標記數據，希望模型在其輸入受到擾動時產生相同的輸出分佈。即：</p><p>重要說明：本文將 定義為人工標籤，其含義是構建“標籤”指導一致性正則的實施，通常採取weak數據增強方法，也可能來自歷史平均預測或模型平均預測。 定義為預測標籤，為模型當前時刻對無標註數據的預測，對其輸入可進行strong增強或對抗擾動。</p><p><strong>(1) Pseudo-Label</strong><strong toutiao-origin=sup>[16]</strong></p><p>Pseudo Label的原理很簡單， 其損失函數定義為：</p><p>其中 為少量標註數據量，為未標註數據量， 為第m個標記數據的logit輸出，為其對應的標籤；為第m個未標記數據的logit輸出， 為其對應的Pseudo Label，具體的做法就是選舉每個未標註樣本的最大概率作為其偽標籤。為了降低噪音的影響，只有當置信度大於閾值時才計算相應的損失。</p><p>我們可以看出上式中第二項正是利用了<strong>熵最小化</strong>的思想，利用未標註數據和偽標籤進行訓練來引導模型預測的類概率逼近其中一個類別，從而將偽標籤條件熵減到最小。</p><p>模擬的是一個確定性退火過程，避免陷入局部最小值，調和平衡標註和未標註數據的訓練，從而使偽label更接近真實標籤：</p><p><strong>(2) Π-Model/Temporal Ensembling</strong><strong toutiao-origin=sup>[17]</strong></p><p>Π-Model 和 Temporal Ensembling來自同一篇論文，均利用了一致性正則。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8G78J7GYvU0><p>Π-Model如上圖所示，對無標註數據輸入進行了兩次不同的隨機數據增強、並通過不同dropout輸出得到和 ，並引入一致性正則到損失函數(L2 loss)中：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8G7XIvCz6xw><p>可以看出和 來自同一時間步產生的兩次結果，同一個train step要進行兩次前向計算，可以預見這種單次計算的噪音較大、同時降低訓練速度。Temporal Ensembling則採用時序融合模型，是歷史的EMA加權平均和，將其視作人工標籤，同一個train step只進行一次計算，如下圖所示：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8G7zEGABZxF><p><strong>(3) Mean Teacher</strong><strong toutiao-origin=sup>[18]</strong></p><p>Mean Teacher是對Temporal Ensembling的升級，仍然採用一致性正則(L2 loss)。</p><p>Temporal Ensembling是對預測結果進行EMA平均，但是每個epoch才更新一次，需要等到下一個epoch相關信息才能被模型學習。為克服這一缺點，Mean Teacher採取對模型參數進行EMA平均，其認為訓練步驟的上平均模型會比直接使用單一模型權重更精確，將平均模型作為teacher預測人工標籤，由當前模型（看作student）預測。</p><p><strong>(4) Virtual Adversarial Training</strong><strong toutiao-origin=sup>[19]</strong></p><p>Virtual Adversarial Training（VAT）仍然採用一致性正則，學習一致性就要添加擾動。作者認為，隨機擾動無法模擬複雜情況的輸入，不同於上述SSL方法採用數據增強進行施加擾動，VAT採取對抗訓練的方式添加噪音。</p><p>VAT不同於傳統的有監督學習下的對抗訓練，其沒有標籤信息，而是採用 構建一個虛擬標籤，並根據這個虛擬標籤計算對抗擾動方向 （通常是梯度上升的方向，為正梯度），這也是稱之為“虛擬對抗訓練”的原因吧～。VAT採用KL散度來計算一致性正則：</p><p>(5) UDA:Unsupervised Data Augmentation for Consistency Training<sup>[4]</sup></p><p>UDA來自Google，同樣也是採用一致性正則。一致性正則的關鍵在於如何注入噪聲，一個好的模型對於輸入擾動的任何細微變化也都應具有魯棒性。上述SSL方法注入噪音的方法通常為高斯噪音、dropout噪音、對抗噪音，這些注入方式被認為是較弱的干擾。UDA針對圖像採取一種高質量的數據增強方法——<strong>RandAugment</strong><sup>[23]</sup>，通過這種strong的干擾來提高一致性訓練性能。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8G8pINg215E><p>上圖為UDA的損失函數，核心在於對無標註數據 通過strong增強轉化為，採用KL散度來計算兩者間的一致性損失。UDA也通過回譯和非核心詞替換對文本進行無監督增強，我們將在第3部分作詳細介紹。</p><p>此外，UDA也利用了一些輔助技術：</p><ul><li><p>結合了熵最小化正則：對無監督信號進行sharpen操作構建人工標籤，使其趨近於 One-Hot 分佈，對某一類別輸出概率趨向 1，其他類別趨向0，此時熵最低。此外，還直接計算了熵損失。</p></li><li><p>將人工標籤與strong增強後的預測標籤共同構建一致性正則，並計算損失時進行了confidence-based masking，低於置信度閾值不參與loss計算。</p></li><li><p>採用訓練信號退火(TSA)方法防止對標註數據過擬合，對於標註數據的置信度高於閾值要進行masking，這與無標註數據正好相反。</p></li><li><p>使用初始模型過濾了領域外的無標註數據。</p></li></ul><p><strong>(6)</strong><strong>MixMatch</strong><strong toutiao-origin=sup>[20]</strong></p><p>MixMatch同樣來自Google，與UDA類似，同樣結合了熵最小化和一致性正則。其重要的操作就是通過MixMatch進行數據增強，與UDA的RandAugment不同，這種增強方式依然是weak的。MixMatch具體的數據增強操作為：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8GZq8RRX9sl><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8GaC26ZLaT9><p>1）對標註數據進行一次增強，對於未標註數據作K次weak增強輸入模型得到average後的概率，並對其進行與UDA類似的sharpen操作得到人工標籤，利用了熵最小化思想。</p><p>2）將無標註數據得到的人工標籤與標註數據混合在一起並進行MixUp<sup>[5]</sup>操作，進而得到增強後的無標註數據以及標註數據。</p><p>最後對於MixMatch增強後的標註數據 和無標註數據分別計算損失項，採用L2 loss引入一致性正則：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8GarFHkijeh><p><strong>(7) ReMixMatch</strong><strong toutiao-origin=sup>[21]</strong></p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8GbEGlUhN4Q><p>ReMixMatch是MixMatch原作者對自己工作的改進，主要有兩點：</p><p><strong>1）Distribution Alignment：</strong>分佈對齊，將無標註數據的人工標籤與標註數據的標籤分佈對齊，如上圖所示：根據標註數據的標籤分佈(Groud-truth labels)與無標註數據的平均預測(Model prediction)的比值作為“對齊因子”，緩解猜測標籤的噪音和分佈不一致情況。</p><p><strong>2）Strong Augmentation：</strong>MixMatch不穩定的原因可能是K次weak增強會導致不同的預測，取平均值不是具有意義的目標；ReMixMatch改進這一點，引入strong增強，將weak增強後的人工標籤與strong增強後的預測標籤共同構建一致性正則（KL散度）。具體的增強方式<strong>CTAugment</strong>可參考原論文。</p><p>此外，ReMixMatch還對未標註數據丟失的權重進行了退火，並引入了Rotation loss，這裡不再贅述。</p><p><strong>(8)</strong><strong>FixMatch</strong><strong toutiao-origin=sup>[22]</strong></p><p>FixMatch也是來自Google，實質上是UDA和ReMixMatch一個綜合簡化版本，捨棄了sharpen操作和UDA的訓練信號退火、ReMixMatch的分佈對齊和旋轉損失等。UDA和ReMixMatch表明引入strong增強方式，在與weak增強方式一同構建一致性正則時是有效的。FixMatch延續了這一思想，strong增強同時使用了UDA的RandAugment和ReMixMatch的CTAugment。</p><p>不同於UDA和ReMixMatch通過sharpen構建人工標籤來指導一致性正則的實施，FixMatch則直接利用Pseudo-Label 構建人工標籤。具體地說：記strong增強為 和weak增強為，對於標註數據只使用弱增強並計算交叉熵；對於無標註數據使用weak增強構建人工標籤 ，使用strong增強構建預測標籤，最終損失形式為：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8GbdBbQ6XHi><p>其中 為置信度閾值，對低於閾值的人工標籤不參與loss計算進行confidence-based masking。</p><p><strong toutiao-origin=span>3、不同半監督學習方法的對比</strong></p><p>至此，我們已經介紹完了近年來主流的半監督深度學習方法。回顧1.1節對一致性正則公式的介紹，我們可以發現：</p><ul><li><p><strong>人工標籤</strong>是構建“標籤”指導一致性正則的實施，通常採取weak數據增強方法，也可能來自歷史平均預測(Temporal Ensembling)或模型平均預測(Mean Teacher)；</p></li><li><p><strong>預測標籤</strong>為模型當前時刻對無標註數據的預測，其輸入可進行strong增強(UDA/ReMixMatch/FixMatch)或對抗擾動(VAT).</p></li></ul><p>我們將其歸納如下：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8H4HFqrW9c4><p>下圖給出了上述SSL方法在不同數據集上的性能對比（指標為錯誤率）：</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/S2C8H4s4jU9ysd><p>我們可以發現借鑑了UDA和ReMixMatch的FixMatch，是目前的SOTA。上述大多數SSL方法都引入了<strong>一致性正則</strong>，其關鍵在於如何注入噪聲，一個好的模型對於輸入擾動的任何細微變化也都應具有魯棒性。也許我們可以形成一個共識：<strong>通過strong增強的預測標籤與weak增強的人工標籤共同構建一致性損失，能夠提高一致性訓練性能，充分挖掘未標註數據中潛在的價值，最終增強泛化性能</strong>。</p><p>上述結合圖像數據增強的半監督學習方法在CV領域已經取得成功，基本滿足本文一開始提出的三個層次評價策略，特別是：在少樣本場景下可以比肩充分樣本下的監督學習模型性能，而在充分樣本場景下，性能仍然繼續提升。相關實驗可以進一步閱讀CV相關論文，接下來我們主要關注其在NLP的表現。</p><p><strong>4</strong></p><p><strong>UDA：文本增強+半監督學習</strong></p><p>作為NLPer，我們更關心上述文本增強與半監督學習的結合在文本領域表現如何？我們主要介紹分析Google的UDA<sup></sup>相關結果。</p><p>本文在第1部分重點介紹了文本增強技術，文本增強方法通常針對標註數據（有監督數據增強），我們可以看到其在少樣本場景通常會取得穩定的性能提升，但相較於充分樣本下的監督學習性能，也許是有限的提升("cherry on the cake")。</p><p>為克服這一限制，UDA通過一致性訓練框架（正如2.2節介紹的那樣），將有監督的數據增強技術的發展擴展到了有大量未標記數據的半監督學習，儘可能的去利用大量未標記數據，這也正是論文名字——無監督數據增強（Unsupervised Data Augmentation）的由來。</p><p>UDA在六個文本分類任務上結合當前如日中天的BERT遷移學習框架進行了實驗。遷移學習框架分別為：(1)Random：隨機初始化的Transformer；(2):BERT_base；(3):BERT_large；(4):BERT_finetune:基於BERT_large在domain數據集上繼續進行預訓練；</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/S2C8H5EAUZjT5u><p>如上圖所示（指標為錯誤率），Pre-BERT SOTA為BERT出現之前的相關SOTA模型。我們可以發現：</p><p>1）在少樣本場景下，UDA相較於同等監督學習模型，性能明顯提升；</p><p>2）在少樣本場景下，UDA能夠逼近充分樣本下的監督學習模型性能，特別地，在IMDb上具有20個標註數據的UDA優於在1250倍標註數據上訓練的SOTA模型。相較於2分類任務，5分類任務難度更高，未來仍有提升空間。</p><p>3）UDA兼容了遷移學習框架，進一步domain預訓練後，性能更佳。</p><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8H5mE1TmG1I><p>那麼，在充分樣本場景下，繼續使用UDA框架表現如何？從上圖可以看出，在更多、更充分的標註數據數量下，融合UDA框架，性能也有一定提升。</p><p><strong>5</strong></p><p><strong>總結與展望</strong></p><p>本文針對「如何解決少樣本困境？」，從「文本增強」和「半監督學習」兩個角度進行了介紹，簡單總結如下：</p><ol><li><p>文本增強提供了原有標註數據缺少的歸納偏差，在少樣本場景下通常會取得穩定、但有限的性能提升；更高級、更多樣化和更自然的增強方法效果更佳。</p></li><li><p>融合文本增強+半監督學習技術是一個不錯的選擇。半監督學習中<strong>一致性正則</strong>能夠充分利用大量未標註數據，同時能夠使輸入空間的變化更加平滑，從另一個角度來看，<strong>降低一致性損失實質上也是將標籤信息從標註數據傳播到未標註數據的過程</strong>。</p></li></ol><img alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/S2C8H678kzJZAn><p>在具體實踐中，如何有效地解決少樣本問題需要更為全面的考慮，我們可以融合文本增強、半監督學習、遷移學習、主動學習、少樣本學習等構建統一的低資源NLP解決方案；如上圖所示，筆者嘗試給出了信息抽取領域的少樣本低資源解決方案；此外，很多弱監督學習方法也被提出，這一類方法更為關鍵的是如何挑選樣本、如何降噪學習等，希望後續有機會與大家交流～</p><p><strong>參考文獻</strong></p><p class=pgc-end-literature><em>[1] A Visual Survey of Data Augmentation in NLP</em></p><p class=pgc-end-literature><em>[2] EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</em></p><p class=pgc-end-literature><em>[3] TinyBERT: Distilling BERT for Natural Language Understanding</em></p><p class=pgc-end-literature><em>[4] Unsupervised Data Augmentation for Consistency Training</em></p><p class=pgc-end-literature><em>[5] mixup: BEYOND EMPIRICAL RISK MINIMIZATION</em></p><p class=pgc-end-literature><em>[6] Augmenting Data with Mixup for Sentence Classification: An Empirical Study</em></p><p class=pgc-end-literature><em>[7] Data Augmentation and Robust Embeddings for Sentiment Analysis</em></p><p class=pgc-end-literature><em>[8] QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension</em></p><p class=pgc-end-literature><em>[9] Data Augmentation Using GANs</em></p><p class=pgc-end-literature><em>[10] [一文搞懂NLP中的對抗訓練]，https://zhuanlan.zhihu.com/p/103593948</em></p><p class=pgc-end-literature><em>[11] Controlled Text Generation for Data Augmentation in Intelligent Artificial Agents</em></p><p class=pgc-end-literature><em>[12] Contextual augmentation: Data augmentation by words with paradigmatic relations</em></p><p class=pgc-end-literature><em>[13] Conditional BERT contextual augmentation</em></p><p class=pgc-end-literature><em>[14] Do Not Have Enough Data? Deep Learning to the Rescue!</em></p><p class=pgc-end-literature><em>[15] Data Augmentation using Pre-trained Transformer Models</em></p><p class=pgc-end-literature><em>[16] Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks</em></p><p class=pgc-end-literature><em>[17] Temporal ensembling for semi-supervised learning</em></p><p class=pgc-end-literature><em>[18] Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</em></p><p class=pgc-end-literature><em>[19] Virtual Adversarial Training: a Regularization Method for Supervised and Semi-supervised Learning</em></p><p class=pgc-end-literature><em>[20] MixMatch: A Holistic Approach to Semi-Supervised Learning</em></p><p class=pgc-end-literature><em>[21] ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring</em></p><p class=pgc-end-literature><em>[22] FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</em></p><p class=pgc-end-literature><em>[23] RandAugment: Practical automated data augmentation with a reduced search space</em></p><p><strong>招 聘</strong></p><p>AI 科技評論希望能夠招聘 <strong class=highlight-text toutiao-origin=span>科技編輯/記者</strong>一名</p><p><em>辦公地點：北京</em></p><p><em>職務：以跟蹤學術熱點、人物專訪為主</em></p><p><em>工作內容：</em></p><p><em>1、</em><em>關注學術領域熱點事件，並及時跟蹤報道；</em></p><p><em>2、採訪人工智能領域學者或研發人員；</em></p><p>3、<em>參加各種人工智能學術會議，並做會議內容報道。</em></p><p><em>要求：</em></p><p>1、<strong class=highlight-text toutiao-origin=span>熱愛人工智能學術研究內容</strong>，擅長與學者或企業工程人員打交道；</p><p><em>2、有一定的理工科背景，對人工智能技術有所瞭解者更佳；</em></p><p><em>3、英語能力強（工作內容涉及大量英文資料）；</em></p><p><em>4、學習能力強，對人工智能前沿技術有一定的瞭解，並能夠逐漸形成自己的觀點。</em></p><p><em>感興趣者，可將簡歷發送到郵箱：jiangbaoshang@yanxishe.com</em></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>增強</a></li><li><a>半監督</a></li><li><a>學習</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html alt=直流鍋爐給水控制學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/eba10edcc8d14d9f8cde6fd5b212d90e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac12f3a1.html title=直流鍋爐給水控制學習>直流鍋爐給水控制學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html alt=HTMLCSS學習筆記（六）——元素類型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/bdb5988349894ce9bf568c6418f85b7d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a1bc38f3.html title=HTMLCSS學習筆記（六）——元素類型>HTMLCSS學習筆記（六）——元素類型</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html alt="web前端（從零開始），每天更新學習筆記 HTML5元素分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/46d70004fcd55e1ddad3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/97886d06.html title="web前端（從零開始），每天更新學習筆記 HTML5元素分類">web前端（從零開始），每天更新學習筆記 HTML5元素分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html alt="MySQL 學習筆記" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c9091681.html title="MySQL 學習筆記">MySQL 學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html alt=深入學習MySQL事務：ACID特性的實現原理「轉」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/cdc702d66d6943499997d11e931425eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/175f9730.html title=深入學習MySQL事務：ACID特性的實現原理「轉」>深入學習MySQL事務：ACID特性的實現原理「轉」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html alt=如何學習模擬IC設計？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6b2ef73.html title=如何學習模擬IC設計？>如何學習模擬IC設計？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html alt=小猿圈python學習-三大特性之多態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad0e8e3777854337abeb7c779ad79a04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c56ee116.html title=小猿圈python學習-三大特性之多態>小猿圈python學習-三大特性之多態</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html alt=地理學習5——地球的運動（地球的公轉及其地理意義） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7b2b74c871eb40beb8ee143627d29611 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03a295fc.html title=地理學習5——地球的運動（地球的公轉及其地理意義）>地理學習5——地球的運動（地球的公轉及其地理意義）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html alt=繼續學習打卡，還真心學不會了，努力，堅持 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f36d6d47a06840aaaf78138853b9d9d1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ebad378f.html title=繼續學習打卡，還真心學不會了，努力，堅持>繼續學習打卡，還真心學不會了，努力，堅持</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html alt=一造學習筆記—管理篇（2）：工程造價管理的組織和內容 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/9e65b076-038f-4720-96ff-182898f42dee style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/112d1b5f.html title=一造學習筆記—管理篇（2）：工程造價管理的組織和內容>一造學習筆記—管理篇（2）：工程造價管理的組織和內容</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>