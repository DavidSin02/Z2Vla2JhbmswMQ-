<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>圖像配準：從SIFT到深度學習 | 极客快訊</title><meta property="og:title" content="圖像配準：從SIFT到深度學習 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/442c425619b84460b306bf5f15583d2c"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6ba9fca.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6ba9fca.html><meta property="article:published_time" content="2020-10-29T20:50:55+08:00"><meta property="article:modified_time" content="2020-10-29T20:50:55+08:00"><meta name=Keywords content><meta name=description content="圖像配準：從SIFT到深度學習"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/6ba9fca.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>圖像配準：從SIFT到深度學習</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/442c425619b84460b306bf5f15583d2c><p class=pgc-img-caption></p></div><p><strong>目錄</strong></p><ul><li>圖像配準：從SIFT到深度學習</li><li>什麼是圖像配準</li><li>傳統的基於特徵的方法</li><li class=ql-indent-1>關鍵點檢測和特徵描述</li><li class=ql-indent-1>特徵匹配</li><li class=ql-indent-1>圖像變換</li><li>深度學習方法</li><li class=ql-indent-1>特徵提取</li><li class=ql-indent-1>Homography學習</li><li class=ql-indent-1>監督學習</li><li class=ql-indent-1>無監督學習</li><li>其他方法</li><li class=ql-indent-1>強化學習</li><li class=ql-indent-1>複雜的轉換</li></ul><p>圖像配準（Image Registration）是計算機視覺中的基本步驟。在本文中，我們首先介紹基於OpenCV的方法，然後介紹深度學習的方法。</p><p><strong>什麼是圖像配準</strong></p><p>圖像配準就是找到一幅圖像像素到另一幅圖像像素間的空間映射關係。這些圖像可以是不同時間（多時間配準），不同傳感器在不同地方拍攝（多模式配準）。這些圖像之間的空間關係可以是剛性（rigid）<sup>[1]</sup>（平移和旋轉），仿射（affine）<sup>[2]</sup>（例如剪切），單應性<sup>[3]</sup>（homographies）或複雜的大變形模型（complex large deformations models）。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d66112accd604ecf91351cb436914565><p class=pgc-img-caption></p></div><p>圖像配準具有廣泛的應用，適用於同一個場景中有多張圖像需要進行匹配或疊加。在醫學圖像領域以及衛星圖像分析和光流（optical flow）方面非常普遍。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/6f001d95b76e48a78c9731a1580bbccb><p class=pgc-img-caption>CT掃描和MRI配準</p></div><p>本文我們將介紹圖像配準的幾種不同方法。</p><h1><strong>傳統的基於特徵的方法</strong></h1><p>自21世紀初以來，圖像配準主要使用基於特徵的方法。這些方法有三個步驟：關鍵點檢測和特徵描述，特徵匹配，圖像變換。簡單的說，我們選擇兩個圖像中的感興趣點，將參考圖像（reference image）與感測圖像（sensed image）中的等價感興趣點進行關聯，然後變換感測圖像使兩個圖像對齊。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4d9f688f0eef47f5bd913ada2dc96037><p class=pgc-img-caption>基於特徵的方法</p></div><p><strong>關鍵點檢測和特徵描述</strong></p><p>關鍵點就是感興趣點，它表示圖像中重要或獨特的內容（邊角，邊緣等）。每個關鍵點由描述符表示，關鍵點基本特徵的特徵向量。描述符應該對圖像變換（定位，縮放，亮度等）具有魯棒性。許多算法使用關鍵點檢測和特徵描述：</p><ul><li><strong>SIFT</strong><sup>[4]</sup>（Scale-invariant feature transform）是用於關鍵點檢測的原始算法，但它不能免費用於商業用途。SIFT特徵描述符對於均勻縮放，方向，亮度變化和對仿射失真不變的部分不會發生變化。</li><li><strong>SURF</strong><sup>[5]</sup>（Speeded Up Robust Features）是一個受SIFT啟發的探測器和描述符。它的優點是非常快。它同樣是有專利的。</li><li><strong>ORB</strong><sup>[6]</sup>（Oriented FAST and Rotated BRIEF）是一種快速的二進制描述符，它基於 FAST<sup>[7]</sup>（Features from Accelerated Segment Test）關鍵點檢測和 BRIEF<sup>[8]</sup>（Binary robust independent elementary features）描述符的組合。它具有旋轉不變性和對噪聲的魯棒性。它由OpenCV實驗室開發，是SIFT有效的免費替代品。</li><li><strong>AKAZE</strong><sup>[9]</sup>（Accelerated-KAZE）是KAZE<sup>[10]</sup>快速版本。它為非線性尺度空間<sup>[11]</sup>提供了快速的多尺度特徵檢測和描述方法，具有縮放和旋轉不變性。</li></ul><p>這些算法都可以在OpenCV中輕鬆使用。在下面的例子中，我們使用了AKAZE的OpenCV實現。其他算法的代碼大致相同，只需要修改算法的名稱。</p><pre>import numpy as npimport cv2 as cvimg = cv.imread('image.jpg')gray= cv.cvtColor(img, cv.COLOR_BGR2GRAY)akaze = cv.AKAZE_create()kp, descriptor = akaze.detectAndCompute(gray, None)img=cv.drawKeypoints(gray, kp, img)cv.imwrite('keypoints.jpg', img)</pre><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/67fc69e583064d6cb096a83b62efed94><p class=pgc-img-caption>圖像關鍵點</p></div><p>更過關於特徵提取和描述的文檔(https://docs.opencv.org/3.4/d7/d66/tutorial_feature_detection.html)</p><p><strong>特徵匹配</strong></p><p>一旦在一對圖像中識別出關鍵點，我們就需要將兩個圖像中對應的關鍵點進行關聯或“匹配”。其中一種方法是BFMatcher.knnMatch()。這個方法計算每對關鍵點之間的描述符的距離，並返回每個關鍵點的k個最佳匹配中的最小距離。</p><p>然後我們設定比率來保持正確率。實際上，為了使匹配更可靠，匹配的關鍵點需要比最近的錯誤匹配更靠近。</p><pre>import numpy as npimport cv2 as cvimport matplotlib.pyplot as pltimg1 = cv.imread('image1.jpg', cv.IMREAD_GRAYSCALE)img2 = cv.imread('image2.jpg', cv.IMREAD_GRAYSCALE)# 初始化 AKAZE 探測器akaze = cv.AKAZE_create()# 使用 SIFT 查找關鍵點和描述kp1, des1 = akaze.detectAndCompute(img1, None)kp2, des2 = akaze.detectAndCompute(img2, None)# BFMatcher 默認參數bf = cv.BFMatcher()matches = bf.knnMatch(des1, des2, k=2)# 旋轉測試good_matches = []for m,n in matches: if m.distance &lt; 0.75*n.distance: good_matches.append([m]) # 畫匹配點img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good_matches,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)cv.imwrite('matches.jpg', img3)</pre><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a2b91950a349474e897a6525208366d8><p class=pgc-img-caption>匹配的關鍵點</p></div><p>OpenCV中有更多關於特徵匹配的實現方法(https://docs.opencv.org/trunk/dc/dc3/tutorial_py_matcher.html)</p><p><strong>圖像變換</strong></p><p>在匹配至少四對關鍵點之後，我們就可以將一個圖像轉換為另一個圖像，稱為圖像變換<sup>[12]</sup>（image warping）。空間中相同平面的兩個圖像通過單應性變換<sup>[13]</sup>（Homographies）進行關聯。Homographies是具有8個自由參數的幾何變換，由3x3矩陣表示圖像的整體變換（與局部變換相反）。因此，為了獲得變換後的感測圖像，需要計算Homographies矩陣。</p><p>為了得到最佳的變換，我們需要使用RANSAC算法檢測異常值並去除。它內置在OpenCV的findHomography方法中。同時也存在RANSAC算法的替代方案，例如LMEDS： Least-Median魯棒方法。</p><pre># 選擇匹配關鍵點ref_matched_kpts = np.float32([kp1[m[0].queryIdx].pt for m in good_matches]).reshape(-1,1,2)sensed_matched_kpts = np.float32([kp2[m[0].trainIdx].pt for m in good_matches]).reshape(-1,1,2)# 計算 homographyH, status = cv.findHomography(ref_matched_kpts, sensed_matched_kpts, cv.RANSAC,5.0)# 變換warped_image = cv.warpPerspective(img1, H, (img1.shape[1]+img2.shape[1], img1.shape[0])) cv.imwrite('warped.jpg', warped_image)</pre><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9171921d6ec442599770b3973b28aa52><p class=pgc-img-caption>變換後的圖像</p></div><p>OpenCV中對這三個步驟進行了綜合敘述(https://docs.opencv.org/3.1.0/db/d27/tutorial_py_table_of_contents_feature2d.html)</p><h1><strong>深度學習方法</strong></h1><p>目前大多數關於圖像配準的研究涉及深度學習。在過去的幾年中，深度學習使計算機視覺任務具有先進的性能，如圖像分類，物體檢測和分割。</p><p><strong>特徵提取</strong></p><p>深度學習用於圖像配準的第一種方式是用於特徵提取。卷積神經網絡設法獲得越來越複雜的圖像特徵並進行學習。2014年以來，研究人員將這些網絡應用於特徵提取的步驟，而不是使用SIFT或類似算法。</p><ul><li>2014年，Dosovitskiy等人提出了一種通用的特徵提取方法，使用未標記的數據訓練卷積神經網絡。這些特徵的通用性使轉換具有魯棒性。這些特徵或描述符的性能優於SIFT描述符以匹配任務。</li><li>2018年，Yang等人開發了一種基於相同思想的非剛性配準方法。他們使用預訓練的VGG網絡層來生成一個特徵描述符，同時保留卷積信息和局部特徵。這些描述符的性能也優於類似SIFT的探測器，特別是在SIFT包含許多異常值或無法匹配足夠數量特徵點的情況下。</li></ul><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2b24856e210f43c98e5791488a318dc9><p class=pgc-img-caption>SIFT和基於深度學習的非剛性配準方法描述符的結果</p></div><p><strong>Homography學習</strong></p><p>研究人員利用神經網絡直接學習幾何變換對齊兩幅圖像，而不僅僅侷限於特徵提取。</p><p><strong>監督學習</strong></p><p>在2016年，DeTone等人發表了 Deep Image Homography Estimation，提出了HomographyNe迴歸網絡，這是一種VGG風格模型，可以學習兩幅相關圖像的單應性。該算法具有以端到端的方式同時學習單應性和CNN模型參數的優勢，不需要前兩個階段的過程！</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b99d0b6e5cfa42ab812922f259e06b55><p class=pgc-img-caption>HomographyNet迴歸網絡</p></div><p>網絡產生八個數值作為輸出。以監督的方式進行訓練，並計算輸出和真實單應性之間的歐幾里德損失。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b3bec6069a0b4d8396e296b9dd57ed6d><p class=pgc-img-caption>Supervised Deep Homography Estimation</p></div><p>與其他有監督方法一樣，該單應性估計方法需要有標記數據。雖然很容易獲得真實圖像的單應性，但在實際數據上要昂貴得多。</p><p><strong>無監督學習</strong></p><p>基於這個想法，Nguyen等人提出了一種無監督的深度圖像單應性估計方法。他們保留了相同結構的CNN，但是使用適合無監督方法的損失函數：不需要人工標籤的光度損失（photometric loss）函數。相反，它計算參考圖像和感測變換圖像之間的相似性。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dd1e5f5a8229449d888a497659c57c94><p class=pgc-img-caption>L1光度損失函數</p></div><p>他們的方法引入了兩種新的網絡結構：張量直接線性變換和空間變換層。我們可以簡單地使用CNN模型輸出的單應性參數獲得變換後的感測圖像，然後我們使用它們來計算光度損失。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/742dc0a29aef4b7fb1cc726fc869e6f9><p class=pgc-img-caption>Unsupervised Deep Homography Estimation</p></div><p>作者聲稱，與傳統的基於特徵的方法相比，這種無監督方法具有相當或更高的準確率和魯棒性，並且具有更快的執行速度。此外，與有監督方法相比，它具有更好的適應性和性能。</p><h1><strong>其他方法</strong></h1><p><strong>強化學習</strong></p><p>強化學習方法作為醫學應用的常用方法正在得到越來越多的關注。與預定義的優化算法相反，在這種方法中，我們使用訓練好的代理進行配準。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0f6a2043e7934ec4bac299d1992c711d><p class=pgc-img-caption>強化學習方法的配準可視化</p></div><ul><li>2016年，Liao 等人首先使用強化學習進行圖像配準。他們的方法基於有監督算法進行端到端的訓練。它的目標是通過尋找最佳的運動動作序列來對齊圖像。這種方法優於最先進的方法，但它只能用於剛性轉換。</li><li>強化學習也可以用於更復雜的轉換。在Robust non-rigid registration through agent-based action learning論文中，Krebs等人使用人工代理優化變形模型參數。該方法對前列腺MRI圖像的患者間的配準進行實驗，在2-D和3-D中表現出了較好的結果。</li></ul><p><strong>複雜的轉換</strong></p><p>在當前圖像配準研究中佔較大比例的是醫學影像。通常，由於患者的局部變形（因呼吸，解剖學變化等），兩個醫學圖像之間的變換不能簡單地通過單應矩陣描述，這需要更復雜的變換模型，例如由位移矢量場表示微分同胚（diffeomorphisms）。</p><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e205c23733a64be096d63f838ffcf259><p class=pgc-img-caption>心臟MRI圖像上的變形網格和位移矢量場示例</p></div><p>研究人員開始嘗試使用神經網絡來估計這些具有許多參數的大變形模型。</p><ul><li>一個例子是上面提到的Krebs等人的強化學習方法。</li><li>2017年De Vos等人提出了DIRNet。它使用CNN來預測控制點網格，該控制點用於生成位移矢量場，然後根據參考圖像變換感測圖像。</li></ul><div class=pgc-img><img alt=圖像配準：從SIFT到深度學習 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dcedded824a14beaa39cb9c01d5c0447><p class=pgc-img-caption>來自MNIST兩個輸入圖像的DIRNet示意圖</p></div><ul><li>Quicksilver配準解決了類似的問題。Quicksilver使用深度編碼-解碼器網絡直接在預測圖像上進行變形。</li></ul><p><sup>[1]</sup>: https://en.wikipedia.org/wiki/Rigid_transformation</p><p><sup>[2]</sup>: https://en.wikipedia.org/wiki/Affine_transformation</p><p><sup>[3]</sup>: https://docs.opencv.org/3.4.1/d9/dab/tutorial_homography.html</p><p><sup>[4]</sup>: https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf</p><p><sup>[5]</sup>: https://www.vision.ee.ethz.ch/~surf/eccv06.pdf</p><p><sup>[6]</sup>: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.370.4395&rep=rep1&type=pdf</p><p><sup>[7]</sup>: https://www.edwardrosten.com/work/rosten_2006_machine.pdf</p><p><sup>[8]</sup>: https://www.cs.ubc.ca/~lowe/525/papers/calonder_eccv10.pdf</p><p><sup>[9]</sup>: http://www.bmva.org/bmvc/2013/Papers/paper0013/paper0013.pdf</p><p><sup>[10]</sup>: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.304.4980&rep=rep1&type=pdf</p><p><sup>[11]</sup>: https://en.wikipedia.org/wiki/Scale_space</p><p><sup>[12]</sup>: https://docs.opencv.org/3.0-beta/modules/cudawarping/doc/warping.html</p><p><sup>[13]</sup>: https://docs.opencv.org/3.4.1/d9/dab/tutorial_homography.html</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>圖像</a></li><li><a>配準</a></li><li><a>SIFT</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/1ef1595.html alt=圖像配準SIFT class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a76d41267463482bade6f89246503944 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1ef1595.html title=圖像配準SIFT>圖像配準SIFT</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/403377d.html alt=MATLAB圖像配準各方法介紹和對比 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a544d694126c47618bb1ca91efc79195 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/403377d.html title=MATLAB圖像配準各方法介紹和對比>MATLAB圖像配準各方法介紹和對比</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a97f673.html alt=全面梳理：圖像配準綜述 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fd6f1d9ada674606946642c4cb01ce8b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a97f673.html title=全面梳理：圖像配準綜述>全面梳理：圖像配準綜述</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/612f314.html alt=圖像配準傳統算法總結 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/590f704b5a5640ef8229e9b2350fbf9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/612f314.html title=圖像配準傳統算法總結>圖像配準傳統算法總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e4eb034.html alt=圖像配準數據集合集-整理方案（1024初稿） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/962ba0f782ff4988b06968d6aff4e4dc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e4eb034.html title=圖像配準數據集合集-整理方案（1024初稿）>圖像配準數據集合集-整理方案（1024初稿）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03a3c47.html alt=圖像配準的前世今生：從人工設計特徵到深度學習 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/aa2bad10159143038cdd088ab470c611 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03a3c47.html title=圖像配準的前世今生：從人工設計特徵到深度學習>圖像配準的前世今生：從人工設計特徵到深度學習</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2c3db761.html alt=計算機中數字、文字、圖像、聲音和視頻的表示與編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8d1d3ec88f2c4a158c7efe55b21d6ed7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2c3db761.html title=計算機中數字、文字、圖像、聲音和視頻的表示與編碼>計算機中數字、文字、圖像、聲音和視頻的表示與編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1b218e68.html alt=圖像拼接算法及實現（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1534489824878547eee8fc2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1b218e68.html title=圖像拼接算法及實現（一）>圖像拼接算法及實現（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0015c711.html alt=圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9be3a601501341f2832a19df18b23c5b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0015c711.html title=圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程>圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d8506a86.html alt=圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ee71b902dab44669882d9525f718a9f6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d8506a86.html title=圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了>圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2b5d07df.html alt=圖像格式：JPEG、RAW、TIFF具體什麼意思，有什麼區別？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/37f000032b738c5c6c6c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2b5d07df.html title=圖像格式：JPEG、RAW、TIFF具體什麼意思，有什麼區別？>圖像格式：JPEG、RAW、TIFF具體什麼意思，有什麼區別？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/682e2d04.html alt=技術實踐——Python圖像處理進階：多種圖像變換算法實踐！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/153594655429837077dd27a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/682e2d04.html title=技術實踐——Python圖像處理進階：多種圖像變換算法實踐！>技術實踐——Python圖像處理進階：多種圖像變換算法實踐！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfd264c3.html alt=切換圖像矩陣對比，RGB與AV、VGA矩陣各有千秋 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfd264c3.html title=切換圖像矩陣對比，RGB與AV、VGA矩陣各有千秋>切換圖像矩陣對比，RGB與AV、VGA矩陣各有千秋</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ba1bdb89.html alt=圖像分類最全資料/源碼總結 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/884568c009d948d7bcded4cee5155854 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ba1bdb89.html title=圖像分類最全資料/源碼總結>圖像分類最全資料/源碼總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a4b3ee88.html alt=圖像紋理特徵總體簡述 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9596808921d4232b329946d2727af58 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a4b3ee88.html title=圖像紋理特徵總體簡述>圖像紋理特徵總體簡述</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>