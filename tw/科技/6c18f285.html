<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 | 极客快訊</title><meta property="og:title" content="Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/SBiiPB6Hdc99gN"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/6c18f285.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/6c18f285.html><meta property="article:published_time" content="2020-11-14T21:02:25+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:25+08:00"><meta name=Keywords content><meta name=description content="Hinton新作！越大的自監督模型，半監督學習需要的標籤越少"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/6c18f285.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Hinton新作！越大的自監督模型，半監督學習需要的標籤越少</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/SBiiPB6Hdc99gN><p class=pgc-img-caption>編譯 | 青暮</p><p>本文介紹了Hinton團隊發表在NeurIPS 2020上的一項研究工作，一作是Ting Chen，研究人員首次在ImageNet上嘗試了半監督學習的典型範式，並取得了優越的結果。此外，他們還發現，網絡的規模越大，需要的標籤數據越少。</p><p>論文地址：https://arxiv.org/abs/2006.10029</p><p>僅使用1％的標籤（每類≤13個標籤圖像），本文提出的方法即可達到73.9％ImageNet top-1準確率，與以前的SOTA相比，標籤效率提高了10倍。</p><p>使用10％的標籤，本文的方法可以達到77.5％的top-1準確率，優於使用100%標籤的標準監督訓練。</p><p><strong>“無監督預訓練、監督微調”範式</strong></p><p>充分利用少量標記示例和大量未標記示例進行學習是機器學習的一個長期存在的問題。</p><p>人們曾經提出一種半監督學習來試圖解決這個問題，其中涉及無監督或自監督的預訓練，然後進行有監督的微調。</p><p>這種方法在預訓練期間以與任務無關的方式利用未標記的數據，僅在有監督微調時使用帶標籤的數據。</p><p>這種方法在計算機視覺上很少受關注，但是在自然語言處理中已成為主流。例如，人們首先在未標記的文本（例如Wikipedia）上訓練大型語言模型，然後在一些帶標記的示例中對該模型進行微調。</p><p>基於視覺表示的自監督學習的最新進展，Ting Chen等人對ImageNet上的半監督學習進行了深入研究，並首次探索了“無監督預訓練、監督微調”範式。</p><p>通過與任務無關的方式使用未標記數據，作者發現，網絡規模非常重要。</p><p>也就是說，使用大型（在深度和廣度上）神經網絡進行自監督的預訓練和微調，可以大大提高準確率。</p><p>除了網絡規模之外，作者表示，這項研究還為對比表示學習提供了一些重要的設計選擇，這些選擇有益於監督微調和半監督學習。</p><p>一旦卷積網絡完成了預訓練和微調，其在特定任務上的預測就可以得到進一步改善，並可以提煉成更小的網絡。</p><p>為此，作者接下來再次使用了未標記的數據，以讓學生網絡模仿教師網絡的標籤預測。</p><p>這種使用未標記數據的蒸餾階段類似於自訓練中偽標籤的使用，但沒有增加太多額外的複雜性。</p><p>作者提出的半監督學習框架包括三個步驟，如圖3所示。</p><p>（1）無監督或自我監督的預訓練；</p><p>（2）有監督的微調；</p><p>（3）使用未標記的數據進行蒸餾。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/SEp62Em9zDcJ4I><p class=pgc-img-caption>圖3：本文提出的半監督學習框架。該框架通過兩種方式利用未標記的數據：（1）在無監督的預訓練中與任務無關的用法，（2）在自訓練/蒸餾中的任務特定的用法。</p><p>此外，作者還開發了對比學習框架SimCLR的改進版本，用於ResNet架構的無監督預訓練，此框架被稱為SimCLRv2。</p><p>在ImageNet ILSVRC-2012上評估該方法的有效性，作者發現，僅需要1％和10％的標籤，就可以實現與過去SOTA方法相當的性能。</p><p>作者表示，對於這種範式的半監督學習，標記越少，就越有可能受益於更大的模型，如圖1所示。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/SEp62FQ62k5A4t><p class=pgc-img-caption>圖1：使用較少標記的示例進行微調時，較大的模型會產生較大的收益。</p><p>較大的自監督模型具有更高的標籤效率，即使僅對少數幾個帶有示例的示例進行微調，它們的性能也明顯更好。</p><p>因此，通過未標記數據的特定任務使用，可以進一步提高模型的預測性能，並將其遷移到較小的網絡中。</p><p>作者進一步證明了，在SimCLR中用於半監督學習的卷積層之後，進行非線性變換（又稱投影頭）很重要。</p><p>更深的投影頭不僅可以改善通過線性評估測得的表示質量，而且還可以改善從投影頭中間層進行微調時的半監督性能。</p><p>結合這些發現，該框架在ImageNet上實現了半監督學習的SOTA，如圖2所示。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/SEp62Fn89S0Ld9><p class=pgc-img-caption>圖2：僅使用1％/10％的標籤，在ImageNet上，以前的SOTA方法和本文方法（SimCLRv2）的top-1準確率。虛線表示完全監督下的ResNet-50進行100％標籤訓練。完整比較見表3。</p><p>在線性評估協議下，SimCLRv2實現了79.8％的top-1準確率，相對於之前的SOTA的改進為4.3％。</p><p>如果僅對1％/ 10％的標記示例進行微調，並使用未標記的示例將其蒸餾至相同的架構，則可以達到76.6％/ 80.9％的top-1準確率，相對於以前的SOTA，準確率提高了21.6％/ 8.7％。</p><p>通過蒸餾，這些改進也可以遷移到較小的ResNet-50網絡中，使用1％/ 10％的標籤達到73.9％/ 77.5％的top-1準確率。</p><p>相比之下，對所有標籤圖像進行訓練的標準監督ResNet-50可以達到76.6％的top-1準確率。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/SEp62IOGamem3I><p>表3：在半監督設置下訓練的模型的ImageNet準確率。對於本文的方法，上表展示了在微調後進行蒸餾的結果。對於較小的模型，使用自蒸餾的ResNet-152（3×+ SK）作為教師網絡。</p><p><strong>關於一作</strong></p><p>Ting Chen於2019年加入谷歌大腦，擔任研究科學家。他在2019年3月獲得了加州大學洛杉磯分校計算機科學系的博士學位，導師是UCLA計算機科學系的副教授孫怡舟。他也是論文SimCLR的一作。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/SEp62v05mVVaKO><p><strong class=highlight-text toutiao-origin=span>贈書福利</strong></p><p>AI科技評論聯合【機械工業出版社華章公司】為大家帶來15本“新版蜥蜴書”正版新書。</p><p>在10月24號頭條文章《1024快樂！最受歡迎的AI好書《蜥蜴書第2版》送給大家！》留言區留言，談一談你對本書內容相關的看法和期待，或你對機器學習/深度學習的理解。</p><p>AI 科技評論將會在留言區選出 15名讀者，每人送出《機器學習實戰：基於Scikit-Learn、Keras和TensorFlow（原書第2版）》一本（在其他公號已獲贈本書者重複參加無效）。</p><p><strong>活動規則：</strong></p><p>1. 在留言區留言，留言點贊最高的前 15 位讀者將獲得贈書。獲得贈書的讀者請聯繫 AI 科技評論客服（aitechreview）。</p><p>2. 留言內容會有篩選，例如“選我上去”等內容將不會被篩選，亦不會中獎。</p><p>3. 本活動時間為2020年10月24日 - 2020年10月31日（23:00），活動推送內僅允許中獎一次。</p><img alt=Hinton新作！越大的自監督模型，半監督學習需要的標籤越少 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/SBKO8Ps5tu50xF></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Hinton</a></li><li><a>自監督</a></li><li><a>半監督</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/5d39767f.html alt="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/S2C8F2A8wkrbVw style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5d39767f.html title="文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？">文本增強、半監督學習，誰才是 NLP 少樣本困境問題更優的解決方案？</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>