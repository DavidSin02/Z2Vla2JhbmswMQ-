<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） | 极客快訊</title><meta property="og:title" content="TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/153490532779764442c6667"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70822daf.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70822daf.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70822daf.html><meta property="article:published_time" content="2020-11-14T21:03:08+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:08+08:00"><meta name=Keywords content><meta name=description content="TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/70822daf.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測）</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><ul><li>本節簡介</li><li>TensorFlow更新</li><li>注意</li><li>下載最新源碼編譯源碼更新</li><li>首先卸載當前的tensorflow</li><li>參考官方的從源碼安裝tensorflow</li><li>直接使用pip工具更新</li><li>更新後可能會遇到的異常</li><li>自定義LSTM循環神經網絡進行時間序列預測</li><li>工程實現</li><li>需要用到的模塊</li><li>生成訓練數據與測試數據</li><li>註解</li><li>定義網絡模型</li><li>創建模型並訓練</li><li>Estimator工具</li><li>繪圖</li><li>利用TFTS進行時間序列預測</li><li>載入數據部分</li><li>從CSV文件中讀入時間序列數據</li><li>使用AR模型預測時間序列</li><li>代碼實現</li><li>產生數據</li><li>創建ar模型</li><li>訓練評估模型並預測</li><li>使用LSTM預測單變量時間序列</li><li>產生訓練數據</li><li>定義訓練模型並預測</li><li>繪製預測數據圖</li><li>使用LSTM預測多變量時間序列</li><li>獲取訓練數據</li><li>定義訓練模型並預測</li><li>繪製預測圖</li><li>總結</li></ul><h1><strong>本節簡介</strong></h1><p>本節關於TFTS模塊的使用參考知乎-何之源-如何優雅地用TensorFlow預測時間序列：TFTS庫詳細教程。</p><p>如何在TensorFlow上使用LSTM來做時間序列預測是一個很老的話題，然而一直沒有比較好的解決方案。在剛剛發佈的TensorFlow1.3版本中，在tf.contrib包下引入了一個Time Series模塊(TensorFlow Time Series,TFTS)。其源碼地址在github timeseries。TFTS提供了一套基礎的時間序列模型API。<strong>目前提供AR、Anomaly Mixture AR、LSTM三種預測模型。</strong></p><p>這裡因為是剛剛發佈的庫，文檔匱乏，我們著重於介紹TFTS的以下幾個功能:</p><ul><li>讀入時間序列數據（分為從numpy數組和csv文件兩種方式）</li><li>用AR模型對時間序列進行預測</li><li>用LSTM模型對時間序列進行預測（包含單變量和多變量）</li></ul><p>先看效果圖，</p><ol><li>使用自定義LSTM循環網絡對單變量進行時間序列預測(沒使用TFTS，代碼比較繁瑣):</li></ol><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153490532779764442c6667><p class=pgc-img-caption></p></div><ol><li><br></li><li>使用TFTS下的AR模型預測效果如下，藍色為訓練數據，綠色為模型擬合數據，紅色為預測數據:</li></ol><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1534905340254238b94744c><p class=pgc-img-caption></p></div><ol><li><br></li><li>使用TFTS下的LSTM對單變量進行時間序列預測:</li></ol><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15349053676857b8384ce87><p class=pgc-img-caption></p></div><ol><li><br></li><li>使用TFTS下的LSTM對多變量進行時間序列預測:</li></ol><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15349053822246c145a2838><p class=pgc-img-caption></p></div><ol><li><br></li></ol><p>這裡涉及到的代碼保存在github-hzy46.網速不好的同學可以到或者在CSDN上下載。</p><hr><hr><h1><strong>TensorFlow更新</strong></h1><p><strong>注意</strong></p><p>後面使用的LSTM模型的例子須使用TensorFlow最新的開發版的源碼。具體來說，要保證下面這句話可以成功執行。</p><p>from tensorflow.contrib.timeseries.python.timeseries.estimators import TimeSeriesRegressor</p><ul><li>1</li><li>2</li></ul><p>如果執行不成功，則需要下面的更新操作。</p><p><strong>下載最新源碼(編譯源碼更新)</strong></p><p><strong>1. 首先卸載當前的tensorflow</strong></p><p>pip uninstall tensorflow #gpu版 就是tensorflow-gpu</p><ul><li>1</li><li>2</li></ul><p><strong>2. 參考官方的從源碼安裝tensorflow</strong></p><p>參考TensorFlow官方安裝教程。我的開發環境是Ubuntu16.04+1080顯卡，需要安裝gpu版本。</p><ul><li>保證顯卡驅動，CUDA8.0,cudnn6.0安裝成功</li><li>安裝bazel bazel安裝教程</li><li>安裝Python依賴包</li><li>sudo apt-get install python-numpy python-dev python-pip python-wheel # 對py2</li><li>sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel #對py3</li><li>1</li><li>2</li><li>從github上下載最新的源碼</li><li>git clone https://github.com/tensorflow/tensorflow</li><li>1</li><li>配置tensorflow安裝</li><li>cd tensorflow # cd to the top-level directory created</li><li>$ ./configure</li><li>'''</li><li>除了CUDA項選擇y，其他都是n或者默認項.</li><li>Configuration finished</li><li>'''</li><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>編譯成pip包</li></ul><p>'''</p><p>編譯</p><p>'''</p><p>bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package</p><p>'''</p><p>挺長的一段編譯時間</p><p>生產pip包</p><p>'''</p><p>bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg</p><p>'''</p><p>安裝</p><p>'''</p><p>sudo pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-py2-none-any.whl</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li></ul><p>如果出啥問題，建議直接看官方教程來整，有啥小問題，上stackoverflow上找找原因。(從源碼編譯tensorflow前前後後花費了我2天的時間，現在整出來了，踩了不少的坑，感覺下次會快很多了～)</p><p>現在9月初tensorflow的pip安裝版本還不支持這個TimeSeriesRegressor類，等到後面版本穩定更新了，應該可以用下面pip工具更新。</p><p><strong>直接使用pip工具更新</strong></p><p>因為本次用到的庫需要運行在TensorFlow1.3版本，而我的環境是Ubuntu下的1.0.1版本的TensorFlow。如果你不知道自己的TensorFlow是啥版本，有一個簡單的方法:</p><p>激活python編程環境，鍵入以下代碼運行即可。</p><p>import tensorflow as tf</p><p>print(tf.__version__) # 查看tensorflow版本</p><p>print(tf.__path__) # 查看tensorflow安裝位置</p><p>'''</p><p>輸出：</p><p>1.0.1</p><p>['/root/anaconda2/lib/python2.7/site-packages/tensorflow']</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li></ul><p>更新方法也很簡單，如果你的TensorFlow是普通的安裝，直接在命令行鍵入以下命令:</p><p>$: sudo pip install --upgrade tensorflow-gpu # 我安裝的是gpu版</p><ul><li>1</li></ul><p>等待更新完成即可。</p><p>import tensorflow as tf</p><p>print(tf.__version__) # 查看tensorflow版本</p><p>print(tf.__path__) # 查看tensorflow安裝位置</p><p>'''</p><p>輸出：</p><p>1.3.0</p><p>['/root/anaconda2/lib/python2.7/site-packages/tensorflow']</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li></ul><p><strong>更新後可能會遇到的異常</strong></p><ul><li>問題描述:</li><li>libcudnn.so.6:cannot open sharedobject file: No such file or directory</li><li>1</li><li>問題分析:</li><li>我在開始安裝1.0.1版本的tensorflow時，配置的是CUDA8.0+cudnn-v5.1。這裡我把tensorflow升級到1.3版本，新的Tensorflow適配的是cudnn-v6.0。故需要升級cudnn。</li><li>解決辦法:</li><li>升級cudnn的方法參考安裝CUDNN。</li></ul><ol><li>下載適配CUDA版本和系統版本的cudnn-v6.0</li></ol><ul><li><br></li></ul><ol><li>解壓下載好的cudnn</li><li>$ : sudo tar -zxvf cudnn-8.0-linux-x64-v6.0.tgz</li><li>…</li><li>將解壓文件拷貝並修改權限</li><li>$ :sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ # copy file</li><li>$ :sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lin64/</li><li>$ :sudo chmod a+r /usr/local/cuda/include/cudnn.h # 修改權限</li><li>$ :sudo chmod a+r /usr/local/cuda/libcudnn*</li></ol><ul><li>1</li><li>2</li><li>3</li><li>4</li></ul><p>到這裡，算是大功告成了～</p><hr><hr><h1><strong>自定義LSTM循環神經網絡進行時間序列預測</strong></h1><p>在使用TFTS庫前，我們先利用自定義循環神經網絡預測正弦函數。初步學習一下如何使用LSTM循環神經網絡進行時間序列預測，這裡我們會使用TensorFlow的一個高級封裝工具-TFLearn(集成在tf.contrib.learn).</p><p><strong>工程實現</strong></p><p><strong>1. 需要用到的模塊</strong></p><p># coding:utf8</p><p>import numpy as np</p><p>import tensorflow as tf</p><p>from tensorflow.contrib.learn.python.learn.estimators.estimator import SKCompat</p><p>import matplotlib.pyplot as plt</p><p>learn = tf.contrib.learn</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ul><p><strong>2. 生成訓練數據與測試數據</strong></p><p>因為是要預測正弦函數，這裡我們使用np模塊下的np.sin函數生成訓練數據和測試數據。</p><p>TRAINING_EXAMPLES = 10000 # 訓練數據大小</p><p>TESTING_EXAMPLES = 1000 # 測試數據大小</p><p>SAMPLE_GAP = 0.01 #採樣間隔</p><p>TIMESTEPS = 10 # 循環神經網絡截斷長度</p><p>def generate_data(seq):</p><p>'''</p><p>定義生成正弦函數數據函數</p><p>:param seq:</p><p>:return: X為訓練數據序列,y為預測數據</p><p>'''</p><p>X = []</p><p>y = []</p><p>for i in range(len(seq) - TIMESTEPS - 1):</p><p>X.append([seq[i: i + TIMESTEPS]]) # 截取以i下標開始的以TIMESTEPS為batch的數據</p><p>y.append([seq[i + TIMESTEPS]]) # 預測i+TIMESTEPS的數據</p><p>return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)</p><p># 生成數據</p><p># TRAINING_EXAMPLES訓練數據個數 SAMPLE_GAP採樣間隔</p><p>test_start = TRAINING_EXAMPLES * SAMPLE_GAP</p><p># 訓練數據和測試數據個數</p><p>test_end = (TRAINING_EXAMPLES + TESTING_EXAMPLES) * SAMPLE_GAP</p><p># np.linspace生成等差數列 即採樣橫軸數據</p><p># 從0到test_start,生成TRAINING_EXAMPLES個數據(即採樣間隔為SAMPLE_GAP)</p><p>train_X, train_y = generate_data(np.sin(np.linspace(</p><p>0, test_start, TRAINING_EXAMPLES, dtype=np.float32)))</p><p># np.linspace生成等差數列</p><p>#</p><p>test_X, test_y = generate_data(np.sin(np.linspace(</p><p>test_start, test_end, TESTING_EXAMPLES, dtype=np.float32)))</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li></ul><hr><p><strong>註解：</strong></p><p>訓練數據TRAINING_EXAMPLES加上測試數據TESTING_EXAMPLES一共需要11000組。</p><p>這裡我們設置是採樣間隔SAMPLE_GAP是0.01。故我們整個採樣距離是11000*0.01=110.也就是在sin函數上，x軸為[0,110]這段距離上均分為11000份。</p><p>訓練數據是以網絡的截斷長度為分割間距。這裡循環神經網絡的截斷長度TIMESTEPS為10。故我們的數據也是10個採樣點和對應的sin值為一組，預測第11個點。(訓練時候就是迴歸第11個點的值).</p><ul><li>先使用np.linspace函數取出等差間隔的採樣點</li><li>再使用np.sin函數獲得對應的sin值。</li><li>在生成數據generate_data時，以TIMESTEPS截斷數據到X內，將TIMESTEPS+1個數據放到對應的標籤y內。</li></ul><p>下面是np.linspace和np.sin的用法示例：</p><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1534905400997ddbd9982c2><p class=pgc-img-caption></p></div><hr><p><strong>3. 定義網絡模型</strong></p><p>我們使用BasicLSTMCell和MultiRNNCell構成一個hidden_size為30的2層的LSTM循環神經網絡。需要注意的是<strong>不同版本下在創建LSTMCells的方法是不一樣的。</strong></p><p>HIDDEN_SIZE = 30 # 隱藏單元個數</p><p>NUM_LAYERS = 2 #LSTM層數</p><p>TRAINING_STEPS = 3000 # 訓練數據輪數</p><p>BATCH_SIZE = 32 # batch大小</p><p>def lstm_model(X, y):</p><p>'''</p><p>定義LSTM模型</p><p>:param X: 訓練數據</p><p>:param y: 預測標籤</p><p>:return:</p><p>'''</p><p># 1.2版本後,tensorflow對使用BasicLSTMCell等 RNNCells生成cells有不同的處理方法，這裡多層的RNN建議採用這種創建cell方法</p><p>stacked_rnn = []</p><p>for iiLyr in range(NUM_LAYERS):</p><p>stacked_rnn.append(tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE, state_is_tuple=True))</p><p>cell = tf.nn.rnn_cell.MultiRNNCell(cells=stacked_rnn, state_is_tuple=True)</p><p>#lstm_cell = tf.contrib.rnn.BasicLSTMCell(HIDDEN_SIZE, state_is_tuple=True) #1.2版本前</p><p>#cell = tf.contrib.rnn.MultiRNNCell([lstm_cell] * NUM_LAYERS)</p><p># 將多層LSTM結構連接成RNN網絡並計算其前向傳播結果</p><p>output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)</p><p># 只關注網絡的最後一個輸出結果,即為下一時刻的預測輸出</p><p>output = tf.reshape(output, [-1, HIDDEN_SIZE])</p><p># 通過無激活函數的全聯接層計算線性迴歸，並將數據壓縮成一維數組的結構。</p><p>predictions = tf.contrib.layers.fully_connected(output, 1, None)</p><p>labels = tf.reshape(y, [-1])</p><p>predictions = tf.reshape(predictions, [-1])</p><p># 定義平方差損失</p><p>loss = tf.losses.mean_squared_error(predictions, labels)</p><p># 創建模型優化器並得到優化步驟</p><p>train_op = tf.contrib.layers.optimize_loss(</p><p>loss, tf.contrib.framework.get_global_step(),</p><p>optimizer="Adagrad", learning_rate=0.1)</p><p>return predictions, loss, train_op</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li></ul><p><strong>4. 創建模型並訓練</strong></p><p>這裡我們使用了tf.contrib.learn下的一個<strong>封裝模型工具Estimator</strong>。使用Estimator封裝好一個預測模型後((已訓練)，我們對測試數據進行了預測，再計算了下均方誤差，大體上的評估了一下模型的預測性能。</p><p># 封裝之前定義的lstm</p><p># 如果你的tensorflow1.2版本前已經訓練好了這樣的的一個模型，在tensorflow更新後，重新生成模型。</p><p># 因為在新版本的Tensorflow裡，LSTM單元的文件改變了，這裡我們簡單的把以前的model_dir修改了，保證創建了新的模型</p><p>regressor = SKCompat(learn.Estimator(model_fn=lstm_model, model_dir="Models/model_3"))</p><p># 擬合數據</p><p>regressor.fit(train_X, train_y, batch_size=BATCH_SIZE, steps=TRAINING_STEPS)</p><p># 計算預測值</p><p>predicted = [[pred] for pred in regressor.predict(test_X)]</p><p># 計算MSE</p><p>rmse = np.sqrt(((predicted - test_y) ** 2).mean(axis=0))</p><p>print ("Mean Square Error is: %f" % rmse[0])</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li></ul><hr><p><strong>Estimator工具</strong></p><p>這裡我們簡單的介紹以下Estimator工具。</p><p>參考TensorFlow 0.12 Estimators Models Layers學習筆記。Estimators的作用是:</p><ul><li>tf.estimator framework用於快速構建和訓練機器學習模型，同時Estimator提供了一些常見的模型(常見的迴歸和分類模型，例如:線性分類，線性迴歸等)</li><li>tf.estimator為monitors,checkpointing提供了初始化配置，同時提供了構建和評估自定義模型的大部分邏輯。依照著tutorial可以很方便的創建一個estimator.TensorFlow關於Estimator介紹</li></ul><p>總的來說，我們可以認為tf.estimator工具是用來提供一個自定義模型的框架，我們照著定義好的格式配置好輸入即可。</p><ol><li><strong>創建一個Estimator</strong></li></ol><ul><li>先看構造器定義:</li><li>init(model_fn=None, model_dir=None, config=None, params=None, feature_engineering_fn=None)</li><li>'''</li><li>Args:</li><li>model_fn: 模型定義，定義了train, eval, predict的實現</li><li>model_dir: log文件和訓練參數的保存目錄</li><li>config: Configuration object</li><li>params: dict of hyper parameters that will be passed into model_fn. Keys are names of parameters, values are basic python types.</li><li>feature_engineering_fn: Feature engineering function. Takes features and labels which are the output of input_fn and returns features and labels which will be fed into model_fn. Please check model_fn for a definition of features and labels.</li><li>'''</li><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li><strong>tf.estimator常接收2個參數:model_fn和model_dir.注意到我們使用的.</strong></li><li>learn.Estimator(model_fn=lstm_model, model_dir="Models/model_3") # model_fn和model_dir參數</li><li>1</li><li><strong>這裡需要注意model_fn:</strong></li></ul><ol><li>model_fn(features, labels, mode, params)</li><li>'''</li><li>features: Tensor or dict of Tensor's. 即樣本數據x.</li><li>labels: Tensor or dict of Tensor's. 樣本數據y.(支持無標籤訓練，調整對應的mode即可)</li><li>mode: 指定model_fn功能.</li><li>params: params is a dict of hyperparameters</li><li>'''</li></ol><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ul><ol><li><strong>訓練模型</strong></li><li>將我們的訓練數據塞給fit，訓練完成後，就會按照前面指定的model_dir存放訓練好的模型.</li><li>fit(x=None, y=None, input_fn=None, steps=None, batch_size=None, monitors=None, max_steps=None)</li><li>'''</li><li>x: 訓練數據x. 格式為[n_samples,n_features...],如果設置此參數，input_fn需為None.</li><li>y: 訓練數據y。x對應的標籤。</li><li>steps: 每次訓練ops.</li><li>batch_size: minibatch size.</li><li>moitors: Used for callbacks inside the training loop.</li><li>max_steps: Number of total steps for which to train model.</li><li>input_fn: 說白了就是把x，y，batch_size包裝一下。 用這個就不用設置x,y,batch_size了.</li><li>'''</li></ol><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li></ul><ol><li><strong>預測</strong></li><li>將需要預測的數據塞給predict，返回的就是預測值.</li><li>predict(x=None, input_fn=None, batch_size=None, outputs=None, as_iterable=True)</li><li>'''</li><li>x : 為需要預測的數據。</li><li>batch_size: minibatch size.</li><li>input_fn: 對x和batch_size的包裝</li><li>outputs: list of str, name of the output to predict. If None, returns all</li><li>as_iterable: If True, return an iterable which keeps yielding predictions for each example until inputs are exhausted. Note: The inputs must terminate if you want the iterable to terminate (e.g. be sure to pass num_epochs=1 if you are using something like read_batch_features).</li><li>'''</li></ol><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li></ul><ol><li><strong>注意</strong></li><li><strong>前面我說了如果在輸入的時候設置x,y,batch_size就不要設置input_fn，需要注意的是:，如果使用x,y而不是input_fn來傳參數的形式，需要用Estimator裡一個叫SKCompat的類包裝一下</strong>.</li><li>estimator_instance = SKCompat(Estimator(model_fn=..., model_dir=...))</li></ol><ul><li>1</li><li>2</li></ul><ol><li>到這裡，我們對TensorFlow內的Estimator工具介紹就算結束了～</li></ol><hr><p><strong>5. 繪圖</strong></p><p>使用plt將預測數據和測試數據繪製出來，有一個直觀上的認識。</p><p>fig = plt.figure()</p><p>plot_predicted, = plt.plot(predicted, label='predicted')</p><p>plot_test, = plt.plot(test_y[0:399], label='real_sin')</p><p>plt.legend([plot_predicted, plot_test],['predicted', 'real_sin'])</p><p>plt.show()</p><p>fig.savefig('pre_sin.png')</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li></ul><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1534905420970d8901ff26f><p class=pgc-img-caption></p></div><hr><hr><h1><strong>利用TFTS進行時間序列預測</strong></h1><p>到這裡算是切入主題了，下面介紹如何使用TFTS模塊進行時間序列預測。</p><p><strong>載入數據部分</strong></p><p>對於時間序列預測問題，我們可以把<strong>數據抽象成:{觀察點:觀察值}</strong>。例如某年一月的價格為120元，二月的價格為130元，三月的價格為135元，四月的價格為132元。那麼觀察的時間點可以看做是1,2,3,4，而在各時間點上觀察到的數據的值為120,130,135,132。</p><p>TFTS庫提供了兩個數據讀取器NumpyReader和CSVReader.</p><p>NumpyReader用於從Numpy數組中讀入數據，下面舉一個demo:</p><p>import numpy as np</p><p>import matplotlib.pyplot as plt</p><p>x = np.array(range(1000))</p><p>noise = np.random.uniform(-0.2, 0.2, 1000) # 隨機生成-0.2~0.2之間的數據</p><p>y = np.sin(np.pi * x * 0.01) + x * 0.005 + noise # y=sin(0.01*pi*x) + 0.005*x + noise</p><p>p = plt.plot(x, y)</p><p>plt.show()</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li></ul><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15349054358039a9e76c444><p class=pgc-img-caption></p></div><p>橫軸即’採樣點x’,縱軸為’採樣值y’.</p><p>TFTS提供的讀入x和y的接口非常簡單，使用demo如下:</p><p>data = {</p><p>tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,</p><p>tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,</p><p>}</p><p>reader = NumpyReader(data)</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li></ul><p>我們首先把x和y轉為Python中的dict.我們來分析以下上面data的寫法。tf.contrib.timeseries.TrainEvalFeatures.TIMES就是一個字符串’times’，而對應tf.contrib.timeseries.TrainEvalFeatures.VALUES也是一個字符串’values’.上面的data定義也可以寫成:</p><p>data = {</p><p>'times' : x,</p><p>'values': y,</p><p>}</p><ul><li>1</li><li>2</li><li>3</li><li>4</li></ul><p>至於為什麼寫成上面的那個形式，也是為了配合規範化。</p><p>NumpyReader返回的對象有一個<strong>read_full()方法，該方法用於從Reader中讀取所有的數據</strong>，但需要注意的是:<strong>read_full()會產生讀取隊列</strong>(這樣的處理訓練數據的方法和TensorFlow開源的AlexNet網絡上對輸入數據做增強操作使用的方法類似)，這要求我們在使用該方法前，需要<strong>先調用tf.train.start_queue_runners啟動隊列</strong>，然後才能讀取數據。使用的demo如下:</p><p>with tf.Session() as sess:</p><p>full_data = reader.read_full()</p><p>coord = tf.train.Coordinator() # 創建一個線程協調器</p><p>threads = tf.train.start_queue_runners(sess=sess, coord=coord) # 啟動線程隊列</p><p>print('times shape:', full_data['times'])</p><p>print('values shape:', full_data['values'])</p><p>print(sess.run(full_data)['times'][0:10])</p><p>print(sess.run(full_data)['values'][0:10])</p><p>coord.request_stop()</p><p>'''</p><p>輸出:</p><p>times shape: Tensor("Squeeze_1:0", shape=(1000,), dtype=int64)</p><p>values shape: Tensor("Squeeze:0", shape=(1000, 1), dtype=float64)</p><p>[0 1 2 3 4 5 6 7 8 9]</p><p>[[-0.09581681]</p><p>[ 0.01284531]</p><p>[ 0.1107236 ]</p><p>[ 0.08856841]</p><p>[ 0.19104294]</p><p>[ 0.32795446]</p><p>[ 0.17780316]</p><p>[ 0.35017529]</p><p>[ 0.10477021]</p><p>[ 0.16101822]]</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li></ul><p>通常在訓練模型時，我們採需要的是<strong>minibatch形式的訓練數據</strong>，TFTS庫提供了<strong>tf.contrib.timeseries.RandomWindowInputFn</strong>方法用於在reader中隨機選取window_size大小的數據組成一組序列數據。demo如下:</p><p>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(</p><p>reader, batch_size=2, window_size=10)</p><p>with tf.Session() as sess:</p><p>batch_data = train_input_fn.create_batch()</p><p>coord = tf.train.Coordinator()</p><p>threads = tf.train.start_queue_runners(sess=sess, coord=coord)</p><p>one_batch = sess.run(batch_data[0])</p><p>coord.request_stop()</p><p>print('one_batch_data:', one_batch)</p><p>'''</p><p>即一個batch為2組序列數據，每組序列數據有10條數據。</p><p>輸出:</p><p>one_batch_data: {</p><p>'values': array([[[ 1.21827106],</p><p>[ 1.37975747],</p><p>[ 1.15419451],</p><p>[ 1.07579377],</p><p>[ 1.19008057],</p><p>[ 1.32173953],</p><p>[ 1.2152622 ],</p><p>[ 1.31092923],</p><p>[ 1.26184174],</p><p>[ 1.25915473]],</p><p>[[ 0.08465949],</p><p>[-0.0859257 ],</p><p>[-0.02987006],</p><p>[ 0.17472125],</p><p>[ 0.23542243],</p><p>[ 0.2032668 ],</p><p>[ 0.07650485],</p><p>[ 0.20822309],</p><p>[ 0.30753332],</p><p>[ 0.16054565]]]),</p><p>'times': array([[61, 62, 63, 64, 65, 66, 67, 68, 69, 70],</p><p>[ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])}</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li></ul><p>TFTS從Numpy中讀取數據的流程大概操作就是這樣了～</p><hr><p><strong>從CSV文件中讀入時間序列數據</strong></p><p>TFTS還提供了CSVReader用於讀取CSV文件。</p><p>項目中提供了一個input_input_csv.py文件用於處理csv文件，這裡處理的文件是’./data/period_trend.csv’.</p><p>這裡CSV的文件形式如下(截取):</p><p>1,-0.6656603714</p><p>2,-0.1164380359</p><p>3,0.7398626488</p><p>4,0.7368633029</p><p>5,0.2289480898</p><p>6,2.257073255</p><p>7,3.023457405</p><p>8,2.481161007</p><p>9,3.773638612</p><p>10,5.059257738</p><p>11,3.553186083</p><p>12,4.554486452</p><p>13,3.655475698</p><p>14,3.419647598</p><p>15,4.303376245</p><p>16,4.830153934</p><p>17,7.253057441</p><p>18,5.064802335</p><p>19,5.448082106</p><p>20,6.251301517</p><p>...</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li></ul><p>CSV的第一列數據為時間點，第二列數據為對應的觀察值。</p><p>CSVReader的操作步驟除了讀取文件的部分不同，後面的操作和前面的NumpyReader是一樣的。操作的demo如下:</p><p>from __future__ import print_function</p><p>import tensorflow as tf</p><p>csv_file_name = './data/period_trend.csv'</p><p>reader = tf.contrib.timeseries.CSVReader(csv_file_name)</p><p>with tf.Session() as sess:</p><p>data = reader.read_full()</p><p>coord = tf.train.Coordinator()</p><p>threads = tf.train.start_queue_runners(sess=sess, coord=coord)</p><p>print(sess.run(data))</p><p>coord.request_stop()</p><p>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(reader, batch_size=4, window_size=16)</p><p>with tf.Session() as sess:</p><p>data = train_input_fn.create_batch()</p><p>coord = tf.train.Coordinator()</p><p>threads = tf.train.start_queue_runners(sess=sess, coord=coord)</p><p>batch1 = sess.run(data[0])</p><p>batch2 = sess.run(data[0])</p><p>coord.request_stop()</p><p>print('batch1:', batch1)</p><p>print('batch2:', batch2)</p><p>'''</p><p>輸出:</p><p>{'values': array([[ -0.66566038],</p><p>[ -0.11643804],</p><p>[ 0.73986262],</p><p>[ 0.73686332],</p><p>[ 0.22894809],</p><p>[ 2.25707316],</p><p>[ 3.02345729],</p><p>...</p><p>dtype=float32), 'times': array([ 1, 2, 3, 4, 5, 6, ...，500])}</p><p>batch1: {'values': array([[[ 9.75562382],</p><p>[ 9.1494894 ],</p><p>[ 8.94796562],</p><p>[ 9.1767683 ],dtype=float32), 'times': array([[ 98, 99，...,129]])}</p><p>batch2: {'values': array([[[ 4.97288084],</p><p>[ 5.21278238],...，dtype=float32), 'times': array([[ 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94,</p><p>95, 96, 97],...，226]])}</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li><li>42</li><li>43</li><li>44</li><li>45</li><li>46</li><li>47</li></ul><p>到這裡為止，載入數據部分到這裡就算結束了。</p><hr><p><strong>使用AR模型預測時間序列</strong></p><p>AR模型是一種線性預測，即已知N個數據，可由模型推出第N點前面或後面的數據（設推出P點），所以其本質類似於插值，其目的都是為了增加有效數據，只是AR模型是由N點遞推，而插值是由兩點（或少數幾點）去推導多點，所以AR模型要比插值方法效果更好。</p><p><strong>代碼實現</strong></p><p><strong>產生數據</strong></p><p>產生數據的方法就是上面介紹的方法。</p><p>x = np.array(range(1000))</p><p>noise = np.random.uniform(-0.2, 0.2, 1000)</p><p>y = np.sin(np.pi * x / 100) + x / 200. + noise</p><p>plt.plot(x, y)</p><p>plt.savefig('timeseries_y.jpg')</p><p>data = {</p><p>tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,</p><p>tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,</p><p>}</p><p>reader = NumpyReader(data)</p><p>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(</p><p>reader, batch_size=16, window_size=40)</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li></ul><p><strong>創建ar模型</strong></p><p>創建ar模型，我們需要使用tf.contrib.timeseries.ARRegressor類</p><hr><p>先看下ARRegressor類</p><p>class ARRegressor(_TimeSeriesRegressor):</p><p>"""</p><p>ARRegressor是基於滑窗模型的。這要求輸入窗口大小要固定為'input_window_size'，輸出窗口大小固定為'output_window_size'. 同時這兩個參數的和必須等於window_size(滿足訓練或評估時使用的input_fn)。建議使用'RandomWindowInputFn'(就是上面講的隨機產生batch數據的函數)產生訓練或者評估。</p><p>"""</p><p>def __init__(self,</p><p>periodicities, input_window_size,</p><p>output_window_size, num_features, num_time_buckets=10,</p><p>loss=ar_model.ARModel.NORMAL_LIKELIHOOD_LOSS,</p><p>hidden_layer_sizes=None, anomaly_prior_probability=None,</p><p>anomaly_distribution=None, optimizer=None,</p><p>model_dir=None, config=None):</p><p>"""</p><p>參數:</p><p>periodicities: value or a list of values. 輸入信號的週期。</p><p>input_window_size: 迴歸時給定的輸入數據時間步數.</p><p>output_window_size: 預測時間步數，建議設置>1.</p><p>num_features: 時間序列的維度.(數據的觀察值)</p><p>loss: SQUARED_LOSS 或者 NORMAL_LIKELIHOOD_LOSS.</p><p>hidden_layer_sizes: 默認即可.</p><p>anomaly_distribution；anomaly_distribution: 默認即可，指定即構成混合模型</p><p>optimizer: defaults to Adagrad with step size 0.1.</p><p>model_dir:模型存儲地址.(上面Estimator有講)</p><p>config: See `Estimator`.</p><p>"""</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li></ul><p>總的來說，需要填的參數有periodicities,input_window_size,output_window_size,num_features,loss。其它的參數默認即可。</p><hr><p>這裡需要注意的有<strong>input_window_size + output_window_size = window_size</strong>.(RandomWindowInputFn生成數據裡面的window_size).我們在上面的生成數據使用的window_size=40.下面使用的是input_window_size=30, output_window_size=10.就是輸入序列30個，預測10個。</p><p><strong>num_features</strong>即時間序列的維度。就是在一個時間點上觀察到的數據維度。我們這裡每一步都是一個單獨的值，所以num_features=1。</p><p><strong>periodicities</strong>是信號的週期分量的週期，我們信號的表達式為:</p><p>y=sin(0.01∗π∗x)+0.005∗x+noise</p><p>y=sin(0.01∗π∗x)+0.005∗x+noise</p><p>y的週期分量的frequency為2∗π∗(1/f)</p><p>2∗π∗(1/f),故f=200,所以periodicities=200</p><p>f=200,所以periodicities=200。</p><p><strong>loss</strong>的取值現在支持NORMAL_LIKELIHOOD_LOSS和SQUARED_LOSS。 ar = tf.contrib.timeseries.ARRegressor(</p><p>periodicities=200, input_window_size=30, output_window_size=10,</p><p>num_features=1,</p><p>loss=tf.contrib.timeseries.ARModel.NORMAL_LIKELIHOOD_LOSS)</p><p>'''</p><p>(input_window_size=30) + (output_window_size=10) = (window_size=40)</p><p>'''</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ul><p><strong>訓練評估模型並預測</strong></p><p>使用train函數傳入創建好的數據train_input_fn訓練模型即可.</p><p>ar.train(input_fn=train_input_fn, steps=6000)</p><ul><li>1</li></ul><p>接下來就是對模型進行評估，首先我們使用AR模型提供的evaluate函數，這裡evaluation的處理是使用訓練好的模型在原先的訓練集上進行計算，由此我們可以觀察到模型的擬合效果.</p><p>evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)</p><p>evaluation = ar.evaluate(input_fn=evaluation_input_fn, steps=1)</p><p># keys of evaluation: ['covariance', 'loss', 'mean', 'observed', 'start_tuple', 'times', 'global_step']</p><p># evaluation['covariance']代表協方差 evaluation['loss']代表損失 etc..</p><ul><li>1</li><li>2</li><li>3</li><li>4</li></ul><p>如果要理解這裡evaluate函數的邏輯，這裡AR模型：每次都接收長度為30的輸入觀測序列，並輸出長度為10的預測序列。以此為規則，每次移動步長為1，以此類推，整個訓練集長度為1000的序列，最終我們得到970個預測值。</p><p>這970個預測值記錄在evaluation[‘mean’]中;evaluation還有其他幾個鍵值:evaluation[‘loss’]表示總的損失，evaluation[‘times’]表示evaluation[‘mean’]對應的時間點等等.</p><p>評估完模型後，下面該是使用模型了，這裡我們會用到predict函數來預測，傳入參數為evaluation[‘start_tuple’]會被用於之後的預測中，它相當於最後30步的輸出值和對應的時間點。以此為起點(也就是給定觀察數據)，我們可以對1000步以後的值進行預測，對應的代碼為：</p><p>(predictions,) = tuple(ar.predict(</p><p>input_fn=tf.contrib.timeseries.predict_continuation_input_fn(</p><p>evaluation, steps=250)))</p><ul><li>1</li><li>2</li><li>3</li></ul><p>這裡的代碼在1000步之後又像後預測了250個時間點。對應的值就保存在predictions[‘mean’]中。我們可以把觀測到的值、模型擬合的值、預測值用下面的代碼畫出來：</p><p>plt.figure(figsize=(15, 5))</p><p>plt.plot(data['times'].reshape(-1), data['values'].reshape(-1), label='origin')</p><p>plt.plot(evaluation['times'].reshape(-1), evaluation['mean'].reshape(-1), label='evaluation')</p><p>plt.plot(predictions['times'].reshape(-1), predictions['mean'].reshape(-1), label='prediction')</p><p>plt.xlabel('time_step')</p><p>plt.ylabel('values')</p><p>plt.legend(loc=4)</p><p>plt.savefig('predict_result.jpg')</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li></ul><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1534905582992424220237f><p class=pgc-img-caption></p></div><hr><p><strong>使用LSTM預測單變量時間序列</strong></p><p>注意：以下LSTM模型的例子必須使用TensorFlow最新的開發版的源碼。具體來說，要保證</p><p>from tensorflow.contrib.timeseries.python.timeseries.estimators import TimeSeriesRegressor</p><ul><li>1</li></ul><p>可以成功執行。(就是前面說的需要安裝最新版的tensorflow)</p><p>給出兩個用LSTM預測時間序列模型的例子，分別是train_lstm.py和train_lstm_multivariate.py。前者是在LSTM中進行單變量的時間序列預測，後者是使用LSTM進行多變量時間序列預測。為了使用LSTM模型，我們需要先使用TFTS庫對其進行定義，定義模型的代碼來源於TFTS的示例源碼，在train_lstm.py和train_lstm_multivariate.py中分別拷貝了一份。</p><p><strong>產生訓練數據</strong></p><p>這裡我們產生的數據公式修改一下</p><p>y=sin(π∗0.02∗x)+cos(π∗0.02∗x)+sin(π∗0.04∗x)+noise</p><p>y=sin(π∗0.02∗x)+cos(π∗0.02∗x)+sin(π∗0.04∗x)+noise</p><p>同樣用函數加噪聲的方法生成一個模擬的時間序列數據：</p><p>x = np.array(range(1000))</p><p>noise = np.random.uniform(-0.2, 0.2, 1000)</p><p>y = np.sin(np.pi * x / 50 ) + np.cos(np.pi * x / 50) + np.sin(np.pi * x / 25) + noise</p><p>data = {</p><p>tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,</p><p>tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,</p><p>}</p><p>'''</p><p>plt.plot(x, y)</p><p>plt.savefig('train_data.jpg')</p><p>'''</p><p>reader = NumpyReader(data)</p><p>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(</p><p>reader, batch_size=4, window_size=100) # batch_size為4 序列長度為100</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li></ul><p>產生數據如下:</p><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1534905461004578947d80b><p class=pgc-img-caption></p></div><p><strong>定義訓練模型並預測</strong></p><p>這裡使用TFTS包內提供的TimeSeriesRegressor模型。其中_LSTMModel來自TFTS包的官方例子。</p><hr><ul><li><strong>_LSTMModel接受兩個參數:</strong>num_units: 模型中使用的LSTM單元個數</li><li>num_features: 時間序列能觀察到的維度.(即每個時間步能觀察到的數據特徵量)</li></ul><p>這裡我們使用的模型參數為num_features = 1表示單變量時間序列，即每個時間點上觀察到的量只是一個單獨的數值。num_units=128表示使用隱層為128大小的LSTM模型。後續的訓練，評估，預測和前面講的代碼類似。在以後的1000組數據上，我們向後預測了200組數據。</p><hr><p>代碼如下:</p><p>estimator = ts_estimators.TimeSeriesRegressor(</p><p>model=_LSTMModel(num_features=1, num_units=128),</p><p>optimizer=tf.train.AdamOptimizer(0.001))</p><p>estimator.train(input_fn=train_input_fn, steps=2000)</p><p>evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)</p><p>evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)</p><p># Predict starting after the evaluation 預測後續的200組數據</p><p>(predictions,) = tuple(estimator.predict(</p><p>input_fn=tf.contrib.timeseries.predict_continuation_input_fn(</p><p>evaluation, steps=200)))</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li></ul><p><strong>繪製預測數據圖</strong></p><p>observed_times = evaluation["times"][0]</p><p>observed = evaluation["observed"][0, :, :]</p><p>evaluated_times = evaluation["times"][0]</p><p>evaluated = evaluation["mean"][0]</p><p>predicted_times = predictions['times']</p><p>predicted = predictions["mean"]</p><p>plt.figure(figsize=(15, 5))</p><p>plt.axvline(999, linestyle="dotted", linewidth=4, color='r')</p><p>observed_lines = plt.plot(observed_times, observed, label="observation", color="k")</p><p>evaluated_lines = plt.plot(evaluated_times, evaluated, label="evaluation", color="g")</p><p>predicted_lines = plt.plot(predicted_times, predicted, label="prediction", color="r")</p><p>plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],</p><p>loc="upper left")</p><p>plt.savefig('predict_result.jpg')</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li></ul><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15349056032327a60fa42cb><p class=pgc-img-caption></p></div><hr><p><strong>使用LSTM預測多變量時間序列</strong></p><p>與上面的使用LSTM預測單變量時間序列不同的地方在於數據的讀取和模型的預測量。使用原理實質上是一致的。</p><p><strong>獲取訓練數據</strong></p><p>所謂多變量時間序列，就是指在每個時間點上的觀測量有多個值。在data/multivariate_periods.csv文件中，保存了一個多變量時間序列的數據：(下面是截取)</p><p>0,0.926906299771,1.99107237682,2.56546245685,3.07914768197,4.04839057867</p><p>1,0.108010001864,1.41645361423,2.1686839775,2.94963962176,4.1263503303</p><p>2,-0.800567600028,1.0172132907,1.96434754116,2.99885333086,4.04300485864</p><p>3,0.0607042871898,0.719540073421,1.9765012584,2.89265588817,4.0951014426</p><p>4,0.933712200629,0.28052120776,1.41018552514,2.69232603996,4.06481164223</p><p>5,-0.171730652974,0.260054421028,1.48770816369,2.62199129293,4.44572807842</p><p>6,-1.00180162933,0.333045158863,1.50006392277,2.88888309683,4.24755865606</p><p>7,0.0580061875336,0.688929398826,1.56543458772,2.99840358953,4.52726873347</p><p>8,0.764139447412,1.24704875327,1.77649279698,3.13578593851,4.63238922951</p><p>9,-0.230331874785,1.47903998963,2.03547545751,3.20624030377,4.77980005228</p><p>10,-1.03846045211,2.01133000781,2.31977503972,3.67951536251,5.09716775897</p><p>11,0.188643592253,2.23285349038,2.68338482249,3.49817168611,5.24928239634</p><p>12,0.91207302309,2.24244446841,2.71362604985,3.96332587625,5.37802271594</p><p>13,-0.296588665881,2.02594634141,3.07733910479,3.99698324956,5.56365901394</p><p>14,-0.959961476551,1.45078629833,3.18996420137,4.3763059609,5.65356015609</p><p>15,0.46313530679,1.01141441548,3.4980215948,4.20224896882,5.88842247449</p><p>16,0.929354125798,0.626635305936,3.70508262244,4.51791573544,5.73945973251</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li></ul><p>即每個時間步上能觀察到多個數據變量(這裡有5組數據)。舉個簡單的例子:如果現在我在跑步，每個時間步上，可以獲取到我的心跳，血壓，體溫。這就是在每個時間步上能觀察到3個數據變量。</p><p>下面依舊是使用CSVReader處理數據，區別在column_names參數，該參數告訴CSVReader那些變量是對應的時間步和變量。</p><p>csv_file_name = path.join("./data/multivariate_periods.csv")</p><p>reader = tf.contrib.timeseries.CSVReader(</p><p>csv_file_name,</p><p>column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)</p><p>+ (tf.contrib.timeseries.TrainEvalFeatures.VALUES,) * 5))</p><p>train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(</p><p>reader, batch_size=4, window_size=32)</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ul><p><strong>定義訓練模型並預測</strong></p><p>這裡與上面的程序不同的地方在於_LSTMModel中參數num_features=5.即能觀察的數據量維度為5.本次向後預測的數據為100組。(訓練數據100組)</p><p>estimator = ts_estimators.TimeSeriesRegressor(</p><p>model=_LSTMModel(num_features=5, num_units=128),</p><p>optimizer=tf.train.AdamOptimizer(0.001))</p><p>estimator.train(input_fn=train_input_fn, steps=200)</p><p>evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)</p><p>evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)</p><p># Predict starting after the evaluation</p><p>(predictions,) = tuple(estimator.predict(</p><p>input_fn=tf.contrib.timeseries.predict_continuation_input_fn(</p><p>evaluation, steps=100)))</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li></ul><p><strong>繪製預測圖</strong></p><p>observed_times = evaluation["times"][0]</p><p>observed = evaluation["observed"][0, :, :]</p><p>evaluated_times = evaluation["times"][0]</p><p>evaluated = evaluation["mean"][0]</p><p>predicted_times = predictions['times']</p><p>predicted = predictions["mean"]</p><p>plt.figure(figsize=(15, 5))</p><p>plt.axvline(99, linestyle="dotted", linewidth=4, color='r')</p><p>observed_lines = plt.plot(observed_times, observed, label="observation", color="k")</p><p>evaluated_lines = plt.plot(evaluated_times, evaluated, label="evaluation", color="g")</p><p>predicted_lines = plt.plot(predicted_times, predicted, label="prediction", color="r")</p><p>plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],</p><p>loc="upper left")</p><p>plt.savefig('predict_result.jpg')</p><ul><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li></ul><div class=pgc-img><img alt=TensorFlow實戰：Chapter-7下（TFTS庫與時間序列預測） onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15349054915748b089e1943><p class=pgc-img-caption></p></div><hr><hr><h1><strong>總結</strong></h1><p>TFTS是Tensorflow官方提供的基於LSTM模型的時序預測工具，可以用於常見的時序模型上(替代HMM)。這裡講了如果使用TFTS模型讀取數據併產生訓練數據，同時講了如果使用TFTS模塊自帶的AR和LSTM模型。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>TensorFlow</a></li><li><a>實戰</a></li><li><a>Chapter</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html alt=OpenCV項目實戰---人臉檢測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f267e46946554437b5ffe48234f3b78d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html title=OpenCV項目實戰---人臉檢測>OpenCV項目實戰---人臉檢測</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html alt=音頻編碼實戰 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/aacf5cab-b987-443f-815e-236f984fb2d0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html title=音頻編碼實戰>音頻編碼實戰</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02729303.html alt=java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d69c7c9d8b85444da9360e334ba6555d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02729303.html title=java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID>java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html alt=老股民總結的賣出技巧實戰圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/7575000bb7b8e57fa260 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html title=老股民總結的賣出技巧實戰圖解>老股民總結的賣出技巧實戰圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html alt=股票交易指南：實戰圖解經典的賣出技巧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15305260751844061be70e0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html title=股票交易指南：實戰圖解經典的賣出技巧>股票交易指南：實戰圖解經典的賣出技巧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eaa95354.html alt=股票賣出實戰技術圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/88520001219b9b7dabd2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eaa95354.html title=股票賣出實戰技術圖解>股票賣出實戰技術圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/feeaba4f.html alt="在線報表設計實戰系列 – ②製作表格類報表" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/47190002d9db05c4adc2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/feeaba4f.html title="在線報表設計實戰系列 – ②製作表格類報表">在線報表設計實戰系列 – ②製作表格類報表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d288ac1b.html alt=打通實戰保障鏈路“最後一公里” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d288ac1b.html title=打通實戰保障鏈路“最後一公里”>打通實戰保障鏈路“最後一公里”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/79ca353a.html alt=「案例實戰」案例解析（24）自噴系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/c8b46117-9cc6-4c33-be2f-ca4e35b8431f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/79ca353a.html title=「案例實戰」案例解析（24）自噴系統>「案例實戰」案例解析（24）自噴系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/db5ee11c.html alt=「案例實戰」案例解析（39）自噴系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/db5ee11c.html title=「案例實戰」案例解析（39）自噴系統>「案例實戰」案例解析（39）自噴系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c3d6e4c9.html alt=Java項目實戰第10天：分頁欄的實現 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/000f44dadac946188c05567c6741ae3c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c3d6e4c9.html title=Java項目實戰第10天：分頁欄的實現>Java項目實戰第10天：分頁欄的實現</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/20b12ef6.html alt=Java項目實戰第7天：導航欄業務的實現 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5ed388098e304e21872e291ae4eebf6f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/20b12ef6.html title=Java項目實戰第7天：導航欄業務的實現>Java項目實戰第7天：導航欄業務的實現</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4110ca16.html alt=股市真正厲害的實戰操盤手：“尾盤30分鐘”是股市全天的最黃金時刻，讀懂本文等於讀懂中國股市 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RbYtVhS9wGTmMO style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4110ca16.html title=股市真正厲害的實戰操盤手：“尾盤30分鐘”是股市全天的最黃金時刻，讀懂本文等於讀懂中國股市>股市真正厲害的實戰操盤手：“尾盤30分鐘”是股市全天的最黃金時刻，讀懂本文等於讀懂中國股市</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/63d702d9.html alt=實戰：快速製作晶格化界面 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f6d9a49e175845eeb3f1cf0891713c6f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/63d702d9.html title=實戰：快速製作晶格化界面>實戰：快速製作晶格化界面</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c3c2cbf1.html alt=三、彙編初步實戰 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c3c2cbf1.html title=三、彙編初步實戰>三、彙編初步實戰</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>