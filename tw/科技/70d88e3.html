<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>文章太長不想看？ML 文本自動摘要了解一下 | 极客快訊</title><meta property="og:title" content="文章太長不想看？ML 文本自動摘要了解一下 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/34f7fc9ba9814b28baa788e9b67df503"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70d88e3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70d88e3.html><meta property="article:published_time" content="2020-10-29T20:50:40+08:00"><meta property="article:modified_time" content="2020-10-29T20:50:40+08:00"><meta name=Keywords content><meta name=description content="文章太長不想看？ML 文本自動摘要了解一下"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/70d88e3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>文章太長不想看？ML 文本自動摘要了解一下</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>選自floydhub</p><p><strong>作者：Alfrick Opidi</strong></p><p><strong>機器之心編譯</strong></p><p><strong>參與：杜偉、張倩</strong></p><blockquote><p>我們在閱讀新聞報道等實時性文章時，需要快速歸納出文章的大意。但是，如果將一篇很長的文章歸納成一個能夠涵蓋原文中心思想的小段落，則需要我們耗費大量時間。本文介紹了自然語言處理中的兩種文本自動摘要生成方法——抽取式和抽象式文本摘要。這兩種方法通過計算文本中句子成分的權重來生成摘要，可以大大節省通讀全文以及歸納總結主要信息的時間，為讀者提供方便。</p></blockquote><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/34f7fc9ba9814b28baa788e9b67df503><p class=pgc-img-caption></p></div><p>你是否曾將一篇冗長的文檔歸納為一個小的段落？你用了多長時間呢？手動歸納總結耗費時間、枯燥乏味。文本自動摘要可以克服此類難題，幫你輕鬆歸納出一篇文章的中心思想。</p><p>文本摘要方法能夠對冗長文本進行簡潔準確的總結，同時將重點放在傳達有用信息的章節，而又不失去文章大意。</p><p>文本自動摘要旨在將冗長文檔變成縮寫版本，若手動完成則可能非常麻煩且成本高昂。</p><p>在生成需要的摘要文本之前，機器學習算法可被訓練用以理解文檔，識別傳達重要事實和信息的章節。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/31085e8312084084a7a37b809938e0cb><p class=pgc-img-caption></p></div><p><em>使用文本摘要機器學習算法生成一篇在線新聞文章的摘要。</em></p><p><strong>文本自動摘要的必要性</strong></p><p>隨著目前數字空間中數據的爆炸式增長，而大多又是非結構化的文本數據，因而需要開發文本自動摘要工具，使人們可以輕易獲知文本大意。當前，我們可以快速訪問大量信息。但是，大多數信息冗長、無關緊要，還可能無法傳達其本意。例如，如果你想從一篇在線新聞報道中搜尋一些特定信息，你也許要吃透報道內容，花費大量時間剔除無用信息，之後才能找到自己想要了解的信息。所以，使用能夠提取有用信息並剔除無關緊要和無用數據的自動文本摘要生成器變得非常重要。文本摘要的實現可以增強文檔的可讀性，減少搜尋信息的時間，獲得更多適用於特定領域的信息。</p><p><strong>文本自動摘要的主要類型</strong></p><p>從廣義的角度看，自然語言處理（NLP）中有兩種文本摘要生成方法：抽取式和抽象式。</p><p><strong>抽取式摘要（extraction-based summarization）</strong></p><p>在抽取式摘要中，抽取一段文本中表示重點內容的單詞子集，並結合起來生成摘要。我們可以將抽取式摘要看作是一支熒光筆-從源文本中抽取主要信息。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/27d7023546764d0d9245e57393aaf1f5><p class=pgc-img-caption></p></div><p><em>熒光筆 = 抽取式摘要</em></p><p>在機器學習中，抽取式摘要通常需要衡量基本句子成分的權重，並根據權重結果生成摘要。</p><p>不同類型的算法和方法均可用於衡量句子的權重，之後根據各成分之間的關聯性和相似性進行排序-並進一步將這些成分連接起來以生成摘要。</p><p>如下例所示：</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b95b79042e8d479fac1fb89af81d1c4a><p class=pgc-img-caption></p></div><p><em>抽取式摘要</em></p><p>如上例所示，抽取式摘要由熒光筆標黃的單詞組成，生成摘要的語法可能不準確。</p><p><strong>抽象式摘要</strong></p><p>在抽象式摘要中，高級深度學習方法（advanced deep learning technique）用於解釋和縮寫原始文檔，就像人類所做的一樣。將抽象式摘要想象成一支鋼筆-它能生成或許不屬於源文檔的新句子。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e8fdebde6c7e4994a21f3802ed091d8c><p class=pgc-img-caption></p></div><p><em>鋼筆 = 抽象式摘要</em></p><p>由於抽象式機器學習算法能夠生成表示源文本中最重要信息的新短語和句子，所以這些抽象式算法有助於克服抽取式摘要中的語法不準確問題。</p><p>如下例所示：</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a70fefc16106485dad742c38df058718><p class=pgc-img-caption></p></div><p><em>抽象式摘要。</em></p><p>儘管抽象式文本摘要的表現更好，但開發相關算法需要複雜的深度學習技巧和語言模型。</p><p>為了獲得合理產出，抽象式摘要方法必須能夠解決諸多自然語言處理問題，如自然語言生成、語義表徵和推理排序（inference permutation）。</p><p>同樣地，抽取式文本摘要方法依然大受歡迎。在本文中，我們將重點介紹抽象式文本摘要方法。</p><p><strong>如何執行文本摘要</strong></p><p>我們使用以下一段話展示如何執行文本摘要抽取：</p><p>我們依照以下步驟對這段話作總結，同時儘可能保留原意。</p><p><strong>第一步：將這段話轉換成句子</strong></p><p>首先，我們將這段話分割成相應的句子。轉換成句子的最佳方法是在句點（period）出現時提取一個句子。</p><p><strong>第二步：文本處理</strong></p><p>接下來，我們在文本處理中移除停止詞（那些沒有實際意義的常見詞，如「and」和「the」）、數字、標點符號以及句子中的其他特殊字符。</p><p>句子成分的過濾有助於移除冗餘和不重要的信息，這些信息對文本意圖的表達或許沒有任何價值。</p><p>以下是文本處理結果：</p><p><strong>第三步：分詞</strong></p><p>切分各個句子，列出句子中的所有單詞。</p><p>以下是單詞列表：</p><pre>['peter','elizabeth','took','taxi','attend','night','party','city','party','elizabeth','collapse','rush','hospital', 'diagnose','brain', 'injury', 'doctor','told','peter','stay','besides','get','well','peter', 'stayed','hospital','days','without','leaving']</pre><p><strong>第四步：評估單詞的加權出現頻率（occurrence frequency）</strong></p><p>緊接著，我們計算所有單詞的加權出現頻率。為此，我們用每個單詞的出現頻率除以這段話中出現最多次的單詞的頻率，在這段話中出現最多的是 Peter，總共出現了三次。</p><p>下表給出了每個單詞的加權出現頻率。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cb2f7995edcc445aa8c942c448f818f1><p class=pgc-img-caption></p></div><p><strong>第五步：用相應的加權頻率替代原句中的各個單詞，然後計算總和。</strong></p><p>我們在文本處理步驟中已經移除了停止詞和特殊字符等無關緊要的單詞，因而它們的加權頻率為零，也就沒有必要在計算時加上。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cd8a72e4c0e342b68cf36f7fc9a1d51f><p class=pgc-img-caption></p></div><p>根據所有單詞的加權頻率總和，我們可以推導出：第一個句子在整段話中的權重最大。所以，第一個句子能夠對這段話的意思作出最具代表性的總結。</p><p>此外，如果第一個句子與第三個句子（該句的權重在整段話中排第二）相結合，則可以作出更好的總結。</p><p>以上例子只是基本說明了如何在機器學習中執行抽取式文本摘要。現在，我們看看如何在創建實際摘要生成器中運用上述概念。</p><p><strong>維基百科文章的文本摘要</strong></p><p>讓我們動手創建一個可以簡化冗長 web 文章中信息的文本摘要生成器。為簡單起見，除了 Python 的 NLTK toolkit，我們不使用任何其他機器學習庫（machine learning library）。</p><p>以下是摘要生成器的代碼 blueprint：</p><pre># Creating a dictionary for the word frequency tablefrequency_table = _create_dictionary_table(article)# Tokenizing the sentencessentences = sent_tokenize(article)# Algorithm for scoring a sentence by its wordssentence_scores = _calculate_sentence_scores(sentences, frequency_table)# Getting the thresholdthreshold = _calculate_average_score(sentence_scores)# Producing the summaryarticle_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)print(article_summary)</pre><p>依照下列步驟使用 Python 語言創建一個簡單的文本摘要生成器。</p><p><strong>第一步：準備數據</strong></p><p>在這個例子中，我們想總結一下這篇 Wikipedia 文章的信息，這篇文章只是對 20 世紀發生的主要事件進行概述。</p><p>為了獲取這篇文章的文本，我們將使用 Beautiful Soup 庫。</p><p>以下是抓取文章內容的代碼：</p><pre>import bs4 as BeautifulSoupimport urllib.request # Fetching the content from the URLfetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')article_read = fetched_data.read()# Parsing the URL content and storing in a variablearticle_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')# Returning &lt;p&gt; tagsparagraphs = article_parsed.find_all('p')article_content = ''# Looping through the paragraphs and adding them to the variablefor p in paragraphs:  article_content += p.text</pre><p>在以上代碼中，我們首先導入抓取網頁數據所必需的庫。BeautifulSoup 庫用於解析網頁內容，而 urllib library 用於連接網頁和檢索 HTML。</p><p>BeautifulSoup 將輸入文本轉化為 Unicode 字符，將輸出文本轉化為 UTF-8 字符，省去了從 web 上抓取文本時處理不同字符集編碼的麻煩。</p><p>我們使用 urllib.request 程序中的 urlopen 函數打開網頁。之後，使用 read 函數讀取所抓取的數據對象。為了解析數據，我們調用 BeautifulSoup 對象，並向它傳遞兩個參數，即 article_read 和 html.parser。</p><p>find_all 函數用於傳回 HTML 中出現的所有&lt;p>元素。此外，.text 使我們只能選擇&lt;p>元素中的文本。</p><p><strong>第二步：處理數據</strong></p><p>為儘可能確保廢棄的文本數據無噪聲，我們將執行一些基本的文本清理（text cleaning）。為協助完成這一處理過程，我們將從 NLTK 庫中導入一個停止詞列表。</p><p>我們還將引入 PorterStemmer，這是一種將單詞還原成詞根形式的算法。例如，單詞 cleaning、cleaned 和 cleaner 都可以還原成詞根 clean。</p><p>此外，我們還將創建一個包含文本中每一單詞出現頻率的字典表。我們將依次讀取文本及相應單詞，以消除所有停止詞。</p><p>之後，我們將檢查單詞是否出現在 frequency_table 中。如果一個單詞之前就在字典中，則其值更新 1。否則，如果一個單詞首次被識別到，則其值設置為 1。</p><p>例如，頻率表應如下所示：</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8dc88fd94e2a410a996128241a872f94><p class=pgc-img-caption></p></div><p>代碼如下：</p><pre>from nltk.corpus import stopwordsfrom nltk.stem import PorterStemmerdef _create_dictionary_table(text_string) -&gt; dict: # Removing stop words stop_words = set(stopwords.words("english")) words = word_tokenize(text_string) # Reducing words to their root form stem = PorterStemmer() # Creating dictionary for the word frequency table frequency_table = dict() for wd in words: wd = stem.stem(wd) if wd in stop_words: continue if wd in frequency_table: frequency_table[wd] += 1 else: frequency_table[wd] = 1 return frequency_table</pre><p><strong>第三步：將文章分割成句子</strong></p><p>為了將 article_content 分割成一個句子集，我們將使用 NLTK 庫中的內置方法。</p><pre>from nltk.tokenize import word_tokenize, sent_tokenizesentences = sent_tokenize(article)</pre><p><strong>第四步：確定句子的加權頻率</strong></p><p>為了評估文本中每個句子的分數，我們將分析每個單詞的出現頻率。在這種情況下，我們將根據句子中的單詞對該句進行評分，也就是加上句子中每個重要單詞的出現頻率。</p><p>請看以下代碼：</p><pre>def _calculate_sentence_scores(sentences, frequency_table) -&gt; dict:  # Algorithm for scoring a sentence by its words sentence_weight = dict() for sentence in sentences: sentence_wordcount = (len(word_tokenize(sentence))) sentence_wordcount_without_stop_words = 0 for word_weight in frequency_table: if word_weight in sentence.lower(): sentence_wordcount_without_stop_words += 1 if sentence[:7] in sentence_weight: sentence_weight[sentence[:7]] += frequency_table[word_weight] else: sentence_weight[sentence[:7]] = frequency_table[word_weight] sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words return sentence_weight</pre><p>重要的是，為了避免長句的分數必然高於短句，我們用每個句子的分數除以該句中的單詞數。</p><p>另外，為了優化字典內存，我們任意添加 sentence[:7]，這指的是每個句子的前七個字符。但在較長的文檔中，你很可能遇到具有相同首個 n_chars 的句子，這時最好使用哈希函數（hash function）或 index 函數（index function）來處理此類極端情況（edge-cases），避免衝突。</p><p><strong>第五步：計算句子閾值</strong></p><p>為了進一步調整適合摘要的句子類型，我們將創建句子的平均分。藉助於這個閾值，我們可以避免選擇分數低於平均分的句子。</p><p>代碼如下：</p><pre>def _calculate_average_score(sentence_weight) -&gt; int: # Calculating the average score for the sentences sum_values = 0 for entry in sentence_weight: sum_values += sentence_weight[entry] # Getting sentence average value from source text average_score = (sum_values / len(sentence_weight)) return average_score</pre><p><strong>第六步：生成摘要</strong></p><p>最後，我們擁有了所有必需的參數，因而現在可以生成文章摘要了。</p><p>代碼如下：</p><pre>def _get_article_summary(sentences, sentence_weight, threshold): sentence_counter = 0 article_summary = '' for sentence in sentences: if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] &gt;= (threshold): article_summary += " " + sentence sentence_counter += 1 return article_summary</pre><p><strong>總結</strong></p><p>下圖展示了創建文本摘要算法的工作流程。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f39a83575d5747a98d6622b486fe7de7><p class=pgc-img-caption></p></div><p>以下是機器學習中簡單抽取式文本摘要生成器的完整代碼：</p><pre>#importing librariesfrom nltk.corpus import stopwordsfrom nltk.stem import PorterStemmerfrom nltk.tokenize import word_tokenize, sent_tokenizeimport bs4 as BeautifulSoupimport urllib.request #fetching the content from the URLfetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')article_read = fetched_data.read()#parsing the URL content and storing in a variablearticle_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')#returning &lt;p&gt; tagsparagraphs = article_parsed.find_all('p')article_content = ''#looping through the paragraphs and adding them to the variablefor p in paragraphs:  article_content += p.textdef _create_dictionary_table(text_string) -&gt; dict: #removing stop words stop_words = set(stopwords.words("english")) words = word_tokenize(text_string) #reducing words to their root form stem = PorterStemmer() #creating dictionary for the word frequency table frequency_table = dict() for wd in words: wd = stem.stem(wd) if wd in stop_words: continue if wd in frequency_table: frequency_table[wd] += 1 else: frequency_table[wd] = 1 return frequency_tabledef _calculate_sentence_scores(sentences, frequency_table) -&gt; dict:  #algorithm for scoring a sentence by its words sentence_weight = dict() for sentence in sentences: sentence_wordcount = (len(word_tokenize(sentence))) sentence_wordcount_without_stop_words = 0 for word_weight in frequency_table: if word_weight in sentence.lower(): sentence_wordcount_without_stop_words += 1 if sentence[:7] in sentence_weight: sentence_weight[sentence[:7]] += frequency_table[word_weight] else: sentence_weight[sentence[:7]] = frequency_table[word_weight] sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words return sentence_weightdef _calculate_average_score(sentence_weight) -&gt; int: #calculating the average score for the sentences sum_values = 0 for entry in sentence_weight: sum_values += sentence_weight[entry] #getting sentence average value from source text average_score = (sum_values / len(sentence_weight)) return average_scoredef _get_article_summary(sentences, sentence_weight, threshold): sentence_counter = 0 article_summary = '' for sentence in sentences: if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] &gt;= (threshold): article_summary += " " + sentence sentence_counter += 1 return article_summarydef _run_article_summary(article): #creating a dictionary for the word frequency table frequency_table = _create_dictionary_table(article) #tokenizing the sentences sentences = sent_tokenize(article) #algorithm for scoring a sentence by its words sentence_scores = _calculate_sentence_scores(sentences, frequency_table) #getting the threshold threshold = _calculate_average_score(sentence_scores) #producing the summary article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold) return article_summaryif __name__ == '__main__': summary_results = _run_article_summary(article_content) print(summary_results)</pre><p>點擊原文中的以下按鈕在 FloydHub Notebook 上運行代碼：</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5614476b4fab46008e00c0f03c09e226><p class=pgc-img-caption></p></div><p>在這個例子中，我們所採用的閾值是平均分的 1.5 倍。這個超參數值（hyperparameter value）在幾次試驗後為我們生成了良好的結果。當然，你可以根據自身的偏好對數值進行微調，並改進摘要生成效果。</p><p>下圖是 Wikipedia 文章的生成摘要。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/767859bbbb8d45a6aa0f45ab3c104e3f><p class=pgc-img-caption></p></div><p><em>使用文本摘要算法生成的 Wikipedia 文章摘要。</em></p><p>如你所見，運行代碼可以對冗長的 Wikipedia 文章進行總結，並簡要概述 20 世紀發生的主要事件。</p><p>儘管如此，我們還可以改進摘要生成器，使之更好地生成長篇幅文本的簡潔、精確摘要。</p><p><strong>更多內容</strong></p><p>當然，本文只是簡要介紹了機器學習中使用文本摘要算法所能實現的功能。</p><p>若想了解更多有關該主題，特別是抽象式文本摘要的知識，下面一些有用的資源可以為你提供幫助：</p><p>有沒有可能將兩種方法（抽象式和抽取式文本自動摘要）相結合？這是指針生成網絡（pointer generator network）的主要原理，該網絡通過結合抽取（指向）和抽象（生成）取得了最佳效果。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/39ef06705c1f4ff9936208e7d44521e9><p class=pgc-img-caption></p></div><p><em>圖源："Taming Recurrent Neural Networks for Better Summarization"</em></p><p>《WikiHow: A Large Scale Text Summarization Dataset》一文提出了一個新的大規模文本自動摘要數據集 WikiHow，該數據集包含提取自 WikiHow 在線知識庫的 230000 多篇文章。目前可用的大多數數據集的規模不足以訓練序列到序列模型，它們也許只能提供有限的摘要，並且更適合執行抽取式摘要。但是，WikiHow 數據集規模大，質量高，能夠在抽象式文本摘要中獲得最優結果。</p><p>《Pretraining-Based Natural Language Generation for Text Summarization》一文提出了一個基於序列到序列範式的獨特二階段模型。該模型同時在編碼器和解碼器側利用 BERT，並在學習過程中注重強化目標。當該模型在一些基準數據集上進行評估時，結果顯示，該方法在文本自動摘要中表現更好，尤其相較於其他傳統系統而言。</p><div class=pgc-img><img alt="文章太長不想看？ML 文本自動摘要了解一下" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f4e49df539f641a584e33e4da48514e6><p class=pgc-img-caption></p></div><p><em>原文鏈接：https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/</em></p><p><strong>本文為機器之心編譯，轉載請聯繫本公眾號獲得授權。</strong></p><p>✄------------------------------------------------</p><p><strong>加入機器之心（全職記者 / 實習生）：hr@jiqizhixin.com</strong></p><p><strong>投稿或尋求報道：content@jiqizhixin.com</strong></p><p><strong>廣告 & 商務合作：bd@jiqizhixin.com</strong></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>太長</a></li><li><a>ML</a></li><li><a>自動</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html alt=方大九鋼檢測部推出生石灰自動取樣器 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/31adec60.html title=方大九鋼檢測部推出生石灰自動取樣器>方大九鋼檢測部推出生石灰自動取樣器</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html alt=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/74f03106.html title=方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好>方大九鋼：給石灰粉自動取樣器腔體洗“鹽酸浴”效果好</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html alt=excel小技巧：自動求和，當新增數據時自動求和 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523970520159b755ba89ba style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/06708c4c.html title=excel小技巧：自動求和，當新增數據時自動求和>excel小技巧：自動求和，當新增數據時自動求和</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1e731346.html alt=太長高速新增固定測速儀，出行的小夥伴們早了解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/567f00029a264d177efb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1e731346.html title=太長高速新增固定測速儀，出行的小夥伴們早了解>太長高速新增固定測速儀，出行的小夥伴們早了解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html alt=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4e8a4e07bff64e6db5dcef502221fa45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f65108b5.html title=37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀>37.3度以上自動報警！實時體溫監測，揭祕“抗疫神器”紅外熱像儀</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html alt=「乾貨」自動噴水滅火系統三大報警閥組原理探索 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/46846030db1d42069626e2365af33521 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ede488a4.html title=「乾貨」自動噴水滅火系統三大報警閥組原理探索>「乾貨」自動噴水滅火系統三大報警閥組原理探索</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html alt=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49a393b8.html title=「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求>「注消每日考點」自動噴水滅火系統“報警閥組”的現場檢查要求</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html alt=新版自動噴水滅火系統規範：第六章-報警閥組 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15251639042140ad0c55a7b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2699be3e.html title=新版自動噴水滅火系統規範：第六章-報警閥組>新版自動噴水滅火系統規範：第六章-報警閥組</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html alt=消防自動噴淋糸統的溼式式報警閥組的工作原理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f728f8c921f4740983ffec87a508565 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0634c992.html title=消防自動噴淋糸統的溼式式報警閥組的工作原理>消防自動噴淋糸統的溼式式報警閥組的工作原理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/830c83f4.html alt=溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/526e34ac258043fe92a9f2f078ea5a6c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/830c83f4.html title=溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！>溼式報警閥彙總，自動噴水滅火系統最重要的部件，消防必會知識！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c73c40a0.html alt=自動噴水滅火系統溼式報警閥組成及原理圖 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9ba360b558964895b7024e2057d4d331 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c73c40a0.html title=自動噴水滅火系統溼式報警閥組成及原理圖>自動噴水滅火系統溼式報警閥組成及原理圖</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8caf26ac.html alt=自動噴水滅火系統（8）報警閥組的設置 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/616c3e2a-0421-408e-b7b3-e74d6bcf420f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8caf26ac.html title=自動噴水滅火系統（8）報警閥組的設置>自動噴水滅火系統（8）報警閥組的設置</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a4446818.html alt=PLC自動控制系統的可靠性分析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/d4269003-f30a-4f2d-8344-2d22662baa75 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a4446818.html title=PLC自動控制系統的可靠性分析>PLC自動控制系統的可靠性分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6e3ed1e.html alt=球閥工作密封自動退出的故障分析及改進 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5e8b000510040f13bd40 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6e3ed1e.html title=球閥工作密封自動退出的故障分析及改進>球閥工作密封自動退出的故障分析及改進</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0d4103f5.html alt=提高打樁效率的利器——PLD自動提樁器服務於非洲大地 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/15368088647768a7f6f372d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0d4103f5.html title=提高打樁效率的利器——PLD自動提樁器服務於非洲大地>提高打樁效率的利器——PLD自動提樁器服務於非洲大地</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>