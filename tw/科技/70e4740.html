<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>從看臉到讀心：深度理解人的視覺技術走到哪了？ | 极客快訊</title><meta property="og:title" content="從看臉到讀心：深度理解人的視覺技術走到哪了？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/Rz4NtRe1Dx4ENF"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70e4740.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/70e4740.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/70e4740.html><meta property="article:published_time" content="2020-10-29T20:51:06+08:00"><meta property="article:modified_time" content="2020-10-29T20:51:06+08:00"><meta name=Keywords content><meta name=description content="從看臉到讀心：深度理解人的視覺技術走到哪了？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/70e4740.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>從看臉到讀心：深度理解人的視覺技術走到哪了？</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NtRe1Dx4ENF><p>作者 | 蔣寶尚</p><p><strong>編輯 | 賈偉</strong></p><p>AI 正在嘗試攻克“讀心術”。</p><p>隨著人臉識別為代表的“看臉”技術已經逐漸走向成熟，越來越多的科學家正在攻克這個難題。利用AI算法，捕捉面部特徵所承載的多維信息，分析推斷一個人精神狀況，從人工智能的角度就變成了輸入表情，輸出性格、情緒、心理活動的“函數”映射問題。其中輸入的特徵可以是微表情，也可以是視線等；輸出結果可以是喜怒哀樂等情緒。</p><p>舉例來說，荷蘭阿姆斯特丹大學的尼克·瑟比博士曾利用現代的深度學習方法對蒙娜麗莎的“情緒"進行破解，發現蒙娜麗莎有83%的快樂，9%的厭惡，6%的恐懼，還有2%的憤怒。</p><p>蒙娜麗莎情緒分析或許有些“玩”的意味，但是它背後所採用的技術對於醫學、情感陪伴、金融保險都有非常重要的意義。例如客觀化、易於實施的自閉症兒童早期診斷技術、能讀懂老人情感和狀態的機器人交互技術、對司機危險駕駛行為的監控和報技術等等。</p><p>具體來看，目前醫學上在精神疾病的診斷更多依賴於量表測試和醫生面診，診斷結果更偏向主觀性。看病就醫時，中醫通過“望聞問切”的“望”來了解患者的病徵，作出診斷；而心理醫生面診時也會通過觀察病人面容來判斷病人在精神層面的狀態。以抑鬱症患者為例，傳統方法下，醫生通常會採取三種檢查手段來判斷病人是否患有抑鬱症以及患病的程度，分別是：面診、量表測試和腦電波測試。而採用計算機視覺技術可有助實現非接觸性檢查。</p><p><strong>1 抑鬱症分析</strong></p><p>我們先來看人工智能在抑鬱症分析上的應用。</p><p>AI在自閉症兒童早期診斷上，整個過程大致有兩個步驟：首先是利用各種傳感器，記錄社交行為或個體行為過程；然後通過AI技術分析兒童的行為特徵。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NtSMIFW4uKa><p>兩個步驟各有難點，例如眼神捕捉的傳感器就不能用普通的攝像頭，而需要比較貴重的眼動儀。採用AI分析技術的時候，需要考慮視點特徵，例如看圖時的關注點模式，視線的移動模式；表情特徵，例如表情豐富度，表情模仿能力，表情解讀能力；社交特徵，例如眼神對視多少，互動方式等等。這裡面用的技術包括：視線估計技術，表情識別技術面部動作識別數據挖掘技術等等。</p><p>目前關於此類分析，已經得出了一些孤獨症（ASD）視點特徵結論：</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NtTF7LZ4SwU><p>ASD視點特徵結論</p><p>基於此，AI 在抑鬱症診斷上的應用也不斷凸顯，來自澳大利亞堪培拉大學以及新南威爾士大學和ANU等就採用人工定義特徵的方法分別對30個重度抑鬱症患者和30個健康人進行了測試。</p><p>具體而言，人工定義的特徵包括語音與語言特徵，例如詞彙數量，停頓數，說話時長；眼神特徵，例如東張西望，眨眼率；頭部姿態特徵，例如頭朝向變化率，各個朝向的時長。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/Rz4NtUE6mmULST><p>此項測試實驗結果表明，如果用副語言特徵就會做到83%，用眼動行為能做到73%，用頭部估計能做到63%，融合之後能夠做到88%的精度。因為只有60個人的數據，且有30個是重度抑鬱症，所以這個結果差強人意。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NtUuHCpiTlK><p>但人工定義特徵更多的是傳統的“專家模式”，2018年，採用深度學習的方法，《IEEE Transactions on Affective Computing》期刊中的一項工作將表徵信息和動態信息分兩路饋送到CNN網絡裡面，然後輸出一個抑鬱分數（Depression Score）。訓練數據是AVEC2013的一個子集，包含82個人的150段視頻。整個結果做到了7.58的MAE精度。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NuGxDsr6tLB><p>更進一步，斯坦福大學的李飛飛，2018在NeurIPS上也曾介紹了一項基於3D表情和語音的抑鬱症評估，核心是用多模態的數據進行分析。模型由兩個技術部分組成：（i）一個句子級的“概要”嵌入（嵌入的目的是“概括”一個可變長度的序列，將它變為固定大小的數字向量。）和（ii）一個因果卷積網絡（C-CNN）。實驗分為兩部分。首先與現有測量抑鬱症症狀嚴重程度的工作進行了比較，預測PHQ評分，並輸出關於患者是否患有重度抑鬱症的二元分類，通常PHQ評分大於或等於10。對模型進行消融研究之後特異性和敏感度分別做到了82.6%和83.3%。</p><p><strong>2 心率分析</strong></p><p>除了抑鬱症，學界也在想辦法通過看臉分析心率，作為人體最基礎的一種生理信號之一，能反映人的身體健康狀況甚至情緒狀態。傳統的心率測量通常依賴於接觸式的傳感器，比如較為精準的心電圖以及便攜式的指夾式心率儀等，這些方法心率估計的精度通常較好，但同時因為需要接觸人體皮膚，限制了其使用的便利性。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NuRU7KMhfWW><p>遠距離/非接觸式光體積變化描記圖法估計能夠克服這個限制，背後的原理非常清楚，即每一次心跳都會有相應的血流量變化對應，這表現在臉上，即皮膚對光線吸收的週期性變化。當然，這個信號非常微弱。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/Rz4NuSZE6w4cxm><p>此類工作在國際上已經有一段時間的發展了。</p><p>2008年是一個節點，在此之前主要還是做接觸式的心率分析。2008年之後開始有一些工作，基於攝像頭拍攝人的面部，通過週期性變化來估計心跳的次數。</p><p>最初的方式是基於獨立元分析：先找出心率的週期性信號，然後通過傅里葉變換、頻率分析等，估計出週期/頻率。</p><p>上述的工作主要是基於物理模型，從臉部皮膚中分割出一個典型的區域，然後提取顏色變化信息，進行頻譜分析，然後估計人的生理特徵。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NuTPCHMvo9F><p>深度學習的出現再次改變了這個領域的研究方法。</p><p>2018年，中科院計算所山世光研究員提出了一種基於深度學習的方法：直接把提取信號送到神經網絡中進行學習。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/Rz4NuU8IvmMjnZ><p>具體而言，其提出的是一個名為RhythmNet的端到端的可訓練心率評估器，利用AI和光電容積脈搏波描記法來應對頭部運動和光線變化方面的挑戰。整個過程分為三部分：在ImageNet上預訓練，然後將數據饋送到深度神經網絡裡面，最後對真實人臉心率信號精調。</p><p>但是訓練過程中數據量小成了約束。當時最大的人臉心率數據集也不超過50人，深度模型容易過擬合。於是他想到人為加上弱週期性的信號去完成預訓練，如此便能生成大量的數據。實驗結果在標準數據集上HRrmse做到了4.49（最好的指標是6.23）。</p><p>但是用來訓練的數據存在一個問題——人的心率分佈是不均衡的。大多數人的心率都集中在60到90之間。120、130此類的數據非常少。用這樣的數據做訓練，顯然會存在偏差。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NvIC9y4YxtJ><p>山世光采用的方法是對人臉心率數據增廣，即在時域中進行上、下采樣，這樣訓練集裡面的心率的數據範圍就會更加的廣泛，且能獲得相對更均勻的心率數據。</p><p><strong>3 微表情分析</strong></p><p>對微表情的研究，方法上類似人臉識別，包含檢測和識別兩個具體問題。</p><p>具體來說，就是先從一段長視頻中把發生微表情的視頻片段檢測出來，然後識別該微表情屬於哪一類微表情。</p><p>微表情檢測，就是指在一段視頻流中，檢測出是否包含微表情，並標記微表情的起點(onset)、峰值(apex)和終點(offset)。起點(onset) 是指微表情出現的時間；峰值(apex) 是指微表情幅度最大的時間; 終點(offset) 是指微表情消失的時間。</p><p>微表情識別是指給定一個已經分割好的微表情片斷，通過某種算法，識別該微表情的情緒種類（例如厭惡、悲傷、驚訝、憤怒、恐懼、快樂等）。如同三維動態表情識別一樣，其處理的對象是視頻片斷，而不只是單幅圖像。對其處理過程中，不僅要考慮空間上的模式，還要考慮時間上的模式。所以許多微表情識別的算法都考慮了時空模式。</p><p>事實上對於微表情研究，最難的是如何收集足夠多的、質量高的微表情數據集。目前，微表情現有的數據庫樣本量都非常小，公開發表的微表情樣本只有不到800個。因此微表情研究是典型的小樣本問題。這也是造成當前基於深度學習的方法在微表情問題上無法完全發揮出它應有威力的主要原因。</p><p>中科院計算所山世光提到過一項基於視頻流的自監督特徵表達方法，通過巧妙利用自監督約束信號，得到提純的面部動作特徵用於微表情識別。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/Rz4NvJd152bF39><p>總體的框架</p><p>區別於當前人臉區域分塊、注意力機制等方法學習人臉局部區域的AU特徵，這類方法在訓練階段需要利用精確標註的AU標籤，由於目前業界發佈的AU數據集人數及圖像總量不足，採用監督學習方法訓練得到的模型往往呈現出在特定數據集上的過擬合現象，他們提出了一種能夠在不依賴AU標籤的前提下，從人臉視頻數據中自動學習AU表徵的方法（Twin-Cycle Autoencoder，簡稱TCAE）。TCAE用於後續的AU識別任務時，只需要利用訓練數據訓練一個分類器即可，顯著減少了所需的訓練數據，並提升了模型的泛化能力。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NvLQJHuHu0x><p>考慮到兩幀人臉圖像之間的運動信息包含了AU以及頭部姿態的運動分量，TCAE通過利用巧妙的自監督約束信號，使得模型能夠分離出AU變化引起的運動分量，以及頭部姿態變化引起的運動分量，從而得到提純的AU特徵。與其他監督方法，TCAE可以利用大量的無標註人臉視頻，這類視頻是海量的。與半監督或者弱監督方法相比， TCAE採用了自監督信號進行模型訓練，避免了對數據或者標籤的分佈做出任何假設。</p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/Rz4NvMLCHpW8Sm><p>無論是抑鬱症分析，還是微表情識別，從國內、國外的研究進展看，視覺智能已經從最初的看臉走向了對人的更深層次的分析。更為準確的說，人臉識別在過去的5年時間裡面，有了一個跨越式的進步，人臉識別之戰基本上已經接近尾聲，以後更多的考慮如何將應用落地，如何將技術應用到各站業務場景。</p><p><em>via 從看臉到讀心：深度理解人的視覺技術進展</em><em>http://www.itdks.com/Live/detail?id=29041</em></p><img alt=從看臉到讀心：深度理解人的視覺技術走到哪了？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RyIeyA5oMGiCx><p>ACL 2020原定於2020年7月5日至10日在美國華盛頓西雅圖舉行，因新冠肺炎疫情改為線上會議。為促進學術交流，方便國內師生提早了解自然語言處理（NLP）前沿研究，AI 科技評論將推出「ACL 實驗室系列論文解讀」內容，同時歡迎更多實驗室參與分享，敬請期待！</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>臉到</a></li><li><a>讀心</a></li><li><a>視覺</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html alt=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1530929302432561dc6cda6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html title=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價>機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/403ada1f.html alt=航攝中如何掌控視覺差異 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6554/5338856107 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/403ada1f.html title=航攝中如何掌控視覺差異>航攝中如何掌控視覺差異</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html alt=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/519b968bf69146fda9bf55f89779d373 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html title=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質>基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1a697cad.html alt=視覺享受的進化!顯示技術的分類和演進 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1a697cad.html title=視覺享受的進化!顯示技術的分類和演進>視覺享受的進化!顯示技術的分類和演進</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cc025c3f.html alt=來自封測官視覺—珠海潮門裡巷的第一場廣華米粉品鑑會 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a5106bbff49f4935b42c19b3abe5fcb7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cc025c3f.html title=來自封測官視覺—珠海潮門裡巷的第一場廣華米粉品鑑會>來自封測官視覺—珠海潮門裡巷的第一場廣華米粉品鑑會</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b792ed3a.html alt=機器視覺檢測設備的外觀缺陷檢測的原理淺析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/35e3f8d87f5d4c96937309010c5a5ec7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b792ed3a.html title=機器視覺檢測設備的外觀缺陷檢測的原理淺析>機器視覺檢測設備的外觀缺陷檢測的原理淺析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ab89c564.html alt=機器視覺表面缺陷檢測綜述 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/bd400c5fc7d049df8d5ce365faec81f6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ab89c564.html title=機器視覺表面缺陷檢測綜述>機器視覺表面缺陷檢測綜述</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/af8d9e1a.html alt=機器視覺表面缺陷檢測設備綜述 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b75804e4e383426595973d8b7b2b2c6f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/af8d9e1a.html title=機器視覺表面缺陷檢測設備綜述>機器視覺表面缺陷檢測設備綜述</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d23e1957.html alt=CCD視覺檢測設備外觀缺陷檢測功能介紹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4a6904c2f55c4e27b12951e9d9580755 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d23e1957.html title=CCD視覺檢測設備外觀缺陷檢測功能介紹>CCD視覺檢測設備外觀缺陷檢測功能介紹</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6938b43a.html alt=【乾貨】機器視覺檢測基礎——鏡頭篇（1） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ad30e323d1c749d98d78304890799ce1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6938b43a.html title=【乾貨】機器視覺檢測基礎——鏡頭篇（1）>【乾貨】機器視覺檢測基礎——鏡頭篇（1）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bfbcef65.html alt=印刷質量缺陷的視覺檢測原理概述 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/08950fffb8f447888dbe20c0bf9e672f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bfbcef65.html title=印刷質量缺陷的視覺檢測原理概述>印刷質量缺陷的視覺檢測原理概述</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7ff8bb95.html alt=工作場景下的視覺篩查 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/152259909123671d94d80e7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7ff8bb95.html title=工作場景下的視覺篩查>工作場景下的視覺篩查</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/50af5e85.html alt=工業機器人「視覺檢測」的原理剖析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2a361cbe48874f73892d766805cbb40a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/50af5e85.html title=工業機器人「視覺檢測」的原理剖析>工業機器人「視覺檢測」的原理剖析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/31c4b4f2.html alt=手機屏幕缺陷視覺檢測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7f7b55b4ee6741059aff7914cb40a135 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/31c4b4f2.html title=手機屏幕缺陷視覺檢測>手機屏幕缺陷視覺檢測</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>