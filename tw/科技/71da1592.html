<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>Hadoop之HDFS | 极客快訊</title><meta property="og:title" content="Hadoop之HDFS - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/1cea562f356248cc81e9df66fdf8b0a1"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/71da1592.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/71da1592.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/71da1592.html><meta property="article:published_time" content="2020-11-14T21:03:23+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:23+08:00"><meta name=Keywords content><meta name=description content="Hadoop之HDFS"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/71da1592.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>Hadoop之HDFS</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right><strong><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">HDFS重要概念</span></strong></h1><ul><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">典型的Master/Slave架構<br>HDFS往往是由一個NameNode（HA架構會有兩個NameNode，聯邦機制）和多個DataNode組成</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">分塊存儲（Block機制）<br>HDFS中的文件在物理上是分塊存儲，塊的大小可調整，2.x版本block大小默認是128M。當文件大於128M，將文件切片存儲</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">命名空間(NameSpace)<br>HDFS支持傳統的層次型文件組織結構。用戶可以創建目錄，可以創建、刪除、移動、重命名文件<br>NameNode 複製維護文件系統的名字空間，任何對文件系統名字空間或屬性的修改</span><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">都護</span><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">被NameNode記錄下來<br>HDFS提供給客戶一個單一抽象的目錄樹，因為數據都存放在DataNode中，不會去顯示存放到哪個DataNode,是把多個DataNode抽象成一個目錄樹，客戶端訪問形式：hdfs://namenode:namenode的port/test/input 即 hdfs://linux121:9000/test/input</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">NameNode的元數據管理<br>目錄結構、文件分塊位置信息叫做元數據，NameNode的元數據記錄每個文件所存放的block信息（block的ID及所在的DataNode節點的信息）</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">DataNode數據儲存<br>文件存放在Block中，而Block的具體管理由DataNode節點承擔，一個Block會有多個DataNode存儲，DataNode會定時相關NameNode彙報自己持有的Block的信息</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">副本機制<br>為了容錯，文件所有的block都有副本，大小和數量都可以配置，副本不是以某個文件而是以整個block備份。副本的默認數量是3個</span></li><li><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">一次寫入，多次讀出<br>HDFS適合一起寫入，多次讀出，不支持隨機修改，支持追加寫入操作。不適合做網盤</span></li></ul><h1 class=pgc-h-arrow-right><strong><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">HDFS架構</span></strong></h1><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1cea562f356248cc81e9df66fdf8b0a1><p class=pgc-img-caption>HDFS架構圖.png</p></div><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/045e34d9b838472ba11659c7ce9d6134><p class=pgc-img-caption>HDFS架構中文版本.png</p></div><ul><li>客戶端 上傳文件到HDFS的時候，Client負責文件的切分Block，然後進行上傳 向DataNode負責上傳下載文件 與NameNode交互，獲取文件Block位置信息</li><li>NameNode 維護管理HDFS的名稱空間（NameSpace） 維護副本策略 記錄文件塊（Block）的映射信息 處理客戶端的讀寫請求</li><li>DataNode 實際存儲Block數據 負責Block讀寫數據 複製（副本）</li></ul><h1 class=pgc-h-arrow-right><strong>Shell命令行操作HDFS</strong></h1><p>查看某個命令的具體用法，如cat的用法</p><pre><code>hadoop fs -help cat</code></pre><p>查看某個目錄下面的文件,例如根目錄(查看的是HDFS的根目錄)</p><pre><code>hdfs dfs -ls /</code></pre><p>創建一個目錄,在根目錄下面創建一個lg和自己bigdata</p><pre><code>hadoop fs -mkdir -p /lagou/bigdata</code></pre><p>從本地移動(剪切粘貼)個文件到服務器</p><pre><code>hadoop fs -moveFromLocal ./test.txt /lagou/bigdata</code></pre><p>查看一個文件內容</p><pre><code> hadoop fs -cat /lagou/bigdata/test.txt</code></pre><p>追加寫入</p><pre><code>#生產一個hdfs.txt的文件，隨便寫點內容vim hdfs.tx#執行追加寫入 hadoop fs -appendToFile ./hdfs.tx /lagou/bigdata/test.txt</code></pre><p>修改文件權限</p><pre><code>hadoop fs -chmod 777 /lagou/bigdata/test.txt</code></pre><p>修改用戶組</p><pre><code>hadoop fs -chown root:root /lagou/bigdata/test.txt</code></pre><p>從本地移動(複製粘貼)個文件到服務器</p><pre><code>hadoop fs -copyFromLocal ./test.txt /lagou/bigdatahadoop fs -put ./test.txt /lagou/bigdata</code></pre><p>從HDFS移動（複製粘貼）到本地</p><pre><code>hadoop fs -corpToLocal /lagou/bigdata/test.txt ./hadoop fs -get /lagou/bigdata/test.txt ./</code></pre><p>刪除空文件夾</p><pre><code>hadoop fs -rmdir /test</code></pre><p>顯示一個文件的末尾</p><pre><code>hadoop fs -tail /lagou/bigdata/test.txt</code></pre><p>統計文件夾大小信息</p><pre><code>hadoop fs -du -s -h /lagou/bigdata </code></pre><p>統計文件大小信息</p><pre><code>hadoop fs -du -s -h /lagou/bigdata/test.txt</code></pre><p>設置HDFS副本數量</p><pre><code>hadoop fs -setrep 10 /test/input/test2.txt</code></pre><p><strong>這裡設置副本數量只是記錄在NameNode裡面，具體有沒有十個副本需要看有多少個DataNode，因為目前只有3臺機器，最有也就三個副本，只有節點數增加到10臺的時候，副本數量才會達到10個。所以，文件真正的副本數量取決於DataNode數量</strong></p><h1 class=pgc-h-arrow-right><strong>使用Idea鏈接HDFS</strong></h1><p>導入pom.xml</p><pre><code>&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;        &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;        &lt;version&gt;2.8.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;        &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;        &lt;version&gt;2.9.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;        &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;        &lt;version&gt;2.9.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;        &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;        &lt;version&gt;2.9.2&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>代碼：</p><pre><code>package com.hhb.hdfs;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.*;import org.apache.hadoop.fs.permission.FsPermission;import org.apache.hadoop.io.IOUtils;import org.junit.After;import org.junit.Before;import org.junit.Test;import java.io.File;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.net.URI;import java.net.URISyntaxException;/** * @Date: 2020-07-02 14:47 * @Description: */public class HdfsClient {    private FileSystem fileSystem = null;    private Configuration configuration = null;    @Before    public void init() throws URISyntaxException, IOException, InterruptedException {        // 1. 獲取Hadoop集群configuration對象        configuration = new Configuration();        //設置客戶端訪問datanode使用hostname來進行訪問        configuration.set("dfs.client.use.datanode.hostname", "true");        // 設置副本數量,生效的優先級，代碼裡的  &gt;  配置文件 &gt; hadoop-hdfs.jar 裡的默認hdfs-default.xml配置//        configuration.set("dfs.replication", "2");        // 2. 根據configuration對象獲取FileSystem對象        fileSystem = FileSystem.get(new URI("hdfs://linux121:9000"), configuration, "root");    }    @After    public void destroy() throws IOException {        fileSystem.close();    }    /**     * 創建目錄     *     * @throws URISyntaxException     * @throws IOException     * @throws InterruptedException     */    @Test    public void testMkdirs() throws URISyntaxException, IOException, InterruptedException {//        // 1. 獲取Hadoop集群configuration對象//        Configuration configuration = new Configuration();//        configuration.set("fs.defaultFs", "hdfs://linux121:9000");//        // 2. 根據configuration對象獲取FileSystem對象//        FileSystem fileSystem = FileSystem.get(new URI("hdfs://linux121:9000"), configuration, "root");        // 3. 使用FileSystem對象創建一個測試目錄        boolean mkdirs = fileSystem.mkdirs(new Path("/api_test"));        System.err.println(mkdirs);        // 4. 釋放FileSystem對象//        fileSystem.close();    }    /**     * 創建目錄     *     * @throws IOException     */    @Test    public void testMkdirs2() throws IOException {        // 1. 獲取Hadoop集群configuration對象//        Configuration configuration = new Configuration();//        configuration.set("fs.defaultFS", "hdfs://linux121:9000");//        // 2. 根據configuration對象獲取FileSystem對象//        FileSystem fileSystem = FileSystem.get(configuration);        // 3. 使用FileSystem對象創建一個測試目錄        boolean mkdirs = fileSystem.mkdirs(new Path("/api_test"));        System.err.println(mkdirs);        // 4. 釋放FileSystem對象//        fileSystem.close();    }    /**     * 上傳文件     */    @Test    public void copyFromLocalToHDFS() throws IOException {        fileSystem.copyFromLocalFile(new Path("/Users/baiwang/Desktop/yarn-site.xml"), new Path("/api_test"));    }    /**     * 下載文件     */    @Test    public void copyFromHDFSToLocal() throws IOException {        // 第一個參數：表示是否刪除源文件        fileSystem.copyToLocalFile(true, new Path("/api_test/yarn-site.xml"), new Path("/Users/baiwang/Desktop/"));    }    /**     * 刪除文件     *     * @throws IOException     */    @Test    public void deleteFile() throws IOException {        //第二個參數表示是否遞歸刪除        fileSystem.delete(new Path("/api_test"), true);    }    /**     * 遍歷HDFS的根目錄，得到文件以及文件夾信息：名稱，權限，長度     *     * @throws IOException     */    @Test    public void listsFile() throws IOException {        //第二個參數表示是否遞歸，該方法返回的一個迭代器，裡面存放的是文件狀態信息        RemoteIterator&lt;LocatedFileStatus&gt; remoteIterator = fileSystem.listFiles(new Path("/"), true);        while (remoteIterator.hasNext()) {            LocatedFileStatus fileStatus = remoteIterator.next();            //文件名稱            String name = fileStatus.getPath().getName();            //文件大小            long len = fileStatus.getLen();            //獲取權限            FsPermission permission = fileStatus.getPermission();            //獲取分組信息            String group = fileStatus.getGroup();            //獲取所屬用戶            String owner = fileStatus.getOwner();            System.err.println(name + "\t" + len + "\t" + permission + "\t" + group + "\t" + owner);            //塊信息            BlockLocation[] blockLocations = fileStatus.getBlockLocations();            for (BlockLocation blockLocation : blockLocations) {                String[] hosts = blockLocation.getHosts();                for (String host : hosts) {                    System.err.println("主機名稱：" + host);                }            }            System.err.println("============");        }    }    /**     * 判讀是文件還是文件夾     *     * @throws IOException     */    @Test    public void isFile() throws IOException {        FileStatus[] fileStatuses = fileSystem.listStatus(new Path("/"));        for (FileStatus fileStatus : fileStatuses) {            boolean file = fileStatus.isFile();            if (file) {                System.err.println("文件：" + fileStatus.getPath().getName());            } else {                System.err.println("文件夾：" + fileStatus.getPath().getName());            }        }    }    /**     * 使用IO流操作HDFS     */    @Test    public void uploadFileIO() throws IOException {        //1. 獲取本地輸入流        FileInputStream fileInputStream = new FileInputStream(new File("/Users/baiwang/Desktop/yarn-site.xml"));        //2. 獲取寫數據的輸出流        FSDataOutputStream fsDataOutputStream = fileSystem.create(new Path("/lagou.txt"));        //3. 輸入流數據拷貝到輸出流,copyBytes方法裡有默認拷貝值大小（4096），也有是否關閉流的操作（true）        IOUtils.copyBytes(fileInputStream, fsDataOutputStream, configuration);    }    /**     * 使用IO流下載文件     */    @Test    public void downLoadFileIO() throws IOException {        //1. 獲取HDFS輸入流        FSDataInputStream fsDataInputStream = fileSystem.open(new Path("/lagou.txt"));        //2. 獲取寫數據的輸出流        FileOutputStream fileOutputStream = new FileOutputStream(new File("/Users/baiwang/Desktop/hhb.xml"));        //3. 輸入流數據拷貝到輸出流,copyBytes方法裡有默認拷貝值大小（4096），也有是否關閉流的操作（true）        IOUtils.copyBytes(fsDataInputStream, fileOutputStream, configuration);    }    /**     * seek 定位讀取,使用IO流把lagou.txt     */    @Test    public void seekReadFile() throws IOException {        //獲取HDFS輸入流        FSDataInputStream fsDataInputStream = fileSystem.open(new Path("/lagou.txt"));        //將輸入流複製到控制檯中，false表示不會自動關閉流        IOUtils.copyBytes(fsDataInputStream, System.out, 4096, false);        //將輸入流複製到控制檯中。遊標在最後的位置，現在將遊標指向最前面        fsDataInputStream.seek(0);        //將輸入流複製到控制檯中，false表示不會自動關閉流        IOUtils.copyBytes(fsDataInputStream, System.out, 4096, false);        //關閉輸入流        fsDataInputStream.close();    }      /**     * 驗證上傳文件是以packet為單位     * 現象：     * 當 hhb.xml 中無信息，不輸出===     * 當 hhb.xml 中信息大於0KB，小於64KB，輸出兩個 ===     * 當 hhb.xml 中信息大於64KB，小於128KB，輸出三個 ===     * 原因：     * 當hhb.xml中無信息的時候，不會與NameNode交互，所以不會輸出，當產生交互的時候，就會先輸出一個====。     * 然後每次上傳64KB，所小於64KB的時候會輸出兩個。一個是建立鏈接時候的輸出，一個是上傳數據的輸出     *     * @throws IOException     */    @Test    public void testUploadFile() throws IOException {        FileInputStream fileInputStream = new FileInputStream(new File("/Users/baiwang/Desktop/hhb.xml"));        FSDataOutputStream fsDataOutputStream = fileSystem.create(new Path("/lagou.txt"), () -&gt; {                    System.err.println("===");                }        );        IOUtils.copyBytes(fileInputStream, fsDataOutputStream, configuration);    }}</code></pre><p>問題：上傳文件的時候報錯，如圖</p><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c2e70326b89948a5824f6e5b9d7e9f3c><p class=pgc-img-caption>Client上傳文件報錯.png</p></div><p>原因：客戶端創建文件先訪問NameNode服務器進行創建文件Meta信息，以及文件樹，此時訪問的的NameNode的IP，NameNode服務器創建文件成功後，會返回對應dataNode的服務器節點，但此時的節點信息中的ip是與NameNode在同一網絡下的內網IP，客戶端是無法訪問，也就無法寫入<br>解決：在客戶端中，或者服務器端etc/hadoop/hdfs-site.xml中配置</p><pre><code>conf.set("dfs.client.use.datanode.hostname","true");//設置客戶端訪問datanode使用hostname來進行訪問</code></pre><p>使用此配置服務端返回的就是在NameNode的控制檯中相應的DataNode對應的HttpAddress</p><h1 class=pgc-h-arrow-right><strong>HDFS讀寫解析</strong></h1><h1 class=pgc-h-arrow-right><strong>HDFS讀數據流程</strong></h1><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/883560f48ff8473491477ab0ea703392><p class=pgc-img-caption>HDFS讀數據流程.png</p></div><ol start=1><li>客戶端通過Distributed FileSystem向NameNode請求下載文件，NameNode通過查詢元數據找到文件塊所在的DataNode地址。NameNode返回的數據：目標文件的塊信息以及所在節點的信息，NameNode是分批返回給的客戶端，客戶端讀取完後獲取下一批。</li><li>客戶端挑選一條DataNode（物理距離，就近原則，然後隨機）服務器，請求讀取數據。</li><li>DataNode開始傳輸數據給客戶端，（從磁盤裡面讀取數據輸入流，以Packet為單位來做校驗，Packet大小為64Kb）</li><li>客戶端以Packet為單位接收，現在本地緩存，然後寫入目標文件</li></ol><h1 class=pgc-h-arrow-right><strong>HDFS寫數據的流程</strong></h1><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/297400de865e4e4bae42494ea7513eb7><p class=pgc-img-caption>HDFS寫數據的流程.png</p></div><ol start=1><li>客戶端通過Distributed FileSystem模塊向NameNode請求上傳文件，NameNode檢查目標文件是否存在，目標文件夾是否存在。</li><li>NameNode返回是否可以上傳</li><li>客戶端請求第一個Block上傳到那幾個DataNode服務器上</li><li>NameNode返回3個DataNode節點，分別為dn1、dn2、dn3.</li><li>客戶端通過FSDataOutputStream模塊請求dn1上傳數據，dn1收到請求會繼續調用dn2，然後dn2調用dn3，將這個通信管道建立完成。</li><li>dn1、dn2、dn3逐級應答客戶端</li><li>客戶端開始往dn1上傳第一個block（先從磁盤讀取數據放到一個本地內存緩存），以Packet為單位，dn1收到一個Packet就會傳給dn2，dn2傳給dn3，dn1沒傳一個packet會放入到確認隊列等待確認,等待dn2、dn3確認數據傳輸完成</li><li>當一個Block傳輸完成之後，客戶端再次請求NameNode上傳第二個block的服務器（重複執行3-7）</li></ol><p><strong>一邊寫入，一邊實現副本同步，這樣雖然上傳數據比較慢，但是保證了數據的安全</strong></p><h1 class=pgc-h-arrow-right><strong>NN與2NN</strong></h1><h1 class=pgc-h-arrow-right><strong>HDFS元數據管理機制</strong></h1><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5e7af16492bd4106923a48cd47621f2a><p class=pgc-img-caption>元數據管理流程圖.png</p></div><ul><li>第一階段：NameNode啟動 第一次啟動NameNode格式化後，創建fsImages（生成慢，恢復快）和Edits（生成快，恢復慢）文件，如果不是第一次啟動，直接加載編輯日誌和鏡像文件到內存。 客戶端對元數據進行增刪改的請求 NameNode記錄操作日誌，更新滾動日誌 NameNode在內存中對數據進行增刪改。</li><li>第二階段：Secondary NameNode（輔助NameNode維護元數據管理）工作 2nn詢問nn是否需要CheckPoint，直接帶回nn是否執行檢察點操作結果 2nn請求執行CheckPoint。 nn滾動正在寫的Edits日誌 將滾動前的編輯日誌和鏡像文件拷貝到2nn 2nn加載編輯日誌和鏡像文件到內存併合並 生產新的鏡像文件fsimage.chkpoint 拷貝fsimage.chpoint到nn nn將fsimage.chpoint 重新命名為fsimage</li></ul><p>checkPoint觸發時機</p><ol start=1><li>到定時時間</li><li>Edits編輯文件滿。<br>Fsimage、edits存放路徑：</li></ol><pre><code>/opt/lagou/servers/hadoop-2.9.2/data/tmp/dfs/name/current</code></pre><h1 class=pgc-h-arrow-right><strong>FsImage 與Edits 文件解析</strong></h1><p>NameNode在執行格式化之後，會在/opt/lg/servers/hadoop-2.9.2/data/tmp/dfs/name/current目錄下生成文件：</p><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6a48fd6b710d42dda0c02b4c2b4226c7><p class=pgc-img-caption>FsImage與Edites文件解析.png</p></div><ul><li>FsImage文件：是NameNode中元數據的鏡像，一般被稱為檢查點，包含HDFS文件系統所有目錄及文件相關信息（Block數量、副本數量、權限）</li><li>Edits文件：存儲的是客戶端對HDFS的增刪改操作</li><li>*.md5文件： 校驗文件。</li><li>seen_txid保存的是一個數字，對應著最後一個Edits文件名的數字</li><li>VERSION：記錄namenode的一些版本號信息，比如custerID，namespaceId</li></ul><p>NameNode啟動時會將FsImage加載到內存中，同時將之前沒有合併到元數據的Edits文件加載，集合兩個文件的元數據，這樣保證了內存中的元數據是最新最全的，</p><h1 class=pgc-h-arrow-right><strong>查看FsImage文件內容</strong></h1><pre><code>## hdfs oiv -p 文件類型（就是fsimage轉成什麼類型）-i 鏡像文件 -o 輸出路徑cd /opt/lagou/servers/hadoop-2.9.2/data/tmp/dfs/name/currenthdfs oiv -p XML -i fsimage_0000000000000000505 -o /opt/hhb.xml</code></pre><p>hhb.xml文件內容</p><pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;fsimage&gt;  &lt;version&gt;    &lt;layoutVersion&gt;-63&lt;/layoutVersion&gt;    &lt;onDiskVersion&gt;1&lt;/onDiskVersion&gt;    &lt;oivRevision&gt;826afbeae31ca687bc2f8471dc841b66ed2c6704&lt;/oivRevision&gt;  &lt;/version&gt;    &lt;NameSection&gt;    &lt;namespaceId&gt;853376951&lt;/namespaceId&gt;    &lt;genstampV1&gt;1000&lt;/genstampV1&gt;    &lt;genstampV2&gt;1045&lt;/genstampV2&gt;    &lt;genstampV1Limit&gt;0&lt;/genstampV1Limit&gt;    &lt;lastAllocatedBlockId&gt;1073741867&lt;/lastAllocatedBlockId&gt;    &lt;txid&gt;505&lt;/txid&gt;  &lt;/NameSection&gt;    &lt;INodeSection&gt;    &lt;lastInodeId&gt;16473&lt;/lastInodeId&gt;    &lt;numInodes&gt;38&lt;/numInodes&gt;    &lt;inode&gt;      &lt;id&gt;16385&lt;/id&gt;      &lt;type&gt;DIRECTORY&lt;/type&gt;      &lt;name/&gt;      &lt;mtime&gt;1593694994111&lt;/mtime&gt;      &lt;permission&gt;root:supergroup:0777&lt;/permission&gt;      &lt;nsquota&gt;9223372036854775807&lt;/nsquota&gt;      &lt;dsquota&gt;-1&lt;/dsquota&gt;    &lt;/inode&gt;      &lt;inode&gt;      &lt;id&gt;16386&lt;/id&gt;      &lt;type&gt;DIRECTORY&lt;/type&gt;      &lt;name&gt;test&lt;/name&gt;      &lt;mtime&gt;1593598825098&lt;/mtime&gt;      &lt;permission&gt;root:supergroup:0777&lt;/permission&gt;      &lt;nsquota&gt;-1&lt;/nsquota&gt;      &lt;dsquota&gt;-1&lt;/dsquota&gt;    &lt;/inode&gt;      。。。  &lt;/INodeSection&gt;    &lt;INodeReferenceSection/&gt;  &lt;SnapshotSection&gt;    &lt;snapshotCounter&gt;0&lt;/snapshotCounter&gt;    &lt;numSnapshots&gt;0&lt;/numSnapshots&gt;  &lt;/SnapshotSection&gt;    &lt;INodeDirectorySection&gt;    &lt;directory&gt;      &lt;parent&gt;16385&lt;/parent&gt;      &lt;child&gt;16471&lt;/child&gt;      &lt;child&gt;16448&lt;/child&gt;      &lt;child&gt;16473&lt;/child&gt;    &lt;/directory&gt;   &lt;/INodeDirectorySection&gt;    &lt;FileUnderConstructionSection/&gt;    &lt;SecretManagerSection&gt;    &lt;currentId&gt;0&lt;/currentId&gt;    &lt;tokenSequenceNumber&gt;0&lt;/tokenSequenceNumber&gt;    &lt;numDelegationKeys&gt;0&lt;/numDelegationKeys&gt;    &lt;numTokens&gt;0&lt;/numTokens&gt;  &lt;/SecretManagerSection&gt;  &lt;CacheManagerSection&gt;    &lt;nextDirectiveId&gt;1&lt;/nextDirectiveId&gt;    &lt;numDirectives&gt;0&lt;/numDirectives&gt;    &lt;numPools&gt;0&lt;/numPools&gt;  &lt;/CacheManagerSection&gt; &lt;/fsimage&gt;</code></pre><p><strong>Fsimage裡面是不記錄block所在的節點信息的，是在集群啟動時，NameNode要求DataNode上報數據塊信息，並間隔一段時間再次上報，這麼做的理由是因為如果FsImage裡記錄了DataNode信息，但是DataNode掛了，NameNode拿著歷史的Fsimage加載到內容，記錄的是歷史數據，會導致數據不一致。</strong></p><h1 class=pgc-h-arrow-right><strong>查看Edits文件內容</strong></h1><pre><code>## hdfs oev -p 文件類型（就是edits轉成什麼類型）-i 編輯日誌 -o 輸出路徑cd /opt/lagou/servers/hadoop-2.9.2/data/tmp/dfs/name/currenthdfs oiv -p XML -i fsimage_0000000000000000505 -o /opt/hhb.xml</code></pre><p>hhb2.xml文件內容</p><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;EDITS&gt;  &lt;EDITS_VERSION&gt;-63&lt;/EDITS_VERSION&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_START_LOG_SEGMENT&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;414&lt;/TXID&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_SET_GENSTAMP_V2&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;415&lt;/TXID&gt;      &lt;GENSTAMPV2&gt;1044&lt;/GENSTAMPV2&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_REASSIGN_LEASE&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;416&lt;/TXID&gt;      &lt;LEASEHOLDER&gt;DFSClient_NONMAPREDUCE_-968919369_1&lt;/LEASEHOLDER&gt;      &lt;PATH&gt;/api_test&lt;/PATH&gt;      &lt;NEWHOLDER&gt;HDFS_NameNode-2020-07-02 20:31:54,840+0800&lt;/NEWHOLDER&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_CLOSE&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;417&lt;/TXID&gt;      &lt;LENGTH&gt;0&lt;/LENGTH&gt;      &lt;INODEID&gt;0&lt;/INODEID&gt;      &lt;PATH&gt;/api_test&lt;/PATH&gt;      &lt;REPLICATION&gt;3&lt;/REPLICATION&gt;      &lt;MTIME&gt;1593693116738&lt;/MTIME&gt;      &lt;ATIME&gt;1593689482882&lt;/ATIME&gt;      &lt;BLOCKSIZE&gt;134217728&lt;/BLOCKSIZE&gt;      &lt;CLIENT_NAME&gt;&lt;/CLIENT_NAME&gt;      &lt;CLIENT_MACHINE&gt;&lt;/CLIENT_MACHINE&gt;      &lt;OVERWRITE&gt;false&lt;/OVERWRITE&gt;      &lt;PERMISSION_STATUS&gt;        &lt;USERNAME&gt;root&lt;/USERNAME&gt;        &lt;GROUPNAME&gt;supergroup&lt;/GROUPNAME&gt;        &lt;MODE&gt;420&lt;/MODE&gt;      &lt;/PERMISSION_STATUS&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_TIMES&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;418&lt;/TXID&gt;      &lt;LENGTH&gt;0&lt;/LENGTH&gt;      &lt;PATH&gt;/lagou.txt&lt;/PATH&gt;      &lt;MTIME&gt;-1&lt;/MTIME&gt;      &lt;ATIME&gt;1593693390155&lt;/ATIME&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_TIMES&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;419&lt;/TXID&gt;      &lt;LENGTH&gt;0&lt;/LENGTH&gt;      &lt;PATH&gt;/yarn-site.xml&lt;/PATH&gt;      &lt;MTIME&gt;-1&lt;/MTIME&gt;      &lt;ATIME&gt;1593693395993&lt;/ATIME&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_END_LOG_SEGMENT&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;420&lt;/TXID&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;&lt;/EDITS&gt;</code></pre><h1 class=pgc-h-arrow-right><strong>CheckPoint的週期</strong></h1><p>hdfs-default.xml</p><pre><code>&lt;!-- 定時一小時 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;    &lt;value&gt;3600&lt;/value&gt;&lt;/property&gt;&lt;!-- 一分鐘檢查一次操作次數，當操作次數達到1百萬時，SecondaryNameNode執行一次 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;    &lt;value&gt;1000000&lt;/value&gt;    &lt;description&gt;操作動作次數&lt;/description&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;    &lt;value&gt;60&lt;/value&gt;    &lt;description&gt; 1分鐘檢查一次操作次數&lt;/description&gt;&lt;/property &gt;</code></pre><h1 class=pgc-h-arrow-right><strong>NameNode故障處理</strong></h1><p>NameNode故障後，HDFS集群就無法正常工作，因為HDFS文件系統的元數據需要NameNode來管理並與Client交互，如果元數據損壞和丟失也會有同樣的問題</p><p>如果元數據丟失如何恢復？</p><ol start=1><li>將2NN的元數據拷貝到NN 但是這種情況會存在元數據丟失</li><li>搭建HDFS的HA（高可用集群），解決NN的單點故障問題！藉助zk實現HA，一個是Active的NameNode，一個是Standby的NameNode</li></ol><h1 class=pgc-h-arrow-right><strong>Hadoop的限額與歸檔以及集群安全模式</strong></h1><h1 class=pgc-h-arrow-right><strong>高級命令</strong></h1><ul><li>HDFS文件限額 HDFS文件的限額配置允許我們以文件大小或者文件個數來限制我們在某個目錄下上傳文件數量或者文件內容。以便我們達到類似百度網盤限制每個用戶上傳的最大文件量</li></ul><ol start=1><li>數量限制</li></ol><pre><code># 對hhb文件夾上傳數量限制，設置為2，實際限制為2-1hdfs dfsadmin -setQuota 2  /hhb# 上傳文件。成功hdfs dfs -copyFromLocal /root/wc.txt /hhb/# 再次上傳，報錯，錯誤：copyFromLocal: The NameSpace quota (directories and files) of directory /hhb is exceeded: quota=2 file count=3hdfs dfs -copyFromLocal /root/wc.txt /hhb/hhh.txt# 清除限額,再次上傳，成功hdfs dfsadmin -clrQuota /hhb</code></pre><ol start=2><li>空間大小限制</li></ol><pre><code># 對hhb文件夾上傳空間限制，設置為4KBhdfs dfsadmin -setSpaceQuota 4K /hhb# 上傳文件報錯：put: The DiskSpace quota of /hhb is exceeded: quota = 4096 B = 4 KB but diskspace consumed = 402653646 B = 384.00 MBhdfs dfs -put /opt/lagou/software/hadoop-2.9.2.tar.gz /hhb/# 清除限制空間大小,再次上傳，上傳成功hdfs dfsadmin -clrSpaceQuota /hhb</code></pre><ul><li>HDFS安全模式 HDFS集群啟動時需要加載FsImage和Edits文件，而這兩個文件都沒有記錄Block對應的DataNode信息，如果client請求下載文件，集群是不能工作的 <strong>安全模式</strong>是HDFS所處的一種特殊狀態，在這種狀態下，文件系統<strong>只接受讀數據請求，而不接受刪除、修改等變更請求</strong>，在NameNode主節點啟動時，HDFS首先進入安全模式，DataNode在啟動時會向NameNode彙報可用的Block等狀態，當整個系統達到安全標準時，HDFS自動離開安全模式，如果HDFS處於安全模式下，則文件Block不能進行任何的副本複製操作，因此達到最小副本數量是要求基於DataNode啟動時的狀態來判定的，啟動時不會做任何惡德複製（從而達到最小副本數量要求），HDFS集群剛啟動的時候，默認30時間時處於安全期的，只有過了30後，集群脫離安全期，然後才可以對集群進行過操作。</li></ul><pre><code>## 進入安全模式hdfs dfsadmin -safemode enter## 退出安全模式hdfs dfsadmin -safemode leave #在頁面的Summary模塊的第二行可以看見當前集群處於不處於安全模式 </code></pre><ul><li>Hadoop歸檔技術</li></ul><p><strong>主要解決HDFS集群存在大量小文件的問題。</strong></p><p>由於大量的小文件會佔用NameNode的內存，因此存儲大量小文件會造成NameNode內存資源的浪費。</p><p>Hadoop存檔文件HAR文件，是一個高效的文件存檔工具，HAR文件是由一組文件通過archive工具創建而來，在減少了NameNode的內存使用的同時，可以對文件進行透明防問，通俗來說就是HAR文件對NameNode來說是一個文件減少了內存的浪費，對於實際操作還是一個個獨立的文件。<br></p><div class=pgc-img><img alt=Hadoop之HDFS onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/09c2836e66f244e8b3137f71ddedf618><p class=pgc-img-caption>HAR文件歸檔.png</p></div><p>目前hhb目錄下有兩個小文件,執行命令</p><pre><code>hadoop archive -archiveName hhb.har -p /hhb /hhbhar</code></pre><p>在hhbhar目錄下就會有hhb.har文件,展示hhb.har文件內容</p><pre><code>hdfs dfs -ls -R /hhbhar/hhb.har </code></pre><p>內容：</p><pre><code>-rw-r--r--   3 root supergroup          0 2020-07-04 14:37 /hhbhar/hhb.har/_SUCCESS-rw-r--r--   3 root supergroup        188 2020-07-04 14:37 /hhbhar/hhb.har/_index-rw-r--r--   3 root supergroup         23 2020-07-04 14:37 /hhbhar/hhb.har/_masterindex-rw-r--r--   3 root supergroup        154 2020-07-04 14:37 /hhbhar/hhb.har/part-0</code></pre><p>在hhbhar目錄下就會有hhb.har文件,展示hhb.har文件內容</p><pre><code> hdfs dfs -ls -R har:///hhbhar/hhb.har</code></pre><p>內容：</p><pre><code>-rw-r--r--   3 root supergroup         77 2020-07-04 14:11 har:///hhbhar/hhb.har/hhh.txt-rw-r--r--   3 root supergroup         77 2020-07-04 14:09 har:///hhbhar/hhb.har/wc.txt</code></pre><p>將/hhb文件夾下面的內容刪除，然後將hhb.har內容解壓過去</p><pre><code>hdfs dfs -rm /hhb/*hdfs dfs -ls /hhbhdfs dfs -cp har:///hhbhar/hhb.har/* /hhb/hdfs dfs -ls /hhb</code></pre></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Hadoop</a></li><li><a>HDFS</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/161b2693.html alt="HDFS 作為分佈式文件管理系統，帶你瞭解Hadoop的基礎" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f360780b4e864e2f9d2b66bfee88366f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/161b2693.html title="HDFS 作為分佈式文件管理系統，帶你瞭解Hadoop的基礎">HDFS 作為分佈式文件管理系統，帶你瞭解Hadoop的基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5b9be76b.html alt=Hadoop分佈式文件系統架構和設計原理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c200950907404ad4bfb1d0172e71b4ef style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5b9be76b.html title=Hadoop分佈式文件系統架構和設計原理>Hadoop分佈式文件系統架構和設計原理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7963f320.html alt=分佈式文件系統HDFS class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/5c0384a2fdf14a1f9c53757ff8fedaeb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7963f320.html title=分佈式文件系統HDFS>分佈式文件系統HDFS</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1e7f6bbc.html alt=只知道HDFS和GFS？你其實並不懂分佈式文件系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d7aca794643c45b6b15489b271e39355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1e7f6bbc.html title=只知道HDFS和GFS？你其實並不懂分佈式文件系統>只知道HDFS和GFS？你其實並不懂分佈式文件系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cd1b81d8.html alt=淺析HDFS架構和設計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/5ab2c36d649e4f21b0ceacc2d36d0d49 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cd1b81d8.html title=淺析HDFS架構和設計>淺析HDFS架構和設計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bd6e9ab.html alt="EB 級 HDFS 集群磁帶存儲資源池的建設實踐" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3e250f81cde3466b83907cf56dfc18a6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bd6e9ab.html title="EB 級 HDFS 集群磁帶存儲資源池的建設實踐">EB 級 HDFS 集群磁帶存儲資源池的建設實踐</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>