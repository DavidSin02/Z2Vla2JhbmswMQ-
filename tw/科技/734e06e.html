<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計 | 极客快訊</title><meta property="og:title" content="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RixptB9J7gzdZC"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/734e06e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/734e06e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/734e06e.html><meta property="article:published_time" content="2020-10-29T21:01:05+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:05+08:00"><meta name=Keywords content><meta name=description content="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/734e06e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RixptB9J7gzdZC><p><em>內容來自將門計算機視覺主題社群</em></p><p><em>作者：黃駿傑</em></p><p>本文為<strong>將門好聲音</strong><strong>第20</strong><strong>期</strong>。</p><p>論文作者是來自</p><blockquote toutiao-origin=span>將門計算機視覺主題社群、中國科學院自動化所的黃駿傑，本次他將與大家分享其一作論文：人體姿態估計中無偏的數據處理方法。</blockquote><p>在「將門好聲音」</p><p toutiao-origin=span>不僅可以分享你最新的研究工作，更可以分享跟技術相關的乾貨觀點、出坑經驗等，點擊</p><strong>“閱讀原文”</strong><strong toutiao-origin=span>或聯繫將門小姐姐！只要內容合適，我"門"送你頭條出道！</strong><p></p><h2 toutiao-origin=h6><strong>關於作者</strong></h2><p>黃駿傑，中國科學院自動化研究所19屆碩士，算法研究員，主要的研究方向是人體姿態估計和視覺伺服。</p><p>個人主頁：<strong class=highlight-text toutiao-origin=span>https://huangjunjie2017.github.io</strong></p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RixptBl6MWnOgR><ul><li><p>論文鏈接:</p></li></ul><p><strong class=highlight-text toutiao-origin=span>https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">xi</i>v.org/abs/1911.07524</strong></p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RWvRrxT7bPqVHJ><p class=pgc-img-caption>數據處理作為人體姿態估計算法的一個重要的組成部分，我們通過深入的研究發現現有的方法中普遍存在兩個問題：一個是在測試過程中由翻轉圖像得到的結果和由原圖得到的結果之間存在偏差，另外一個問題是現有的state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art方法所使用的編碼解碼方法存在較大的統計誤差。</p><p>這兩個問題耦合在一起，產生的影響包括：算法的精度較低、state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art指標復現困難和實驗結論不可靠。本文中，我們提出<strong class=highlight-text toutiao-origin=strong>用於人體姿態估計算法無偏的數據處理方法（UDP）</strong>。</p><p>UDP適用於所有top-down的方法，以幾乎可以忽略的計算代價，不僅僅把現有state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art算法的性能提升到前所未有的高度，同時通過詳細的剖析幫助大家深入瞭解用於人體姿態估計數據處理，並且為社區提供一個更加可靠的baseline以促進進一步的研究。</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RWvRrxw8jrLrPi><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RixptCGJFQHG3P><p></p><h1 toutiao-origin=h4><strong toutiao-origin=h1>背 景</strong></h1><p>多目標的人體姿態估計以檢測場景內所有人的關鍵點為目的，目前用於性能評估的公開數據集主要是COCO,方法主要有bottom-up(先檢測所有關鍵點，再做實例分析) 和 top-down(先檢測人，然後做單人的姿態估計)。所有計算機視覺任務都需要數據處理，同時，很多數據處理的方法在不同任務之間都是通用的，比如數據在座標系之間變換和樣本增廣等。這種通用性使得我們可以直接借鑑其他任務的數據處理方法，甚至複用其他任務的代碼。</p><p>然而，這種通用性也往往會讓人忽略不同任務對數據處理的特殊要求。根據不同任務的評測原理，我們可以總結他們對目標位置的<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">敏感</i>程度。其中分類是一個對目標位置不<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">敏感</i>的任務，而檢測和分割則是對目標位置<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">敏感</i>的任務。相比之下，關鍵點檢測是對目標位置極其<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">敏感</i>的任務，這是因為關鍵點評測會直接懲罰目標和真值之間的空間距離，存在於數據處理過程中的系統誤差會對算法的精度產生重大的影響。</p><p>在人體姿態top-down方法中的數據處理主要包括數據變換、數據增廣和編碼解碼。其中數據變換指的是樣本數據在不同座標系（原始數據、網絡輸入和網絡輸出）之間的變換。<strong>在這個過程中已知的方法使用像素去度量圖像的大小，這導致測試過程中由翻轉圖像得到的結果和原圖得到的結果不對齊。</strong>state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art方法中都憑經驗地在後處理中對這種不對齊進行補償，比如MSRA在SimpleBaseline和HRNet中對由翻轉圖像得到的結果shift了一個像素，這方法可以有效地緩解這種不對齊帶來的影響。Face++的CPN和MSPN在網絡輸入空間中對ensemble的結果（由翻轉圖像得到的結果和原圖得到的結果求均值）shift了兩個像素，有異曲同工之妙。</p><p>這些沒有解釋在paper裡的操作可以對算法的性能帶來巨大的提升，比如在HRNet-w32-256x192的backbone下在COCO val上可以有高達2.3AP的提升（73.3APvs75.6AP）。如此大幅度的影響使得這些技巧成為論文指標復現的關鍵，同時也拉開了這些方法和沒有這些技巧的方法的<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">差距</i>，使得在並不公平的條件下得到的對比實驗結果往往是不可靠的。這種不可靠使得很多很好的方法可能會被不理想的實驗結果所埋沒，畢竟可以在沒有這些技巧之下能在性能上超越這些state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art的方法還是很少的。</p><p>比如在本文中介紹的基於offset的編碼解碼方法（Google提出的）原本是一種很好的方法，但在沒有這些技巧的情況下用在HRNet-w32-256x192中，在COCO val 上的得分只有 74.5AP，和MSRA在同樣backbone下的指標（75.6AP）相比，這結果就相當不如人意了。</p><p>數據增廣是提高算法泛化性能的通用技巧，top-down的人體姿態估計中主要的策略有隨機旋轉、隨機裁剪、翻轉和半身監督。數據增廣一般是在數據從原始數據座標系轉換到網絡輸入座標系的過程中實現的。</p><p>編碼解碼是指把關鍵點的座標在訓練過程中編碼成易於網絡學習的形式，然後在測試過程再從網絡輸出解碼得到關鍵點座標的方法。編碼解碼被廣泛應用在state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art方法中，主流的做法（Face++的CPN和MSPN，MSRA的SimpleBaseline和HRNet）是使用以座標為中心的單高斯響應圖作為座標編碼解碼的媒介。而State-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art們在使用這種方法時存在較大的統計誤差。</p><p>Google在2017年時提出了一種基於offset設計的編碼解碼方法，這種方法在理想情況下（網絡學習能力完美）可以做到沒有統計誤差，但是卻沒有被廣泛應用在state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art方法中。此外，上個月電子科技大學提出Dark：一種可以達到二階泰勒展開精度的編碼解碼方法。我們的實驗結果顯示，Dark的性能表現和Google的方法在HRNet上幾乎一致，在SimpleBaseline上稍遜一籌（相差0.5AP左右）。這些方法都可以有效提高現有state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art算法的性能（1AP左右）。</p><p></p><h1 toutiao-origin=h4><strong toutiao-origin=h1>UDP——無偏的數據變換</strong></h1><p>我們在文章中詳細推導了在數據轉換過程中，使用像素作為圖像大小度量尺度（有偏的）以及使用對應座標系單位長度作為圖像大小度量尺度（無偏的）兩種情況的過程、結果以及影響，得到以下主要的結論。</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RixptPjCX6Oymh><p>首先，值得注意的一點是使用和不使用像素作為圖像大小的度量尺度，得到的用於網絡訓練的樣本在語義上都是和原樣本對齊的，因此如果在測試過程中不使用翻轉的圖像作ensemble的話，這兩種做法在性能表現上應該是一樣，對比實驗中得到的結果分別是74.5AP和74.4AP也驗證了這一點。</p><p>然而，我們以MSRA的SimpleBaseline和HRNet為例子，經過推導發現如果在測試過程中使用翻轉圖像作ensemble的話，由翻轉圖像得到的結果和由原圖得到的結果在<em>O</em><em>o</em><em>-</em><em>X</em><em>o</em>方向上存在<em>-(s-1)/s</em>大小的偏差。此處的s代表網絡輸入和輸出的大小比值（步長）。在CPN、MSPN、SimpleBaseline和HRNet中使用的步長都是4，對應的偏差是-0.75個單位距離，其均值誤差為0.375單位距離會對結果造成2.5AP的影響（75.8APvs73.3AP）；而MSRA把由翻轉圖像得到的結果在<em>O</em><em>o</em><em>-</em><em>X</em><em>o</em>方向上shift了一個像素，使得兩個結果的偏差縮小為0.25個單位距離。使得取均值後的誤差縮小為0.125個單位距離，對比實驗的結果顯示，這技巧可以把2.5AP的影響縮小為僅僅0.2AP的影響（75.8AP vs 75.6AP)。雖然在MSRA結果上直接補償這個0.125單位距離的剩餘誤差可以使得結果無偏，但相比之下使用<em>O</em><em>o</em><em>-</em><em>X</em><em>o</em>座標系中的單位長度去度量圖像的大小，可以直接得到無偏的估計結果，並且免去複雜的後處理環節。</p><p>此外，當我們把誤差映射回原圖的時候可以得到在原始樣本的座標系 <em>O</em><em>s</em><em>-</em><em>X</em>s<em>-</em><em>Y</em><em>s</em>中實際的誤差大小為:</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RixptPy9kD89pN><p>測試過程中邊界框的大小是固定的，使用更大的網絡輸入可以有效減少上述誤差帶來的影響。這也是為什麼現有的state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art都在非常大的輸入分辨率上做報告，低分辨率會使得現有state-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">of</i>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i>-art的性能大幅下降。</p><p></p><h1 toutiao-origin=h4><strong toutiao-origin=h1>無偏的編碼解碼方法</strong></h1><p>我們以MSRA所使用的編碼解碼方法為例子在網絡輸出空間中進行量化分析，在訓練過程中，他們把關鍵點的座標編碼為以關鍵點為中心的高斯響應圖：</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RixptQEDCl6AMa><p>然後在解碼的時候以相應圖的響應最大點的座標為基礎，通過梯度稍作正得到關鍵點的估計座標。該方法在理想情況下（網絡的學習能力完美），估計結果和真值之間的關係為：</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RixptQW2CHa8Lo><p>其中<strong>F </strong>和<strong>C</strong>函數分別表示向上和向下取整，m表示關鍵點在<em>O</em><em>o</em><em>-</em><em>X</em><em>o</em>方向上的座標值，離散的估計結果和真值間存在一定的統計誤差。</p><p>在這裡我們介紹兩種在理想情況下，誤差為零或者幾乎為零的編碼解碼方法。第一種是電子科技大學最近新提出的Dark，Dark也是使用高斯分佈的響應圖編碼關鍵點的座標，但是在推理解碼的時候，並非簡單的利用一階梯度作一個簡單修正。Dark利用響應圖分佈已知的特點，通過在響應最大值點附近利用二階泰勒展開求極值點的方法，去求取真正的中心點（根據高斯響應<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">最高</i>值點梯度為零）。這種方法理想情況下可以達到二階泰勒展開的精度。</p><p>另外一種是我們在論文中介紹的Google早在2017年就已經提出的基於offset的方法。這方法在訓練時把關鍵點座標編碼成三個通道的響應圖：</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RixptRG9vEw4rC><p>在解碼時通過在H中尋找響應最大值點k，並與offset圖中對應響應相加，即可在理想情況下達到零誤差的效果。</p><p>我們也做了這兩種方法的對比實驗，其中在COCOval上，使用HRNet-w32的backbone時，兩種方法的性能表現幾乎一樣。使用SimpleBaseline-R50的backbone時，Dark的性能稍遜一籌。當然，Google的方法因為監督增加會帶來少量的計算增量以及對IO傳輸要求更多。</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RixptdUC6CVfon><p>在test-dev上Google的方法在性能上會比Dark要好：</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RixptdpCxK40q6><p><em>*沒有使用無偏的數據轉換，據我們論文推理以及實驗經驗，這個在256x192的分辨率上會有0.2AP的性能損失，384x288的分辨率上損失會少於0.2AP</em></p><p></p><h1 toutiao-origin=h4><strong toutiao-origin=h1>實 驗</strong></h1><p>首先我們在COCOval上使用一個更好的人體檢測結果，重新跑了一遍SimpleBaseline和HRNet的結果，和使用UDP後的方法作公平對比，重新跑的結果會比原文的在AP上高一個點左右。</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/Rixpte7CEP3S9S><p>對比之下有兩點值得注意的是：</p><p>1.UDP在不同backbone上的提升相近，表明UDP具備通用性；</p><p>2.UDP在低輸入分辨率時帶來的提升更大，分辨率越低提升越顯著，UDP可以有效縮小高分辨率和低分辨率之間的性能差異，使得算法在性能和計算量之間取得更優的權衡。</p><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RixpteY6lBRigH><p>UDP在COCO test-dev2017上也有兩個值得注意的點：</p><p>1.UDP在test-dev上帶來的提升毫不遜色於其在val上帶來的提升，表明UDP所帶來的性能提升並非過擬合val數據集；</p><p>2.使用UDP和HRNet-W48-384x288的backbone，test-dev上的指標達到76.5AP，是已公開方法中<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">最高</i>的。</p><p></p><h1 toutiao-origin=h4><strong toutiao-origin=h1>總結</strong></h1><p>無偏的數據處理對於人體姿態估計任務非常重要，其重要性不僅體現在可以幫現有的方法取得更高的精度和更好的指標，還體現在是指標復現的關鍵點之一以及可以促進後續的研究。如果想要對文章中的理論細節和代碼實現有更深入的瞭解，請查看原文和作者主頁：</p><p>論文鏈接: <strong class=highlight-text toutiao-origin=span>https://ar<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">xi</i>v.org/abs/1911.07524</strong></p><p>個人主頁: <strong class=highlight-text toutiao-origin=span>https://huangjunjie2017.github.io</strong></p><p>項目代碼：<strong class=highlight-text toutiao-origin=span>https://github<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">.com</i>/HuangJunJie2017/UDP-Pose</strong></p><p></p><h2 toutiao-origin=h6>參考文獻</h2><p><em>[1]: Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll´ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European Conference on Computer V<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>ion, pages 740–755. Springer, 2014.</em></p><p><em>[2]: Bin Xiao, Haiping Wu, and Yichen Wei. <i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">Simple</i> baselines for human pose estimation and tracking. In European Conference on Computer V<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>ion, pages 466–481, 2018.</em></p><p><em>[3]: Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution representation learning for human pose estimation. In IEEE Conference on Computer V<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>ion and Pattern Recognition, 2019.</em></p><p><em>[4]: Yilun Chen, Zhicheng Wang, Yu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">xi</i>ang Peng, Zhiqiang Zhang, Gang Yu, and Jian Sun. Cascaded pyramid network for multi-person pose estimation. In IEEE Conferenceon Computer V<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>ion and Pattern Recognition, pages 7103–7112, 2018.</em></p><p><em>[5]: George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan Tompson, Chr<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i> Bregler, and Kevin Murphy. Towards accurate multi-person pose estimation in <i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">the</i> wild. In IEEE Conference on Computer V<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>ion and Pattern Recognition, pages 4903–4911, 2017.</em></p><p><em>[6]: Zhang F , Zhu X , Dai H , et al. D<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">is</i>tribution-Aware Coordinate Representation for Human Pose Estimation[J]. 2019.</em></p><p>來掃我呀</p><p>-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">The</i> End-</p><p><strong>將門</strong>是一家以專注於<strong>發掘、加速及投資技術驅動型<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">創業</i>公司</strong>的新型<strong>創投機構</strong>，旗下涵蓋</p><blockquote toutiao-origin=span>將門創新服務、將門技術社群以及將門創投基金。將門成立於2015年底，創始團隊由微軟創投在中國的創始團隊原班人馬構建而成，曾為微軟優選和深度孵化了126家創新的技術型<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">創業</i>公司。</blockquote><p><strong>將門創新服務</strong></p><blockquote toutiao-origin=span>專注於使創新的技術落地於真正的應用場景，激活和實現全新的商業價值，服務於行業領先企業和技術創新型<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">創業</i>公司。</blockquote><p><strong>將門技術社群</strong></p><blockquote toutiao-origin=span>專注於幫助技術創新型的<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">創業</i>公司提供來自產、學、研、創領域的核心技術專家的技術分享和學習內容，使創新成為持續的核心競爭力。</blockquote><p><strong>將門創投基金</strong></p><p toutiao-origin=span>專注於投資通過技術創新激活商業場景，實現商業價值的初創企業，<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">關注</i>技術領域包括</p><strong toutiao-origin=span>機器智能、物聯網、自然人機交互、企業計算。</strong><p toutiao-origin=span>在三年的時間裡，將門創投基金已經投資了包括量化派、碼隆科技、禾賽科技、寬拓科技、杉數科技、迪英加科技等數十傢俱有高成長潛力的技術型<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">創業</i>公司。</p><p></p><blockquote toutiao-origin=span>如果您是技術領域的初創企業，不僅想獲得投資，還希望獲得一系列持續性、有價值的投後服務，</blockquote>歡迎發送或者推薦項目給我“門”: bp@thejiangmen<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">.com</i><img alt="將門好聲音 | 中科院自動化所：無偏數據處理方法助你實現SOTA人體姿態估計" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/R6RrkaV5T8rQhn><p>點擊右上角，把文章朋友圈</p><p><strong>將門創投</strong></p><p>讓創新獲得認可！</p><p><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">微信</i>：thejiangmen</p><p>bp@thejiangmen<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">.com</i></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>將門</a></li><li><a>聲音</a></li><li><a>自動化</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca8037a5.html alt="1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/85515822d72a46eda621433ce5df7dfd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca8037a5.html title="1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom">1毛錢身板，千元級聲音！小巧得過分MQA音頻便攜解碼Hilidac Atom</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html alt=聲音錄製，用軟件算法模擬硬件也能出專業效果 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15374046796064ae0d9cd60 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c214d3b9.html title=聲音錄製，用軟件算法模擬硬件也能出專業效果>聲音錄製，用軟件算法模擬硬件也能出專業效果</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8c6ba3d5.html alt=聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/6f35099874d14909bcbded3a8e7d8a8e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8c6ba3d5.html title=聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？>聲音是如何被記錄的？其中又有哪些奇妙的發明和發現呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a73cf80a.html alt="自動化彈性伸縮如何支持百萬級核心錯峰混部 | 架構沙龍回顧" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/61d58d713ab649708f7796af3bc5f21b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a73cf80a.html title="自動化彈性伸縮如何支持百萬級核心錯峰混部 | 架構沙龍回顧">自動化彈性伸縮如何支持百萬級核心錯峰混部 | 架構沙龍回顧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e7cc472b.html alt=快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RMb7ATOIoTL1Cm style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e7cc472b.html title=快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！>快來為《中國好聲音》德宏賽區30強打call！5月4日我們總決賽見！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e6372c2e.html alt=數控機床自動化上下料機械手的好處 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e6372c2e.html title=數控機床自動化上下料機械手的好處>數控機床自動化上下料機械手的好處</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/714c8510.html alt=自動化上下料機械臂是由什麼要素組成？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5b430001856ca1491feb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/714c8510.html title=自動化上下料機械臂是由什麼要素組成？>自動化上下料機械臂是由什麼要素組成？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/71fa9ef1.html alt=9年自動化設備師傅告訴你各種液壓缸使用原理，解決你使用問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/823654fce7bf455b93e730e6da6322b3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/71fa9ef1.html title=9年自動化設備師傅告訴你各種液壓缸使用原理，解決你使用問題>9年自動化設備師傅告訴你各種液壓缸使用原理，解決你使用問題</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b9405916.html alt=自動化設備的維修與管理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b9405916.html title=自動化設備的維修與管理>自動化設備的維修與管理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/46550ad1.html alt=障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15345657066257a9443fa45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/46550ad1.html title=障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色>障板聲音好，無奈體積大，6.5寸低音箱結合小障板，聲音一樣出色</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/11b5ccf3.html alt=自動化設備機架結構的選擇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/4a12fefddc184e458b6484c906150bf5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/11b5ccf3.html title=自動化設備機架結構的選擇>自動化設備機架結構的選擇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/34e81298.html alt=自動化設備結構特點及運行方案 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2a9c996aa84845a0be7aad496355c5ae style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/34e81298.html title=自動化設備結構特點及運行方案>自動化設備結構特點及運行方案</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b792d28f.html alt=露珠滴落的聲音，像一首搖籃曲 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/402dd6727b364918b84928933b8154b7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b792d28f.html title=露珠滴落的聲音，像一首搖籃曲>露珠滴落的聲音，像一首搖籃曲</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e743ec99.html alt=愛奇藝全鏈路自動化監控平臺的探索與實踐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a251285ab0114113a21ddb71be44f4a3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e743ec99.html title=愛奇藝全鏈路自動化監控平臺的探索與實踐>愛奇藝全鏈路自動化監控平臺的探索與實踐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/32b90bfe.html alt=【自動化專題】工業視覺檢測之輪廓提取 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/240460904eee4b5b8c78588a816c223b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/32b90bfe.html title=【自動化專題】工業視覺檢測之輪廓提取>【自動化專題】工業視覺檢測之輪廓提取</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>