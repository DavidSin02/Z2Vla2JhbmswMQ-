<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>關於自然語言處理，數據科學家需要了解的 7 項技術 | 极客快訊</title><meta property="og:title" content="關於自然語言處理，數據科學家需要了解的 7 項技術 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/RkQWj5EIZaB6LJ"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/747c116b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/747c116b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/747c116b.html><meta property="article:published_time" content="2020-11-14T21:00:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:19+08:00"><meta name=Keywords content><meta name=description content="關於自然語言處理，數據科學家需要了解的 7 項技術"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/747c116b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>關於自然語言處理，數據科學家需要了解的 7 項技術</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RkQWj5EIZaB6LJ><p>作者 | George Seif</p><p>譯者 | 孫薇，責編 | 屠敏</p><p>頭圖 | CSDN 下載自東方 IC</p><p>出品 | CSDN（ID：CSDNnews）</p><p><strong>以下為譯文：</strong></p><p>現代公司要處理大量的數據。這些數據以不同形式出現，包括文檔、電子表格、錄音、電子郵件、JSON以及更多形式。這類數據最常用的記錄方式之一就是通過文本，這類文本通常與我們日常所使用的自然語言十分相似。</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RwTasNjmEJ0Ug><p>自然語言處理（NLP）是針對計算機編程的研究，探索處理和分析大量自然文本數據的方式。自然語言處理的知識對於數據科學家來說至關重要，因為文本是數據存儲中極為易用和常用的介質。</p><p>面對針對文本數據執行分析和構建模型的任務時，我們必須清楚要如何執行基礎的數據科學任務，包括清理、格式化、解析、分析、執行可視化和對文本數據建模。當數據還處於原始數字的構成形態時，除了這些任務的常規方法，還會需要一些額外的步驟。</p><p>本篇指南將對在數據科學中使用自然語言處理做基礎性的介紹，包括處理文本數據時最常用的7種技術，如NLTK及Scikit Learn等。</p><p><strong>(1) 標記化（Tokenization）</strong></p><p>標記化指的是將文本切分為句子或單詞，在此過程中，我們也會丟棄標點符號及多餘的符號。</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RwTasOICDYnp0g><p>這個步驟並非看起來那麼簡單。舉個例子：在上圖的實例中，“紐約（New York）”一詞被拆成了兩個標記，但紐約是個代名詞，在我們的分析中可能會很重要，因此最好只保留一個標記。在這個步驟中要注意這一點。</p><p>標記化的好處在於，會將文本轉化為更易於轉成原始數字的格式，更合適實際處理。這也是文本數據分析顯而易見的第一步。</p><pre><code>import nltk<br>sentence = "My name is George and I love NLP"<br>tokens = nltk.word_tokenize(sentence)<br>print(tokens)<br><br># Prints out ['My', 'name', 'is', 'George', 'and', 'I', 'love', 'NLP']</code></pre><p><strong>(2) 刪除停止詞（Stop Words Removal）</strong></p><p>在標記化之後，下一步自然是刪除停止詞。這一步的目標與上一步類似，也是將文本數據轉化為更容易處理的格式。這一步會刪除英語中常見的介詞，如“and”、“the”、“a”等。之後在分析數據時，我們就能消除干擾，專注於具有實際意義的單詞了。</p><p>通過比對預定義列表中的單詞來執行停止詞的刪除非常輕鬆。要注意的重要問題是：並沒有普天皆適的停止詞列表。因此這個列表一般是從零開始創建，並針對所要處理的應用執行了定製。</p><pre><code>import nltk<br>from nltk.corpus import stopwords<br><br>sentence = "This is a sentence for removing stop words"<br>tokens = nltk.word_tokenize(sentence)<br><br>stop_words = stopwords.words('english')<br>filtered_tokens = [w for w in tokens if w not in stop_words]<br>print(filtered_tokens)<br><br># Prints out ['This', 'sentence', 'removing', 'stop', 'words']</code></pre><p><strong>(3) 提取主幹（Stemming）</strong></p><p>清理文本數據的另一個技術就是提取主幹。這種方法是將單詞還原為詞根形式，目的是將因上下文拼寫略有不同，但含義相同的單詞縮減為相同的標記來統一處理。例如：考慮在句子中使用單詞“cook”的情況——寫cook這個詞是有很多方式的，具體要取決於上下文：</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RwTasOV46RbAsP><p>上圖中cook的所有形式含義都基本相同，因此理論上，在分析時我們可以將其映射到同一個標記上。在本例中，我們將cook、cooks、cooked和cooking全部標記為“cook”，這將大大簡化我們對文本數據的進一步分析。</p><pre><code>import nltk<br><br>snowball_stemmer = nltk.stem.SnowballStemmer('english')<br><br>s_1 = snowball_stemmer.stem("cook")<br>s_2 = snowball_stemmer.stem("cooks")<br>s_3 = snowball_stemmer.stem("cooked")<br>s_4 = snowball_stemmer.stem("cooking")<br><br># s_1, s_2, s_3, s_4 all have the same result</code></pre><p><strong>(4) 單詞嵌入（Word Embeddings）</strong></p><p>從上面三個步驟中，我們已經將數據清理完畢，現在可以將其轉化為可用於實際處理的格式。</p><p>單詞嵌入是一種將單詞以數字表達的方式，這樣一來，具有相似含義的單詞表達也會相似。如今的單詞嵌入是將單個單詞表示為預定義向量空間中的實值向量。</p><p>所有單詞的向量長度相同，只是值有差異。兩個單詞的向量之間的距離代表著其語義的接近程度。舉個例子：單詞“cook”（烹飪）和“bake”（烘焙）的向量就非常接近，但單詞“football”（足球）和“bake”（烘焙）的向量則完全不同。</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RwTasmTAnAWLOf><p>有一種創建單詞嵌入的常見方法被稱為GloVe，它代表著“全局向量”。GloVe捕獲文本語料庫的全局統計信息和局部統計信息，以創建單詞向量。</p><p>GloVe使用了所謂的共現矩陣（co-occurrence matrix）。共現矩陣表示每對單詞在語料庫裡一起出現的頻率。例如：假設我們要為以下三個句子創建一個共現矩陣：</p><ul><li><p>我喜歡數據科學（I love Data Science）。</p></li><li><p>我喜歡編程（I love coding）。</p></li><li><p>我應該學習自然語言處理（I should learn NLP）。</p></li></ul><p>該文本庫的共現矩陣如下所示：</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RwTasmq8qb8IFj><p>真實世界中的數據集，矩陣會大得多。好處在於：單詞嵌入只需計一次數據，之後就可以保存到磁盤中了。</p><p>之後，我們要訓練GloVe學習每個單詞的固定長度向量，以便讓任何兩個單詞的向量點積（dot product）與共現矩陣中對數單詞的共現概率相等。在下面論文的目標函數中表達為：</p><img alt="關於自然語言處理，數據科學家需要了解的 7 項技術" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RwTasn6HvfkpqR><p>在等式中，X代表著在共現矩陣中位置 (i,j)的值，而w則是要得出的單詞向量。因此，藉助該目標函數，GloVe能將兩個單詞向量的點積與共現的差異最小化，從而有效地保證要得出的向量與矩陣中的共現值相關。</p><p>過去幾年中，由於GloVe在單詞語義及其相似性方面的編碼極其有效，已被證實是一種非常強大且用途廣泛的單詞嵌入技術。對於數據科學應用來說，這是一種經過驗證的方法，可以將單詞轉為我們能夠處理和分析的格式。</p><p>點擊這裡可以查看在Python中如何使用GloVe的完整教程：</p><p>https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db</p><p><strong>(5) 詞頻-逆文檔頻率（Term Frequency-Inverse Document Frequency, TF-IDF）</strong></p><p>術語“詞頻-逆文檔頻率”（常被稱為TF-IDF）是一種加權因子，經常在諸如信息檢索及文本挖掘類的應用中使用。TF-IDF會使用統計數據來衡量某個單詞對特定文檔的重要程度。</p><ul><li><p>TF——詞頻：衡量某字符串在某個文檔中出現的頻率。計算方式：將文檔中出現的總數除以文檔總長度（以標準化）。</p></li><li><p>IDF——逆文檔頻率：衡量某字符串在某個文檔中的重要程度。例如：特定字符串如“is”、“of”和“a”會在許多文檔中多次出現，但並無多少實際含義——它們不是形容詞或者動詞。因此IDF會根據重要程度對每個字符串加權，計算方式為：將數據集的總文檔數目，除以包含該字符串的文檔數目（需將分母+1，避免分母為0），再將得到的商取對數算出。</p></li><li><p>TF-IDF：其最終的計算結果只是將TF與IDF簡單相乘。</p></li></ul><p>TF-IDF可以達到完美平衡，並考慮到目標單詞的本地與全局統計水平。在文檔中出現越頻繁的單詞，其權重也越高，不過前提是這個單詞在整個文檔中出現並不頻繁。</p><p>由於其強大程度，TF-IDF技術通常被搜索引擎用在指定關鍵字輸入時，評判某文檔相關性的評分與排名上。在數據科學中，我們可以通過這種技術，瞭解文本數據中哪些單詞和相關信息更為重要。</p><pre><code>import pandas as pd<br>from sklearn.feature_extraction.text import TfidfVectorizer<br><br>def get_tf_idf(vectorizer):<br>feature_names = vectorizer.get_feature_names<br>dense_vec = vectors.todense<br>dense_list = dense_vec.tolist<br>tfidf_data = pd.DataFrame(dense_list, columns=feature_names)<br>return tfidf_data<br><br><br>vectorizer = TfidfVectorizer<br><br>doc_1 = "TF-IDF uses statistics to measure how important a word is to " \<br>"a particular document"<br>doc_2 = "The TF-IDF is perfectly balanced, considering both local and global " \<br>"levels of statistics for the target word."<br>doc_3 = "Words that occur more frequently in a document are weighted higher, " \<br>"but only if they're more rare within the whole document."<br>documents_list = [doc_1, doc_2, doc_3]<br><br>vectors = vectorizer.fit_transform(documents_list)<br><br>tfidf_data = get_tf_idf(vectorizer)<br><br>print(tfidf_data)<br># Prints the TF-IDF data for all words across all documents</code></pre><p><strong>(6) 主題建模（Topic Modeling）</strong></p><p>在自然語言處理中，主題建模是從文本數據或文檔的集合中提取主要話題的過程。本質來講，由於我們將大量文本數據縮減為數量較少的主題，這是一種降維形式。主題建模在許多數據科學場景中都很有用。</p><p>下面舉幾個例子：</p><ul><li><p>文本的數據分析——提取數據的潛在趨勢和主要組成部分；</p></li><li><p>分類文本——與降維處理經典機器學習問題的方式類似，由於我們會將文本壓縮為關鍵功能，因此主題建模在這裡也很有用。</p></li><li><p>構建推薦系統——主題建模會自動提供為文本數據提供一些基礎的分組，甚至可以提供構建和訓練模型的附加功能。</p></li></ul><p>主題建模通常通過隱含狄利克雷分佈（LDA）來完成。藉助LDA，我們將各個文本文檔按照主題的多項分佈，各個主題按照單詞（通過標記化、停用詞刪除、提取主幹等多個技術清理出的單個字符）的多項分佈來建模。</p><p>LDA是假設文檔由多個主題構成，這些主題之後會基於其概率分佈來生成單詞。</p><p>首先，我們會告知LDA各個文檔應當有多少主題，每個主題應當由多少單詞構成。針對指定文檔的數據集，LDA會嘗試確定哪些主題的組合和分佈可以準確重建相應文檔以及其中的所有文本。可以通過構建實際文檔，確定哪個主題有效，並在指定主題的情況下，根據單詞的概率分佈對單詞進行採樣以完成構建。</p><p>一旦LDA找出可以在數據集中準確重建所有文檔及其內容的主題分佈，我們最終具有恰當分佈的主題就確定了。</p><pre><code>from sklearn.decomposition import LatentDirichletAllocation as LDA<br><br>NUM_TOPICS = 3<br><br># Here we create and fit the LDA model<br># The "document_word_matrix" is a 2D array where each row is a document<br># and each column is a word. The cells contain the count of the word within<br># each document<br>lda = LDA(n_components=NUM_TOPICS, n_jobs=-1)<br>lda.fit(document_word_matrix)<br></code></pre><p><strong>(7) 情感分析（Sentiment Analysis）</strong></p><p>情感分析是一種自然語言分析技術，旨在識別與提取文本數據中的主觀信息。與主題建模類似，情感分析可以將非結構化的文本轉為嵌入在數據中的信息基本摘要。</p><p>大多情感分析技術都屬於以下兩個類別之一：基於規則和機器學習的方法。基於規則的方法需要根據簡單的步驟來獲得結果。在進行了一些類似標記化、停止詞消除、主幹提取等預處理步驟後，基於規則的方法可能會遵從以下步驟：</p><ol><li><p>對於不同的情感，定義單詞列表。例如，如果我們打算定義某個段落是消極的還是積極的，可能要為負面情感定義“壞的”和“可怕的”等單詞，為正面情感定義“棒極了”和“驚人的”等單詞；</p></li><li><p>瀏覽文本，分別計算正面與負面情感單詞的數量。</p></li><li><p>如果標記為正面情感的單詞數量比負面的多，則文本情緒是積極的，反之亦然。</p></li></ol><p>基於規則的方法在情感分析用於獲取大致含義時效果很好。但是，如今最先進的系統通常會使用深度學習，或者至少經典的機器學習技術讓整個過程自動化。</p><p>通過深度學習技術，將情感分析按照分類問題來建模。將文本數據編碼到一個嵌入空間中（與上述的單詞嵌入類似），這是功能提取的一種形式。之後將這些功能傳遞到分類模型，對文本情緒進行分類。</p><p>這種基於學習的方法非常強大，因為我們可以將其自動化為優化問題。我們連續向模型發送數據，以獲得持續改進，也是一個巨大的好處。更多的數據可以繼續優化功能提取和情感分類。</p><p>關於如何通過機器學習模型使用情感分析有大量的優秀教程，下面是其中幾個：</p><ul><li><p>With Logistic Regression ：https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184</p></li><li><p>With Random Forest：https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/</p></li><li><p>With Deep Learning LSTM：https://towardsdatascience.com/sentiment-analysis-for-text-with-deep-learning-2f0a0c6472b5</p></li></ul><p>原文：https://towardsdatascience.com/an-introductory-guide-to-nlp-for-data-scientists-with-7-common-techniques-584d623c40f0</p><p>本文為 CSDN 翻譯，轉載請註明來源出處。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>關於</a></li><li><a>語言</a></li><li><a>處理</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html alt=第12屆自然語言處理和知識工程國際會議將在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html title=第12屆自然語言處理和知識工程國際會議將在西華大學舉行>第12屆自然語言處理和知識工程國際會議將在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html alt=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/4e62000034a58600d55e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html title=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行>第12屆自然語言處理與知識工程國際學術會議在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9b0808fe.html alt="關於汙水處理系統一級處理 你知道多少？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c3a85192675849a0b98ee6777bbfca09 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9b0808fe.html title="關於汙水處理系統一級處理 你知道多少？">關於汙水處理系統一級處理 你知道多少？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cdc73197.html alt="關於基坑底土層含水量大的處理 方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dd1233231de94867b30f2794f241e377 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cdc73197.html title="關於基坑底土層含水量大的處理 方法">關於基坑底土層含水量大的處理 方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/67dc63cd.html alt=關於特殊路基的處理技術，如果遇到了可以拿出來參考參考 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8fbc0971cae541ceafe5dd42f6b466b3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/67dc63cd.html title=關於特殊路基的處理技術，如果遇到了可以拿出來參考參考>關於特殊路基的處理技術，如果遇到了可以拿出來參考參考</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html alt=你對自然語言處理了解多少呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/150674bcc0e44efcae3427c70ad2f072 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html title=你對自然語言處理了解多少呢？>你對自然語言處理了解多少呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html alt=自然語言處理中的深度學習：評析與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html title=自然語言處理中的深度學習：評析與展望>自然語言處理中的深度學習：評析與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html alt=自然語言處理中的語言模型簡介 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html title=自然語言處理中的語言模型簡介>自然語言處理中的語言模型簡介</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html alt=自然語言處理的十大應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dea6cbd6fbef4e9c935b6f56cb9b0097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html title=自然語言處理的十大應用>自然語言處理的十大應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html alt=人工智能之自然語言處理初探 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S4bjUwAFhO20v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html title=人工智能之自然語言處理初探>人工智能之自然語言處理初探</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html alt=人工智能的研究熱點：自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5fdd13a7-6c6d-45d6-9fcd-2829793b5dd3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html title=人工智能的研究熱點：自然語言處理>人工智能的研究熱點：自然語言處理</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>