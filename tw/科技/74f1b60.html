<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>盤點機器學習優化的那些算法！ | 极客快訊</title><meta property="og:title" content="盤點機器學習優化的那些算法！ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/153628931406957507c6ae2"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/74f1b60.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/74f1b60.html><meta property="article:published_time" content="2020-10-29T21:01:06+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:06+08:00"><meta name=Keywords content><meta name=description content="盤點機器學習優化的那些算法！"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/74f1b60.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>盤點機器學習優化的那些算法！</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p><strong>點擊上方關注，All in AI中國</strong></p></blockquote><p>作者：Ravindra Parmar</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153628931406957507c6ae2><p class=pgc-img-caption>機器學習的梯度下降</p></div><p>優化是機器學習算法最重要的組成部分。它首先定義某種損失函數/成本函數，然後使用一個或另一個優化例程使其最小化。優化算法的選擇可以在幾小時或幾天內獲得的良好精度之間產生差異。其優化的應用是無限的，是工業界和學術界廣泛研究的課題。在本文中，我們將介紹在深度學習領域中使用的幾種優化算法。（你可以通過本文了解損失函數的基礎知識）</p><p>https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23</p><p><strong>隨機梯度下降法</strong></p><p>隨機梯度下降（SGD）是用於查找最小化給定成本函數的參數的最簡單優化算法。顯然，為了使梯度下降收斂到最佳的最小值，其成本函數應該是凸出的。在此演示一下成本函數的圖形表示。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289366111fc60ff0dcf><p class=pgc-img-caption>梯度下降的例證</p></div><p>我們首先定義參數的一些隨機初始值。優化算法的目標是找到對應於成本函數的最小值的參數值。具體而言，梯度下降開始於計算每個參數w.r.t成本函數的梯度（導數）。這些梯度使我們需要對每個參數進行數值調整，以便最小化成本函數。這個過程一直持續到我們達到局部/全局最小值（成本函數最小化w.r.t的周圍值）。在數學上，</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289496338bd68cc8351><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1536289505932eebcb9b993><p class=pgc-img-caption>學習率對梯度下降的影響</p></div><p>學習率定義了每次迭代中應該更改的參數量。換句話說，它控制我們應該收斂到最低或最快的速度。一方面，小的學習率可以使迭代收斂，大的學習率可以超過最小值，如上圖所示。</p><p>儘管在實踐中很容易應用，但它在深度神經網絡中有很多缺點，因為這些網絡需要適應大量參數。為了說明梯度下降的問題，我們假設只有兩個參數的成本函數。假設成本函數對參數之一（例如垂直方向）的變化非常敏感，而對其他參數（即水平方向）的變化也非常敏感（這意味著成本函數具有高條件數）。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289542006da84863724><p class=pgc-img-caption>曲折運動與梯度下降</p></div><p>如果我們在這個函數上運行隨機梯度下降，我們會得到一種曲折線條。從本質上講，隨機梯度下降（SGD）在向敏感度較低的方向發展緩慢，而對高敏感方向則發展更快一些，因此在最小化方向並不一致。在實踐中，深度神經網絡可能具有數百萬個參數，因此具有數百萬個方向來適應梯度調整，從而使問題複雜化。</p><p>隨機梯度下降（SGD）的另一個問題是局部最小值或鞍點問題。鞍點是在所有方向上梯度為零的點。因此，我們的隨機梯度下降（SGD）將只停留在那裡。另一方面，局部最小值是最小值w.r.t周圍的點，但並非最小值。由於梯度在局部最小值為零，當全局最小值在其他位置時，梯度下降會將其報告為最小值。</p><p>為了解決批次梯度下降的問題，近年來開發了幾種先進的優化算法。以下將逐一介紹。</p><p><strong>隨機梯度下降與動量</strong></p><p>為了理解高級優化背後的動力學，我們首先要掌握指數加權平均的概念。假設我們獲得了所有特定城市一年365天的溫度數據。繪製這些數據，我們在下圖中的左上角得到一個圖表。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1536289572008758f6f8ab2><p class=pgc-img-caption>演示指數加權平均值</p></div><p>現在，如果我們希望計算當地全年的平均溫度，按如下方式進行。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289592870d1c0bbda90><p class=pgc-img-caption></p></div><p>在每一天，我們計算前一天溫度和當日溫度的加權平均值。上面計算的圖表顯示在右上角。該圖是過去10天的平均溫度（α= 0.9）。左下角（綠線）顯示過去50天的平均數據（alpha = 0.98）。</p><p>這裡需要注意的一點是，隨著我們對更多天數進行平均，曲線對溫度變化的敏感度會降低。相反，如果我們在較少的天數內進行平均，則曲線將對溫度的變化更敏感，並因此變得更加蠕動。</p><p>延遲的增加是由於我們給前一天的溫度提供了比當日溫度更高的權重。</p><p>到目前為止，這很好，但問題是這一切能給我們帶來什麼。很相似，通過平均過去幾個值的梯度，我們傾向於減少更敏感方向的振盪，從而使其收斂更快。</p><p>在實踐中，基於動量的優化算法幾乎總是比批次梯度下降更快。在數學上，</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289608611d3f51d7b2e><p class=pgc-img-caption></p></div><p><strong>AdaGrad的優化</strong></p><p>我們的想法是，對於每個參數，我們存儲其所有歷史梯度的平方和。這個總和稍後用於縮放學習率。</p><p>請注意，與之前的優化相比，這裡我們對每個參數都有不同的學習率。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15362896343838dbd2ceebe><p class=pgc-img-caption></p></div><p>現在的問題是，當我們的損失函數具有非常高的條件數時，這種縮放是如何幫助我們的？</p><p>對於具有高梯度值的參數，平方項將很大，因此用較大的平方項劃分會使梯度在該方向上緩慢加速。類似地，具有低梯度的參數將產生較小的平方項，因此梯度將在該方向上加速更快。</p><p>然而請注意，隨著梯度在每一步進行平方，其移動估計將隨著時間的推移單調增長，因此我們的算法將收斂到最小值的步長會變得越來越小。</p><p>從某種意義上說，這對於凸起問題是有益的，因為在這種情況下我們預計會減慢到最小值。然而，在非凸優化問題的情況下，同樣的好處會變成詛咒，因為陷入鞍點的機會增加。</p><p>RMSProp的優化</p><p>這是AdaGrad的一個細微變化，在實踐中效果更好，因為它解決了所留下的問題。與AdaGrad類似，這裡我們也將保持平方梯度的估計值，但不是讓平方估計值累積在訓練上，而是讓估計值逐漸衰減。為此，我們將當前的平方梯度估計值與衰減率相乘。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153628965204383c3767808><p class=pgc-img-caption></p></div><p><strong>Adam</strong></p><p>這包含了RMSProp和Gradient下降的所有優點和動量。</p><p>具體而言，該算法計算梯度的指數移動平均值和平方梯度，而參數beta_1和beta_2控制這些移動平均值的衰減率。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289683065aa5c740229><p class=pgc-img-caption></p></div><p>請注意，我們已將second_moment初始化為零。因此，在開始時，second_moment將被計算為非常接近零的某個時刻。因此，我們通過除以非常小的數字來更新參數，從而對參數進行大量更新。這意味著最初，算法會做出更大的步驟。為了糾正這一點，我們通過結合當前步驟創建了對first_moment和second_moment的無偏估計。然後我們根據這些無偏估計而不是更新first_moment和second_moment的參數。在數學上，</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536289704509795b5d1ee4><p class=pgc-img-caption></p></div><p>下圖演示了迭代過程中每個優化算法的性能。顯然，增加動量可以提高準確性。然而，在實踐中，Adam能夠很好地處理大型數據集和複雜功能。</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15362892083197f9a768e57><p class=pgc-img-caption>優化的性能度量</p></div><p>資源</p><p>RMSprop - 優化算法| Coursera</p><p>https://www.coursera.org/lecture/deep-neural-network/rmsprop-BhJlm</p><p>你可以找到更多的數學背景。請通過評論告訴本文可能適用的任何修改/改進。</p><p>https://www.coursera.org/lecture/deep-neural-network/rmsprop-BhJlm</p><div class=pgc-img><img alt=盤點機器學習優化的那些算法！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1536289783409d22b949ad9><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>盤點</a></li><li><a>機器</a></li><li><a>學習</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html alt=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ebc79c3aa76541b393374cc521297870 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html title=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用>機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html alt=基於機器學習在雙光子光刻過程中進行自動探測產品的質量 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7550407fa66941b2991e53b5a9ec4071 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html title=基於機器學習在雙光子光刻過程中進行自動探測產品的質量>基於機器學習在雙光子光刻過程中進行自動探測產品的質量</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html alt=機器學習中模型評估和選擇的一些問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6c3b00005e98772353a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html title=機器學習中模型評估和選擇的一些問題>機器學習中模型評估和選擇的一些問題</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/84d97e2a.html alt=盤點工業機器人的末端夾持機構有哪些 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RLrprIJCFWpfTY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/84d97e2a.html title=盤點工業機器人的末端夾持機構有哪些>盤點工業機器人的末端夾持機構有哪些</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>