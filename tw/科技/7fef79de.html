<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 | 极客快訊</title><meta property="og:title" content="模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/53e6fb5a44444812802c93c6c584d509"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/7fef79de.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/7fef79de.html><meta property="article:published_time" content="2020-11-14T21:03:07+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:07+08:00"><meta name=Keywords content><meta name=description content="模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/7fef79de.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote class=pgc-blockquote-abstract><p>圖像領域的 GPT 模型終於來了！OpenAI 推出了用於圖像分類的模型 iGPT，該模型生成的特徵在多個分類數據集上實現了當前 SOTA 性能，並且實現了良好的圖像補全效果。</p></blockquote><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/53e6fb5a44444812802c93c6c584d509><p class=pgc-img-caption></p></div><p>無監督和自監督學習，或者無人工標註數據的學習，這些都是機器學習領域長期存在的挑戰。近期，BERT、GPT-2、RBERTa、T5 等 Transformer 模型以及其他變體在一系列語言任務上實現了最佳性能。然而，在生成用於圖像分類的強特徵方面卻始終沒有出現性能強大的模型。</p><p>這是因為，與 GPT-2 和 BERT 這類依賴於詞預測的無監督學習算法相比，像素序列無法清楚地包含它們所屬圖像的標籤。</p><p>近日，OpenAI 發佈了一項新研究，旨在探索在圖像上訓練 GPT-2 的性能以及無監督準確率表現。研究者表示，BERT 和 GPT-2 等 Transformer 模型是域不可知的，這意味著它們可以直接應用於任何形式的 1D 序列。</p><p>OpenAI 研究者在圖像上訓練 GPT-2（這些圖像被分解為長像素序列），他們稱該模型稱為 iGPT。結果發現這種模型似乎能夠理解物體外觀和類別等 2D 圖像特徵。iGPT 生成的各種一致性圖像樣本可以證明這一點，即使沒有人為標籤的指導。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/07fb6867466040c28178dc221ff9fe13><p class=pgc-img-caption></p></div><p>論文地址：https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf</p><p>GitHub 地址：https://github.com/openai/image-gpt</p><p>項目主頁：https://openai.com/blog/image-gpt/</p><p>iGPT 緣何能夠成功呢？這是因為，在下一像素預測（next pixel prediction）上訓練的足夠大的 transformer 模型最終可能學會生成具有清晰可識別物體的樣本。一旦學會了生成此類樣本，那麼通過「合成分析」，iGPT 將知道目標類別。實驗表明，iGPT 模型的特徵在大量的分類數據集上實現了當前 SOTA 性能，以及在 ImageNet 數據集上實現了接近 SOTA 的無監督準確率。</p><p>我們先直觀地看一下 iGPT 的效果。下圖展示了，在 CIFAR-10、CIFAR-100、STL-10 和 ImageNet 數據集上，iGPT 與當前最佳非 iGPT 模型的性能對比情況：</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/38c7460239244a3780bdcfced57c586e><p class=pgc-img-caption></p></div><p>為了突出生成序列建模作為通用無監督學習算法的潛力，該研究特意使用了與 GPT-2 相同的 Transformer 架構，因而該模型需要更多計算才能生成與頂級無監督卷積網絡相當的特徵。結果表明，當面對一個正確模型先驗未知的新領域時，大型 GPT-2 模型可以學習優秀特徵，並且不需要領域特定的架構設計選擇。</p><p><strong>iGPT 處理圖像任務的效果如何</strong></p><p>iGPT 可實現較好的圖像補全效果。不管是動物、建築物、風景、運動場面、藝術作品，甚至表情包，它都可以實現不錯的補全效果。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ea16286128814566b77b7ccc95c2881d><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c1e39af4a6a7479c953c5a34e7f1cb29><p class=pgc-img-caption></p></div><p>下圖展示了 iGPT 生成的圖像樣本。研究者在採樣過程中使用 temperature 1，且未使用束搜索或核採樣（nucleus sampling）等 trick。研究者表示，以下所有樣本均未經過挑選。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/de951d54ecc145868609efb7f1b3e2d5><p class=pgc-img-caption></p></div><p>我們可以看出，幾乎所有生成圖像均包含清晰可識別的物體。</p><p><strong>方法</strong></p><p>OpenAI 研究人員提出的方法包含兩個階段：預訓練和微調。</p><p>在預訓練階段中，研究人員探索自迴歸目標和 BERT 目標，並使用序列 Transformer 架構來預測像素，而非語言 token。</p><p>如下圖所示，該方法首先對原始圖像進行預處理，將其調整為低分辨率和 1D 序列；然後在自迴歸下一像素預測或掩碼像素預測這兩個預訓練目標中選擇一個；最後，利用 linear probe 或微調，對這些目標學得的表徵進行評估。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1018dc97cae441e0b63076497afd59b2><p class=pgc-img-caption></p></div><p>該研究在 ImageNet 上訓練了三個 transformer 模型：iGPT-S、iGPT-M 和 iGPT-L，它們分別包含 76M、455M 和 14 億參數。此外，研究者還基於 ImageNet 和網絡圖片的混合數據訓練了 iGPT-XL，它包含 68 億參數。</p><p>由於使用密集注意力建模長序列的計算成本較高，因此該研究選擇使用較低的分辨率：32x32、48x48 和 64x64。</p><p>分辨率繼續降低可以進一步減少計算成本，但是之前研究表明在這種情況下，人類的圖像分類能力會急劇下降。因此，該研究受早期顏色顯示調色板（color display palettes）的啟發，創建了 9-bit 顏色調色板來表示像素。使用該調色板可以得到長度僅為標準 (R, G, B) 1/3 的輸入序列，同時還能有效編碼顏色。</p><p><strong>實驗結果</strong></p><p>該研究使用兩種方法來評估模型性能，二者均涉及下游分類任務。</p><p>方法 1：linear probe，即使用訓練好的模型從下游數據集圖像中提取特徵，然後將 logistic 迴歸與標籤進行擬合；</p><p>方法 2：微調，基於下游數據集微調整個模型。</p><p><strong>在沒有潛變量的生成模型中，哪種表徵效果最好？</strong></p><p>下一像素預測任務與圖像分類並不明顯相關，最後一層的特徵可能無法最好地預測物體類別。</p><p>該研究的實驗結果表明，特徵質量先是顯著提升，然後逐漸放緩。這表明 transformer 生成模型通過以下兩個階段運行：</p><p>第一階段：每個位置從周圍語境中收集信息，以構建語境化圖像特徵；</p><p>第二階段：使用語境化特徵解決下一像素預測任務。</p><p>下圖表明，特徵質量嚴重依賴於模型層數。並且，與監督模型相反，下圖中這些生成模型的最優特徵出現在網絡中段。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5732eeb0134a478db16d1a9977bd4556><p class=pgc-img-caption></p></div><p><strong>更好的生成模型學到的表徵也更好</strong></p><p>該研究執行的另一項實驗試圖在生成性能和特徵質量之間建立聯繫。實驗結果表明，模型規模的擴大和訓練迭代次數的增加會帶來更好的生成性能，而這可以直接轉換為更好的特徵質量。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/5732eeb0134a478db16d1a9977bd4556><p class=pgc-img-caption></p></div><p><strong>在 CIFAR 和 STL-10 上的 Linear Probe 效果</strong></p><p>研究者評估了不同模型使用 linear probe 在 CIFAR-10、CIFAR-100 和 STL-10 數據集上的性能，發現該研究提出的方法優於其他監督和無監督遷移算法。甚至在完全微調的設置下，iGPT 的性能仍具備競爭力。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/50dc36d31b6f43d08df3a291f915597d><p class=pgc-img-caption></p></div><p><strong>在 ImageNet 上的 Linear Probe 效果</strong></p><p>該研究使用 linear probe 在 ImageNet 上進行性能評估。基於 48x48 圖像訓練的 iGPT-L，使用 1536 個特徵得到的最優層 top-1 準確率達到 65.2%，超過了 AlexNet。</p><p>下表展示了 iGPT 和當前最優自監督模型的 linear probe 準確率對比情況：</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/732f4578701444cca861c3c7f43ba55d><p class=pgc-img-caption></p></div><p><strong>BERT</strong></p><p>由於像 BERT 這樣的遮蔽語言模型（masked language models）在大多數語言任務上的性能都優於生成模型，因此該研究也在圖像模型上評估了 BERT 的性能。</p><p>他們沒有按照在之前所有像素的基礎上預測下一個像素的方式來訓練模型，而是遮蔽掉了 15% 的像素，然後訓練模型基於未遮蔽的像素進行預測。研究者發現，儘管 BERT 模型的 linear probe 性能明顯較差，但在微調方面 BERT 模型仍然表現亮眼：</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/51e0d7b74b8f4dca9e3e33f50e41076f><p class=pgc-img-caption></p></div><p><strong>在低數據 CIFAR-10 分類任務上的性能</strong></p><p>如下表所示，研究者在這一子域的競爭性基準上對 iGPT-L 進行了評估，結果發現基於非增強圖像特徵的簡單 linear probe 表現優於 Mean Teacher 和 MixMatch，但弱於 FixMatch。</p><div class=pgc-img><img alt=模型跨界成潮流？OpenAI用GPT-2做圖像分類，實現SOTA性能 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4e5c97825cf14dd2ac949e9a8d15fcfd><p class=pgc-img-caption></p></div><p><strong>iGPT 的侷限性</strong></p><p>儘管該研究表明 iGPT 能夠學習強大的圖像特徵，但是該方法仍存在很大的侷限性。</p><p>由於該研究採用的是用於語言任務的 GPT-2 的通用序列 Transformer，所以需要大量計算：iGPT-L 在 V100 上大約需要訓練 2500 天，而性能類似的 MoCo 模型大約需要訓練 70 天。</p><p>此外，該研究用 Transformer 對低分辨率輸入建模，而大多數自監督結果採用的是基於卷積的編碼器，這些編碼器可以輕鬆地處理高分辨率輸入。可能需要一種新的架構，例如與域無關的多尺度 Transformer，以實現進一步擴展。</p><p>考慮到這些侷限性，該研究工作主要是概念證明，證明了基於 Transformer 的大型語言模型在一些新領域中可以學習優秀的無監督表徵，而無需硬編碼領域的知識。但是，訓練這些模型需要大量的資源成本，而基於卷積神經網絡的方法又具有更高的準確率，這讓這些表徵在視覺領域中無法實際應用。</p><p>最後，生成模型可能會呈現出偏差，這些偏差是模型訓練所用的數據造成的。這些偏差中有許多都是有用的，例如假設棕色和綠色像素的部分代表葉子上覆蓋的分支，然後用這種偏差繼續生成圖像。</p><p>但是，從公平性和代表性方面考慮，有些偏差是有害的。例如，如果模型建立了一種偏向男性的科學家視覺觀念，那麼它很有可能一直用男性而不是混合性別的人來完成科學家圖像。研究者希望開發者能夠更加關注系統的輸入數據，並更好地瞭解輸入數據與訓練模型中偏差的關係。</p><p><strong>結論</strong></p><p>研究者表示，通過 2D 知識與 scale 之間的權衡，並從網絡中部選擇預測特徵，序列 Transformer 的性能可以與頂級無監督圖像分類卷積網絡相媲美。</p><p>此外，值得注意的是，研究者將 GPT-2 語言模型直接用於圖像生成，也得到了相應的實驗結果。該結果表明，得益於簡單性和通用性，基於足夠計算量的序列 Transformer 可能是多個領域中學習優秀特徵的有效方法。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>跨界成</a></li><li><a>OpenAI</a></li><li><a>GPT</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/47b1140.html alt=GPT家族又壯大了！OpenAI首次推出數學定理推理模型GPT-f，23個推導結果被專業數據庫收錄 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/SDCImrh2X2TFrE style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/47b1140.html title=GPT家族又壯大了！OpenAI首次推出數學定理推理模型GPT-f，23個推導結果被專業數據庫收錄>GPT家族又壯大了！OpenAI首次推出數學定理推理模型GPT-f，23個推導結果被專業數據庫收錄</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a880b38b.html alt="以假亂真？加州某高材生用 GPT-3 生成偽文章成功騙得 26000 訪問" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/a957621a557142bfbf979b68c3284a55 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a880b38b.html title="以假亂真？加州某高材生用 GPT-3 生成偽文章成功騙得 26000 訪問">以假亂真？加州某高材生用 GPT-3 生成偽文章成功騙得 26000 訪問</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/88648190.html alt=GPT分區安裝win7 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1535770389012e1169851f6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/88648190.html title=GPT分區安裝win7>GPT分區安裝win7</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9f6f7aad.html alt=史上最大，人工智能算法模型GPT-3問世，這意味著什麼？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/c9e713a489404eb4bb452b6158ed9316 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9f6f7aad.html title=史上最大，人工智能算法模型GPT-3問世，這意味著什麼？>史上最大，人工智能算法模型GPT-3問世，這意味著什麼？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51acc7f.html alt=你知道如何把磁盤改為GPT，在UEFI下安裝計算機操作系統嗎？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1535012691438d3351d23f8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51acc7f.html title=你知道如何把磁盤改為GPT，在UEFI下安裝計算機操作系統嗎？>你知道如何把磁盤改為GPT，在UEFI下安裝計算機操作系統嗎？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4ad2e47.html alt=GPT-3：一個令人失望的語言模型 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/97e6c08407634d1ca482349a94984fed style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4ad2e47.html title=GPT-3：一個令人失望的語言模型>GPT-3：一個令人失望的語言模型</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>