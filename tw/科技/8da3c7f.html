<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>2019年kafka架構與原理最全面解析的文章，不看後悔 | 极客快訊</title><meta property="og:title" content="2019年kafka架構與原理最全面解析的文章，不看後悔 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/4bb2a4d1ec8a496aae347dc09cb230b5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/8da3c7f.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/8da3c7f.html><meta property="article:published_time" content="2020-10-29T20:59:18+08:00"><meta property="article:modified_time" content="2020-10-29T20:59:18+08:00"><meta name=Keywords content><meta name=description content="2019年kafka架構與原理最全面解析的文章，不看後悔"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/8da3c7f.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>2019年kafka架構與原理最全面解析的文章，不看後悔</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>1、 簡介</strong></p><p>它可以讓你發佈和訂閱記錄流。在這方面，它類似於一個消息隊列或企業消息系統。</p><p>它可以讓你持久化收到的記錄流，從而具有容錯能力。</p><p>首先，明確幾個概念：</p><p>• Kafka運行在一個或多個服務器上。</p><p>• Kafka集群分類存儲的記錄流被稱為主題(Topics)。</p><p>• 每個消息記錄包含一個鍵，一個值和時間戳。</p><p>Kafka有四個核心API：</p><p>• 生產者 API 允許應用程序發佈記錄流至一個或多個Kafka的話題(Topics)。</p><p>• 消費者API 允許應用程序訂閱一個或多個主題，並處理這些主題接收到的記錄流。</p><p>• Streams API 允許應用程序充當流處理器(stream processor)，從一個或多個主題獲取輸入流，並生產一個輸出流至一個或多個的主題，能夠有效地變換輸入流為輸出流。</p><p>• Connector API 允許構建和運行可重用的生產者或消費者，能夠把 Kafka主題連接到現有的應用程序或數據系統。例如，一個連接到關係數據庫的連接器(connector)可能會獲取每個表的變化。</p><p><strong>對大數據以及人工智能概念都是模糊不清的，該按照什麼線路去學習，學完往哪方面發展，想深入瞭解，想學習的同學歡迎加入大數據學習qq群：458345782，有大量乾貨（零基礎以及進階的經典實戰）分享給大家，讓大家瞭解到目前國內最完整的大數據高端實戰實用學習流程體系 。從java和linux入手，其後逐步的深入到HADOOP-hive-oozie-web-flume-python-hbase-kafka-scala-SPARK等相關知識一一分享！</strong></p><p>• Kafka的客戶端和服務器之間的通信是靠一個簡單的，高性能的，與語言無關的TCP協議完成的。這個協議有不同的版本，並保持向前兼容舊版本。Kafka不光提供了一個Java客戶端，還有許多語言版本的客戶端。</p><p><strong>2、 架構</strong></p><p><strong>2.1 Broker</strong></p><p>每個kafka server稱為一個Broker，多個borker組成kafka cluster。一個機器上可以部署一個或者多個Broker，這多個Broker連接到相同的ZooKeeper就組成了Kafka集群。</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4bb2a4d1ec8a496aae347dc09cb230b5><p class=pgc-img-caption></p></div><p><strong>2.2 主題Topic</strong></p><p>讓我們先來了解Kafka的核心抽象概念記錄流 – 主題。主題是一種分類或發佈的一系列記錄的名義上的名字。Kafka的主題始終是支持多用戶訂閱的; 也就是說，一個主題可以有零個，一個或多個消費者訂閱寫入的數據。</p><p><strong>Topic 與broker</strong></p><p>一個Broker上可以創建一個或者多個Topic。同一個topic可以在同一集群下的多個Broker中分佈。</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/9c4ba8be041147fc96bece9fa176b252><p class=pgc-img-caption></p></div><p>當然，Topic只是一個名義上的組件，真正在Broker間分佈式的Partition。</p><p><strong>2.3 分區與日誌</strong></p><p>一個主題對應多個分區，一個分區對應一個日誌</p><p>Kafka會為每個topic維護了多個分區(partition)，每個分區會映射到一個邏輯的日誌(log)文件。每個分區是一個有序的，不可變的消息序列，新的消息不斷追加到這個有組織的有保證的日誌上。分區會給每個消息記錄分配一個順序ID號 – 偏移量， 能夠唯一地標識該分區中的每個記錄。</p><p>日誌分區是分佈式的存在於一個kafka集群的多個broker上。每個partition會被複制多份存在於不同的broker上。這樣做是為了容災。具體會複製幾份，會複製到哪些broker上，都是可以配置的。經過相關的複製策略後，每個topic在每個broker上會駐留一到多個partition：</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/be281e8b523b4e569440d4a4a967bd25><p class=pgc-img-caption></p></div><p><strong>2.4 保留策略與Offset</strong></p><p>Kafka集群保留所有發佈的記錄，不管這個記錄有沒有被消費過，Kafka提供可配置的保留策略去刪除舊數據(還有一種策略根據分區大小刪除數據)。例如，如果將保留策略設置為兩天，在記錄公佈後兩天內，它可用於消費，之後它將被丟棄以騰出空間。Kafka的性能跟存儲的數據量的大小無關， 所以將數據存儲很長一段時間是沒有問題的。</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6e6a7b77b231472fa23baa367ace04ab><p class=pgc-img-caption></p></div><p>事實上，保留在每個消費者元數據中的最基礎的數據就是消費者正在處理的當前記錄的偏移量(offset)或位置(position)。這種偏移是由消費者控制：通常偏移會隨著消費者讀取記錄線性前進，但事實上，因為其位置是由消費者進行控制，消費者可以在任何它喜歡的位置讀取記錄。例如，消費者可以恢復到舊的偏移量對過去的數據再加工或者直接跳到最新的記錄，並消費從“現在”開始的新的記錄。</p><p>這些功能的結合意味著，實現Kafka的消費者的代價都是很小的，他們可以增加或者減少而不會對集群或其他消費者有太大影響。例如，你可以使用我們的命令行工具去追隨任何主題，而且不會改變任何現有的消費者消費的記錄。</p><p><strong>2.5 Leader與Followers</strong></p><p>一個Topic可能有很多分區，以便它能夠支持海量的的數據，更重要的意義是分區是進行並行處理的基礎單元。日誌的分區會跨服務器的分佈在Kafka集群中，每個分區可以配置一定數量的副本分區提供容錯能力。為了保證較高的處理效率，消息的讀寫都是在固定的一個副本上完成。這個副本就是所謂的Leader，而其他副本則是Follower，而Follower則會定期地到Leader上同步數據。</p><p>(1)leader處理所有的讀取和寫入分區的請求，而followers被動的從領導者拷貝數據。</p><p>(2)如果leader失敗了，followers之一將自動成為新的領導者。</p><p>(3)每個服務器可能充當一些分區的leader和其他分區的follower，這樣的負載就會在集群內很好的均衡分配。</p><p>(4)一個分區在同一時刻只能有一個消費者實例進行消費。</p><p><strong>舉例：</strong></p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfddd003a0d14a58a8ca38b51d79bb28><p class=pgc-img-caption></p></div><p>可以看見我們一共有3個分區分別是0，1，2， replica 有2個：</p><p>partition 0 的leader在broker1， follower在broker2</p><p>partition 1 的leader在broker2， follower在broker0</p><p>partition 2 的leader在broker0， follower在brokder1</p><p>一個broker中不會出現兩個一樣的Partition，replica會被均勻的分佈在各個kafka server(broker)上 。Kafka並不允許replicas 數設置大於 broker數，因為在一個broker上如果有2個replica其實是沒有意義的，因為再多的replica同時在一臺broker上，隨著該broker的crash，一起不可用。</p><p><strong>(1)Leader選舉與ISR</strong></p><p>如果某個分區所在的服務器除了問題，不可用，kafka會從該分區的其他的副本中選擇一個作為新的Leader。之後所有的讀寫就會轉移到這個新的Leader上。現在的問題是應當選擇哪個作為新的Leader。顯然，只有那些跟Leader保持同步的Follower才應該被選作新的Leader。</p><p>Kafka會在Zookeeper上針對每個Topic維護一個稱為ISR(in-sync replica，已同步的副本)的集合，該集合中是一些分區的副本。只有當這些副本都跟Leader中的副本同步了之後，kafka才會認為消息已提交，並反饋給消息的生產者。如果這個集合有增減，kafka會更新zookeeper上的記錄。如果某個分區的Leader不可用，Kafka就會從ISR集合中選擇一個副本作為新的Leader。顯然通過ISR，kafka需要的冗餘度較低，可以容忍的失敗數比較高。假設某個topic有f+1個副本，kafka可以容忍f個服務器不可用。</p><p><strong>(2)為什麼不用少數服從多數的方法</strong></p><p>少數服從多數是一種比較常見的一致性算法和Leader選舉法。它的含義是隻有超過半數的副本同步了，系統才會認為數據已同步;選擇Leader時也是從超過半數的同步的副本中選擇。這種算法需要較高的冗餘度。譬如只允許一臺機器失敗，需要有三個副本;而如果只容忍兩臺機器失敗，則需要五個副本。而kafka的ISR集合方法，分別只需要兩個和三個副本。</p><p><strong>(3)如果所有的ISR副本都失敗了怎麼辦</strong></p><p>此時有兩種方法可選，一種是等待ISR集合中的副本復活，一種是選擇任何一個立即可用的副本，而這個副本不一定是在ISR集合中。這兩種方法各有利弊，實際生產中按需選擇。如果要等待ISR副本復活，雖然可以保證一致性，但可能需要很長時間。而如果選擇立即可用的副本，則很可能該副本並不一致。</p><p><strong>2.6 生產者和消費者</strong></p><p><strong>(1)生產者</strong></p><p>生產者發佈數據到他們所選擇的主題。生產者負責選擇把記錄分配到主題中的哪個分區。這可以使用輪詢算法( round-robin)進行簡單地平衡負載，也可以根據一些更復雜的語義分區算法(比如基於記錄一些鍵值)來完成。</p><p><strong>(2)消費者</strong></p><p>消費者以消費群(consumer group)的名稱來標識自己，每個發佈到主題的消息都會發送給訂閱了這個主題的消費群裡面的一個消費者實例，即一個消費群只發送一次。消費者的實例可以在單獨的進程或單獨的機器上。</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d84e846d33f4438d978a6f16125f3a16><p class=pgc-img-caption></p></div><p>上圖中兩個服務器的Kafka集群具有四個分區(P0-P3)和兩個消費群。A消費群有兩個消費者，B群有四個。更常見的是，我們會發現主題有少量的消費群，每一個都是“邏輯上的訂閱者”。每組都是由很多消費者實例組成，從而實現可擴展性和容錯性。這只不過是發佈 – 訂閱模式的再現，區別是這裡的訂閱者是一組消費者而不是一個單一的進程的消費者。</p><p>Kafka消費群的實現方式是通過分割分區給每個Consumer實例實現的，使每個實例在任何時間點的都可以“公平分享”獨佔的分區。維持消費群中的成員關係的這個過程是通過Kafka動態協議處理。如果新的實例加入該組，他將接管該組的其他成員的一些分區; 如果一個實例死亡，其分區將被分配到剩餘的實例。</p><p>Kafka只保證一個分區內的消息有序，不能保證一個主題的不同分區之間的消息有序。分區的消息有序與依靠主鍵進行數據分區的能力相結合足以滿足大多數應用的要求。但是，如果你想要保證所有的消息都絕對有序可以只為一個主題分配一個分區，雖然這將意味著每個消費群同時只能有一個消費進程在消費。</p><p><strong>3 、數據可靠性與一致性</strong></p><p><strong>3.1 Partition Recovery機制</strong></p><p>每個Partition會在磁盤記錄一個RecoveryPoint，記錄已經flush到磁盤的最大offset。當broker fail 重啟時，會進行loadLogs。 首先會讀取該Partition的RecoveryPoint，找到包含RecoveryPoint的segment及以後的segment， 這些segment就是可能沒有完全flush到磁盤segments。然後調用segment的recover，重新讀取各個segment的msg，並重建索引。</p><p><strong>優點</strong></p><p>• 以segment為單位管理Partition數據，方便數據生命週期的管理，刪除過期數據簡單。</p><p>• 在程序崩潰重啟時，加快recovery速度，只需恢復未完全flush到磁盤的segment。</p><p>• 通過index中offset與物理偏移映射，用二分查找能快速定位msg，並且通過分多個Segment，每個index文件很小，查找速度更快。</p><p>3.2 Partition Replica同步機制</p><p>• Partition的多個replica中一個為Leader，其餘為follower</p><p>• Producer只與Leader交互，把數據寫入到Leader中</p><p>• Followers從Leader中拉取數據進行數據同步</p><p>• Consumer只從Leader拉取數據</p><p>ISR：in-sync replica，已同步的副本。準確的定義是“所有不落後的replica集合”。不落後有兩層含義:距離上次FetchRequest的時間不大於某一個值或落後的消息數不大於某一個值， Leader失敗後會從ISR中選取一個Follower做Leader。</p><p><strong>3.4 消息的順序消費問題</strong></p><p>在說到消息中間件的時候，我們通常都會談到一個特性：消息的順序消費問題。這個問題看起來很簡單：Producer發送消息1, 2, 3;Consumer按1, 2, 3順序消費。但實際情況卻是：無論RocketMQ，還是Kafka，缺省都不保證消息的嚴格有序消費!困難如下：</p><p><strong>(1)Producer</strong></p><p>發送端不能異步發送，異步發送在發送失敗的情況下，就沒辦法保證消息順序。比如你連續發了1，2，3。 過了一會，返回結果1失敗，2, 3成功。你把1再重新發送1遍，這個時候順序就亂掉了。</p><p><strong>(2)存儲端</strong></p><p>對於存儲端，要保證消息順序，會有以下幾個問題：</p><p>消息不能分區。也就是1個topic，只能有1個隊列。在Kafka中，它叫做partition;在RocketMQ中，它叫做queue。 如果你有多個隊列，那同1個topic的消息，會分散到多個分區裡面，自然不能保證順序。</p><p>即使只有1個隊列的情況下，會有第2個問題。該機器掛了之後，能否切換到其他機器?也就是高可用問題。比如你當前的機器掛了，上面還有消息沒有消費完。此時切換到其他機器，可用性保證了。但消息順序就亂掉了。要想保證，一方面要同步複製，不能異步複製;另1方面得保證，切機器之前，掛掉的機器上面，所有消息必須消費完了，不能有殘留。很明顯，這個很難。</p><p><strong>(3)接收端</strong></p><p>對於接收端，不能並行消費，也即不能開多線程或者多個客戶端消費同1個隊列。</p><p><strong>3.5 Producer發送消息的配置</strong></p><p><strong>3.5.1 同步模式</strong></p><p>kafka有同步(sync)、異步(async)以及oneway這三種發送方式，某些概念上區分也可以分為同步和異步兩種，同步和異步的發送方式通過producer.type參數指定，而oneway由request.require.acks參數指定。</p><p>producer.type的默認值是sync，即同步的方式。這個參數指定了在後臺線程中消息的發送方式是同步的還是異步的。如果設置成異步的模式，可以運行生產者以batch的形式push數據，這樣會極大的提高broker的性能，但是這樣會增加丟失數據的風險。</p><p><strong>3.5.2 異步模式</strong></p><p>對於異步模式，還有4個配套的參數，如下：</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/831e75990c4a413fa18e504a590536c3><p class=pgc-img-caption></p></div><p><strong>3.5.3 oneway</strong></p><p>oneway是隻顧消息發出去而不管死活，消息可靠性最低，但是低延遲、高吞吐，這種對於某些完全對可靠性沒有要求的場景還是適用的，即request.required.acks設置為0。</p><p><strong>3.5.4 消息可靠性級別</strong></p><p>當Producer向Leader發送數據時，可以通過request.required.acks參數設置數據可靠性的級別：</p><p>• 0: 不論寫入是否成功，server不需要給Producer發送Response，如果發生異常，server會終止連接，觸發Producer更新meta數據;</p><p>• 1: Leader寫入成功後即發送Response，此種情況如果Leader fail，會丟失數據</p><p>• -1: 等待所有ISR接收到消息後再給Producer發送Response，這是最強保證</p><p>僅設置acks=-1也不能保證數據不丟失，當Isr列表中只有Leader時，同樣有可能造成數據丟失。要保證數據不丟除了設置acks=-1， 還要保 證ISR的大小大於等於2，具體參數設置:</p><p>• (1)request.required.acks: 設置為-1 等待所有ISR列表中的Replica接收到消息後採算寫成功;</p><p>• (2)min.insync.replicas: 設置為大於等於2，保證ISR中至少有兩個Replica</p><p><strong>Producer要在吞吐率和數據可靠性之間做一個權衡。</strong></p><p><strong>3.5.5 一般配置</strong></p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/06f854aa8d7c48508ee6ea35d58c552d><p class=pgc-img-caption></p></div><p><strong>4、 應用場景</strong></p><p><strong>4.1 消息系統</strong></p><p><strong>消息處理模型歷來有兩種：</strong></p><p><strong>隊列模型</strong>：一組消費者可以從服務器讀取記錄，每個記錄都會被其中一個消費者處理，為保障消息的順序，同一時刻只能有一個進程進行消費。</p><p><strong>發佈-訂閱模型：</strong>記錄被廣播到所有的消費者。</p><p>Kafka的消費群的推廣了這兩個概念。消費群可以像隊列一樣讓消息被一組進程處理(消費群的成員)，與發佈 – 訂閱模式一樣，Kafka可以讓你發送廣播消息到多個消費群。</p><p>Kafka兼顧了消息的有序性和併發處理能力。傳統的消息隊列的消息在隊列中是有序的，多個消費者從隊列中消費消息，服務器按照存儲的順序派發消息。然而，儘管服務器是按照順序派發消息，但是這些消息記錄被異步傳遞給消費者，消費者接收到的消息也許已經是亂序的了。這實際上意味著消息的排序在並行消費中都將丟失。消息系統通常靠 “排他性消費”( exclusive consumer)來解決這個問題，只允許一個進程從隊列中消費，當然，這意味著沒有並行處理的能力。</p><p>Kafka做的更好。通過一個概念：並行性-分區-主題實現主題內的並行處理，Kafka是能夠通過一組消費者的進程同時提供排序保證和並行處理以及負載均衡的能力：</p><p><strong>(1)排序保障</strong></p><p>每個主題的分區指定給每個消費群中的一個消費者，使每個分區只由該組中的一個消費者所消費。通過這樣做，我們確保消費者是一個分區唯一的讀者，從而順序的消費數據。</p><p><strong>(2)並行處理</strong></p><p>因為有許多的分區，所以負載還能夠均衡的分配到很多的消費者實例上去。但是請注意，一個消費群的消費者實例不能比分區數量多，因為分區數代表了一個主題的最大併發數，消費者的數量高於這個數量意義不大。</p><p><strong>4.2 日誌採集</strong></p><p>大多數時候，我們的log都會輸出到本地的磁盤上，排查問題也是使用linux命令來搞定，如果web程序組成負載集群，那麼就有多臺機器，如果有幾十臺機器，幾十個服務，那麼想快速定位log問題和排查就比較麻煩了，所以很有必要有一個統一的平臺管理log，現在大多數公司的套路都是收集重要應用的log集中到kafka中，然後在分別導入到es和hdfs上，一個做實時檢索分析，另一個做離線統計和數據備份。如何能快速收集應用日誌到kafka中?</p><p><strong>方法一：使用log4j的集成包</strong></p><p>kafka官網已經提供了非常方便的log4j的集成包 kafka-log4j-appender，我們只需要簡單配置log4j文件，就能收集應用程序log到kafka中。</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3241206e18704b6a93e55e14bea528f9><p class=pgc-img-caption></p></div><p>注意，需要引入maven的依賴包：</p><div class=pgc-img><img alt=2019年kafka架構與原理最全面解析的文章，不看後悔 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/760204b6fce44d8c981756e558920f4b><p class=pgc-img-caption></p></div><p>非常簡單，一個maven依賴加一個log4j配置文件即可，如果依然想寫入log到本地 文件依然也是可以的，這種方式最簡單快速，但是默認的的log日誌是一行一行的純文本，有些場景下我們可能需要json格式的數據。</p><p><strong>方法二: 重寫Log4jAppender</strong></p><p>重寫Log4jAppender，自定義輸出格式，支持json格式，如果是json格式的數據打入到kafka中，後續收集程序可能就非常方便了，直接拿到json就能入到mongodb或者es中，如果打入到kafka中的數據是純文本，那麼收集程序，可能需要做一些etl，解析其中的一些字段然後再入到es中，所以原生的輸出格式，可能稍不靈活，這樣就需要我們自己寫一些類，然後達到靈活的程度。</p><p><strong>總結：</strong></p><p>(1)方法一簡單快速，不支持json格式的輸出，打到kafka的消息都是原樣的log日誌信息</p><p>(2)方法二稍微複雜，需要自己擴展log收集類，但支持json格式的數據輸出，對於想落地json數據直接到存儲系統中是非常適合的。</p><p>此外需要注意，在調試的時候log發送數據到kafka模式最好是同步模式的否則你控制檯打印的數據很有可能不會被收集kafka中，程序就停止了。生產環境最好開啟異步發送數據模式，因為內部是批量的處理，所以能提升吞吐,但有一定的輕微延遲。</p><p><strong>4.3 流處理</strong></p><p>只是讀，寫，以及儲存數據流是不夠的，目的是能夠實時處理數據流。在Kafka中，流處理器是從輸入的主題連續的獲取數據流，然後對輸入進行一系列的處理，並生產連續的數據流到輸出主題。</p><p>這些簡單處理可以直接使用生產者和消費者的API做到。然而，對於更復雜的轉換Kafka提供了一個完全集成的流API。這允許應用程序把一些重要的計算過程從流中剝離或者加入流一起。這種設施可幫助解決這類應用面臨的難題：處理雜亂的數據，改變代碼去重新處理輸入，執行有狀態的計算等。流API建立在Kafka提供的核心基礎單元之上：它使用生產者和消費者的API進行輸入輸出，使用Kafka存儲有狀態的數據，並使用群組機制在一組流處理實例中實現容錯。</p><p><strong>把功能組合起來</strong></p><p>消息的傳輸，存儲和流處理的組合看似不尋常，卻是Kafka作為流處理平臺的關鍵。像HDFS分佈式文件系統，允許存儲靜態文件進行批量處理。像這樣的系統允許存儲和處理過去的歷史數據。傳統的企業消息系統允許處理您訂閱後才抵達的消息。這樣的系統只能處理將來到達的數據。</p><p>Kafka結合了這些功能，這種結合對Kafka作為流應用平臺以及數據流處理的管道至關重要。通過整合存儲和低延遲訂閱，流處理應用可以把過去和未來的數據用相同的方式處理。這樣一個單獨的應用程序，不但可以處理歷史的，保存的數據，當它到達最後一條記錄不會停止，繼續等待處理未來到達的數據。這是泛化了的流處理的概念，包括了批處理應用以及消息驅動的應用。同樣，流數據處理的管道結合實時事件的訂閱使人們能夠用Kafka實現低延遲的管道; 可靠的存儲數據的能力使人們有可能使用它傳輸一些重要的必須保證可達的數據。可以與一個定期加載數據的線下系統集成，或者與一個因為維護長時間下線的系統集成。流處理的組件能夠保證轉換(處理)到達的數據。</p><p><strong>5、Kafka與ActiveMQ對比</strong></p><p>首先，Active MQ與Kafka的相同點只有一個，就是都是消息中間件。其他沒有任何相同點。</p><p><strong>5.1 consumer的不同</strong></p><p><strong>(1)AMQ消費完的消息會被清理掉</strong></p><p>AMQ無論在standalone還是分佈式的情況下，都會使用mysql作為存儲，多一個consumer線程去消費多個queue, 消費完的message會在mysql中被清理掉。</p><p><strong>(2)AMQ的消費邏輯在Broker中完成</strong></p><p>作為AMQ的consume clinet的多個consumer線程去消費queue，AMQ Broker會接收到這些consume線程，阻塞在這裡，有message來了就會進行消費，沒有消息就會阻塞在這裡。具體消費的邏輯也就是處理這些consumer線程都是AMQ Broker那面處理。</p><p>kafka是message都存在partition下的segment文件裡面，有offsite偏移量去記錄那條消費了，哪條沒消費。某個consumer group下consumer線程消費完就會，這個consumer group 下的這個consumer對應這個partition的offset+1，kafka並不會刪除這條已經被消費的message。其他的consumer group也可以再次消費這個message。在high level api中offset會自動或手動的提交到zookeeper上(如果是自動提交就有可能處理失敗或還沒處理完就提交offset+1了，容易出現下次再啟動consumer group的時候這條message就被漏了)，也可以使用low level api，那麼就是consumer程序中自己維護offset+1的邏輯。kafka中的message會定期刪除。</p><p><strong>(3)Kafka有consumer group的概念，AMQ沒有。</strong></p><p>一個consumer group下有多個consumer，每個consumer都是一個線程，consumer group是一個線程組。每個線程組consumer group之間互相獨立。同一個partition中的一個message只能被一個consumer group下的一個consumer線程消費，因為消費完了這個consumer group下的這個consumer對應的這個partition的offset就+1了，這個consumer group下的其他consumer還是這個consumer都不能在消費了。 但是另外一個consumer group是完全獨立的，可以設置一個from的offset位置，重新消費這個partition。</p><p><strong>5.2 關於存儲結構</strong></p><p>ActiveMQ的消息持久化機制有JDBC，AMQ，KahaDB和LevelDB</p><p>Kafka是文件存儲，每個topic有多個partition，每個partition有多個replica副本(每個partition和replica都是均勻分配在不同的kafka broker上的)。每個partition由多個segment文件組成。這些文件是順序存儲的。因此讀取和寫入都是順序的，因此，速度很快，省去了磁盤尋址的時間。</p><p>很多系統、組件為了提升效率一般恨不得把所有數據都扔到內存裡，然後定期flush到磁盤上;而Kafka決定直接使用頁面緩存;但是隨機寫入的效率很慢，為了維護彼此的關係順序還需要額外的操作和存儲，而線性的順序寫入可以避免磁盤尋址時間，實際上，線性寫入(linear write)的速度大約是300MB/秒，但隨即寫入卻只有50k/秒，其中的差別接近10000倍。這樣，Kafka以頁面緩存為中間的設計在保證效率的同時還提供了消息的持久化，每個consumer自己維護當前讀取數據的offset(也可委託給zookeeper)，以此可同時支持在線和離線的消費。</p><p><strong>5.3 關於使用場景與吞吐量</strong></p><p>ActiveMQ用於企業消息中間件，使得業務邏輯和前端處理邏輯解耦。AMQ的吞吐量不大，zuora的AMQ就是用作jms來使用。AMQ吞吐量不夠，並且持久化message數據通過jdbc存在mysql，寫入和讀取message性能太低。而Kafka的吞吐量非常大。</p><p><strong>5.4 push/pull 模型</strong></p><p>對於消費者而言有兩種方式從消息中間件獲取消息：</p><p>①Push方式：由消息中間件主動地將消息推送給消費者，採用Push方式，可以儘可能快地將消息發送給消費者;②Pull方式：由消費者主動向消息中間件拉取消息，會增加消息的延遲，即消息到達消費者的時間有點長</p><p>但是，Push方式會有一個壞處：如果消費者的處理消息的能力很弱(一條消息需要很長的時間處理)，而消息中間件不斷地向消費者Push消息，消費者的緩衝區可能會溢出。</p><p><strong>AMQ的Push消費</strong></p><p>ActiveMQ使用PUSH模型， 對於PUSH，broker很難控制數據發送給不同消費者的速度。AMQ Broker將message推送給對應的BET consumer。ActiveMQ用prefetch limit 規定了一次可以向消費者Push(推送)多少條消息。當推送消息的數量到達了perfetch limit規定的數值時，消費者還沒有向消息中間件返回ACK，消息中間件將不再繼續向消費者推送消息。</p><p><strong>AMQ的Pull消費</strong></p><p>ActiveMQ prefetch limit 設置成0意味著什麼?意味著此時，消費者去輪詢消息中間件獲取消息。不再是Push方式了，而是Pull方式了。即消費者主動去消息中間件拉取消息。</p><p>那麼，ActiveMQ中如何採用Push方式或者Pull方式呢?從是否阻塞來看，消費者有兩種方式獲取消息。同步方式和異步方式。</p><p>同步方式使用的是ActiveMQMessageConsumer的receive()方法。而異步方式則是採用消費者實現MessageListener接口，監聽消息。使用同步方式receive()方法獲取消息時，prefetch limit即可以設置為0，也可以設置為大於0。</p><p>prefetch limit為零 意味著：“receive()方法將會首先發送一個PULL指令並阻塞，直到broker端返回消息為止，這也意味著消息只能逐個獲取(類似於Request&lt;->Response)”。</p><p>prefetch limit 大於零 意味著：“broker端將會批量push給client 一定數量的消息(&lt;= prefetch)，client端會把這些消息(unconsumedMessage)放入到本地的隊列中，只要此隊列有消息，那麼receive方法將會立即返回，當一定量的消息ACK之後，broker端會繼續批量push消息給client端。”</p><p>當使用MessageListener異步獲取消息時，prefetch limit必須大於零了。因為，prefetch limit 等於零 意味著消息中間件不會主動給消費者Push消息，而此時消費者又用MessageListener被動獲取消息(不會主動去輪詢消息)。這二者是矛盾的。</p><p><strong>Kafka只有Pull消費方式</strong></p><p>Kafka使用PULL模型，PULL可以由消費者自己控制，但是PULL模型可能造成消費者在沒有消息的情況下盲等，這種情況下可以通過long polling機制緩解，而對於幾乎每時每刻都有消息傳遞的流式系統，這種影響可以忽略。Kafka 的 consumer 是以pull的形式獲取消息數據的。 pruducer push消息到kafka cluster ，consumer從集群中pull消息。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>2019</a></li><li><a>kafka</a></li><li><a>架構</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html alt=2019年土木畢業生要知道的那些事 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html title=2019年土木畢業生要知道的那些事>2019年土木畢業生要知道的那些事</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html alt=2019年度《特種鑄造及有色合金》優秀論文結果公佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/137c70000b816835d80bf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html title=2019年度《特種鑄造及有色合金》優秀論文結果公佈>2019年度《特種鑄造及有色合金》優秀論文結果公佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html alt=2019年度《特種鑄造及有色合金》網絡評選結果出爐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/66c26cbe459a4361b1d501e4bbac6c88 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html title=2019年度《特種鑄造及有色合金》網絡評選結果出爐>2019年度《特種鑄造及有色合金》網絡評選結果出爐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html alt=金川集團公司2019年全國合金鑄造行業商洽會舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html title=金川集團公司2019年全國合金鑄造行業商洽會舉行>金川集團公司2019年全國合金鑄造行業商洽會舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/24a6006e.html alt=服務器架構：十張圖帶你瞭解大型網站架構 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/2af10e2429bc47a5823244277a07bb77 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/24a6006e.html title=服務器架構：十張圖帶你瞭解大型網站架構>服務器架構：十張圖帶你瞭解大型網站架構</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html alt="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html title="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班">2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html alt=2019年最爆笑的120個名場面合集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dc6fcd05f35e499a9ef7a2d19ff9c66b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html title=2019年最爆笑的120個名場面合集>2019年最爆笑的120個名場面合集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html alt=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a08cc2f25cb41c5be515de0d79879a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html title=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝>《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html alt="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/Rk8ZSn39iz0Be8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html title="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法">2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html alt=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/f8d17716-f3b8-4c6d-8eb7-f482334ad491 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html title=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！>2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html alt=2019年正在流行的16個網頁設計趨勢 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RPgQdSQEjBTN6Z style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html title=2019年正在流行的16個網頁設計趨勢>2019年正在流行的16個網頁設計趨勢</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d72ed228.html alt=2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fbcf9bc4d8224c309106305ad34adf9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d72ed228.html title=2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一）>2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d4044e1f.html alt=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d4044e1f.html title=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一）>2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f855d5ae.html alt=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9796cfd44f754f9ab22310d91088423e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f855d5ae.html title=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二）>2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9adee5f1.html alt=2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d6a75905fb9346ccb6e4c8a304a79e63 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9adee5f1.html title=2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2>2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>