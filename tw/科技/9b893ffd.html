<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>大數據處理經典方法 | 极客快訊</title><meta property="og:title" content="大數據處理經典方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/dfic-imagehandler/aafcb0ae-1169-4605-98f1-3c041f9fd2a4"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9b893ffd.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9b893ffd.html><meta property="article:published_time" content="2020-11-14T21:04:22+08:00"><meta property="article:modified_time" content="2020-11-14T21:04:22+08:00"><meta name=Keywords content><meta name=description content="大數據處理經典方法"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/9b893ffd.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>大數據處理經典方法</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=大數據處理經典方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/dfic-imagehandler/aafcb0ae-1169-4605-98f1-3c041f9fd2a4><p class=pgc-img-caption></p></div><p>1.Hadoop集群可以運行的3個模式？</p><p>單機（本地）模式</p><p>偽分佈式模式</p><p>全分佈式模式</p><p>2. 單機（本地）模式中的注意點？</p><p>在單機模式（standalone）中不會存在守護進程，所有東西都運行在一個JVM上。這裡同樣沒有DFS，使用的是本地文件系統。單機模式適用於開發過程中運行MapReduce程序，這也是最少使用的一個模式。</p><p>3. 偽分佈模式中的注意點？</p><p>偽分佈式（Pseudo）適用於開發和測試環境，在這個模式中，所有守護進程都在同一臺機器上運行。</p><p>4. VM是否可以稱為Pseudo？</p><p>不是，兩個事物，同時Pseudo只針對Hadoop。</p><p><strong>在這裡還是要推薦下我自己建的大數據學習交流群:199427210，群裡都是學大數據開發的，如果你正在學習大數據</strong></p><p><strong>，小編歡迎你加入,大家都是軟件開發黨，不定期分享乾貨（只有大數據軟件開發相關的），包括我自己整理的一份</strong></p><p><strong>最新的大數據進階資料和高級開發教程，歡迎進階中和進想深入大數據的小夥伴加入。</strong></p><p>5. 全分佈模式又有什麼注意點？</p><p>全分佈模式通常被用於生產環境，這裡我們使用N臺主機組成一個Hadoop集群，Hadoop守護進程運行在每臺主機之上。這裡會存在Namenode運行的主機，Datanode運行的主機，以及task tracker運行的主機。在分佈式環境下，主節點和從節點會分開。</p><p>6. Hadoop是否遵循UNIX模式？</p><p>是的，在UNIX用例下，Hadoop還擁有“conf”目錄。</p><p>7. Hadoop安裝在什麼目錄下？</p><p>Cloudera和Apache使用相同的目錄結構，Hadoop被安裝在cd/usr/lib/hadoop-0.20/。</p><p>8. Namenode、Job tracker和task tracker的端口號是？</p><p>Namenode，70；Job tracker，30；Task tracker，60。</p><p>9. Hadoop的核心配置是什麼？</p><p>Hadoop的核心配置通過兩個xml文件來完成：1，hadoop-default.xml；2，hadoop-site.xml。這些文件都使用xml格式，因此每個xml中都有一些屬性，包括名稱和值，但是當下這些文件都已不復存在。</p><p>10. 那當下又該如何配置？</p><p>Hadoop現在擁有3個配置文件：1，core-site.xml；2，hdfs-site.xml；3，mapred-site.xml。這些文件都保存在conf/子目錄下。</p><p>11. RAM的溢出因子是？</p><p>溢出因子（Spill factor）是臨時文件中儲存文件的大小，也就是Hadoop-temp目錄。</p><p>12. fs.mapr.working.dir只是單一的目錄？</p><p>fs.mapr.working.dir只是一個目錄。</p><p>13. hdfs-site.xml的3個主要屬性？</p><p>dfs.name.dir決定的是元數據存儲的路徑以及DFS的存儲方式（磁盤或是遠端）</p><p>dfs.data.dir決定的是數據存儲的路徑</p><p>fs.checkpoint.dir用於第二Namenode</p><p>14. 如何退出輸入模式？</p><p>退出輸入的方式有：1，按ESC；2，鍵入:q（如果你沒有輸入任何當下）或者鍵入:wq（如果你已經輸入當下），並且按下Enter。</p><p>15. 當你輸入hadoopfsck /造成“connection refused java exception’”時，系統究竟發生了什麼？</p><p>這意味著Namenode沒有運行在你的VM之上。</p><p>16. 我們使用Ubuntu及Cloudera，那麼我們該去哪裡下載Hadoop，或者是默認就與Ubuntu一起安裝？</p><p>這個屬於Hadoop的默認配置，你必須從Cloudera或者Edureka的dropbox下載，然後在你的系統上運行。當然，你也可以自己配置，但是你需要一個Linux box，Ubuntu或者是Red Hat。在Cloudera網站或者是Edureka的Dropbox中有安裝步驟。</p><p>17. “jps”命令的用處？</p><p>這個命令可以檢查Namenode、Datanode、Task Tracker、 Job Tracker是否正常工作。</p><p>18. 如何重啟Namenode？</p><p>點擊stop-all.sh，再點擊start-all.sh。</p><p>鍵入sudo hdfs（Enter），su-hdfs （Enter），/etc/init.d/ha（Enter），及/etc/init.d/hadoop-0.20-namenode start（Enter）。</p><p>19. Fsck的全名？</p><p>全名是：File System Check。</p><p>20. 如何檢查Namenode是否正常運行？</p><p>如果要檢查Namenode是否正常工作，使用命令/etc/init.d/hadoop-0.20-namenode status或者就是簡單的jps。</p><p>21. mapred.job.tracker命令的作用？</p><p>可以讓你知道哪個節點是Job Tracker。</p><p>22. /etc /init.d命令的作用是？</p><p>/etc /init.d說明了守護進程（服務）的位置或狀態，其實是LINUX特性，和Hadoop關係不大。</p><p>23. 如何在瀏覽器中查找Namenode？</p><p>如果你確實需要在瀏覽器中查找Namenode，你不再需要localhost:8021，Namenode的端口號是50070。</p><p>24. 如何從SU轉到Cloudera？</p><p>從SU轉到Cloudera只需要鍵入exit。</p><p>25. 啟動和關閉命令會用到哪些文件？</p><p>Slaves及Masters。</p><p>26. Slaves由什麼組成？</p><p>Slaves由主機的列表組成，每臺1行，用於說明數據節點。</p><p>27. Masters由什麼組成？</p><p>Masters同樣是主機的列表組成，每臺一行，用於說明第二Namenode服務器。</p><p>28. hadoop-env.sh是用於做什麼的？</p><p>hadoop-env.sh提供了Hadoop中. JAVA_HOME的運行環境。</p><p>29. Master文件是否提供了多個入口？</p><p>是的你可以擁有多個Master文件接口。</p><p>30. Hadoop-env.sh文件當下的位置？</p><p>hadoop-env.sh現在位於conf。</p><p>31. 在Hadoop_PID_DIR中，PID代表了什麼？</p><p>PID代表了“Process ID”。</p><p>32. /var/hadoop/pids用於做什麼？</p><p>/var/hadoop/pids用來存儲PID。</p><p>33. hadoop-metrics.properties文件的作用是？</p><p>hadoop-metrics.properties被用做“Reporting”，控制Hadoop報告，初始狀態是“not to report”。</p><p>34. Hadoop需求什麼樣的網絡？</p><p>Hadoop核心使用Shell（SSH）來驅動從節點上的服務器進程，並在主節點和從節點之間使用password-less SSH連接。</p><p>35. 全分佈式環境下為什麼需求password-less SSH？</p><p>這主要因為集群中通信過於頻繁，Job Tracker需要儘可能快的給Task Tracker發佈任務。</p><p>36. 這會導致安全問題嗎？</p><p>完全不用擔心。Hadoop集群是完全隔離的，通常情況下無法從互聯網進行操作。與眾不同的配置，因此我們完全不需要在意這種級別的安全漏洞，比如說通過互聯網侵入等等。Hadoop為機器之間的連接提供了一個相對安全的方式。</p><p>37. SSH工作的端口號是？</p><p>SSH工作的端口號是NO.22，當然可以通過它來配置，22是默認的端口號。</p><p>38. SSH中的注意點還包括？</p><p>SSH只是個安全的shell通信，可以把它當做NO.22上的一種協議，只需要配置一個密碼就可以安全的訪問。</p><p>39. 為什麼SSH本地主機需要密碼？</p><p>在SSH中使用密碼主要是增加安全性，在某些情況下也根本不會設置密碼通信。</p><p>40. 如果在SSH中添加key，是否還需要設置密碼？</p><p>是的，即使在SSH中添加了key，還是需要設置密碼。</p><p>41. 假如Namenode中沒有數據會怎麼樣？</p><p>沒有數據的Namenode就不能稱之為Namenode，通常情況下，Namenode肯定會有數據。</p><p>42. 當Job Tracker宕掉時，Namenode會發生什麼？</p><p>當Job Tracker失敗時，集群仍然可以正常工作，只要Namenode沒問題。</p><p>43. 是客戶端還是Namenode決定輸入的分片？</p><p>這並不是客戶端決定的，在配置文件中以及決定分片細則。</p><p>44. 是否可以自行搭建Hadoop集群？</p><p>是的，只要對Hadoop環境足夠熟悉，你完全可以這麼做。</p><p>45. 是否可以在Windows上運行Hadoop？</p><p>你最好不要這麼做，Red Hat Linux或者是Ubuntu才是Hadoop的最佳操作系統。在Hadoop安裝中，Windows通常不會被使用，因為會出現各種各樣的問題。因此，Windows絕對不是Hadoop的推薦系統。</p><p><strong>第一部分、十道海量數據處理面試題</strong></p><p><strong>1、海量日誌數據，提取出某日訪問百度次數最多的那個IP。</strong></p><p>首先是這一天，並且是訪問百度的日誌中的IP取出來，逐個寫入到一個大文件中。注意到IP是32位的，最多有個2^32個IP。同樣可以採用映射的方法， 比如模1000，把整個大文件映射為1000個小文件，再找出每個小文中出現頻率最大的IP（可以採用hash_map進行頻率統計，然後再找出頻率最大 的幾個）及相應的頻率。然後再在這1000個最大的IP中，找出那個頻率最大的IP，即為所求。</p><p>或者如下闡述（雪域之鷹）：</p><p><strong>算法思想：分而治之+Hash</strong></p><p>1.IP地址最多有2^32=4G種取值情況，所以不能完全加載到內存中處理；</p><p>2.可以考慮採用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日誌分別存儲到1024個小文件中。這樣，每個小文件最多包含4MB個IP地址；</p><p>3.對於每一個小文件，可以構建一個IP為key，出現次數為value的Hash map，同時記錄當前出現次數最多的那個IP地址；</p><p>4.可以得到1024個小文件中的出現次數最多的IP，再依據常規的排序算法得到總體上出現次數最多的IP；</p><p><strong>2、搜索引擎會通過日誌文件把用戶每次檢索使用的所有檢索串都記錄下來，每個查詢串的長度為1-255字節。</strong></p><p>假設目前有一千萬個記錄（這些查詢串的重複度比較高，雖然總數是1千萬，但如果除去重複後，不超過3百萬個。一個查詢串的重複度越高，說明查詢它的用戶越多，也就是越熱門。），請你統計最熱門的10個查詢串，要求使用的內存不能超過1G。</p><p>文中，給出的最終算法是：</p><p>第一步、先對這批海量數據預處理，在O（N）的時間內用Hash表完成<strong>統計</strong>（之前寫成了排序，特此訂正。July、2011.04.27）；</p><p>第二步、藉助堆這個數據結構，找出Top K，時間複雜度為N‘logK。</p><p>即，藉助堆結構，我們可以在log量級的時間內查找和調整/移動。因此，維護一個K(該題目中是10)大小的小根堆，然後遍歷300萬的Query，分別 和根元素進行對比所以，我們最終的時間複雜度是：O（N） + N’*O（logK），（N為1000萬，N’為300萬）。ok，更多，詳情，請參考原文。</p><p>或者：採用trie樹，關鍵字域存該查詢串出現的次數，沒有出現為0。最後用10個元素的最小推來對出現頻率進行排序。</p><p><strong>3、有一個1G大小的一個文件，裡面每一行是一個詞，詞的大小不超過16字節，內存限制大小是1M。返回頻數最高的100個詞。</strong></p><p>方案：順序讀文件中，對於每個詞x，取hash(x)%5000，然後按照該值存到5000個小文件（記為x0,x1,…x4999）中。這樣每個文件大概是200k左右。</p><p>如果其中的有的文件超過了1M大小，還可以按照類似的方法繼續往下分，直到分解得到的小文件的大小都不超過1M。</p><p>對每個小文件，統計每個文件中出現的詞以及相應的頻率（可以採用trie樹/hash_map等），並取出出現頻率最大的100個詞（可以用含100個結 點的最小堆），並把100個詞及相應的頻率存入文件，這樣又得到了5000個文件。下一步就是把這5000個文件進行歸併（類似與歸併排序）的過程了。</p><p><strong>4、有10個文件，每個文件1G，每個文件的每一行存放的都是用戶的query，每個文件的query都可能重複。要求你按照query的頻度排序。</strong></p><p>還是典型的TOP K算法，解決方案如下：</p><p>方案1：</p><p>順序讀取10個文件，按照hash(query)%10的結果將query寫入到另外10個文件（記為）中。這樣新生成的文件每個的大小大約也1G（假設hash函數是隨機的）。</p><p>找一臺內存在2G左右的機器，依次對用hash_map(query, query_count)來統計每個query出現的次數。利用快速/堆/歸併排序按照出現次數進行排序。將排序好的query和對應的 query_cout輸出到文件中。這樣得到了10個排好序的文件（記為）。</p><p>對這10個文件進行歸併排序（內排序與外排序相結合）。</p><p>方案2：</p><p>一般query的總量是有限的，只是重複的次數比較多而已，可能對於所有的query，一次性就可以加入到內存了。這樣，我們就可以採用trie樹/hash_map等直接來統計每個query出現的次數，然後按出現次數做快速/堆/歸併排序就可以了。</p><p>方案3：</p><p>與方案1類似，但在做完hash，分成多個文件後，可以交給多個文件來處理，採用分佈式的架構來處理（比如MapReduce），最後再進行合併。</p><p><strong>5、 給定a、b兩個文件，各存放50億個url，每個url各佔64字節，內存限制是4G，讓你找出a、b文件共同的url？</strong></p><p>方案1：可以估計每個文件安的大小為5G×64=320G，遠遠大於內存限制的4G。所以不可能將其完全加載到內存中處理。考慮採取分而治之的方法。</p><p>遍歷文件a，對每個url求取hash(url)%1000，然後根據所取得的值將url分別存儲到1000個小文件（記為a0,a1,…,a999）中。這樣每個小文件的大約為300M。</p><p>遍歷文件b，採取和a相同的方式將url分別存儲到1000小文件（記為b0,b1,…,b999）。這樣處理後，所有可能相同的url都在對應的小 文件（a0vsb0,a1vsb1,…,a999vsb999）中，不對應的小文件不可能有相同的url。然後我們只要求出1000對小文件中相同的 url即可。</p><p>求每對小文件中相同的url時，可以把其中一個小文件的url存儲到hash_set中。然後遍歷另一個小文件的每個url，看其是否在剛才構建的hash_set中，如果是，那麼就是共同的url，存到文件裡面就可以了。</p><p>方案2：如果允許有一定的錯誤率，可以使用Bloom filter，4G內存大概可以表示340億bit。將其中一個文件中的url使用Bloom filter映射為這340億bit，然後挨個讀取另外一個文件的url，檢查是否與Bloom filter，如果是，那麼該url應該是共同的url（注意會有一定的錯誤率）。</p><p>Bloom filter日後會在本BLOG內詳細闡述。</p><p><strong>6、在2.5億個整數中找出不重複的整數，注，內存不足以容納這2.5億個整數。</strong></p><p>方案1：採用2-Bitmap（每個數分配2bit，00表示不存在，01表示出現一次，10表示多次，11無意義）進行，共需內存2^32 * 2 bit=1 GB內存，還可以接受。然後掃描這2.5億個整數，查看Bitmap中相對應位，如果是00變01，01變10，10保持不變。所描完事後，查看 bitmap，把對應位是01的整數輸出即可。</p><p>方案2：也可採用與第1題類似的方法，進行劃分小文件的方法。然後在小文件中找出不重複的整數，並排序。然後再進行歸併，注意去除重複的元素。</p><p><strong>7、騰訊面試題：給40億個不重複的unsigned int的整數，沒排過序的，然後再給一個數，如何快速判斷這個數是否在那40億個數當中？</strong></p><p>與上第6題類似，我的第一反應時快速排序+二分查找。以下是其它更好的方法：</p><p><strong>方案1：</strong>oo，申請512M的內存，一個bit位代表一個unsigned int值。讀入40億個數，設置相應的bit位，讀入要查詢的數，查看相應bit位是否為1，為1表示存在，為0表示不存在。</p><p>dizengrong：</p><p><strong>方案2：</strong>這個問題在《編程珠璣》裡有很好的描述，大家可以參考下面的思路，探討一下：</p><p>又因為2^32為40億多，所以給定一個數可能在，也可能不在其中；</p><p>這裡我們把40億個數中的每一個用32位的二進制來表示</p><p>假設這40億個數開始放在一個文件中。</p><p>然後將這40億個數分成兩類:</p><p>1.最高位為0</p><p>2.最高位為1</p><p>並將這兩類分別寫入到兩個文件中，其中一個文件中數的個數&lt;=20億，而另一個>=20億（這相當於折半了）；</p><p>與要查找的數的最高位比較並接著進入相應的文件再查找</p><p>再然後把這個文件為又分成兩類:</p><p>1.次最高位為0</p><p>2.次最高位為1</p><p>並將這兩類分別寫入到兩個文件中，其中一個文件中數的個數&lt;=10億，而另一個>=10億（這相當於折半了）；</p><p>與要查找的數的次最高位比較並接著進入相應的文件再查找。</p><p>…….</p><p>以此類推，就可以找到了,而且時間複雜度為O(logn)，方案2完。</p><p><strong>附：</strong>這裡，再簡單介紹下，位圖方法：</p><p>使用位圖法判斷整形數組是否存在重複</p><p>判斷集合中存在重複是常見編程任務之一，當集合中數據量比較大時我們通常希望少進行幾次掃描，這時雙重循環法就不可取了。</p><p>位圖法比較適合於這種情況，它的做法是按照集合中最大元素max創建一個長度為max+1的新數組，然後再次掃描原數組，遇到幾就給新數組的第幾位置上 1，如遇到5就給新數組的第六個元素置1，這樣下次再遇到5想置位時發現新數組的第六個元素已經是1了，這說明這次的數據肯定和以前的數據存在著重複。這 種給新數組初始化時置零其後置一的做法類似於位圖的處理方法故稱位圖法。它的運算次數最壞的情況為2N。如果已知數組的最大值即能事先給新數組定長的話效 率還能提高一倍。</p><p>歡迎，有更好的思路，或方法，共同交流。</p><p><strong>8、怎麼在海量數據中找出重複次數最多的一個？</strong></p><p>方案1：先做hash，然後求模映射為小文件，求出每個小文件中重複次數最多的一個，並記錄重複次數。然後找出上一步求出的數據中重複次數最多的一個就是所求（具體參考前面的題）。</p><p><strong>9、上千萬或上億數據（有重複），統計其中出現次數最多的錢N個數據。</strong></p><p>方案1：上千萬或上億的數據，現在的機器的內存應該能存下。所以考慮採用hash_map/搜索二叉樹/紅黑樹等來進行統計次數。然後就是取出前N個出現次數最多的數據了，可以用第2題提到的堆機制完成。</p><p><strong>10、一個文本文件，大約有一萬行，每行一個詞，要求統計出其中最頻繁出現的前10個詞，請給出思想，給出時間複雜度分析。</strong></p><p>方案1：這題是考慮時間效率。用trie樹統計每個詞出現的次數，時間複雜度是O(n*le)（le表示單詞的平準長度）。然後是找出出現最頻繁的前10 個詞，可以用堆來實現，前面的題中已經講到了，時間複雜度是O(n*lg10)。所以總的時間複雜度，是O(n*le)與O(n*lg10)中較大的哪一 個。</p><p><strong>附、100w個數中找出最大的100個數。</strong></p><p>方案1：在前面的題中，我們已經提到了，用一個含100個元素的最小堆完成。複雜度為O(100w*lg100)。</p><p>方案2：採用快速排序的思想，每次分割之後只考慮比軸大的一部分，知道比軸大的一部分在比100多的時候，採用傳統排序算法排序，取前100個。複雜度為O(100w*100)。</p><p>方案3：採用局部淘汰法。選取前100個元素，並排序，記為序列L。然後一次掃描剩餘的元素x，與排好序的100個元素中最小的元素比，如果比這個最小的 要大，那麼把這個最小的元素刪除，並把x利用插入排序的思想，插入到序列L中。依次循環，知道掃描了所有的元素。複雜度為O(100w*100)。</p><p><strong>第二部分、十個海量數據處理方法大總結</strong></p><p>ok，看了上面這麼多的面試題，是否有點頭暈。是的，需要一個總結。接下來，本文將簡單總結下一些處理海量數據問題的常見方法，<strong>而日後，本BLOG內會具體闡述這些方法。</strong></p><p>一、Bloom filter</p><p>適用範圍：可以用來實現數據字典，進行數據的判重，或者集合求交集</p><p>基本原理及要點：</p><p>對於原理來說很簡單，位數組+k個獨立hash函數。將 hash函數對應的值的位數組置1，查找時如果發現所有hash函數對應位都是1說明存在，很明顯這個過程並不保證查找的結果是100%正確的。同時也不 支持刪除一個已經插入的關鍵字，因為該關鍵字對應的位會牽動到其他的關鍵字。所以一個簡單的改進就是 counting Bloom filter，用一個counter數組代替位數組，就可以支持刪除了。</p><p>還有一個比較重要的問題，如何根據輸入元素個數n，確定位數組m的大小及hash函數 個數。當hash函數個數k=(ln2)*(m/n)時錯誤率最小。在錯誤率不大於E的情況下，m至少要等於n*lg(1/E)才能表示任意n個元素的集 合。但m還應該更大些，因為還要保證bit數組裡至少一半為0，則m應該>=nlg(1/E)*lge 大概就是nlg(1/E)1.44倍(lg表示以2為底的對數)。</p><p>舉個例子我們假設錯誤率為0.01，則此時m應大概是n的13倍。這樣k大概是8個。</p><p>注意這裡m與n的單位不同，m是bit為單位，而n則是以元素個數為單位(準確的說是不同元素的個數)。通常單個元素的長度都是有很多bit的。所以使用bloom filter內存上通常都是節省的。</p><p>擴展：</p><p>Bloom filter將集合中的元素映射到位數組中，用k（k為哈希函數個數）個映射位是否全1表示元素在不在這個集合中。Counting bloom filter（CBF）將位數組中的每一位擴展為一個counter，從而支持了元素的刪除操作。Spectral Bloom Filter（SBF）將其與集合元素的出現次數關聯。SBF採用counter中的最小值來近似表示元素的出現頻率。</p><p>問題實例：給你A,B兩個文件，各存放50億條URL，每條URL佔用64字節，內存限制是4G，讓你找出A,B文件共同的URL。如果是三個乃至n個文件呢？</p><p>根據這個問題我們來計算下內存的佔用，4G=2^32大概是40億*8大概是340 億，n=50億，如果按出錯率0.01算需要的大概是650億個bit。現在可用的是340億，相差並不多，這樣可能會使出錯率上升些。另外如果這些 urlip是一一對應的，就可以轉換成ip，則大大簡單了。</p><p>二、Hashing</p><p>適用範圍：快速查找，刪除的基本數據結構，通常需要總數據量可以放入內存</p><p>基本原理及要點：</p><p>hash函數選擇，針對字符串，整數，排列，具體相應的hash方法。</p><p>碰撞處理，一種是open hashing，也稱為拉鍊法；另一種就是closed hashing，也稱開地址法，opened addressing。</p><p>擴展：</p><p>d-left hashing中的d是多個的意思，我們先簡化這個問題，看一看2-left hashing。2-left hashing指的是將一個哈希表分成長度相等的兩半，分別叫做T1和T2，給T1和T2分別配備一個哈希函數，h1和h2。在存儲一個新的key時，同 時用兩個哈希函數進行計算，得出兩個地址h1[key]和h2[key]。這時需要檢查T1中的h1[key]位置和T2中的h2[key]位置，哪一個 位置已經存儲的（有碰撞的）key比較多，然後將新key存儲在負載少的位置。如果兩邊一樣多，比如兩個位置都為空或者都存儲了一個key，就把新key 存儲在左邊的T1子表中，2-left也由此而來。在查找一個key時，必須進行兩次hash，同時查找兩個位置。</p><p>問題實例：</p><p>1).海量日誌數據，提取出某日訪問百度次數最多的那個IP。</p><p>IP的數目還是有限的，最多2^32個，所以可以考慮使用hash將ip直接存入內存，然後進行統計。</p><p>三、bit-map</p><p>適用範圍：可進行數據的快速查找，判重，刪除，一般來說數據範圍是int的10倍以下</p><p>基本原理及要點：使用bit數組來表示某些元素是否存在，比如8位電話號碼</p><p>擴展：bloom filter可以看做是對bit-map的擴展</p><p>問題實例：</p><p>1)已知某個文件內包含一些電話號碼，每個號碼為8位數字，統計不同號碼的個數。</p><p>8位最多99 999 999，大概需要99m個bit，大概10幾m字節的內存即可。</p><p>2)2.5億個整數中找出不重複的整數的個數，內存空間不足以容納這2.5億個整數。</p><p>將bit-map擴展一下，用2bit表示一個數即可，0表示未出現，1表示出現一次，2表示出現2次及以上。或者我們不用2bit來進行表示，我們用兩個bit-map即可模擬實現這個2bit-map。</p><p>四、堆</p><p>適用範圍：海量數據前n大，並且n比較小，堆可以放入內存</p><p>基本原理及要點：最大堆求前n小，最小堆求前n大。方法，比如求前n小，我們比較當前 元素與最大堆裡的最大元素，如果它小於最大元素，則應該替換那個最大元素。這樣最後得到的n個元素就是最小的n個。適合大數據量，求前n小，n的大小比較 小的情況，這樣可以掃描一遍即可得到所有的前n元素，效率很高。</p><p>擴展：雙堆，一個最大堆與一個最小堆結合，可以用來維護中位數。</p><p>問題實例：</p><p>1)100w個數中找最大的前100個數。</p><p>用一個100個元素大小的最小堆即可。</p><p>五、雙層桶劃分—-其實本質上就是【分而治之】的思想，重在“分”的技巧上！</p><p>適用範圍：第k大，中位數，不重複或重複的數字</p><p>基本原理及要點：因為元素範圍很大，不能利用直接尋址表，所以通過多次劃分，逐步確定範圍，然後最後在一個可以接受的範圍內進行。可以通過多次縮小，雙層只是一個例子。</p><p>擴展：</p><p>問題實例：</p><p>1).2.5億個整數中找出不重複的整數的個數，內存空間不足以容納這2.5億個整數。</p><p>有點像鴿巢原理，整數個數為2^32,也就是，我們可以將這2^32個數，劃分為2^8個區域(比如用單個文件代表一個區域)，然後將數據分離到不同的區域，然後不同的區域在利用bitmap就可以直接解決了。也就是說只要有足夠的磁盤空間，就可以很方便的解決。</p><p>2).5億個int找它們的中位數。</p><p>這個例子比上面那個更明顯。首先我們 將int劃分為2^16個區域，然後讀取數據統計落到各個區域裡的數的個數，之後我們根據統計結果就可以判斷中位數落到那個區域，同時知道這個區域中的第 幾大數剛好是中位數。然後第二次掃描我們只統計落在這個區域中的那些數就可以了。</p><p>實際上，如果不是int是int64，我們可以經過3次這樣的劃分即可降低到可以接受 的程度。即可以先將int64分成2^24個區域，然後確定區域的第幾大數，在將該區域分成2^20個子區域，然後確定是子區域的第幾大數，然後子區域裡 的數的個數只有2^20，就可以直接利用direct addr table進行統計了。</p><p>六、數據庫索引</p><p>適用範圍：大數據量的增刪改查</p><p>基本原理及要點：利用數據的設計實現方法，對海量數據的增刪改查進行處理。</p><p>七、倒排索引(Inverted index)</p><p>適用範圍：搜索引擎，關鍵字查詢</p><p>基本原理及要點：為何叫倒排索引？一種索引方法，被用來存儲在全文搜索下某個單詞在一個文檔或者一組文檔中的存儲位置的映射。</p><p>以英文為例，下面是要被索引的文本：</p><p>T0 = “it is what it is”</p><p>T1 = “what is it”</p><p>T2 = “it is a banana”</p><p>我們就能得到下面的反向文件索引：</p><p>“a”: {2}</p><p>“banana”: {2}</p><p>“is”: {0, 1, 2}</p><p>“it”: {0, 1, 2}</p><p>“what”: {0, 1}</p><p>檢索的條件”what”,”is”和”it”將對應集合的交集。</p><p>正向索引開發出來用來存儲每個文檔的單詞的列表。正向索引的查詢往往滿足每個文檔有序 頻繁的全文查詢和每個單詞在校驗文檔中的驗證這樣的查詢。在正向索引中，文檔佔據了中心的位置，每個文檔指向了一個它所包含的索引項的序列。也就是說文檔 指向了它包含的那些單詞，而反向索引則是單詞指向了包含它的文檔，很容易看到這個反向的關係。</p><p>擴展：</p><p>問題實例：文檔檢索系統，查詢那些文件包含了某單詞，比如常見的學術論文的關鍵字搜索。</p><p>八、外排序</p><p>適用範圍：大數據的排序，去重</p><p>基本原理及要點：外排序的歸併方法，置換選擇敗者樹原理，最優歸併樹</p><p>擴展：</p><p>問題實例：</p><p>1).有一個1G大小的一個文件，裡面每一行是一個詞，詞的大小不超過16個字節，內存限制大小是1M。返回頻數最高的100個詞。</p><p>這個數據具有很明顯的特點，詞的大小為16個字節，但是內存只有1m做hash有些不夠，所以可以用來排序。內存可以當輸入緩衝區使用。</p><p>九、trie樹</p><p>適用範圍：數據量大，重複多，但是數據種類小可以放入內存</p><p>基本原理及要點：實現方式，節點孩子的表示方式</p><p>擴展：壓縮實現。</p><p>問題實例：</p><p>1).有10個文件，每個文件1G，每個文件的每一行都存放的是用戶的query，每個文件的query都可能重複。要你按照query的頻度排序。</p><p>2).1000萬字符串，其中有些是相同的(重複),需要把重複的全部去掉，保留沒有重複的字符串。請問怎麼設計和實現？</p><p>3).尋找熱門查詢：查詢串的重複度比較高，雖然總數是1千萬，但如果除去重複後，不超過3百萬個，每個不超過255字節。</p><p>十、分佈式處理 mapreduce</p><p>適用範圍：數據量大，但是數據種類小可以放入內存</p><p>基本原理及要點：將數據交給不同的機器去處理，數據劃分，結果歸約。</p><p>擴展：</p><p>問題實例：</p><p>1).The canonical example application of MapReduce is a process to count the appearances of</p><p>each different word in a set of documents:</p><p>2).海量數據分佈在100臺電腦中，想個辦法高效統計出這批數據的TOP10。</p><p>3).一共有N個機器，每個機器上有N個數。每個機器最多存O(N)個數並對它們操作。如何找到N^2個數的中數(median)？</p><p>經典問題分析</p><p>上千萬or億數據（有重複），統計其中出現次數最多的前N個數據,分兩種情況：可一次讀入內存，不可一次讀入。</p><p>可用思路：trie樹+堆，數據庫索引，劃分子集分別統計，hash，分佈式計算，近似統計，外排序</p><p>所謂的是否能一次讀入內存，實際上應該指去除重複後的數據量。如果去重後數據可以放入 內存，我們可以為數據建立字典，比如通過 map，hashmap，trie，然後直接進行統計即可。當然在更新每條數據的出現次數的時候，我們可以利用一個堆來維護出現次數最多的前N個數據，當 然這樣導致維護次數增加，不如完全統計後在求前N大效率高。</p><p>如果數據無法放入內存。一方面我們可以考慮上面的字典方法能否被改進以適應這種情形，可以做的改變就是將字典存放到硬盤上，而不是內存，這可以參考數據庫的存儲方法。</p><p>當然還有更好的方法，就是可以採用分佈式計算，基本上就是map-reduce過程， 首先可以根據數據值或者把數據hash(md5)後的值，將數據按照範圍劃分到不同的機子，最好可以讓數據劃分後可以一次讀入內存，這樣不同的機子負責處 理各種的數值範圍，實際上就是map。得到結果後，各個機子只需拿出各自的出現次數最多的前N個數據，然後彙總，選出所有的數據中出現次數最多的前N個數 據，</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>大數據</a></li><li><a>處理</a></li><li><a>經典</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/0ef96dd8.html alt=圖像處理十大經典算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2dcf54d94a52473d9cae29a6c4cb5b63 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/0ef96dd8.html title=圖像處理十大經典算法>圖像處理十大經典算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0653dd2.html alt=大唐鍋爐經典事故處理預案 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/dfic-imagehandler/b358cc05-9ec2-40e0-9c98-8532e15523d2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0653dd2.html title=大唐鍋爐經典事故處理預案>大唐鍋爐經典事故處理預案</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd89985.html alt="一文搞懂大數據批量處理框架Spring Batch的完美解析方案是什麼。" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/154047961018239d2cc8e07 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd89985.html title="一文搞懂大數據批量處理框架Spring Batch的完美解析方案是什麼。">一文搞懂大數據批量處理框架Spring Batch的完美解析方案是什麼。</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d566b6d.html alt=巧解圖像處理經典難題之圖像配準 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RdsLtaa7H5sExw style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d566b6d.html title=巧解圖像處理經典難題之圖像配準>巧解圖像處理經典難題之圖像配準</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bcc4c942.html alt=「鋼構知識」經典鋼結構設計問答 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bcc4c942.html title=「鋼構知識」經典鋼結構設計問答>「鋼構知識」經典鋼結構設計問答</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7f6e1fd9.html alt=「鋼構知識」經典鋼結構設計問答彙總 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/76195b1e9d934c2e952b060dad0951e6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7f6e1fd9.html title=「鋼構知識」經典鋼結構設計問答彙總>「鋼構知識」經典鋼結構設計問答彙總</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/15d8539d.html alt=經典設計延續至今的烏尼莫克403萬能卡車 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/132ba54553374c7eb2c0a9c155bba041 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/15d8539d.html title=經典設計延續至今的烏尼莫克403萬能卡車>經典設計延續至今的烏尼莫克403萬能卡車</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c08f7fcf.html alt=寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c08f7fcf.html title=寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究>寶信軟件：公司聚焦大數據、人工智能、虛擬製造等七大關鍵技術的研究</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0249bca7.html alt=民間經典名言「上」：仰不愧天，俯不愧地，那不愧心 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/4000b541-b105-4302-8cc9-546a79e90ece style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0249bca7.html title=民間經典名言「上」：仰不愧天，俯不愧地，那不愧心>民間經典名言「上」：仰不愧天，俯不愧地，那不愧心</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0be408a4.html alt="MySQL 事務處理" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0be408a4.html title="MySQL 事務處理">MySQL 事務處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/011d2da0.html alt=MySql併發與事務的處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/f13d8a1e-5e60-4b48-90bc-3c26e312a208 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/011d2da0.html title=MySql併發與事務的處理>MySql併發與事務的處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3c48fcc.html alt=Spring聲明式事務處理的實現原理，來自面試官的窮追拷問 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3c48fcc.html title=Spring聲明式事務處理的實現原理，來自面試官的窮追拷問>Spring聲明式事務處理的實現原理，來自面試官的窮追拷問</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/efc2a519.html alt=你知道MySQL的事務處理和隔離級別嗎？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/efc2a519.html title=你知道MySQL的事務處理和隔離級別嗎？>你知道MySQL的事務處理和隔離級別嗎？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c96865e4.html alt=C語言經典100例004-統計各個年齡階段的人數 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/98c4bb54-8d7e-4234-bf07-0d8190ba1a0c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c96865e4.html title=C語言經典100例004-統計各個年齡階段的人數>C語言經典100例004-統計各個年齡階段的人數</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>