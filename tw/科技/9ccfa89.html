<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習模型中的偏差要怎麼解決？ | 极客快訊</title><meta property="og:title" content="機器學習模型中的偏差要怎麼解決？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/e263df6ad2da44e3834d38b2f14d12d4"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/9ccfa89.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/9ccfa89.html><meta property="article:published_time" content="2020-10-29T20:58:14+08:00"><meta property="article:modified_time" content="2020-10-29T20:58:14+08:00"><meta name=Keywords content><meta name=description content="機器學習模型中的偏差要怎麼解決？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/9ccfa89.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習模型中的偏差要怎麼解決？</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>機器學習中的預測分析模型嚴重依賴迴歸、分類和聚類方法。在分析預測模型的有效性時，預測越接近實際數據越好。本條款希望成為主要問題和最流行/有效的解決方案的一種參考，而不需深入細節。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e263df6ad2da44e3834d38b2f14d12d4><p class=pgc-img-caption>線性迴歸圖</p></div><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/13cf8035a10345fca4a41116cdf3303c><p class=pgc-img-caption>聚類算法圖</p></div><p>首先，數據選擇和修剪是在數據準備階段發生的，你要先處理掉錯誤的數據。還存在與數據相關的問題（它們與在訓練期間的機器學習（ML）模型的目標相關），還有使用算法上的問題，以及在整個過程中出現的數據中的錯誤。實際上，模型被測試了偏差、方差、自相關，以及在最終確定模型時可能發生的許多此類錯誤。在最終確定模型之前，對數據執行一些已定義的測試——這些測試算法可以檢測此類錯誤。</p><p>在運行這些測試之後，您將返回到模型並進行那些更正，並將確定哪些機器學習模型是擬合的。業界最優秀的人已經找到了在進一步迭代中避免此類錯誤的方法。儘管可能會出現很多錯誤，但是讓我們通過定義良好且最有效的測試和解決方案來探索其中的一些錯誤:</p><h1>過度擬合和欠擬合</h1><p><strong>Bias-Variance權衡屬性可以解釋過度擬合和欠擬合問題：</strong></p><p>當數據中存在偏差和方差中的任何一個時，就會出現偏差-方差權衡。</p><p><strong>偏差：</strong>描述的是預測值（估計值）的期望與真實值之間的差距。偏差越大，越偏離真實數據。數據可能會有這些偏差，但是應該儘量減少這些偏差，以便從這些數據中獲得公平的推論。</p><p><strong>方差：</strong>描述的是預測值的變化範圍，離散程度，也就是離其期望值的距離。方差越大，數據的分佈越分散。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0f9b7f8de95844249bf64fb20c54463a><p class=pgc-img-caption></p></div><blockquote><p>低方差和低偏差是精確模型的最佳組合。</p></blockquote><p>因此，偏差和方差是機器學習預測分析模型中兩種最常見現象的因素。</p><p><strong>偏差和方差如何導致過度擬合和欠擬合？</strong></p><p>為了確定模型的完美擬合，我們分析下測試樣本/數據點是如何進行模型分析的。在解析數百萬行實例時，您可能會嘗試包含所有數據點，無論是否相關，或者在前面的閾值中超過閾值。這裡的關鍵不在於每個數據點都是完美的，也不要在嘗試擬合曲線時忽略數據點。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9ffc06f7246a4af2bfeed514a51b2b2d><p class=pgc-img-caption></p></div><p>高偏差和高差異是最差的組合，創造出離現實更遠的結果。當您嘗試單獨減少偏差時，方差仍然存在，從而產生過度擬合現象。僅僅考慮高方差，並且仍存在高偏差，這將導致欠擬合。這就是“權衡”一詞出現的原因，因為減少偏差，不會改善機器學習模型，反之亦然。“最佳點”是將數據點降落在存在低偏差和低差異的地方。基本上，要找到一種模式，不要採取任何極端情況，以免影響準確性。大多數時候，這些點的規劃和選擇是數據科學家和分析師面臨的最大挑戰。</p><p>然而，也有一些方法可以測試模型的適用性。解決這些問題的方法有:</p><p><strong>對Bias-Variance權衡問題的回答：</strong></p><ul><li><strong>構建更復雜的機器學習模型</strong></li></ul><p>解決不擬合問題的第一個也是最簡單的方法是訓練一個更復雜的模型來解決這個問題。對於過度擬合模型，獲取更多數據和正則化。</p><ul><li><strong>交叉驗證</strong></li></ul><p>在交叉驗證中，所有可用或選擇的數據都不會用於模型的培訓。通常有三種方法可以幫助執行交叉驗證方法——培訓數據、測試數據和驗證數據集。你可以單獨使用訓練和測試數據，或者使用全部的三種數據。</p><blockquote><p>[訓練數據=模型訓練</p><p>測試數據=用於模型超參數調整</p><p>驗證數據=用於模型驗證和準確度估算]</p></blockquote><p>有許多方法可以使用，通常訓練數據佔總數據集的60%，測試數據集佔20%，驗證數據集佔剩餘20%。</p><p>首先利用訓練數據對模型進行訓練，然後將該模型與經過測試數據訓練的模型進行比較。通過這種方式，我們可以確定哪些數據點可以帶來更好的預測。交叉驗證有很多變體:</p><p><strong>hold out：</strong>數據分為測試數據和訓練數據，然後進行比較。在Hold-Out方法中，我們只使用一組保持不變的訓練數據。</p><p>如有100個樣本，其中60個訓練，20個測試，以及20個驗證數據集。在訓練期間，您可以計算模型的準確性。測試是在訓練模型後測試準確性。</p><p><strong>K-fold交叉驗證：</strong>此處數據分為k-sets。然後第一個fold是驗證數據集，並且從folds總數中移除第一個fold（其中，假設k = 10）。對於每次迭代，我們採用一個fold進行驗證（第9次，在第一次迭代（k-1）之後），然後從現在剩餘的總folds（現在k = 9）中減去它。該方法有效但需要巨大的計算能力。如下圖：</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2d28ef97a28b4134ab175c3e8ebfbec3><p class=pgc-img-caption>具有10-folds的k-fold交叉驗證的實例</p></div><p><strong>Leave-One-Out：</strong>這種方法更加費力，因為每次測試n個數據點時都會消除一個數據。</p><ul><li><strong>Dropout：</strong></li></ul><p>在深度學習中使用神經網絡時，會使用Dropout方法。Dropout是一種古老的技術，經證明可以幫助提高機器學習模型的準確性。這使得層中的某些激活失效（等於0）。我們可以從數據集中選擇任意數量的數據來創建Dropout層。通常，這在20％或30％的範圍內。假設，如果我們使用30％的Dropout，那麼該特定層中隨機30％神經元的激活將被停用。停用的神經元將不會傳播到網絡的下一層。我們這樣做是為了避免過度擬合，因為更多噪聲會使模型更加穩健。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/03f366918e4f4b5d81a6eb9b35d9f0a8><p class=pgc-img-caption></p></div><p>Dropout方法：這裡，一些神經元已被停用（紅色，右）。假設激活是x，那麼在dropout中它等於零</p><p>直觀地說，這迫使網絡即使在缺少某些信息的情況下也必須是準確的。</p><ul><li><strong>梯度噪音：</strong></li></ul><p>該方法涉及在訓練期間添加梯度噪聲，該方法被證明提高了模型的準確性。</p><p>添加從高斯分佈中採樣的噪聲：</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e71eeacf8ad34dcfb3822b5f78d823c1><p class=pgc-img-caption></p></div><ul><li><strong>正則化：</strong></li></ul><p>正則化是另一種減少過度擬合現象的流行方法。用於解決高方差的問題，該技術涉及懲罰係數和權重，以獲得訓練數據和測試數據的更高準確度。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/06044f7d062a4866b4d0403529b6f078><p class=pgc-img-caption></p></div><p>這裡，w是權重值，紅色框表示正則化項，而lambda是正則化參數，它在訓練期間得到優化。剩餘部分是計算最小平方值的損失函數。</p><h1>梯度消失和梯度爆炸問題</h1><p>當使用反向傳播訓練深度神經網絡時，需要向網絡中添加新的隱藏層。這最終會構建一個高度複雜的模型，但會影響到訓練的速度。在這裡，當使用sigmoid激活函數或tanh激活函數時，梯度消失的問題就出現了，這兩個函數用於激活神經網絡的神經元，它們決定了梯度在通過這些層時的行為。</p><p>當權重矩陣的梯度被計算出來，然後從相同的矩陣中減去時，就會發生這種情況。如果模型有很多層，最終一些梯度等於零，因此使它的權重值不變，他們停止學習。這造成了一個問題，因為模型沒有從這些消失的梯度中學到什麼。通常，梯度值遞減的效果會隨著層的反向傳播而增加，從而使那些較早的層停止學習。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3debb971f35d47dbb60b0ca4c2e11af0><p class=pgc-img-caption>梯度下降和消失/爆炸梯度</p></div><p>在使用反向傳播時，如果使用的是在0和1之間取值的sigmoid激活函數。因此，如果生成一個高值(>1)，激活函數將激活該值為1，在反向傳播過程中，導數變為0，從而完全丟失高值，反之亦然(低值[>0]，在0處保持不變)。為了避免這種消失梯度，使用了ReLU、PReLU、SeLu、ELU等其他激活函數。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/321bd02a0a854cf1b012d26da27e7e8b><p class=pgc-img-caption>Tanh函數</p></div><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/70e31e88048b464c95795e8106ee3c8a><p class=pgc-img-caption>sigmoid函數</p></div><p><strong>激活函數 - ReLU，PReLU，RReLU，ELU</strong></p><p>ReLU :為了使大於零的值不會無效，ReLU將其標記為無窮大，從而生成一個線性函數。但是，ReLu將小於0的值標記為0，這在某些情況下不是很好，因為它完全忽略了這些值，但是提高了速度。當數值saturation低於0時，ReLU實際上會阻止任何訓練。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2d9fad49e35a4c9bbbba6149716de7d5><p class=pgc-img-caption></p></div><p>PReLU：優於ReLU，PReLU通過不停用低於零的值，但提高速度有效。它通過用參數'α'代替0.01來減輕saturation。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/67f1a1f7adda4aed88cfe6b90a8793ec><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/673fed5a06454af9beb36761388c0691><p class=pgc-img-caption></p></div><p>RReLU：據說RReLU擊敗了上述每一個激活函數。RReLU將隨機值分配給負斜率，從而不會影響速度或準確度。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6468636553a847d3b4c54aeffaaf8e65><p class=pgc-img-caption></p></div><p>ELU：ELU通過使值等於1來避免0以上值的saturation。ELU主要用於提高分類準確度，加快了訓練速度。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/834f43cb109648979193fff9b488331b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/433d19088f0e424e9975a951b563596f><p class=pgc-img-caption></p></div><p><strong>歸一化：</strong></p><p>歸一化解決了過度擬合，欠擬合和消失梯度問題的問題。</p><p>批歸一化：批歸一化技術用於改善反向傳播的性能。它涉及重新調整輸入值以防止它們變得太大或太小。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/dfcc4bfd33034aa7959e1ad619c521f0><p class=pgc-img-caption></p></div><p>實例歸一化:實例歸一化是隻使用一個樣本，而不是一批樣本的歸一化，就像批處理歸一化一樣。</p><h1>多重共線性</h1><p>當模型預測中的預測變量之間存在多個相關性時，會發生多重共線性。這種現象是大多數人熟悉的並且在迴歸模型中非常常見。多重共線性問題只有在您需要知道某些預測發生的原因時才會發生，即需要預測的原因。這可以為模型的任何預測帶來解釋。有時，一個高度相關的列似乎是某些結果的因果關係，而實際上它們只是相關的。</p><p>在數據集中發現多重共線性，可以防止對某些結果得出嚴重錯誤的結論，比如在患有哮喘的肺炎患者中，他們被認為對哮喘有更好的抵抗力，因為他們得到的治療更早。然而，事實是哮喘患者在同時感染肺炎時得到了及時的護理，因為如果不立即治療，他們更容易出現致命的後果。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ae7b105fe8004fc98da8f0e646c9af6d><p class=pgc-img-caption></p></div><p><strong>回答多重共線性</strong></p><p>自相關和部分自相關測試：這些測試可以檢測模型中的相關現象。它們通常在時間序列分析和預測期間使用。通過這些測試，您可以檢測出現相關性的位置，並刪除高度相關的列。</p><p>自相關：它主要在時間序列分析和預測中檢測數據中的相關性或重複信號的出現。它可能發生在兩個因變量x1和x2之間。</p><p><strong>主成分分析（PCA）：</strong></p><p>主成分分析用於糾正相關誤差。它只保留一組新的預測變量，這些變量是高度相關的變量行為的組合。因此，這些新變量不會丟棄那些在模型中有自己角色的相關變量，而是保留那些其他循環和相關變量的行為。它通過特徵提取工作。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8f9b873e17004992b240f28490cb2e2e><p class=pgc-img-caption></p></div><p>通過特徵提取分析數據集主成分的繪圖</p><p><strong>線性判別分析（LDA）</strong>：</p><p>LDA用於預測分析問題。</p><div class=pgc-img><img alt=機器學習模型中的偏差要怎麼解決？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e3646bca0416459b8bca3288df7ba89d><p class=pgc-img-caption></p></div><p>它假定一組新的輸入將屬於到目前為止收集的數據集中的類。在使用logistic迴歸時，會出現模型不穩定等侷限性。相反，我們可以將LDA用於線性迴歸。該算法還利用著名的貝葉斯定理來計算輸入輸出的概率。</p><p>P（Y = x | X = x）=（PIk * fk（x））/ sum（PIl * fl（x））</p><p><strong>Pearson相關係數：</strong></p><p>Pearson係數用於找到兩個變量X和Y之間的相關性。它給出介於-1和1之間的值，描述負相關或正相關，如果該值為零，則不存在相關性。</p><p><strong>自相關和部分自相關測試：</strong></p><p>自相關測試結果與變量的（關係）相關程度。自相關函數（ACF）用於計算時間序列中的相關性。時間序列預測的觀測值與已收集的時間序列觀測值相關。因此，名稱自相關。ACF的目的是使用這些值繪製所有相關的圖表以及滯後。這裡的滯後是通過從先前時間序列觀察中出現的項中取得使系列靜止所需的值來計算的項。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>怎麼</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7d5292dc.html alt=新手學習php怎麼入門？含學習路線、5大php性能優化技巧！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/3b15000460bd5a8fd143 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7d5292dc.html title=新手學習php怎麼入門？含學習路線、5大php性能優化技巧！>新手學習php怎麼入門？含學習路線、5大php性能優化技巧！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html alt=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ebc79c3aa76541b393374cc521297870 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html title=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用>機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html alt=基於機器學習在雙光子光刻過程中進行自動探測產品的質量 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7550407fa66941b2991e53b5a9ec4071 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html title=基於機器學習在雙光子光刻過程中進行自動探測產品的質量>基於機器學習在雙光子光刻過程中進行自動探測產品的質量</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html alt=機器學習中模型評估和選擇的一些問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6c3b00005e98772353a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html title=機器學習中模型評估和選擇的一些問題>機器學習中模型評估和選擇的一些問題</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>