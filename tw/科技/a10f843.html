<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器學習之神經網絡學習及其模型 | 极客快訊</title><meta property="og:title" content="機器學習之神經網絡學習及其模型 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/3c459f460e0f45cc8a9107f1557bc027"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a10f843.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a10f843.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a10f843.html><meta property="article:published_time" content="2020-10-29T21:05:34+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:34+08:00"><meta name=Keywords content><meta name=description content="機器學習之神經網絡學習及其模型"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/a10f843.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器學習之神經網絡學習及其模型</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h1 class=pgc-h-arrow-right><strong>1、神經元模型</strong></h1><p>歷史上，科學家一直希望模擬人的大腦，造出可以思考的機器。人為什麼能夠思考？科學家發現，原因在於人體的神經網絡。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3c459f460e0f45cc8a9107f1557bc027><p class=pgc-img-caption></p></div><p>神經網絡最基本的成分是神經元模型</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fb1ee28c3bd2420d9b74a6e3cd4eae37><p class=pgc-img-caption></p></div><p>其中，W表示的是向量，代表的是權重，函數f稱為激活函數，</p><ul><li>其中f()我們一般選擇sigmoid函數（這裡選擇對數機率函數）</li><li>對數機率函數相較於階躍函數優點：連續光滑，任意階可導</li></ul><h1 class=pgc-h-arrow-right><strong>2、感知機與多層網絡</strong></h1><p><strong>感知器的例子</strong> 城裡正在舉辦一年一度的遊戲動漫展覽，小明拿不定主意，週末要不要去參觀。 他決定考慮三個因素。</p><pre><code>天氣：週末是否晴天？同伴：能否找到人一起去？價格：門票是否可承受？</code></pre><p>這就構成一個感知器。上面三個因素就是外部輸入，最後的決定就是感知器的輸出。如果三個因素都是 Yes（使用1表示），輸出就是1（去參觀）；如果都是 No（使用0表示），輸出就是0（不去參觀）。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e797041281794e29b02e3704607c41b7><p class=pgc-img-caption></p></div><p>單層感知機：有兩層神經元組成，只有一層M-P神經元的網絡模</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1a4877b4aee847b4b14f87e5004a6c1a><p class=pgc-img-caption></p></div><p>單層感知機學習參數的調整</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/52c2c677883b4d5380d2b938a5e6c077><p class=pgc-img-caption></p></div><p>單層感知機只能解決線性可分的問題，對於非線性可分問題，需要考慮使用</p><p><strong>多層功能神經元</strong></p><p>多層前饋神經網絡：</p><ol start=1><li>多層：有隱含層</li><li>前饋：不存在信號的逆向傳播，不存在環和迴路</li><li>不存在同層連接，不存在跨層連接</li></ol><h1 class=pgc-h-arrow-right><strong>3、誤差逆傳播算法</strong></h1><h1 class=pgc-h-arrow-right><strong>BP算法（誤差逆傳播算法）</strong></h1><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/23f2bcd010b84eafaf9300bab770e8c7><p class=pgc-img-caption></p></div><p>1.初始化 2.反覆調整（信號向前傳播->誤差逆向傳播->權值與閾值更新）</p><p>BP神經網絡的過程主要分為兩個階段，第一階段是信號的前向傳播，從輸入層經過隱含層，最後到達輸出層；第二階段是誤差的反向傳播，從輸出層到隱含層，最後到輸入層，依次調節隱含層到輸出層的權重和偏置，輸入層到隱含層的權重和偏置。</p><p><strong>訓練流程圖</strong></p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/fd18e22adf604aa594616853b5857434><p class=pgc-img-caption></p></div><p><strong>BP算法可能出現的問題</strong> 1.初始化問題：</p><pre><code>初始化為不同的小隨機數不同：保證網絡可以學習小隨機數：防止過大提前進入飽和狀態如果跌入局部最優，就要重新初始化</code></pre><p>2.步長設置問題：</p><pre><code>學習率（0到1之間）控制著算法的每一輪迭代中更新的步長若太大，容易發生振盪，若太小，收斂速度緩慢。</code></pre><p>3.結構學習問題：</p><ul><li>輸入層個數： 若給點屬性為連續值，則等於訓練數據的維度 若為離散值，等於維度+編碼方式</li><li>輸出層個數： 若為分類問題，與待分類類別數目大致成二為底的對數函數關係</li><li>隱層神經元個數： 試錯法或者經驗確定 一個包含足夠多神經元的隱層，多層前饋神經網絡就可以任意精度比較任意函數，所以，總可以找到一個合適的隱層神經元個數。</li></ul><p>4.權值閾值更新問題：</p><ul><li>標準BP算法： 每次更新只針對單個樣例，參數更新非常頻繁，不同樣例的更新效果可能會有“抵消現象”，為了達到累計誤差最小點，可能需要更多次的迭代。</li><li>累計BP算法： 直接針對累計誤差最小化，讀取整個數據集D之後才更新一次，更新頻率低。但降到一定程度時，下降非常緩慢。 5.過擬合問題：</li><li>過擬合：訓練誤差持續降低，但是測試誤差卻上升 解決策略 ①早停 ②正則化</li></ul><h1 class=pgc-h-arrow-right><strong>4、全局最小和局部最小</strong></h1><p>由於初始化的時候隨機初始化為不同的隨機小數，則很有可能將網絡跌入局部最優。不同的初始點，可能得到的最優解可能不同。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/bbb3c07cf7fb434e83ec74c07a0615b2><p class=pgc-img-caption></p></div><p>跳出局部最優的策略：</p><ol start=1><li>以多組不同參數值初始化多個神經網絡，從不同 的點開始搜索最優點，可能會得到的結果不同， 從中選擇有可能獲得更接近全局最小的結果。</li><li>模擬退火技術 模擬退火在每一步都以一定概率接受比當前解更差 的結果，從而有助於跳出局部最優。</li><li>使用隨機梯度下降，即使跌入局部極小點，因為 加入了隨機因素，可能跳出局部最優。</li></ol><h1 class=pgc-h-arrow-right><strong>5、常見的其他神經網絡</strong></h1><p><strong>1.RBF網絡</strong> 單隱層前饋神經網絡 使用徑向基函數作為隱層神經元激活函數，輸出層是對隱層神經元輸出的線性組合</p><p><strong>2.ART網絡</strong> 競爭學習型，由比較層，識別層，識別閾值和重置模塊組成 有較好的“可塑性，穩定性” 可進行增量學習，在線學習</p><p><strong>3.SOM網絡</strong> 競爭學習型的無監督神經網絡，將高維輸入數據映射到低維空間</p><p><strong>4.級聯相關網絡</strong> 不僅學習連接權，閾值，還要學習網絡結構。希望在訓練過程中找到最符合數據特點的網網絡結構。</p><p><strong>5.Elman網絡</strong> 允許網絡中出現環狀結構，從而可以讓一些神經元的輸出反饋回來作為輸入信號。</p><h1 class=pgc-h-arrow-right><strong>6、神經網絡的例子</strong></h1><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/196540c273c247fda368063c050285d2><p class=pgc-img-caption></p></div><p>所謂"車牌自動識別"，就是高速公路的探頭拍下車牌照片，計算機識別出照片裡的數字。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e06d4cffc3f249ef94761c87205789e6><p class=pgc-img-caption></p></div><p>這個例子裡面，車牌照片就是輸入，車牌號碼就是輸出，照片的清晰度可以設置權重（w）。然後，找到一種或多種圖像比對算法，作為感知器。算法的得到結果是一個概率，比如75%的概率可以確定是數字1。這就需要設置一個閾值（b）（比如85%的可信度），低於這個門檻結果就無效。</p><p>一組已經識別好的車牌照片，作為訓練集數據，輸入模型。不斷調整各種參數，直至找到正確率最高的參數組合。以後拿到新照片，就可以直接給出結果了。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/74bf99d60b6d4926b58d8e1f9a8f8058><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>7、輸出的連續性</strong></h1><p>上面的模型有一個問題沒有解決，按照假設，輸出只有兩種結果：0和1。但是，模型要求w或b的微小變化，會引發輸出的變化。如果只輸出0和1，未免也太不敏感了，無法保證訓練的正確性，因此必須將"輸出"改造成一個連續性函數。</p><p>這就需要進行一點簡單的數學改造。</p><p>首先，將感知器的計算結果wx + b記為z。</p><pre><code>z = wx + b</code></pre><p>然後，計算下面的式子，將結果記為σ(z)。</p><pre><code>σ(z) = 1 / (1 + e^(-z))</code></pre><p>這是因為如果z趨向正無窮z → +∞（表示感知器強烈匹配），那麼σ(z) → 1；如果z趨向負無窮z → -∞（表示感知器強烈不匹配），那麼σ(z) → 0。也就是說，只要使用σ(z)當作輸出結果，那麼輸出就會變成一個連續性函數。</p><p>原來的輸出曲線是下面這樣。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3cba1c8a53474a7f80a7a9a70a295189><p class=pgc-img-caption></p></div><p>現在變成了這樣。</p><div class=pgc-img><img alt=機器學習之神經網絡學習及其模型 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/257779d9aa7a47eab6f8a6641fe2c4c8><p class=pgc-img-caption></p></div><p><strong>推薦博客</strong> <strong>神經網絡，BP算法，計算圖模型</strong></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>學習</a></li><li><a>機器</a></li><li><a>神經</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/35db2356.html alt="大數據深度學習的新利器: 快速神經網絡訓練:P-network" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d172925963f2465aa131058c05cd72f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/35db2356.html title="大數據深度學習的新利器: 快速神經網絡訓練:P-network">大數據深度學習的新利器: 快速神經網絡訓練:P-network</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html alt=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ebc79c3aa76541b393374cc521297870 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html title=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用>機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html alt=基於機器學習在雙光子光刻過程中進行自動探測產品的質量 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7550407fa66941b2991e53b5a9ec4071 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html title=基於機器學習在雙光子光刻過程中進行自動探測產品的質量>基於機器學習在雙光子光刻過程中進行自動探測產品的質量</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html alt=機器學習中模型評估和選擇的一些問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6c3b00005e98772353a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html title=機器學習中模型評估和選擇的一些問題>機器學習中模型評估和選擇的一些問題</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>