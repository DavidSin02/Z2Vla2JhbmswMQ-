<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM） | 极客快訊</title><meta property="og:title" content="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM） - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/44a1c6d1d405420d81a50513351efb8d"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/a20a49b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/a20a49b.html><meta property="article:published_time" content="2020-10-29T21:01:05+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:05+08:00"><meta name=Keywords content><meta name=description content="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/a20a49b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><h2 class=pgc-h-arrow-right>1. K均值算法（K-Means）</h2><p>是一種無監督的聚類學習算法，它嘗試找到樣本數據的自然類別，分類K是由用戶自己定義的，它在不需要任何其它先驗知識的情況下，依據算法的迭代規則，把樣本劃分為K類，通過不斷跌代和移動質心來完成分類。是一種硬分類的方法：即以距離為依據，離哪個點距離越近，它就應該標記為哪個編號，計算兩個點之間的距離，有可能是向量（x，y）或（x，y，z）。不斷的迭代，中心點不斷的變換，使得逐漸接近真實的結果，最後要求取前後兩次中心點的差值，或到達一定的迭代次數就結束。</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/44a1c6d1d405420d81a50513351efb8d><p class=pgc-img-caption></p></div><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5b4e839fb5db4edda4efa21506b32109><p class=pgc-img-caption></p></div><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c3ade0d245804f10990b4ca975709748><p class=pgc-img-caption></p></div><p><strong>API參數：</strong></p><ul><li>參數1：輸入的數據集合，可以是一維或多維，它是浮點數。</li><li>參數2：K 為分類的數目。</li><li>參數3：分類的標籤，分類索引編號。</li><li>參數4：停止條件，可以用迭代的次數或者我們指定的精度閾值。</li><li>參數5：attempts 嘗試幾次，有時候為了獲得最佳的分類效果，算法要用不同的初始分類進行嘗試。</li><li>參數6：flags 表示用哪一種方法進行初始化，最常用的是隨機選擇。</li></ul><p><strong>例子代碼：</strong></p><pre><code>#include&lt;opencv2/opencv.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;void test(){    Mat srcImg;    srcImg = imread("toux.jpg");    if (srcImg.empty())    {        cout &lt;&lt; "could not load image...\n" &lt;&lt; endl;    }    namedWindow("Original image", CV_WINDOW_AUTOSIZE);    imshow("Original image", srcImg);    //預定義分割的一些顏色    Scalar colorTab[] = {        Scalar(0, 0, 255),        Scalar(0, 255, 0),        Scalar(0, 0, 0),        Scalar(255, 0, 0),        Scalar(255, 0, 255),    };    //首先獲取圖像的寬和高，每一個像素對應一個數據點，要把數據進行轉換，    //kmeans 輸入參數是以所有的數據點為每一行，列為數據的維度（圖像為3 RGB顏色通道）    int width = srcImg.cols;    int height = srcImg.rows;    int dims = srcImg.channels();    int sampleCount = width*height;  //總像素    int clusterCount = 4;  //分為 4 類    //數據點，即把所有樣本裝到一個數據點（一行），每一行只有一個數據    Mat points(sampleCount, dims, CV_32F, Scalar(10));     Mat labels;    Mat centers(clusterCount, 1, points.type());  //中心點    //將 RGB 數據轉換到樣本數據    int index = 0;    for (int i = 0; i &lt; height; i++)  //循環把每個樣本找出來    {        for (int j = 0; j &lt; width; j++)        {            index = i*width + j;            Vec3b bgr = srcImg.at&lt;Vec3b&gt;(i, j);  //獲取圖像上點像素的值            //把只作為樣本傳進去            points.at&lt;float&gt;(index, 0) = static_cast&lt;int&gt;(bgr[0]);  //把數據轉換            points.at&lt;float&gt;(index, 1) = static_cast&lt;int&gt;(bgr[1]);            points.at&lt;float&gt;(index, 2) = static_cast&lt;int&gt;(bgr[2]);        }    }    //運行 kmeans     TermCriteria cirteria = TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 10, 0.1);    kmeans(points, clusterCount, labels, cirteria, 3, KMEANS_PP_CENTERS, centers);    //顯示分類的結果    Mat result = Mat::zeros(srcImg.size(), srcImg.type());    for (int i = 0; i &lt; height; i++)    {        for (int j = 0; j &lt; width; j++)        {            index = i*width + j;  //把二維數組轉換到一維數組，找它裡面的index            //結果顯示通過label 獲取，根據聚類的編號            int label = labels.at&lt;int&gt;(index, 0);             result.at&lt;Vec3b&gt;(i, j)[0] = colorTab[label][0];            result.at&lt;Vec3b&gt;(i, j)[1] = colorTab[label][1];            result.at&lt;Vec3b&gt;(i, j)[2] = colorTab[label][2];        }    }    for (int i = 0; i &lt; centers.rows; i++)    {        int x = centers.at&lt;float&gt;(i, 0);        int y = centers.at&lt;float&gt;(i, 0);        cout &lt;&lt; "center =  " &lt;&lt; i &lt;&lt;"  "&lt;&lt; "c.x: " &lt;&lt; x &lt;&lt;"\t"&lt;&lt; "c.y: " &lt;&lt; y &lt;&lt; endl;    }    imshow("KMeans", result);}</code></pre><p><strong>效果圖：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/0940a49e9d2a4d7aa950c44609d7176b><p class=pgc-img-caption></p></div><p><br></p><h2 class=pgc-h-arrow-right>2.高斯混合模型（GMM）</h2><h3 class=pgc-h-arrow-right>2.1 一些概念理解</h3><h4 class=pgc-h-arrow-right>2.1.1 協方差</h4><p>統計學裡最基本的就是樣本的均值、方差和標準差。在一個含有n個樣本的集合X={X1 ,…,Xn}。</p><p>均值：</p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/13a4add1f08e4ca7ae5a2e1a6620da10><p class=pgc-img-caption></p></div><p>標準差：</p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/52b99a6fabe14dfe962d2656091190fb><p class=pgc-img-caption></p></div><p>方差：</p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/194f0ca39aa74114b650b1d3bb72ee88><p class=pgc-img-caption></p></div><p>均值描述的是樣本集合的中間點，它告訴我們的信息是很有限的，而標準差描述的是樣本集合的各個樣本點到均值的距離之平均。以這兩個集合為例，[0，8，12，20]和[8，9，11，12]，兩個集合的均值都是10，但顯然兩個集合差別是很大的，計算兩者的標準差，前者是8.3，後者是1.8，顯然後者較為集中，所以標準差小一點，標準差描述的就是這種“散佈度”。之所以除以n-1而不是除以n，是因為這樣能使我們以較小的樣本集更好的逼近總體的標準差，即統計上所謂的“無偏估計”。方差則僅僅是標準差的平方。</p><p><strong>為什麼需要協方差？</strong>上面幾個統計量看似已經描述的差不多了，但注意到，標準差和方差一般是用來描述一維數據的，現實生活我們常常遇到含有多維數據的數據集，例如要統計多個學科的考試成績。面對這樣的數據集，可以按照每一維獨立的計算其方差，但是通常我們還想了解更多，比如，一個男孩子的猥瑣程度跟他受女孩子歡迎程度是否存在一些聯繫啊，嘿嘿~協方差就是這樣一種用來度量兩個隨機變量關係的統計量，我們可以仿照方差的定義：</p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f4918338498d49f1aabf2008aa072eaf><p class=pgc-img-caption></p></div><p>來度量各個維度偏離其均值的程度，標準差可以這麼來定義：</p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ad833160331e48999ea83186dfc3d986><p class=pgc-img-caption></p></div><p>如果協方差的結果的結果為正值，則說明兩者是正相關的(從協方差可以引出“相關係數”的定義)，也就是說一個人越猥瑣就越受女孩子歡迎，結果為負值就說明負相關的，越猥瑣女孩子越討厭，可能嗎？如果為0，也是就是統計上說的“相互獨立”。</p><h4 class=pgc-h-arrow-right>2.1.2 高斯函數（模型）</h4><p>高斯一維函數：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7d3c16841a994c6b9714fb51ba097560><p class=pgc-img-caption></p></div><p>高斯概率分佈函數：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7adfbd2bc432421b9dab21652de9b81f><p class=pgc-img-caption></p></div><h4 class=pgc-h-arrow-right>2.1.3 EM 算法</h4><p>MLE 是用來求模型參數的，核心是“模型已知，求取參數”，模型的意思就是數據符合什麼函數，比如我們硬幣的正反就是二項分佈模型，再比如我們平時隨機生成的一類數據符合高斯模型,公式如下：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e0c99e492bba4a73a534263f053a4598><p class=pgc-img-caption></p></div><p><br></p><ul><li>L(Θ)：聯合概率分佈函數，就是每個樣本出現的概率乘積。</li><li>x1,x2,x3….xn : 樣本</li><li>Θ：模型的參數（比如高斯模型的兩個參數：μ、σ）</li><li>p(xi ; Θ):第i個樣本的概率模型</li><li>xi: 第i個樣本</li></ul><p>平時使用的時候取對數，完全為了求解方便：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/03af45428e864e888a4c97de42718f7f><p class=pgc-img-caption></p></div><p>ê 為平均對數似然。而我們平時所稱的最大似然為最大的對數平均似然，即:</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/62d56715887c469f8de83c96dbc9e083><p class=pgc-img-caption></p></div><p><strong>舉個例子：</strong>拋硬幣的簡單例子，現在有一個正反面不是很勻稱的硬幣，如果正面朝上記為H，方面朝上記為T，拋10次的結果如下：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a8d5f28dc1014384a7518329c801d7dd><p class=pgc-img-caption></p></div><p><br></p><p>求這個硬幣正面朝上的概率有多大？很顯然這個概率是0.2。現在我們用MLE的思想去求解它。我們知道每次拋硬幣都是一次二項分佈，設正面朝上的概率是μ；那麼似然函數為：<br></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/5dd2a9e26b294cd493969a3891833287><p class=pgc-img-caption></p></div><p>x=1表示正面朝上，x=0表示方面朝上。那麼有：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/f63d4282d7c44c75b80ae1114f0850f0><p class=pgc-img-caption></p></div><p><strong>求導：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ea5b115a336845c69ca8e90258cdfc12><p class=pgc-img-caption></p></div><p><strong>令導數為0，很容易得到：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1f2f461453e44a259f355422b1014c82><p class=pgc-img-caption></p></div><p><br></p><p>也就是0.2 。</p><p><br></p><p><strong>再舉個例子：</strong></p><p>假如我們有一組連續變量的採樣值（x1,x2,…,xn），我們知道這組數據服從正態分佈，標準差已知。請問這個正態分佈的期望值為多少時，產生這個已有數據的概率最大？</p><p>P(Data | M) = ？</p><p>根據公式：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2e8bc9fae52a473d804ae9bac188f61e><p class=pgc-img-caption></p></div><p><strong>可得:</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c90948b5694045e7892cc372b2f961ac><p class=pgc-img-caption></p></div><p><strong>對μ求導可得：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/41f8c2890baa4cc8b97d1d3d253df9ef><p class=pgc-img-caption></p></div><p>則最大似然估計的結果為μ=(x1+x2+…+xn) / n</p><p><br></p><p><strong>總結：</strong>其實我們用的很多函數都可以說是一個最大似然函數，比如符合y = x2、y = kx…都可以當做一個模型去求解一個極大似然函數，只不過我們得到的數據不符合這些模型而已。只要是求概率的問題，都會寫出一個函數，這個函數其實就是最大似然函數，可以說是目標函數，也可以說是似然函數，把每個數據出現的概率相乘就是似然函數，再求對數，再求均值，再求最值，這就是極大似然了，就是一個名字而已！</p><p><strong>EM算法核心：</strong>猜（E-step）,反思（M-step）,重複；</p><p><strong>算法理解：</strong></p><p><strong>問題一：</strong></p><p>現在一個班裡有50個男生，50個女生，且男生站左，女生站右。我們假定男生的身高服從正態分佈:</p><p>N(μ1,σ1²)</p><p>女生的身高則服從另一個正態分佈：</p><p>N(μ2,σ2²)</p><p>這時候我們可以用極大似然法（MLE），分別通過這50個男生和50個女生的樣本來估計這兩個正態分佈的參數。</p><p><strong>問題二：</strong></p><p>但現在我們讓情況複雜一點，就是這50個男生和50個女生混在一起了。我們擁有100個人的身高數據，卻不知道這100個人每一個是男生還是女生。這時候情況就有點尷尬，因為通常來說，我們只有知道了精確的男女身高的正態分佈參數我們才能知道每一個人更有可能是男生還是女生。但從另一方面去考量，我們只有知道了每個人是男生還是女生才能儘可能準確地估計男女各自身高的正態分佈的參數。</p><p><strong>問題二需要求解兩個問題：</strong></p><ul><li>假設a=（第k個樣本是男生還是女生）</li><li>假設b=（高斯模型的參數）<br>如果知道a，那用問題一的方法就可以求解b，如果知道b那也就可以分類a了，但是前提是兩個都不知道,比如y=x+1，現在讓你求解x和y的值，怎麼辦？</li></ul><p><strong>解決：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1d6a01c53ce04035bc72a6a7cd20c111><p class=pgc-img-caption></p></div><p><strong>總結：</strong>其實EM算法就是先通過假設的參數把數據進行分類，然後通過分類的數據計算參數，接著對比計算的參數和假設的參數是否滿足精度，不滿足就返回去，滿足就結束。EM是一種思想，而不是像K-means等是一種算法。</p><p><strong>高斯混合函數的原理：</strong>（1）單高斯分佈模型GSM：多維變量X服從高斯分佈時，它的概率密度函數為：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1e3cea77756d4a7092dab6ed2944439c><p class=pgc-img-caption></p></div><p>x是維度為d的列向量，u是模型期望，Σ是模型方差。在實際應用中u通常用樣本均值來代替，Σ通常用樣本方差來代替。很容易判斷一個樣x本是否屬於類別C。因為每個類別都有自己的u和Σ，把x代入（1）式，當概率大於一定閾值時我們就認為x屬於C類。從幾何上講，單高斯分佈模型在二維空間應該近似於橢圓，在三維空間上近似於橢球。遺憾的是在很多分類問題中，屬於同一類別的樣本點並不滿足“橢圓”分佈的特性。這就引入了高斯混合模型。</p><p><strong>高斯混合模型GMM：</strong>GMM認為數據是從幾個GSM中生成出來的，即：</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/84bb8fb9994a4cc9bf7f0fe3a0b29704><p class=pgc-img-caption></p></div><p>K需要事先確定好，就像K-means中的K一樣。πk是權值因子。其中的任意一個高斯分佈N(x;uk,Σk)叫作這個模型的一個component。這裡有個問題，為什麼我們要假設數據是由若干個高斯分佈組合而成的，而不假設是其他分佈呢？實際上不管是什麼分佈，只K取得足夠大，這個XX Mixture Model就會變得足夠複雜，就可以用來逼近任意連續的概率密度分佈。只是因為高斯函數具有良好的計算性能，所GMM被廣泛地應用。</p><p><strong>樣本分類已知情況下的GMM:</strong>當每個樣本所屬分類已知時，GMM的參數非常好確定，直接利用Maximum Likelihood。設樣本容量為N，屬於K個分類的樣本數量分別是N1,N2,…,Nk，屬於第k個分類的樣本集合是L(k)。</p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4b837bf68a7e4f45a0c627ecb2985a17><p class=pgc-img-caption></p></div><p><strong>樣本分類未知情況下的GMM:</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7a06d51f75df40f9b88a2abe2048bf45><p class=pgc-img-caption></p></div><p><strong>EM求解：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d3db1bc094004c35b9ba85a052054638><p class=pgc-img-caption></p></div><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/046c3663c8ff48eaab322b4779c826a5><p class=pgc-img-caption></p></div><p><strong>例子代碼：</strong></p><pre><code>#include&lt;opencv2/opencv.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;//高斯混合方法using namespace cv::ml;void test(){    Mat srcImg;    srcImg = imread("toux.jpg");    if (srcImg.empty())    {        cout &lt;&lt; "could not load image...\n" &lt;&lt; endl;    }    namedWindow("Original image", CV_WINDOW_NORMAL);    imshow("Original image", srcImg);    //預定義分割的一些顏色    Scalar colors[] = {        Scalar(0, 0, 255),  //紅        Scalar(0, 255, 0),  //綠        Scalar(255, 0, 0),  //藍        Scalar(0, 255, 255), // 黃        Scalar(255, 0, 255),  //品紅    };    //首先獲取圖像的寬和高，每一個像素對應一個數據點，要把數據進行轉換，    //kmeans 輸入參數是以所有的數據點為每一行，列為數據的維度（圖像為3 RGB顏色通道）    int width = srcImg.cols;    int height = srcImg.rows;    int dims = srcImg.channels();    int numCount = width*height;  //總像素點數    int numCluster = 3;  //分為 3 類    //數據點，即把所有樣本裝到一個數據點（一行），每一行只有一個數據    Mat points(numCount, dims, CV_64FC1);    Mat labels;    //將圖像 RGB 數據轉換為樣本數據    int index = 0;    for (int row = 0; row &lt; height; row++)  //這裡的步驟與 KMeans 是一樣的    {        for (int col = 0; col &lt; width; col++)        {            index = row*width + col;            Vec3b rgb = srcImg.at&lt;Vec3b&gt;(row, col);  //獲取圖像上點像素的rgb值            //把只作為樣本傳進去            points.at&lt;double&gt;(index, 0) = static_cast&lt;int&gt;(rgb[0]);            points.at&lt;double&gt;(index, 1) = static_cast&lt;int&gt;(rgb[1]);            points.at&lt;double&gt;(index, 2) = static_cast&lt;int&gt;(rgb[2]);        }    }    // EM 訓練    Ptr&lt;EM&gt;emModel = EM::create();  //生成 EM 期望最大化，起圖像分割的方式是基於機器學習的方式    emModel-&gt;setClustersNumber(numCluster);  //設置分類數    emModel-&gt;setCovarianceMatrixType(EM::COV_MAT_SPHERICAL);  //協方差矩陣的類型    //迭代條件，EM 訓練比 KMeans 耗時，可能會不收斂，所以迭代次數設大點    emModel-&gt;setTermCriteria(TermCriteria(TermCriteria::EPS +        TermCriteria::COUNT, 10, 0.1));    //EM 訓練，獲得分類結果，參數 labels 與 KMeans 的 labels 參數意思一樣，速度比 KMeans 要慢很多    emModel-&gt;trainEM(points, noArray(), labels, noArray());    //對每個像素標記顏色與顯示    Mat resultNoPredict = Mat::zeros(srcImg.size(), CV_8UC3);    Mat resultPredict = Mat::zeros(srcImg.size(), CV_8UC3);    Mat sample(dims, 1, CV_64FC1);    double time = getTickCount();    int r = 0, g = 0, b = 0;  //預言會用到    for (int row = 0; row &lt; height; row++)    {        for (int col = 0; col &lt; width; col++)        {            //獲取訓練的分類結果，放到 result 中            index = row*width + col;  //把二維數組轉換到一維數組，找它裡面的index            //結果顯示通過label 獲取，根據聚類的編號            int label = labels.at&lt;int&gt;(index, 0);            Scalar c = colors[label];  //label 上已經有顏色了            resultNoPredict.at&lt;Vec3b&gt;(row, col)[0] = c[0];            resultNoPredict.at&lt;Vec3b&gt;(row, col)[1] = c[1];            resultNoPredict.at&lt;Vec3b&gt;(row, col)[2] = c[2];            //通過預言獲得分類結果，因為 EM 訓練用的是 srcImg 的顏色數據，所以用 srcImg 的顏色數據做預言，            //得到的結果與 result 是一模一樣的            b = srcImg.at&lt;Vec3b&gt;(row, col)[0];            g = srcImg.at&lt;Vec3b&gt;(row, col)[1];            r = srcImg.at&lt;Vec3b&gt;(row, col)[2];            sample.at&lt;double&gt;(0) = b;            sample.at&lt;double&gt;(1) = g;            sample.at&lt;double&gt;(2) = r;            //預言            int response = cvRound(emModel-&gt;predict2(sample, noArray())[1]);            Scalar c2 = colors[response];            resultPredict.at&lt;Vec3b&gt;(row, col)[0] = c2[0];            resultPredict.at&lt;Vec3b&gt;(row, col)[1] = c2[1];            resultPredict.at&lt;Vec3b&gt;(row, col)[2] = c2[2];        }    }    //打印所需要的時間    cout &lt;&lt; "execution time(ms):" &lt;&lt; (getTickCount() - time) / getTickFrequency() * 1000 &lt;&lt; endl;    namedWindow("EM-Segmentation nopredict", CV_WINDOW_NORMAL);    imshow("EM-Segmentation nopredict", resultNoPredict);    namedWindow("EM-Segmentation predict", CV_WINDOW_NORMAL);    imshow("EM-Segmentation predict", resultPredict);}int main(){    test();    waitKey(0);    return 0;}</code></pre><p><strong>效果圖：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e95c08446b9e42e683a726944df27a14><p class=pgc-img-caption></p></div><p><br></p><p><strong>遇到的問題：</strong></p><p><br></p><div class=pgc-img><img alt="圖像分割實戰 - K均值算法（K-Means）和高斯混合模型（GMM）" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3adc59f2dd644f94be514aa01509d6d8><p class=pgc-img-caption></p></div><p><strong>我的解決辦法：</strong></p><p>更換 OpenCV 版本:報錯時用的是3.1版本，更換成3.3版本，這裡要注意 OpenCV 版本與 VS 之間的對應版本即可。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>圖像</a></li><li><a>實戰</a></li><li><a>Means</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html alt=OpenCV項目實戰---人臉檢測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f267e46946554437b5ffe48234f3b78d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html title=OpenCV項目實戰---人臉檢測>OpenCV項目實戰---人臉檢測</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2c3db761.html alt=計算機中數字、文字、圖像、聲音和視頻的表示與編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/8d1d3ec88f2c4a158c7efe55b21d6ed7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2c3db761.html title=計算機中數字、文字、圖像、聲音和視頻的表示與編碼>計算機中數字、文字、圖像、聲音和視頻的表示與編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html alt=音頻編碼實戰 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/aacf5cab-b987-443f-815e-236f984fb2d0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html title=音頻編碼實戰>音頻編碼實戰</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02729303.html alt=java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d69c7c9d8b85444da9360e334ba6555d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02729303.html title=java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID>java實戰項目常用類，Date、Calendar、BigDecimal、Math、UUID</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html alt=老股民總結的賣出技巧實戰圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/7575000bb7b8e57fa260 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/73ba27bb.html title=老股民總結的賣出技巧實戰圖解>老股民總結的賣出技巧實戰圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html alt=股票交易指南：實戰圖解經典的賣出技巧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15305260751844061be70e0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/22408815.html title=股票交易指南：實戰圖解經典的賣出技巧>股票交易指南：實戰圖解經典的賣出技巧</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eaa95354.html alt=股票賣出實戰技術圖解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/88520001219b9b7dabd2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eaa95354.html title=股票賣出實戰技術圖解>股票賣出實戰技術圖解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1b218e68.html alt=圖像拼接算法及實現（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1534489824878547eee8fc2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1b218e68.html title=圖像拼接算法及實現（一）>圖像拼接算法及實現（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/feeaba4f.html alt="在線報表設計實戰系列 – ②製作表格類報表" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/47190002d9db05c4adc2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/feeaba4f.html title="在線報表設計實戰系列 – ②製作表格類報表">在線報表設計實戰系列 – ②製作表格類報表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d288ac1b.html alt=打通實戰保障鏈路“最後一公里” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d288ac1b.html title=打通實戰保障鏈路“最後一公里”>打通實戰保障鏈路“最後一公里”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/79ca353a.html alt=「案例實戰」案例解析（24）自噴系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/c8b46117-9cc6-4c33-be2f-ca4e35b8431f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/79ca353a.html title=「案例實戰」案例解析（24）自噴系統>「案例實戰」案例解析（24）自噴系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/db5ee11c.html alt=「案例實戰」案例解析（39）自噴系統 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/db5ee11c.html title=「案例實戰」案例解析（39）自噴系統>「案例實戰」案例解析（39）自噴系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0015c711.html alt=圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9be3a601501341f2832a19df18b23c5b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0015c711.html title=圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程>圖像顯示30萬像素不丟幀？這個電池廠機器視覺檢測案例有教程</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d8506a86.html alt=圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ee71b902dab44669882d9525f718a9f6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d8506a86.html title=圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了>圖像視覺｜相機、鏡頭、光源如何選型？看完這篇你就懂了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c3d6e4c9.html alt=Java項目實戰第10天：分頁欄的實現 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/000f44dadac946188c05567c6741ae3c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c3d6e4c9.html title=Java項目實戰第10天：分頁欄的實現>Java項目實戰第10天：分頁欄的實現</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>