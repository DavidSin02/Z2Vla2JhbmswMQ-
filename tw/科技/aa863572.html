<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 | 极客快訊</title><meta property="og:title" content="如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/74183d903c17462494208c834aeb9012"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/aa863572.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/aa863572.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/aa863572.html><meta property="article:published_time" content="2020-11-14T21:02:26+08:00"><meta property="article:modified_time" content="2020-11-14T21:02:26+08:00"><meta name=Keywords content><meta name=description content="如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/aa863572.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote><p>作者：Tushar Kolhe</p><p>編譯：ronghuaiyang</p></blockquote><p><strong>導讀</strong></p><p><span style="color:#3e3e3e;--tt-darkmode-color: #A3A3A3">以監控攝像頭數據集的人體檢測模型為例，說明了如何通過對數據的理解來逐步提升模型的效果，不對模型做任何改動，將mAP從0.46提升到了0.79。</span></p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/74183d903c17462494208c834aeb9012><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>介紹<br></strong></h1><p>目標檢測能夠完成許多視覺任務，如實例分割、姿態估計、跟蹤和動作識別。這些計算機視覺任務在監控、自動駕駛和視覺問答等領域都有廣泛的應用。隨著這種廣泛的現實應用，目標檢測自然成為一個活躍的研究領域。</p><p>我們在Fynd的研究團隊正在訓練一個行人檢測模型來提升我們的目標跟蹤模型。在本文中，我們將解釋我們如何選擇一個模型架構，創建一個數據集，併為我們的特定的用例來訓練它。</p><h1 class=pgc-h-arrow-right><strong>什麼是物體檢測？</strong></h1><p>目標檢測是一種計算機視覺技術，它允許我們識別和定位圖像或視頻中的目標。目標檢測可以分為兩部分：目標定位和目標分類。定位可以理解為預測圖像中物體的準確位置(邊界框)，分類是定義它屬於哪個類(人/車/狗等)。</p><p><br></p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/717976eda4b44d4ca78636154446b8c8><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right>物體檢測的方法</h1><p>有各種各樣的方法來解決目標檢測任務。我們可以將模型分為三類。</p><ul><li><strong>兩階段檢測器</strong>：模型有兩種網絡，一個是做區域建議，一個做檢測。一些典型的例子是RCNN family。</li><li><strong>帶anchor的一階段探測器</strong>：這類架構沒有單獨的區域建議網絡，但依賴於預定義的anchor框。我們可以通過YOLO家族來了解這些網絡。</li><li><strong>單階段無anchor檢測器</strong>：這是一個相當新的物體檢測方法，這樣的網絡是端到端可微分的，不依賴於感興趣的區域(ROI)。而且一次性來預測物體。這是一個非常有趣的方法，它塑造了的新研究的思路。要了解更多可以看看CornerNet或CenterNet。</li></ul><h1 class=pgc-h-arrow-right><strong>什麼是COCO數據集？</strong></h1><p>為了比較模型，業界廣泛使用了一個稱為COCO的公共數據集(Common Objects in Context)。這是一個具有挑戰性的數據集，有80個類和超過<strong>150萬個物體實例</strong>，因此這個數據集是初始模型選擇的一個非常好的基準。每年都有各種新的和創新的方法出現，並在該任務上競提升性能。</p><h1 class=pgc-h-arrow-right><strong>如何查看性能?</strong></h1><p>業內提出了評價目標檢測的各種指標。其中一些挑戰包括：</p><ul><li>The PASCAL VOC Challenge (Everingham et al. 2010)</li><li>The COCO Object Detection Challenge (Lin et al. 2014)</li><li>The Open Images Challenge (Kuznetsova 2018).</li></ul><p>要理解這些度量標準，你需要很好地理解一些基本概念，如精度、召回率和IOU。下面是這個公式的一個簡短定義。</p><p><strong>Average Precision</strong></p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8821d78fa3764e6896d5821c77b399c3><p class=pgc-img-caption></p></div><p>AP可以定義為插值後的precision-recall曲線下的面積，計算公式如下：</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7f285aa7094341dfbf7d70838f843134><p class=pgc-img-caption></p></div><p><strong>Mean average precision</strong></p><p>AP的計算只涉及一個類。然而，在目標檢測中，通常有K>1個類。<strong>mAP</strong>定義為AP在所有K類上的平均值：</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d9883aab721648cfa6ae46d3421e66bd><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>實際問題描述<br></strong></h1><p>我們的任務是在零售商店的閉路電視視頻中檢測人的邊界框。該模型非常關鍵，因為跟蹤模型依賴於它，檢測產生的所有誤差都會傳播到跟蹤模型中。以下是在此類視頻中檢測的一些主要挑戰。</p><h1 class=pgc-h-arrow-right><strong>挑戰</strong></h1><ul><li><strong>視角</strong>: 閉路電視是頂部安裝的，和正常照片的視角不一樣。</li><li><strong>擁擠</strong>: 商店有時會有非常擁擠的場景。</li><li><strong>背景很亂</strong>: 零售商店有很多的干擾或雜物(對我們的模型來說)，比如衣服、貨架、人體模型等，這可能會導致誤報。</li><li><strong>燈光條件</strong>：店內的燈光條件與戶外攝影不同。</li><li><strong>圖像質量</strong>：來自閉路電視的視頻幀有時會很差，還可能包含運動模糊。</li></ul><h1 class=pgc-h-arrow-right><strong>構建測試集</strong></h1><p>我們創建了一個驗證集，其中包含來自零售店CCTV視頻的視頻幀。我們使用<em>person邊界框</em>對每幀進行標註，並使用<strong>mAP@ 0.50 IOU</strong>閾值在整個訓練迭代過程中測試模型。</p><h1 class=pgc-h-arrow-right><strong>第1個人體檢測模型</strong></h1><p>我們的第一個模型是COCO的預訓練的模型，其中“person”是其中一個類。我們在每種方法中篩選出了2個模型，並根據<em>COCO mAP val</em>和推理時間對其進行了評估。</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4e8108f21a664aa98d7175e8a5d81264><p class=pgc-img-caption></p></div><p>YOLOv5的單階段特性(快速推理)和在<em>COCO mAP val</em>上的良好性能被我們列入了候選名單。它也有更快的版本，如YOLOv5m和YOLOv5s。</p><h1 class=pgc-h-arrow-right><strong>YOLOv5</strong></h1><p>YOLO家族屬於單階段物體探測器，不像RCNN家族，它沒有一個單獨的區域建議網絡(RPN)，並依賴於不同尺度的anchor。整體結構架構可分為三部分：backbone, neck和head。使用<em>CSP (Cross Stage Partial Networks)</em>作為backbone從輸入圖像中提取特徵。<em>PANet</em>用作收集特徵金字塔的neck，head是使用特徵上的anchor檢測物體的最終檢測層。</p><p>YOLO架構使用的激活功能是谷歌Brains在2017年提出的<em>Hard Swish</em>的變體，它看起來和<em>ReLU</em>非常相似，但不像ReLU，它在x=0附近是平滑的。</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/95cb408e381d4c608c87d42020cc3bdd><p class=pgc-img-caption></p></div><p><strong>損失函數</strong>用的是二元交叉熵。</p><h1 class=pgc-h-arrow-right><strong>性能</strong></h1><p>0.48 mAP @ 0.50 IOU (在我們自己的測試集上)</p><h1 class=pgc-h-arrow-right><strong>分析</strong></h1><p>這個開箱即用的模型不是很好，因為模型是在包含一些不必要的類的COCO數據集上訓練的。包含<em>人的實例</em>的圖像數量較少，人群密度也較低。此外，包含<em>人的實例</em>的圖像分佈與CCTV視頻幀中的非常不同。</p><h1 class=pgc-h-arrow-right><strong>結論</strong></h1><p>我們需要更多的數據來訓練模型，使其包含更多擁擠的場景，並使攝像機的視角在45⁰- 60⁰之間(和CCTV類似)。</p><h1 class=pgc-h-arrow-right><strong>收集公共數據</strong></h1><p>我們的下一步是收集包含人邊界框的公開數據集。有大量的人檢測的數據集，但我們需要一些關於數據集的額外信息，如視角，圖像質量，人的密度和背景，以捕獲數據集分佈信息。</p><p>我們可以看到滿足我們確切需求的數據集並不是很多，但是我們仍然可以使用這些數據集，因為具備人的邊界框的基本要求已經得到了滿足。下載所有數據集後，我們將其轉換為常見的COCO格式用於檢測。</p><h1 class=pgc-h-arrow-right><strong>第2個人體檢測模型</strong></h1><p>我們用所有收集到的公共數據集訓練模型。</p><p><strong>訓練迭代 2</strong>:</p><ul><li>Backbone: YOLOv5x</li><li>模型初始化：COCO預訓練權重</li><li>Epochs: 10 epochs</li></ul><h1 class=pgc-h-arrow-right><strong>性能</strong></h1><p>0.65 mAP @ 0.50 IOU</p><h1 class=pgc-h-arrow-right><strong>分析</strong></h1><p>隨著數據集的增加，模型性能顯著提高。一些數據集有高擁擠的場景，滿足我們的一個要求，和一些包含頂部的相機視角，滿足另一個要求。</p><h1 class=pgc-h-arrow-right><strong>總結</strong></h1><p>雖然模型的性能有所提高，但有些數據集是視頻序列，而且在某些情況下背景仍然是靜態的，可能會導致過擬合。很少量的數據集中有非常小的人類，這使得任務很難學習。</p><h1 class=pgc-h-arrow-right><strong>清洗數據</strong></h1><p>下一步是清理數據。我們從訓練和驗證集中過濾出造成損失最多的圖像，或者我們可以說是那些mAP非常小的圖像。我們選擇了0.3 mAP閾值並對圖像進行可視化。我們從數據集中過濾了三種類型的用例。</p><ul><li>標籤錯誤的邊框</li><li>圖像包含非常小的邊框或太多太擁擠</li><li>重複的或近似重複的幀</li></ul><p>為了去除重複的幀，我們只從視頻序列中選擇稀疏的幀。</p><h1 class=pgc-h-arrow-right><strong>第3個人體檢測模型</strong></h1><p>有了清理和整理之後的數據集，我們就可以開始第三次迭代了</p><p><strong>訓練迭代 3</strong>:</p><ul><li>Backbone: YOLOv5x</li><li>模型初始化：COCO預訓練權重</li><li>Epochs: ~100 epochs</li></ul><h1 class=pgc-h-arrow-right><strong>性能</strong></h1><p>0.69 mAP @ 0.50 IOU</p><h1 class=pgc-h-arrow-right><strong>分析</strong></h1><p>將未清理的數據從訓練和驗證集中刪除後，模型性能略有改善。</p><h1 class=pgc-h-arrow-right><strong>總結</strong></h1><p>數據集被清理，可以看到性能的改進。我們可以得出結論，進一步改進數據集可以提高模型性能。為了提高性能，我們需要確保數據集包含與測試用例相似的圖像。我們處理了人群情況和一些視角情況，但大多數數據都是向前的視角。</p><h1 class=pgc-h-arrow-right><strong>數據增強</strong></h1><p>我們已經列出了在現實案例中檢測時將面臨的一些挑戰，但是收集的數據集分佈不同。因此，我們使用了一些數據增強技術，使訓練分佈更接近生產用例或測試分佈。</p><p>下面是我們希望對數據集進行的擴充。</p><ul><li><strong>視角</strong>- 透視變換</li></ul><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1e9b754dff6f4f5c8410eaf3d931e076><p class=pgc-img-caption></p></div><ul><li><strong>光照條件</strong>- 亮度 - 對比度</li></ul><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/54733819a0d14b1fb9610309cdff206b><p class=pgc-img-caption></p></div><ul><li><strong>圖像質量</strong>- 噪聲 - 圖像壓縮 - 運動模糊</li></ul><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/95f7864d188f4fb694b6a262021bd5d4><p class=pgc-img-caption></p></div><p>通過將所有這些增強加在一起，我們可以將公共數據分佈轉換為更接近生產分佈的數據。我們可以看到從下面的圖像和比較原始和轉換後的圖像。</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/36e3620726fc472699b417f6e7293ac3><p class=pgc-img-caption></p></div><p>所有這些增強都是通過使用“albumentation”來實現的，“albumentation”是一個很容易與PyTorch數據轉換集成的python庫。它還有一個demo應用，我們使用該應用為不同的方法設置增強參數。在庫中還有許多可用於其他用例的擴展。</p><h1 class=pgc-h-arrow-right><strong>第4個人體檢測模型</strong></h1><p>現在有了轉換後的數據集，我們就可以進行第四個迭代了</p><p><strong>訓練迭代 4</strong>:</p><ul><li>Backbone: YOLOv5x</li><li>模型初始化：來自第3個迭代的模型權重</li><li>Epochs: ~100 epochs</li></ul><h1 class=pgc-h-arrow-right><strong>性能</strong></h1><p>0.77 mAP @ 0.50 IOU</p><h1 class=pgc-h-arrow-right><strong>分析</strong></h1><p>![](How to boost object detection accuracy by understanding data.assets/1_H3gjYDGFDHq5aEk85dSBUw.png)</p><p>YOLO v5x 在自定義的測試集上使用TIDE進行分析的結果，mAP @0.5: 0.77</p><p>性能提高了近8%，該模型能夠預測大多數情況，並在攝像機視角上進行了泛化。由於背景雜波和遮擋的影響，視頻序列中仍然存在誤報和漏報的現象。</p><h1 class=pgc-h-arrow-right><strong>結論</strong></h1><p>我們嘗試收集數據集並覆蓋任務中幾乎所有的挑戰，但仍有一個挑戰阻礙了我們的模型性能。我們需要收集包含這些用例的數據。</p><h1 class=pgc-h-arrow-right><strong>創建自定義的標註</strong></h1><p>通過數據增強，我們創建了一些真實的案例，但我們的數據在圖像背景方面仍然缺乏多樣性。對於一個零售商店來說，框架背景充滿了雜亂、人體模型或衣服架子，這會導致誤報，大遮擋會導致漏報。為了增加多樣性，我們放棄了谷歌，我們從商店中收集閉路電視錄像，並手工標註圖像。首先，我們將迭代4中的所有圖像通過模型進行預測，並創建自動標籤，然後使用開源標註工具CVAT (Computer Vision and annotation tool)進一步的修正標註。</p><h1 class=pgc-h-arrow-right><strong>最終的人體檢測模型</strong></h1><p>我們將自定義的存儲圖像添加到之前的數據集中，併為最後的迭代訓練我們的模型。我們最終的數據集分佈是這樣的。</p><div class=pgc-img><img alt=如何通過理解數據在自定義數據集上逐步提升物體檢測模型效果 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/572258e5db29480ab7f8128fbaaac029><p class=pgc-img-caption>最終訓練集的數據分佈</p></div><p><strong>訓練迭代 5</strong>:</p><ul><li>Backbone: YOLOv5x</li><li>模型初始化: 從第4個迭代的權重開始</li><li>Epochs: ~100 epochs</li></ul><h1 class=pgc-h-arrow-right><strong>性能</strong></h1><p>0.79 mAP @ 0.50 IOU</p><h1 class=pgc-h-arrow-right><strong>分析</strong></h1><p>![](How to boost object detection accuracy by understanding data.assets/1_1FhHmPPBpWHwn04_m6jf1Q.png)</p><p>YOLO v5x 在自定義的測試集上使用TIDE進行分析的結果，mAP @0.5: 0.79</p><p>模型的性能顯示出~ 0.2%的正增長。從TIDE 分析中可以看出，假陽性對錯誤的貢獻減小了。</p><h1 class=pgc-h-arrow-right><strong>結論</strong></h1><p>額外的數據有助於使模型對背景干擾更健壯，但是收集的數據量仍然比總體數據集的大小少得多，並且模型仍然有一些false negatives。當對隨機圖像進行測試時，該模型能夠很好地泛化。</p><h1 class=pgc-h-arrow-right><strong>過程概述</strong></h1><p>我們從模型選擇開始，以COCO mAP作為基準，我們選出了一些模型。此外，我們考慮了推理時間和模型架構，並選擇YOLO v5。我們收集並清理了各種公開可用的數據集，並使用各種數據增強技術將其轉換為我們的用例。最後，我們從頭收集圖像，並在手工標註之後將它們添加到數據集中。我們最終的模型是在這個經過整理的數據集上訓練的，能夠從 <em>0.46 mAP @ IOU0.5</em>改進到<em>0.79 mAP @ IOU 0.5</em>。</p><h1 class=pgc-h-arrow-right><strong>總結</strong></h1><p>通過根據用例對數據集進行處理，我們將物體檢測模型改進了約20%。該模型在mAP和延遲方面仍有改進空間。選擇的超參數是YOLO v5默認給出的，我們可以使用超參數搜索庫，如optuna對它們進行優化。當訓練分佈和測試分佈之間存在差異時，域適應是另一種可以使用的技術。此外，這樣的情況可能需要使用額外數據集進行連續的訓練循環，以確保模型的持續改進。</p><p><br></p><p style=text-align:start>英文原文：https://blog.gofynd.com/boost-object-detection-model-accuracy-552586d698c</p><p>更多內容，請關注微信公眾號<strong>“AI公園”</strong>。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>通過</a></li><li><a>數據</a></li><li><a>義數據</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f0a58eb.html alt=通過數據說話，R語言有哪七種可視化應用？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/153959835449010fc334911 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f0a58eb.html title=通過數據說話，R語言有哪七種可視化應用？>通過數據說話，R語言有哪七種可視化應用？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html alt=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3e507bb24abc482fb28df1121a7ee097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/862c99dd.html title=數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出>數據告訴你，為什麼要在上升趨勢買入和下降趨勢賣出</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a80e0cfa.html alt=男子通過二手物品交易網站賣出3把仿真槍，提起公訴 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/S6fqkl8J4dccZ8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a80e0cfa.html title=男子通過二手物品交易網站賣出3把仿真槍，提起公訴>男子通過二手物品交易網站賣出3把仿真槍，提起公訴</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html alt="數據科學家常犯的 10 個編程錯誤" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1f742b21.html title="數據科學家常犯的 10 個編程錯誤">數據科學家常犯的 10 個編程錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html alt=數據科學家常遇到的10個錯誤 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/59f660bac8b541888e71459b604ba733 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d5773fc2.html title=數據科學家常遇到的10個錯誤>數據科學家常遇到的10個錯誤</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html alt=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f120ed2c1ed549e39bfa60bb3a86d591 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5ff7d77e.html title=WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定>WORD表格的數據老闆讓增加合計，同事用計算器計算，我3秒鐘搞定</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html alt="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7aa6ee1b961f467e8090ed56f45c110f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cea55527.html title="多列數據合併一列，還在用數據透視就out了，用=號只要三步完成">多列數據合併一列，還在用數據透視就out了，用=號只要三步完成</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html alt=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3609570de59a49a9be5667dd9a637f65 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/37396ded.html title=數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心>數據結構系列：哈希表？這涉及的是“加密/區塊鏈”等技術的核心</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html alt=「數據結構」Hash表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/617a6d43032e4efbac6b996c9bb5ab11 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0e2547f1.html title=「數據結構」Hash表>「數據結構」Hash表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html alt=備戰秋招——算法與數據結構（5） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ab6859411bd8435bb2616d6fef468556 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b37254e1.html title=備戰秋招——算法與數據結構（5）>備戰秋招——算法與數據結構（5）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html alt=懂了數據結構框架思維，一切算法不過是紙老虎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ad2c8a60d9634e0aa36b5d8a664de355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f605b4b8.html title=懂了數據結構框架思維，一切算法不過是紙老虎>懂了數據結構框架思維，一切算法不過是紙老虎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e03941dc.html alt=數據結構一(哈希表)想進大廠的必備知識點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/86ad7a2f62cc48f98bbe53b42ca4bf9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e03941dc.html title=數據結構一(哈希表)想進大廠的必備知識點>數據結構一(哈希表)想進大廠的必備知識點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/385a3c55.html alt="數據結構中的 Hash 表" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/0e43812c-6f05-4cf6-af7e-18011d0a316a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/385a3c55.html title="數據結構中的 Hash 表">數據結構中的 Hash 表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/90dc0f86.html alt=通過圖片帶你認識消防控制室消防設備 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/760e9be85de94141b9d8725547143f42 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/90dc0f86.html title=通過圖片帶你認識消防控制室消防設備>通過圖片帶你認識消防控制室消防設備</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html alt=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5d4a0000046e1bea8b90 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html title=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？>Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>