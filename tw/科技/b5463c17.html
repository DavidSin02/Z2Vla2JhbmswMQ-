<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ | 极客快訊</title><meta property="og:title" content="實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/a8b4a4fe73ea4c188b242b9a63646c06"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b5463c17.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b5463c17.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/b5463c17.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p><strong>點擊上方關注，All in AI中國</strong></p></blockquote><p>Keras是一個很棒的庫，它提供了一個簡單的API來構建神經網絡，但最近對PyTorch的興奮感最終讓我對探索這個庫產生了興趣。雖然我是一個"盲目追隨炒作"的人，但是研究人員的採用和fast.ai的推崇使我確信在這個深度學習的新入口中必定有新的東西值得我去探尋。</p><p>由於學習新技術的最佳方法是使用它來解決問題，所以我學習PyTorch的工作始於一個簡單的項目：使用預先訓練的卷積神經網絡進行對象識別任務。在本文中，我們將看到如何使用PyTorch來實現這一目標，並在此過程中學習一些關於庫和遷移學習的重要概念。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a8b4a4fe73ea4c188b242b9a63646c06><p class=pgc-img-caption></p></div><p>雖然PyTorch可能不適合所有人，但在這一點上，很難說出哪個深度學習庫會脫穎而出，而能夠快速學習和使用不同的工具對於成為數據科學家來說至關重要。</p><p>該項目的完整代碼在GitHub上以Jupyter Notebook的形式提供（https://github.com/WillKoehrsen/pytorch_challenge/blob/master/Transfer%20Learning%20in%20PyTorch.ipynb）。這個項目源於我參加Udacity PyTorch獎學金挑戰（https://www.udacity.com/facebook-pytorch-scholarship）。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b1283fa6a5bd4c49a83ddc633150b180><p class=pgc-img-caption>從受過訓練的網絡預測</p></div><p><strong>遷移學習法</strong></p><p>我們的任務是訓練可以識別圖像中物體的卷積神經網絡（CNN）。我們將使用Caltech 101數據集（http://www.vision.caltech.edu/Image_Datasets/Caltech101/），該數據集包含101個類別的圖像。大多數類別只有50個圖像，這些圖像通常不足以讓神經網絡學會高精度。因此，我們將使用預先構建和預先訓練的模型來應用遷移學習，而不是從頭開始構建和訓練CNN。</p><p>遷移學習的基本前提很簡單：採用在大型數據集上訓練的模型，並將其轉移到較小的數據集上。對於使用CNN的對象識別，我們凍結網絡的早期卷積層，並且僅訓練進行預測的最後幾層。這個想法是卷積層提取適用於圖像的一般，低級特徵（例如邊緣、圖案、漸變）後面的圖層識別圖像中的特定特徵，如眼睛或車輪。</p><p>因此，我們可以使用在大規模數據集（通常是Imagenet）中訓練不相關類別的網絡，並將其應用於我們自己的問題中，因為圖像之間共享通用的低級特徵。Caltech 101數據集中的圖像與Imagenet數據集中的圖像非常相似，模型在Imagenet上學習的知識應該很容易轉移到此任務中。（http://www.image-net.org/）</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b4c8a60121dd4a079250632623286360><p class=pgc-img-caption></p></div><p>遷移學習背後的理念</p><p>以下是物體識別的遷移學習的概要：</p><ol><li>加載在大型數據集上訓練的預訓練CNN模型</li><li>凍結模型的下卷積層中的參數（權重）</li><li>添加具有多層可訓練參數的自定義分類器以進行建模</li><li>訓練可用於任務的訓練數據的分類器層</li><li>根據需要微調超參數並解凍更多層</li></ol><p>事實證明，這種方法適用於廣泛的領域。這是一個很好的工具，通常是面對新的圖像識別問題時應該嘗試的第一種方法。</p><p><strong>數據設置</strong></p><p>對於所有數據科學問題，正確格式化數據將決定項目的成功或失敗。幸運的是，Caltech 101數據集圖像清晰，並以正確的格式存儲。如果我們正確設置數據目錄，PyTorch可以很容易地將正確的標籤與每個類關聯起來。我將數據分為訓練，驗證和測試集，分別為50％，25％，25％，然後按如下方式構建目錄：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/41f2de894f6044999f060a04f2feb47d><p class=pgc-img-caption></p></div><p>按類別劃分的訓練圖像數量（我可以互換地使用術語類別和類別）：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ea86bae55fbe4f7094d5c44ce11f720b><p class=pgc-img-caption>按類別劃分的訓練圖像數量</p></div><p>我們希望模型在具有更多示例的類上做得更好，因為它可以更好地學習將特性映射到標籤。為了處理有限數量的訓練樣例，我們將在訓練期間使用數據增加。</p><p>作為另一項數據探索，我們還可以查看大小分佈。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a9b9bda314ad4f3ab1bd7894185f09a6><p class=pgc-img-caption>按類別分佈平均圖像大小（以像素為單位）</p></div><p>Imagenet模型需要224 x 224的輸入大小，因此其中一個預處理步驟將是調整圖像大小。預處理也是我們為訓練數據實施數據增強的地方。</p><p><strong>數據增強</strong></p><p>數據增強的想法是通過對圖像應用隨機變換來人為地增加模型看到的訓練圖像的數量。例如，我們可以隨機旋轉或裁剪圖像或水平翻轉它們。我們希望我們的模型能夠區分對象，而不管方向如何，數據增強也可以使模型對輸入數據的轉換不變。</p><p>無論大象朝哪個方向走，大象仍然是大象！</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d1cb02b095e847e79c185e5332ddb03d><p class=pgc-img-caption>訓練數據的圖像變換</p></div><p>通常僅在訓練期間進行增強（儘管在fast.ai庫中可以進行測試時間增加）。每個時期 - 通過所有訓練圖像的一次迭代 - 對每個訓練圖像應用不同的隨機變換。這意味著如果我們迭代數據20次，我們的模型將看到每個圖像的20個略有不同的版本。整體結果應該是一個模型，它可以學習對象本身，而不是如何呈現它們或圖像中的工件。</p><p><strong>圖像預處理</strong></p><p>這是處理圖像數據最重要的一步。在圖像預處理期間，我們同時為網絡準備圖像並將數據增強應用於訓練集。每個模型都有不同的輸入要求，但如果我們讀完Imagenet所需的內容，我們就會發現我們的圖像需要為224x224並標準化為一個範圍。</p><p>要在PyTorch中處理圖像，我們使用遷移，即應用於數組的簡單操作。驗證（和測試）遷移如下：</p><ul><li>調整</li><li>中心裁剪為224 x 224</li><li>遷移為張量</li><li>用均值和標準差標準化</li></ul><p>通過這些遷移的最終結果是可以進入我們網絡的張量。訓練變換是相似的，但增加了隨機增強。</p><p>首先，我們定義訓練和驗證轉換：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e2b7f9feebd84fbeaf880a94a62a4d76><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9bd737ed130e49629ac162700bdd5e8e><p class=pgc-img-caption></p></div><p>然後，我們創建數據集和數據閱讀器。ImageFolder創建數據集，PyTorch將自動將圖像與正確的標籤關聯，前提是我們的目錄設置如上述。然後將數據集傳遞給DataLoader，這是一個產生批量圖像和標籤的迭代器。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/adb1b44ffed84dad9c483859355c209a><p class=pgc-img-caption></p></div><p>我們可以使用以下方法查看DataLoader的迭代行為：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a45aae39745c47bfbd90a23784e5a7be><p class=pgc-img-caption></p></div><p>批處理的形狀是（batch_size，color_channels，height，width）。在訓練、驗證和最終測試期間，我們將遍歷DataLoaders，一次通過包含一個時期的完整數據集。每個時期，訓練DataLoader將對圖像應用稍微不同的隨機變換以進行訓練數據增強。</p><p><strong>用於圖像識別的預訓練模型</strong></p><p>隨著我們的數據的成形，我們接下來將注意力轉向模型。為此，我們將使用預先訓練的卷積神經網絡。PyTorch有許多模型已經在Imagenet的1000個類中訓練了數百萬個圖像。完整的模型列表可以在這裡看到（https://pytorch.org/docs/stable/torchvision/models.html）。這些模型在Imagenet上的性能如下所示：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f831f990197d481f96b0b4ab14ee44b7><p class=pgc-img-caption>PyTorch中的預訓練模型和Imagenet上的性能</p></div><p>對於此實現，我們將使用VGG-16。雖然它沒有記錄最低的錯誤，但我發現它適用於任務，並且比其他模型訓練得更快。使用預訓練模型的過程已經建立：</p><ol><li>從在大型數據集上訓練的網絡加載預訓練的權重</li><li>凍結較低（卷積）圖層中的所有權重：根據新任務與原始數據集的相似性調整要凍結的圖層</li><li>用自定義分類器替換網絡的上層：輸出數必須設置為等於類的數量</li><li>僅為任務訓練自定義分類器層，從而優化較小數據集的模型</li></ol><p>在PyTorch中加載預先訓練的模型很簡單：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/67e35fde3e3a4128abdb1b21fafb2a9f><p class=pgc-img-caption></p></div><p>這個模型有超過1.3億個參數，但我們只訓練最後幾個完全連接的層。首先，我們凍結所有模型的權重：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2b4e5629ee524b84945a18411fc33427><p class=pgc-img-caption></p></div><p>然後，我們使用以下圖層添加我們自己的自定義分類器：</p><ul><li>與ReLU激活完全連接，shape =（n_inputs，256）</li><li>Dropout有40％的可能性下降</li><li>與log softmax輸出完全連接，shape =（256，n_classes）</li></ul><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1f6a3cc4c5664eefa374e50f4e984ecd><p class=pgc-img-caption></p></div><p>將額外圖層添加到模型時，默認情況下將它們設置為可訓練（require_grad = True）。對於VGG-16，我們只改變最後一個原始的全連接層。卷積層和前5個完全連接層中的所有權重都是不可訓練的。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/2dec159089a04510ab98d637f1be4bf2><p class=pgc-img-caption></p></div><p>網絡的最終輸出是我們數據集中100個類中每個類的對數概率。 該模型共有1.35億個參數，其中只有100多萬個將被訓練。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/522c65e5ecd6436986dc803554558ceb><p class=pgc-img-caption></p></div><p><strong>將模型移動到GPU（s）</strong></p><p>PyTorch的最佳方面之一是可以輕鬆地將模型的不同部分移動到一個或多個gpus（https://pytorch.org/docs/stable/notes/cuda.html），以便你可以充分利用你的硬件。由於我使用2 gpus進行訓練，我首先將模型移動到cuda，然後創建一個分佈在gpus上的DataParallel模型：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d9293ff12d9945b5839ccdcc74521311><p class=pgc-img-caption></p></div><p>（這個筆記本應該在一個gpu上運行，以便在合理的時間內完成。對CPU的加速可以輕鬆達到10倍或更多。）</p><p><strong>訓練損失和優化</strong></p><p>訓練損失（預測和真值之間的誤差或差異）是負對數似然（NLL：https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/）。（PyTorch中的NLL損失需要對數概率，因此我們從模型的最後一層傳遞原始輸出。）PyTorch使用自動微分，這意味著張量不僅跟蹤它們的值，而且還跟蹤每個操作（乘法，加法，激活等）。這意味著我們可以針對任何先前張量計算網絡中任何張量的梯度。</p><p>這在實踐中意味著損失不僅跟蹤誤差，而且跟蹤模型中每個權重和偏差對誤差的貢獻。在我們計算損失後，我們可以找到相對於每個模型參數的損失梯度，這個過程稱為反向傳播。一旦我們獲得了梯度，我們就會使用它們來更新參數和優化器。</p><p>優化器是Adam（https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/），梯度下降的有效變體，通常不需要手動調整學習速率。在訓練期間，優化器使用損失的梯度來嘗試通過調整參數來減少模型輸出的誤差（"優化"）。只會優化我們在自定義分類器中添加的參數。</p><p>損失和優化器初始化如下：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6df156e6504e4841a0fb2f65b46aeb7c><p class=pgc-img-caption></p></div><p>通過預先訓練的模型，自定義分類器，損失，優化器以及最重要的數據，我們已準備好進行訓練。</p><p><strong>訓練</strong></p><p>PyTorch中的模型訓練比Keras中的實際操作多一些，因為我們必須自己進行反向傳播和參數更新步驟。主循環迭代多個時期，並且在每個時期迭代通過DataLoader。 DataLoader生成一批我們通過模型的數據和目標。在每個訓練批次之後，我們計算損失，相對於模型參數反向傳播損失的梯度，然後用優化器更新參數。</p><p>我建議你查看筆記本上的完整訓練詳細信息（https://github.com/WillKoehrsen/pytorch_challenge/blob/master/Transfer%20Learning%20in%20PyTorch.ipynb），但基本的偽代碼如下：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/8577cc3bbd6e4934840568914b3083ad><p class=pgc-img-caption></p></div><p>我們可以繼續迭代數據，直到達到給定數量的時期。然而，這種方法的一個問題是，我們的模型最終將過度擬合訓練數據。為了防止這種情況，我們使用驗證數據並早期停止。</p><p><strong>早期停止</strong></p><p>早期停止（https://en.wikipedia.org/wiki/Early_stopping）意味著當驗證損失在許多時期沒有減少時停止訓練。在我們繼續訓練時，訓練損失只會減少，但驗證損失最終會達到最低限度並達到穩定水平或開始增加。理想情況下，當驗證損失最小時，我們希望停止訓練，希望此模型能夠最好地推廣到測試數據。當使用早期停止時，驗證損失減少的每個時期，我們保存參數，以便我們以後可以檢索具有最佳驗證性能的那些。</p><p>我們通過在每個訓練時期結束時迭代驗證DataLoader來實現早期停止。我們計算驗證損失並將其與最低驗證損失進行比較。如果到目前為止損失最小，我們保存模型。如果在一定數量的時期內損失沒有改善，我們停止訓練並返回已保存到磁盤的最佳模型。</p><p>同樣，完整的代碼在筆記本中，但偽代碼是：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/04894655eec6457b865f818c7e91c1c5><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/86bfa6d4a4544953804a5660ddc58fd8><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c9c61e3af7d54a809876c61c34653b8c><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f5953322344e40d2b97ec12f7b7835fc><p class=pgc-img-caption></p></div><p>要了解早期停止的好處，我們可以查看顯示訓練和驗證損失和準確性的訓練曲線：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/89e0f5aa820d402f8e0cbb7a8071cd7f><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4cf5bf09b2754ad2b522542971c3624e><p class=pgc-img-caption>負對數似然和準確性訓練曲線</p></div><p>正如預期的那樣，隨著進一步的訓練，訓練損失只會繼續減少。另一方面，驗證損失達到最低和穩定的狀態。在某一時期，進一步訓練是沒有回報的（甚至是負回報）。我們的模型將僅開始記憶訓練數據，並且無法推廣到測試數據。</p><p>如果沒有早期停止，我們的模型將訓練超過必要的時間並且將過度訓練數據。</p><p>我們從訓練曲線中可以看到的另一點是我們的模型並沒有過度擬合。總是存在一些過度擬合，但是在第一個可訓練的完全連接層之後的退出可以防止訓練和驗證損失過多。</p><p><strong>做出預測：推論</strong></p><p>在筆記本中我處理了一些無聊但必要的保存和加載PyTorch模型的細節，但在這裡我們將移動到最佳部分：對新圖像進行預測。我們知道我們的模型在訓練甚至驗證數據方面做得很好，但最終的測試是它如何在一個前所未見的保持測試集上的執行。我們保存了25％的數據，以確定我們的模型是否可以推廣到新數據。</p><p>使用訓練過的模型進行預測非常簡單。我們使用與訓練和驗證相同的語法：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2c9ab1473a734f28b58aa0b8a10ca6d8><p class=pgc-img-caption></p></div><p>我們概率的形狀是（batch_size，n_classes），因為我們有每個類的概率。我們可以通過找出每個示例的最高概率來找到準確性，並將它們與標籤進行比較：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/263ae616ef47486b8fe69fc28b8ece0b><p class=pgc-img-caption></p></div><p>在診斷用於對象識別的網絡時（https://www.coursera.org/lecture/machine-learning/model-selection-and-train-validation-test-sets-QGKbr），查看測試集的整體性能和單個預測會很有幫助。</p><p><strong>模型結果</strong></p><p>以下是模型的兩個預測：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/64662841da574ca585dcf3cf0e74157d><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9e4ea8737af5477598ff775456213e69><p class=pgc-img-caption>這些都很簡單，所以我很高興模型沒有問題！</p></div><p>我們不僅僅想關注正確的預測，我們還將很快就會看到一些錯誤的輸出。現在讓我們評估整個測試集的性能。為此，我們希望迭代測試DataLoader並計算每個示例的損失和準確性。</p><p>用於對象識別的卷積神經網絡通常根據topk精度（https://stats.stackexchange.com/questions/95391/what-is-the-definition-of-top-n-accuracy）來測量。這是指真實的類是否屬於k最可能預測的類中。例如，前5個準確度是5個最高概率預測中正確等級的百分比。你可以從PyTorch張量中獲取topk最可能的概率和類，如下所示：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2d2c10894c1f41fa836ddbf778db76d8><p class=pgc-img-caption></p></div><p>在整個測試集上評估模型，我們計算指標：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7582c967d87945a48ecd61f975839295><p class=pgc-img-caption></p></div><p>這些與驗證數據中接近90％的top1精度相比是有利的。總的來說，我們得出結論，我們的預訓練模型能夠成功地將其知識從Imagenet轉移到我們較小的數據集。</p><p><strong>模型調查</strong></p><p>儘管該模型表現良好，但仍有可能採取一些步驟可以使其變得更好。通常，弄清楚如何改進模型的最佳方法是調查其錯誤（注意：這也是一種有效的自我改進方法。）</p><p>我們的模型不太適合識別鱷魚，所以我們來看看這個類別的一些測試預測：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7d39ee75bd9d432a92b7587c291afea1><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e1d2dfd63d0e4813845c7ada9befc36b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/497857aa77f942ef9f73edcd0bb744de><p class=pgc-img-caption></p></div><p>考慮到鱷魚和鱷魚頭之間的微妙區別，以及第二張圖像的難度，我會說我們的模型在這些預測中並非完全不合理。圖像識別的最終目標是超越人類的能力，我們的模型幾乎已經接近了！</p><p>最後，我們希望模型在具有更多圖像的類別上表現更好，因此我們可以查看給定類別中的準確度圖表與該類別中的訓練圖像數量：</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9f91d41720fc47a0b898a52471022d56><p class=pgc-img-caption></p></div><p>在訓練圖像的數量和前一個測試精度之間似乎存在正相關關係。這表明更多的訓練數據增加是有所幫助的，或者我們應該對測試時間進行增加。我們還可以嘗試不同的預訓練模型，或者構建另一個自定義分類器。目前，深度學習仍然是一個經驗領域，這意味著經常需要實驗！</p><p><strong>結論</strong></p><p>雖然有更容易使用的深度學習庫，但PyTorch的優點是速度快，對模型架構/訓練的各個方面的控制好，能使張量自動區分的反向傳播，以及由於PyTorch圖的動態特性而易於調試的代碼。對於生產代碼或你自己的項目，我不確定使用PyTorch而不是具有更溫和學習曲線的庫（例如Keras）還存在令人信服的論據，但知道如何使用不同選項會很有幫助。</p><p>通過這個項目，我們能夠看到使用PyTorch的基礎知識以及遷移學習的概念，這是一種有效的對象識別方法。我們可以使用已在大型數據集上進行過訓練的現有體系結構，然後根據我們的任務調整它們，而不是從頭開始訓練模型。這無疑減少了訓練的時間並且通常導致更好的整體性能。這個項目的成果是對遷移學習和PyTorch一些知識的應用，我們可以構建它來構建更復雜的應用程序。</p><p>我們確實生活在一個令人難以置信的深度學習時代，任何人都可以利用輕鬆可用的資源建立深度學習模型！現在是時候，通過構建自己的項目來更好的利用這些資源了。</p><div class=pgc-img><img alt=實踐課堂：PyTorch中使用卷積神經網絡進行遷移學習！ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/73dc86d3deff4a4bb0ddeb0126a3b335><p class=pgc-img-caption></p></div><p>作者——William Koehrsen</p><p>文章來源：https://towardsdatascience.com/ten-applications-of-ai-to-fintech-22d626c2fdac</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>實踐</a></li><li><a>課堂</a></li><li><a>PyTorch</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/b6acbddb.html alt=「壓鑄實踐」大截面ZA27鋅合金蝸輪的雙重擠壓鑄造應用案例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/972374c8b24644389e188cb290249f17 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b6acbddb.html title=「壓鑄實踐」大截面ZA27鋅合金蝸輪的雙重擠壓鑄造應用案例>「壓鑄實踐」大截面ZA27鋅合金蝸輪的雙重擠壓鑄造應用案例</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a68154e3.html alt="衡真課堂 | 電力系統中7個最常見的知識點" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/038eab503e1b47469a24f92162e48713 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a68154e3.html title="衡真課堂 | 電力系統中7個最常見的知識點">衡真課堂 | 電力系統中7個最常見的知識點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8acadb42.html alt=超能課堂(209)：從CD開始的音頻編碼進化之路 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2b134f30f50f45779c576c52e79fdfa5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8acadb42.html title=超能課堂(209)：從CD開始的音頻編碼進化之路>超能課堂(209)：從CD開始的音頻編碼進化之路</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2438c41e.html alt=超能課堂(220)：數字視頻編碼的發展歷程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/Rtg4MNgBtlHiVI style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2438c41e.html title=超能課堂(220)：數字視頻編碼的發展歷程>超能課堂(220)：數字視頻編碼的發展歷程</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/89c5457e.html alt=建築課堂建築工程施工常用鋼筋連接方式簡介 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/cc80a949af1b43b68cbe4ee87ee37a5e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/89c5457e.html title=建築課堂建築工程施工常用鋼筋連接方式簡介>建築課堂建築工程施工常用鋼筋連接方式簡介</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/441e32c5.html alt=擰緊微課堂｜擰緊策略——螺栓連接的分類 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1529806969192cd5df56477 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/441e32c5.html title=擰緊微課堂｜擰緊策略——螺栓連接的分類>擰緊微課堂｜擰緊策略——螺栓連接的分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e07fc1ef.html alt=擰緊微課堂｜軟硬連接的定義和對於擰緊過程的影響 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1529765560055dc98759e16 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e07fc1ef.html title=擰緊微課堂｜軟硬連接的定義和對於擰緊過程的影響>擰緊微課堂｜軟硬連接的定義和對於擰緊過程的影響</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bd213158.html alt=擰緊微課堂｜擰緊策略—摩擦力扭矩 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/152980681082224b749b890 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bd213158.html title=擰緊微課堂｜擰緊策略—摩擦力扭矩>擰緊微課堂｜擰緊策略—摩擦力扭矩</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b096e432.html alt=餐飲業的共益實踐案例：是什麼留住了海底撈的員工？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3253c0fd3b54497282e5ebfb67cc350c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b096e432.html title=餐飲業的共益實踐案例：是什麼留住了海底撈的員工？>餐飲業的共益實踐案例：是什麼留住了海底撈的員工？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8ece3d8b.html alt=溼法鋅冶煉氟、氯現在走向及生產實踐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/c6ec0692-63fe-42f8-8df3-b0a6226ca1a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8ece3d8b.html title=溼法鋅冶煉氟、氯現在走向及生產實踐>溼法鋅冶煉氟、氯現在走向及生產實踐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2e9a67fa.html alt=「路橋課堂—涵洞施工」圓管涵施工技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15279000002872a0b24c46a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2e9a67fa.html title=「路橋課堂—涵洞施工」圓管涵施工技術>「路橋課堂—涵洞施工」圓管涵施工技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9b07011e.html alt="小葵花消防課堂 建築問題：電偶腐蝕" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1530519660479f8f39cf8e5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9b07011e.html title="小葵花消防課堂 建築問題：電偶腐蝕">小葵花消防課堂 建築問題：電偶腐蝕</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1eaf92bc.html alt=消防知識小課堂報警閥的組安裝 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/348e9a2dc4dc4ef9b6b992225b303428 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1eaf92bc.html title=消防知識小課堂報警閥的組安裝>消防知識小課堂報警閥的組安裝</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2d3ddfcb.html alt="技術課堂｜WEY VV5四驅旗艦版底盤解析 它的表現到底如何呢？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9a1f6545da404214b5e0b6717f5c9618 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2d3ddfcb.html title="技術課堂｜WEY VV5四驅旗艦版底盤解析 它的表現到底如何呢？">技術課堂｜WEY VV5四驅旗艦版底盤解析 它的表現到底如何呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6de0fe5c.html alt=「材料課堂」鋁鋰合金：現代飛機新型材料的選擇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5e840004ae950fff6026 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6de0fe5c.html title=「材料課堂」鋁鋰合金：現代飛機新型材料的選擇>「材料課堂」鋁鋰合金：現代飛機新型材料的選擇</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>