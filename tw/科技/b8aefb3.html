<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>使用Python中的NLTK和spaCy刪除停用詞與文本標準化 | 极客快訊</title><meta property="og:title" content="使用Python中的NLTK和spaCy刪除停用詞與文本標準化 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/372d81de857f498f8e29115b521984fa"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/b8aefb3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/b8aefb3.html><meta property="article:published_time" content="2020-10-29T21:07:50+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:50+08:00"><meta name=Keywords content><meta name=description content="使用Python中的NLTK和spaCy刪除停用詞與文本標準化"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/b8aefb3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>使用Python中的NLTK和spaCy刪除停用詞與文本標準化</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p><strong>介紹</strong></p><p>多樣化的自然語言處理(NLP)是真的很棒，我們以前從未想象過的事情現在只是幾行代碼就可做到。這真的令人開心。</p><p>但使用文本數據會帶來一系列挑戰。機器在處理原始文本方面有著較大的困難。在使用NLP技術處理文本數據之前，我們需要執行一些稱為預處理的步驟。</p><p>錯過了這些步驟，我們會得到一個不好的模型。這些是你需要在代碼，框架和項目中加入的基本NLP技術。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/372d81de857f498f8e29115b521984fa><p class=pgc-img-caption></p></div><p>我們將討論如何使用一些非常流行的NLP庫(NLTK，spaCy，Gensim和TextBlob)刪除停用詞並在Python中執行文本標準化。</p><p><strong>目錄</strong></p><ul><li>什麼是停用詞?</li><li>為什麼我們需要刪除停用詞?</li><li>我們應該何時刪除停用詞?</li><li>刪除停用詞的不同方法</li><li class=ql-indent-1>使用NLTK</li><li class=ql-indent-1>使用spaCy</li><li class=ql-indent-1>使用Gensim</li><li>文本標準化簡介</li><li>什麼是詞幹化和詞形還原?</li><li>執行詞幹化和詞形還原的方法</li><li class=ql-indent-1>使用NLTK</li><li class=ql-indent-1>使用spaCy</li><li class=ql-indent-1>使用TextBlob</li></ul><h1><strong>1. 什麼是停用詞?</strong></h1><p>在任何自然語言中停用詞是最常用的詞。為了分析文本數據和構建NLP模型，這些停用詞可能對構成文檔的意義沒有太多價值。</p><blockquote><p>通常，英語文本中使用的最常用詞是"the"，"is"，"in"，"for"，"where"，"when"，"to"，"at"等。</p></blockquote><p>考慮這個文本,"There is a pen on the table"。現在，單詞"is"，"a"，"on"和"the"在解析它時對語句沒有任何意義。而像"there"，"book"和"table"這樣的詞是關鍵詞，並告訴我們這句話是什麼意思。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/62381abf37eb4efca39d2f06e505ac18><p class=pgc-img-caption></p></div><p>一般來說在去除停用詞之前要執行分詞操作。</p><p>以下是一份停用詞列表，可能對你有用</p><blockquote><p>a about after all also always am an and any are at be been being but by came can cant come</p><p>could did didn't do does doesn't doing don't else for from get give goes going had happen</p><p>has have having how i if ill i'm in into is isn't it its i've just keep let like made make</p><p>many may me mean more most much no not now of only or our really say see some something</p><p>take tell than that the their them then they thing this to try up us use used uses very</p><p>want was way we what when where which who why will with without wont you your youre</p></blockquote><h1><strong>2. 為什麼我們需要刪除停用詞?</strong></h1><p>這是一個你必須考慮到的非常重要的問題</p><p><strong>在NLP中刪除停用詞並不是一項嚴格的規則。這取決於我們正在進行的任務</strong>。對於文本分類等(將文本分類為不同的類別)任務，從給定文本中刪除或排除停用詞，可以更多地關注定義文本含義的詞。</p><p>正如我們在上一節中看到的那樣，單詞there,book要比單詞is,on來得更加有意義。</p><p>但是，在機器翻譯和文本摘要等任務中，卻不建議刪除停用詞。</p><p>以下是刪除停用詞的幾個主要好處：</p><ul><li>在刪除停用詞時，數據集大小減小，訓練模型的時間也減少</li><li>刪除停用詞可能有助於提高性能，因為只剩下更少且唯一有意義的詞。因此，它可以提高分類準確性</li><li>甚至像Google這樣的搜索引擎也會刪除停用詞，以便從數據庫中快速地檢索數據</li></ul><h1><strong>3. 我們應該什麼時候刪除停用詞?</strong></h1><p>我把它歸納為兩個部分：刪除停用詞的情況以及當我們避免刪除停用詞的情況。</p><p><strong>刪除停用詞</strong></p><p>我們可以在執行以下任務時刪除停用詞：</p><ul><li>文本分類</li><li>垃圾郵件過濾</li><li>語言分類</li><li>體裁(Genre)分類</li><li>標題生成</li><li>自動標記(Auto-Tag)生成</li></ul><p><strong>避免刪除停用詞</strong></p><ul><li>機器翻譯</li><li>語言建模</li><li>文本摘要</li><li>問答(QA)系統</li></ul><h1><strong>4. 刪除停用詞的不同方法</strong></h1><p><strong>4.1. 使用NLTK刪除停用詞</strong></p><p>NLTK是文本預處理的自然語言工具包。這是我最喜歡的Python庫之一。<strong>NLTK有16種不同語言的停用詞列表</strong>。</p><p>你可以使用以下代碼查看NLTK中的停用詞列表：</p><pre>import nltkfrom nltk.corpus import stopwordsset(stopwords.words('english'))</pre><p>現在，要使用NLTK刪除停用詞，你可以使用以下代碼塊</p><pre># 下面的代碼是使用nltk從句子中去除停用詞# 導入包import nltkfrom nltk.corpus import stopwordsfrom nltk.tokenize import word_tokenize set(stopwords.words('english'))# 例句text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were."""# 停用詞集合stop_words = set(stopwords.words('english')) # 分詞word_tokens = word_tokenize(text) filtered_sentence = [] for w in word_tokens:  if w not in stop_words:  filtered_sentence.append(w) print("\n\nOriginal Sentence \n\n")print(" ".join(word_tokens)) print("\n\nFiltered Sentence \n\n")print(" ".join(filtered_sentence)) </pre><p>這是我們分詞後的句子：</p><pre>He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rightshad become much less valuable, and he had indeed the vaguest idea where the wood and river in question were.</pre><p>刪除停用詞後：</p><pre>He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He ready becuase rights become much less valuable, indeed vaguest idea wood river question.</pre><p>請注意，文本的大小几乎減少到一半！你能想象一下刪除停用詞的用處嗎?</p><p><strong>4.2. 使用spaCy刪除停用詞</strong></p><p>spaCy是NLP中功能最多，使用最廣泛的庫之一。我們可以使用SpaCy快速有效地從給定文本中刪除停用詞。它有一個自己的停用詞列表，可以從<strong>spacy.lang.en.stop_words</strong>類導入。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d8a046ff82cb46a9a50aa5269a63fec4><p class=pgc-img-caption></p></div><p>以下是在Python中使用spaCy刪除停用詞的方法：</p><pre>from spacy.lang.en import English# 加載英語分詞器、標記器、解析器、NER和單詞向量nlp = English()text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were."""# "nlp"對象用於創建具有語言註釋的文檔。my_doc = nlp(text)# 構建詞列表token_list = []for token in my_doc: token_list.append(token.text)from spacy.lang.en.stop_words import STOP_WORDS# 去除停用詞後創建單詞列表filtered_sentence =[] for word in token_list: lexeme = nlp.vocab[word] if lexeme.is_stop == False: filtered_sentence.append(word) print(token_list)print(filtered_sentence) </pre><p>這是我們在分詞後獲得的列表：</p><pre>He determined to drop his litigation with the monastry and relinguish his claims to the wood-cuting and \n fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n indeed the vaguest idea where the wood and river in question were.</pre><p>刪除停用詞後的列表：</p><pre>determined drop litigation monastry, relinguish claims wood-cuting \n fishery rihgts. readybecuase rights become valuable, \n vaguest idea wood river question</pre><p>需要注意的一點是，去除停用詞並不會刪除標點符號或換行符，我們需要手動刪除它們。</p><p><strong>4.3. 使用Gensim刪除停用詞</strong></p><p>Gensim是一個非常方便的庫，可以處理NLP任務。在預處理時，gensim也提供了去除停用詞的方法。我們可以從類<strong>gensim.parsing.preprocessing</strong>輕鬆導入<strong>remove_stopwords</strong>方法。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/61f8459276884a9aaca758ce110f6436><p class=pgc-img-caption></p></div><p>嘗試使用Gensim去除停用詞：</p><pre># 以下代碼使用Gensim去除停用詞from gensim.parsing.preprocessing import remove_stopwords# pass the sentence in the remove_stopwords functionresult = remove_stopwords("""He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were.""")print('\n\n Filtered Sentence \n\n')print(result) He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts once.He ready becuase rights valuable, vaguest idea wood river question were.</pre><p><strong>使用gensim去除停用詞時，我們可以直接在原始文本上進行</strong>。在刪除停用詞之前無需執行分詞。這可以節省我們很多時間。</p><h1><strong>5. 文本標準化(text normalization)簡介</strong></h1><p>在任何自然語言中，根據情況，可以以多種形式書寫或說出單詞。這就是語言的精美之處。例如：</p><ul><li>Lisa <strong>ate</strong> the food and washed the dishes.</li><li>They were <strong>eating</strong> noodles at a cafe.</li><li>Don’t you want to <strong>eat</strong> before we leave?</li><li>We have just <strong>eaten</strong> our breakfast.</li><li>It also <strong>eats</strong> fruit and vegetables.</li></ul><p>在所有這些句子中，我們可以看到"eat"這個詞有多種形式。對我們來說，很容易理解"eat"就是這裡具體的活動。所以對我們來說，無論是'eat'，'ate'還是'eaten'都沒關係,因為我們知道發生了什麼。</p><p>不幸的是，機器並非如此。他們區別對待這些詞。因此，我們需要將它們標準化為它們的根詞，在我們的例子中是"eat"。</p><p>因此，文本標準化是將單詞轉換為單個規範形式的過程。這可以通過兩個過程來實現，即<strong>詞幹化(stemming)</strong>和<strong>詞形還原(lemmatization)</strong>。讓我們詳細瞭解它們的含義。</p><h1><strong>6. 什麼是詞幹化和詞形還原?</strong></h1><blockquote><p>詞幹化和詞形還原只是單詞的標準化，這意味著將單詞縮減為其根形式。</p></blockquote><p>在大多數自然語言中，根詞可以有許多變體。例如，"play"一詞可以用作"playing"，"played"，"plays"等。你可以想到類似的例子(並且有很多)。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/35ead0982c7c48af951987ee1db22896><p class=pgc-img-caption></p></div><p><strong>詞幹化</strong></p><p>讓我們先了解詞幹化：</p><ul><li>詞幹化是一種文本標準化技術，它通過考慮可以在該詞中找到的公共前綴或後綴列表來切斷單詞的結尾或開頭。</li><li>這是一個基於規則的基本過程，從單詞中刪除後綴("ing"，"ly"，"es"，"s"等)</li></ul><p><strong>　詞形還原</strong></p><p>另一方面，詞形還原是一種結構化的程序，用於獲得單詞的根形式。它利用了詞彙(詞彙的字典重要性程度)和形態分析(詞彙結構和語法關係)。</p><p><strong>為什麼我們需要執行詞幹化或詞形還原?</strong></p><p>讓我們考慮以下兩句話：</p><ul><li><strong>He was driving</strong></li><li><strong>He went for a drive</strong></li></ul><p>我們可以很容易地說兩句話都傳達了相同的含義，即過去的駕駛活動。機器將以不同的方式處理兩個句子。因此，為了使文本可以理解，我們需要執行詞幹化或詞形還原。</p><p>文本標準化的另一個好處是它減少了文本數據中詞典的大小。這有助於縮短機器學習模型的訓練時間。</p><p><strong>我們應該選擇哪一個?</strong></p><p><strong>詞幹化</strong>算法通過從詞中剪切後綴或前綴來工作。<strong>詞形還原</strong>是一種更強大的操作，因為它考慮了詞的形態分析。</p><p>詞形還原返回詞根，詞根是其所有變形形式的根詞。</p><p>我們可以說詞幹化是一種快速但不那麼好的方法，可以將詞語切割成詞根形式，而另一方面，詞形還原是一種智能操作，它使用由深入的語言知識創建的詞典。<strong>因此，詞形還原有助於形成更好的效果。</strong></p><h1><strong>7. 執行文本標準化的方法</strong></h1><p><strong>7.1. 使用NLTK進行文本標準化</strong></p><p>NLTK庫有許多令人驚奇的方法來執行不同的數據預處理步驟。有些方法如PorterStemmer()和WordNetLemmatizer()分別執行詞幹化和詞形還原。</p><p>讓我們看看他們的實際效果。</p><p><strong>詞幹化</strong></p><pre>from nltk.corpus import stopwordsfrom nltk.tokenize import word_tokenize from nltk.stem import PorterStemmerset(stopwords.words('english'))text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were."""stop_words = set(stopwords.words('english')) word_tokens = word_tokenize(text) filtered_sentence = [] for w in word_tokens:  if w not in stop_words:  filtered_sentence.append(w) Stem_words = []ps =PorterStemmer()for w in filtered_sentence: rootWord=ps.stem(w) Stem_words.append(rootWord)print(filtered_sentence)print(Stem_words)He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He ready becuase rights become much less valuable, indeed vaguest idea wood river question.He determin drop litig monastri, relinguish claim wood-cut fisheri rihgt. He readi becuasright become much less valuabl, inde vaguest idea wood river question.</pre><p>我們在這裡就可以很清晰看到不同點了，我們繼續對這段文本執行詞形還原</p><p><strong>詞形還原</strong></p><pre>from nltk.corpus import stopwordsfrom nltk.tokenize import word_tokenize import nltkfrom nltk.stem import WordNetLemmatizerset(stopwords.words('english'))text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were."""stop_words = set(stopwords.words('english')) word_tokens = word_tokenize(text) filtered_sentence = [] for w in word_tokens:  if w not in stop_words:  filtered_sentence.append(w) print(filtered_sentence) lemma_word = []import nltkfrom nltk.stem import WordNetLemmatizerwordnet_lemmatizer = WordNetLemmatizer()for w in filtered_sentence: word1 = wordnet_lemmatizer.lemmatize(w, pos = "n") word2 = wordnet_lemmatizer.lemmatize(word1, pos = "v") word3 = wordnet_lemmatizer.lemmatize(word2, pos = ("a")) lemma_word.append(word3)print(lemma_word)He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He ready becuase rights become much less valuable, indeed vaguest idea wood river question.He determined drop litigation monastry, relinguish claim wood-cuting fishery rihgts. He ready becuase right become much le valuable, indeed vaguest idea wood river question.</pre><blockquote><p>在這裡，<strong>v</strong>表示<strong>動詞</strong>，<strong>a</strong>代表<strong>形容詞</strong>和<strong>n</strong>代表<strong>名詞</strong>。該詞根提取器(lemmatizer)僅與lemmatize方法的<strong>pos</strong>參數匹配的詞語進行詞形還原。</p></blockquote><p>詞形還原基於詞性標註(POS標記)完成。</p><p><strong>7.2. 使用spaCy進行文本標準化</strong></p><p>正如我們之前看到的，spaCy是一個優秀的NLP庫。它提供了許多工業級方法來執行詞形還原。不幸的是，spaCy沒有用於詞幹化(stemming)的方法。要執行詞形還原，請查看以下代碼：</p><pre>#確保使用"python -m spacy download en"下載英語模型import en_core_web_smnlp = en_core_web_sm.load()doc = nlp(u"""He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were.""")lemma_word1 = [] for token in doc: lemma_word1.append(token.lemma_)lemma_word1-PRON- determine to drop -PRON- litigation with the monastry, and relinguish -PRON- claimto the wood-cuting and \n fishery rihgts at once. -PRON- be the more ready to do this becuase the right have become much less valuable, and -PRON- have \n indeed the vague ideawhere the wood and river in question be.</pre><p>這裡-PRON-是代詞的符號，可以使用正則表達式輕鬆刪除。<strong>spaCy的好處是我們不必傳遞任何pos參數來執行詞形還原。</strong></p><p><strong>7.3. 使用TextBlob進行文本標準化</strong></p><p>TextBlob是一個專門用於預處理文本數據的Python庫。<strong>它基於NLTK庫</strong>。我們可以使用TextBlob來執行詞形還原。但是，TextBlob中沒有用於詞幹化的模塊。</p><div class=pgc-img><img alt=使用Python中的NLTK和spaCy刪除停用詞與文本標準化 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3f820ab528294a808e14a9f82cb3604d><p class=pgc-img-caption></p></div><p>那麼讓我們看看如何在Python中使用TextBlob執行詞形還原：</p><pre># from textblob lib import Word method from textblob import Word text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were."""lem = []for i in text.split(): word1 = Word(i).lemmatize("n") word2 = Word(word1).lemmatize("v") word3 = Word(word2).lemmatize("a") lem.append(Word(word3).lemmatize())print(lem)He determine to drop his litigation with the monastry, and relinguish his claim to the wood-cuting and fishery rihgts at once. He wa the more ready to do this becuase the righthave become much le valuable, and he have indeed the vague idea where the wood and riverin question were.</pre><p>就像我們在NLTK小節中看到的那樣，TextBlob也使用POS標記來執行詞形還原。</p><h1><strong>8. 結束</strong></h1><p>停用詞在情緒分析，問答系統等問題中反而起著重要作用。這就是為什麼刪除停用詞可能會嚴重影響我們模型的準確性。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Python</a></li><li><a>NLTK</a></li><li><a>spaCy</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/91eece92.html alt="只需 45 秒，Python 給故宮畫一組手繪圖！" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/df1bd890ffee4a439e9f5142ae42c102 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91eece92.html title="只需 45 秒，Python 給故宮畫一組手繪圖！">只需 45 秒，Python 給故宮畫一組手繪圖！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8aab963e.html alt=Python手繪圖瞭解一下！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/746c9e6e214b48b2a0215fc9e151cdc8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8aab963e.html title=Python手繪圖瞭解一下！>Python手繪圖瞭解一下！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfd854c6.html alt=故宮下雪了！我用Python給它畫了一組手繪圖，僅用45秒（附代碼） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/774d2f0a372f48c589ec84dd3a164dd9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfd854c6.html title=故宮下雪了！我用Python給它畫了一組手繪圖，僅用45秒（附代碼）>故宮下雪了！我用Python給它畫了一組手繪圖，僅用45秒（附代碼）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b433c17e.html alt="四十、Python模塊random: 偽隨機數據生成與隨機元素抽取" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/25f231d6-c1ce-4cf8-8988-5da509a0c26a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b433c17e.html title="四十、Python模塊random: 偽隨機數據生成與隨機元素抽取">四十、Python模塊random: 偽隨機數據生成與隨機元素抽取</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/04486eba.html alt=Python爬蟲使用selenium爬取群成員信息（全自動實現自動登陸） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/e11e69f643584941aaa2b71ee6ed3d7f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/04486eba.html title=Python爬蟲使用selenium爬取群成員信息（全自動實現自動登陸）>Python爬蟲使用selenium爬取群成員信息（全自動實現自動登陸）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/86b46e6d.html alt=Python爬蟲教程，利用Python採集QQ群成員信息 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6d6cce76ad48405c9dbb960d4617bcef style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/86b46e6d.html title=Python爬蟲教程，利用Python採集QQ群成員信息>Python爬蟲教程，利用Python採集QQ群成員信息</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html alt=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5d4a0000046e1bea8b90 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7739dc7a.html title=Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？>Python數據可視化Matplotlib，如何在一副圖像中顯示多組柱形圖？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/05b8f164.html alt=Python中的多進程 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/49dd44b999924b69bd3396709ecacaf4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/05b8f164.html title=Python中的多進程>Python中的多進程</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/389d4437.html alt="Python常用算法學習(5) 樹二叉樹（原理+代碼）-最全總結" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d3d5fd4ef98c4a8e8dc9095eeef052a6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/389d4437.html title="Python常用算法學習(5) 樹二叉樹（原理+代碼）-最全總結">Python常用算法學習(5) 樹二叉樹（原理+代碼）-最全總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0fa274c2.html alt="七十九、Python | Leetcode 二叉樹系列（上篇）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a6c9fa6432a3419a8a60bd334f978a11 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0fa274c2.html title="七十九、Python | Leetcode 二叉樹系列（上篇）">七十九、Python | Leetcode 二叉樹系列（上篇）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f0a927d6.html alt=Python中如何定義只讀屬性？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/60dafb43-a3bb-4456-9f60-3d55ab9e1c4e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f0a927d6.html title=Python中如何定義只讀屬性？>Python中如何定義只讀屬性？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/68f62be6.html alt=Python文件讀寫方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/dca556bb2ffb4013b992ebb4b6a9a296 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/68f62be6.html title=Python文件讀寫方法>Python文件讀寫方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4d9fe5d5.html alt=Python開發常見問題彙總 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1525506011510ee699a3e91 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4d9fe5d5.html title=Python開發常見問題彙總>Python開發常見問題彙總</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7dad731d.html alt=對於新手來說，Python中有哪些難以理解的概念？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f4ec4c3a6484cf58453023c44e01d75 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7dad731d.html title=對於新手來說，Python中有哪些難以理解的概念？>對於新手來說，Python中有哪些難以理解的概念？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ab8f2e4e.html alt=整數溢出是怎麼回事？Python和Numpy的整數為何不一樣？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d700b7792dc04a3c9b39679d104469d8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ab8f2e4e.html title=整數溢出是怎麼回事？Python和Numpy的整數為何不一樣？>整數溢出是怎麼回事？Python和Numpy的整數為何不一樣？</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>