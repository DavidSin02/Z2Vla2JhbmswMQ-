<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>人工智能時代，機器人真的能在對話中識別人的意圖嘛？ | 极客快訊</title><meta property="og:title" content="人工智能時代，機器人真的能在對話中識別人的意圖嘛？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/7804be8632614272aab014f77d8f40a9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/bc93016e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/bc93016e.html><meta property="article:published_time" content="2020-11-14T21:08:19+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:19+08:00"><meta name=Keywords content><meta name=description content="人工智能時代，機器人真的能在對話中識別人的意圖嘛？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/bc93016e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>人工智能時代，機器人真的能在對話中識別人的意圖嘛？</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote><p>口語理解是人機對話系統的重要組成部分，而意圖識別是口語理解中的一個子任務，而且至關重要。意圖識別的準確性直接關係到語義槽填充的性能並且有助於後續對話系統的研究。考慮到人機對話系統中意圖識別的困難，傳統的機器學習方法無法理解用戶話語的深層語義信息，主要對近些年應用在意圖識別研究方面的深度學習方法進行分析、比較和總結，進一步思考如何將深度學習模型應用到多意圖識別任務中，從而推動基於深度神經網絡的多意圖識別方法的研究。</p></blockquote><p><strong>1 引言</strong></p><p class=ql-align-justify>隨著人工智能時代的到來，越來越多的智能產品已被廣泛應用到日常生活中，如情感陪護機器人、私人手機助理Siri、語音助手Google Now和Cortana、微軟亞洲研究院推出的智能聊天機器人小冰以及百度公司推出的小度機器人等。這些智能對話系統不僅可以和用戶進行正常的信息交流，而且能為用戶的生活帶來很多方便。對話系統主要由語音識別（Automatic Speech Recognition，ASR）、口語理解（Spoken Language Understanding，SLU）、對話管理（Dialog Management，DM）、對話生成（Dialogue Generation，DG）和語音合成（Text to Speech，TTS）這五部分組成[1]，如圖1 所示。為了讓機器更好地理解用戶的表達，進而為用戶反饋正確信息，口語理解起著及其重要的作用。而意圖識別（Intent Detection，ID）作為口語理解的子模塊，也是人機對話系統構成的關鍵。傳統的口語理解主要分為兩個子任務——意圖識別和語義槽填充。因為早期的研究受應用場景、數據以及計算能力的約束，多數的口語理解限定在某些領域中。但是伴隨著技術革新以及多領域對話系統的出現，現今的口語理解時常被分解為三個任務——領域識別、意圖識別和語義槽填充[2]。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7804be8632614272aab014f77d8f40a9><p class=pgc-img-caption></p></div><p class=ql-align-center>圖1 對話系統示意圖</p><p class=ql-align-justify>在對話系統中，意圖識別至關重要。所謂意圖就是用戶的意願，即用戶想要做什麼。意圖有時也被稱為“對話行為”（Dialog Act）[3]，即用戶在對話中共享的信息狀態或上下文變化並不斷更新的行為。意圖一般以“動詞+名詞”命名，如查詢天氣、預訂酒店等。而意圖識別又稱為意圖分類，即根據用戶話語所涉及到的領域和意圖將其分類到先前定義好的意圖類別中[4]。</p><p class=ql-align-justify>隨著人機對話系統的廣泛運用，用戶在不同的場合下可能會有不同意圖，因而會涉及人機對話系統中的多個領域，其中包括任務型垂直領域和閒聊等。任務型垂直領域的意圖文本具有主題鮮明，易於檢索的特點，比如，查詢機票、天氣、酒店等。而聊天類意圖文本一般具有主題不明確，語義寬泛、語句簡短等特點，注重在開放域上與人類進行交流。在對話系統中只有明確了用戶的話題領域，才能正確分析用戶的具體需求，否則會造成後面意圖的錯誤識別。圖2 是口語理解中三個任務應用的實例圖，當用戶輸入一個詢問，首先需要明確用戶輸入的文本所屬的話題領域為“火車”還是“航班”，由於意圖的類別比話題領域的粒度更細，因此需要根據用戶的具體語義信息確定用戶的意圖是訂票、退票還是查詢時間，而語義槽的填充也有助於用戶意圖的判斷。所以在人機對話系統的意圖識別模塊中，首先要對用戶話題領域進行識別，接著明確用戶的具體意圖需求，最終表示成語義框架的形式。</p><p><strong>2 意圖識別的難點</strong></p><p><strong>2.1 數據來源匱乏</strong></p><p class=ql-align-justify>隨著人工智能技術的不斷髮展，大型互聯網公司推出聊天機器人，由於用戶體驗性較低，大多數研究者難以獲取到用戶與機器人之間的聊天文本，因而導致需要研究的對話文本數量有限，這成為意圖識別任務面臨的重大問題[5]。在實際的意圖識別過程中，帶標註的意圖文本特別少，獲取也十分困難，這也給意圖識別的研究和發展帶來了挑戰[6]。</p><p><strong>2.2 用戶表達的不規範性</strong></p><p class=ql-align-justify>在聊天系統中，用戶的意圖表達文本一般具有表達口語化、語句簡短、內容寬泛等特點，這就使得意圖識別較為困難。例如，“我想找個吃飯的地方”，這種口語化的日常用語表達對應的意圖則是“找餐館”，所以意圖文本的口語化使得領域主題不明確，不利於用戶意圖的識別。對於“漢庭”這種語義不豐富的意圖表達方式，雖然“漢庭”常常與“酒店”搭配出現，但讓機器識別出用戶的話題領域為“酒店”，則是一項非常困難的任務。對於“我想訂票”這種意圖表達方式而言，訂票有可能是訂機票、訂火車票、訂汽車票等。由於用戶的意圖表達內容太籠統，導致機器不能及時為用戶反饋結果。</p><p><strong>2.3 意圖的隱含性</strong></p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/2e31737f66d54aa3b1fa9614fffbb813><p class=pgc-img-caption></p></div><p class=ql-align-center>圖2 意圖識別實例圖</p><p class=ql-align-justify>隨著人機對話系統應用範圍的不斷擴大，意圖的表達方式也越來越多。有些意圖表達很明確，而有些意圖表達卻蘊含有更深層的意思。因此意圖按照表達種類可以分為顯式意圖和隱式意圖[7]，顯式意圖指用戶通過文本形式，明確指出自己的意圖需求，包含話題領域、意圖類別等內容。隱式意圖指用戶沒有明確自己的意圖需求，需要通過分析用戶的潛在意圖，來推理用戶的真實意圖[8]，用戶常用的意圖表達文本如表1所示。</p><p class=ql-align-center>表1 用戶常用的意圖表達</p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e83d63aa622f4f6ba02861a3600521cf><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>從表1的三個例子可以看出，每個例子的兩種文本表達方式截然不同，但具有相同的意圖。例1的顯式意圖文本明確用戶需要訂機票，而隱式意圖文本雖然沒有相關的領域信息，通過推測，用戶可能需要訂去北京的機票。例2的顯式意圖文本表明用戶想要預定酒店，隱式意圖文本沒有直接明確意圖需求，通過推測表明用戶需要預訂深圳的酒店。例3 的顯式意圖文本明確用戶具有消費意圖，而隱式意圖文本沒有直接說明購買意圖，但是通過分析，表明用戶具有潛在的消費意圖。所以沒有明確話題領域和類別信息的隱式意圖識別也成為意圖識別中的一大難點。</p><p><strong>2.4 意圖的多樣性</strong></p><p class=ql-align-justify>用戶表達的一句話中有時不是僅含有一種意圖，而是含有多種意圖。如：“我想預訂一張從呼和浩特到上海的機票，並預訂當天上海外灘周圍的酒店一晚”，這句話同時包含訂機票和預定酒店兩種意圖。在用戶表達的一句話中同時識別出兩種甚至多種意圖的問題成為多意圖識別問題。多意圖識別類似於多標籤（Multi-Label，ML）分類，但又不同於多標籤分類，多標籤分類通常處理的是長文本，而多意圖識別主要針對短文本進行處理。如何在較短的文本內識別出用戶的多種意圖則是意圖識別的又一個難點。在多意圖識別過程中，首先需要分析用戶意圖文本是否包含多種意圖，如果用戶意圖文本包含多種意圖，如何準確識別用戶的多種意圖是值得去思考的問題。</p><p><strong>3 傳統的意圖識別方法</strong></p><p class=ql-align-justify>近年來，意圖識別成為學術界和工業界新的研究熱點，為了正確理解人機對話系統中的用戶意圖，大部分學者將意圖識別看作是一種語義話語分類（Semantic Utterance Classification，SUC）問題[9]。傳統的意圖識別方法主要有基於規則（Rule-Based）模板的語義識別方法[10]和使用統計特徵的分類算法[11-12]。</p><p><strong>3.1 單意圖識別方法</strong></p><p class=ql-align-justify><strong>3.1.1 基於規則模板的意圖識別方法</strong></p><p class=ql-align-justify>基於規則模板的意圖識別方法一般需要人為構建規則模板以及類別信息對用戶意圖文本進行分類[13]。Ramanand 等人[14]針對消費意圖識別，提出基於規則和圖的方法來獲取意圖模板，在單一領域取得了較好的分類效果。Li等人[15]研究發現在同一領域下，不同的表達方式會導致規則模板數量的增加，需要耗費大量的人力物力。所以，基於規則模板匹配的方法雖然不需要大量的訓練數據，就可以保證識別的準確性，但是卻無法解決意圖文本更換類別時帶來重新構造模板的高成本問題。</p><p class=ql-align-justify><strong>3.1.2 基於統計特徵分類的意圖識別方法</strong></p><p class=ql-align-justify>基於統計特徵分類的方法，則需要對語料文本進行關鍵特徵的提取，如字、詞特徵、N-Gram等，然後通過訓練分類器實現意圖分類。常用的方法有樸素貝葉斯（Naive Bayes，NB）[16]、Adaboost[17]、支持向量機（Support Vector Machine，SVM）[18]和邏輯迴歸[19]等。</p><p class=ql-align-justify>陳浩辰[20]分別使用SVM 和Naive Bayes 分類器對微博語料進行消費意圖分類，F1值都達到70%以上，但這兩種分類器都需要人工提取特徵，不僅成本高，而且特徵的準確性無法得到保障，同時還會導致數據稀疏問題。由於SVM對多類別數據信息的分類效果不好而且泛化性能較差，賈俊華[21]通過引入AdaBoost算法和PSO算法，利用PSO 優化SVM 參數，並且用AdaBoost 算法集成PSOSVM 分類器，得到一種AdaBoost-PSOSVM 強分類器，在相同數據集上分類性能明顯高於SVM 分類器。但這些方法都不能準確理解用戶文本的深層次語義信息。</p><p><strong>3.2 多意圖識別方法</strong></p><p class=ql-align-justify>對於多意圖識別任務，Kim等人[22]提出一種基於單意圖標記訓練數據的多意圖識別系統。他將句子看作三種類型，單意圖語句、帶連詞的多意圖語句和不帶連詞的多意圖語句，然後採用兩階段法實現多意圖識別，如圖3 所示。該研究將用戶意圖文本含有的意圖數量最多限制為兩種，如果第一階段識別出的意圖少於兩種，則執行第二階段，如果第二階段識別出的意圖同樣少於兩種，則進行單意圖識別。第一階段，該系統根據輸入句子中的連詞生成多意圖假設集合H，其中一個多意圖假設h ∈H，可以表示為＜hleft,hconj,hright ＞，hleft表示連詞左側的子句，hconj 表示連接詞，hright 表示連詞右側的子句。然後採用最大熵模型[23]對假設進行評估，選取滿足特定條件的最優假設。第二階段，系統對輸入的句子進行順序標註和意圖標記，採用線性鏈條件隨機場（Conditional Random Fields，CRF）分類器[24]進行意圖識別。實驗結果表明採用兩階段法實現多意圖識別性能優於單階段方法。該方法在多意圖識別任務上取得了不錯的進展。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/16d6161a86004ce7bf3501773de59df6><p class=pgc-img-caption></p></div><p class=ql-align-center>圖3 多意圖識別流程圖</p><p><strong>4 基於深度學習的意圖識別方法</strong></p><p class=ql-align-justify>隨著深度學習的不斷髮展，越來越多的學者們將詞向量、卷積神經網絡（Convolutional Neural Networks，CNN）、循環神經網絡（Recurrent Neural Network，RNN）和其變體長短時記憶（Long Short-Term Memory，LSTM）網絡、門控循環單元（Gated Recurrent Unit，GRU）、注意力機制和膠囊網絡應用於意圖識別任務中，相比於傳統的機器學習方法，深度學習模型在識別性能上有了很大的提升。</p><p><strong>4.1 單意圖識別方法</strong></p><p class=ql-align-justify><strong>4.1.1 基於詞向量的意圖識別</strong></p><p class=ql-align-justify>近年來，在自然語言處理過程中，由於使用原始詞法特徵會導致數據稀疏問題，詞向量逐漸被用於語義分析任務中，而且連續表示學習可以解決數據稀疏問題[25]。Kim 等人[26]將詞向量作為詞法特徵進行意圖分類，與傳統的詞袋模型相比，基於詞向量的意圖分類方法對不同分類內容的表徵能力和領域可擴展性更好。</p><p class=ql-align-justify>考慮到詞向量的語義信息不全等問題，Kim等人[27]利用語義詞彙字典（如WordNet[28]和Paraphrase Database（PPDB）[29]）的信息來豐富詞向量，從而提高意圖文本的語義表示，通過構建BLSTM（Bidirectional Long Short-Term Memory）模型進行意圖識別。在航空旅行信息系統（Air Travel Information System，ATIS）數據集和來自Microsoft Cortana 的關於地點的真實日誌數據集上驗證，表明豐富的語義詞彙向量可以提高意圖的識別性能。而且對於規模較小的訓練集採用複雜的深度學習模型，提供豐富的詞向量會對模型性能有一定的幫助。所以詞向量的研究會對深度學習模型的運用起到至關重要的作用。</p><p class=ql-align-justify><strong>4.1.2 基於卷積神經網絡的意圖識別</strong></p><p class=ql-align-justify>CNN最初被用於圖像處理[30]，隨著詞向量技術的出現，CNN 被廣泛應用於自然語言處理領域[31]，並且取得了很好的研究成果。Kim[32]等人嘗試將CNN 用於文本分類任務中，並取得了十分理想的效果。基於此，Hashemi 等人[33]採用CNN 提取文本向量表示作為查詢分類特徵來識別用戶搜索查詢的意圖，與傳統的人工特徵提取方法相比，不僅減少了大量的特徵工程，而且可以得到更深層次的特徵表示。但是CNN只能提取到意圖文本的局部語義特徵，不能保持語義的連貫性。</p><p class=ql-align-justify><strong>4.1.3 基於循環神經網絡及其變體的意圖識別</strong></p><p class=ql-align-justify>RNN不同於CNN，它表示的是一個詞序列，而且可以根據上下文學習詞序語義信息。Bhargava[34]將上下文信息納入意圖識別任務中降低了意圖識別的錯誤率，說明上下文信息有助於意圖的識別。一個簡單的RNN存在梯度爆炸或梯度消失等問題，不能很好地模擬長期依賴關係。</p><p class=ql-align-justify>而序列建模最流行的網絡LSTM[35]通過在RNN 結構中引入一個內存單元來解決這個問題，同時它可以控制要保留和遺忘的信息。該模型也常被用於解決意圖識別問題，Ravuri等人[36]提出用RNN和LSTM兩種模型來解決意圖分類問題，將兩種模型分別在ATIS 數據集上進行實驗，結果表明LSTM模型的意圖識別錯誤率比RNN 低1.48%。主要是因為LSTM 對文本的時序關係具有良好的建模能力，而且對輸入較長的文本具有很好的記憶功能。</p><p class=ql-align-justify>GRU 是LSTM 模型的一種改進[37-38]，具有在長序列上保留信息的能力，而且可以學習上下文語義信息。它和LSTM 在 大 部 分 實 驗 中 都 優 於RNN[36，39]，相 比 於LSTM，GRU只使用兩個門即重置門（reset gate）和更新門（update gate），模型結構更簡單，含有的參數更少，需要的文本語料更少[38]。而雙向門控循環單元（Bidirectional Gated Recurrent Unit，BGRU）可以充分考慮上下文語義信息從而對意圖文本進行更好的特徵表示，通常將隱藏狀態的最終輸出作為意圖文本表示，從而得到意圖類別結果。</p><p class=ql-align-justify>針對意圖識別任務，Ravuri 等人[39]又採用圖4 所示的GRU 和LSTM 在ATIS 和Cortana 數據集上進行全面比較。實驗表明GRU和LSTM模型在意圖分類任務上的性能幾乎一樣，但是GRU的參數更少，模型更簡單。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/7b9fbd48f3b743e090ef2c1d2cc2fb09><p class=pgc-img-caption></p></div><p class=ql-align-center>圖4 LSTM和GRU模型用於意圖分類</p><p class=ql-align-justify><strong>4.1.4 深度學習模型的組合運用於意圖識別</strong></p><p class=ql-align-justify>考慮到各種深度學習模型的優缺點，大部分研究者將具有不同優勢的深度學習模型進行組合對用戶意圖進行分類。錢嶽[8]利用CNN 可以更深層次地提取意圖文本特徵以及LSTM 可以對文本的時序關係建模的優點，提出基於Convolutional-LSTM的出行消費意圖識別模型，並且取得了很好的性能。餘慧等人[40]針對短文本會導致數據稀疏的問題，提出了基於短文本主題模型（Biterm Topic Model，BTM）和BGRU 的多輪對話意圖識別模型，該混合模型在用戶就醫意圖識別上取得了很好的效果，而且優於文獻[8]的性能。黃佳偉[41]提出了Character-CNN-BGRU 深度學習組合模型，該組合模型利用基於字符的方法不僅使得所用詞表範圍更小而且可以解決未登錄詞問題的優勢，再結合CNN 可以提取到意圖文本的深層局部特徵以及BGRU 可以保證文本的時序關係對意圖識別任務進行建模，突出組合模型在意圖識別任務上的優勢。但是組合模型結構複雜，訓練時間較長，如何簡化組合模型是值得人們思考的問題。</p><p class=ql-align-justify><strong>4.1.5 基於BLSTM的自注意力模型的意圖識別</strong></p><p class=ql-align-justify>詞向量已經被廣泛應用於自然語言處理領域中，隨著深度學習模型的發展，出現了各種句子級別向量的表示，如：使用CNN中的最大池化（max-pooling）或平均池化（mean-pooling）得到句子向量，使用RNN的隱藏狀態或最終隱藏狀態創建句子表示等。Lin等人[42]提出了一種通過引入自注意力（self-attention）機制提取句子表示的模型改進原有方法，通過二維矩陣來表示句子向量，將句子的不同語義信息用多個向量進行表示。該模型在BLSTM 上執行，通過對BLSTM 的隱層狀態加權求和得到句子向量表示，從而實現意圖分類。該模型通過自注意力機制可以獲取到句子的多種語義信息，有助於多意圖識別的研究。</p><p class=ql-align-justify>圖5 為自注意力模型圖，如圖5（a）所示，假設輸入序列為S=(w1,w2,…,wn)∈Rn×d，將S 輸入到BLSTM中，得到第t 個單詞的前後項隱藏狀態計算如下：</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/98541996764d4bf897ae086729ec7e65><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>如果LSTM的隱藏單元數為k，將前後項隱藏狀態連接得到ht，且ht∈R2k，則輸入的意圖文本可以用H ∈Rn×2k 表示所有隱藏狀態ht 的集合，即H=(h1,h2,…,hn)。</p><p class=ql-align-justify>將自注意力權重矩陣表示為：</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ab02319d112b49d39136a177a2a2cd03><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>如圖5（b）所示，Ws1 ∈Rm×2k 和Ws2 ∈R1×m 為自注意力權重矩陣，m 為自注意力的隱藏單元數，是一個超參數，可以任意設置，H T ∈R2k×n 為H 的轉置矩陣。通過計算可以得到a ∈R1×n。所以意圖文本向量可以表示為：d=a ⋅H，則d ∈R1×2k。</p><p class=ql-align-justify>如果從意圖文本中提取r 個語義特徵，則需要r 個自注意力頭部進行語義特徵提取，則Ws2 ∈Rr×m，得到A ∈Rr×n，最終的意圖文本向量可以表示為：D=A ⋅H，則D ∈Rr×2k。</p><p class=ql-align-justify><strong>4.1.6 膠囊網絡模型用於意圖識別</strong></p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/56c66a11e6f14e1ab5e5a316edf163c7><p class=pgc-img-caption></p></div><p class=ql-align-center>圖5 基於BLSTM的自注意力模型圖</p><p class=ql-align-justify>“膠囊”的概念最先由Hinton等人[43]提出，用來解決CNN 的表徵侷限性，一個膠囊包含一組神經元的向量表示，向量的方向表示實體屬性，向量的長度表示實體存在的概率。Sabour等人[44]提出了膠囊網絡，將CNN的標量輸出特徵檢測器用矢量輸出膠囊代替，並且通過協議路由代替最大池化。相比於原來的CNN，膠囊網絡會保持實體在區域內的準確位置信息。因此，Zhao 等人[45]首次將膠囊網絡用於文本分類任務，提出三種動態路由策略來提高動態路由過程的性能，以減輕噪聲（停用詞和與類別無關的詞）膠囊的干擾。在標準數據集上的實驗，表明膠囊網絡在文本分類任務上具有很好的性能，同時在多標籤文本分類任務上也表現出很好的效果。</p><p class=ql-align-justify>在意圖識別任務上，Xia 等人[46]提出了一個基於膠囊網絡的意圖膠囊模型，該模型利用膠囊模型在文本建模中的優勢對文本進行分層建模，如圖6 所示，首先採用文獻[42]的方法對意圖文本提取具有自注意力的語義特徵，即語義向量。由於不同用戶對同一種意圖的表達方式不同，但對一種意圖的貢獻大於其他意圖，通過採用動態路由機制動態分配每種語義的適當貢獻度將其聚合形成更高級別的預測向量，即意圖語義表示，從而進行意圖分類。該模型在意圖識別任務上取得了不錯的效果。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/98de1aba2393483aa05895d27c57590f><p class=pgc-img-caption></p></div><p class=ql-align-center>圖6 基於意圖膠囊的意圖識別過程圖</p><p class=ql-align-justify><strong>4.1.7 聯合識別的方法用於意圖識別</strong></p><p class=ql-align-justify>隨著意圖識別方法的不斷研究與改進，考慮單一任務研究因其獨立的模型而容易出現錯誤傳播，有些學者提出了語義槽填充和意圖識別的聯合模型。李豔玲等人[47]通過三角鏈條件隨機場對意圖識別和語義槽填充進行聯合建模，與將語義槽填充結果作為意圖識別特徵的級聯模型相比，聯合模型在意圖識別任務上表現出很好的性能，突出了兩者之間的關聯性。Liu 等人[48]通過在雙向循環神經網絡的隱層上增加注意力機制來捕捉句子的重要語義成分，從而提高意圖識別的準確率，在ATIS數據集上驗證基於注意力機制的雙向循環神經網絡模型的意圖識別錯誤率為2.35%。研究者通過將語義槽填充與意圖識別聯合實驗，在相同數據集上驗證，意圖識別的錯誤率降到1.79%。可見，語義槽填充有助於意圖識別。</p><p><strong>4.2 多意圖識別方法</strong></p><p class=ql-align-justify>針對多意圖識別，楊春妮等人[49]將用戶意圖文本進行依存句法分析確定是否包含多意圖，利用詞頻-逆文檔頻率（TF-IDF）和訓練好的詞向量計算矩陣距離來確定句子的意圖數量，通過將句法特徵和CNN 結合進行意圖分類，最終判別用戶的多種意圖。該方法在10 種類別的多意圖識別任務中取得了不錯的效果。到目前為止，基於深度神經網絡的多意圖識別研究較少，所以這是值得研究的一個方向。</p><h1>最後</h1><div class=pgc-img><img alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b95c16e6fb8349129e2a2ee658b842da><p class=pgc-img-caption></p></div><p>前幾天有私信小編要Python的學習資料，小編整理了一些有深度的Python教程和參考資料，從入門到高級的都有，文件已經打包好了，正在學習Python的同學可以下載學習學習。文件下載方式：點擊小編頭像，關注後私信回覆“<strong>python</strong>”即可下載。首先把代碼擼起來！首先把代碼擼起來！首先把代碼擼起來！重要的事說三遍，哈哈。“編程是門手藝活”。什麼意思？得練啊。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>時代</a></li><li><a>機器</a></li><li><a>中識別</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html alt=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1530929302432561dc6cda6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html title=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價>機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/81701dbe.html alt=大項目定製虛擬製造信息時代的全新制造模式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/31927bfce0514c87bd95f4f3b8b3a451 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/81701dbe.html title=大項目定製虛擬製造信息時代的全新制造模式>大項目定製虛擬製造信息時代的全新制造模式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c6909bb4.html alt=虛擬製造：信息時代的全新制造模式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/53f60001361786aae83a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c6909bb4.html title=虛擬製造：信息時代的全新制造模式>虛擬製造：信息時代的全新制造模式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html alt=「火爐煉AI」機器學習048-Harris檢測圖像角點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d756b20a1dbc4ab4b4f22d6b61be2043 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html title=「火爐煉AI」機器學習048-Harris檢測圖像角點>「火爐煉AI」機器學習048-Harris檢測圖像角點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html alt=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfDgA10IBHJqK9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html title=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？>AI也有偏見：你在機器“眼裡”是好人還是壞蛋？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html alt=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/519b968bf69146fda9bf55f89779d373 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html title=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質>基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3a8b1347.html alt="高像素時代 究竟多少萬像素才夠你用？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5e3400075f8ca677db23 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3a8b1347.html title="高像素時代 究竟多少萬像素才夠你用？">高像素時代 究竟多少萬像素才夠你用？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html alt=如何減少焊接機器人出現焊接件變形的情況？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3a62de9fde6c4a09ac0950d5f16dea0a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html title=如何減少焊接機器人出現焊接件變形的情況？>如何減少焊接機器人出現焊接件變形的情況？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/34b922ed.html alt="內燃機時代全面結束 廣西沿海鐵路全面實現電氣化運營" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/34b922ed.html title="內燃機時代全面結束 廣西沿海鐵路全面實現電氣化運營">內燃機時代全面結束 廣西沿海鐵路全面實現電氣化運營</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/46aeceb2.html alt=高鐵時代迅速落寞的這些城市，普速時代曾是輝煌的重要鐵路樞紐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b39a4d946ffe4f88ba3a7d5cfac0c16e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/46aeceb2.html title=高鐵時代迅速落寞的這些城市，普速時代曾是輝煌的重要鐵路樞紐>高鐵時代迅速落寞的這些城市，普速時代曾是輝煌的重要鐵路樞紐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>