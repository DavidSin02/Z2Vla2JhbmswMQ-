<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>CAAI AIDL 第七期 演講實錄丨章國鋒：視覺SLAM技術與AR應用 | 极客快訊</title><meta property="og:title" content="CAAI AIDL 第七期 演講實錄丨章國鋒：視覺SLAM技術與AR應用 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/098283f570024390af0681b956fa4d9b"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/c4b7d1a6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/c4b7d1a6.html><meta property="article:published_time" content="2020-11-14T21:03:55+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:55+08:00"><meta name=Keywords content><meta name=description content="CAAI AIDL 第七期 演講實錄丨章國鋒：視覺SLAM技術與AR應用"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/c4b7d1a6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>CAAI AIDL 第七期 演講實錄丨章國鋒：視覺SLAM技術與AR應用</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><blockquote>8月31日-9月1日，由中國人工智能學會主辦，華中科技大學電子信息與通信學院承辦的主題為《計算機視覺應用技術》的AI前沿講習班第七期在華中科技大學成功舉辦。浙江大學計算機輔助設計與圖形學國家重點實驗室教授、博士生導師、國家優秀青年科學基金獲得者章國鋒發表了主題為《視覺SLAM技術與AR應用》的精彩演講。</blockquote><div class=pgc-img><img alt="CAAI AIDL 第七期 演講實錄丨章國鋒：視覺SLAM技術與AR應用" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/098283f570024390af0681b956fa4d9b><p class=pgc-img-caption>章國鋒 浙江大學計算機輔助設計與圖形學 國家重點實驗室教授博士生導師、國家優秀青年科學基</p></div><p>以下是章國鋒的演講實錄：</p><p>章國鋒：非常感謝也榮幸有機會跟大家分享一下我們課題組最近一些年在視覺SLAM方面做的一些工作，以及在AR和自動駕駛方面做的一些應用。</p><p>我們來看一下，首先這樣一個非常複雜的城市的場景，地上有無人車在開，天上有無人機在飛，大家戴著VR或AR的頭盔在看，你會發現這裡面都需要用到對設備的實時定位和對環境的三維感知，這就需要用到SLAM技術，所謂SLAM就是能夠實現在未知環境中定位自身的方位，並同時去構建這個環境的三維地圖，無論像增強現實、虛擬現實、機器人、無人駕駛、航天航空領域都需要用到實時的定位和三維地圖的構建，所以需要到SLAM技術。SLAM技術的類型有很多，根據不同的傳感器方法也是不一樣的，甚至差別非常大，比如一些深度的傳感器、激光雷達等等之類的，還有攝像頭，分為單目、雙目或者多目，還有慣性傳感器，就是我們智能手機裡面都會有的傳感器。</p><p>我們先看一下SLAM的運行結果，根據傳感器的信息它可以實時計算設備在空間中的位置和朝向，並且同時構建三維地圖；根據地圖的稀疏性可以分為左邊的稀疏SLAM，只恢復一些稀疏的三維頂雲，或者右邊非常稠密的點雲甚至是三維網格。SLAM經過幾十年的發展，它的整個框架已經趨於定型了，這個是目前主流的框架，最早是2007年PTAM這個工作提出來的，整個計算分為兩類線程，即前臺線程和後臺線程（後臺線程可能不止一個），前臺線程是實時計算的，根據輸入傳感器的信息，在完成初始化之後就可以進行實時的位姿恢復。後臺線程通過對局部或者全局的地圖優化來減少誤差累積，如果有迴路把迴路檢測出來通過全局優化閉合掉，還有如果跟蹤丟了可以通過重定位來恢復跟蹤。</p><p>我下面簡要地把這其中的幾個關鍵模塊講一下。首先是初始化，SFM翻譯成中文叫運動恢復結構，它跟SLAM其實是非常類似的。SFM一般是離線處理的，實時的SFM其實就是視覺SLAM。很多時候我們需要處理相機內參未知的情況，比如互聯網上找的一些照片可能沒有內參信息，我們可以通過SFM技術恢復出它的內參以及外參（即位姿）。但是SLAM通常一般認為相機的內參已經事先標定好，這樣它的初始化是在內參已知的情況下進行的，常用的方法有五點法。如果是雙目或者多目的SLAM的話那就更加簡單了。這裡介紹一下SLAM常見的幾種初始化策略。比如PTAM需要用戶指定兩個關幀進行初始化，但是這在AR應用裡體驗肯定是不好的；ORBSLAM在PTAM的框架上做了一些改進，它可以自動選幀來做初始化，還有一些其他的方法，比如說單幀的初始化，但是它要假設對著地平面或者基本對著地平面。還有一種比較常見的方式就是通過檢測出一個已知的Marker來完成初始化。初始化完了以後要進行特徵跟蹤，先檢測特徵，然後進行特徵的匹配，通過跟地圖裡的三維特徵點建立對應關係之後，就可以根據若干3D-2D的對應點把當前幀的位姿求解出來。完成了當前幀的位姿估計之後再三角化出更多的三維點，進行地圖擴展，基本上是這樣一個過程。跟蹤主要有兩類方法，一類是基於關鍵幀的特徵跟蹤，地圖點一般是依附於關鍵幀的，當前幀和關鍵幀（當然關鍵幀可能不止一個）匹配的時候，可以基於一定的運動預測（比如假設相機做一個平滑運動），來初略估計當前幀的初始位姿，再把地圖點投影過來進行局部的搜索來實現快速準確的匹配。這裡特徵的匹配，還要考慮空間的均勻分佈，避免大部分匹配點集中在一小塊區域。這是基於關鍵幀的匹配，另一類方法就是連續幀的匹配跟蹤。比如光流法，先在第一幀提取特徵點直接到下一幀的局部區域去搜索對應點，找到了之後基於下一幀的對應點繼續跟下下一幀去匹配，一般只會在相鄰幀之間進行匹配，不會再跟之前的間隔比較遠的某一幀進行匹配。連續幀的跟蹤方法一般比較簡單，一般直接用光流法就可以了，不需要用基於描述量的方法。但是它比較適合連續幀的跟蹤，如果某一個特徵點由於遮擋的原因跟蹤斷了之後，後面即使重複提取出來也會被認為是新的特徵點，不會再跟之前的匹配，因此它比較難去處理非連續幀之間的匹配和迴路的閉合。此外，在運動比較快的情況下，連續幀跟蹤比較丟掉，一旦有一個遮擋就跟蹤斷掉了，而且容易產生誤差累積。基於關鍵幀的跟蹤和基於連續幀的跟蹤有他們的優缺點，關鍵幀跟蹤方法不容易有誤差累積，因為你總是跟關鍵幀匹配，所以它不會產生慢慢漂移的情況，但是它的缺點是在弱紋理和重複紋理的情況下容易匹配錯誤，因為它總是跟關鍵幀進行匹配，在弱紋理或重複紋理的情況下，關鍵幀相比於連續幀來說還是顏色差異比較大些，而且位姿變換也比較大，很容易造成誤匹配。相比而言連續幀的跟蹤在弱紋理和重複紋理的情況下要好一些，因為相鄰幀之間的圖像顏色變化一般不是那麼大，而且位姿變換也不大，所以它的穩定性要好。但是基於連續幀的跟蹤很容易有漂移和誤差累積問題，而且很難實現迴路的閉合。所以比較好的方式是將這兩個方法結合起來，在關鍵幀跟蹤的基礎上再結合連續幀跟蹤來加強跟蹤的穩定性。</p><p>我們跟蹤得到了一些匹配點之後，通過最小化目標函數，就是優化三維點到對應的二維特徵點的距離，就可以把當前幀相機的位姿給解出來。這其實是一個PnP問題，有很多方法，最簡單就是構造一個線性的矩陣去求解，還有一些其他的方法，方法非常多，我就不細講了。</p><p>前臺的跟蹤基本是這樣的，那麼後臺線程需要不停地對地圖進行優化。後臺優化最主要的就是集束調整，集束調整裡面的變量有三維點和相機位姿，放在一起進行全局的優化。它的複雜度是非常高的，在規模比較大的情況下很難保證實時性。所以有一些策略，比如說採用局部集束調整法來進行高頻次的優化，而全局集束調整比較低頻次的調用，往往只有在迴路閉合的時候才會用到。另外是迴路閉合，迴路閉合需要先檢測出迴路之後再通過全局優化來閉合，比較耗時，因此一般放在後端。還有重新定位、稠密的三維重建這些模塊，一般也是放在後端。如果迴路沒有閉合之前誤差已經很大了，閉合之後可以把誤差消除掉。剛才講到後臺的全局優化，因為你要用相機的狀態和地圖的三維點進行批量式的優化，因為它用了所有的信息，所以它的精度是最高的，當然速度就比較慢。</p><p>對於局部的窗口的優化大致可以分為兩類，都是採取滑動窗口的方式，比如說滑動窗口裡有十個關鍵幀，新的關鍵幀進來了以後要把老的關鍵幀給移出去，至於移出去的策略可以有好多種，最簡單的就是新的關鍵幀進來，最老的一個關鍵幀滑出去。窗口內始終保持一定數量的關鍵幀，優化速度非常快，缺點是精度比較低，因為舊的關鍵幀的相機狀態移出去以後它的信息被固化了，不會再被優化，所以一旦有誤差累積就一直累積在那裡，就是錯誤的信息不能得到糾正。所以後來提出帶有狀態先驗的局部窗口優化，最大的不同是什麼？就是我滑出去的這一幀，並不是直接把它的相機狀態和三維點給固化掉，而是對它做一個邊緣化的處理，所謂邊緣化就是根據當前的狀態值進行線性化，然後作為先驗加到目標函數裡。這個方法比直接對狀態進行固化的方式精度要高，但是速度要慢些，因為增加了目標函數的複雜度。但是總的來說，只要滑動窗口的大小固定，增加的複雜度也是有限的，所以計算複雜度不會無限增長。</p><p>全局優化就是對所有的相機狀態進行批量式的優化，理論上是最優的。由於計算複雜度很高，一般只進行低頻次的調用，或者在迴路閉合的時候調用。一些加速的方法也被相繼提出來，比如有人提出把三維點都消元掉，只留下相機位姿參數，因為相機位姿的變量數是遠遠要小於三維點的數目的，所以這樣它的計算複雜度會降低很多。當然它的精度也會下降，特別是如果三維不準的話，這樣做的誤差也是很大的。</p><p>還有一種策略是採用增量式的集束調整方法，每來一幀不是重新構造一遍，而是通過重用上次計算的結果，只要做一些局部的更新就好了。還有一個就是狀態刪除的策略，你要保證地圖不能無限制的上漲，關鍵幀的數目要設一個上限。怎麼刪除關鍵幀就比較關鍵了，一種是直接刪除，直接刪除會造成信息的丟失，還有一個是邊緣化刪除，這樣的話雖然做了一些刪除，但還是保留了部分信息，當然計算複雜度會高些。</p><p>SLAM難免會有跟蹤丟掉的情況，丟掉了以後需要恢復回來，這就需要用到重定位。另外一種情況是，隨著運動時間和距離加長，誤差難以避免會不停的累積，這時候如果有一個迴路，可以通過迴路閉合來把誤差累積消除掉。重定位和迴路閉合有相似的地方，一開始都要去尋找當前場景跟已經生成的地圖的聯繫，也就是圖像檢索的過程，這是第一步。但是二者的優化目標不一樣，重定位只需要得到當前幀相機的位姿，迴路閉合則需要修正整個相機軌跡以及相關的三維點的座標。</p><p>剛才說到它們都是用到的圖像檢索，隨著場景的拓展，關鍵幀的數量不斷增加，主要的問題是如何快速魯棒地從中找到和當前幀相似的關鍵幀。可以分為兩類方法，一類是基於局部特徵的檢索方法，還有一類是全局圖像的檢索。局部特徵大家都比較熟悉了，我就不展開來講了。還有就是基於整張圖像進行檢索，比如說用Gist這種比較傳統的方法，但這類方法的速度比較慢，現在普遍採用深度學習的方法來做。</p><p>前面我們快速過了一下SLAM系統中的幾大模塊，下面我重點講一下視覺SLAM以及視覺SLAM的挑戰和針對性的解決方法。目前它主要有兩個方面的挑戰，一個是精度和穩定性，因為這個場景是動態變化的，視覺特徵匹配由於弱紋理或者重複紋理會導致匹配不準，從而導致優化計算不穩定。還有一個是場景的規模非常大，比如在一個城市規模的場景下，計算複雜度會很高，如何在手機或者眼鏡這種低功耗設備上做到實時穩定的運行，挑戰還是很大的。</p><p>針對第一個挑戰，我們需要做到目標函數裡的約束方程要正確，如果有大量的Outliers，會造成錯誤的約束，從而導致求解的不穩定，需要將它們剔除掉。還有就是要保證約束的充分性，比如在一些弱紋理場景下，沒有足夠的特徵匹配，導致約束的方程很少，也會造成優化的不穩定，這需要增加一些約束，比如加上運動先驗的約束，最典型的就是利用幀與幀之間的加速度、角速度信息來進行相鄰幀的運動約束。還有就是如果場景有一些平面性的結構或垂直關係，把這些先驗信息用上的話也可以提高穩定性。</p><p>關於第一個方法，就是如何檢測出outliers，我們在2013年的時候做了一個工作RDSLAM，這是整個的框架，在Mapping線程我們會不停地檢測哪些三維點已經改變，如果某個點發生改變那麼需要從地圖裡把它標誌為無效或者刪掉，某個關鍵幀如果無效點太多的話也需要把它替換掉。我們採用關鍵幀的表達方法，每次在線匹配了之後，我們會選五個與當前幀位姿最接近的關鍵幀，把關鍵幀的點投影到當前幀來。因為我們沒有法向的信息，這樣投過來的話，如果沒有進行角度的矯正的話，實際上誤差可能會比較大，所以我們如果只是做一個簡單的比較需要限制一個角度，不能改變太大。因此我們加了這樣一個限制，在這種情況下如果顏色變化依然比較大，我們還要進一步排除是不是由於遮擋造成的，當然投過來的是不一樣的，我們進一步排除遮擋，如果不是遮擋造成的，那就是確實改變了。這裡給出了一個例子，我們故意拿一張紙在鏡頭前面晃來晃去，如果我不進行遮擋處理，系統會誤認為這裡的點都是被改變掉的，然後就會把這些點全部移除掉，這會造成不穩定，因此我們需要排除這種情況，也就是隻把真正改變的點去掉。還有一個也是非常重要的，我們在有大量outliers的情況下要迭代很多次才可以選出正確的一組inliers，然後把相機位姿給解出來。比如說每次選六對點，如果inliers比例是10%的話，那麼要選六對點保證都是inliers的概率是非常低的，所以在這樣的情況下傳統的RANSAC方法就很難工作了。因此我們針對這個問題提出了一個基於時序先驗的RANSAC方法。我們首先對圖像進行一個10×10的等分。為什麼做10×10的等分呢？因為我們發現如果特徵點匹配都集中在某一塊小的區域其實意義不大，所以我們每一塊區域只需要選一對點就夠了，再多了其實意義不大。我們計算每一個小塊的inliers的分佈，然後假設當前幀和前一幀的運動是比較平滑的，我們直接把上一幀的inliers分佈概率傳遞到當前幀。這時候我們不需要完全隨機選點了，而是根據inliers分佈優先去選inliers可能性比較高的幀，這樣就會大大提高我們選出一組都是inliers的可能性。僅僅是這樣還不夠，如果這個場景中有一個剛性運動的物體，而且特徵很豐富，這時候只選出inliers數目最大的一組的話，就可能會出問題了，可能會誤認為這個做剛性運動物體的點是inliers，應該是靜態的點。事實上，我們發現這些在剛性運動物體上的點往往集中在一個比較小的區域，而靜態背景的點一般分佈比較均勻，因此我們可以算一個點分佈的協方差，然後跟inliers數目綜合考慮起來，這樣能比較有效地區分。這裡有一組例子，左邊顯示的是有200個綠色的點，屬於靜態背景，然後300個紫色的點是位於剛性運動的物體上，還有另外500個是完全隨機的。我們發現剛性物體上的點的數目比靜態背景上的數目還要多一些，因此你如果用傳統的算法只算inliers數目的話這兩個是非常接近的，甚至可能弄錯了。但如果我們進一步考慮了這些點的分佈面積之後，就能正確區分出來。</p><p>我們來看一個例子，這本紅色的書，如果是用傳統的方法很可能會誤認為它屬於靜態背景，恢復出來的相機運動是跟著這本書的。而採用了我們提出的PARSAC方法，能正確選出靜態背景上的特徵點，從而恢復的相機位姿不會隨著書的運動而運動。最後放一下結果，這是一個很有挑戰性的場景，人在整理書本，同時有手電筒在照，造成一些光照的變化，大家可以看到跟蹤還是比較穩定的，這個是恢復三維的點，就是關鍵幀，紅色的點代表的是改變的三維點。這是跟PTAM的比較。</p><p>剛才說的是怎麼去通過先驗去很好地選出inliers來提高SLAM的穩定性以及效率。但如果在特徵不夠豐富的場景下，或者匹配不是很好的情況下，這個時候怎麼辦呢？我們知道，視覺慣性SLAM利用IMU來彌補視覺的不足。如果是隻有攝像頭沒有IMU，有沒有辦法從視覺慣性SLAM做一些借鑑來提高視覺SLAM的穩定性呢？IMU主要有加速度和角速度信息，加速度（尤其是手持設備的加速度）往往比較小，因此我們可以直接把它設為零來對相鄰幀的運動做約束。但旋轉的角度不能這麼做，需要對它做一個比較準確的估計。我們假設位移比較小，將特徵匹配和整張圖像對齊結合起來只估計連續幀之間的旋轉角度，這樣即使在運動模糊情況下沒有足夠的特徵匹配很多時候依然能穩定地求解旋轉角度。這個是我們2016年的一個工作，也就是RKSLAM。這是整個系統的框架，首先前端是基於Multi—Homography的跟蹤方法，假設這個場景可能會存在多個平面，通過擬合多平面去提高跟蹤穩定性。另外就是把角速度估計出來，然後通過滑動窗口優化提高跟蹤穩定性。這裡有一個比較，左上角是基於我們估計出的連續幀旋轉角度的跟蹤結果，右上角是用了真實IMU的跟蹤結果，下面兩個，其中一個是直接將角速度設為零，還有一個是不加運動約束的結果。這個對比還是非常強烈的，上面兩個的結果還是很接近的，有真實IMU會好一點，下面的兩個跟蹤結果就差距比較大了。這個是我們跟其他方法做的對比。我們也在TUM數據集上做了評估和比較。我們選了12個序列分為四組，其中D組是快速運動和強旋轉，可以看到在D組序列的跟蹤成功率上是明顯好於ORB-SLAM的。而且我們的方法速度要快很多，是ORB-SLAM的將近5倍，在手機上可以做到實時。</p><p>剛才講到跟蹤的穩定性，我們分享瞭如何解決跟蹤穩定性做的一些工作。還有就是如何解決求解效率的問題，這個裡面最主要的模塊就是集束調整，就是通過優化目標函數把所有的三維點和相機參數放在一起進行聯合優化，大家可以想像這個目標函數是非常的龐大，因為三維點的個數可能非常多。如果你不利用稀疏性去解，計算複雜度是很高的。因此我們肯定得利用矩陣的稀疏性，一般常規的做法是每次迭代都會解這樣一個線性方程組，上面的是相機參數的變量，下面是相應的三維點的變量，因為三維點的變量數目一般遠遠大於相機參數的變量數，所以我們先把相機參數解出來，把右上角的W變成零。上面部分可以獨立地把相機的參數解出來，之後再回來把三維點數目解出來，這樣的好處是因為相機參數的數目比較小，可以解得比較快，然後再回到下面這個線性方程組求解三維點，這時候每個點可以獨立的求解，因此可以非常高效。但是即使是這樣利用稀疏性去做，這是我們用常規的方法去做的，雖然關鍵幀數目的增長，可以看到它基本上是線性的，可能是因為稀疏性發生了改變。隨著SLAM的幀數越來越多，複雜度還是會增長很快。主要有兩種思路，一個是分治求解，還有一個是增量式計算。分治求解常見有兩類方法，一個是基於分段的BA，就是將一個長序列分成若干段短序列，每段整體（幀和三維點）做一個7DoF的相似變換，這樣變量數大幅下降，優化速度可以大幅提升，而且因為是全局優化不容易陷入局部最優解。當然自由度下降了，優化能力肯定也會有所下降，可能優化的結果誤差還是比較大的，那麼我們可以對段進一步分裂然後再優化，不斷地重複這個過程直到不能再分裂或誤差小於某一個閾值為止。分佈式BA的做法也是有點類似，將整個數據集分成若干個子集，對每一個子集進行獨立的局部BA優化，然後通過共享變量的方式進行全局優化。這個是基於分段BA的結果，可以看到經過幾次迭代之後基本上就不變化了，也就是收斂了。這個數據集有6段視頻序列將近10萬幀，在一臺PC上進行求解只需要16分鐘，加上匹配的時間，平均下來達到17.7fps，還是相當快的。</p><p>我們再看一下增量式BA，對於SLAM來說，特別是基於關鍵幀的SLAM，每加一個關鍵幀都需要進行優化，如果每加一個關鍵幀整體重新優化一遍，每次優化的複雜度都是會增加的，這對於大尺度場景來說就不太可行。所以有些人就提出來，每加一幀進行優化的時候，是不是可以重複利用前面優化或計算的結果呢？代表性的增量式方法有iSAM以及iSAM2，我們也做了一些工作，也就是EIBA和ICE-BA。增量式方法的核心思想就是隻更新加入或更新的變量對應的矩陣元素，也就是進行增量的更新，而不是從頭到尾重新構造。比如說原有來C1、C2、C3三幀，現在加入了一個新的三維點X3以及新的幀C4，我們只需要這兩個變量對應的矩陣元素就好了，其它不需要重新構造，這樣就有點像一個局部BA，但精度可以達到全局BA。當然如果在有迴路閉合的情況下，這種增量式BA就要退化到批量式全局BA，因為所有的變量對應的元素都要更新了。我們來看一下Incremental BA的效率，比之前的方法有一個數量級的提升。對於局部BA來說，滑動窗口裡面的特徵軌跡可能會比較長，導致對應的信息矩陣的複雜度會比較高。為了高效的求解，我們提出把一個很長的特徵點軌跡切成若干段短的特徵軌跡，這樣對應的信息矩陣變得稀疏很多。如果矩陣比較大，就更明顯了，求解的效率會大大提高。大家可能會問，這樣會不會造成精度的下降？因為把特徵軌跡切分成若干段，其實是放鬆了一些約束。不過我們是隻在計算相機參數的時候把特徵軌跡切分，而回代去求解三維點的時候並沒有切分，因此這時候是沒有近似的。事實上，我們發現雖然它比常規的優化方法需要更長的迭代次數，但是因為每次迭代的速度大幅提升，所以整體最後收斂的時間反而是更快的，而且我們發現最後的優化精度其實是沒有下降的，基本上跟標準的方法是一樣的。這是局部BA方面，我們的方法和OKVIS的對比，可以看到速度提升了一個數量級。在全局BA方面，我們的方法也比iSAM2快一個數量級。</p><p>最後講一些應用。我們和商湯一起開發的SenseAR平臺，跟其他平臺比起來，它能支持單目、雙目和RGB-D等多種類型的傳感器，目前已經支持了AR測量、高德地圖AR步行導航以及《王者榮耀》和《一起來捉妖》等遊戲的應用。最近又升級到了2.0，形成了一個雲與端融合的增強現實平臺，通過構建視覺高精度地圖以及雲和端結合的方式實現室內大尺度場景的導航。再比如，基於雲-端結合的AR多人共享，你和朋友各自拿一個手機可以一起來玩這樣一個AR多人射擊遊戲。</p><p>提到AR，對於AR來說SLAM主要面臨哪些挑戰呢？在AR的應用場景裡面其實挑戰還是很大的，因為用戶拿到手機不會那麼小心翼翼，他可能會突然地轉動，然後場景裡可能有很多動態物體、高光和重複紋理、甚至弱紋理區域。對於好的AR體驗來說要求三維註冊要很精確，沒有漂移現象，走了一圈迴路要閉合起來，而且希望跟蹤丟失的情況儘可能少，就算丟失了也可以儘快的恢復，也就是重定位的時間要很短。我們來看一下現有的一些SLAM方面的數據集，就是視覺加IMU，它們往往採用同步比較好的傳感器，IMU一般也是比較好的。但是目前無論是手機還是AR眼鏡，裡面的IMU不會太好。那這樣的數據集實際上並不能滿足我們在AR場景下對SLAM性能的評估。因此，我們自己構建了一個新的數據集。我們當時用了兩款手機，一個是iPhone X，還有一個是小米8，這是它們的圖像、分辨率的參數，為了模擬AR運動的情況我們選了五種運動類型。我們分別用小米8手機錄了A系列序列，iPhone X錄了B系列序列。我們來看一下這些序列是怎麼樣的。A系列序列還是屬於比較正常的運動類型，就是我剛才說的幾種常規的運動，主要是用來測試跟蹤精度的；而B系列序列是測試魯棒性的，相對來說比較極端，比如說突然手去擋住相機，或者突然把圖像變成黑色，強迫SLAM系統跟蹤丟失進入重定位狀態。</p><p>我們提出了一些新的指標，首先是Tracking Accuracy。跟以往的標準不同，除了絕對的位置精度，我們還專門提出了完整度，絕對位置誤差如果小於某一個設定的閾值就認為是好的位姿，然後算一個好位姿的比例。相對於平均絕對位置精度，完整度不容易受到個別位姿誤差很大的影響。還有一個很重要的指標就是初始化的質量，有兩個方面：一個是初始化的時間，還有初始化完成之後尺度的精度。我們把這兩方面綜合起來評估初始化的質量。也就是初始化的時間越短越好（甚至做到用戶無感初始化），尺度的精度越高越好。還有一個是跟蹤的魯棒性，比如是不是容易跟丟，跟丟之後重定位回來是不是準確。還有就是重定位時間，也就是跟丟之後多久能重定位回來。為了準確估計重定位的時間，我們需要知道SLAM系統什麼時候真正丟掉，什麼時候完成重定位。因此，我們會故意把圖像變成純黑的，對於視覺SLAM來說肯定就跟蹤丟掉了，但對於VISLAM來說，雖然視覺跟蹤會丟失，但它還是會持續地輸出位姿信息，這個時候我們到底怎麼判斷重定位成功了呢？視覺SLAM的判斷很簡單，直到它輸出一個正常的位姿就說明重定位成功了。但VISLAM就沒那麼容易了，不能直接看出它什麼時候完成了重定位，當然如果我們可以讀它的源代碼根據系統內部的狀態判斷是可以的，但是我們不想把問題複雜化，而是希望只是輸出位姿信息就能判斷是不是重定位了。為此我們做了這樣一個檢測：當黑屏結束之後，系統應該會啟動重定位，如果後面某個時刻位姿突然跳了一下就說明是重定位成功了，然後計算重定位的時間。</p><p>目前有這麼多的代表性方法，我們從中選了一些開源的方法，以及我們和商湯合作研發的SenseSLAM。我們將這些方法分為VSLAM和VISLAM兩類，並制定了跟蹤精度、初始化質量、跟蹤魯棒性以及重定位時間來進行比較。這裡，我們特別看一下重定位的結果比較。VSLAM系統（PTAM和ORB-SLAM）重定位的時間明顯比VISLAM短一些，這是因為VISLAM不僅要解出來當前幀的位姿，還需要重置IMU的狀態，所以一般需要好幾幀的時間。不過，一般一秒以內的重定位還是可以接受的。我們這個Benchmark對應的文章已經發表了，大家有興趣可以去看一下。對於開源的軟件，我們可以通過導入一樣的數據集運行輸出結果來評估，但如果是不支持導入序列的商業軟件，那怎麼辦呢？針對這種情況，我們把兩個配置一樣分別裝了SenseSLAM和ARCore的手機並排放在一起，將位姿實時輸出進行比較。可以看到，SenseSLAM 2.0和ARCore 1.9的結果在各個方面基本差不多。</p><p>最後講一下我們在自動駕駛方面做的一些工作，結果都還比較初步。自動駕駛完全用純視覺的SLAM技術還很困難，目前比較現實的還是視覺怎麼和其他傳感器進行融合，比如可以跟LiDAR融合，跟GPS融合，甚至和輪速計融合。此外，通過視覺技術生成帶有語義的高精度地圖，對自動駕駛來說也是很有用的，它可以幫助更好地做定位修正，消除誤差累積。我們做了基於雙目的里程計以及融合了LiDAR的里程計。目前基於LiDAR的單幀定位耗時10毫秒左右，精度基本上100米的誤差在1%左右。另外，還可以融合IMU和GPS，比如融合IMU尤其是場景裡面有體積比較大的動態物體，比如像一些大卡車開過會造成運動的偏移，有了IMU可以有效地減緩這個問題。如果有GPS也可以進一步降低誤差累積，因為普通的GPS雖然精度不是很高，但沒有誤差累積。一般車上都有輪速計，根據輪速計也可以計算出運動軌跡，但是誤差累積還是比較大的，比如在這個實驗裡它的尺度誤差超過了10%。如果是隻利用單目相機的信息，也是很難準確估計尺度，而且漂移也比較嚴重。但是我們把兩者融合起來之後，定位精度會得到明顯的提升。特別是結合帶有語義的地圖，通過對道路進行一些平面以及線的識別，然後再用點到線的方式進行定位修正，這樣橫向的誤差可以明顯降低。當然，這還只是非常初步的一些結果，未來我們計劃將更多的語義信息融合提高定位的精度和可靠性。</p><p>剛才介紹的一些工作的可執行程序或源代代碼都已經放出來了，未來我們計劃開源更多的算法和數據集（http://github.com/zju3dv），歡迎大家關注和下載使用。</p><p>最後講一下視覺SLAM技術的發展趨勢。視覺SLAM最大的問題就是對特徵的依賴非常明顯，因此大家都在考慮如何緩解對特徵的依賴，比如結合基於邊、面特徵的跟蹤，採用直接圖像跟蹤或半稠密跟蹤，還有結合機器學習等。當然，這些方法只能緩解但不能徹底解決特徵依賴問題。每個傳感器都有各自的優點和缺點，如果能把多種傳感器的信息融合起來，那就可以得到一個更高可靠性和高精度的定位，這也是未來的一大發展趨勢。此外，視覺SLAM也在朝著稠密三維重建的趨勢發展。比如目前基於單目或多目的三維重建，已經能做到實時了；如果有深度相機，那麼實時三維重建可以做得更好，甚至能做到對非剛性物體的實時三維重建。</p><p>我今天的報告就到這裡，謝謝大家！</p><p>嘉賓：謝謝章老師，下面的時間大家可以提問。</p><p>提問：現在你們在無人機場景下考慮做了一些什麼嗎？</p><p>章國鋒：暫時還沒有。</p><p>提問：比如在長隧道里面GPS失效了，在隧道里面你如何用SLAM提高它的定位精度？</p><p>章國鋒：在隧道里面我們沒有測過，但是VSLAM我覺得還是可以工作的，當然前提是隧道里面不能太黑，如果完全黑了的話那就不行了。基於LiDAR的SLAM技術在隧道里應該也能比較好地工作。</p><p>提問：還有一個問題，就是隧道里面無法進行迴環檢測。</p><p>張輝：對，沒有迴環檢測誤差累積就難以消除。那麼關鍵就是誤差累積有多快了，這個其實跟傳感器和運動的速度都有關係。比如圖像如果比較模糊，那麼誤差累積一般會厲害一點；如果視覺融合IMU信息，誤差累積可能就沒有那麼快了。當然還可以和LIDAR以及其他一些深度傳感器融合，比如毫米波雷達，也能提高定位的精度，減緩誤差累積。</p><p>嘉賓：毫米波雷達的定位精度有多高？</p><p>章國鋒：毫米波雷達沒有試過。定位精度其實跟傳感器本身的精度和場景類型都有關係。比如基於純激光雷達的里程計，在KITTI數據集上已經可以做到每100米的平均誤差在1米左右，目前差不多都是這樣一個級別。如果跟其他傳感器融合，定位精度應該還會再高一點。</p><p>嘉賓：章老師，我想請教一下，你們的技術有沒有在一些室內的場館裡面運用？</p><p>章國鋒：這個其實我們已經在做了。我們為杭州國際博覽中心做了定位導航，就是通過視覺的方法做的。</p><p>嘉賓：但是大型的場館有時候會有遮擋，包括人員也很稠密，之前有團隊是用無線的技術做的導航，但是有一個問題是，無線的信號是很容易被屏蔽的，就需要藉助一些視覺的技術。</p><p>章國鋒：結合肯定可以做，但是我們的出發點是儘可能把視覺的潛力發揮到極限。比如，國博的場景還是很有挑戰的，地面都是大理石，反光很嚴總，而且很多區域很相似，在那樣的場景下我們單幀的平均定位成功率已經達到80%以上，而且還在進一步改進中，預計未來可以做到90%的定位成功率；如果是旋轉半圈拍攝視頻的方式，那麼定位的成功率可以達到96%，基本上可以滿足實際應用的要求了。</p><p>嘉賓：您剛剛說用手機在室內導航必須要先有地圖嗎？</p><p>章國鋒：是的，還是需要先把地圖構建出來才能進行定位導航，就跟現在的室外導航一樣的道理。</p><p>嘉賓：是離線構圖嗎？</p><p>章國鋒：是的。</p><p>嘉賓：有沒有可能在沒有任何先驗的數據環境下用SLAM就可以實時定位？</p><p>章國鋒：問題是SLAM的實時定位是基於系統自己的一套三維座標系，跟地理信息座標系或場景地圖的三維座標系是不一致的，因此這樣的定位無法用於導航。因為你不知道自己在整個場景中位於哪個位置，也不知道目標位置在哪裡，這種情況下是無法導航到目標位置的。</p><p>嘉賓：我們想先解決A點的定位問題，B點的信息用其他的算法可以解決。</p><p>章國鋒：因為SLAM技術可以在未知的環境下恢復相機相對於場景的位姿，並且不斷地恢復周圍環境的三維結構，所以確實可以確定A點的定位信息（相對於A點所在的局部場景而言）。但是由於一開始並不知道B點相對於A點的方位，所以這種情況下還是無法導航的。對於導航來說，如果沒有預先的地圖信息（哪怕是比較粗糙的相對方位信息）是不可能做到的。</p><p>嘉賓：地圖信息必須要下載到手機端嗎？</p><p>章國鋒：不需要。完整的地圖信息可以放在雲端，通過雲端定位的方式來實現。</p><p>嘉賓：章老師我有一個問題，在自動駕駛裡面跟蹤很重要，如果要達到很高的精度，我希望跟蹤的特徵點軌跡要足夠長，但是如果太長了以後會它產生漂移嗎？</p><p>章國鋒：這要看是基於關鍵幀的跟蹤還是連續幀跟蹤。對於連續幀跟蹤，確實特徵點跟蹤長了會逐漸漂移。我們可以通過基於關鍵幀的跟蹤方法來抑制漂移問題；當然如果視角變化過大，基於關鍵幀可能很難匹配上。</p><p>嘉賓：所以這個時候語義可以提供幫助嗎？</p><p>章國鋒：結合語義信息可以幫助減緩這個問題，但是目前的方法還很難做到點和點的準確對應。通過結合語義信息建立的約束可以減少誤差，特別是有比較大的累積誤差的時候，還是有效果的。但是如果希望得到非常高的精度，儘可能把誤差累積消除掉，那麼可能還是需要建立準確的點和點之間的對應，這個對於基於語義的方法來說目前還是有難度的。</p><p>嘉賓：時間有限，非常感謝章老師的精彩報告。</p><p>（本報告根據速記整理）</p><p class=ql-align-center><br></p><p class=ql-align-center>CAAI原創 丨 作者章國鋒</p><p class=ql-align-center>未經授權嚴禁轉載及翻譯</p><p class=ql-align-center><strong>如需轉載合作請向學會或本人申請</strong></p><p class=ql-align-center><strong>轉發請註明轉自中國人工智能學會</strong></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>第七期</a></li><li><a>CAAI</a></li><li><a>AIDL</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/d11e596.html alt="CAAI AIDL 第八期 演講實錄丨張偉男：任務型對話系統" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/cda59915fa384d2785b7948a65c03347 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d11e596.html title="CAAI AIDL 第八期 演講實錄丨張偉男：任務型對話系統">CAAI AIDL 第八期 演講實錄丨張偉男：任務型對話系統</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0d523471.html alt=CAAI知識工程與分佈智能專委會大數據知識工程研討會成功召開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e0248eb2ba9f4fc3b8cb7efab16d5e90 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0d523471.html title=CAAI知識工程與分佈智能專委會大數據知識工程研討會成功召開>CAAI知識工程與分佈智能專委會大數據知識工程研討會成功召開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c52977ad.html alt=燃燒吧少年第七期（肖戰、白澍、彭楚粵、夏之光、陳澤希） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c52977ad.html title=燃燒吧少年第七期（肖戰、白澍、彭楚粵、夏之光、陳澤希）>燃燒吧少年第七期（肖戰、白澍、彭楚粵、夏之光、陳澤希）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/915c2682.html alt="「新學員介紹」第七期Founders Class學員——恆諾物聯" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/3c9f5d555694464ca2f749a17b39d5cb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/915c2682.html title="「新學員介紹」第七期Founders Class學員——恆諾物聯">「新學員介紹」第七期Founders Class學員——恆諾物聯</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/e0b80344.html alt=《股權百問百答》第七期：出資不足的股權能否轉讓？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/138c7d94-c3f8-41b4-9df0-12943222288b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/e0b80344.html title=《股權百問百答》第七期：出資不足的股權能否轉讓？>《股權百問百答》第七期：出資不足的股權能否轉讓？</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/b8760862.html alt="《園林植保信息》2020年第七期：加大病蟲害防治力度 降低病蟲危害" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R69iHyf1nPvhVV style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/b8760862.html title="《園林植保信息》2020年第七期：加大病蟲害防治力度 降低病蟲危害">《園林植保信息》2020年第七期：加大病蟲害防治力度 降低病蟲危害</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9d86d1d9.html alt="「現場」“共振蛻變” 中歐創業營第七期正式開營，尋求創業者“二次創業”突破之旅" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1537436296299939c995d91 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9d86d1d9.html title="「現場」“共振蛻變” 中歐創業營第七期正式開營，尋求創業者“二次創業”突破之旅">「現場」“共振蛻變” 中歐創業營第七期正式開營，尋求創業者“二次創業”突破之旅</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/1ed0eb3.html alt="「好書推薦 第七期」診斷微生物學新技術（第二版）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1533617197103509b566a08 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/1ed0eb3.html title="「好書推薦 第七期」診斷微生物學新技術（第二版）">「好書推薦 第七期」診斷微生物學新技術（第二版）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/63c3dc7.html alt=供方庫走訪第七期——走進海尚文旅（海南自貿區）集團有限公司 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/671e9ea3ce77429f9901ae9cdbe41f96 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/63c3dc7.html title=供方庫走訪第七期——走進海尚文旅（海南自貿區）集團有限公司>供方庫走訪第七期——走進海尚文旅（海南自貿區）集團有限公司</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a26a77b.html alt="設備（塔）去哪兒？第七期 塔器的佈置" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5b4d0003d576a7f098d5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a26a77b.html title="設備（塔）去哪兒？第七期 塔器的佈置">設備（塔）去哪兒？第七期 塔器的佈置</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/a39f5e6.html alt=學會動態丨CAAI走進高校系列活動--山東科技大學 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=http://p9.pstatp.com/large/pgc-image/67f2e0a9af3b4935afd748b10be70a27 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/a39f5e6.html title=學會動態丨CAAI走進高校系列活動--山東科技大學>學會動態丨CAAI走進高校系列活動--山東科技大學</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/d02a54c.html alt="「直播文字版」第七期 青春解碼，果酸換膚入門" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=http://p1.pstatp.com/large/9b1e00019e849ff74439 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/d02a54c.html title="「直播文字版」第七期 青春解碼，果酸換膚入門">「直播文字版」第七期 青春解碼，果酸換膚入門</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/fb99b46.html alt=夢幻五開大百科第七期：如何打造五開任務須彌寵？技巧分享給大家 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=http://p9.pstatp.com/large/pgc-image/8bdf41a54a6b4df3af854bf70f211f07 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/fb99b46.html title=夢幻五開大百科第七期：如何打造五開任務須彌寵？技巧分享給大家>夢幻五開大百科第七期：如何打造五開任務須彌寵？技巧分享給大家</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>