<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>純乾貨|Boosting家族之GBDT | 极客快訊</title><meta property="og:title" content="純乾貨|Boosting家族之GBDT - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/e8608f5a5496448bb7926da57722748a"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d20c7eb6.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d20c7eb6.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="純乾貨|Boosting家族之GBDT"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/d20c7eb6.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>純乾貨|Boosting家族之GBDT</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>本文就對Boosting家族中另一個重要的算法梯度提升樹(Gradient Boosting Decison Tree, 以下簡稱GBDT)做一個總結。GBDT有很多簡稱，有GBT（Gradient Boosting Tree）, GTB（Gradient Tree Boosting ）， GBRT（Gradient Boosting Regression Tree）, MART(Multiple Additive Regression Tree)，其實都是指的同一種算法，本文統一簡稱GBDT。GBDT在BAT大廠中也有廣泛的應用，假如要選擇3個最重要的機器學習算法的話，個人認為GBDT應該佔一席之地。</p><h1><strong>1. GBDT概述</strong></h1><p>GBDT也是集成學習Boosting家族的成員，但是卻和傳統的Adaboost有很大的不同。回顧下Adaboost，我們是利用前一輪迭代弱學習器的誤差率來更新訓練集的權重，這樣一輪輪的迭代下去。GBDT也是迭代，使用了前向分佈算法，但是弱學習器限定了只能使用CART迴歸樹模型，同時迭代思路和Adaboost也有所不同。</p><p>在GBDT的迭代中，假設我們前一輪迭代得到的強學習器是</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e8608f5a5496448bb7926da57722748a><p class=pgc-img-caption></p></div><p>, 損失函數是</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7252490b4f244773a775ab4197e15181><p class=pgc-img-caption></p></div><p>, 我們本輪迭代的目標是找到一個CART迴歸樹模型的弱學習器</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/cfec7fa3a4ad46bda3caad773249a15f><p class=pgc-img-caption></p></div><p>，讓本輪的損失損失</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/39b006524e694376b8f7d29866855382><p class=pgc-img-caption></p></div><p>最小。也就是說，本輪迭代找到決策樹，要讓樣本的損失儘量變得更小。</p><p>GBDT的思想可以用一個通俗的例子解釋，假如有個人30歲，我們首先用20歲去擬合，發現損失有10歲，這時我們用6歲去擬合剩下的損失，發現差距還有4歲，第三輪我們用3歲擬合剩下的差距，差距就只有一歲了。如果我們的迭代輪數還沒有完，可以繼續迭代下面，每一輪迭代，擬合的歲數誤差都會減小。</p><p>從上面的例子看這個思想還是蠻簡單的，但是有個問題是這個損失的擬合不好度量，損失函數各種各樣，怎麼找到一種通用的擬合方法呢？</p><h1><strong>2. GBDT的負梯度擬合</strong></h1><p>必須要澄清的誤區：提起決策樹（DT, Decision Tree) 絕大部分人首先想到的就是C4.5分類決策樹。但如果一開始就把GBDT中的樹想成分類樹，那就是一條歪路走到黑，一路各種坑，最終摔得都要咯血了還是一頭霧水，所以說千萬不要以為GBDT是很多棵分類樹。決策樹分為兩大類，迴歸樹和分類樹。前者用於預測實數值，如明天的溫度、用戶的年齡、網頁的相關程度；後者用於分類標籤值，如晴天/陰天/霧/雨、用戶性別、網頁是否是垃圾頁面。這裡要強調的是，前者的結果加減是有意義的，如10歲+5歲-3歲=12歲，後者則無意義，如 男+男+女=到底是男是女？ GBDT的核心在於累加所有樹的結果作為最終結果，每棵樹學的是之前所有樹結論和的殘差。這也就是“Boost”思想的應用，就像前面對年齡的累加（-3是加負3），而分類樹的結果顯然是沒辦法累加的，所以GBDT中的樹都是迴歸樹，不是分類樹，這點對理解GBDT相當重要（儘管GBDT調整後也可用於分類但不代表GBDT的樹是分類樹）。</p><p>這裡的殘差是怎樣計算的呢？？所以“G” 就派上用場了，也就是梯度下降思想。梯度下降作用的是損失函數，使其損失函數迭代到極小值。在GBDT 中處理不同的問題，其損失函數是不一樣的。</p><p>在上一節中，我們介紹了GBDT的基本思路，但是沒有解決損失函數擬合方法的問題。針對這個問題，大牛Freidman提出了用損失函數的負梯度來擬合本輪損失的近似值，進而擬合一個CART迴歸樹。第t輪的第i個樣本的損失函數的負梯度表示為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8c28600591ce4e9ebc4c531824dff963><p class=pgc-img-caption></p></div><p>利用</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a5f956c37f1f45d6962839e36fce662f><p class=pgc-img-caption></p></div><p>,我們可以擬合一顆CART迴歸樹，得到了第t顆迴歸樹，其對應的葉節點區域</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/b91b4cf2924f44fc8f6aa889d1e3d134><p class=pgc-img-caption></p></div><p>。其中J為葉子節點的個數。</p><p>針對每一個葉子節點裡的樣本，我們求出使損失函數最小，也就是擬合葉子節點最好的的輸出值</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/887badda4aeb4876bf1b6699d7e9c8f1><p class=pgc-img-caption></p></div><p>如下：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6c2c4f4d7bf14b82a943e9159102aeb5><p class=pgc-img-caption></p></div><p>這樣我們就得到了本輪的決策樹擬合函數如下：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b29e344e717e44928bd4b23e54758a59><p class=pgc-img-caption></p></div><p>從而本輪最終得到的強學習器的表達式如下：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d34f55a6f5194626a30e07c978de35ae><p class=pgc-img-caption></p></div><p>通過損失函數的負梯度來擬合，我們找到了一種通用的擬合損失誤差的辦法，這樣無輪是分類問題還是迴歸問題，我們通過其損失函數的負梯度的擬合，就可以用GBDT來解決我們的分類迴歸問題。區別僅僅在於損失函數不同導致的負梯度不同而已。</p><h1><strong>3. GBDT迴歸算法</strong></h1><p>好了，有了上面的思路，下面我們總結下GBDT的迴歸算法。為什麼沒有加上分類算法一起？那是因為分類算法的輸出是不連續的類別值，需要一些處理才能使用負梯度，我們在下一節講。</p><p>輸入是訓練集樣本</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c079c68d1f5649bb996de366f29c04af><p class=pgc-img-caption></p></div><p>， 最大迭代次數T, 損失函數L。</p><p>輸出是強學習器f(x)</p><p>1) 初始化弱學習器</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/e7af2386b1b24fa48465ce18ea6a53e6><p class=pgc-img-caption></p></div><p>2) 對迭代輪數t=1,2,...T有：</p><p>a)對樣本i=1,2，...m，計算負梯度</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dfd388888b5f444a9c92fb6a6ba4dc5f><p class=pgc-img-caption></p></div><p>b)利用</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/25f6d0d5c7e24944a023bfca13cf5495><p class=pgc-img-caption></p></div><p>擬合一顆CART迴歸樹,得到第t顆迴歸樹，其對應的葉子節點區域為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/177b59f2b24c4e5183178cc60a5259f1><p class=pgc-img-caption></p></div><p>其中J為迴歸樹t的葉子節點的個數。</p><p>c) 對葉子區域j =1,2,..J,計算最佳擬合值</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15f9fa88ea6c41cc8b314ea7ce6a3c1a><p class=pgc-img-caption></p></div><p>d) 更新強學習器</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c91804d8e84c431fbc90060afaf52e1d><p class=pgc-img-caption></p></div><p>3) 得到強學習器f(x)的表達式</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/1b888f056c3e4ec1b65a738bacb04915><p class=pgc-img-caption></p></div><h1><strong>4. GBDT分類算法</strong></h1><p>這裡我們再看看GBDT分類算法，GBDT的分類算法從思想上和GBDT的迴歸算法沒有區別，但是由於樣本輸出不是連續的值，而是離散的類別，導致我們無法直接從輸出類別去擬合類別輸出的誤差。</p><p>為了解決這個問題，主要有兩個方法，一個是用指數損失函數，此時GBDT退化為Adaboost算法。另一種方法是用類似於邏輯迴歸的對數似然損失函數的方法。也就是說，我們用的是類別的預測概率值和真實概率值的差來擬合損失。本文僅討論用對數似然損失函數的GBDT分類。而對於對數似然損失函數，我們又有二元分類和多元分類的區別。</p><p><strong>4.1 二元GBDT分類算法</strong></p><p>對於二元GBDT，如果用類似於邏輯迴歸的對數似然損失函數，則損失函數為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e24a8e9ddd1d4b3e9ee9ab0cf88683cf><p class=pgc-img-caption></p></div><p>其中y∈{−1,+1}</p><p>。則此時的負梯度誤差為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b9d5078809654ceaaaffaf6057cf8a48><p class=pgc-img-caption></p></div><p>對於生成的決策樹，我們各個葉子節點的最佳殘差擬合值為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3c95c502519a476e804a8d2f4373bd9e><p class=pgc-img-caption></p></div><p>由於上式比較難優化，我們一般使用近似值代替</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cc6a4621a77f401cb38b9daaac5172de><p class=pgc-img-caption></p></div><p>除了負梯度計算和葉子節點的最佳殘差擬合的線性搜索，二元GBDT分類和GBDT迴歸算法過程相同。</p><p><strong>4.2 多元GBDT分類算法</strong></p><p>多元GBDT要比二元GBDT複雜一些，對應的是多元邏輯迴歸和二元邏輯迴歸的複雜度差別。假設類別數為K，則此時我們的對數似然損失函數為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e4a643251ede4716aa6bc1411b7565e5><p class=pgc-img-caption></p></div><p>其中如果樣本輸出類別為k，則</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b09c3f87143243248c90f17dc876b9f4><p class=pgc-img-caption></p></div><p>。第k類的概率</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4ac6a53edb244607ac37814bdce44458><p class=pgc-img-caption></p></div><p>的表達式為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5705e993bf3c4cd0a2abaa5bf2531bc2><p class=pgc-img-caption></p></div><p>集合上兩式，我們可以計算出第t</p><p>t輪的第i</p><p>i個樣本對應類別l</p><p>l的負梯度誤差為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/6969f46b63f5444eb88b2b0179ba2134><p class=pgc-img-caption></p></div><p>觀察上式可以看出，其實這裡的誤差就是樣本i</p><p>i對應類別l</p><p>l的真實概率和t−1</p><p>輪預測概率的差值。</p><p>對於生成的決策樹，我們各個葉子節點的最佳殘差擬合值為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f35965f511c542a0a8ed474fd4a0f7e3><p class=pgc-img-caption></p></div><p>由於上式比較難優化，我們一般使用近似值代替</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1178d0a8584c4a94b45e356b4c96d300><p class=pgc-img-caption></p></div><p>除了負梯度計算和葉子節點的最佳殘差擬合的線性搜索，多元GBDT分類和二元GBDT分類以及GBDT迴歸算法過程相同。</p><h1><strong>5. GBDT常用損失函數</strong></h1><p>這裡我們再對常用的GBDT損失函數做一個總結。</p><p>對於分類算法，其損失函數一般有對數損失函數和指數損失函數兩種:</p><p>a) 如果是指數損失函數，則損失函數表達式為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/56060f7e00ff46c2a1a2a975c27990eb><p class=pgc-img-caption></p></div><p>其負梯度計算和葉子節點的最佳殘差擬合參見Adaboost原理篇。</p><p>b) 如果是對數損失函數，分為二元分類和多元分類兩種，參見4.1節和4.2節。　</p><p>對於迴歸算法，常用損失函數有如下4種:</p><p>a)均方差，這個是最常見的迴歸損失函數了</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ed51ed331a3c4189be4dec2f314f183c><p class=pgc-img-caption></p></div><p>b)絕對損失，這個損失函數也很常見</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/74efba45ab5b414a9955a2909a5a7f40><p class=pgc-img-caption></p></div><p>對應負梯度誤差為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d0526c395dee49e38616d96f591152c6><p class=pgc-img-caption></p></div><p>c) Huber損失，它是均方差和絕對損失的折衷產物，對於遠離中心的異常點，採用絕對損失，而中心附近的點採用均方差。這個界限一般用分位數點度量。損失函數如下：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3a4ed48579e54d0aaa41d90abaa1b100><p class=pgc-img-caption></p></div><p>對應的負梯度誤差為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fa436fa98bd64854a15b64771f981202><p class=pgc-img-caption></p></div><p>d) 分位數損失。它對應的是分位數迴歸的損失函數，表達式為</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/586d3edc327a49478e2a4d289ebd8a4b><p class=pgc-img-caption></p></div><p>其中θ</p><p>為分位數，需要我們在迴歸前指定。對應的負梯度誤差為：</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4c15bbf91b504287a13fe4efb18d8430><p class=pgc-img-caption></p></div><p>對於Huber損失和分位數損失，主要用於健壯迴歸，也就是減少異常點對損失函數的影響。</p><h1><strong>6. GBDT的正則化</strong></h1><p>和Adaboost一樣，我們也需要對GBDT進行正則化，防止過擬合。GBDT的正則化主要有三種方式。</p><p>第一種是和Adaboost類似的正則化項，即步長(learning rate)。定義為ν</p><p>ν,對於前面的弱學習器的迭代</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/67a49355bb4d4076a05d57cffbf0c02a><p class=pgc-img-caption></p></div><p>如果我們加上了正則化項，則有</p><div class=pgc-img><img alt=純乾貨|Boosting家族之GBDT onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/116f83a461db4f6786a77c001b239f33><p class=pgc-img-caption></p></div><p>ν的取值範圍為0&lt;ν≤1</p><p>0&lt;ν≤1。對於同樣的訓練集學習效果，較小的ν</p><p>ν意味著我們需要更多的弱學習器的迭代次數。通常我們用步長和迭代最大次數一起來決定算法的擬合效果。</p><p>第二種正則化的方式是通過子採樣比例（subsample）。取值為(0,1]。注意這裡的子採樣和隨機森林不一樣，隨機森林使用的是放回抽樣，而這裡是不放回抽樣。如果取值為1，則全部樣本都使用，等於沒有使用子採樣。如果取值小於1，則只有一部分樣本會去做GBDT的決策樹擬合。選擇小於1的比例可以減少方差，即防止過擬合，但是會增加樣本擬合的偏差，因此取值不能太低。推薦在[0.5, 0.8]之間。</p><p>使用了子採樣的GBDT有時也稱作隨機梯度提升樹(Stochastic Gradient Boosting Tree, SGBT)。由於使用了子採樣，程序可以通過採樣分發到不同的任務去做boosting的迭代過程，最後形成新樹，從而減少弱學習器難以並行學習的弱點。</p><p>第三種是對於弱學習器即CART迴歸樹進行正則化剪枝。在決策樹原理篇裡我們已經講過，這裡就不重複了。</p><h1><strong>7. GBDT小結　</strong></h1><p>GBDT終於講完了，GDBT本身並不複雜，不過要吃透的話需要對集成學習的原理，決策樹原理和各種損失函樹有一定的瞭解。由於GBDT的卓越性能，只要是研究機器學習都應該掌握這個算法，包括背後的原理和應用調參方法。目前GBDT的算法比較好的庫是xgboost。當然scikit-learn也可以。</p><p>最後總結下GBDT的優缺點。</p><p>GBDT主要的優點有：</p><p>1) 可以靈活處理各種類型的數據，包括連續值和離散值。</p><p>2) 在相對少的調參時間情況下，預測的準備率也可以比較高。這個是相對SVM來說的。</p><p>3）使用一些健壯的損失函數，對異常值的魯棒性非常強。比如 Huber損失函數和Quantile損失函數。</p><p>GBDT的主要缺點有：</p><p>1)由於弱學習器之間存在依賴關係，難以並行訓練數據。不過可以通過自採樣的SGBT來達到部分並行。</p><p>參考：</p><p>1、https://www.cnblogs.com/pinard/p/6140514.html</p><p>2、https://blog.csdn.net/zbj366112/article/details/70037865</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>純乾貨</a></li><li><a>Boosting</a></li><li><a>GBDT</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/0853e1f9.html alt=超全純乾貨！工程造價概預算常識詳解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ec04ad19d6e44c6e84d6b610bf0f3dad style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0853e1f9.html title=超全純乾貨！工程造價概預算常識詳解>超全純乾貨！工程造價概預算常識詳解</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5bb7f951.html alt=純乾貨分享：直線導軌的選型安裝及十大品牌介紹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/bdbda1fdfb3c4a889f9be9554641727d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5bb7f951.html title=純乾貨分享：直線導軌的選型安裝及十大品牌介紹>純乾貨分享：直線導軌的選型安裝及十大品牌介紹</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8b9b284b.html alt=純乾貨！公路設計費的正確打開方式，我來告訴你（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/269ff3f136a3439cbcc72b8122a639b2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8b9b284b.html title=純乾貨！公路設計費的正確打開方式，我來告訴你（二）>純乾貨！公路設計費的正確打開方式，我來告訴你（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3d754597.html alt=純乾貨！市政工程設計費計算，那些年你忽視的問題、走過的坑 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/07387defc90f4be5a03527e8a2ec8e8e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3d754597.html title=純乾貨！市政工程設計費計算，那些年你忽視的問題、走過的坑>純乾貨！市政工程設計費計算，那些年你忽視的問題、走過的坑</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bf079e5d.html alt=【純乾貨】家裡窗簾怎麼選，看完這篇文章，以後買窗簾不用再發愁 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2c2c4570fa2c438e831a7efbf6177cda style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bf079e5d.html title=【純乾貨】家裡窗簾怎麼選，看完這篇文章，以後買窗簾不用再發愁>【純乾貨】家裡窗簾怎麼選，看完這篇文章，以後買窗簾不用再發愁</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/433071a1.html alt="日本預製混凝土：石材反打工藝 純乾貨！" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1531105445168a8988cac39 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/433071a1.html title="日本預製混凝土：石材反打工藝 純乾貨！">日本預製混凝土：石材反打工藝 純乾貨！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1ecf9bc8.html alt=純乾貨丨電線電纜型號大全 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1482c2715a0f462d8a278210b9104c95 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1ecf9bc8.html title=純乾貨丨電線電纜型號大全>純乾貨丨電線電纜型號大全</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/178bc13f.html alt=C語言指針難嗎？紙老虎而已，純乾貨講解 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/71b50f2a7c1141a2ac44a24efb4a84ff style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/178bc13f.html title=C語言指針難嗎？紙老虎而已，純乾貨講解>C語言指針難嗎？紙老虎而已，純乾貨講解</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/5412fb17.html alt=純乾貨：實際控制人不是你想的那樣！看法院是怎麼認定的 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/9e93359e-8f48-44e7-9bd7-8a79b5c62f47 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/5412fb17.html title=純乾貨：實際控制人不是你想的那樣！看法院是怎麼認定的>純乾貨：實際控制人不是你想的那樣！看法院是怎麼認定的</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/8478775b.html alt=中醫論汗「純乾貨」建議收藏 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/46e4000564a182f15b7e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/8478775b.html title=中醫論汗「純乾貨」建議收藏>中醫論汗「純乾貨」建議收藏</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/5824b2a5.html alt=“從頭到腳”的純乾貨，珍藏版 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/00fd70a604af4bd59f0bde040479a4b4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/5824b2a5.html title=“從頭到腳”的純乾貨，珍藏版>“從頭到腳”的純乾貨，珍藏版</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/4155abe4.html alt=「愛考寶典」純乾貨：你的寒假數學複習規劃 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/5672000488e2a4955fac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/4155abe4.html title=「愛考寶典」純乾貨：你的寒假數學複習規劃>「愛考寶典」純乾貨：你的寒假數學複習規劃</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/0755a488.html alt=純乾貨！學詩必備，詳解《笠翁對韻》，送給孩子漲知識吧 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f255fbe016cb46f586d11cb07eaa9806 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/0755a488.html title=純乾貨！學詩必備，詳解《笠翁對韻》，送給孩子漲知識吧>純乾貨！學詩必備，詳解《笠翁對韻》，送給孩子漲知識吧</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/ca40221b.html alt=純乾貨！不同物料制砂生產線該如何制定生產線？方案彙總！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/58984691d49447f4995c0c92db6e2c07 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/ca40221b.html title=純乾貨！不同物料制砂生產線該如何制定生產線？方案彙總！>純乾貨！不同物料制砂生產線該如何制定生產線？方案彙總！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f969fea9.html alt=深入理解GBDT多分類算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/22b3a5a1b5784d34b3e60fbd556fbbe9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f969fea9.html title=深入理解GBDT多分類算法>深入理解GBDT多分類算法</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>