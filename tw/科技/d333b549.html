<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>在機器學習模型中使用XGBoost | 极客快訊</title><meta property="og:title" content="在機器學習模型中使用XGBoost - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/1536987068038afafd18f06"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d333b549.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d333b549.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="在機器學習模型中使用XGBoost"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/d333b549.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>在機器學習模型中使用XGBoost</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt=在機器學習模型中使用XGBoost onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1536987068038afafd18f06><p class=pgc-img-caption></p></div><p>在本教程中，我們將介紹XGBoost，這是一種機器學習算法，最近主導了應用的機器學習空間。</p><p>本文主要內容</p><ul><li>什麼是XGBoost？</li><li>你為什麼要用XGBoost？</li><li>促進Vis-a-vis Bagging</li><li>在Python中應用XGBoost</li><li>XGBoost的超參數</li><li>使用XGBoost時的交叉驗證</li><li>在XGBoost中可視化特徵的重要性</li><li>結論</li></ul><p>什麼是XGBoost？</p><p>XGBoost是一個開源庫，為Python，Java和C ++，R和Julia 提供梯度增強。在本教程中，我們將重點介紹Python。Gradient Boosting是一種用於分類和迴歸問題的機器學習技術，可以從弱決策樹集合中進行預測。</p><p>你為什麼要用XGBoost？</p><p>您使用此算法的主要原因是其準確性，效率和可行性。它是一個線性模型和一個樹學習算法，可以在一臺機器上進行並行計算。它還具有用於進行交叉驗證和計算特徵重要性的額外功能。以下是該模型的一些主要特徵：</p><ul><li>稀疏性：它接受樹booster 和線性booster 的稀疏輸入。</li><li>定製：它支持定製的目標和評估功能。</li><li>DMatrix：其優化的數據結構，可提高其性能和效率。</li></ul><p>提升Vis-a-vis Bagging</p><p>Boosting是一種機器學習集成算法，它減少了將弱學習者轉化為強學習者的偏差和方差。XGBoost是一個增強算法示例。另一方面，Bagging是一種技術，人們從數據中隨機抽取樣本，建立學習算法，找到Bagging概率。</p><p>在Python中應用XGBoost</p><p>接下來讓我們展示一下如何將XGBoost應用到他們的機器學習模型中。如果您沒有安裝XGBoost，如果您正在使用pip包管理，可以通過在終端中鍵入以下命令來安裝XGBoost：</p><pre>pip3 install xgboost</pre><p>我們將使用Scikit-learn附帶的Boston Housing Dataset 。我們假設讀者瞭解基本的科學包，如Pandas，Scikit-learn和numpy。</p><p>我們從sklearn.datasets加載數據集開始。然後我們導入pandas以使我們能夠將Boston Housing Dataset轉換為dataframe。接下來，我們使用feature_name 屬性獲取特徵。我們使用target屬性獲取目標變量，在本例中為price列。</p><pre>from sklearn.datasets import load_bostonboston = load_boston()import pandas as pddata = pd.DataFrame(boston.data)data.columns = boston.feature_namesdata['PRICE'] = boston.target</pre><p>我們將使用XGBoost來預測數據集的price列。在這種情況下，數據集中的所有要素都是數字。值得注意的是，XGBoost僅適用於數值。如果我們有分類特徵，我們必須使用諸如one-hot-encoding之類的技術將它們轉換為數字。</p><p>接下來，我們導入XGBoost，numpy mean_squared_error，我們將其用作評估指標，以檢查訓練模型在測試數據集上的性能。然後，我們繼續使用pandas iloc實用程序將特徵變量與目標變量分開。</p><pre>import xgboost as xgbfrom sklearn.metrics import mean_squared_errorimport numpy as npX, y = data.iloc[:,:-1],data.iloc[:,-1]</pre><p>為了充分利用XGBoost的性能和效率，我們將數據集轉換為DMatrix。這是通過使用XGBoost的Dmatrix函數實現的。</p><pre>data_dmatrix = xgb.DMatrix(data=X,label=y)</pre><p>XGBoost的超參數</p><p>XGBoost為我們提供了一種調整參數的方法，以獲得最佳結果。基於樹的學習者（如XGBoost）最常見的調整參數是：</p><p>. Booster：指定使用哪種booster 。它可以是gbtree，gblinear或者dart。gbtree和dart使用基於樹模型，而gblinear使用線性函數。gbtree是默認值。</p><ul><li>silent：0表示打印運行消息。1表示靜音模式。默認值為0。</li><li>nthread 是用於運行XGBoost的並行線程數。</li><li>disable_default_eval_metric是禁用默認度量標準的標誌。設置為> 0以禁用。默認值為0。</li><li>num_pbuffer是預測緩衝區的大小，通常設置為訓練實例的數量。緩衝區用於保存最後一個boosting 步驟的預測結果。它由XGBoost自動設置，因此無需由用戶設置</li><li>num_feature是boosting中使用的特徵尺寸，設置為特徵的最大尺寸。它由XGBoost自動設置，因此不需要由用戶設置</li></ul><p>然後，我們使用model_selection模塊中的train_test_split函數將數據集分割為訓練和測試集。我們將測試大小設置為20%，並將隨機狀態設置為100，以確保得到相同的結果。</p><pre>from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)</pre><p>下一步是創建XGBoost Regressor類的實例。參數說明如下：</p><ol><li>objective =’reg:linear’ 指定學習任務是線性的。</li><li>colsample_bytree是構造每棵樹時列的子採樣率。子採樣將在每次boosting迭代中發生一次。該數字的範圍為0到1。</li><li>learning_rate是步長shrinkage ，用於防止過度擬合。該數字的範圍為0到1。</li><li>max_depth指定樹的最大深度。增加此數字會使模型複雜化並增加過度擬合的可能性。默認值為6。</li><li>alpha是權重的L1正則化。增加這個數字使模型更加保守。</li><li>n_estimators 是適合增強樹木的數量</li></ol><pre>xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5,alpha = 10, n_estimators = 10)</pre><p>下一步是調整迴歸量並使用它進行預測。</p><pre>xg_reg.fit（X_train，y_train）preds = xg_reg.predict（X_test）</pre><p>在此之後，我們計算均方根誤差，以評估我們模型的性能。</p><pre>xg_reg.fit(X_train,y_train)preds = xg_reg.predict(X_test)</pre><p>使用XGBoost時的交叉驗證</p><p>使用交叉驗證使模型更加健壯是一種非常常見的做法。XGboost通過該cv() 函數支持K-fold驗證。我們將使用它來對我們的模型應用交叉驗證。</p><p>現在我們指定一個新的變量params來保存除n_estimators之外的所有參數，因為我們將使用cv()工具中的num_boost_rounds。cv()實用程序所取的參數如下所示:</p><ol><li>dtrain 是要訓練的數據。</li><li>params 指定booster 參數。</li><li>nfold 是交叉驗證函數中的folds 數。</li><li>num_boost_round 是boosting迭代的數量。</li><li>early_stopping_rounds 激活early stopping。CV error 需要至少每輪&lt;early_stopping_rounds>)減少才能繼續。</li><li>metrics 是交叉驗證中要觀察的評估指標。</li><li>as_pandas如果True將返回一個pandas dataframe; 如果為false，它將返回一個numpy數組。</li></ol><pre>params = {"objective":"reg:linear",'colsample_bytree': 0.3,'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10} cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,num_boost_round=50,early_stopping_rounds=10,metrics="rmse", as_pandas=True, seed=100</pre><p>該cv_results變量將返回訓練並測試每次boosting round的RMSE。最終 boosting round 指標可以如下獲得：</p><pre>print((cv_results["test-rmse-mean"]).tail(1))</pre><p>在XGBoost中可視化特徵重要性</p><p>您可能有興趣查看數據集中最重要的特徵。</p><p>XGBoost具有一個plot_importance()函數，使您可以查看數據集中按重要性排名的所有特徵。Python代碼如下：</p><pre>import matplotlib.pyplot as pltxgb.plot_importance(xg_reg)plt.rcParams['figure.figsize'] = [5, 5]plt.show()</pre><div class=pgc-img><img alt=在機器學習模型中使用XGBoost onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15369872842899e0dfafd0a><p class=pgc-img-caption></p></div><p>您可以使用上述可視化為機器學習模型選擇最相關的特徵。</p><p>結論</p><p>您可以使用其他技術（如網格搜索）來改進機器學習模型。Grid Search的工作原理是對estimator的指定參數值進行詳盡搜索。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>學習</a></li><li><a>XGBoost</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html alt=機器學習入門第2章：SVM（支持向量機）—編碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/28eb40e101e44cfb8b88aac745d012d6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f71cd4af.html title=機器學習入門第2章：SVM（支持向量機）—編碼>機器學習入門第2章：SVM（支持向量機）—編碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html alt=機器學習總結（基礎）：偏差和方差、iid、分佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/a9681e5f716547e288303eae292c5b3e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a55cbbea.html title=機器學習總結（基礎）：偏差和方差、iid、分佈>機器學習總結（基礎）：偏差和方差、iid、分佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html alt=機器學習數學篇—基礎數學知識清單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/59470000766ddb369113 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/41b2e34d.html title=機器學習數學篇—基礎數學知識清單>機器學習數學篇—基礎數學知識清單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html alt=機器學習之線性代數速查表 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/153089168574158dba8fa5a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fee3515e.html title=機器學習之線性代數速查表>機器學習之線性代數速查表</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html alt=使用機器學習的手寫數字識別 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1f78eeb0e00a46b789e4bcb4ad07d97b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6cc52e2b.html title=使用機器學習的手寫數字識別>使用機器學習的手寫數字識別</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html alt=專為機器學習打造的半導體器件：可進行任意邏輯運算 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4654f6d6a6dd496ebbf6787bb43a7231 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f575bcd3.html title=專為機器學習打造的半導體器件：可進行任意邏輯運算>專為機器學習打造的半導體器件：可進行任意邏輯運算</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html alt=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/ebc79c3aa76541b393374cc521297870 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fc9d01d7.html title=機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用>機器學習降維技術（PCA，ICA和流形學習）及醫學中流形學習的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html alt=基於機器學習在雙光子光刻過程中進行自動探測產品的質量 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7550407fa66941b2991e53b5a9ec4071 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dd736e73.html title=基於機器學習在雙光子光刻過程中進行自動探測產品的質量>基於機器學習在雙光子光刻過程中進行自動探測產品的質量</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html alt=機器學習中模型評估和選擇的一些問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/6c3b00005e98772353a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e33110be.html title=機器學習中模型評估和選擇的一些問題>機器學習中模型評估和選擇的一些問題</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3873d795.html alt=金融中的AI和機器學習：在銀行，保險，投資以及用戶體驗中的用例 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/694a9289cde541dca807f9a30d291d0d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3873d795.html title=金融中的AI和機器學習：在銀行，保險，投資以及用戶體驗中的用例>金融中的AI和機器學習：在銀行，保險，投資以及用戶體驗中的用例</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>