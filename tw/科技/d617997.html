<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ICML 2018｜模型層面的對偶學習 | 极客快訊</title><meta property="og:title" content="ICML 2018｜模型層面的對偶學習 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/15254155590772a5cdbae00"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d617997.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d617997.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d617997.html><meta property="article:published_time" content="2020-10-29T20:51:27+08:00"><meta property="article:modified_time" content="2020-10-29T20:51:27+08:00"><meta name=Keywords content><meta name=description content="ICML 2018｜模型層面的對偶學習"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/d617997.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ICML 2018｜模型層面的對偶學習</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15254155590772a5cdbae00><p>編者按：很多人工智能任務都具有對偶的性質，例如中文到英文翻譯和英文到中文翻譯、語音識別和語音合成等。基於此，微軟亞洲研究院在2016年提出了對偶學習，利用任務互為對偶的特點從無標註的數據中進行學習。事實上，對偶性不僅存在於數據層面，也存在於模型的層面。因此微軟亞洲研究院在ICML 2018上提出了一個全新的角度——在模型層面來研究對偶學習。模型層面的對偶學習能夠利用一個模型來解決一組對偶任務，該方法在神經機器翻譯和文本分析兩個任務上都被驗證了其有效性。</p><p>多個任務聯合學習被機器學習領域廣泛地接受，特別是在數據不足，或者任務之間關聯性很強的場景下。研究人員提出了多種不同的學習框架，例如多任務學習（multi-task learning）、遷移學習、對偶學習等。多任務學習的思想是讓多個相關任務之間通過參數共享的方式實現特徵表述，或是關係表述的共享，其能夠成功的原因在於<strong>多個任務之間知識能夠互相傳遞，從而提升了模型的泛化能力</strong>。遷移學習是另一種將知識在任務之間互相遷移的學習方法，目的是將一個已經學習好的模型遷移到另一個任務中。</p><p>微軟亞洲研究院機器學習組在NIPS 2016上提出的<strong>對偶學習事實上也是多個任務之間通過互相協作提高模型性能的工作</strong>。最初的對偶學習方法可以總結為數據層面的對偶，也就是所有的對偶信息都是通過數據為媒介傳遞的。而在很多任務中（例如神經機器翻譯、對話生成等），模型的不同部分已經具備了對偶的性質，以神經機器翻譯為例：通常的神經機器翻譯模型都是利用了編碼器-解碼器（encoder-decoder）的結構，我們在下圖抽象了以遞歸神經網絡（LSTM）為例的神經機器翻譯過程。</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531243508116c9f32acb5f><p>圖1 標準的基於編碼器-解碼器神經機器翻譯的結構（黑色框表示一個單位時間的延遲）</p><p>神經機器翻譯過程可以用如下數學公式描述：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124350795638fb1ec7b0><p>在原始任務中，編碼器</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15312435079848748932ba3><p>服務於編碼<em>x</em>而不需要任何外部條件；在對偶任務中，解碼器</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531243508194d7a7ea80a5><p>用於解碼<em>x</em>，基於得到的文本信息Z<sup>Y</sup>。也就是說，給定一對對偶任務，原始任務的編碼器和對偶任務的解碼器高度相關，因為它們都是為了處理同一種語言，只是依賴的條件不同。</p><p>受到多任務學習中共享表述的啟發，我們提出共享對偶任務中相關的模型參數，即對於神經機器翻譯，做如下設置：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243508209b3bf1a5747><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243508723980b3155c1><p>我們將這種方法稱為<strong>模型層面的對偶學習</strong>（model-level dual learning，縮寫為MDL）。</p><p>除了類似於神經機器翻譯這種嚴格對稱的模型，模型層面的對偶學習同樣適用於非對稱的機器學習任務。以情感分類為例，原始任務是判斷一個句子具有積極情感還是消極情感，解決這個任務的網絡結構是：輸入的句子會被長短期記憶網絡（LSTM）逐詞編碼得到隱狀態，而後這些隱狀態會被輸入到一個全連接網絡進行分類。對偶任務是給定一個標籤，生成具有特定感情色彩的回覆。在對偶任務中，標籤首先會被單詞嵌入投射到一個特定的空間，而後，另一個LSTM會基於這個標籤產生一個句子。在這個非對稱的任務中，原始任務的編碼器和對偶任務的解碼器可以被共享。這可以視為我們提出的模型的一種退化形式——只需要設置</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243508706d602af8fbb><p>。</p><p><strong>模型框架</strong></p><p>我們考慮建立在兩個空間<em>x</em>和<em>y</em>之間的對偶任務，其中，原始任務是學習映射<em>f:x</em>→<em>y</em>，對偶任務是學習反向的映射<em>g : y</em>→<em>x。</em></p><p>對於對稱的場景，<em>x</em>和<em>y</em>中的元素形式相同，因而有可能使用相同的模型結果來對對偶學習中的兩個任務進行建模。例如，在神經機器翻譯和Q&A中，<em>x</em>和<em>y</em>中元素都是自然語言的句子，因此我們都可以用LSTM來為<em>f</em>和<em>g</em>進行建模。</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243508680d7aa0c9fe4><p><em>X</em>-元素和<em>Y</em>-元素示意圖</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124350887927537705a9><p>原始模型，其中</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531243508896e118331ac4><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15312435092964991ca45b6><p>對偶模型，其中</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124350931484201cbfcd><p>圖2 對稱條件下，模型層面的對偶學習模型結構的有向圖（黑色的框表示一個單位的延遲，圖中結點對應變量，有向邊對應算子，其中箭頭指向的點為輸出，另一端為輸入）</p><p>在非對稱的場景中，<em>x</em>和<em>y</em>中的元素不對等，甚至語義空間也不同，因此，原始和對偶任務的模型也不盡相同。例如，在情感分類的任務中，<em>x</em>是自然語言的集合，而<em>y</em>是標籤的集合，例如，<em>y</em>={0,1}。<em>x</em>和<em>y</em>的異質性使得我們要使用不同的模型結構。</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531243509489f44cee9565><p>圖3 非對稱條件下模型層面對偶學習的框架</p><p>在模型層面的對偶學習中，<strong>原始模型和對偶模型的參數是共享的，意味著模型有著更少的參數</strong>，因此這種方法也可以看作是一種全新的模型壓縮的辦法。另外，對於給定的一對有標數據(x, y)，模型的每一部分都被更新兩次，分別來自原始任務和對偶任務。因此，<strong>相比於標準的有監督學習，數據會被利用的更加充分</strong>。最後，<strong>由於參數的共享，兩個模型的複雜度被降低了，因此會有更好的泛化能力</strong>。</p><p><strong>模型層面對偶學習在神經機器翻譯中的應用</strong></p><p>我們在神經機器翻譯任務中對模型層面的對偶學習方法進行測試，選用Transformer作為實驗的模型，Transformer是由一個基本模塊不斷堆疊得到的一個完整模型。一個基本模塊包括三個部分：（1）自我注意力機制，用於將底層的隱藏表達自適應地線性加權並提交給上一層；（2）編碼器-解碼器注意力機制：用於自適應地將編碼器端的隱藏表達加權得到相應地文本信息；（3）非線性變換層，用於對自我注意力機制和編碼器-解碼器注意力機制的輸出進行非線性變換。</p><p>下圖展示了Transformer中的基本模塊和前面介紹的模型的對應關係。</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15312435097024a40c5d170><p>圖4 模型層面的對偶學習在神經機器翻譯任務中的模型結構</p><p>該實驗中，我們選擇了三個廣泛應用的數據集作為訓練數據：</p><ul><li><p>IWSLT 2014的德英互譯的任務 (153k訓練數據)，簡記為IWSLT De↔En；</p></li><li><p>LDC的中英互譯任務(1.25M訓練數據)，簡記為Zh↔En；</p></li><li><p>WMT14的英德互譯任務(4.5M訓練數據)，簡記為WMT En↔De。</p></li></ul><p>測試數據：</p><ul><li><p>對於IWSLT De↔En，我們選用和表1列出的對比算法一樣的測試集；</p></li><li><p>對於Zh↔En，我們選用NIST2004、2005、2006、2008和2012作為測試集；</p></li><li><p>對於WMT En↔De，我們選取newstest14為測試集。</p></li></ul><p>我們將所有的實驗模型設置為6個模塊。對於IWSLTDe↔En任務，我們選擇transformer_small參數配置辦法，其餘兩個任務選擇的配置均為transformer_big。同時，我們使用對偶有監督學習作為對比算法。</p><p>IWSLT De↔En的實驗結果如下表：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124350989779cdef5b4d><p>表1 IWSLT De↔En的實驗結果</p><p>在IWSLT De↔En任務中，我們得到了德文到英文的最佳結果34.71。相比於基準算法Transformer，我們在原始任務德文到英文和對偶任務英文到德文上分別提高了1.85和0.90個點。相比於對偶有監督學習，我們的方法能夠分別獲得1.13和0.73個點的提升。</p><p>為了進一步探索新模型如何隨著模型複雜度變化而工作，我們研究了隨著網絡模塊數的變化，BLEU值的變化。我們分別測試了含有2、4、6、8個模塊的模型的BLEU值（注意每個模塊含有3層）。測試的結果如下圖所示：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243510920627a065102><p>圖5 BLEU隨著模型模塊數的變化</p><p>通過實驗，我們發現：</p><p>（1）對於不同的模塊數目以及不同的任務，我們提出的算法都能夠提高模型的性能；</p><p>（2）當模型的模塊數小於6的時候，在兩個方向的翻譯任務上，隨著模塊數的增加，模型層面的對偶學習提升的性能（圖中綠色部分）會提升。這說明，雖然更深的模型有更強的表達力，但可能會受到過擬合的影響，特別是在數據量比較小的IWSLT數據集上。我們提出的方法能將對偶性引入模型中約束模型空間，並且能夠更加充分地利用數據；</p><p>（3）即便是對於具有8個模塊的網絡，我們的方法仍然能夠提升模型性能，儘管沒有6個模塊帶來的提升明顯。在這種情況下，為了帶來更大的提升，我們需要引入更強的泛化性能的約束，例如採用對偶有監督學習。</p><p>中英互譯的結果如下表：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243511155c7b871015b><p>表2 中英互譯的實驗結果</p><p>在中文到英文的翻譯任務中，模型層面的對偶學習利用更簡單的模型和更少的數據，再一次取得了最好的效果。在Transformer的算法之上，我們的方法平均給每個數據集帶來1.21個點的性能提升，同時也超越了對偶有監督學習算法的表現。對於英文到中文的翻譯任務，相比於基準算法，我們的方法在每個數據集上平均取得0.69個點的增益。</p><p>最後，在WMT英德互譯的任務上，模型層面的對偶學習能夠在Transformer的基礎上將模型的性能進一步提升0.5個點。實驗結果如下表：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243510681bcfd645442><p>表3 WMT英德互譯的實驗結果</p><p><strong>模型層面的對偶學習在情感分析中的應用</strong></p><p>在情感分析中，原始任務是情感分類，對偶任務是帶有情感的句子生成<em>。x</em>是自然語言的集合，<em>y</em>是標籤的集合。因此，兩個空間的數據形式和語言完全不同。所以，我們要採用非對稱形式的模型層面的對偶學習。</p><p>我們在IMDB數據集上進行了驗證。我們選用標準的LSTM網絡作為原始任務和對偶任務模型的基本單元。模型的單詞嵌入和情感標籤的嵌入表達均為500維，隱藏層節點數為1024，詞表的大小是10k，Dropout的值設置為0.5。我們將softmax矩陣和單詞嵌入矩陣（包括單詞的和情感標籤的）共享。實驗結果如下表：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15312435105148813f29f75><p>表4 情感分析的實驗結果</p><p>在原始任務中，相比於標準的LSTM，模型層面的對偶學習能夠將錯誤率下降2.69個百分點；相比於對偶有監督學習，我們的方法也能將錯誤率下降1.79個百分點。在對偶任務中，模型層面的對偶學習能夠比對偶有監督學習下降3.19個點。</p><p><strong>與對偶推斷的結合</strong></p><p>對偶推斷是我們在IJCAI 2017上提出的將對偶性應用到推斷的過程中，用來提升已有對偶模型推斷/預測準確度的方法。為了進一步提升模型效果，我們將對偶推斷和模型層面對偶學習進行結合。</p><p>模型層面的對偶學習和對偶推斷結合的結果如下：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124351071908f1ef5286><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243511652f7bd54b8eb><p>和</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153124351177266e1665f51><p>分別對應原始任務和對偶任務的損失函數，</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1531243511719f1d607b6dc><p>和</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153124351159049d829544a><p>是經過驗證集確定的參數。</p><p>我們在IWSLT德英互譯任務上驗證了模型層面的對偶學習和對偶推斷結合的性能，實驗結果如下表：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15312435119061a7deaa82c><p>表5 模型層面對偶學習和對偶推斷結合在IWSLT德英互譯任務上的實驗結果（第三行表示標準的Transformer在標準推斷和對偶推斷的結果；第四行表示模型層面的對偶學習在標準推斷和對偶推斷下的結果）</p><p>可以看出，對偶推斷可以將我們提出的算法在兩個任務上分別提升0.48個點（德文到英文）和0.19個點（英文到德文）。對偶推斷也能為標準Transformer分別帶來0.66和0.10個點的提升。</p><p>我們同樣在情感分類任務中測試了模型層面對偶學習和對偶推斷結合的性能。下表展示了對偶推斷在IMDB數據集的分類錯誤率：</p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1531243512480fe87440cab><p>表6 模型層面對偶學習和對偶推斷結合在情感分類任務上的實驗結果</p><p>從表格中可以看出，在使用了對偶推斷之後，我們可以將錯誤率下降0.45個點。</p><p>總結來說，模型層面的對偶學習可以與數據層面的對偶學習形成互補。這種新的方法利用模型層面的對偶性來設計網絡結構，進而提升網絡性能。同時，模型層面的對偶學習可以用一個模型解決一組對偶任務，能夠起到節省參數量的作用。</p><p>瞭解更多細節，請訪問下面鏈接或點擊<strong>閱讀原文</strong>訪問我們的論文：</p><p>論文鏈接：</p><p>http://proceedings.mlr.press/v80/xia18a.html</p><p><strong>作者簡介</strong></p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/153124351237220a9d14a85><p>夏應策，中國科技大學2015博士生，在微軟亞洲研究院機器學習組實習。主要研究方向為對偶學習、神經機器翻譯以及深度學習算法設計。</p><p><strong>你也許還想看</strong><strong>：</strong></p><img alt="ICML 2018｜模型層面的對偶學習" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/15257688659625afe8005d1><p>感謝你關注“微軟研究院AI頭條”，我們期待你的留言和投稿，共建交流平臺。來稿請寄：msraai@microsoft.com。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ICML</a></li><li><a>2018</a></li><li><a>層面</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/81e23745.html alt=2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/9ea544b278cc4007bf1ea7c686f4af6a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/81e23745.html title=2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高>2018年中國虛擬現實行業規模超200億元，其中虛擬製造佔比最高</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7e39f460.html alt=太好了！2018志願填報“模板”來了，三分鐘定位院校不求人 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15274780975837f1bb5470f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7e39f460.html title=太好了！2018志願填報“模板”來了，三分鐘定位院校不求人>太好了！2018志願填報“模板”來了，三分鐘定位院校不求人</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5aff079a.html alt="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/1528975110519ee64a67c03 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5aff079a.html title="ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析">ACL 2018｜中科院軟件研究所：基於端到端語義圖生成的語義解析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f49d9179.html alt=2018年全國排化學中考複習二輪專項練習-物質的構成和分類 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/7dc6eb7a4299414a920f1987a1809095 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f49d9179.html title=2018年全國排化學中考複習二輪專項練習-物質的構成和分類>2018年全國排化學中考複習二輪專項練習-物質的構成和分類</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/816b04b7.html alt=從JVM層面帶你分析Java的Object類源碼第一部分 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/816b04b7.html title=從JVM層面帶你分析Java的Object類源碼第一部分>從JVM層面帶你分析Java的Object類源碼第一部分</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7e00dfe5.html alt="2018年12月以來上海日照時數創歷史新低 明天陽光上線" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/REtv8O37mCho3I style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7e00dfe5.html title="2018年12月以來上海日照時數創歷史新低 明天陽光上線">2018年12月以來上海日照時數創歷史新低 明天陽光上線</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fb27fd8d.html alt=2018鹿邑交警那些事，哪些更能讓你記憶深刻 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/R69u2M5GcN8qci style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fb27fd8d.html title=2018鹿邑交警那些事，哪些更能讓你記憶深刻>2018鹿邑交警那些事，哪些更能讓你記憶深刻</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1d114e79.html alt=阿榮旗2018年度“清風乾部”公示名單 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1d114e79.html title=阿榮旗2018年度“清風乾部”公示名單>阿榮旗2018年度“清風乾部”公示名單</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8dbdc94b.html alt=2018年質量、環境和職業健康安全管理體系程序文件（全套） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1538011762616c2e5d2f7a7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8dbdc94b.html title=2018年質量、環境和職業健康安全管理體系程序文件（全套）>2018年質量、環境和職業健康安全管理體系程序文件（全套）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cef67581.html alt=農哈哈2018款六行玉米大豆旋耕播種機 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/6c3700014cf434fa998d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cef67581.html title=農哈哈2018款六行玉米大豆旋耕播種機>農哈哈2018款六行玉米大豆旋耕播種機</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/03761e70.html alt=2018一建建造師機電工程必做題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/03761e70.html title=2018一建建造師機電工程必做題>2018一建建造師機電工程必做題</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/890f9192.html alt=2018年中國RV減速機行業競爭格局及供需現狀分析「圖」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e486fa0206e34414a4a55317b6c0aa6e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/890f9192.html title=2018年中國RV減速機行業競爭格局及供需現狀分析「圖」>2018年中國RV減速機行業競爭格局及供需現狀分析「圖」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0495ea53.html alt=刷題｜2018二建實務，考前模擬（5.30） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1527650084831cdb85abefa style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0495ea53.html title=刷題｜2018二建實務，考前模擬（5.30）>刷題｜2018二建實務，考前模擬（5.30）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bfc06696.html alt=2018中國顯示學術會議行程即將開啟，會務組溫馨提示 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15369954349373c6f6b1355 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bfc06696.html title=2018中國顯示學術會議行程即將開啟，會務組溫馨提示>2018中國顯示學術會議行程即將開啟，會務組溫馨提示</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/db890d60.html alt=2018年度最具實用價值的10個光學實驗經驗 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f83c6e7c0b204acebb859b60ca4a5cb1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/db890d60.html title=2018年度最具實用價值的10個光學實驗經驗>2018年度最具實用價值的10個光學實驗經驗</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>