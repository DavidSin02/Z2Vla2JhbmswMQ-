<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>手工打造神經網絡：透視分析 | 极客快訊</title><meta property="og:title" content="手工打造神經網絡：透視分析 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/6ee200033390f3f6b2ca"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/d7196c1.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/d7196c1.html><meta property="article:published_time" content="2020-10-29T21:05:34+08:00"><meta property="article:modified_time" content="2020-10-29T21:05:34+08:00"><meta name=Keywords content><meta name=description content="手工打造神經網絡：透視分析"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/d7196c1.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>手工打造神經網絡：透視分析</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1>內容導讀</h1><blockquote><p>MNIST只包含70000張28x28像素的手寫數字的單通道灰度圖，對於現在的算力來說是很小的數據。我定義一個模型訓練函數，目標是不斷優化權重和偏差得到最佳組合。現在輸入層到隱藏層我選擇了ReLu作為激活函數，從圖形中看出它具備左側硬飽和的特性。接下來自然就會思考，權重和偏差如何迭代優化呢? 首先正向傳播計算出output_layer節點，用損失函數計算一下和標註y的差距，根據損失大小返回來修正權重和偏差，這個通過鏈式法則對多層複合函數求導的過程就是反向傳播，其目標就是要最小化訓練集上的累積誤差。第二種方式是每跑訓練集中的一條數據就計算損失函數並更新參數，速度比較快，但收斂性不太好，可能會出現較多毛刺在最優點附近搖擺。完成模型訓練代碼後可以再定義一個交叉熵損失函數來觀察收斂效果，迭代到三五千次的時候其實已經差不多了，後面的幾萬次學習依然會不時出現一些毛刺影響準確率。</p></blockquote><p>MNIST就是機器學習的Hello World, 或者說圖片處理的Lena, 是必不可少的經典初體驗。它已有20多年的歷史，但是到今天依然魅力不減，依然是最高引用的數據集。MNIST只包含70000張28x28像素的手寫數字的單通道灰度圖，對於現在的算力來說是很小的數據。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee200033390f3f6b2ca></p><p>Denise Krebs on Flickr</p><p>網上大多數的MNIST教程，包括TensorfFlow官方教程帶給我們的都是一種自然主義的學習體驗，給出代碼示例簡單教會步驟，對著代碼敲一下就能運行，畢竟參與感不夠。從結構主義的學習方式來看，我們應該至少嘗試一次不用任何深度學習的現成框架，純手工從零開始實現一次神經網絡，並且打開其中的黑盒，以可視化的呈現方式形象理解神經網絡如何工作，這就是我寫此文的目的。</p><p><strong>數據準備 (Data Preparation)</strong></p><p>MNIST數據集中Train dataset有60000張圖片與相應的標註，其中55000張訓練集，5000張驗證集(Validation)，Test dataset有10000張訓練集，下載完這四個文件後我保存到MNIST-data目錄下。</p><blockquote><p>train-images-idx3-ubyte.gz: training set images (9912422 bytes)<br>train-labels-idx1-ubyte.gz: training set labels (28881 bytes)<br>t10k-images-idx3-ubyte.gz: test set images (1648877 bytes)<br>t10k-labels-idx1-ubyte.gz: test set labels (4542 bytes)</p></blockquote><p>數據集就是這麼四個文件，都是特殊的Binary格式。解析起來費點功夫，不過TensorFlow已封裝好了便利的接口 - input_data.read_data_sets。雖然這次我不用TensorFlow框架的神經網絡，但是解析數據部分借用一下無妨。這個函數會自動嘗試下載數據集到指定目錄中，不過強烈建議自己手工下載好這四個文件，由於不可描述的原因，用這個方法直接下載數據基本都是以time out失敗告終。第一個參數是指定的數據集存放路徑，第二個參數決定是否以獨熱鍵(one-hot)形式讀取標籤，如果設為True則以10維向量形式代表一個數字。</p><blockquote><p>mndata = input_data.read_data_sets("MNIST-data/", one_hot=True)</p></blockquote><p>分別獲取訓練集和測試集的圖片和標註</p><blockquote><p>X_train=mndata.train.images # training set<br>y_train=mndata.train.labels<br>X_test=mndata.test.images # testing set<br>y_test=mndata.test.labels</p></blockquote><p>然後寫一個畫圖的函數，讀取矩陣數據在表格中展示，僅展示非0數字且保留兩位小數。</p><blockquote><p># visualize grid data of a matrix, zero cell shown as empty<br>def plt_grid(data):<br>fig, ax = plt.subplots()<br>fig.set_size_inches(30,30)<br>width, height = data.shape</p><p>#imshow portion<br>imshow_data = np.random.rand(width, height)<br>ax.imshow(imshow_data, cmap=plt.cm.Pastel1, interpolation='nearest')</p><p>for x in range(0, height):<br>for y in range(0, width):<br>if (data[y][x]>0):<br>ax.text(x, y, np.round(data[y][x],2), va='center', ha='center', fontsize=20)<br>plt.show()</p></blockquote><p>隨便找個吉利數字88作為index, 從訓練集中抽一張圖片打印原始數據看看這個28x28的矩陣裡到底存放了什麼</p><blockquote><p>plt_grid(X_train[88].reshape(28,28))</p></blockquote><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25df9767538></p><p>數字3</p><p>非0的數值本身就已經能看到數字的形狀了，是個3. 數值越接近1表示顏色越白，邊緣的顏色應該是比較灰的，而背景數值為0自然就是黑色。</p><p>打印相應的標籤出來也是3: [ 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]</p><p>下面我再直接把圖片抽出來打印對比一下，果不其然, 和上圖長的一模一樣。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25e98f04787></p><p><strong>網絡架構 (Network Layouts)</strong></p><p>數據準備好後就開始設計神經網絡了, 簡單一點就三層: input layer, hidden layer, output layer</p><p>input layer(輸入層)的節點就是要餵給神經網絡的像素值，共784個節點。</p><p>hidden layer(隱藏層)可以讓網絡在抽象層次上學習特徵，雖然我只放一層，但是也可以有多層。少量隱藏層會得到淺層神經網絡SNN，隱藏層很多時就是深層神經網絡DNN。理論上，單隱藏層神經網絡也可以逼近任何連續函數，只要神經元數量夠多。如果增加隱藏層或者隱藏層神經元的數量，神經網絡的容量會變大，空間表達能力會變強，但如果太多的話也容易過擬合。先暫定15個節點吧。</p><p>output layer(輸出層)有10個節點，因為圖片要分類映射到十個數字上。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee50002bef9200dccef></p><p>Neural Network and Deep Learning</p><p><strong>權重和偏差 (Weights and Bias)</strong></p><p>上圖中兩個神經元之間的每一條連線都代表一個權重值，神經網絡通過不斷調整權重來逼近結果。首先把一組權重應用在input layer的節點上，加上偏差值後得到hidden layer的節點，然後對hidden layer的節點應用另一組權重，加上偏差值後最終得到output layer的節點。</p><p>先設置一下兩組權重和偏差的初始值，後面再看如何更新這些權重和偏差。我定義一個模型訓練函數，目標是不斷優化權重和偏差得到最佳組合。第一組權重是一個784 x 15的矩陣，第二組權重是一個15 x 10的矩陣，用隨機函數生成一堆0到1之間的浮點數值，偏差就先都設為0. 兩組權重都除以5是我在調參過程中發現初始權重數值要更小一些效果比較好，隨便拍的一個數。</p><blockquote><p>input_layer_size = 28 * 28<br>hidden_layer_size = 15<br>output_layer_size = 10</p><p>def train_model():<br># init weights and bias<br>np.random.seed(1)<br>W1 = np.random.random([input_layer_size, hidden_layer_size])/5 # 784 x 15<br>b1 = np.zeros((1, hidden_layer_size))<br>W2 = np.random.random([hidden_layer_size, output_layer_size])/5 # 15 x 10<br>b2 = np.zeros((1, output_layer_size))</p></blockquote><p>現在可以把權重W1也打印出來看看，我只拿輸入層第一個節點和隱藏層第一個簡單之間的一根線來查看。可以看到都是非常微小的隨機數字，最大不會超過0.2</p><blockquote><p>plt_grid(W1.T[0].reshape(28,28))</p></blockquote><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee400030db6324f2555></p><p>第一條線權重</p><p>後來在訓練50000次之後可以用plt將十個數字權重的熱力圖可視化呈現:</p><blockquote><p>for i in range(10):<br>plt.subplot(2, 5, i+1)<br>weight = W1[:,i]<br>plt.title(i)<br>plt.imshow(weight.reshape([28,28]), cmap=plt.get_cmap('seismic'))<br>frame1 = plt.gca()<br>frame1.axes.get_xaxis().set_visible(False)<br>frame1.axes.get_yaxis().set_visible(False)</p></blockquote><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee2000333910cb8c03c></p><p>Weight Heatmap</p><p><strong>激活函數 (Activation Function)</strong></p><p>Montreal 大學的 Bengio 教授在 ICML 2016 中給出了激活函數定義: 激活函數是映射 h:R→R，且幾乎處處可導。</p><p>引入激活函數是為了將權值轉化為分類結果，有多重選擇: Sigmoid(S型), Tanh(雙切正切), ReLu(只保留非零), Softmax(歸一化) etc. 這些常用的激活函數多數都是非線性的，為了彌補線性函數區分度不夠好的短板，而且激活函數要能保證數據輸入與輸出也是可微的。本來我嘗試用Sigmoid作為激活函數，但是可能由於我的實現方式導致效果不好，準確率到70%多我就優化不下去了，可能它本身由於軟飽和性也容易出現梯度消失的問題，只好暫時放棄。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee400030db7c8a5f18f></p><p>上面這句話我再解釋一下，Sigmoid就是處處可導的S型曲線，且兩側導數趨近於0，所以它是一個軟飽和函數，而且左右兩側都是軟飽和。一旦落入了軟飽和區f'(x)就接近於0了，無法再繼續傳遞梯度，這就是所謂的梯度消失。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b641874e0002></p><p>Sigmoid圖形</p><p>現在輸入層到隱藏層我選擇了ReLu作為激活函數，從圖形中看出它具備左側硬飽和的特性。</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee50002befac5b3752a></p><p>ReLu Formula</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee60001d25f8187a1ea></p><p>ReLu 圖形</p><p>代碼實現如下</p><blockquote><p>def relu(x):<br>return np.maximum(x, 0)</p></blockquote><p>從隱藏層到輸出層我選擇了softmax作為激活函數</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b6427c984347></p><p>Softmax Formula</p><p>序列中最大的那個數映射的分量逼近於 1, 其他就逼近於 0，非常適合多分類問題。取指數是為了讓馬太效應凸顯，大數進一步放大，同時也滿足了可導函數的需求。</p><p>Softmax代碼實現如下 (如果出現overflow的話可以參考scikit-learn源碼的實現方式)</p><blockquote><p>def softmax(x):<br>e_x = np.exp(x - np.max(x))<br>return e_x / e_x.sum()</p></blockquote><p><strong>正向傳播(Forward Propagation)</strong></p><p>正向傳播的計算就是把輸入層到隱藏層的節點與權重和偏差結合，計算出輸出層節點的過程。<br>對於這個三層網絡，假定x是包含一個單一訓練樣本的列向量。則向量化的正向傳播步驟如下：(這個圖我畫完以後感覺用更嚴謹的方式來描述的話，四個標註應該是隱藏層的輸入，隱藏層的輸出，輸出層的輸入，輸出層的輸入，但懶得改圖了)</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee200033392be486202></p><p>Forward Propagation</p><p>假設我要訓練50000次，train_model方法中加入正向傳播的循環代碼實現如下</p><blockquote><p>batch= 50000<br>for i in range(0, batch):<br>X = X_train[i]<br>y = y_train[i]</p><p>input_layer = X.dot(W1)<br>hidden_layer = relu(input_layer + b1)<br>output_layer = np.dot(hidden_layer, W2) + b2<br>output_probs = softmax(output_layer)</p></blockquote><p>我還是繼續拿index為88的數字3圖片為例看看各層是什麼數字</p><p>input_layer是輸入層矩陣與權重1矩陣相乘得到15維向量</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b643db70a946></p><p>input_layer</p><p>hidden_layer是上一層加上偏差1作為ReLu的輸入計算出來的, 維度同上</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/6ee10003f4e8682c1c90></p><p>Hidden Layer</p><p>此時權重2是15x10的矩陣</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee60001d260fa9e6fff></p><p>W2</p><p>權重2和hidden_layer矩陣相乘加上偏差2得到十維向量output_layer, 這裡最大的數字是第九位的20.09</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/6ee2000333933ca14ae4></p><p>output_layer</p><p>output_layer作為softmax輸入計算後得到最終結果output_probs, 第九位被轉成了非常接近1的一個小數，也是序列中最大的數字。這是訓練之初的數值，實際上最大的數字應該在第四位，所以此時誤差比較大。大概在學習3000次之後已經能較大概率的在第四位逼近1</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee50002befb6df58064></p><p>output_probs</p><p><strong>反向傳播 (Backward Propagation)</strong></p><p>接下來自然就會思考，權重和偏差如何迭代優化呢? 首先正向傳播計算出output_layer節點，用損失函數計算一下和標註y的差距，根據損失大小返回來修正權重和偏差，這個通過鏈式法則對多層複合函數求導的過程就是反向傳播，其目標就是要最小化訓練集上的累積誤差。</p><p>在前文"<a target=_blank>人工神經元是如何模擬生物神經元的</a>"中我提到機器學習需要不斷調整weight和bias來逐步逼近預期的輸出值，<strong>而且必須保證weight和bias的微小變化也只會帶來輸出值的微小變化.</strong></p><p>調參的過程就像打高爾夫一樣，目標是以最少的杆數將球打進洞，如果過於謹慎可能耗費的杆數太多，如果太過激進可能球被打進了沙池或者水坑，欲速則不達。每一杆都要讓球離球洞更近，進入果嶺的時候還要確保不要用力過度讓球跑過頭了。(見下文<strong>學習率</strong>)</p><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee70000b6445aa7d4e4></p><p>在train_model方法中繼續實現這個逆向過程, 計算輸出層的error, 再將此error逆向傳播到隱藏層，最後根據隱藏層的error來對連接權重與偏差進行調整，迭代循環下去不斷更新讓error收斂。核心邏輯是梯度下降的算法，這裡有三種選擇: 批量梯度下降(Batch Gradient Descent)，隨機梯度下降(Stochastic Gradient Descent)和小批量梯度下降。</p><p>第一種方式遍歷完整訓練集算出一個損失函數，然後更新參數再跑一次完整訓練集，如此迭代循環，所以計算量很恐怖。第二種方式是每跑訓練集中的一條數據就計算損失函數並更新參數，速度比較快，但收斂性不太好，可能會出現較多毛刺在最優點附近搖擺。最後一個是前兩者的這種方案，既不是跑全量數據而不是跑單個數據，而是拿一小批數據來計算損失函數更新參數。我先用SGD來跑，後面可以通過圖像看到毛刺的問題。</p><p>用數學語言來描述，梯度下降算法的核心是<strong>多元函數求微</strong>，針對每一個變量都分別求微，每一次迭代都用多元函數減去多元函數的微分與學習率的乘積。下面代碼中第一行設置的參數是學習率，這個參數是要在精度和速度之間找到平衡，學習率太大則訓練的快但精度不夠(每次擊球都很大力)，學習率太小則提升精度但過於耗費時間(每次擊球都小心翼翼輕輕揮杆保證精準)，這裡設置的學習率是固定的，這樣的靜態設置顯然不會是最佳選擇，不過處於學習目的也夠了。</p><blockquote><p>learning_rate = .01<br>reg_lambda = .01</p><p>output_error = (output_probs - y) / output_probs.shape[0]</p><p>hidden_error = np.dot(output_error, W2.T)<br>hidden_error[hidden_layer &lt;= 0] = 0</p><p># gradient layer2 weights and bias<br>g2_weights = np.dot(hidden_layer.T, output_error)<br>g2_bias = np.sum(output_error, axis = 0, keepdims = True)</p><p># gradient layer1 weights and bias<br>g1_weights = np.dot(X.reshape(input_layer_size,1), hidden_error)<br>g1_bias = np.sum(hidden_error, axis = 0, keepdims = True)</p><p># gradient descent parameter update<br>W1 -= learning_rate * g1_weights<br>b1 -= learning_rate * g1_bias<br>W2 -= learning_rate * g2_weights<br>b2 -= learning_rate * g2_bias</p></blockquote><p><strong>正則化干擾 (Regularization Terms)</strong></p><p>為了讓擬合效果更好可以在error後面加入正則干擾項, 讓模型和樣本不要完全擬合，當出現欠擬時干擾項的影響要小，當出現過擬時干擾項的影響要大。reg_lambda就是設置的擬合參數，所以可以在更新w和b之前再加兩行代碼。</p><blockquote><p># add regularization terms<br>g2_weights += reg_lambda * W2<br>g1_weights += reg_lambda * W1</p></blockquote><p><strong>預測函數</strong></p><p>這個邏輯很簡單，和訓練集的正向傳播完全一樣，只不過輸入參數換成測試集數據，代入已經訓練好的權重和偏差，統計正確預測的比例。</p><blockquote><p>input_layer = np.dot(X_test[:10000], W1)<br>hidden_layer = relu(input_layer + b1)<br>scores = np.dot(hidden_layer, W2) + b2<br>probs = softmax(scores)<br>print ('Test accuracy: {0}%'.format(accuracy(probs, y_test[:10000])))</p></blockquote><p>完成模型訓練代碼後可以再定義一個交叉熵損失函數來觀察收斂效果，迭代到三五千次的時候其實已經差不多了，後面的幾萬次學習依然會不時出現一些毛刺影響準確率。</p><blockquote><p>def cross_entropy_loss(probs, y_onehot):<br>indices = np.argmax(y_onehot, axis = 0).astype(int)<br>predicted_prob = probs[np.arange(len(probs)), indices]<br>log_preds = np.log(predicted_prob)<br>loss = -1.0 * np.sum(log_preds) / len(log_preds)<br>return loss</p></blockquote><p><img alt=手工打造神經網絡：透視分析 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/6ee200033394c684d879></p><p>最後把上面的代碼重構一下整合起來貼出完整代碼(不包含調試打印圖片和日誌)，預測準確率90%, 下一篇我將改用TensorFlow對Fashion MNIST預測，並提升準確率。</p><blockquote><p>import numpy as np</p><p>from tensorflow.examples.tutorials.mnist import input_data</p><p>import matplotlib.pyplot as plt</p><p>mndata = input_data.read_data_sets("MNIST-data/", one_hot=True)</p><p>X_train=mndata.train.images # training set</p><p>y_train=mndata.train.labels</p><p>X_test=mndata.test.images # testing set</p><p>y_test=mndata.test.labels</p><p>input_layer_size = 28 * 28</p><p>hidden_layer_size = 15</p><p>output_layer_size = 10</p><p>reg_lambda = .01</p><p>learning_rate = .01</p><p># visualize grid data of a matrix, zero cell shown as empty</p><p>def plt_grid(data):</p><p>fig, ax = plt.subplots()</p><p>fig.set_size_inches(30,30)</p><p>width, height = data.shape</p><p>#imshow portion</p><p>imshow_data = np.random.rand(width, height, 2)</p><p>ax.imshow(imshow_data, cmap=plt.cm.Pastel1, interpolation='nearest')</p><p>for x in range(0, height):</p><p>for y in range(0, width):</p><p>if (data[y][x]>0):</p><p>ax.text(x, y, np.round(data[y][x],8), va='center',</p><p>ha='center', fontsize=20)</p><p>plt.show()</p><p>def softmax(x):</p><p>e_x = np.exp(x - np.max(x))</p><p>return e_x / e_x.sum()</p><p>def relu(x):</p><p>return np.maximum(x, 0)</p><p>def cross_entropy_loss(probs, y_onehot):</p><p>indices = np.argmax(y_onehot, axis = 0).astype(int)</p><p>predicted_prob = probs[np.arange(len(probs)), indices]</p><p>log_preds = np.log(predicted_prob)</p><p>loss = -1.0 * np.sum(log_preds) / len(log_preds)</p><p>return loss</p><p># init weights and bias</p><p>def init_weights_bias():</p><p>np.random.seed(1)</p><p>W1 = np.random.random([input_layer_size, hidden_layer_size])/5 # 784 x 15</p><p>b1 = np.zeros((1, hidden_layer_size))</p><p>W2 = np.random.random([hidden_layer_size, output_layer_size])/5 # 15 x 10</p><p>b2 = np.zeros((1, output_layer_size))</p><p>model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}</p><p>return model</p><p># derivative weights and bias</p><p>def derivative_weights_bias(output_error, hidden_layer, X, model):</p><p>W1, _, W2, _ = model['W1'], model['b1'], model['W2'], model['b2']</p><p>hidden_error = np.dot(output_error, W2.T)</p><p>hidden_error[hidden_layer &lt;= 0] = 0</p><p># gradient layer2 weights and bias</p><p>g2_weights = np.dot(hidden_layer.T, output_error)</p><p>g2_bias = np.sum(output_error, axis = 0, keepdims = True)</p><p># gradient layer1 weights and bias</p><p>g1_weights = np.dot(X.reshape(input_layer_size,1), hidden_error)</p><p>g1_bias = np.sum(hidden_error, axis = 0, keepdims = True)</p><p># add regularization terms</p><p>g2_weights += reg_lambda * W2</p><p>g1_weights += reg_lambda * W1</p><p>param = { 'dW1': g1_weights, 'db1': g1_bias, 'dW2': g2_weights, 'db2': g2_bias}</p><p>return param</p><p>def forward_propagation(X, model):</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p>input_layer = np.dot(X, W1)</p><p>hidden_layer = relu(input_layer + b1)</p><p>output_layer = np.dot(hidden_layer, W2) + b2</p><p>probs = softmax(output_layer)</p><p>return probs, hidden_layer</p><p>def accuracy(predictions, labels):</p><p>preds_correct_boolean = np.argmax(predictions, 1) == np.argmax(labels, 1)</p><p>correct_predictions = np.sum(preds_correct_boolean)</p><p>accuracy = 100.0 * correct_predictions / predictions.shape[0]</p><p>return accuracy</p><p>#predict test set</p><p>def predict(X, model):</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p>input_layer = np.dot(X_test[:10000], W1)</p><p>hidden_layer = relu(input_layer + b1)</p><p>output_layer = np.dot(hidden_layer, W2) + b2</p><p>probs = softmax(output_layer)</p><p>print ('Test accuracy: {0}%'.format(accuracy(probs, y_test[:10000])))</p><p># - batch: Size of passes through the training data for gradient descent</p><p>def train_model(batch, X, y):</p><p>model = init_weights_bias()</p><p>W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']</p><p># Gradient descent. For each batch...</p><p>for i in range(0, batch):</p><p>output_probs, hidden_layer = forward_propagation(X[i], model)</p><p>output_error = (output_probs - y[i]) / output_probs.shape[0]</p><p>param = derivative_weights_bias(output_error, hidden_layer, X[i], model)</p><p>dW1, db1, dW2, db2 = param['dW1'], param['db1'], param['dW2'], param['db2']</p><p># gradient descent parameter update</p><p>W1 -= learning_rate * dW1</p><p>b1 -= learning_rate * db1</p><p>W2 -= learning_rate * dW2</p><p>b2 -= learning_rate * db2</p><p>model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}</p><p>loss = cross_entropy_loss(output_probs, y[i])</p><p>if (i % 2000 == 0):</p><p>print('loss @ %d is %f' % (i, loss))</p><p>return model</p><p>model = train_model(50000, X_train[:50000], y_train[:50000])</p><p>predict(X_test[:10000], model)</p></blockquote><p><em>References:</em></p><p><em><a rel=nofollow target=_blank>Neural Network Vectorization</a></em></p><p><em><a rel=nofollow target=_blank>Neural Network and Deep Learning</a></em></p><p><em>Not another MNIST tutorial with TensorFlow OReilly Media</em></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>神經</a></li><li><a>網絡</a></li><li><a>透視</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html alt=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/65c4000bda98898dcdbb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html title=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼>谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html alt=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/470f0001d893b2ad09e2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fd4c22a3.html title=你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮>你還不知道神經網絡是啥？十分鐘教你跟上人工智能熱潮</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html alt=神經網絡與圖靈機的複雜度博弈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/4af200040ff1f5233c1c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5d2a6211.html title=神經網絡與圖靈機的複雜度博弈>神經網絡與圖靈機的複雜度博弈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html alt=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/3c0b503678da4b15be05f6f56c0d213f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cc9d1be9.html title=基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成>基於二維材料、用於人工神經網絡的高密度憶阻陣列的晶圓級集成</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/6062a4c0.html alt=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6d474536ff3d4b1fba0cbfc85968ff6f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/6062a4c0.html title=BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界>BP神經網絡的線性本質的理解和剖析-卷積小白的隨機世界</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/f149efd9.html alt=用於調整深度神經網絡的簡單參考指南 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15379529924702cde52ac04 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/f149efd9.html title=用於調整深度神經網絡的簡單參考指南>用於調整深度神經網絡的簡單參考指南</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html alt=貝葉斯神經網絡(系列)：第二篇 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RKYlnth9DPo8ac style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0396dba3.html title=貝葉斯神經網絡(系列)：第二篇>貝葉斯神經網絡(系列)：第二篇</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html alt=針對深度神經網絡的簡單黑盒對抗攻擊 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b9ec712cd33442338496141ebfcecb45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a4bbdd29.html title=針對深度神經網絡的簡單黑盒對抗攻擊>針對深度神經網絡的簡單黑盒對抗攻擊</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html alt=模式識別與神經網絡的發展 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1523254283784d3d276a90f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cafcc06.html title=模式識別與神經網絡的發展>模式識別與神經網絡的發展</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html alt=BP神經網絡學習筆記 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fc5cec456c184c48b1ee22a233b9ee0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcf9e89.html title=BP神經網絡學習筆記>BP神經網絡學習筆記</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html alt=機器學習：神經網絡學習之多層前饋神經網絡（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a0a4cd0f7d9244a6a12da3c0af6893a5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9f3924a.html title=機器學習：神經網絡學習之多層前饋神經網絡（一）>機器學習：神經網絡學習之多層前饋神經網絡（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html alt=機器學習：神經網絡學習之多層前饋神經網絡（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/2d53a815-ab09-4da3-94a2-5b6843366e3a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/556321d.html title=機器學習：神經網絡學習之多層前饋神經網絡（二）>機器學習：神經網絡學習之多層前饋神經網絡（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html alt=一文幫你梳理清楚深度神經網絡的基礎知識！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2f16bcb220e14085a04994454ea4998a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/f3732f4.html title=一文幫你梳理清楚深度神經網絡的基礎知識！>一文幫你梳理清楚深度神經網絡的基礎知識！</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/2d00c65.html alt=理解神經網絡 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15409758920775d7570f483 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/2d00c65.html title=理解神經網絡>理解神經網絡</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>