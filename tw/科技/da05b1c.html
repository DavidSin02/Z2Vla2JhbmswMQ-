<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>迴歸分析不可不知的關鍵詞和統計量 | 极客快訊</title><meta property="og:title" content="迴歸分析不可不知的關鍵詞和統計量 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/RBWOS40F2Bbyso"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/da05b1c.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/da05b1c.html><meta property="article:published_time" content="2020-10-29T21:01:05+08:00"><meta property="article:modified_time" content="2020-10-29T21:01:05+08:00"><meta name=Keywords content><meta name=description content="迴歸分析不可不知的關鍵詞和統計量"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/da05b1c.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>迴歸分析不可不知的關鍵詞和統計量</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>“愛數據學習社”訂閱我吧!-</strong></p><p><strong>迴歸分析關鍵詞</strong></p><p><strong>1、迴歸（regression）</strong>：發生倒退或表現倒退；常指趨於接近或退回到中間狀態。在線性迴歸中，迴歸指各個觀察值都圍繞、靠近估計直線的現象。</p><p><strong>2、多元迴歸模型（multiple regression model）</strong>：包含多個自變量的迴歸模型，用於分析一個因變量與多個自變量之間的關係。它與一元迴歸模型的區別在於，多元迴歸模型體現了統計控制的思想。</p><p><strong>3、因變量（dependent variable）</strong>：也稱為依變量或結果變量，它隨著自變量的變化而變化。從試驗設計角度來講，因變量也就是被試的反應變量，它是自變量造成的結果，是主試觀測或測量的行為變量。</p><p><strong>4、自變量（independent variable）</strong>：在一項研究中被假定作為原因的變量，能夠預測其他變量的值，並且在數值或屬性上可以改變。</p><p><strong>5、隨機變量（random variable）</strong>：即隨機事件的數量表現。這種變量在不同的條件下由於偶然因素影響，可能取各種不同的值，具有不確定性和隨機性，但這些取值落在某個範圍的概率是一定的。</p><p><strong>6、連續變量（continuous variable）</strong>：在一定區間內可以任意取值的變量，其數值是連續不斷的，相鄰兩個數值可作無限分割，即可取無限個數值，比如身高、體重等。</p><p><strong>7、名義變量（nominal variable）</strong>：本身的編碼不包含任何具有實際意義的數量關係，變量值之間不存在大小、加減或乘除的運算關係。</p><p><strong>8、截距（intercept）</strong>：函數與y座標軸的相交點，即迴歸方程中的常數項。</p><p><strong>9、斜率（slope）</strong>：即迴歸方程中各自變量的係數。它表示自變量一個單位的變化所引起的因變量的變化量，如果是線性模型，則在座標圖上表現為兩個變量擬合直線之斜率。</p><p><strong>10、偏效應（partial effect）</strong>：在控制其他變量的情況下，或者說在其他條件相同的情況下，各自變量X對因變量Y的淨效應（net effect）或獨特效應（unique effect）。</p><p><strong>11、效應幅度（size of effect）</strong>：指反映變量作用大小的具體數值。一個變量的係數可能在統計上顯著地區別於0，但是該係數的值卻不大，即效應幅度很小，從而不具有很大的實質性意義。</p><p><strong>12、擬合優度（goodness of fit）</strong>：指回歸模型對觀察數據的概括擬合程度，反映的是模型的效率，即模型在多大程度上解釋了因變量的變化。</p><p><strong>13、誤差（error）</strong>：指可以避免或不可避免的觀測值和真實值之間的差。</p><p><strong>14、預測值（predicted values）</strong>：通過根據估計的迴歸模型代入解釋變量觀察值後計算得到的因變量值。</p><p><strong>15、總平方和（sum of squares total）</strong>：即因變量觀察值與其平均值的離差平方和，是需要解釋的因變量的變異總量。</p><p><strong>16、殘差平方和（sum of squares error）</strong>：因變量觀察值與對應的迴歸模型預測值的離差平方和。是觀察值落在迴歸線（面）之外而引起的，是模型中各自變量對因變量線性影響之外的其他因素對因變量總平方和的影響。</p><p><strong>17、迴歸平方和（sum of squares regression）</strong>：通過迴歸模型計算得到的因變量預測值與因變量觀察值的均值的離差平方和。這是由自變量變化引起的，是迴歸模型所解釋的部分。</p><p><strong>18、均方（mean square）</strong>：離差平方和除以相應的自由度即可得到均方。在迴歸分析中，研究者感興趣的是迴歸均方（mean square regression，簡寫為MSR）和均方誤（mean square error，簡寫為MSE）。</p><p><strong>19、判定係數（coefficient of determination）</strong>：迴歸平方和佔總平方和的比例，記為R2。通常把它理解為迴歸方程解釋掉的平方和佔其總平方和的比例。判定係數被用來作為對方程擬合優度進行測量的指標，取值在[0，1]之間，值越大表明迴歸方程的解釋能力越強。</p><p><strong>20、判定係數增量（increamental R2）</strong>：在原有迴歸模型基礎上，通過加入新的自變量所帶來的判定係數的增加量。</p><p><strong>21、嵌套模型（nested models）</strong>：如果一個模型（模型一）中的自變量為另一個模型（模型二）中自變量的子集或子集的線性組合，我們就稱這兩個模型是嵌套模型。模型一稱為限制性模型（restricted model），模型二稱為非限制性模型（unrestricted model）。限制性模型嵌套於非限制性模型中。</p><p><strong>22、虛擬編碼（dummy coding）</strong>：依據名義變量各類別對其進行重新編碼從而令其能夠作為自變量納入迴歸方程的編碼方式。對於一個包含J個類別的名義變量，理論上可以得到J個取值為0或1的虛擬變量，但在迴歸分析中，通常只建構J-1個虛擬變量”。每一虛擬變量對應著原名義變量的一個類別，如果屬於該類別則虛擬變量取值為1，否則取值為0。</p><p><strong>23、虛擬變量（dummy variable）</strong>：也稱作指示變量（indicator），取值為0或1的變量，故也被稱作0-1變量。</p><p><strong>24、二分變量（dichotomous variable）</strong>：即只有兩種可能取值的變量，如性別。</p><p><strong>25、參照組（reference group）</strong>：被排除出迴歸模型的那個虛擬變量所對應的類別，亦即所有虛擬變量取值全部為零的類別。</p><p><strong>26、交互項（interaction term）</strong>:在操作上，交互項就是兩個或多個（一般不多於三個）自變量的乘積。在迴歸模型中引入交互項後，參與構造交互項的各自變量對因變量的作用依賴於交互項中其他自變量的取值。</p><p><strong>27、交互效應（interaction effect）</strong>：也稱為調節效應或條件效應，指一個自變量對因變量的效應依賴於另一個自變量的取值。迴歸分析中通常設定相應的交互項來探究某個自變量的條件效應。</p><p><strong>28、常規最小二乘法（ordinaryleast squares，OLS）</strong></p><p>：線性迴歸中求解參數的常用方法。該方法的基本思路為：根據從總體中隨機抽出的一個樣本，在平面直角座標系中找到一條直線，使得觀測值和擬合值之間的距離最短，即兩者之間殘差的平方和最小。</p><p><strong>29、線性（linearity</strong>）：指自變量與因變量之間的關係為單調的一次函數關係，因變量取值隨著自變量而變化的速率不隨自變量取值的大小不同而存在差異。另外，線性也指回歸分析中因變量為各回歸係數的線性組合。</p><p><strong>30、無偏性（unbiasedness）</strong>：當樣本統計量的期望值等於總體真值時，該統計量具有無偏性。無偏性是選擇估計量的首要標準。</p><p><strong>31、偏誤（bias）</strong>：統計估計中的估計值和真實值之間的差。</p><p><strong>32、忽略變量偏誤（omitted variable bias）</strong>：迴歸模型設定中，由於忽略了某些本該納入卻未納入的相關自變量，而該自變量又與模型中其他自變量存在相關，導致迴歸參數估計值存在一定的誤差，則這一誤差被稱作忽略變量偏誤。偏誤的方向取決於被忽略變量對因變量效應的方向以及該自變量與已納入模型中自變量之間關係的方向；而偏誤的大小則直接取決於該忽略自變量對因變量的效應的大小以及與模型中其他自變量之間的相關關係的強弱，它們之間的相關性越強，則忽略變量偏誤越大。</p><p><strong>33、相關條件（correlation condition）</strong>：判斷迴歸模型中存在忽略變量偏誤的條件之一，指的是被忽略的自變量與已納入模型中的關鍵自變量之間相關。</p><p><strong>34、有關條件（relevance condition）</strong>：判斷迴歸模型中存在忽略變量偏誤的條件之一，指的是被忽略的自變量會影響因變量。</p><p><strong>35、有效性（efficiency）</strong>：對總體參數進行估計時，在所有可能得到的無偏估計量中，抽樣分佈方差最小的無偏估計量，就具有有效性，是選擇估計量的另一個標準。</p><p><strong>36、獨立同分布假定（assumption ofindependent identical distributed errors）</strong>：或稱i.i.d.假定，假定一般線性模型中的隨機誤差項獨立（彼此獨立且獨立於自變量）並且服從零均值等方差的同質性分佈。</p><p><strong>37、一致性（consistency）</strong>：是選擇估計量的第三個標準。一致性表達的是，估計量以概率方式收斂於參數真值。</p><p><strong>38、最佳線性無偏估計（best linear unbiasedestimator）</strong>：在滿足所需假定條件的情況下，迴歸參數的常規最小二乘估計是所有無偏線性估計中方差最小的，因此，將其稱作最佳線性無偏估計。</p><p><strong>39、近似多重共線性（appro<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">xi</i>matemulticollinearity）</strong>：當數據矩陣中一個或幾個自變量列向量可以近似表示成其他自變量列向量的線性組合時，就會出現近似多重共線性問題。此時，模型仍是可以估計的，只是參數估計值的標準誤值過大，從而會造成統計檢驗和推論的不可靠。</p><p><strong>40、完全多重共線性（perfectmulticollinearity）</strong>：當數據矩陣中一個或幾個自變量列向量可以表示成其他自變量列向量的線性組合時，自變量矩陣X’X會嚴格不可逆，就出現了完全多重共線性。當發生完全多重共線性時，直接導致模型參數無解，即出現模型識別問題。</p><p><strong>41、復相關係數（multiple correlation coefficient）</strong>：度量複相關程度的指標。它是一個變量同時與數個變量之間的相關程度，可利用單相關係數和偏相關係數求得。復相關係數越大，表明變量之間的線性相關程度越高。</p><p><strong>42、容許度（tolerance）</strong>：迴歸分析中反映自變量之間存在多重共線性程度的統計量之一。對每一個變量，定義容許度為1減去模型中其他自變量之間的復相關係數。顯然，當容許度越小，越接近０時，多重共線性就越嚴重。當容許度嚴格等於０時，也就是復相關係數嚴格等於１時，就意味著完全多重共線性的存在。</p><p><strong>43、方差膨脹因子（variance inflation factor）</strong>：迴歸分析中反映自變量之間存在多重共線性程度的統計量之一，它等於容許度的倒數。對於某個自變量，其方差膨脹因子可定義為容許度的倒數。</p><p><strong>迴歸分析統計量</strong></p><p><strong>1、</strong><strong>迴歸係數</strong>：注意迴歸係數的正負要符合理論和實際。截距項的迴歸係數無論是否通過T檢驗都沒有實際的經濟意義。</p><p><strong>2、</strong><strong>迴歸係數的標準差</strong>：標準誤差越大，迴歸係數的估計值越不可靠，這可以通過T值的計算公式可知（自查）。</p><p><strong>3、</strong><strong>T檢驗</strong>：用於檢驗係數是否為零。通過查表可以得到相應的臨界值：如果該值大於臨界值，則該係數在相應的顯著水平上是可靠的；如果該值小於臨界值，則係數在相應顯著水平上是不顯著的。</p><p><strong>4、</strong><strong>P值</strong>：P值為理論T值超越樣本T值的概率，應該聯繫顯著性水平α相比，α表示原假設成立的前提下，理論T值超過樣本T值的概率，當P值&lt;α值，說明這種結果實際出現的概率的概率比在原假設成立的前提下這種結果出現的可能性還小但它偏偏出現了，因此拒絕接受原假設。</p><p><strong>5、</strong><strong>可決係數（R-squared）</strong>：表示迴歸的擬合程度，就是被解釋變量被所有解釋變量解釋的部分。R方的取值範圍在0到1之間：如果R方等於零，則表示該回歸併不比被解釋變量的簡單平均數預測的更好；如果R方等於1，則表示該回歸擬合的最為完美。</p><p><strong>6、</strong><strong>調整後的可決係數</strong>：即經自由度修正後的可決係數，從計算公式可知調整後的可決係數小於可決係數，並且可決係數可能為負，此時說明模型極不可靠。隨著解釋變量的增加，R方只會增加而不會減少。為對增加的解釋變量進行“懲罰”，對R方進行調整</p><p><strong>7、</strong><strong>迴歸殘差的標準誤</strong>：殘差的經自由度修正後的標準差，OLS的實質其實就是使得均方差最小化，而均方差與此的區別就是沒有經過自由度修正。</p><p><strong>8、</strong><strong>對數似然估計函數值</strong>：首先，理解極大似然估計法。極大似然估計法雖然沒有OLS運用廣泛，但它是一個具有更強理論性質的點估計方法。極大似然估計的出發點是已知被觀測現象的分佈，但不知道其參數。極大似然法用得到觀測值（樣本）最高概率（離散分佈以概率聚集函數表示，連續分佈以概率密度函數表示。因為要使得樣本中所有樣本點都出現，假定抽樣是隨機的則各個樣本點的是獨立同分布的，所以最後總的概率表現為概率聚集函數或者概率密度函數的連乘形式，稱之為似然函數。要取最大概率，即將似然函數對未知參數求導令導數等於0即可獲得極大似然函數。一般為簡化函數的處理過程都會對似然函數進行對數化處理，這樣最後得到的極大似然函數就稱之為對數極大似然函數）的那些參數的值來估計該分佈的參數，從而提供一種用於估計刻畫一個分佈的一組參數的方法。</p><p>其次，理解對數似然估計函數值。對數似然估計函數值一般取負值，實際值（不是絕對值）越大越好。第一，基本推理。對於似然函數，如果是離散分佈，最後得到的數值直接就是概率，取值區間為0-1，對數化之後的值就是負數了；如果是連續變量，因為概率密度函數的取值區間並不侷限於0-1，所以最後得到的似然函數值不是概率而只是概率密度函數值，這樣對數化之後的正負就不確定了。第二，Eviews的計算公式解釋。公式值的大小關鍵取之於殘差平方和（以及樣本容量），只有當殘差平方和與樣本容量的比之很小時，括號內的值才可能為負，從而公式值為正，這時說明參數擬合效度很高；反之公式值為負，但其絕對值越小表示殘差平方和越小，因而參數擬合效度越高。</p><p><strong>9</strong><strong>、DW檢驗值</strong>：DW統計量用於檢驗序列的自相關，公式就是測度殘差序列與殘差的滯後一期序列之間的差異大小，經過推導可以得出DW值與兩者相關係數的等式關係，因而很容易判斷。DW值的取值區間為0-4，當DW值很小時（大致&lt;1）表明序列可能存在正自相關；當DW值很大時（大致>3）表明序列可能存在負自相關；當DW值在2附近時（大致在1.5到2.5之間）表明序列無自相關；其餘的取值區間表明無法確定序列是否存在自相關。當然，DW具體的臨界值還需要根據樣本容量和解釋變量的個數通過查表來確定。</p><p>DW值並不是一個很適用的檢驗手段，因為它存在苛刻的假設條件：解釋變量為非隨機的；隨機擾動項為一階自迴歸形式；解釋變量不能包含滯後的被解釋變量；必須有截距項；數據無缺失值。當然，可以通過DW-h檢驗來檢驗包含滯後被解釋變量作為解釋變量的序列是否存在自相關。h統計量與滯後被解釋變量的迴歸係數的方差呈正相關關係，可以消除其影響。</p><p><strong>10</strong><strong>、被解釋變量的樣本均值</strong>：被解釋變量的樣本均值（MeanDependent Var）</p><p><strong>11</strong><strong>、被解釋變量的樣本標準誤差</strong>：被解釋變量的樣本標準誤差（S.D.Dependent Var）</p><p><strong>12、</strong><strong>赤池信息準則（AIC）</strong>：AIC和SC在時間序列分析過程中的滯後階數確定過程中非常重要，一般是越小越好。</p><p>一般理解：根據AIC的計算公式（-2*L/N+2*k/N，L為對數似然估計函數值，k為滯後階數，N為樣本容量）可知：當滯後階數小時，2*k/N小，但因為模型的模擬效果會比較差所以L（負值）會比較小，加上負號之後則變得較大，因此最後的AIC有可能較大；當滯後階數大時，模型的模擬效果會比較好所以L（負值）會比較大，加上負號之後則變得較小，但是2*k/N過大（損失自由度的代價），因此最後的AIC也有可能較大。綜上，AIC較小意味著滯後階數較為合適。</p><p><strong>13</strong><strong>、施瓦茨信息準則（SC）</strong>：與AIC沒有任何本質區別，只是加入樣本容量的對數值以修正損失自由度的代價。</p><p><strong>14</strong><strong>、F統計量（F-statistic）</strong>：F統計量考量的是所有解釋變量整體的顯著性，所以F檢驗通過並不代表每個解釋變量的t值都通過檢驗。當然，對於一元線性迴歸，T檢驗與F檢驗是等價的。</p><p><strong>15</strong><strong>、prob（F-statistic） </strong>：F統計量的P值，一切的P值都是同樣的實質意義。</p><p><strong>迴歸模型殘差檢驗</strong></p><p>迴歸模型估計完畢後，通常研究者會對模型估計的殘差進行檢驗，通過迴歸殘差的性質來判斷模型估計的效果。常用的檢驗有：Q檢驗和LM檢驗用來判斷殘差是否違背無相關假定、異方差檢驗用來判斷殘差是否違背同方差假定、正態性檢驗用於判斷殘差的分佈。檢驗的一般程序（適用於絕大部分統計量檢驗）是計算相關統計量的原假設成立的概率P值，如果該概率P值小於某個設定顯著水平（通常為5%）,則拒絕原假設，認為備擇假設成立；反之，則不能拒絕原假設。</p><p><strong>殘差自相關的Q檢驗：</strong></p><p>檢驗目的：Q統計量的全稱是Ljung-Box Q，該統計量一般用於檢驗序列是否存在自相關。檢驗假設：該統計量的原假設H0為：殘差序列不存在自相關；備擇假設H1為：殘差序列存在自相關。</p><p><strong>殘差自相關的LM檢驗：</strong></p><p>LM檢驗是Breush-Godfrey Lagrange Multiplier的簡稱，主要用於檢驗殘差序列是否存在高階自相關的重要假設。該統計量的計算首先必須利用OLS估計出原模型的殘差序列u；然後以u為被解釋變量，以u的1到P階滯後項為解釋變量再次進行迴歸，同時<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">記錄</i>該回歸的擬合優度R方。LM檢驗統計量的原假設為H0為：殘差序列直到P階不存在自相關；備擇假設H1為：殘差序列P階內存在自相關。</p><p><strong>殘差的正態性檢驗：</strong></p><p>檢驗目的：Histogram-Normality Test檢驗主要是通過計算JB統計量實現的，JB統計量用來檢驗序列觀測值是否服從正態分佈，在零假設下，JB統計量服從χ2(2)分佈。檢驗假設：該檢驗的原假設H0為：樣本殘差服從正態分佈。備擇假設H1為：殘差序列不服從正態分佈。</p><p><strong>殘差的異方差檢驗：</strong></p><p>檢驗目的：由於最小二乘方法是建立在殘差同方差假設基礎上的，一旦出現異方差就說明OLS方法就不可靠了，需要利用加權最小二乘方法進行糾正。異方差檢驗是利用輔助迴歸的方法進行的，該統計量服從卡方分佈。檢驗假設：懷特異方差檢驗的原假設H0為：殘差序列不存在異方差。備擇假設H1為：殘差序列存在異方差。</p><img alt=迴歸分析不可不知的關鍵詞和統計量 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RBWOS40F2Bbyso></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>關鍵</a></li><li><a>統計量</a></li><li><a>不可</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/56c317a5.html alt=科普文：神祕的汙水處理流程，都有哪些關鍵步驟呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7113d7e544d14241957a3996c2bec8b0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/56c317a5.html title=科普文：神祕的汙水處理流程，都有哪些關鍵步驟呢？>科普文：神祕的汙水處理流程，都有哪些關鍵步驟呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d86b1a6d.html alt=手機顯示屏關鍵材料成本降了，汙染輕了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1531616443789c3e2d32478 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d86b1a6d.html title=手機顯示屏關鍵材料成本降了，汙染輕了>手機顯示屏關鍵材料成本降了，汙染輕了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bf248ef5.html alt=2018年收藏和田玉最新關鍵詞——線上交易！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/54000003fda0ced1dd2b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bf248ef5.html title=2018年收藏和田玉最新關鍵詞——線上交易！>2018年收藏和田玉最新關鍵詞——線上交易！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/76b97e91.html alt=先聚人再談交易，“社區”是盛世收藏十年來的關鍵詞 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/6778/2898233604 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/76b97e91.html title=先聚人再談交易，“社區”是盛世收藏十年來的關鍵詞>先聚人再談交易，“社區”是盛世收藏十年來的關鍵詞</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9c867cb4.html alt=關鍵時刻，脈動有些“不在狀態”，全面升級後能否“脈動回來”？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/821410d754234b3e8af93b2a8d1193b5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9c867cb4.html title=關鍵時刻，脈動有些“不在狀態”，全面升級後能否“脈動回來”？>關鍵時刻，脈動有些“不在狀態”，全面升級後能否“脈動回來”？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/510e0826.html alt=你不可不知的光纜基本常識 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/510e0826.html title=你不可不知的光纜基本常識>你不可不知的光纜基本常識</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5b5bf91d.html alt=中國人不可不知的知識 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/dfic-imagehandler/61cd9a97-90a3-41e7-b149-b5ea9a2e56aa style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5b5bf91d.html title=中國人不可不知的知識>中國人不可不知的知識</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1ad88931.html alt=帶你搞定多線程，併發編程關鍵字Java多線程之volatile class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/79e01a43526949a3b1ce35f41d4f0d5e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1ad88931.html title=帶你搞定多線程，併發編程關鍵字Java多線程之volatile>帶你搞定多線程，併發編程關鍵字Java多線程之volatile</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/088b60bf.html alt=考研數學學習的關鍵還是：迴歸書本，重視基礎 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b4690bc5dfb941f1ad541254f9a4bd2a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/088b60bf.html title=考研數學學習的關鍵還是：迴歸書本，重視基礎>考研數學學習的關鍵還是：迴歸書本，重視基礎</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5e9e69b4.html alt=統計學系列——兩個重要統計量 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f12cc14a89404e6c8195efb14d3513b3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5e9e69b4.html title=統計學系列——兩個重要統計量>統計學系列——兩個重要統計量</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/679d2807.html alt=氧化還原反應，關鍵在於掌握“得、低、氧、還；失、高、還、氧” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/39f60772913a4462867344ea2ea7d343 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/679d2807.html title=氧化還原反應，關鍵在於掌握“得、低、氧、還；失、高、還、氧”>氧化還原反應，關鍵在於掌握“得、低、氧、還；失、高、還、氧”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/94e388c9.html alt=新型特種功能關鍵材料研發取得突破 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/94e388c9.html title=新型特種功能關鍵材料研發取得突破>新型特種功能關鍵材料研發取得突破</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/72190256.html alt=5G網絡關鍵技術之八—無線資源調度與共享 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1532497217002d7f84c7b2d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72190256.html title=5G網絡關鍵技術之八—無線資源調度與共享>5G網絡關鍵技術之八—無線資源調度與共享</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b8567dc0.html alt=C語言關鍵字整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b8567dc0.html title=C語言關鍵字整理>C語言關鍵字整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/64a7d12e.html alt=易經：人生關鍵的幾步，決定一個人的命運，要把握3個黃金時刻！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/694aa7b1973545a4926fd460ee45c39f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/64a7d12e.html title=易經：人生關鍵的幾步，決定一個人的命運，要把握3個黃金時刻！>易經：人生關鍵的幾步，決定一個人的命運，要把握3個黃金時刻！</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>