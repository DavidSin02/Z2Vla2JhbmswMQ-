<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等 | 极客快訊</title><meta property="og:title" content="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/RqRS7P03AH4R3v"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/dab0f30f.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/dab0f30f.html><meta property="article:published_time" content="2020-11-14T21:03:07+08:00"><meta property="article:modified_time" content="2020-11-14T21:03:07+08:00"><meta name=Keywords content><meta name=description content="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/dab0f30f.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>目錄</strong></p><ul><li><p>層次遞歸網絡序列標註的轉移學習</p></li><li><p>注意力神經網絡序列標記模型中的特徵</p></li><li><p>基於雙向LSTM-CNNs的命名實體識別</p></li><li><p>通過雙向LSTM-CNNs-CRF進行端到端序列標記</p></li><li><p>更好的物體表徵，更好地從純圖像重建世界</p></li></ul><p><strong>層次遞歸網絡序列標註的轉移學習</strong></p><p>論文名稱：TRANSFER LEARNING FOR SEQUENCE TAGGING WITH HIERARCHICAL RECURRENT NETWORKS</p><p>作者：Zhilin Yang /Ruslan Salakhutdinov</p><p>發表時間：2017/3/18</p><p>論文鏈接：https://arxiv.org/pdf/1703.06345.pdf</p><p>核心問題：在序列標註問題中，為了解決傳統的機器學習存在的需要手動構建特徵的問題，這裡常常使用神經網絡的方式，但是神經網絡常常需要大量的數據才可以，那麼現在就面臨一種情況，當數據量不足的時候，如何才可以解決這個問題呢？</p><p>創新點：在計算機視覺中，當面臨數據不足的時候，我們常常使用遷移學習的方式，本論文也將探討遷移學習的方法，其中使用具有豐富註釋的源任務來改善具有較少可用註釋的目標任務的性能</p><p>研究意義：通過這種方式可以將訓練的模型參數和架構遷移過來，並且取得了不錯的效果，事實上現在nlp中的重要預訓練模型興起，這也一定程度上證明了這種方向的可行性。</p><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS7P03AH4R3v><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS7PYGyF7G5p><p></p><h1 toutiao-origin=h2>注意力神經網絡序列標記模型中的特徵</h1><p>論文名稱：Attending to Characters in Neural Sequence Labeling Models</p><p>作者：Marek Rei /Gamal K.O. Crichton /Sampo Pyysalo</p><p>發表時間：2016/11/14</p><p>論文鏈接：https://www.aclweb.org/anthology/C16-1030.pdf</p><p>推薦原因</p><p>核心問題：序列標註問題有一個問題需要處理，這個問題就是當一句話中出現的單詞是陌生詞的時候，那麼此時就會出現問題。這種詞稱為OOV問題</p><p>創新點：創新點就是為了解決這個問題，首先單詞有OOV問題，但是字符沒有OOV問題，這裡引入了字符級別的信息。然後引入了注意力機制，使用經典的attention+RNN+CEF的組合方式，這樣通過將詞級別和字符級別的向量相結合，從而達到非OVV的詞的字符向量與其詞向量相近。</p><p>研究意義：在許多數據集上達到了很好的效果，並且這種模型的參數較少。</p><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RqRS7Q2COX4N9h><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS7QK2RiBlai><p></p><h1 toutiao-origin=h2>基於雙向LSTM-CNNs的命名實體識別</h1><p>論文名稱：Named Entity Recognition with Bidirectional LSTM-CNNs</p><p>作者：Jason P.C. Chiu /Eric Nichols</p><p>發表時間：2016/7/19</p><p>論文鏈接：https://arxiv.org/pdf/1511.08308.pdf</p><p>推薦原因</p><p>核心問題：本文解決的是命名實體識別的任務，這是nlp中非常具備挑戰性的工作，傳統的機器學習方法需要使用手工的方式，但是這種方式並不好。</p><p>創新點：本論文使用的是深度學習的方式，和傳統的深度學習方法不同的是，這裡搭建了一個新的神經網絡結構，能夠自動檢測字級和字符級特徵使用雙向LSTM和CNN混合架構，消除了大多數特徵工程的需要。除此之外本文還提出了一種新的方法，使用這個方法在神經網絡中對部分詞典匹配進行編碼，可以取得較好的效果。</p><p>研究意義：實驗表明，這種模型效果超過當前的模型，並且在多個數據集中取得了最佳的效果。</p><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/RqRS7Qj4GOVBAc><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqRS88y7kFgVYj><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS89PEE10RDR><p></p><h1 toutiao-origin=h2>通過雙向LSTM-CNNs-CRF進行端到端序列標記</h1><p>論文名稱：End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</p><p>作者：Xuezhe Ma /Eduard Hovy</p><p>發表時間：2016/5/29</p><p>論文鏈接：https://arxiv.org/pdf/1603.01354.pdf</p><p>核心問題：本文核心是解決nlp領域中的命名實體識別的問題</p><p>創新點：在之前的常用的模型是LSRM+CRF，本論文搭建了一個端到端的神經網絡模型，引入了CNN結構，這可以很好的處理局部信息</p><p>研究意義：這個模型的效果超過之前的模型效果。</p><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqRS89g3adUhNy><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS8A4AwGMFFm><p></p><h1 toutiao-origin=h2>更好的物體表徵，更好地從純圖像重建世界</h1><p>論文名稱：Contrastive Learning of Structured World Models</p><p>作者：Thomas Kipf /Elise van der Pol /Max Welling</p><p>發表時間：2019/9/26</p><p>論文鏈接：https://openreview.net/forum?id=H1gax6VtDB</p><p>人類可以從眼睛觀察到的視覺信號理解還原出世界中的物體、物體間的關係、層次等等，這是人類認知能力的重要組成部分，也是機器學習、深度學習、計算視覺仍面對的一大挑戰（從原始的像素輸入還原帶有結構的世界模型）。</p><p>維吉尼亞大學的作者們在這篇論文中提出了一個基於對比度訓練的有結構的世界模型C-SWM，它使用了一種對比度方法來用組合式的結構學習環境的表徵。它可以不需要直接的監督，只通過對原始像素的觀察就發現提取環境中的物體。</p><p>作者們在含有多個獨立、可控制的物體的交互環境中評價了模型的表現，既包括了簡單的Atari遊戲，也包括了多物體的物理仿真環境。實驗表明，這個模型可以克服以往的基於像素重建的模型的很多不足，在高度結構化的環境中也發揮了比同類表徵模型更好的表現，同時它學習到的基於物體的表徵還是具有可解釋性的。</p><p>這篇論文的方法實際、效果出色，得到了審稿人的高度評價，被ICLR2020接收為口頭報告論文。</p><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqRS8AWGcpJ6ze><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RqRS8oM8Vcpr9a><img alt="今日 Paper | 從純圖像重建世界；層次遞歸網絡序列；注意力神經網絡；命名實體識別等" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RqRS8oz6l4XSef><p></p><h1 toutiao-origin=h2># 論文作者團隊招募</h1><p>為了更好地服務廣大 AI 青年，AI 研習社正式推出全新「論文」版塊，希望以論文作為聚合 AI 學生青年的「興趣點」，通過論文整理推薦、點評解讀、代碼復現。致力成為國內外前沿研究成果學習討論和發表的聚集地，也讓優秀科研得到更為廣泛的傳播和認可。</p><p>我們希望熱愛學術的你，可以加入我們的論文作者團隊。</p><p>加入論文作者團隊你可以獲得</p><p>1.署著你名字的文章，將你打造成最耀眼的學術明星</p><p>2.豐厚的稿酬</p><p>3.AI 名企內推、大會門票福利、獨家周邊紀念品等等等。</p><p>加入論文作者團隊你需要：</p><p>1.將你喜歡的論文推薦給廣大的研習社社友</p><p>2.撰寫論文解讀</p><p>如果你已經準備好加入 AI 研習社的論文兼職作者團隊，可以添加運營小姐姐的微信，備註“論文兼職作者”</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>網絡</a></li><li><a>Paper</a></li><li><a>純圖</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ea1bb612.html alt=光纜——未來網絡主導 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e75c1afe12354a93bad8495ad1057693 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ea1bb612.html title=光纜——未來網絡主導>光纜——未來網絡主導</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bdc59733.html alt="網絡詞名場面是什麼意思 名場面是什麼梗" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bdc59733.html title="網絡詞名場面是什麼意思 名場面是什麼梗">網絡詞名場面是什麼意思 名場面是什麼梗</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a002ca18.html alt=王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/26add5cdc08e4214800b25e21b623eb1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a002ca18.html title=王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯>王一博那句年度網絡流行語「不愧是我」的：正版英文翻譯</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html alt=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/65c4000bda98898dcdbb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ad6f0929.html title=谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼>谷歌大腦發佈神經網絡的「核磁共振」，並公開相關代碼</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8dce33e7.html alt=理解生成對抗網絡，一步一步推理得到GANs（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/bee194d6fbec4d6f82e82998def3f7a3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8dce33e7.html title=理解生成對抗網絡，一步一步推理得到GANs（一）>理解生成對抗網絡，一步一步推理得到GANs（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1fe1c2dd.html alt=瞭解生成對抗網絡（GAN） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/634604de44ad4d17931ccc0bcf3e46ef style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1fe1c2dd.html title=瞭解生成對抗網絡（GAN）>瞭解生成對抗網絡（GAN）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2a9a3956.html alt="100 個網絡基礎知識普及，看完成半個網絡高手！" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/955ea722-be77-4b2d-b87a-64a8a04c8ea8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2a9a3956.html title="100 個網絡基礎知識普及，看完成半個網絡高手！">100 個網絡基礎知識普及，看完成半個網絡高手！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/78c87167.html alt=奧迪A7車載電路與網絡連接之網絡連接 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d34213e3b03545bd8e87ab074b54ca0f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/78c87167.html title=奧迪A7車載電路與網絡連接之網絡連接>奧迪A7車載電路與網絡連接之網絡連接</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8a15db0b.html alt=網絡上共享跨平臺的點對點文件 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/666bf87a9e16425ea1c9adc4f2c10acd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8a15db0b.html title=網絡上共享跨平臺的點對點文件>網絡上共享跨平臺的點對點文件</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2b6ecb90.html alt=網絡基礎知識術語你知道哪些？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2b6ecb90.html title=網絡基礎知識術語你知道哪些？>網絡基礎知識術語你知道哪些？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6474ccee.html alt=點對點網絡的基本知識分享 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8678a34470a144ad88fc0487f0d8da91 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6474ccee.html title=點對點網絡的基本知識分享>點對點網絡的基本知識分享</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a61e29b6.html alt="幫助信息網絡犯罪活動罪 | 廈門刑事律師--辦案資料" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a61e29b6.html title="幫助信息網絡犯罪活動罪 | 廈門刑事律師--辦案資料">幫助信息網絡犯罪活動罪 | 廈門刑事律師--辦案資料</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ded83afe.html alt=博士論文摘要｜馬下平：“陸態網絡”並址站歸心基線精密解算及GNSS基準站數據處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/53350006726e50ef72f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ded83afe.html title=博士論文摘要｜馬下平：“陸態網絡”並址站歸心基線精密解算及GNSS基準站數據處理>博士論文摘要｜馬下平：“陸態網絡”並址站歸心基線精密解算及GNSS基準站數據處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/65c66d61.html alt=網絡分析儀校準很頭疼，三大要點得記住！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/41dd3f31e88f48688e75d64978b36acf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/65c66d61.html title=網絡分析儀校準很頭疼，三大要點得記住！>網絡分析儀校準很頭疼，三大要點得記住！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html alt=為了更好的深度神經網絡視覺，只需添加反饋（循環） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/17fccfd7096d44eeb3921bbd0dc29a13 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2bc1496a.html title=為了更好的深度神經網絡視覺，只需添加反饋（循環）>為了更好的深度神經網絡視覺，只需添加反饋（循環）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>