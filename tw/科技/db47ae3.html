<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 | 极客快訊</title><meta property="og:title" content="論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/53350006726e50ef72f9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/db47ae3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/db47ae3.html><meta property="article:published_time" content="2020-10-29T21:08:15+08:00"><meta property="article:modified_time" content="2020-10-29T21:08:15+08:00"><meta name=Keywords content><meta name=description content="論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/db47ae3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>《測繪學報》</p><p>構建與學術的橋樑 拉近與權威的距離</p><p>許夙暉<sup>1</sup><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/53350006726e50ef72f9>, 慕曉冬<sup>1</sup>, 張雄美<sup>1</sup>, 柴棟<sup>2</sup></p><p>1. 火箭軍工程大學信息工程系, 陝西 西安 710025; 2. 北京航空工程技術研究中心, 北京 100076</p><p>收稿日期：2017-06-05；修回日期：2017-10-24</p><p>基金項目：國家自然科學基金（61640007）</p><p>第一作者簡介：許夙暉(1989-), 女, 博士生, 研究方向為遙感圖像處理和模式識別。E-mail:xu_suhui@163.com</p><p><strong>摘要</strong>：使用機器學習進行遙感影像標註的一個重要前提是有足夠的訓練樣本，而樣本的標註是非常耗時的。本文采用了域適應的方法來解決遙感影像場景分類中小樣本量的無監督學習問題，提出了結合對抗網絡與輔助任務的遙感影像域適應方法。首先建立了基於深度卷積神經網絡的遙感影像分類框架；其次，為了學習到域不變特徵，在標籤分類器的基礎上增加域分類器，並使域損失函數在其反射傳播時的梯度與標籤損失的梯度相反，從而保證域分類器不能區分樣本來自於哪個域；最後引入了輔助分類任務，擴充了樣本的同時使網絡更具泛化能力。試驗結果表明，本文方法優於主流的無監督域適應方法，在小樣本遙感影像無監督分類中得到了較好的效果。</p><p><strong>Unsupervised Remote Sensing Domain Adaptation Method with Adversarial Network and Auxiliary Task</strong></p><p>XU Suhui<sup>1</sup>, MU Xiaodong<sup>1</sup>, ZHANG Xiongmei<sup>1</sup>, CHAI Dong<sup>2</sup></p><p><strong>Abstract</strong>: An important prerequisite when annotating the remote sensing images by machine learning is that there are enough training samples for training, but labeling the samples is very time-consuming. In this paper, we solve the problem of unsupervised learning with small sample size in remote sensing image scene classification by domain adaptation method. A new domain adaptation framework is proposed which combines adversarial network and auxiliary task. Firstly, a novel remote sensing scene classification framework is established based on deep convolution neural networks. Secondly, a domain classifier is added to the network, in order to learn the domain-invariant features. The gradient direction of the domain loss is opposite to the label loss during the back propagation, which makes the domain predictor failed to distinguish the sample's domain. Lastly, we introduce an auxiliary task for the network, which augments the training samples and improves the generalization ability of the network. The experiments demonstrate better results in unsupervised classification with small sample sizes of remote sensing images compared to the baseline unsupervised domain adaptation approaches.</p><p>Key words: remote sensing image scene classification domain adaptation deep convolutional neural network adversarial network multi-task learning</p><p>遙感影像的分類效果很大程度取決於提取的影像特徵，文獻[1]將現有的遙感影像特徵提取方法分為3大類：①人工特徵，如影像的光譜、紋理、空間、GIST、SIFT、HOG等；②基於無監督的特徵，如主成分分析、K-均值聚類、稀疏編碼等；③深度特徵，如SAE、CNNs等。由於深度特徵可以代表影像更為抽象的特徵，因此近兩年大量研究採用深度神經網絡來提取遙感影像的特徵<sup>[2-8]</sup>。然而，深度網絡能夠提取出有效特徵的前提是有足夠的訓練樣本<sup>[9]</sup>。對於一幅陌生的遙感影像，首要的是選取大量的樣本並且對其進行標記，這在實際過程中非常耗時<sup>[10-11]</sup>。因此在訓練樣本有限甚至沒有的情況下如何訓練出泛化能力較強的網絡是目前深度學習領域正在解決的熱點問題。</p><p>假設已有一個相對較大的已經標註過的遙感影像數據集，若利用其更加豐富的數據作為訓練樣本，理論上可以訓練出更為成熟、泛化能力更強的網絡，用這個網絡將會對新的遙感影像提取出更好的特徵。然而，不同數據集之間由於傳感器、拍攝角度、季節等的差異，造成同一類型的地物在不同的域中差異巨大。直接將大規模數據集樣本訓練的網絡來預測目標數據集，得到的分類結果並不理想。由此，不同數據集之間的域適應問題得以提出，在域適應問題中，提供訓練樣本的數據集所在的域稱為源域，對需要進行分類的數據集稱為目標域。</p><p>近些年，諸多學者對域適應問題進行了研究，研究的圖像對象主要集中在Office/Caltech數據集，和Mnist/Mnist_M/USPS/SVHN數據集，前者包含4個域，內容為數碼照片，後者是0-9數字圖像。研究的問題可按照目標域中是否有可用標籤分為兩類<sup>[12]</sup>：一種是監督/半監督學習，即目標域中所有類或者部分類中部分圖像含有標籤，可以直接作為訓練樣本；另一種是完全無監督學習，即目標域中沒有可用標籤。研究的方法通常有兩種類型：一是用人工特徵、或者訓練好的CNN網絡對遙感影像進行特徵提取，然後求出一個轉換矩陣，將源域的特徵映射到目標域中，使兩個域的影像享有同一個特徵空間，這類方法的相關研究有ARC-t<sup>[13]</sup>、MMDT<sup>[14]</sup>、HFA<sup>[15]</sup>、GFK<sup>[16]</sup>、Landmarks<sup>[17]</sup>等，其中，GFK和Landmarks是無監督的，其他方法為監督學習的方法。</p><p>域適應的另外一種類型是基於深度學習的方法。文獻[18]在標籤代價函數的基礎上，引入了稱為域混淆損失的代價函數，具體做法是在最後一層全連接層之前加了域適應層，源域和目標域的樣本經過該層的輸出特徵後，計算其最大平均偏差距離(maximum mean discrepancy，MMD)，該距離與標籤損失之和為新的目標函數。針對監督和半監督分類，文獻[19]在文獻[18]的基礎上加入了軟標籤損失，用來保持源域和目標域各類之間相對分佈的一致性。文獻[20]使用了對抗網絡框架<sup>[21]</sup>來解決域適應問題，其目標函數包括標籤分類器和域分類器兩部分，該方法的對抗思想體現在：對於域適應問題，一是希望網絡學到的特徵表示具有域不變的特徵，這就導致域分類器不能正確進行域分類，即域分類器的分類損失最大；二是在對域分類器訓練同時，要求標籤分類器能儘可能地正確分類，即標籤分類器的分類損失最小。</p><p>目前域適應方法普遍的試驗對象為普通圖像，近年來也有學者針對遙感影像的域適應方法進行針對性的研究<sup>[22-23]</sup>。遙感影像相對於普通圖像在域適應問題上有很大不同：一方面其源域和目標域差異較大；另一方面圖像包含的地物信息豐富，需要更深的網絡，而更深的網絡需要更為豐富的樣本數據支持。傳統域適應方法直接用於遙感影像很難取得較好的分類效果。</p><p>針對遙感影像域適應過程中的高分辨率遙感影像尺寸大而數據量小的問題，本文提出了基於對抗網絡和輔助任務的遙感影像域適應方法，其創新點在於：①首次進行遙感影像無監督域適應場景分類的研究，構建了遙感影像域適應試驗的數據集，設計了結合輔助任務的對抗網絡架構；②引入域損失函數，在目標函數中增加了域分類任務，使分類器學習到域不變特徵；③引入不同標籤空間的輔助分類任務，豐富了訓練樣本，提高網絡的泛化能力和特徵提取能力。試驗表明，本文方法加入了域損失任務與輔助分類任務，與主流域適應算法相比，在分類效果上有明顯的優勢。</p><p>1 本文提出的方法</p><p>問題描述：設源域數據集合為<em>S</em>={(<strong>x</strong><sub>s</sub><sup>i</sup>,<strong>y</strong><sub>s</sub><sup>i</sup>)}<em>i</em>=1n<sub>s</sub>，其中<strong>x</strong><sub>s</sub><sup>i</sup>為源域中圖像數據，<strong>y</strong><sub>s</sub><sup>i</sup>為相應的標籤，<strong>y</strong><sub>s</sub><sup>i</sup>∈Y<sub>s</sub>={0，1，2，…<em>l</em>,<em>l</em>+1, …<em>L</em>}, n<sub>s</sub>為源域中樣本數量；目標域數據集合為<em>T</em>={(<strong>x</strong><sub>t</sub><sup>i</sup>)}<em>i</em>=1n<sub>t</sub>，<strong>x</strong><sub>t</sub><sup>i</sup>為目標域中圖像數據，n<sub>t</sub>為目標域中樣本數量，目標域中每個樣本的標籤<strong>y</strong><sub>t</sub><sup>i</sup>是未知的，但是其所在空間是已知的，<strong>y</strong><sub>t</sub><sup>i</sup>∈Y<sub>t</sub>={0，1，2，…<em>l</em>}，即Y<sub>T</sub>⊂Y<sub>S</sub>。<em>S</em>和<em>T</em>服從不同的分佈, 記<em>S</em>~D<sub>s</sub>，<em>T</em>~D<sub>t</sub>，且D<sub>s</sub>≠D<sub>t</sub>。將源域中與目標域享有共同標籤空間的樣本稱為主樣本<em>S</em><sub>main</sub>={(<strong>x</strong><sub>main</sub><em>i</em>,<strong>y</strong><sub>main</sub><em>i</em>)}<em>i</em>=1<em>n</em><sub>main</sub>，源域中不屬於目標域空間的樣本稱為輔助樣本<em>S</em><sub>aux</sub>={(<strong>x</strong><sub>aux</sub><em>i</em>,<strong>y</strong><sub>aux</sub><em>i</em>)}<em>i</em>=1<em>n</em><sub>aux</sub>，且滿足</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78850002c6504800eb79><p>(1)</p><p>式中，<strong>x</strong><sub>main</sub><em>i</em>和<strong>x</strong><sub>aux</sub><em>i</em>分別為主樣本和輔助樣本中圖像數據；<strong>y</strong><sub>main</sub><em>i</em>和<strong>y</strong><sub>aux</sub><em>i</em>為相應的標籤；<em>n</em><sub>main</sub>和<em>n</em><sub>aux</sub>為樣本數量。</p><p>算法的目的是，利用源域數據<em>S</em>，求解一個分類器C<sub>θ</sub>，使得</p><p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/727c000a5b882d789ebe>(2)</p><p>本文方法的框架如圖 1所示，源域和目標域的數據共同輸入到多層卷積神經網絡提取特徵，然後將輔助樣本的特徵作為輔助標籤預測器(上側區域)的輸入；將主樣本的特徵輸入到主標籤預測器(中間區域)和域預測器中(下側區域)；將目標域的特徵輸入到域預測器中。所有分類器輸出後與相應的標籤計算損失。本文方法的損失函數為</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727b000a5b46164aea98><p>圖 1 本文方法的框架Fig. 1 Framework of the proposed method</p><p>圖選項</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/727b000a5b478f342a48><p>(3)</p><p>損失函數由3部分構成：主損失函數<em>L</em><sub>main</sub>、輔助類損失函數<em>L</em><sub>aux</sub>和域損失函數L<sub>d</sub>，<em>λ</em>與<em>γ</em>為相應的權重係數。</p><p>1.1 對抗網絡</p><p>本文設計的網絡基於兩個目的：一是網絡可以對地物類型進行分類，二是網絡具有域不變特性，即網絡區分不出來輸入影像來自於哪一個域。前者可以理解調整網絡參數，使類損失函數最小；後者可以通過一個域損失函數來實現。對於兩個不同域的影像，除了其自帶的類標籤，人為定義一個域標籤，比如對於源域其標籤為0，對於目標域其標籤為1。域損失越大，域分類器就越難區別輸入影像來自源域或目標域，網絡的域適應性也就越好。因此，網絡參數需要同時滿足分類損失最小化和域損失最大化，這兩個部分是對抗的。</p><p>主損失函數為類別損失，其定義如下</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/78810007964f7fe3914b><p>(4)</p><p>式中，<strong>x</strong><sub>main</sub>、<strong>y</strong><sub>main</sub>分別為共享樣本數據和標籤；<strong>θ</strong><sub>f</sub>為特徵提取單元的網絡參數；<strong>θ</strong><sub>main</sub>為主分類器的網絡參數，該分類器由若干個全連接層組成，分類器最後輸出的單元數為主類的類別數；1為指示函數，當<strong>y</strong><sub>main</sub>=<em>m</em>成立時值取1，否則取0；p<sub>m</sub>為softmax層的輸出值，p<sub>m</sub>=softmax[<strong>θ</strong><sub>main</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>main</sub>;<strong>θ</strong><sub>f</sub>)]。</p><p>按照所在域的不同，分別為源域中的主樣本和目標域中的樣本增加一個域標籤，記為<strong>y</strong><sub>d</sub><sup>main</sup>與<strong>y</strong><sub>d</sub><sup>t</sup>，並定義：{<strong>y</strong><sub>d</sub><sup>main</sup>}<em>n</em><sub>main</sub>=0，{<strong>y</strong><sub>d</sub><sup>t</sup>}n<sub>t</sub>=1。域損失定義如下</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78840004935e983be61e><p>(5)</p><p>式中，<strong>θ</strong><sub>d</sub>為域分類器的網絡參數，該分類器輸出的單元數為域標籤的類別數，即為2；1為指示函數，當<strong>y</strong><sub>d</sub>=<em>d</em>成立時值取1，否則取0；p<sub>d</sub>為域分類器softmax層的輸出值，p<sub>d</sub>=softmax[<strong>θ</strong><sub>d</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>main</sub>,<strong>x</strong><sub>t</sub>;<strong>θ</strong><sub>f</sub>)]。</p><p>由於對抗網絡的目標是學習到域不變特徵，也就是說域分類器分辨不出類別最好。因此域的損失函數不能與類別損失函數一樣越小越好，而是在源域類別損失相對較小的情況下，域損失函數越大越好。因此求解目標是</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727c000a5b89e9728132><p>(6)</p><p>注意到式(6)中，L<sub>d</sub>的求解目標是使其最大化，這種情況不能用梯度下降進行求解。為了解決這個問題，定義一箇中間函數<em>R</em>(<strong>x</strong>)，在前向與反向傳播中</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8ad0841e93><p>(7)</p><p>式(7)表示正向傳播時無影響，而反向用梯度更新參數時進行梯度反轉，由此就得到可以滿足使用梯度下降法的表現形式。</p><p>1.2 輔助任務</p><p>在本文遙感影像域適應應用場景中，源域樣本中還包括了目標域中不存在類別的樣本。為了充分利用源域的樣本，本文加入了輔助任務，其思想來源於多任務學習。多任務學習在單一任務的基礎上，結合了輔助的任務學習共同的特徵表示<sup>[24-25]</sup>。通過輔助任務學習，最大限度地豐富了訓練樣本，學習到的特徵相對於單任務學習具有更好的泛化能力，並且有效地減小類內距離與增大類間距離，有利於提高分類精度。</p><p>本文的輔助損失函數的定義如下</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78850002c6510fc1fab6><p>(8)</p><p>式中，<strong>x</strong><sub>aux</sub>、<strong>y</strong><sub>aux</sub>分別為輔助樣本數據和標籤；<strong>θ</strong><sub>aux</sub>為輔助類線性分類器的網絡參數，分類器最後輸出的單元數為輔助類的類別數；1為指示函數，當<strong>y</strong><sub>aux</sub>=<em>k</em>成立時值取1，否則取0；p<sub>k</sub>為softmax層的輸出值，p<sub>k</sub>=softmax[<strong>θ</strong><sub>aux</sub><sup>T</sup><em>f</em>(<strong>x</strong><sub>aux</sub>;<strong>θ</strong><sub>f</sub>)]。輔助損失函數為類別損失，要求其損失越小越好，即求解目標為<img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/727c000a5b8b56611e3e></p><p>1.3 算法流程</p><p>本文方法的參數更新流程如下</p><p>輸入：源域數據<em>S</em>={(<strong>x</strong><sub>s</sub><sup>i</sup>,<strong>y</strong><sub>s</sub><sup>i</sup>)}<em>i</em>=1n<sub>s</sub>，目標域數據<em>T</em>={(<strong>x</strong><sub>t</sub><sup>i</sup>)}<em>i</em>=1n<sub>t</sub>，初始化參數<strong>θ</strong><sub>f</sub>、<strong>θ</strong><sub>aux</sub>、<strong>θ</strong><sub>main</sub>、<strong>θ</strong><sub>d</sub>，權重係數<em>λ</em>與<em>γ</em>，迭代次數<em>i</em>=0，初始學習率<em>ϕ</em>(0)，最大迭代次數num_step，單次輸入樣本數量batchsize</p><p>While <em>i</em>＜num_step:</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78840004935f28fcfafb><p>更新參數：</p><p><strong>θ</strong><sub>main</sub>=<strong>θ</strong><sub>main</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>main</sub>，<strong>θ</strong><sub>aux</sub>=<strong>θ</strong><sub>aux</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>aux</sub>，<strong>θ</strong><sub>d</sub>=<strong>θ</strong><sub>d</sub>-<em>ϕ</em>(<em>i</em>)·Δ<strong>θ</strong><sub>d</sub>，<strong>θ</strong><sub>f</sub>=<strong>θ</strong><sub>f</sub>-<em>ϕ</em>(<em>i</em>)·Δ<em>θ</em><sub>f</sub></p><p><em>i</em>+=1</p><p>End while</p><p>輸出：<strong>θ</strong><sub>f</sub>，<strong>θ</strong><sub>main</sub>，並預測標籤<img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78830004b643de75aaf0></p><p>本方法有3個需要人工設置的參數，<em>λ</em>、<em>γ</em>及學習率<em>ϕ</em>。其中，<em>λ</em>是固定的，<em>γ</em>和<em>ϕ</em>按照式(9)和式(10)更新</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/788400049360c9e7da8e><p>(9)</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78820006a523263632c2><p>(10)</p><p>式中，<em>ϕ</em>(0)為初始學習率；<em>t</em>=<em>i</em>/num_step，<em>i</em>為當前迭代次數，num_step為最大迭代次數。</p><p>2 試驗2.1 構建數據集</p><p>目前還沒有公開的適用於遙感影像域適應試驗的數據集，故本文使用了3個數據作為數據源構建域適應數據集，分別是：①NWPU-RESISC45數據集<sup>[1]</sup>(簡稱NWPU)，該數據集含有45類場景的遙感影像，每類影像都包含有700張圖片，共31500張影像；②一整幅遙感影像為Quickbird衛星拍攝的西安市遙感影像(簡稱Xian)，尺寸為13312×7680像素。對Xian進行了切割，並人工分類標註，選出與NWPU重疊的8個類，共339張影像；③一整幅遙感影像為高分二號衛星拍攝的廣州市遙感影像(簡稱GZ)，與處理Xian類似，對其進行切割與人工標註，選出與NWPU重疊的8個類，共826幅影像。因此以上3個數據集共構成了兩組遙感影像域適應數據集，將其分別命名為NWPU-Xian8及NWPU-GZ8。示例圖像如圖 2所示，每張示例圖像底部數字為該類樣本數。從圖 2可以看出，NWPU-Xian8的圖像差異較大，Xian的影像顏色存在失真，並且噪聲較為嚴重，而NWPU-GZ8影像差異較小。兩組數據集中NWPU的其餘37類影像在這裡不再展示，請參考文獻[1]。以上所有影像的尺寸為256×256。</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8d72caf960><p>圖 2 數據集各類示例Fig. 2 Samples from each category in the domain adaptation datasets</p><p>圖選項</p><p>2.2 試驗設置</p><p>針對兩組數據集進行的試驗中，分別將NWPU整個45類作為源域，Xian及GZ作為目標域。因此在NWPU-Xian8及NWPU-GZ8中，主任務的數據類別都為8類，輔助類別為37類。訓練及測試時對輸入到網絡中的影像隨機裁剪為227×227，網絡的各個參數，比如卷積核大小，步長和卷積層的層數如圖 3所示，前8個方框表示特徵提取層，本文特徵提取階段使用了預訓練的Alexnet網絡結構<sup>[24]</sup>。緊接著特徵提取層，為3個網絡分支，這3個分支分別為主分類器，輔助分類器和域分類器。3個分類器都是由全連接層構成，其最終輸出結點分別為8、37和2。本文所有試驗代碼基於tensorflow進行搭建，硬件環境為Amazon EC2的P2.xlarge實例，該實例的GPU型號為nvidia tesla k80。</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/78820006a5288b384718><p>圖 3 本文方法的網絡結構Fig. 3 The net structure of the proposed approach</p><p>圖選項</p><p>2.3 試驗結果與分析</p><p>將本文方法與文獻中其他方法進行試驗對比。對比的方法有：①source only，將源域數據輸入到網絡進行訓練，直接對目標域進行分類，不加入域損失和輔助損失函數；②GFK，文獻[5]中的方法；③Landmark，文獻[6]所介紹的方法，是文獻[5]方法的擴展，GFK和Landmark，其使用的圖像特徵是由預訓練的alexnet網絡的fc7層提取得到，每張圖像都表示為4096維特徵；④source+domain，文獻[20]中的方法，即源域樣本分類與域分類同時進行，沒有增加輔助分類任務；⑤MMD，文獻[7]中的方法，使用MMD損失函數進行域間最小化。對於source only及後3種方法，設置初始學習率<em>ϕ</em>(0)=0.002，batchsize=64，最大迭代次數為10000；MMD中，MMD損失是用fc7的輸出進行計算得到，係數為0.25；本文方法中，<em>λ</em>=1。各類方法最後對目標域數據進行分類，對於GFK和Landmark，計算20次試驗的平均精度作為其最終精度。對於其他方法，設置每訓練25次進行一次測試，將最後10次測試的平均精度作為其最終精度，6種方法最終測試精度列於表 1。基於最後一次測試的結果計算各方法預測的混淆矩陣，將各個方法對於NWPU-Xian8數據集的混淆矩陣列於圖 4。</p><p>表 1 不同算法分類精度Tab. 1 Classification accuracy of different algorithms</p><table><thead><tr><td colspan=7>(%)</td></tr><tr><br><td>source only</td><td>GFK</td><td>Landmark</td><td>source+domain</td><td>MMD</td><td>本文方法</td></tr></thead><tbody><tr><td>NWPU-Xian8</td><td>58.40</td><td>60.47</td><td>69.44</td><td>76.40</td><td>63.12</td><td>79.63</td></tr><tr><td>NWPU-GZ8</td><td>76.99</td><td>78.32</td><td>81.07</td><td>83.50</td><td>77.05</td><td>84.63</td></tr></tbody></table><p>表選項</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/727c000a5b8ed703d2e5><p>圖 4 NWPU-Xian8數據集混淆矩陣Fig. 4 Confusion matrix for NWPU-Xian8 dataset</p><p>圖選項</p><p>從表 1可以得到看出，本文方法在精度上優於其他算法，source+domain次之。圖 4中，本文方法相對於其餘5類方法，表現較為均衡，對於容易混淆的intersection、freeway和overpass這3類的精度也有了一定的提高。由此表明了對抗網絡和輔助任務可以較好地學習到域不變特徵，提高網絡的泛化能力和分類精度。</p><p>為了進一步驗證本文方法提取域不變特徵的優勢，用高維數據可視化工具t-SNE對NWPU-Xian8數據集聚類結果進行可視化(t-SNE詳情參見文獻[27])。聚類的對象為進入到分類器之前目標域所有數據的特徵。如圖 5所示，圖(a)為直接採用預訓練的Alexnet網絡提取的fc7層特徵，圖(b)為本文方法倒數第2層輸出的特徵，兩種特徵都為4096維。兩張圖分別表示未進行域適應和進行了域適應後目標域數據各類之間的關係。可以看出進行域適應後，目標域各類之間距離增大，同類之間距離減小，很好地學習到了域不變特徵。</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/78850002c65381cefecb><p>圖 5 NWPU-Xian8數據集目標域圖像特徵的二維可視化Fig. 5 2-D visualization of image feature in the target domain for NWPU-Xian8 dataset</p><p>圖選項</p><p>3 結論</p><p>本文針對遙感影像場景分類中小樣本量的無監督學習問題，提出了一種結合對抗網絡與輔助任務的遙感影像域適應方法，建立了基於深度卷積神經網絡的遙感影像分類框架，在標籤損失函數的基礎上加入了域分類器，並使得域損失函數與標籤損失形成對抗的關係，最後引入了輔助分類任務，擴充訓練樣本。在本文構建的遙感影像域適應數據集上試驗結果表明，本文方法能夠通過域損失學習到域不變特徵，通過輔助分類任務增加類間距離、減小類內距離，並使網絡具有良好的泛化能力，在不同域的無監督分類中有明顯的優勢。對小樣本量的Xian和GZ數據集無監督分類精度達到79.63%和84.63%，相對於直接利用大樣本量數據集NWPU對Xian和GZ數據集分類(58.40%和76.99%)，本文方法分類效果有顯著提高。</p><p><strong>【引文格式】許夙暉，慕曉冬，張雄美，等。結合對抗網絡與輔助任務的遙感影像無監督域適應方法[J]. 測繪學報，2017，46(12)：1969-1977. DOI: 10.11947/j.AGCS.2017.20170291</strong></p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/39d40000b5178f24974d><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/1d58000c77f8222af5dc><p>往期精彩回顧</p><img alt=論文推薦｜許夙暉：結合對抗網絡與輔助任務的遙感影像無監督域適應方法 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/3009000f15ca5ebfaebd><p><strong>李德仁院士：老師教我做人做學問</strong></p><p><strong>關於稿件“時間”安排那些事兒~</strong></p><p><strong>重磅！新增博士、碩士學位授權點名單出爐，有你的母校嗎</strong></p><p><strong>組建“自然資源部”的來龍去脈</strong></p><p>權威 | 專業 | 學術 | 前沿</p><p>微信投稿郵箱 | song_qi_fan@163.com</p><p>微信公眾號中搜索「測繪學報」，<strong>關注我們</strong>，長按上圖二維碼，關注學術前沿動態。</p><p>進群請備註：姓名+單位+稿件編號</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>論文</a></li><li><a>推薦</a></li><li><a>許夙暉</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/e55aaf9b.html alt="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e55aaf9b.html title="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望">論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html alt=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html title=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術>論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html alt="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html title="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法">論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html alt=「論文推薦」左建平教授談岩層移動研究進展及重點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RmTmvrAHAwNOUb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html title=「論文推薦」左建平教授談岩層移動研究進展及重點>「論文推薦」左建平教授談岩層移動研究進展及重點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html alt=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ReafrDd7EHXniF style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html title=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制>「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html alt="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html title="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法">論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html alt=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S0q6oVj53DcDnj style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html title=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究>「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html alt="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html title="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法">論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html alt="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html title="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析">論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html alt="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html title="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法">論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html alt="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html title="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術">論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c7555ef5.html alt=論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/53410004acf9b032d928 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c7555ef5.html title=論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法>論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f22ea791.html alt=論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f22ea791.html title=論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法>論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7c51035d.html alt=論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15294875207731e288b7418 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7c51035d.html title=論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法>論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d07bf9bc.html alt=論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/53350006726e50ef72f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d07bf9bc.html title=論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解”>論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解”</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>