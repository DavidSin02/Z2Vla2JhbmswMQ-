<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>自然語言處理中的深度學習：評析與展望 | 极客快訊</title><meta property="og:title" content="自然語言處理中的深度學習：評析與展望 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e0b5c472.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e0b5c472.html><meta property="article:published_time" content="2020-11-14T21:00:20+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:20+08:00"><meta name=Keywords content><meta name=description content="自然語言處理中的深度學習：評析與展望"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e0b5c472.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>自然語言處理中的深度學習：評析與展望</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>為什麼深度學習能夠成為自然語言處理的強大工具？未來深度學習在自然語言處理中將如何發展？本文嘗試回答這兩個大家都關心的問題。首先，概述腦科學、認知科學中關於人的語言處理的學說，之後，從機器學習理論角度總結深度學習的特性、優勢和不足。接著，分析深度學習在自然語言處理成功的原因和特點。最後，展望自然語言處理的未來發展方向，總結自然語言處理的重要研究課題。</p><p><strong>1. 人的語言處理</strong></p><p>人是如何進行語言處理，即語言理解和語言生成的？這個問題仍是當今科學最大的未解之迷。腦科學、認知科學有一些發現和假說。比如達馬西奧（Antonio Damasio）等腦科學家有這樣的觀點[1]。</p><p>人腦是由神經元組成的大規模複雜神經網絡，生物信號在神經網絡上不斷傳遞，使神經網絡的狀態不斷髮生變化，不同的狀態形成不同的神經表徵（neural representation）。這種“神經計算”都是在人的下意識中進行的，只有一部分能夠上升到意識，對應著人的思考。人的思考其實是在意識中產生表象（image）的神經計算，表象有視覺表象、聽覺表象，運動表象等。</p><p>人的語言處理也一樣，本質是在下意識中進行的神經計算，能意識到的只是語言理解和生成過程中產生的表象。人的語言理解過程是喚起語言相關的概念的表象，在其基礎上組合產生出新的表象的過程。語言中的符號包括語音符號，文字符號，以表徵的形式記憶在人腦裡，語言處理中被激活使用。人的語言處理不是符號計算。</p><p><strong>2. 深度學習</strong></p><p>深度學習是以複雜人工神經網絡為模型的機器學習。（人工）神經網絡是受生物神經網絡啟發而開發的，由（人工）神經元連接組成的網絡，本質是數學模型。神經元是非線性函數，神經網絡是由許多神經元組成的複合函數。神經網絡的特點是擁有大量參數，參數的估計可以通過在數據上的目標函數優化得到。參數的學習使用反向傳播算法，只要神經網絡的函數可微分，就可以進行。神經網絡的計算能夠實現某種功能，如圖像識別、機器翻譯。</p><p>事實證明，深度學習是實現機器智能的強大工具。以下從機器學習理論角度總結深度學習的優缺點。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade><p class=pgc-img-caption>圖1. 關於深度學習的一些理論結果</p></div><p><strong>優點</strong></p><p>深度學習的優點主要體現在三個方面。</p><p>首先，神經網絡擁有強大的函數近似能力。通用函數近似定理（定理1）指出，即使是二層神經網絡就可以以任意精度近似任意一個連續函數。假設實現某一功能的“理想”的函數存在，則有可能存在一個神經網絡是這個函數的充分近似。</p><p>其次，深的神經網絡比淺的神經網絡擁有更精簡的表達能力，更高的樣本效率（sample complexity）。存在這樣的情況，深而窄的神經網絡與淺而寬的神經網絡是等價的。但前者的參數比後者更少，只需要較少的樣本就可以學到。極端情況，淺而寬的神經網絡的寬度是指數級的，現實中並不可取。這方面的理論支持來自邏輯門電路。因為神經網絡可以表示邏輯門電路，所以關於邏輯門電路的結論（定理2）也適用於神經網絡。</p><p>再有，深度學習有很強的泛化能力，也就是從訓練集上學到的誤差小的模型在測試集上也同樣有小的誤差[2]。深度學習中常常不做正則化也不產生過擬合。通常是在大規模訓練數據，過參數化（over-parameterized）神經網絡、以及隨機梯度下降（SGD）訓練的條件下發生的，這裡過參數化是指網絡的參數數量大於訓練數據數量。已有機器學習理論尚不能很好解釋這種現象，是當前熱門的研究課題。最近有理論研究對一些特殊情況下的泛化能力做出證明（定理3）[3]。</p><p>這些事實說明深度學習具有強大的複雜模式學習的能力。</p><p><strong>缺點</strong></p><p>深度學習也有缺點，缺乏強健性（robustness）是一個廣為人知的問題。也就是數據中很小的擾動就會導致預測錯誤。這應該是深度學習的強大學習能力所致。強健的學習可以定義為min max的優化問題。一般的機器學習的目標是在平均情況下預測誤差最小，而強健的學習的目標是在最壞情況下預測誤差最小，具體地數據在某個範圍內發生對自己最不利的擾動時也能保證平均預測誤差最小。最近的理論研究證明[4]，在一些特殊情況，強健的學習比一般的學習需要更多的樣本（定理4），結論對深度學習和傳統機器學習都適用。這對深度學習來說不是一個好消息，意味著它需要更多的樣本才能變得強健。</p><p>深度學習的另一個缺點是筆者稱為恰當性（adequacy）的問題。深度學習權威Yoshua Bengio曾說：“從現有深度學習系統的失敗我們能得出什麼結論？ 我會說，最顯著的是系統往往通過表面線索學習，而這些線索有助於幫助完成特定任務。 但通常這些並不是人認為最重要的。”由於訓練數據的偏差，機器學習的特點（預測誤差最小化導向，訓練中的隨機性）等原因所至，深度學習常常“學到不恰當的知識”。比如，圖像識別中認為有把手的就是杯子，有輪胎的就是汽車。傳統機器學習也有這個問題，但深度學習的問題更突出。深度學習就像是一個只擅長考試的學生，成績很好，但並沒有掌握好知識。</p><p><strong>可解釋性</strong></p><p>神經網絡不具備可解釋性，但筆者認為這並不一定是缺點。可解釋性依賴於應用，比如在金融、醫療等領域的預測需要可解釋，但是其他領域的預測未必如此。人也不能解釋自己是如何進行感知和認知處理的，未必需要深度神經網絡能夠解釋自己的決策過程。</p><p><strong>3. 深度學習用於自然語言處理</strong></p><p>自然語言處理的問題從機器學習的角度可以歸結為五大類問題，分別是分類、匹配、轉換、結構預測、序列決策過程，如表1所示。深度學習使這五大任務的正確率都有很大提升，特別是匹配和轉換[5]。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/57b07c8444ea4897a2827da2f9b36099><p class=pgc-img-caption>表1 自然語言處理問題</p></div><p>我們還不知道人是如何進行語言處理的。深度學習，特別是在監督學習的場景，實際是在用數據驅動的方法近似人的語言處理功能。參照人如何對給定輸入產生相應輸出，然後進行“模仿“，如圖2所示。人工的神經處理和生物的神經處理有某些相似性，但更本質的是人工神經網絡作為數學模型有很強的表達能力，深度學習作為機器學習方式有很強的學習能力。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/68dca8be07934c30b0ca0739f01898a8><p class=pgc-img-caption>圖2. 自然語言處理中使用深度學習</p></div><p>機器學習專家David McAllester認為：深度學習提供的是一種通用的可微分的編程工具集，包括各種網絡、殘差連接，門控，注意力，GAN等。人工智能的進步主要來自這些深度學習工具的使用，而這個趨勢會持續下去[6]。</p><p>深度學習用於自然語言處理，通常將單詞表示為實數向量，也就是單詞嵌入。將句子或文本表示為單詞的向量序列，作為輸入。輸出是通過軟最大化（softmax）得到的類別，可以針對整個輸入，也可以針對每個單詞。自然語言處理中常使用的模型有前饋神經網絡、循環神經網絡、卷積神經網絡、序列對序列模型。常用的損失函數是交叉熵。注意力是自然語言處理中強大的工具，機器翻譯中的Transformer、預訓練模型BERT都使用注意力。</p><p>注意力實際是一種軟的聯想記憶機制，是鍵-值（key-value）數據庫的一種推廣。傳統的鍵-值數據庫中，查詢、鍵、值都是符號。給定查詢（query），找到完全匹配的鍵，返回相應的值。注意力中，查詢、鍵、值都是實數向量。給定查詢，計算查詢和所有鍵的匹配度，以歸一化匹配度為權重計算值的加權平均，並返回加權平均向量，如圖3所示。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/dfic-imagehandler/da6f7762-8e64-4d79-91c5-36824eabcc54><p class=pgc-img-caption>圖3. 注意力機制</p></div><p>考慮Transformer的編碼器，也是BERT的基本模型。給定一個句子，編碼器可以生成其層次化的語義表示。每一個單詞在每一層上有以這個單詞為中心的語義表示(實數向量)。下一層的語義表示通過自我注意力(self-attention)生成上一層的語義表示。直觀上每個單詞的語義表示和其他所有單詞的語義表示基於相似度組合成新的語義表示。比如，圖4中“John”，“loves”，“Mary”三個字各自有一個語義表示，在自我注意力中都成為查詢、鍵、值。以每個單詞的語義表示為查詢，以所有單詞的語義表示作為鍵和值，通過注意力可以得到每個單詞的新的語義表示。這樣一層層疊加，可以得到整個句子所有單詞的語義表示。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/e01c8eee3cd54ec4a3d4693ddc8fb4c5><p class=pgc-img-caption>圖4. 通過自我注意力從下一層語義表示生成上一層語義表示</p></div><p class=ql-align-center><strong>4. 未來研究課題</strong></p><p>面向未來，圍繞著深度學習與自然語言處理，筆者認為有幾個重要課題需要進行探索，也能帶來很大的技術進步，分別是多模態、生成、預訓練、神經符號處理。關鍵是開發相關的新的神經網絡模型。</p><p>深度學習之前，圖像、語音、語言幾個領域的技術相對比較獨立。深度學習把它們緊密地聯繫在一起。首先，有很多深度學習技術可以跨領域使用，比如卷積神經網絡。再有，在深度學習裡，圖像、語音、語言的內容都用同樣的實數向量來表示，可以做跨模態的信息處理，比如看圖說話就是典型的例子。多模態信息處理還有很大發展空間，可以預見今後還會產生很多新的技術及新的應用。</p><p>深度學習給自然語言處理帶來的主要變革在於生成。序列對序列模型，特別是Transformer，大幅度提高了機器翻譯的正確率。在訓練語料充分的領域的機器翻譯，比如新聞的翻譯，已經可以實用。生成式的對話系統之前基本不存在。現在，只要有足夠多的對話數據，訓練一個序列對序列模型，在一定範圍內可以進行表面自然的單輪對話。圍繞著生成，還有很多可以研究的課題，技術創新還有很大的潛力。</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/9a846fe0acfd4668850589268246fbd8><p class=pgc-img-caption>圖5. 深度學習中的預訓練</p></div><p>預訓練是指用大量的無標註數據，事先訓練語言表示模型，然後用於各種語言處理任務。圖5顯示預訓練與語言處理任務的關係，x'表示無標註數據，h(x')表示通過預訓練學到的表示模型，可以幫助任務y=f(x)完成得更好。甚至只需要有少量數據精調任務模型即可。最近預訓練的語言表示模型BERT用於不同的語言處理任務，都帶來了正確率的大幅度提升，讓人驚歎。無標註數據是大量存在的，預訓練技術促進自然語言處理髮展的前景非常可觀。深度學習權威Geoffrey Hinton等一直強調無監督學習是深度學習未來發展方向，理由是機器需要像人一樣只用少量標註數據就可以學到知識。他在最近的Google I/O 2019大會上闡述了同樣觀點[1]</p><div class=pgc-img><img alt=自然語言處理中的深度學習：評析與展望 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0be5591604d34dc3bae8f83bd839797c><p class=pgc-img-caption>圖6. 神經符號處理</p></div><p>神經符號處理是指將神經處理（深度學習）與符號處理（傳統方法）進行結合，實現更強大的語言處理能力。神經符號處理並沒有嚴格定義，圖6顯示一種基本情況，s表示有結構的符號，g(s)表示從符號中得到的神經表徵。可以認為神經處理與符號處理各自對應著人的下意識和意識層面的信息處理。兩種處理擁有完全不同的特性，其結合不是一件簡單的事情。但如果有突破，會給自然語言處理帶來革命性的進步。NeurIPS 2018會議上，向Geoffrey Hinton請教了他對神經符號處理的看法。Hinton沒有正面回答這個問題，而是用一個比喻做了說明。他說：“假設你有一個很好的電動汽車，豐田汽車來找你，問是否可以把它和傳統的燃油汽車結合到一起。你問的問題就像是這樣一個問題“。感覺大師不是很看好這個方向。</p><p><strong>5. 結語</strong></p><p>深度學習的成功依賴於大數據和大算力。過去30年，計算速度、通信速度、內存容量均提高了100萬倍。可以預見，計算能力未來速度有可能減緩，但增長態勢不會變化。所以隨著硬件技術的發展，深度學習技術本身（如第4節所述技術）也會不斷進步，給自然語言處理領域帶來巨大變革。</p><p>另一方面語言是認知現象，涉及到知識和推理。人的語言使用乃至思考的機制還不清楚，但從現象上看涉及到意識（表象）和下意識（表徵）。看來僅僅利用深度學習、更一般地神經計算可能不能完全實現。（這一點與屬於感知的圖像和語音不同）。現實中，知識還主要靠人工定義，雖然有很大侷限，但仍是最可行且最有效的手段。</p><p>未來的自然語言處理是基於神經計算，符號計算，還是兩者的結合？現在還不是很清楚。需要長時間的探索和研究。</p><p><strong>參考文獻</strong></p><p>1. 李航，智能與計算，計算機學會通訊，2019年第一期。</p><p>2. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding Deep Learning Requires Rethinking Generalization, 2017.</p><p>3. Yuanzhi Li, Yingyu Liang. Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data, 2018.</p><p>4. Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, Aleksander Mądry. Adversarially Robust Generalization Requires More Data, 2018.</p><p>5. Hang Li. Deep Learning for Natural Language Processing, National Science Review, Perspective, 2017.</p><p>6. David McAllester. Universality in Deep Learning and Models of Computation, Second Workshop on Symbolic-Neural Learning, Nagoya, 2018.</p><p>[1] Hinton用無監督學習這個術語，就是這裡說的預訓練。</p><hr></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>語言</a></li><li><a>處理</a></li><li><a>學習</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/b0abef72.html alt="深度學習自然語言處理模型實現大集合（精簡版<100行）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d1461dcb71974b569c9b1ae64e150139 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b0abef72.html title="深度學習自然語言處理模型實現大集合（精簡版<100行）">深度學習自然語言處理模型實現大集合（精簡版&lt;100行）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html alt=第12屆自然語言處理和知識工程國際會議將在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html title=第12屆自然語言處理和知識工程國際會議將在西華大學舉行>第12屆自然語言處理和知識工程國際會議將在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html alt=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/4e62000034a58600d55e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html title=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行>第12屆自然語言處理與知識工程國際學術會議在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1b9aa0e9.html alt=最有效的易語言命令學習方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/aa37fb5eda8c4ae280dd0cacc0f60944 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1b9aa0e9.html title=最有效的易語言命令學習方法>最有效的易語言命令學習方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/824bb18c.html alt=自然語言的語義表示學習方法與應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/521cf0b197594fb3957739696fc08bc7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/824bb18c.html title=自然語言的語義表示學習方法與應用>自然語言的語義表示學習方法與應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html alt=你對自然語言處理了解多少呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/150674bcc0e44efcae3427c70ad2f072 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html title=你對自然語言處理了解多少呢？>你對自然語言處理了解多少呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html alt=自然語言處理中的語言模型簡介 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html title=自然語言處理中的語言模型簡介>自然語言處理中的語言模型簡介</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html alt=自然語言處理的十大應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dea6cbd6fbef4e9c935b6f56cb9b0097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html title=自然語言處理的十大應用>自然語言處理的十大應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html alt=人工智能之自然語言處理初探 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S4bjUwAFhO20v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html title=人工智能之自然語言處理初探>人工智能之自然語言處理初探</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html alt=人工智能的研究熱點：自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5fdd13a7-6c6d-45d6-9fcd-2829793b5dd3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html title=人工智能的研究熱點：自然語言處理>人工智能的研究熱點：自然語言處理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html alt=什麼是自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/64bcc3b1fb8a4f9ca59d452035ca25cb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cb76338d.html title=什麼是自然語言處理>什麼是自然語言處理</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>