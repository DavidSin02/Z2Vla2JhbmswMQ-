<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望 | 极客快訊</title><meta property="og:title" content="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e55aaf9b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e55aaf9b.html><meta property="article:published_time" content="2020-11-14T21:08:27+08:00"><meta property="article:modified_time" content="2020-11-14T21:08:27+08:00"><meta name=Keywords content><meta name=description content="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e55aaf9b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong class=highlight-text toutiao-origin=span>《測繪學報》</strong></p><p><strong class=highlight-text toutiao-origin=span>構建與學術的橋樑 拉近與權威的距離</strong></p><p><strong>航攝影像密集匹配的研究進展與展望</strong></p><p>袁修孝<sup>1</sup><img alt="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY>, 袁巍<sup>1,2</sup>, 許殊<sup>1,3</sup>, 紀豔華<sup>1</sup></p><p>1. 武漢大學遙感信息工程學院, 湖北 武漢 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">30</i>0<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">79</i>;</p><p>2. 東京大學空間信息科學中心, 東京 柏市 277-6568;</p><p>3. 中國科學院空天信息創新研究院, 北京 100094</p><p>收稿日期：2019-10-31；修回日期：2019-11-20</p><p>基金項目：國家自然科學基金(4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">177</i><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">147</i>9);國家高分專項(民用部分)(50-H31D01-0508-13/15)</p><p>第一作者簡介：袁修孝(1963-), 男, 博士, 教授, 博士生導師, 主要研究航空航天遙感高精度對地目標定位理論與方法、高分辨率衛星遙感影像幾何處理等。E-mail:yuanxx@whu.edu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">.cn</i></p><p><strong>摘要</strong>：給出了航攝影像密集匹配的總體流程，依據是否顯式使用光滑假設將密集匹配方法分為局部最優密集匹配和全局最優密集匹配兩類，深入探討了兩種方法的關鍵技術，指出了從理論、技術、普適性和實用性方面值得<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">關注</i>的問題，期望能對相關研究有所裨益。</p><p>關鍵詞：航攝影像 密集影像匹配 局部最優匹配 全局最優匹配 光流場法 深度學習方法</p><p><strong>Research developments and prospects on dense image matching in photogrammetry</strong></p><p>YUAN Xiu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">xi</i>ao<sup>1</sup>, YUAN Wei<sup>1,2</sup>, XU Shu<sup>1,3</sup>, JI Yanhua<sup>1</sup></p><p>1. School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">30</i>0<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-6">79</i>, China;</p><p>2. Center for Spatial Information Science, University of Tokyo, Kashiwa 2776568, Japan;</p><p>3. Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China</p><p>Foundation support: The National Natural Science Foundation of China (No. 4<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">177</i><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">147</i>9); The National High-Resolution Earth Observation System (the Civil Part) (No. 50-H31D01-0508-13/15)</p><p>First author: YUAN Xiu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">xi</i>ao(1963—), male, PhD, professor, PhD supervisor, majors in theory and method for high precision airborne and spaceborne photogrammetric positioning and geometric processing of high-resolution satellite remote sensing imagery.E-mail:yuanxx@whu.edu<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">.cn</i>.</p><p><strong>Abstract</strong>: The general workflow for dense matching of aerial images is given in this paper. Dense matching is divided into two categories, namely, those that utilize local matching algorithms and global matching algorithms, respectively. The key technologies of the two methods are analyzed in details. Concerns in theory, technology, universality and practicability are proposed. We hope it will be helpful to the related research on dense matching.</p><p>Key words: aerial image dense image matching local matching algorithm global matching algorithm optical flow field-based method deep learning-based method</p><p>航攝影像密集匹配是在獲得影像間的相對位置關係之後於重疊區域內尋找每個像素同名像點的稠密影像匹配方法，是從二維航攝影像自動重建三維物體模型的最有效手段之一。由此生成的三維點雲具有位置精準、密度甚高、紋理豐富、逼真度好、成本低廉等特點，不但可用於數字表面模型(digital surface model, DSM)、數字高程模型(digital elevation model, DEM)和數字正射影像圖(digital orthphoto map, DOM)等地理信息的自動提取，而且可為數字/智慧城市建設直接提供目標三維座標源數據<sup>[1</sup><sup>-2</sup><sup>]</sup>。</p><p>航攝影像的密集匹配不同於影像量測的稀疏匹配<sup>[3</sup><sup>]</sup>，主要表現在：①點位不可選擇。密集影像匹配要儘可能地做到逐像素匹配，這就無法迴避較大幾何畸變、弱紋理及重複紋理等特殊紋理區域。②<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>策略不一樣。密集影像匹配通常是在核線影像上設定的視差範圍內進行一維<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>，而稀疏影像匹配往往需要在一個較大的平面區域或者核線段內進行遍歷。③複雜度不一致。密集影像匹配的代價或流程不宜太複雜，否則會因計算機的性能限制或耗時太長而缺乏實用價值，稀疏影像匹配由於只需對特定的特徵點進行識別，即使是設計出相對複雜的描述符或流程往往也是可以接受的。④匹配約束不相同。密集影像匹配由於需要對每個像素都識別同名像點，很容易施加普遍的顯式光滑約束，而稀疏影像匹配一般無須這樣處理。</p><p>縱觀現行的航攝影像密集匹配方法，根據所採用的圖像基元可以將其分為基於灰度的密集匹配、基於特徵的密集匹配和基於相位的密集匹配3大類型。基於灰度的密集匹配能夠獲得非常稠密的匹配點雲，但其精度受影像幾何和輻射畸變的影響較大，像素點約束窗口的大小和形狀難以選擇；基於特徵的密集匹配可以得到高精度的匹配點雲，但特徵提取計算代價太大，容易受到地物遮蔽、紋理重複等因素的影響，匹配效率比較低；基於相位的密集匹配一般不太適合於光學遙感影像。另一方面，根據所採用的優化理論又可以將影像密集匹配分為局部最優密集匹配和全局最優密集匹配兩種。前者雖然效率高，但是誤匹配點較多，精度比較低；後者雖然能夠得到整體高精度的匹配點雲，但是優化代價太大，匹配效率不高。為此，本文擬對當前廣泛應用的密集影像匹配方法進行綜合分析和探討，以期對相關的研究起到拋磚引玉的作用。</p><p><strong toutiao-origin=span>1 密集影像匹配的總體流程</strong></p><p>航攝影像的密集匹配可以對單個立體影像對<sup>[4</sup><sup>-5</sup><sup>]</sup>、也可以對多度重疊的多視影像序列<sup>[6</sup><sup>-7</sup><sup>]</sup>進行。在獲得影像的內、外方位元素或者影像的相對方位元素的前提下，實施過程大體分為核線影像生成、匹配代價計算、匹配代價聚合、視差計算與精化、三維點雲生成幾個主要步驟。其一般流程可描述為圖 1。</p><img alt="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RnOpWS8FDt1USz><p>圖 1 航攝影像密集匹配Fig. 1 Dense image matching for aerial images</p><p>圖選項</p><p><strong toutiao-origin=span>2 現行的密集影像匹配方法</strong><strong toutiao-origin=span>2.1 局部最優密集匹配</strong></p><p>局部最優密集匹配通過計算待匹配點與周圍局部鄰域點的匹配代價，隱式地使用光滑假設約束，採用WTA(winner-takes-all)策略選取匹配代價最小點作為同名像點<sup>[8</sup><sup>]</sup>。由於這類方法大多采用矩形窗口進行匹配代價聚合，所以又稱為基於窗口的密集影像匹配。最具代表性的有基於絕對誤差和(sum of absolute differences, SAD)<sup>[9</sup><sup>]</sup>、絕對平方差和(sum of squared differences, SSD)<sup>[10</sup><sup>]</sup>測度的密集匹配和基於相關係數的密集匹配<sup>[11</sup><sup>]</sup>等。這類方法的優勢在於計算複雜度低，冗餘計算量少<sup>[12</sup><sup>]</sup>；缺點是容易陷入局部最優，導致匹配結果與真實地形不太相符<sup>[13</sup><sup>-15</sup><sup>]</sup>。究其原因就在於：①假設視差在匹配窗口內一致，與事實明顯不符，導致在影像深度不連續處(多為地物邊緣)和遮蔽區域的匹配效果不佳；②由於同譜異物現象，使算法出現病態，無法正確找到同名像點，特別是在影像紋理貧乏區匹配效果較差。為此，在代價聚合方式上逐漸演化出如下3種解決方案。</p><p><strong toutiao-origin=span>2.1.1 窗口形狀改變法</strong></p><p>這類方法通過調節匹配窗口的形狀，或者從多個窗口中選擇一個視差較為一致的窗口，來解決匹配窗口視差不一致的問題，同時也希望通過擴大窗口來最大限度地提高匹配的可靠性。早期的研究有移動窗口法<sup>[9</sup><sup>]</sup>和形狀自適應窗口法<sup>[16</sup><sup>]</sup>。這類方法對以目標像素為中心的匹配窗口聚合代價，前者將窗口內的最小代價直接賦給待匹配像素，本質上是以內部更加一致的窗口代替了鄰近或橫跨邊緣的聚合窗口，使視差不連續處的匹配效果得以改善，以犧牲地物的邊緣信息為代價；後者是在假設匹配窗口內視差滿足一定條件(譬如高斯分佈)的前提下，通過窗口內視差的均值和方差來獲得不確定度，依此選擇窗口變化的方向和大小。這種方法簡化了現實場景的複雜度，增加了不確定度的迭代計算量。此後，人們又提出了基於十字的代價聚合方法<sup>[17</sup><sup>]</sup>。它依據顏色相近的像素很有可能具有一樣視差的假設，在某個閾值下為每個像素判斷出連續的十字範圍，通過截取目標像素水平臂上相應像素的垂直臂的並集來獲得代價聚合區域，取得了比較好的試驗結果。由於方法高度的規則性，代價聚合可以通過積分影像技術進行加速，但閾值需要根據匹配效果來人工調節。</p><p><strong toutiao-origin=span>2.1.2 窗口權重改變法</strong></p><p>這類方法是在匹配代價聚合過程中通過改變匹配窗口內原始代價的權值來實現的，分為基於濾波的和基於分割的兩種方法。</p><p>濾波的方法是依據顏色一致區域的視差非常接近、連續區域具有更加相近的視差的假設，確定匹配窗口內每個像素的權重，以此來進行匹配代價聚合。其本質是對不滿足窗口假設條件的代價賦予小的權值<sup>[18</sup><sup>]</sup>。具體說來，就是用與中心像素的幾何距離以及與中心像素顏色的差異來定權。離中心像素越遠、顏色差異越大，其權值就越小。這種方法首次將局部匹配方法的正確率提升到了與全局方法相當的程度，但由於其需要大量的重複計算，效率比較低。此外，由於地物邊緣處會出現顏色相近像素較少的情況，效果明顯變差。為了提高密集影像匹配的效率，人們又進行了一系列的改進<sup>[19</sup><sup>-20</sup><sup>]</sup>，加速了匹配代價聚合的過程。文獻[18]的假設在大多數情況下都能滿足，但在複雜空間中顏色相近、視差相距甚遠的情況也時有發生。文獻[21]用測地線距離定權來解決這個問題，即當目標像素與中心像素有一條通路上的顏色沒有明顯改變時，可以獲得較大的權值，以此來附加聚合區域的聯通約束。這種改進，對區域相對簡單的場合比較有效，但對於結構高度複雜的區域，由於定權方式所導致的聚合區域過小而變得效果不佳。沿著這種濾波思路，人們相繼又提出了旨在提高計算效率並解決邊緣支持度不足的基於引導濾波的定權方法<sup>[22</sup><sup>-23</sup><sup>]</sup>和利用空間通道可靠性定權的方法<sup>[24</sup><sup>]</sup>。</p><p>分割的方法是假定分割塊的邊緣與深度不連續處保持一致，且在每個分割塊內的視差保持一致或滿足某種關係(譬如仿射變換)，並以待匹配點是否落在分割塊內作為定權的一個重要參考依據<sup>[25</sup><sup>]</sup>。文獻[26]使用Mean Shift方法所獲得的分割結果作為輔助，給聚合窗口內與中心像素處於同一個分割塊的匹配代價以高權值，將位於其他分割塊內的匹配代價視為粗差，給予其低權值直至零值。文獻[27]顧及了對稱的兩張影像的分割，以避免遮蔽等在使用一張影像時的影響。這類方法依賴於影像分割的質量，新分割方法(如SLIC分割<sup>[28</sup><sup>]</sup>)的應用常常會促進方法的進步。儘管該類方法始於分割和局部匹配，但目前還是傾向於同時確定分割和視差、面向對象的匹配、語意匹配<sup>[29</sup><sup>-33</sup><sup>]</sup>等全局方法。</p><p><strong toutiao-origin=span>2.1.3 非前向平行窗口法</strong></p><p>與前面兩類方法不同，這類方法採用了非前向平行的聚合窗口，在處理與影像面有較大夾角的空間結構時，具有更好的匹配效果。其關鍵在於如何估計符合場景的斜面的方向。早期嘗試了平面聚類方法<sup>[34</sup><sup>-35</sup><sup>]</sup>，通過估計並使用非前向平行平面進行代價聚合和視差確定。此後，基於面片匹配的方法<sup>[36</sup><sup>-37</sup><sup>]</sup>為每個像素隨機生成初始視差及視差空間的法向量。依據空間相鄰像素和左右影像上潛在的同名像點具有同一參數的準則，通過比較利用鄰近像素和潛在同名點參數與使用當前點參數所計算出的匹配代價，選定一組更能符合實際情況的參數，並取代價小的參數作為新參數。為了進一步減小匹配代價，這類方法對選定的參數進行了精化。具體做法是在參數允許的最大變化範圍內，在原始參數上隨機地<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">加上</i>一個增量，觀察是否減小了代價。若減小了，則更新為新參數。否則，繼續增加，直至減小為止。在隨機初始化後，面片匹配方法希望能在具有相同或相近參數的區域中至少找到一個像素對應的參數能夠接近正確參數值。這類方法的缺點是：①因為隨機過程有可能遺漏了正確的候選視差，而根本無法獲得正確的匹配結果；②空間傳播和視傳播並非並行模式，不利於加速計算；③沒有顯式的光滑約束。針對這些問題，又衍生出了許多改進的方法。譬如，通過增加候選視差產生方式來避免遺漏；開始時為每一個像素準備好所有可能的參數，並非通過傳播和精化手段來逐漸增加，以利於並行處理；將其運用在全局方法中以顯式地建立光滑約束。</p><p>以上3種方法中，窗口形狀改變法和窗口權重改變法是在使用前向平行窗口時，努力使聚合窗口內的視差保持一致，而非前向平行窗口法則是使用了傾斜窗口，以便儘可能地估計出與實際情況相符的支持區域。</p><p><strong toutiao-origin=span>2.2 全局最優密集匹配</strong></p><p>全局最優密集匹配是通過構建全局能量函數來優化基於像素或者基於對象的匹配代價的，通過顯示式地使用光滑假設約束及相應的優化方法來獲取視差圖，從而找到同名像點，使得最終的匹配結果達到全局最優<sup>[38</sup><sup>]</sup>。在全局能量函數構建中，將像素間的光度相似性構成了代價函數的數據項，將對相近像素視差的變化約束懲罰構成了代價函數的光滑項。由於顧及了影像中每個像素的信息，匹配精度較高，但冗餘計算較大，匹配效率比較低。目前的研究主要集中在全局能量函數的構建和優化求解上。在匹配代價計算上，主要採用了基於互信息的匹配代價<sup>[39</sup><sup>]</sup>、基於梯度的匹配代價<sup>[40</sup><sup>]</sup>、基於Census變換的匹配代價<sup>[10</sup><sup>]</sup>和來自於深度學習的匹配代價<sup>[41</sup><sup>-42</sup><sup>]</sup>；在優化求解上，除了採用傳統的模擬退火<sup>[43</sup><sup>]</sup>、動態規劃<sup>[44</sup><sup>]</sup>等方法以外，圖割優化<sup>[45</sup><sup>-46</sup><sup>]</sup>、置信度傳播<sup>[47</sup><sup>-48</sup><sup>]</sup>等一系列方法的應用，使該類方法得以長足的發展。</p><p>為了能夠充分發揮全局最優密集匹配精度高和局部最優密集匹配速度快的優勢，文獻[39]最早提出了半全局密集匹配(semi-global matching, SGM)方法。其基本思想來源於線性規劃，通過多方向動態規劃提高了計算效率，但在影像匹配時並沒有考慮到全部像素，僅顧及了所有的非遮蔽點，相對於全局匹配和局部匹配方法而言，其精度和效率都有了不同程度的提高。具體表現為，在對相鄰像素視差依據其變化的程度差異給予不同懲罰值之後，首先對原始的全局方法分別按照8個或16個方向進行1維掃描線優化，然後通過<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">累加</i>多個方向的代價而獲得整體的聚合代價，最後運用WTA方法獲得每一個像素對應的視差值，從而導出同名像點。然而，這類方法存在的主要問題是掃描線優化時需要人為設定控制視差變化的兩個懲罰因子。懲罰過大則在視差斷裂處易出現過度平滑的情況，懲罰過小則在平滑區域會受噪聲影響而產生凹凸不平的現象。SGM方法曾試圖使用影像梯度來克服這個問題，即在高梯度區域使用低懲罰，在低梯度區域使用高懲罰。但是，由於影像梯度大的地方並不完全對應著深度不連續區域，因此在影像複雜紋理區域其效果並不理想。目前效果較好的遙感影像密集匹配商用軟件SURE<sup>[49</sup><sup>]</sup>採用了Canny邊緣檢測算子來自適應地調整匹配參數，在一定程度上緩解了上述矛盾，但對影像灰度噪聲仍相當<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">敏感</i>。文獻[2]通過分析核線影像的紋理信息，使用局部梯度、標準差計算紋理指標，在紋理缺乏區域施加較大視差連續性約束，在紋理豐富區域保留更大的匹配代價權重，以達到自適應調整參數的目的。文獻[5]充分利用稀疏匹配所獲得的較為可靠的匹配點作為約束，改善了密集匹配的效果。</p><p>為了提高航攝影像密集匹配對遮蔽和噪聲的穩健性，多視影像的密集匹配方法成為了另一個研究主題。計算機視覺中顧及了多視影像間的幾何關係和冗餘信息的基於面片的密集匹配算法被引入了攝影測量領域。通過提取到的影像中的稀疏特徵點，構建若干小的特徵面片集合，經匹配傳播達到密集匹配的效果<sup>[50</sup><sup>-52</sup><sup>]</sup>。文獻[7]提出的基於面片的多視影像匹配(patch-based multi-view stereo, PMVS)方法備受推崇。由於PMVS不需要先驗知識和初始化設置，並且適用於大場景影像的三維重建，被廣泛應用於無人機低空攝影測量中。Ai等將高精度的稀疏匹配點輸入PMVS作為種子點，對無人機航攝影像進行密集匹配，<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-1">大大</i>提高了PMVS的效率<sup>[53</sup><sup>]</sup>。文獻[54]將PMVS的匹配點作為初始值構建擴張的面片集，通過最小二乘精化和MPGC(multi-photo geometrical constrained)方法對面片中匹配點的位置進行調整，提高了匹配結果對遮蔽和噪聲的穩健性，獲得的匹配點雲更加稠密<sup>[55</sup><sup>]</sup>。</p><p>在綜合分析SGM和PMVS算法的基礎上，文獻[56]於2016年率先將光流場引入航攝影像的密集匹配中，提出了一種基於光流場的航攝立體影像密集匹配方法(optical flow field-based dense image matching, OFFDIM)。其基本思想是以稀疏匹配所提取的高精度像片連接點作為種子點，運用基於特徵金字塔L-K方法和基於三角網多層B樣條插值方法，快速估計出立體影像對重疊區域內的密集光流場，得到逐像素的粗匹配點，然後<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-3">結合</i>幾何約束和影像紋理信息，採用基於Census變換的匹配代價，運用快速引導濾波優化算法對初始視差圖進行精化，以此為基礎對粗匹配點進行逐一修正，以提取密集匹配點雲。這種方法充分利用光流場信息，採用由粗到精的金字塔匹配策略，縮小了影像匹配的<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-4">搜索</i>範圍，減少了大量的冗餘計算，可用於寬基線大幅面航攝影像的密集匹配。經對普通數字航攝影像和無人機低空航攝影像的試驗，真正實現了逐像素的密集匹配，達到了子像素級的匹配精度，速度快，可靠性高，完全可以滿足攝影測量中的目標三維重建、DSM/DOM自動生成等的應用需求<sup>[57</sup><sup>]</sup>。</p><p>近年來，隨著深度學習的飛速發展，眾多深度神經網絡模型被運用於影像密集匹配中。基於深度學習的密集匹配方法大體上可分為分佈式方法和端到端方法兩類。分佈式方法通常運用深度神經網絡模型計算立體像對間的匹配代價<sup>[42</sup><sup>, 58</sup><sup>]</sup>，然後採用傳統的匹配代價聚合方法生成視差圖，從而找到同名像點。相較於傳統的逐像素密集匹配方法，其在常規紋理區域的匹配精度有顯著的提高。然而，在紋理貧乏、地物遮蔽和光照較強區域，其匹配效果依然不盡人意。端到端方法通過在深度神經網絡模型中加入三維卷積層，達到計算匹配代價聚合的目的<sup>[59</sup><sup>-61</sup><sup>]</sup>。這類方法進一步提高了密集匹配的精度，但由於三維卷積計算的大量內存消耗和高計算複雜度，通常只能處理較小的影像塊，其實用性遠不如傳統密集方法和分佈式方法。此外，基於深度學習的密集方法對輸入的訓練標籤有著極強的依賴性。訓練數據中，每個像素都必須提供相應的深度真值或者視差真值，這類訓練數據通常由人為準備，這也使得其普適性和適用性比較差。</p><p><strong toutiao-origin=span>2.3 兩種密集匹配方法的比較</strong></p><p>總體說來，局部最優密集匹配方法比全局最優密集匹配方法簡單快速，但正確率和精度要稍遜一籌，表 1對這兩類方法作了簡要的比較。此外，大多數全局最優密集匹配方法借鑑了局部最優密集匹配方法的代價聚合模式，這就使得後者的很多優點在前者中得以體現。實際應用中，兩種方法是存在互補的。</p><p>表 1 局部最優與全局最優密集匹配方法的比較Tab. 1 Comparision between local matching algorithm and global matching algorithm</p><table><thead><tr><td>密集匹配方法</td><td>光滑約束</td><td>正確率</td><td>速度</td><td>計算機內存佔用</td><td><i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">關注</i>要點</td><td>約束引入</td></tr></thead><tbody><tr><td>局部最優</td><td>隱式</td><td>較高</td><td>快</td><td>少</td><td>代價聚合</td><td>難</td></tr><tr><td>全局最優</td><td>顯式</td><td>高</td><td>較快</td><td>多</td><td>建模優化</td><td>易</td></tr></tbody></table><p>表選項</p><p>圖 2為採用國際攝影測量與遙感學會(ISPRS)公開的數據集，在德國Vahingen地區利用DMC相機獲取的多光譜合成影像(相機主距120 mm, 像幅7680×13 824像素，像元大小12.0 μm, 航向重疊度為60%)，使用SGM、PMVS和OFFDIM的匹配點雲圖，從中可以清楚看出它們在匹配效果上的差異。</p><img alt="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RnOpWSs3ugyrsM><p>圖 2 利用半全局密集影像匹配生成的點雲Fig. 2 Dense 3D point clouds acquired by semi-globe dense image matching for single stereo image pairs</p><p>圖選項</p><p><strong toutiao-origin=span>3 展望</strong></p><p>目前，航攝影像的密集匹配普遍採用半全局匹配方法，一批以SURE、PhotoScan、Smart3D為代表的商業軟件也相繼推向了市場，但人們對密集匹配算法的研究依然表現出了濃厚的興趣。如何獲得更優的匹配代價、採用更好的匹配代價聚合方式、更合理地構建全局能量方程及其優化求解，依然是當前密集影像匹配的桎梏。近些年來，出現了大量的利用卷積神經網絡獲取匹配代價、顧及影像邊緣的自適應代價聚合<sup>[63]</sup>、置信度傳播、圖割優化等技術，已成為密集影像匹配新的研究熱點。儘管如此，筆者認為以下4個方面的問題值得<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">關注</i>：</p><p>(1) 如何構建更能反映像素間相似度的數據項是密集匹配的理論基礎。事實上，我們無法建立真實反映像素間相似度的數據項，原因就在於現實世界中異物同譜現象的存在以及攝影曝光和光照的不同，有些像素不再滿足光度一致性條件；而且由於航攝影像場景複雜，地物相互遮擋、地形突變致深度不連續、紋理重複等現象，給密集匹配帶來了極大的挑戰。在動態規劃的框架下，計算錯誤的數據項往往會影響鄰域點的視差估計，並將錯誤擴散。因此，構建更能反映像素間相似度的數據項模型，對於減少誤匹配、提高密集影像匹配的精度和可靠性是至關重要的。穩健的數據項應對航攝場景中的複雜地形變化、光照變化等噪聲不<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">敏感</i>，能很好地顧及重複紋理、深度不連續等的影響因素。</p><p>(2) 如何自適應設定可估計像素間視差不連續的平滑項是非局部密集匹配的技術關鍵。平滑項是對相鄰像素間的視差不連續性的懲罰因子，非局部密集匹配平滑項存在的主要問題是需要人為設定控制視差變化的兩個懲罰參數。為了保持視差的平滑，非局部密集匹配算法的平滑項採用雙參數<em>P</em><sub>1</sub>和<em>P</em><sub>2</sub>(<em>P</em><sub>2</sub>><em>P</em><sub>1</sub>)來建立相鄰像素間視差的光滑約束，用參數表達懲罰強度。懲罰參數<em>P</em><sub>1</sub>和<em>P</em><sub>2</sub>的選擇對最終的匹配結果有較大的影響：參數過大則容易在深度不連續處過度平滑，導致無法保持地物邊緣等重要特徵；參數過小則難以保證視差平滑，產生明顯的匹配噪聲，造成凹凸不平的現象。現行方法對整個立體像對採用同一參數，是難以適應不同地形條件的，往往會導致物體邊緣不銳利，前景視差延伸到地面等問題，使生成的DSM、DOM的地物邊緣帶有明顯的毛刺。</p><p>(3) 如何有效消除地物遮蔽處及特殊紋理區域的匹配空洞是密集匹配的普適性問題。密集匹配的終極目標是能夠達到影像重疊區域內的逐像素匹配，對於紋理豐富、視差比較連續的影像區域，實現這一目標並非難事，但對於影像遮蔽區域，特別是在高樓林立、陰影交錯的城區以及紋理重複的森林和農田地區，公認的半全局匹配經常會產生較大範圍的點雲空洞。基於光流場的密集影像粗匹配能夠真正實現像素級的逐像素密集匹配，但為了生成子像素級的高精度DSM，精匹配算法還有待改進。無論是精化算法的本身，還是多度重疊序列影像的整體匹配策略，都值得進一步探討。</p><p>(4) 如何通過並行計算提高影像匹配的效率是密集匹配的實用性問題。當前的密集匹配方法大多來自於計算機視覺領域，算法均是針對短基線的小幅面影像而設計，航攝影像一般是寬基線的大幅面影像序列，密集影像匹配的計算複雜度非常高、匹配結果的數據海量、誤匹配率也很高，這不但對計算機的內外存儲器、計算性能等硬件指標提出了苛刻的要求，而且也要求在匹配和誤匹配點剔除等算法的程序實現上儘可能地採用諸如影像分塊、CPU多線程並行處理、GPU加速計算等技術，使1億像素幅面影像對的密集匹配時間可以控制在分鐘級的可接受範圍內。</p><p>【引文格式】袁修孝, 袁巍, 許殊, 等. 航攝影像密集匹配的研究進展與展望. 測繪學報，2019，48(12)：<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-2">154</i>2-<i class="chrome-extension-mutihighlight chrome-extension-mutihighlight-style-5">155</i>0. DOI: 10.11947/j.AGCS.2019.20190453</p><p></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>論文</a></li><li><a>推薦</a></li><li><a>袁修</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html alt=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html title=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術>論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html alt="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html title="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法">論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html alt=「論文推薦」左建平教授談岩層移動研究進展及重點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RmTmvrAHAwNOUb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html title=「論文推薦」左建平教授談岩層移動研究進展及重點>「論文推薦」左建平教授談岩層移動研究進展及重點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html alt=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ReafrDd7EHXniF style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html title=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制>「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html alt="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html title="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法">論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html alt=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S0q6oVj53DcDnj style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html title=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究>「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html alt="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html title="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法">論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html alt="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html title="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析">論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html alt="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html title="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法">論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html alt="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html title="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術">論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c7555ef5.html alt=論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/53410004acf9b032d928 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c7555ef5.html title=論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法>論文推薦｜姚宜斌：顧及設計矩陣誤差的AR模型新解法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f22ea791.html alt=論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f22ea791.html title=論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法>論文推薦｜楊幸彬：高分辨率遙感影像DSM的改進半全局匹配生成方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7c51035d.html alt=論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/15294875207731e288b7418 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7c51035d.html title=論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法>論文推薦｜邢志斌：我國陸海統一似大地水準面構建的三維重力矢量法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d07bf9bc.html alt=論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/53350006726e50ef72f9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d07bf9bc.html title=論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解”>論文推薦｜馬下平：ITRF中GNSS/SLR並址站歸心基線的“一步解”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b44462ad.html alt="論文推薦 | 劉洋：MF多源測深數據融合方法及大洋水深模型構建" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b44462ad.html title="論文推薦 | 劉洋：MF多源測深數據融合方法及大洋水深模型構建">論文推薦 | 劉洋：MF多源測深數據融合方法及大洋水深模型構建</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>