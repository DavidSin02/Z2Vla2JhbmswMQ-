<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>實時構建:Apache Kafka的大數據消息傳遞，Part 1 | 极客快訊</title><meta property="og:title" content="實時構建:Apache Kafka的大數據消息傳遞，Part 1 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/c357d9f64cd948fa8d1c85d7e6f010f3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e63e7a3.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e63e7a3.html><meta property="article:published_time" content="2020-10-29T21:04:29+08:00"><meta property="article:modified_time" content="2020-10-29T21:04:29+08:00"><meta name=Keywords content><meta name=description content="實時構建:Apache Kafka的大數據消息傳遞，Part 1"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e63e7a3.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>實時構建:Apache Kafka的大數據消息傳遞，Part 1</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt="實時構建:Apache Kafka的大數據消息傳遞，Part 1" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c357d9f64cd948fa8d1c85d7e6f010f3></div><p>當大數據運動開始時，它主要集中於批處理。分佈式數據存儲和查詢工具(如MapReduce、Hive和Pig)都被設計成批量處理數據，而不是連續處理數據。企業將每天晚上運行多個作業從數據庫中提取數據，然後分析、轉換並最終存儲數據。最近，企業發現了在數據和事件發生時分析和處理它們的能力，而不僅僅是每隔幾個小時進行一次。然而，大多數傳統的消息傳遞系統都無法實時處理大數據。因此，LinkedIn的工程師們構建了開源的Apache Kafka:一個分佈式的消息傳遞框架，通過在普通硬件上擴展來滿足大數據的需求。</p><p>在過去的幾年中，Apache Kafka解決了各種各樣的用例。在最簡單的情況下，它可以是存儲應用程序日誌的簡單緩衝區。結合Spark流等技術，它可以用於跟蹤數據更改，並在將數據保存到最終目的地之前對數據採取行動。Kafka的預測模式使其成為檢測欺詐的強大工具，例如在信用卡交易發生時檢查其有效性，而不是在數小時後等待批處理。</p><p>本教程分為兩部分，首先介紹如何在開發環境中安裝和運行Kafka。您將瞭解Kafka的體系結構，然後介紹如何開發一個開箱即用的Apache Kafka消息傳遞系統。最後，您將構建一個定製的生產者/消費者應用程序，該應用程序通過Kafka服務器發送和消費消息。在本教程的第二部分中，您將瞭解如何對消息進行分區和分組，以及如何控制Kafka使用者將使用哪些消息。</p><p>Apache Kafka是什麼?</p><p>Apache Kafka是為大數據構建的消息傳遞系統。類似於Apache ActiveMQ或RabbitMq, Kafka允許構建在不同平臺上的應用程序通過異步消息傳遞進行通信。但Kafka與這些更傳統的消息傳遞系統在關鍵方面有所不同:</p><ul><li>它被設計成水平伸縮，通過添加更多的商品服務器。</li><li>它為生產者和使用者流程提供了更高的吞吐量。</li><li>它可以用於支持批處理用例和實時用例。</li><li>它不支持JMS, Java的面向消息的中間件API。</li></ul><p>Apache Kafka的架構</p><p>在我們探索卡夫卡的建築之前，你應該知道它的基本術語:</p><ul><li>生產者是可以向主題發佈消息的流程。</li><li>消費者是可以訂閱一個或多個主題並使用發佈到主題的消息的流程。</li><li>主題類別是發佈消息的提要的名稱。</li><li>一個broker是在單臺機器上運行的進程。</li><li>一個cluster是一組一起工作的brokers。</li><li>Apache Kafka的體系結構非常簡單，可以在某些系統中獲得更好的性能和吞吐量。Kafka中的每個主題都像一個簡單的日誌文件。當生產者發佈消息時，Kafka服務器將其附加到給定主題的日誌文件的末尾。服務器還分配一個偏移量，這是一個用於永久標識每個消息的數字。隨著消息數量的增加，每個偏移量的值也隨之增加;例如，如果生產者發佈三個消息，第一個消息的偏移量可能是1，第二個消息的偏移量是2，第三個消息的偏移量是3。</li><li><br></li></ul><div class=pgc-img><img alt="實時構建:Apache Kafka的大數據消息傳遞，Part 1" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/dce505041e8a4f1b8df55fdcafca8422></div><ul><li><br></li></ul><p>當Kafka使用者第一次啟動時，它將向服務器發送一個pull請求，請求檢索偏移量大於0的特定主題的任何消息。服務器將檢查該主題的日誌文件，並返回三條新消息。使用者將處理消息，然後發送一個偏移量大於3的消息請求，以此類推。</p><p><strong>[ 企業架構師領導數字轉型。這個多元視野的介紹課程解釋基本的EA和它的最新實踐。 ]</strong></p><p>在Kafka中，客戶機負責記住偏移量計數並檢索消息。Kafka服務器不跟蹤或管理消息消費。默認情況下，Kafka服務器將保存消息七天。服務器中的後臺線程檢查和刪除七天以上的消息。只要消息在服務器上，使用者就可以訪問它們。它可以多次讀取消息，甚至可以以相反的接收順序讀取消息。但是，如果使用者在七天結束前沒有檢索到該消息，那麼它將錯過該消息。</p><p>Kafka benchmarks</p><p>LinkedIn和其他企業的使用表明，通過適當的配置，Apache Kafka能夠每天處理數百gb的數據。2011年，三名LinkedIn工程師使用基準測試證明Kafka可以實現比ActiveMQ和RabbitMQ更高的吞吐量。</p><p>Apache Kafka快速設置和演示</p><p>在本教程中，我們將構建一個定製的應用程序，但是首先讓我們使用開箱即用的生產者和消費者來安裝和測試Kafka實例。</p><ol><li>訪問Kafka下載頁面安裝最新的版本(撰寫本文時為0.9)。</li><li>將二進制文件解壓縮到軟件/kafka文件夾中。對於當前版本，它是software/kafka_2.11-0.9.0.0。</li><li>將當前目錄更改為指向新文件夾。</li><li>通過執行以下命令啟動Zookeeper服務器:bin/ Zookeeper -server- Start.sh config/ zookeeper.properties。</li><li>通過執行來啟動Kafka服務器: bin/kafka-server-start.sh config/server.properties.</li><li>創建一個可用於測試的測試主題: bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic javaworld.</li><li>啟動一個簡單的控制檯使用者，該使用者可以使用發佈到給定主題的消息, 例如javaworld: bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic javaworld --from-beginning.</li><li>啟動一個可以向測試主題發佈消息的簡單生成器控制檯: bin/kafka-console-producer.sh --broker-list localhost:9092 --topic javaworld.</li><li>嘗試在生成器控制檯輸入一到兩條消息。您的消息應該顯示在使用者控制檯中。</li></ol><p>Apache Kafka的示例應用程序</p><p>您已經看到了Apache Kafka是如何開箱即用的。接下來，讓我們開發一個定製的生產者/消費者應用程序。生成器將從控制檯檢索用戶輸入，並將每個新行作為消息發送到Kafka服務器。使用者將檢索給定主題的消息並將其打印到控制檯。在這種情況下，生產者和消費者組件是您自己的kafka-console-producer實現。sh和kafka-console-consumer.sh。</p><p>讓我們從創建一個Producer.java類。這個客戶機類包含從控制檯讀取用戶輸入並將該輸入作為消息發送到Kafka服務器的邏輯。</p><p>我們通過從java.util.Properties中創建一個對象來配置生成器。屬性類並設置其屬性。ProducerConfigclass定義了所有可用的不同屬性，但是Kafka的默認值對於大多數使用來說已經足夠了。對於默認配置，我們只需要設置三個強制屬性:</p><ul><li>BOOTSTRAP_SERVERS_CONFIG</li><li>KEY_SERIALIZER_CLASS_CONFIG</li><li>VALUE_SERIALIZER_CLASS_CONFIG</li></ul><p>BOOTSTRAP_SERVERS_CONFIG (bootstrap.servers)設置一個主機:端口對列表，用於在host1:port1、host2:port2、…格式。即使Kafka集群中有多個代理，我們也只需要指定第一個代理的主機:port的值。Kafka客戶機將使用這個值對代理進行discover調用，該調用將返回集群中所有代理的列表。在BOOTSTRAP_SERVERS_CONFIG中指定多個代理是一個好主意，這樣如果第一個代理宕機，客戶機就可以嘗試其他代理。</p><p>Kafka服務器需要byte[] key, byte[] value格式的消息。Kafka的客戶端庫允許我們使用更友好的類型，如String 和int來發送消息，而不是轉換每個鍵和值。庫將把這些轉換為適當的類型。例如，示例應用程序沒有特定於消息的鍵，因此我們將對該鍵使用null。對於這個值，我們將使用一個String，它是用戶在控制檯上輸入的數據</p><p>為了配置消息鍵，我們在org.apache.kafka.common. serialize . bytearrayserializer中設置KEY_SERIALIZER_CLASS_CONFIG的值。這是因為null不需要轉換為byte[]。對於消息值，我們在org.apache.kafka.common. serialize . stringserializer上設置VALUE_SERIALIZER_CLASS_CONFIG，因為該類知道如何將String 轉換為byte[]。</p><p>自定義鍵/值對象</p><p>類似於StringSerializer, Kafka為int和long等其他原語提供了序列化器。為了為鍵或值使用自定義對象，我們需要創建一個實現org.apache.kafka.common. serialize . serializer的類。然後可以添加邏輯將類序列化為byte[]。我們還必須在消費者代碼中使用相應的反序列化器。</p><p>Kafka生產者</p><p>在用必要的配置屬性填充Properties類之後，我們可以使用它來創建KafkaProducer的對象。在此之後，每當我們想向Kafka服務器發送消息時，我們將創建一個ProducerRecord對象，並使用該記錄調用KafkaProducer的send()方法來發送消息。ProducerRecord接受兩個參數:應該向其發佈消息的主題的名稱和實際消息。在使用生成器時，不要忘記調用Producer.close()方法:</p><p>清單1. KafkaProducer</p><p>public class Producer {</p><p>private static Scanner in;</p><p>public static void main(String[] argv)throws Exception {</p><p>if (argv.length != 1) {</p><p>System.err.println("Please specify 1 parameters ");</p><p>System.exit(-1);</p><p>}</p><p>String topicName = argv[0];</p><p>in = new Scanner(System.in);</p><p>System.out.println("Enter message(type exit to quit)");</p><p>//Configure the Producer</p><p>Properties configProperties = new Properties();</p><p>configProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");</p><p>configProperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,"org.apache.kafka.common.serialization.ByteArraySerializer");</p><p>configProperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,"org.apache.kafka.common.serialization.StringSerializer");</p><p>org.apache.kafka.clients.producer.Producer producer = new KafkaProducer&lt;String, String>(configProperties);</p><p>String line = in.nextLine();</p><p>while(!line.equals("exit")) {</p><p>ProducerRecord&lt;String, String> rec = new ProducerRecord&lt;String, String>(topicName, line);</p><p>producer.send(rec);</p><p>line = in.nextLine();</p><p>}</p><p>in.close();</p><p>producer.close();</p><p>}</p><p>}</p><p>配置消息使用者</p><p>接下來，我們將創建訂閱主題的簡單使用者。每當向主題發佈新消息時，它將讀取該消息並將其打印到控制檯。消費者代碼與生產者代碼非常相似。我們首先創建一個java.util.Properties對象。屬性，設置其特定於使用者的屬性，然後使用它創建KafkaConsumer的新對象。ConsumerConfig類定義了我們可以設置的所有屬性。</p><ul><li>BOOTSTRAP_SERVERS_CONFIG (bootstrap.servers)</li><li>KEY_DESERIALIZER_CLASS_CONFIG (key.deserializer)</li><li>VALUE_DESERIALIZER_CLASS_CONFIG (value.deserializer)</li><li>GROUP_ID_CONFIG (bootstrap.servers)</li></ul><p>Just as we did for the producer class, we'll use BOOTSTRAP_SERVERS_CONFIG to configure the host/port pairs for the consumer class. This config lets us establish the initial connections to the Kakfa cluster in the host1:port1,host2:port2,... format.</p><p>就像我們對producer類所做的那樣，我們將使用BOOTSTRAP_SERVERS_CONFIG來為consumer類配置主機/端口對。這個配置允許我們用host1:port1,host2:port2，…格式建立對kafka集群的初始化的鏈接。</p><p>如前所述，Kafka服務器需要byte[]鍵和byte[]值格式的消息，並有自己的實現來將不同的類型序列化為byte[]。就像我們對生成器所做的那樣，在消費者端，我們必須使用自定義反序列化器將byte[]轉換回適當的類型。</p><p>在示例應用程序中，我們知道生成器對鍵使用ByteArraySerializer，對值使用StringSerializer。因此，在客戶端，我們需要為鍵使用org.apache.kafka.common. serialize . ByteArrayDeserializer，為值使用org.apache.kafka.common. serialize . StringDeserializer。將這些類設置為KEY_DESERIALIZER_CLASS_CONFIG和VALUE_DESERIALIZER_CLASS_CONFIG的值將使使用者能夠反序列化生產者發送的byte[]編碼類型。</p><p>最後，我們需要設置GROUP_ID_CONFIG的值。這應該是字符串格式的組名。稍後我將進一步解釋這個配置。現在，只需查看Kafka消費者設置的4個強制屬性:</p><p>清單 2. KafkaConsumer</p><p>public class Consumer {</p><p>private static Scanner in;</p><p>private static boolean stop = false;</p><p>public static void main(String[] argv)throws Exception{</p><p>if (argv.length != 2) {</p><p>System.err.printf("Usage: %s &lt;topicName> &lt;groupId>\n",</p><p>Consumer.class.getSimpleName());</p><p>System.exit(-1);</p><p>}</p><p>in = new Scanner(System.in);</p><p>String topicName = argv[0];</p><p>String groupId = argv[1];</p><p>ConsumerThread consumerRunnable = new ConsumerThread(topicName,groupId);</p><p>consumerRunnable.start();</p><p>String line = "";</p><p>while (!line.equals("exit")) {</p><p>line = in.next();</p><p>}</p><p>consumerRunnable.getKafkaConsumer().wakeup();</p><p>System.out.println("Stopping consumer .....");</p><p>consumerRunnable.join();</p><p>}</p><p>private static class ConsumerThread extends Thread{</p><p>private String topicName;</p><p>private String groupId;</p><p>private KafkaConsumer&lt;String,String> kafkaConsumer;</p><p>public ConsumerThread(String topicName, String groupId){</p><p>this.topicName = topicName;</p><p>this.groupId = groupId;</p><p>}</p><p>public void run() {</p><p>Properties configProperties = new Properties();</p><p>configProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");</p><p>configProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");</p><p>configProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");</p><p>configProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</p><p>configProperties.put(ConsumerConfig.CLIENT_ID_CONFIG, "simple");</p><p>//Figure out where to start processing messages from</p><p>kafkaConsumer = new KafkaConsumer&lt;String, String>(configProperties);</p><p>kafkaConsumer.subscribe(Arrays.asList(topicName));</p><p>//Start processing messages</p><p>try {</p><p>while (true) {</p><p>ConsumerRecords&lt;String, String> records = kafkaConsumer.poll(100);</p><p>for (ConsumerRecord&lt;String, String> record : records)</p><p>System.out.println(record.value());</p><p>}</p><p>}catch(WakeupException ex){</p><p>System.out.println("Exception caught " + ex.getMessage());</p><p>}finally{</p><p>kafkaConsumer.close();</p><p>System.out.println("After closing KafkaConsumer");</p><p>}</p><p>}</p><p>public KafkaConsumer&lt;String,String> getKafkaConsumer(){</p><p>return this.kafkaConsumer;</p><p>}</p><p>}</p><p>}</p><p>Consumer and ConsumerThread</p><p>將清單2中的使用者代碼分為兩部分編寫，可以確保在退出之前關閉Consumer對象。我將依次描述每個類。首先，ConsumerThread是一個內部類，它以主題名和組名作為參數。在run()方法中，它創建一個具有適當屬性的KafkaConsumer對象。它通過調用kafkaConsumer.subscribe()方法訂閱主題（在構造器中主題會被作為參數傳遞），然後每100毫秒輪詢Kafka服務器，檢查主題中是否有任何新消息。它將遍歷新消息的列表並且打印到控制檯。</p><p>在Consumer類中，我們創建了一個新的ConsumerThread對象，並在另一個線程中啟動它。ConsumerThead啟動一個無限循環，並不斷輪詢主題以獲取新消息。同時，在Consumer類中，主線程等待用戶在控制檯輸入exit。一旦用戶進入exit，它將調用KafkaConsumer.wakeup()方法，導致KafkaConsumer停止輪詢新消息並拋出WakeupException。然後，我們可以通過調用KafkaConsumer的close()方法優雅地關閉KafkaConsumer。</p><p>測試運行</p><p>要測試這個應用程序，可以在IDE中運行清單1和清單2中的代碼，或者遵循以下步驟:</p><ol><li>通過執行以下命令下載示例代碼KafkaAPIClient: git clone https://github.com/sdpatil/KafkaAPIClient.git.</li><li>編譯代碼並使用該命令創建一個fat JAR​: mvn clean compile assembly:single.</li><li>運行consumer: java -cp target/KafkaAPIClient-1.0-SNAPSHOT-jar-with-dependencies.jar com.spnotes.kafka.simple.Consumer test group1.</li><li>運行producer: java -cp target/KafkaAPIClient-1.0-SNAPSHOT-jar-with-dependencies.jar com.spnotes.kafka.simple.Producer test.</li><li>在生產者控制檯中輸入一條消息，並檢查該消息是否出現在使用者中。試著發幾條信息。</li><li>在consumer和producer控制檯中鍵入exit關閉它們。</li></ol><div class=pgc-img><img alt="實時構建:Apache Kafka的大數據消息傳遞，Part 1" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/637c4701d1a94183b18fbdccd3bb7926></div><p>總結 Part 1</p><p>在本教程的前半部分，您已經學習了使用Apache Kafka進行大數據消息傳遞的基礎知識，包括Kafka的概念概述、設置說明以及如何使用Kafka配置生產者/消費者消息傳遞系統。</p><p>正如您所看到的，Kafka的體系結構既簡單又高效，是為性能和吞吐量而設計的。在第2部分中，我將介紹使用Kafka進行分佈式消息傳遞的一些更高級的技術，首先使用分區來細分主題。我還將演示如何管理消息偏移量，以支持不同的用例。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>實時</a></li><li><a>構建</a></li><li><a>Apache</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/bcc3f9eb.html alt=解讀新規範——構建精細化橋樑之路 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/9317d74f6fd541a6b6e1e5269a0a549c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bcc3f9eb.html title=解讀新規範——構建精細化橋樑之路>解讀新規範——構建精細化橋樑之路</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4c77e1c3.html alt=跟著一起來基於Apache服務器部署WEB網站 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/221ad8e63e62434eb3b54b7f20b6154c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4c77e1c3.html title=跟著一起來基於Apache服務器部署WEB網站>跟著一起來基於Apache服務器部署WEB網站</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/93ce7858.html alt=實時更新！關閉口岸、封鎖邊境、暫停所有商業航班、禁止入境、強制隔離、近50國進入緊急狀態 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/Rk9jaw1CGxVnCU style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/93ce7858.html title=實時更新！關閉口岸、封鎖邊境、暫停所有商業航班、禁止入境、強制隔離、近50國進入緊急狀態>實時更新！關閉口岸、封鎖邊境、暫停所有商業航班、禁止入境、強制隔離、近50國進入緊急狀態</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9c87514a.html alt=構建高速公路數字化運營管理體系！中交高速隧道水消防自動監測系統正式上線 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/8f31532172f24b1483fd817526874c6c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9c87514a.html title=構建高速公路數字化運營管理體系！中交高速隧道水消防自動監測系統正式上線>構建高速公路數字化運營管理體系！中交高速隧道水消防自動監測系統正式上線</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a9aae7f8.html alt=超車防剮蹭，高速上如何實時判斷車距？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/S9stoIbFwWKzle style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a9aae7f8.html title=超車防剮蹭，高速上如何實時判斷車距？>超車防剮蹭，高速上如何實時判斷車距？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d5b06822.html alt=基於合成數據的實時三維車輛姿態估計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/e19205cdd518461bbf3e95ca3c3197fe style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d5b06822.html title=基於合成數據的實時三維車輛姿態估計>基於合成數據的實時三維車輛姿態估計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/26c66227.html alt=烽火張賓：構建下一代智慧光網，共贏數字化時代 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RTEXexr8uCUK8V style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/26c66227.html title=烽火張賓：構建下一代智慧光網，共贏數字化時代>烽火張賓：構建下一代智慧光網，共贏數字化時代</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/25d043a2.html alt=利用柵格系統，構建優秀的響應式設計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RviaJmz1mKK1es style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/25d043a2.html title=利用柵格系統，構建優秀的響應式設計>利用柵格系統，構建優秀的響應式設計</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/12a8383c.html alt=實時分析頁面指標，把握轉化「黃金一頁」 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c968363cd3bd4c3fbe82449dbc96de3c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/12a8383c.html title=實時分析頁面指標，把握轉化「黃金一頁」>實時分析頁面指標，把握轉化「黃金一頁」</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ded90648.html alt=好書推薦：《實時熒光定量PCR（第二版）》 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/5e3c001b4b83ca30fe89 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ded90648.html title=好書推薦：《實時熒光定量PCR（第二版）》>好書推薦：《實時熒光定量PCR（第二版）》</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f6111cec.html alt=實時熒光PCR核酸檢測技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f6111cec.html title=實時熒光PCR核酸檢測技術>實時熒光PCR核酸檢測技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/73e13b38.html alt="實時熒光定量PCR檢測儀 檢測非洲豬瘟" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4231fc50827647da9693448852e46e16 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/73e13b38.html title="實時熒光定量PCR檢測儀 檢測非洲豬瘟">實時熒光定量PCR檢測儀 檢測非洲豬瘟</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3638ad51.html alt="Apache Flink 1.10 細粒度資源管理解析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15513883d97c4f799a3897342310c24f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3638ad51.html title="Apache Flink 1.10 細粒度資源管理解析">Apache Flink 1.10 細粒度資源管理解析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eeb1da89.html alt=批量提取工作表的名稱，實時動態更新超級簡單！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4f0e611ffd5f4f279f550f0924c5efc3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eeb1da89.html title=批量提取工作表的名稱，實時動態更新超級簡單！>批量提取工作表的名稱，實時動態更新超級簡單！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7e803abd.html alt=基於FPGA的多通道同步實時高速數據採集系統設計 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RT9ec7T8clHaQI style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7e803abd.html title=基於FPGA的多通道同步實時高速數據採集系統設計>基於FPGA的多通道同步實時高速數據採集系統設計</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>