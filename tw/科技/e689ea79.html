<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>史上最全的語義SLAM論文筆記整理 | 极客快訊</title><meta property="og:title" content="史上最全的語義SLAM論文筆記整理 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/8edae3f2a53c4599b2532c390698a247"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e689ea79.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e689ea79.html><meta property="article:published_time" content="2020-11-14T21:01:41+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:41+08:00"><meta name=Keywords content><meta name=description content="史上最全的語義SLAM論文筆記整理"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e689ea79.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>史上最全的語義SLAM論文筆記整理</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><pre>關注微信公眾號：人工智能前沿講習，重磅乾貨，第一時間送達</pre><p>語義信息的挖掘和應用，是目前SLAM問題中的研究熱點，本文從特徵選擇、動態SLAM、單目SLAM的尺度恢復、long-term的定位、提高定位精度等方面介紹了當前最新的一些論文中的研究工作。</p><p>一：語義信息於特徵選擇</p><p>二：語義信息用於動態slam</p><p>三：語義信息用於單目SLAM的尺度恢復</p><p>四：語義信息用於long-term定位</p><p>五：語義信息用於提高定位精度</p><p class=ql-align-justify><br></p><h1>一、<strong>語義信息用於特徵選擇</strong></h1><p class=ql-align-justify><strong>1.1 選擇感興趣區域的點</strong></p><p class=ql-align-justify>SalientDSO:Bringing Attention to Direct Sparse Odometry（直接法）</p><p class=ql-align-justify>本文是在DSO的基礎上，改變了跟蹤點的選取策略。DSO是在圖像上均勻選取點，如圖a所示，本文是在圖像上的感興趣區域上選取點，下面具體介紹：</p><p class=ql-align-justify><strong>a. 顯著性圖獲取</strong></p><p>分為兩步：首先使用SalGAN網絡提取圖像中的顯著性圖，如圖 e 所示，顯著性定義為人類對圖像中每個像素的關注量，顏色越接近紅色表示顯著性越高。接著使用PSPNet進行獲取語義分割的結果，如圖 f 所示。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8edae3f2a53c4599b2532c390698a247><p class=pgc-img-caption></p></div><p class=ql-align-justify>利用語義分割的結果對顯著性圖進行filter，即重新調整每個像素點的顯著性得分，目的是降低無信息區域的顯著性得分，例如牆，天花板和地板等。論文中為每種語義類別設置一個經驗權重 Wc，根據得到的語義分割圖 Cj，對顯著性圖 Sj 的每個像素點乘以該像素點對應類別的經驗權重，得到 Sj [weighted] :</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6b4666a98aa94be286fb6c644cc0f8ef><p class=pgc-img-caption></p></div><p class=ql-align-justify>這還不是最終的顯著性圖，論文中提到為了平滑和為每種類別維持一個一致的顯著性圖，每個像素的顯著性得分被圖中所有該類像素的顯著性得分的中值代替，得到最終的顯著性圖Sj [final] :</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c978c62cbfe44701b7fb103f4ae1db49><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>b. 點的選擇策略</strong></p><p class=ql-align-justify>首先，將圖像分割為K×K的patch, 對於每個patch，計算顯著性中值，顯著性中值作為該patch的被選擇的權重，如果該patch的顯著性高，則被選擇的概率越大，然後在選擇的patch內根據梯度值進一步選擇點，可參考DSO的策略。</p><p class=ql-align-justify><strong>c. 論文的理論依據</strong></p><p class=ql-align-justify>顯著性區域的點對於光照和視角的變化更加魯棒。</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>1.2 選擇具有更大信息量的點</strong></p><p class=ql-align-justify>Visual SLAM with Network Uncertainty Informed Feature Selection（特徵點法）</p><p class=ql-align-justify>這篇論文還對應著一個畢業論文：SIVO：Semantically Informed Visual odometry and mapping，裡面的第三章具體介紹了該論文。開源代碼：https://github.com/navganti/SIVO</p><p>本文是在Active search for real-time vision和Covariance recovery from a square root information matrix for data association兩篇論文的基礎上改進的，參考論文使用信息熵判斷觀測數據是否用於更新估計的狀態量，如果在新觀測數據下待估計變量的協方差的秩相比之前數據條件下待估計變量的協方差的秩是否下降了一定閾值，是則選擇該觀測數據（特徵點）參與跟蹤和優化，本文在此基礎上將語義分割的不確定性融入到信息熵的計算中，在選擇具有。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/552e60c56f3d4087b0272bb7d5ae2170><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>a. 基於信息論的特徵選擇策略</strong></p><p class=ql-align-justify>對於一個統計變量X，它的熵（平均不確定性）記為H(X)，在條件Y下的熵記為H(X|Y)，兩者的差值記為I(X;Y)，為X和Y之間的互信息。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6f07920594e245ba8b30f7ee715b0030><p class=pgc-img-caption></p></div><p class=ql-align-justify>在SLAM問題中，I表示為位姿數據和觀測數據之間的互信息，是衡量觀測數據質量的指標，如果在某個新的觀測數據（特徵點）的加入下，位姿的熵變化∆H 超過一個閾值，則該觀測數據（特徵點）被選擇，說明該特徵點具有的信息量大。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b51036984ce442458b0c6fa79958eb30><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>b. 融合語義分割不確定性的特徵選擇策略</strong></p><p class=ql-align-justify>本文的創新點在於計算∆H的時候引入了語義分割的不確定性，即下面等式的最後一項H(ci|I,D)。如果某個特徵點（像素）在語義分割中的不確定性H(ci|I,D)越高，則∆H 越小，該特徵越不容易被選擇，例如，語義分割網絡是輸出該像素屬於每種類別的概率都相同，則H(ci|I,D)最大；反之，如果該像素屬於某種類別的概率達到了100%，則H(ci|I,D)=0。綜上所述，即某特徵點互信息越大，分類不確定性越小，越容易被選擇。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/90df2d0c65fc4bfbbded67aef3875a6c><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>c. 論文的效果</strong></p><p class=ql-align-justify>減少了大量的信息量少的特徵點，減小了地圖的規模，同時能夠達到和ORBSLAM差不多的精度。</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>1.3 去除動態(e.g,car)和遠處(e.g, sky)的類別的點</strong></p><p class=ql-align-justify>Utilizing Semantic Visual Landmarks for Precise Vehicle Navigation—ITSC2017</p><p>本文的思路比較簡單，在因子圖中增加了一個門限信號c，如果該類別有效，則對應的觀測數據lt就添加到因子圖中，否則不添加。本文認為無效的類別為：non-static (such as Pedestrian, Vehicle, Bike) and far-away classes (such as Sky)</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ae9f6bed0e1b44cdac11d2b35e7bcabf><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><h1>二、<strong>語義信息用於動態slam</strong></h1><p class=ql-align-justify>實際上該類別也屬於語義信息用於特徵點的選擇裡面，只是動態slam論文比較多，方法也各不相同，所以單獨總結下。</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（1）Detect-SLAM: Making Object Detection and SLAM Mutually Beneficial_WACV2018</strong></p><p class=ql-align-justify>本文的貢獻在於：通過目標檢測去除動態點，但是為了使得目標檢測線程和slam線程同步，沒有對每一幀進行檢測，而是隻在關鍵幀進行檢測，然後通過特徵匹配和擴展影響區域的形式進行運動概率的傳播，然後在slam過程中去除動態點的影響，只利用靜態點進行跟蹤。另外，slam過程中構建的地圖能夠提高目標檢測的結果。下面分別介紹：</p><p class=ql-align-justify><strong>a. 動態點的去除</strong></p><p class=ql-align-justify>運動概率更新</p><p class=ql-align-justify>對關鍵幀進行目標檢測，在動態物體檢測框內的點運動概率為1，不在框內的點運動概率為0。特徵點投影到世界座標系中的地圖點具有相同的運動概率，但是同一個地圖點在不同幀中對應不同的特徵點，而這些特徵點不一定具有相同的運動概率，所以當地圖點匹配到新的特徵點時需要對地圖點的運動概率進行更新：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/be2e4a3a1ee04fe8998541a0d4c63852><p class=pgc-img-caption></p></div><p class=ql-align-justify>第一項表示上一關鍵幀更新的運動概率，第二項表示當前關鍵幀根據檢測結果得到的運動概率，α表示對兩個量的信任權重，本文設置α=0.3，表示更相信之前更新的運動概率，因為檢測結果總會有錯誤。</p><p>運動概率傳播</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8d09ed9bb471418cb285195d7f018afe><p class=pgc-img-caption></p></div><p class=ql-align-justify>普通幀的特徵點的運動概率通過特徵匹配傳播，包括與上一幀的匹配和與局部地圖的匹配；另外，具有高概率的點，無論是高概率的動態點還是高概率的靜態點都會將其運動概率傳播到周圍半徑為r的一個區域。</p><p class=ql-align-justify><strong>b. slam加強目標檢測結果</strong></p><p>將SLAM構建的點雲語義地圖投影到圖像上得到可能出現物體的候選區域，然後用於挖掘困難樣本，這些樣本可以作為訓練數據提高或者微調檢測網絡。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/54d866ffe3ea404d9363bc29628e3a09><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（2）DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments—IROS2018</strong></p><p class=ql-align-justify>本文采用語義分割和運動一致性檢測結合的形式進行動態點的去除，並沒有用到語義分割的類別，只是用語義分割得到一個物體的邊界，無論該物體類別是什麼，只要有經過運動檢測判定為動態的點位於該物體內，即去除該物體的所有點，但實際上該論文的代碼裡值針對人這一類物體進行檢測。代碼：https://github.com/ivipsourcecode/DS-SLAM</p><p class=ql-align-justify>運動一致性檢測</p><p class=ql-align-justify>由於語義分割比較耗時，所以在語義分割的線程進行過程中，跟蹤線程進行運動一致性檢測。採用如下策略：</p><p class=ql-align-justify>第一步：計算光流金字塔以獲得當前幀中匹配的特徵點。</p><p class=ql-align-justify>第二步：如果匹配的特徵點太靠近圖像邊緣或者與中心處3×3圖像塊的像素差太大，則將會被丟棄當前的匹配。</p><p class=ql-align-justify>第三步：通過 RANSAC 算法求取基礎矩陣。緊接著，使用基礎矩陣計算當前幀的極線。最後，判斷從匹配點到其對應極線的距離是否小於某個閾值。如果距離大於閾值，則確定匹配點是移動的。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/428d35f50e7644f0a232710bd4ce391c><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（3）DynaSLAM: Tracking, Mapping and Inpainting in Dynamic Scenes—IEEE Robotics and Automation Letters, 2018</strong></p><p class=ql-align-justify>代碼：https://github.com/BertaBescos/DynaSLAM</p><p class=ql-align-justify>文章不僅能夠去除動態物體，還能恢復出動態物體遮擋的背景。同時本文針對RGBD輸入圖像動態點的去除做了很多細緻的處理：</p><p class=ql-align-justify><strong>a. 不具有運動性質的物體發生運動，例如人手上的書</strong></p><p>對於每個當前幀，選擇具有高重疊的之前5幀關鍵幀，然後計算關鍵幀的每個特徵點在當前幀的投影，得到投影點和深度值，和該位置的深度圖值進行比較，如果差值超過一定的閾值，則判斷為動態點。下圖a是僅通過上述方法判斷的動態點，b是通過mask-rcnn檢測的動態點，c是結合兩個方法檢測的動態點。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/aa319b33f73f4446b21c8bc50fe80817><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>b. 將動態像素周圍具有相同深度值的像素設置為動態。</strong></p><p class=ql-align-justify><strong>c. 如果一個動態像素周圍的patch的深度具有很大的方差，則設置該點為靜態，防止因為邊緣分割不準確，將背景點也誤分類為動態點。</strong></p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（4）Semantic Monocular SLAM for Highly Dynamic Environments—IROS2018</strong></p><p class=ql-align-justify>大多數語義用於動態slam都是將所有潛在運動的物體的點直接去除，但是例如停靠的車等並沒有發生運動，如果運動的物體佔據相機視角的大部分，那麼將車上的點都去除會對位姿估計產生很嚴重的錯誤，另外，本文提到一種場景，當車停在信號燈前面時是靜止的，但是隨著時間的推移，車會慢慢開始運動，所以本文提出對地圖點的靜態率（inlier ratio）進行估計，能夠實現地圖點在靜態和動態狀態之間的平滑過渡。</p><p class=ql-align-justify>本文參考SVO的深度濾波思路：通過不斷的添加新觀測數據對地圖點的深度進行更新，只有當地圖點的深度值收斂的時候才將該地圖點添加到地圖中；本文在此基礎上，引入對於地圖點是否為靜態點的概率的估計——靜態率，首先，根據語義分割網絡的輸出賦予靜態率一個先驗值，例如車具有較低的靜態率，建築具有較高的靜態率等，然後根據不斷的引入新的觀測數據來更新該地圖點的靜態率，實現地圖點在動靜態之間的平滑過渡。</p><p>如下圖是車輛停在信號燈前，b是orbslam選擇的點，c是將所有潛在動態物體上的點都去除（紅色），d是根據本文方法選出外點，可以保留大部分車上的靜態點。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/d19afe62c419469db65341d5ae685fbe><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（5）Semantic segmentation–aided visual odometry for urban autonomous driving—IJARS2017</strong></p><p class=ql-align-justify>本文將直接法和特徵點法結合，並引入語義信息減少動態物體的影響。通過計算相鄰幀間某類物體的所有像素的總投影誤差為每類物體賦予不同的權重，這個權重作為RANSAC選擇點的權重，由於靜態物體的投影誤差小，所以更傾向於被選擇。</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（6）Stereo Vision-based Semantic 3D Object and Ego-motion Tracking for Autonomous Driving—ECCV2018</strong></p><p class=ql-align-justify>本文出自港科大的沈劭劼團隊，同樣基於自動駕駛的背景研究動態環境下的slam問題，利用Faster R-CNN在雙目的左圖上進行目標檢測，利用視點分類的方法擴展出物體的3D檢測框，然後將語義信息融合到一個統一的優化求解框架中。</p><p>作者將ORB特徵點分為背景點和物體點，首先利用背景點進行相機位姿和背景點的3D 位置進行最大似然估計，即找出一組參數 x,f 使得模型產生觀測數據的概率最大，式中變量的上下角標的0都表示背景點，下式就是一個典型的SLAM方法：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6900a21cde60468cb448adf286f174d2><p class=pgc-img-caption></p></div><p>有了相機的位姿，接下來進行運動物體的跟蹤，在這裡面融入了物體的先驗尺寸信息和語義測量（bounding box）信息，由於有了可利用的先驗信息，所以採用最大後驗估計的方法估計物體的位姿：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/db08643e48c846b6935a11b6c432aff5><p class=pgc-img-caption></p></div><p class=ql-align-justify>其中，要求解的第一個變量表示第k個物體的狀態，從左到右依次是：3D檢測框的中心點在世界座標系中的位置，物體的三維尺寸（x,y,z長寬高），水平旋轉角度，速度角和轉向角。</p><p class=ql-align-justify>第二個變量表示第k個物體幀上的特徵的3D位置，注意運動物體上的特徵相對於物體幀是靜止的。sk表示語義測量，即檢測框，zk表示物體上的特徵點測量，所以上述最大後驗理解為：在已知相機位姿，特徵點觀測和語義測量的條件下，估計最有可能的物體狀態以及物體上特徵點的3D位置。公式（7）中引入了物體的先驗尺寸p(dk)將最大後驗概率寫成最大似然和先驗概率的乘積。</p><p>接下來，同樣將最大後驗轉化為最小二乘的問題：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/17e46cc42b0e431798c57d3d22c6d11c><p class=pgc-img-caption></p></div><p class=ql-align-justify>下面分別介紹這四個優化項：</p><p class=ql-align-justify>第一項的形式和求解相機位姿的最小二乘形式相似，同樣是特徵點的重投影誤差。區別在於是將世界座標系的點投影到物體幀上比較重投影誤差，因為運動物體的點相對於物體幀本身是靜止的。第二項是尺寸先驗的誤差，即估計的物體3D框的尺寸和先驗值的差。第三項是物體的運動模型，根據t-1時刻的運動狀態估計t時刻的運動。第四項是物體的3D框在圖像上的投影與原本的2D檢測框的差。</p><p class=ql-align-justify><br></p><h1>三、語義信息用於單目SLAM的尺度恢復</h1><p class=ql-align-justify><strong>（1）Recovering Stable Scale in Monocular SLAM Using Object-Supplemented Bundle Adjustment_IEEE Transactions on Robotics 2018</strong></p><p>本文將點和物體構建為統一的模型——球體，由中心點位置和半徑組成，點的半徑為0，論文裡僅提到了車這一類物體，定義一個經驗半徑為1.2m。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a861b2aa1dd04a6bbfc19bf5feeec636><p class=pgc-img-caption></p></div><p>物體在圖像上的投影表示為：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/927973bf46b543a4900d34390c23f277><p class=pgc-img-caption></p></div><p>然後將點和物體的重投影誤差構建為最小二乘的形式，由於兩個路標具有統一的形式，並且物體的半徑是不需要優化的，點的半徑為0，所以需要優化的量只有點和物體的中心點位置，所以將誤差函數化簡為下面的形式：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/14770d6cd68a4bf5b1f2b92079f3770d><p class=pgc-img-caption></p></div><p class=ql-align-justify>其中，重投影誤差為：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/352879bfbda748f89ef2e3e5cbb21cb9><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（2）Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift—ICRA2018</strong></p><p class=ql-align-justify>核心思想：設置物體（車輛）的先驗高度，或者說是服從先驗高度（1.5m）的一個高斯分佈，利用這個真實的高度比上地圖中表達的車的高度就是要求的尺度因子。</p><p>所以現在的主要問題就是如何求地圖中的車的高度，首先，局部地圖中的3D點投影到圖像上，投影位置在檢測款內的3D點被認為是類別為car的點，在這裡需要濾除一些偏差太大的點，下圖中用不同顏色區分</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/21f91c955d1948ea95ba5bfacd4913d5><p class=pgc-img-caption></p></div><p>計算類別為car的點的均值，表示為下圖中的紅色點ps，以ps所在豎直方向畫一條豎線就是車的高度方向所在的直線，將直線投影到2d圖像上得到一條豎直線和bounding box有上下兩個交點，綠色表示，然後將兩個點投影回3D空間確定了一個線段的長度，也就是車的高度，於是，尺度因子就是先驗高度和實際高度之比。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e226837617644f619e70d3f518c83285><p class=pgc-img-caption></p></div><p class=ql-align-justify><br></p><h1>四、<strong>語義信息用於long-term定位</strong></h1><p class=ql-align-justify>Long-term Visual Localization using Semantically Segmented Images—ICRA2018</p><p class=ql-align-justify>論文作者Erik Stenborg，是瑞典查爾姆斯理工大學信號處理研究小組的博士，參與了車輛定位項目，該項目旨在將車輛定位提高到足以實現自動駕駛的可靠性。</p><p class=ql-align-justify>本文解決的問題是在已有的3D地圖上進行定位，傳統方法是基於特徵匹配進行的，但是在自動駕駛的應用場景下，當前檢測的特徵和保存的地圖特徵一般具有很大的時間跨度，而普通的特徵不具有魯棒性，所以本文提出了一種依賴於語義標籤和3D位置的定位算法。</p><p class=ql-align-justify>本文對基於SIFT特徵和基於語義特徵定義了統一的觀測模型：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/fa7ed68f59174f2ab6db02e8278f298d><p class=pgc-img-caption></p></div><p class=ql-align-justify>ft表示當前圖像，xt表示相機的位姿，M表示已知的地圖，公式中將圖像ft 表示為(ut,dt)的集合，即圖像是由圖像中所有的特徵點及其描述子構成的，對於SIFT來說，就是圖像中所有的SIFT特徵點及計算出來的描述子，對於語義特徵來說，特徵是圖像中所有的像素，描述子是每個像素對應的語義標籤（因為語義分割可以獲取圖像中所有像素的語義標籤），所以語義特徵的圖像是稠密的。</p><p class=ql-align-justify>λ t 表示圖像上的特徵點和地圖中的地圖點之間的數據關聯，下面公式表示當前圖像第i個特徵點對應地圖中的第j個地圖點，如果j>0表示地圖中存在一個地圖點和該特徵點對應，如果j=0表示當前特徵點沒有對應的的地圖點：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/8f55c3200ad34a43b7baefbcbefc187c><p class=pgc-img-caption></p></div><p class=ql-align-justify>數據關聯的獲取對於SIFT特徵和語義特徵有差別。對於SIFT來說，首先獲取地圖M中位於當前相機位姿xt視角下的局部地圖Ms，將局部地圖中的點和圖像特徵進行匹配，包括使用RANSAC方法得到更準確的匹配關係作為數據關聯；對於語義特徵來說，同樣獲取當前相機視角下的一個局部地圖Ms，將Ms中的每個點都投影到當前圖像上，因為當前圖像是稠密的，每一個像素都是特徵點，所以可以直接建立數據關聯，即地圖點和投影點之間的對應。需要注意的是：有的圖像像素沒有對應的地圖點，即 λ t =0的情況。</p><p class=ql-align-justify>本文假設ut和dt相互獨立，所以將觀測模型的概率分為兩項的乘積：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/55cc1c123ab84c0d8f09c0cd85101ef3><p class=pgc-img-caption></p></div><p class=ql-align-justify>上式第一項的意義為在像素i位置檢測到特徵點的概率，由於語義圖像上每一個像素點都是特徵，所以該項是一個常數。可以將概率化簡為：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7e572d8676f94924879f0861a80f3f02><p class=pgc-img-caption></p></div><p class=ql-align-justify>這裡存在兩種情況：λit = 0，特徵點沒有對應的地圖點，λit > 0 特徵點有對應的地圖點。</p><p class=ql-align-justify>對於第一種情況，我們無法從地圖中得到關於該特徵點類別的信息，所以將特徵點類別的分佈假設為在所有類別上的邊緣分佈：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f9187398ec12429a8fc53d87d53669d8><p class=pgc-img-caption></p></div><p class=ql-align-justify>對於第二種情況， 特徵點有對應的地圖點，所以寫成在已知對應的地圖點類別的條件下特徵點的類別概率分佈。但是該地圖點可能被遮擋，所以引入一個檢測概率：δ=1，未遮擋；δ=0，遮擋。將分佈概率改寫成下面形式：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/926cf64ce27d44838038d4cdf2a60555><p class=pgc-img-caption></p></div><p class=ql-align-justify>上述公式中，第一項表示對應地圖點可見或者被遮擋下的特徵點的類別概率，第二項表示對應的地圖點可見或被遮擋的概率，公式不列出了。</p><p class=ql-align-justify>語義的觀測模型的意義在於通過位姿的調整使得圖像中像素點類別和對應的地圖點類別儘可能多的一致。在定義了運動模型和觀測模型後，利用粒子濾波實現定位。</p><p class=ql-align-justify><br></p><h1>五、<strong>語義信息用於提高定位精度</strong></h1><p class=ql-align-justify><strong>（1）Probabilistic Data Association for Semantic SLAM—ICRA2017</strong></p><p class=ql-align-justify>本文第一次將幾何，語義，IMU統一到一個優化框架中，用EM算法求解，實現了一個更高定位精度的slam系統，不考慮幾何和IMU部分，下面介紹一下作者是如何將語義信息融合到SLAM優化框架中的。</p><p class=ql-align-justify>首先，論文裡提到數據關聯，即觀測與地圖中路標之間的對應關係。由於幾何的數據關聯是通過特徵跟蹤實現的，所以這裡只考慮語義的數據關聯，即圖中觀測的檢測框是地圖中哪個物體的。本文沒有考慮硬性的數據關聯，觀測就是和某個路標對應，而是考慮每一個觀測和每一個路標之間都有可能對應，這個對應關係的可信度用一個權重因子w來表示，如果觀測的數量和路標的數量近似相等，那麼數據關聯的個數就是平方的關係。w是EM算法的E步驟求解的。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b22f5bedd5b942a390d450d3e7b74c54><p class=pgc-img-caption></p></div><p class=ql-align-justify>對於每一個數據關聯，定義一個語義factor，所有的語義factor加上幾何factor加上IMUfactor一起構成要優化的目標函數(每個factor對應一個代價函數)：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7933e72f84c9479bb3c81557302b7cb4><p class=pgc-img-caption></p></div><p class=ql-align-justify>下面介紹一下語義factor的幾何意義：</p><p class=ql-align-justify>skb是圖像中通過DPM算法得到的物體檢測框，hπ()表示路標lj在圖像上的投影點，作者假設相機對於lj的觀測服從高斯分佈，均值是投影點，方差和檢測框的大小成正比，也就是相機對於lj的觀測位置應該位於以投影點為中心的一個不確定橢圓內，不確定性大致就是檢測框那麼大，作者在公式(10)中定義的代價函數幾何意義就是最小化投影點到檢測框中心的距離，即最小化高斯分佈均值和檢測框中心點位置之間的差。</p><p class=ql-align-justify>EM算法的E步驟就是計算上面提到的數據關聯的權重；M步是已知權重，計算相機位姿和路標點的位置， 用ISAM2求解。</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（2）VSO Visual Semantic Odometry—ECCV2018</strong></p><p class=ql-align-justify>本文利用場景語義信息建立跟蹤過程中的中期約束（相鄰幀匹配為短期約束，閉環檢測為長期約束），從而減少視覺里程計的漂移。</p><p>在這裡，作者定義了一個語義誤差項，意圖是：如果一個標籤為car的地圖點，在圖像上的投影位置離圖像中的最近的一個car（記為正確分類）的距離小於一個閾值，就最小化這個投影誤差，通過調整估計的相機位姿將投影位置拉到正確分類內。但是car那麼大，具體拉到哪一個點呢，作者在求解的時候考慮到這個問題，即語義誤差項缺少結構信息，所以提出了幾個解決辦法：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/716e4669a90443ada0f91bf3df271a80><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>a 語義誤差項和基本的視覺里程計誤差聯合優化，優化的位置參考VO結果給出的建議</strong></p><p class=ql-align-justify><strong>b. 多個點同時優化，優化的位置參考其他點給出的建議</strong></p><p class=ql-align-justify>那麼，需要將投影過來的點與正確分類的距離轉化為概率才能加如到目標函數中參與優化，作者定義了距離轉化函數DT，投影點距離正確分類的距離越近，具有該類別的概率就越高，反之越小。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d13b54f2cf154f00a6f64c96869bbe60><p class=pgc-img-caption></p></div><p class=ql-align-justify>然後就可以定義語義誤差項了，再將語義誤差E_sem和視覺里程計的誤差E_base設置一個權重進行聯合優化</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（3）CubeSLAM: Monocular 3D Object Detection and slam without prior</strong></p><p class=ql-align-justify>本文出自卡內基梅隆大學的Shichao Yang，作者有很多優秀的開源代碼：shichaoy - Overview，包括本篇論文也部分開源，可以在作者的github上找到。本文利用目標檢測算法生成2D檢測框，然後通過消失點法生成物體的3D檢測框，將物體作為一個路標，最後將物體約束結合幾何信息融合到一個最小二乘公式中，提高slam的定位精度。本文也是基於單目相機，但是沒有利用語義先驗信息恢復尺度，而是通過固定相機的高度實現尺度的統一。</p><p class=ql-align-justify>下面公式為本文構建的最終目標函數，聯合優化相機位姿C，物體O，點P：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6923066d3ba44cf397982bdae1367472><p class=pgc-img-caption></p></div><p class=ql-align-justify>其中 ，相機位姿Tc ∈ SE(3)，點P ∈ R3，物體O= {To , D} ，物體的6自由度位姿：To ∈ SE(3) ,物體尺寸D ∈ R3，長寬高。上面的目標函數包含下面三類誤差：</p><p class=ql-align-justify>object-camera誤差：O= {To , D}，Tc</p><p class=ql-align-justify><strong>a. 3D 測量：</strong></p><p class=ql-align-justify>第一項是將物體的位姿轉化到相機座標系下（前兩個T相乘），和已有的3D框的測量值比較（Tom），由於誤差形式是log誤差，所以位姿是通過乘逆的形式進行比較，如果Tc^-1*To=Tom,那麼log函數裡面是1，該誤差為0，如果不相等，則會產生一定的誤差。第二項比較簡單，直接比較物體的尺寸的差。通過讀作者開源的部分代碼可知，作者將第0幀觀測到的物體作為世界座標系的頂點，以後每一幀都對這個物體有一個觀測作為比較的基準。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/32f3e7afd3d44f43a8224851b2cd6338><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>b. 2D 測量：</strong></p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/8858c69ee0fe482eb9f68f822444bfd6><p class=pgc-img-caption></p></div><p class=ql-align-justify>將3D框投影到圖像平面上，如下圖紅色的2D框，和當前幀本身的檢測框（藍色）作比較，c是檢測框的中心點位置，d是框的尺寸，包括長和寬。</p><p>將3D框投影到圖像平面上，如下圖紅色的2D框，和當前幀本身的檢測框（藍色）作比較，c是檢測框的中心點位置，d是框的尺寸，包括長和寬。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/aff4097bd1d14d5c853a296778ba58c6><p class=pgc-img-caption></p></div><p class=ql-align-justify>Object-point誤差：O= {To , D}，P</p><p>如果點屬於一個物體，那麼應該位於物體的3D檢測框內，公式為：</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7ce5a93424cd45abadf5189ae5889884><p class=pgc-img-caption></p></div><p class=ql-align-justify>即將點根據物體的6自由度位姿轉化到物體幀的點座標應該小於物體本身的長寬高Dm，即位於3D框內，此時誤差取0。如果轉化後的點座標超出了物體的尺寸，誤差取超出的距離。</p><p class=ql-align-justify>Point-camera誤差：P，Tc即傳統slam中的重投影誤差。</p><p class=ql-align-justify>類似的論文：QuadricSLAM: Dual Quadrics From ObjectDetections as Landmarks in Object-Oriented SLAM，本文將物體建模為一個二次曲面，同樣作為一個路標添加到優化中。作者來自昆士蘭科技大學機器人視覺中心，他們有一個面向物體的語義SLAM建立的網站，http://semanticslam.ai/quadricslam.html</p><p class=ql-align-justify><br></p><p class=ql-align-justify><strong>（4）Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments—IROS2018</strong></p><p class=ql-align-justify>本文利用粒子濾波實現定位，機器人的狀態向量定義為：x [m]=[ x y z θ φ ψ ]，前三個值表示機器人在世界座標系中的位置座標，後三個值表示相對於世界座標系幀的pitch, roll and yaw，在粒子濾波中，每個粒子都表示一個可能的x [m]。</p><p class=ql-align-justify>在預測階段，通過一個雙目視覺里程計計算的位姿增量實現初步的下一時刻狀態預測</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/0e08b355096a4f1983fda2826132f263><p class=pgc-img-caption></p></div><p class=ql-align-justify>在更新階段，分為以下兩個方面進行更新：</p><p class=ql-align-justify><strong>a. IMU 用於更新x [m]中的θ，φ，ψ；</strong></p><p>通過計算每個粒子的θ，φ，ψ與IMU測量出的三個值進行做差來更新每個粒子的權重，決定resample階段更相信哪些粒子的狀態。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ef8a16ac499a4624845543c8d7548d2a><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>b. 語義數據用於更新x [m]中的x, y, z；</strong></p><p class=ql-align-justify>圖像中的2D檢測框通過計算的深度信息投影到世界座標系中形成物體的三維點雲作為語義數據，包含位置信息，類別，包含的3D點的數量和類別置信度。論文中提到參與更新的語義數據需要滿足幾個條件，例如置信度大於一個閾值，包含的3D點數量大於一個閾值等。</p><p>首先，將恢復出的物體點雲的位置通過每個粒子代表的機器人位姿轉化到世界座標系下，然後和地圖中具有相同類別的物體點雲比較位置的差異，如果小於一個閾值，就將恢復出的物體點雲和地圖中已有的物體建立聯繫，並利用上述差異更新粒子的權重，更相信將物體點雲投影后和地圖中對應點雲位置差小的粒子（每個粒子代表一個可能的機器人位姿）。另外，如果找不到對應的地圖中的物體，就新建一個。</p><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/228df776a411495fa5778ce24b9db661><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify>作者 | <a class=pgc-link data-content=mp href=https://www.zhihu.com/people/zhang-shan-shan-50-57-2 target=_blank>張珊珊 - 知乎</a></p><p class=ql-align-justify>版權聲明</p><p class=ql-align-justify>本文版權歸《張珊珊》，轉載請自行聯繫</p><pre>點擊下方“瞭解更多”，瞭解CCAI 2019大會信息</pre><div class=pgc-img><img alt=史上最全的語義SLAM論文筆記整理 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/0f3601aae52f4f5d958b9f16b9f95f84><p class=pgc-img-caption></p></div></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>語義</a></li><li><a>SLAM</a></li><li><a>論文</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/e55aaf9b.html alt="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e55aaf9b.html title="論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望">論文推薦 | 袁修孝：航攝影像密集匹配的研究進展與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html alt=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4653cf8e.html title=論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術>論文推薦｜王濤：國產機載大視場三線陣CCD相機GNSS偏心矢量和IMU視軸偏心角標定技術</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8fcabd80.html alt=亞馬遜的Alexa的語義分析性能得到大幅度提高 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RPsVq1PFCI1UDR style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8fcabd80.html title=亞馬遜的Alexa的語義分析性能得到大幅度提高>亞馬遜的Alexa的語義分析性能得到大幅度提高</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/16133b9e.html alt=深度語義模型以及在淘寶搜索中的應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/48529b82dc7c4f048fc3e45d586717e6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/16133b9e.html title=深度語義模型以及在淘寶搜索中的應用>深度語義模型以及在淘寶搜索中的應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f4c5c93c.html alt=谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/46ea0001172cab9535dc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f4c5c93c.html title=谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用>谷歌推出自然語言框架語義解析器SLING，但沒說有沒有用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html alt="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5718fd72.html title="論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法">論文推薦 | 閆廣峰：L1範數探測粗差失效的觀測量識別方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html alt=「論文推薦」左建平教授談岩層移動研究進展及重點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RmTmvrAHAwNOUb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2c7df1e.html title=「論文推薦」左建平教授談岩層移動研究進展及重點>「論文推薦」左建平教授談岩層移動研究進展及重點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html alt=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ReafrDd7EHXniF style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d77a0e0.html title=「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制>「論文推薦」郭廣禮等：無井式煤炭地下氣化岩層及地表移動與控制</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html alt="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c63c80c1.html title="論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法">論文推薦 | 劉照欣：高光譜亞像元定位的線特徵探測法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html alt=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S0q6oVj53DcDnj style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/be8eee7a.html title=「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究>「論文推薦」狄軍貞​等：粒徑對煤矸石汙染物溶解釋放規律影響研究</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0105060d.html alt=分享一個V-SLAM中點雲配准算法改進的方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/598eb7e23bb84efb980c344e323e6d22 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0105060d.html title=分享一個V-SLAM中點雲配准算法改進的方法>分享一個V-SLAM中點雲配准算法改進的方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html alt="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6Ieh75DBRtmcY style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7f16a422.html title="論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法">論文推薦| 李宗春：一種顧及現勢指向的上行天線陣相位中心精確標校方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html alt="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6f4959cd.html title="論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析">論文推薦| 林秀秀:極區慣導編排中地球近似模型的適用性分析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html alt="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a6b0d6e2.html title="論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法">論文推薦| 皮英冬:利用稀少控制點的線陣推掃式光學衛星在軌幾何定標方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html alt="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/R6W0QpMHySg0Qb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b5a90f38.html title="論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術">論文推薦| 閆利：SLAM激光點雲整體精配準位姿圖技術</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>