<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>NLP自然語言處理入門-- 文本預處理Pre-processing | 极客快訊</title><meta property="og:title" content="NLP自然語言處理入門-- 文本預處理Pre-processing - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/dfic-imagehandler/c4324ca7-63dc-4505-a33f-438441cf21f5"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e78c9d2.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e78c9d2.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="NLP自然語言處理入門-- 文本預處理Pre-processing"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e78c9d2.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>NLP自然語言處理入門-- 文本預處理Pre-processing</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/dfic-imagehandler/c4324ca7-63dc-4505-a33f-438441cf21f5><p class=pgc-img-caption></p></div><p><em>引言</em></p><p>自然語言處理NLP（nature language processing），顧名思義，就是使用計算機對語言文字進行處理的相關技術以及應用。在對文本做數據分析時，我們一大半的時間都會花在文本預處理上，而中文和英文的預處理流程稍有不同，本文就對中、英文文本挖掘的常用的NLP的文本預處技術做一個總結。</p><p>文章內容主要按下圖流程講解：</p><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/ee35272103f24ca593cb0585b8c7891d><p class=pgc-img-caption>圖片來自貪心科技</p></div><p>1.中英文文本預處理的特點</p><p>中英文的文本預處理大體流程如上圖，但是還是有部分區別。首先，中文文本是沒有像英文的單詞空格那樣隔開的，因此不能直接像英文一樣可以直接用最簡單的空格和標點符號完成分詞。所以一般我們需要用分詞算法來完成分詞，具體操作後面會講到。</p><p>當然，英文文本的預處理也有自己特殊的地方——拼寫問題，很多時候，對英文預處理要包括拼寫檢查，比如“Helo World”這樣的錯誤，我們不能在分析的時候再去糾錯。還有就是詞幹提取(stemming)和詞形還原(lemmatization)，主要是因為英文中一個詞會會不同的形式，這個步驟有點像孫悟空的火眼金睛，直接得到單詞的原始形態。比如，"faster"、"fastest", 都變為"fast"；“leafs”、“leaves”,都變為"leaf"。</p><p>2. 收集數據</p><p>文本數據的獲取一般有兩個方法：</p><ul><li>別人已經做好的數據集，或則第三方語料庫，比如wiki。這樣可以省去很多麻煩。自己從網上爬取數據。但很多情況所研究的是面向某種特定的領域，這些開放語料庫經常無法滿足我們的需求。我們就需要用爬蟲去爬取想要的信息了。可以使用如beautifulsoup、scrapy等框架編寫出自己需要的爬蟲。</li></ul><p>3.文本預處理</p><p>3.1 去除數據中的非文本部分</p><p>由於爬下來的內容中有很多html的一些標籤，需要去掉。還有少量的非文本內容的可以直接用Python 的正則表達式(re)刪除, 另外還有一些特殊的非英文字符和標點符號,也可以用Python的正則表達式(re)刪除。</p><pre>import re# 過濾不了\\ \ 中文（）還有————r1 = u'[a-zA-Z0-9’!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@，。?★、…【】《》？“”‘’！[\\]^_`{|}~]+'#用戶也可以在此進行自定義過濾字符 # 者中規則也過濾不完全r2 = "[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&amp;*（）]+"# \\\可以過濾掉反向單槓和雙槓，/可以過濾掉正向單槓和雙槓，第一個中括號裡放的是英文符號，第二個中括號裡放的是中文符號，第二個中括號前不能少|，否則過濾不完全r3 = "[.!//_,$&amp;%^*()&lt;&gt;+\"'?@#-|:~{}]+|[——！\\\\，。=？、：“”‘’《》【】￥……（）]+" # 去掉括號和括號內的所有內容r4 = "\\【.*?】+|\\《.*?》+|\\#.*?#+|[.!/_,$&amp;%^*()&lt;&gt;+""'?@|:~{}#]+|[——！\\\，。=？、：“”‘’￥……（）《》【】]"sentence = "hello! wo?rd!."cleanr = re.compile('&lt;.*?&gt;')sentence = re.sub(cleanr, ' ', sentence) #去除html標籤sentence = re.sub(r4,'',sentence)print(sentence)</pre><p>3.2 分詞</p><ul><li>由於英文單詞間由空格分隔，所以分詞分簡單，只需要調用split()函數即可。對於中文來說常用的中文分詞軟件有很多，例如，結巴分詞。安裝也很簡單，比如基於Python的，用"pip install jieba"就可以完成。</li></ul><pre>import jiebasentence = "我們學習人工智能"sentence_seg = jieba.cut(sentence)result = ' '.join(sentence_seg)print(result)</pre><p>3.3 去掉停用詞</p><p>停用詞就是句子沒什麼必要的單詞，去掉他們以後對理解整個句子的語義沒有影響。文本中，會存在大量的虛詞、代詞或者沒有特定含義的動詞、名詞，這些詞語對文本分析起不到任何的幫助，我們往往希望能去掉這些“停用詞”。</p><ul><li>在英文中，例如，"a"，"the",“to"，“their”等冠詞，藉此，代詞..... 我們可以直接用nltk中提供的英文停用詞表。首先，"pip install nltk"安裝nltk。當你完成這一步時，其實是還不夠的。因為NLTK是由許多許多的包來構成的，此時運行Python，並輸入下面的指令。</li></ul><pre>import nltkfrom nltk.tokenize import word_tokenizenltk.download()</pre><p>然後，Python Launcher會彈出下面這個界面，你可以選擇安裝所有的Packages，以免去日後一而再、再而三的進行安裝，也為你的後續開發提供一個穩定的環境。</p><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3eeb903f986644a0bc3cfdff1c3cdb84><p class=pgc-img-caption></p></div><p>我們可以運行下面的代碼，看看英文的停用詞庫。</p><pre>from nltk.corpus import stopwords stop = set(stopwords.words('english')) print(stop)</pre><p>去除停用詞</p><pre>sentence = "this is a apple"filter_sentence= [w for w in sentence.split(' ') if w not in stopwords.words('english')]print(filter_sentence)</pre><p>對於中文停用詞，由於nlkt不支持中文，所以需要自己構造中文停用詞。常用的中文停用詞表是1208個，下載地址在這 。有了中文停用詞表，去除停用詞的代碼和英文類似，這裡就不贅述了。</p><p>3.4 英文單詞--stemming和lemmatization</p><p>詞幹提取(stemming)和詞型還原(lemmatization)是英文文本預處理的特色。兩者其實有共同點，即都是要找到詞的原始形式。只不過詞幹提取(stemming)會更加激進一點，它在尋找詞幹的時候可以會得到不是詞的詞幹。比如"leaves"的詞幹可能得到的是"leav", 並不是一個詞。而詞形還原則保守一些，它一般只對能夠還原成一個正確的詞的詞進行處理。nltk中提供了很多方法，wordnet的方式比較好用，不會把單詞過分精簡。</p><pre>from nltk.stem import SnowballStemmerstemmer = SnowballStemmer("english") # 選擇語言stemmer.stem("leaves") # 詞幹化單詞from nltk.stem import WordNetLemmatizer wnl = WordNetLemmatizer() print(wnl.lemmatize('leaves')) </pre><p>3.5 英文單詞--轉換為小寫</p><p>英文單詞有大小寫之分，Python和python是同一個單詞，所以轉換為小寫可以減少單詞數量。</p><pre>word = "Python"word = word.lower() #轉換成lower_caseprint(word)</pre><p>3.6 特徵處理</p><p>數據處理到這裡，基本上是乾淨的文本了，現在可以調用sklearn來對我們的文本特徵進行處理了。常用的方法如下：</p><ul><li>Bag of Words詞袋模型BowTf-idfN-gram語言模型BigramTrigramWord2vec分佈式模型Word2vec</li></ul><p>接下來我將結合代碼簡單講解一下Tf-idf，Bigram，word2vec的用法。語言模型這一塊內容，可以在之後的文章深入瞭解。</p><p>Tf-idf（Term Frequency-Inverse Document Frequency）</p><p>該模型基於詞頻，將文本轉換成向量，而不考慮詞序。假設現在有N篇文檔，在其中一篇文檔D中，詞彙x的TF、IDF、TF-IDF定義如下：</p><blockquote><p>1.Term Frequency(TF(x)):指詞x在當前文本D中的詞頻</p><p>2.Inverse Document Frequency(IDF): N代表語料庫中文本的總數，而N(x)代表語料庫中包含詞x的文本總數，平滑後的IDF如下：</p></blockquote><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/85146902e75d4ab5ba1acf736fb00cf6><p class=pgc-img-caption></p></div><blockquote><p>3.TF-IDF ：</p></blockquote><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/7590a3bfa93a4072b6ed0faf0cc8feef><p class=pgc-img-caption></p></div><blockquote></blockquote><p>使用sklearn庫裡的TfidfVectorizer類可以幫助我們完成向量化，TF-IDF和標準化三步。</p><pre>from sklearn.feature_extraction.text import TfidfVectorizercorpus = ["This is sample document.", "another random document.", "third sample document text"]vector = TfidfVectorizer()tf_data = vector.fit_transform(corpus)print(tf_data) #(句子下標, 單詞特徵下標) 權重print(vector.vocabulary_) #單詞特徵df1 = pd.DataFrame(tf_data.toarray(), columns=vector.get_feature_names()) # to DataFramedf1</pre><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a00b9ffa067a44d1925f4ef469aec7f8><p class=pgc-img-caption></p></div><p>N-gram語言模型</p><p>詞袋模型不考慮每個單詞的順序。有時候把一句話順序搗亂，我們可能就看不懂這句話在說什麼了，例如：</p><blockquote><p>我玩電腦 = 電腦玩我 ？</p></blockquote><p>N-gram模型是一種語言模型（Language Model），語言模型是一個基於概率的判別模型，它的輸入是一句話（單詞的順序序列），輸出是這句話的概率，即這些單詞的聯合概率（joint probability）。N-gram本身也指一個由N個單詞組成的集合，各單詞具有先後順序，且不要求單詞之間互不相同。常用的有 Bi-gram (N=2N=2) 和 Tri-gram (N=3N=3)，一般已經夠用了。例如,"I love deep learning"，可以分解的 Bi-gram 和 Tri-gram ：</p><blockquote><p>Bi-gram : {I, love}, {love, deep}, {love, deep}, {deep, learning}</p><p>Tri-gram : {I, love, deep}, {love, deep, learning}</p></blockquote><p>sklearn庫中的CountVectorizer 有一個參數ngram_range，如果賦值為(2,2)則為Bigram，當然使用語言模型會大大增加我們字典的大小。</p><pre>ram_range=(1,1) 表示 unigram, ngram_range=(2,2) 表示 bigram, ngram_range=(3,3) 表示 thirgramfrom sklearn.feature_extraction.text import CountVectorizerimport pandas as pdimport jiebadata = ["為了祖國，為了勝利，向我開炮！向我開炮！", "記者：你怎麼會說出那番話", "我只是覺得，對準我自己打"]data = [" ".join(jieba.lcut(e)) for e in data] # 分詞，並用" "連接vector = CountVectorizer(min_df=1, ngram_range=(2,2)) # bigramX = vector.fit_transform(data) # 將分詞好的文本轉換為矩陣print(vector.vocabulary_ ) # 得到特徵print(X) #(句子下標, 單詞特徵下標) 頻數df1 = pd.DataFrame(X.toarray(), columns=vector.get_feature_names()) # to DataFramedf1.head()</pre><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4af4630b292e49e385dc940c4ddaa21e><p class=pgc-img-caption></p></div><p>Word2vec詞向量</p><p>Word2Vec使用一系列的文檔的詞語去訓練模型，把文章的詞映射到一個固定長度的連續向量</p><p>。一般維數較小，通常為100 ~ 500。意義相近的詞之間的向量距離較小。它以稠密的向量形式表示單詞。有兩種模式：</p><blockquote><p>CBOW（Continuous Bag-Of-Words）：利用詞的上下文預測當前的詞。</p><p>Skip-Gram：利用當前的詞來預測上下文。</p></blockquote><p>因為word2vector模型的得到的是詞向量，如何表示句子呢？最簡單的方法就是，將每個句子中的詞向量相加取平均值，即每個句子的平均詞向量來表示句子的向量。</p><pre>from gensim.models import Word2Vec import numpy as npdata = ["I love deep learning","I love studying","I want to travel"]#詞頻少於min_count次數的單詞會被丟棄掉#size指特徵向量的維度為50#workers參數控制訓練的並行數train_w2v = Word2Vec(data,min_count=5,size=50, workers=4)for row in data: #計算平均詞向量，表示句子向量 vec = np.zeros(50) count = 0 for word in row: try: vec += train_w2v[word] count += 1 except: pass avg_data.append(vec/count) print(avg_data[1])</pre><div class=pgc-img><img alt="NLP自然語言處理入門-- 文本預處理Pre-processing" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c7716fb88e89471fbe6d2847fea9bef6><p class=pgc-img-caption></p></div><p>4. 建立分析模型</p><p>有了每段文本的特徵向量後，我們就可以利用這些數據建立分類模型，或者聚類模型了，或者進行相似度的分析。</p><p>5.總結</p><p>3.6小節中的特徵提取一塊，為了demo演示的方便，沒有和前面的分詞，清洗，標準化結合在一起。如果是從分詞步驟開始做的文本預處理，需要注意：在特徵提取時，要將每個句子的單詞以空格連接起來。</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>NLP</a></li><li><a>語言</a></li><li><a>處理</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html alt=自然語言處理（NLP）常用庫整理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/235e94cda81a4858a3000bb62b4f970d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d3668904.html title=自然語言處理（NLP）常用庫整理>自然語言處理（NLP）常用庫整理</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html alt=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d1504f3b2d614621bd4081a64ef145ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2070e90b.html title=一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）>一文看懂自然語言處理-NLP（4個典型應用+5個難點+6個實現步驟）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html alt="自然語言處理 NLP 發展簡史" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a09ec23681e48f5952e8b830fbca5bb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/475b62da.html title="自然語言處理 NLP 發展簡史">自然語言處理 NLP 發展簡史</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bfb5529.html alt=自然語言處理（NLP）學習路線總結 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bfb5529.html title=自然語言處理（NLP）學習路線總結>自然語言處理（NLP）學習路線總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html alt=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/10c7d8fd.html title=神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列>神州泰嶽：公司在自然語言處理領域的基礎技術研究和應用落地均走在行業前列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html alt=第12屆自然語言處理和知識工程國際會議將在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/45b722bf.html title=第12屆自然語言處理和知識工程國際會議將在西華大學舉行>第12屆自然語言處理和知識工程國際會議將在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html alt=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/4e62000034a58600d55e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49bb3bbd.html title=第12屆自然語言處理與知識工程國際學術會議在西華大學舉行>第12屆自然語言處理與知識工程國際學術會議在西華大學舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html alt=自然語言處理中的遷移學習(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfRw76K9qI7Kdu style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/91a0fd9b.html title=自然語言處理中的遷移學習(上)>自然語言處理中的遷移學習(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html alt=你對自然語言處理了解多少呢？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/150674bcc0e44efcae3427c70ad2f072 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/eabb9fa9.html title=你對自然語言處理了解多少呢？>你對自然語言處理了解多少呢？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html alt=自然語言處理中的深度學習：評析與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3738e409cd4648ef9d28084a94faaade style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e0b5c472.html title=自然語言處理中的深度學習：評析與展望>自然語言處理中的深度學習：評析與展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html alt=自然語言處理中的語言模型簡介 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0da5799ae4d94824b62b9e71c6e07aa3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49d71ab7.html title=自然語言處理中的語言模型簡介>自然語言處理中的語言模型簡介</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html alt=自然語言處理的十大應用 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dea6cbd6fbef4e9c935b6f56cb9b0097 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/316cbcad.html title=自然語言處理的十大應用>自然語言處理的十大應用</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html alt=一文讓你入門NLP自然語言處理，看不懂你來找我 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/e0409d62-8a85-4eee-848a-f939a843c1db style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4829ec8a.html title=一文讓你入門NLP自然語言處理，看不懂你來找我>一文讓你入門NLP自然語言處理，看不懂你來找我</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html alt=人工智能之自然語言處理初探 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S4bjUwAFhO20v style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/49c42cc2.html title=人工智能之自然語言處理初探>人工智能之自然語言處理初探</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html alt=人工智能的研究熱點：自然語言處理 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5fdd13a7-6c6d-45d6-9fcd-2829793b5dd3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ca1cc7d7.html title=人工智能的研究熱點：自然語言處理>人工智能的研究熱點：自然語言處理</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>