<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別 | 极客快訊</title><meta property="og:title" content="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/f6b15f58c21a453f8a2f53b7d1b78bb8"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e7c05d5b.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e7c05d5b.html><meta property="article:published_time" content="2020-11-14T20:59:54+08:00"><meta property="article:modified_time" content="2020-11-14T20:59:54+08:00"><meta name=Keywords content><meta name=description content="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e7c05d5b.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>一、背景</p><p>利用業內數據構建知識圖譜是很多客戶正在面臨的問題，其中中文命名實體識別（Named Entity Recognition，簡稱NER）是構建知識圖譜的一個重要環節。我們在與客戶的交流中發現，現有的NER工具（比如Jiagu）對於特定領域的中文命名實體識別效果難以滿足業務需求，而且這些工具很難使用自定義數據集訓練。因此客戶迫切想使用業內最先進的算法在行業內數據集上進行訓練，以改進現有NER工具的不足。本文將介紹如何使用Amazon SageMaker運行基於TensorFlow的中文命名實體識別。</p><p>命名實體識別，是指識別文本中具有特定意義的實體，主要包括人名、地名、機構名、專有名詞等。命名實體識別是信息提取、問答系統、句法分析、機器翻譯、知識圖譜等應用領域的重要基礎工具。</p><p>英語中的命名實體具有比較明顯的形式標誌（即實體中的每個詞的第一個字母要大寫），所以實體邊界識別相對容易，任務的重點是確定實體的類別。和英語相比，中文命名實體識別任務更加複雜，而且相對於實體類別標註子任務，實體邊界的識別更加困難。</p><p>二、中文命名實體識別算法</p><p>NER一直是自然語言處理（NLP）領域中的研究熱點，從早期基於詞典和規則的方法，到傳統機器學習的方法，到近年來基於深度學習的方法，NER研究進展的大概趨勢大致如下圖所示。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/f6b15f58c21a453f8a2f53b7d1b78bb8><p class=pgc-img-caption></p></div><p></p><p>早期的命名實體識別方法基本都是基於規則的。之後由於基於大規模的語料庫的統計方法在自然語言處理各個方面取得不錯的效果之後，一大批機器學習的方法也出現在命名實體類識別任務。</p><p>值得一提的是，由於深度學習在自然語言的廣泛應用，基於深度學習的命名實體識別方法也展現出不錯的效果，此類方法基本還是把命名實體識別當做序列標註任務來做，比較經典的方法是LSTM+CRF、BiLSTM+CRF。</p><p>我們知道，預訓練模型可以大幅提升計算機視覺的深度學習算法表現，而在NLP領域也是同理，預訓練語言模型可以有效提升文本分類、機器翻譯、命名實體識別等任務的效果。預訓練語言模型經歷了從詞嵌入（Word Embedding），到BERT，再到ALBERT的演進。</p><p>BERT的全稱是Bidirectional Encoder Representation from Transformers，即雙向Transformer的編碼器（Encoder），因為解碼器（Decoder）是不能獲得要預測的信息的。模型的主要創新點都在預訓練方法上，即用了Masked LM和Next Sentence Prediction兩種方法分別捕捉詞語和句子級別的表示。</p><p>ALBERT（見參考資料4）基於BERT，但有一些改進，它可以在主要基準測試上獲得最先進的性能，而參數卻減少了30％。比如，對於albert_base_zh，它只有原始BERT模型的10%的參數，但是保留了主要精度。</p><p>本文將使用預訓練語言模型ALBERT做中文命名實體識別，該項目基於開源的代碼修改而來（本文代碼見參考資料1，原始代碼見參考資料2），使用TensorFlow框架開發，在下一節，我們將展示如何在Amazon SageMaker中進行該模型的訓練。</p><p>三、在Amazon SageMaker中運行TensorFlow</p><p>本節將介紹如何使用Amazon SageMaker的自定義容器 （Bring Your Own Container，簡稱BYOC）和自定義腳本（Bring Your Own Script，簡稱BYOS）兩種方式來運行TensorFlow程序的訓練任務。首先我們來看下如何在Amazon SageMaker Notebook上運行這個項目，然後再把它運行在Amazon SageMaker上。</p><h3 class=pgc-h-arrow-right>1. 在Amazon SageMaker Notebook上運行TensorFlow開源代碼</h3><p>我們首先要創建Amazon SageMaker Notebook，然後下載代碼和數據，最後運行代碼。如果一切運行正常，我們就可以進行下一步工作——將該TensorFlow代碼運行到Amazon SageMaker中了。</p><p>1.1 創建Amazon SageMaker Notebook</p><p>我們首先要創建一個Amazon SageMaker Notebook，筆記本實例類型最好選擇ml.p2.xlarge，這樣就可以使用GPU進行訓練的測試了，卷大小建議改成10GB或以上，因為運行該項目需要下載一些額外的數據。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/21b2153c0cc04b02997a9a350cdc20d0><p class=pgc-img-caption></p></div><p>1.2 下載代碼和數據</p><p>筆記本啟動後，打開頁面上的終端，執行以下命令下載代碼：</p><pre><code>cd ~/SageMakergit clone https://github.com/whn09/albert-chinese-ner.git</code></pre><p>執行以下命令下載和解壓數據（數據來源見參考資料3）：</p><pre><code>cd ~/SageMaker/albert-chinese-nerwget https://storage.googleapis.com/albert_zh/albert_base_zh_additional_36k_steps.zipunzip albert_base_zh_additional_36k_steps.zip -d albert_base_zh</code></pre><p>1.3 運行代碼</p><p>我們需要進入一個虛擬環境tensorflow_p36，該環境預製了運行TensorFlow所需要的常用組件，運行run_train.sh進行訓練，命令如下：</p><pre><code>cd ~/SageMaker/albert-chinese-nersource activate tensorflow_p36./run_train.sh</code></pre><p>如果出現下面的輸出，說明運行結果正常，在實例類型為ml.p2.xlarge的筆記本中，訓練速度可以達到23個樣本/秒，如果是其他類型實例，速度可能有差異。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/807f6b05e157440db68805544df985d5><p class=pgc-img-caption></p></div><p></p><p>2. 自定義容器（BYOC）</p><p>自定義容器需要經歷準備Dockerfile，創建訓練的啟動腳本，創建鏡像並上傳到Amazon ECR，本地測試和Amazon SageMaker測試等步驟。完整執行過程見tensorflow_bring_your_own.ipynb。</p><p>2.1 準備Dockerfile</p><p>我們首先需要準備Dockerfile，在其中安裝TensorFlow程序運行必須的環境，拷貝所有代碼到鏡像中。</p><pre><code>FROM tensorflow/tensorflow:1.15.2-gpu-py3ENV PATH="/opt/ml/code:${PATH}"COPY ./ /opt/ml/codeWORKDIR /opt/ml/code</code></pre><p>這裡我們需要了解Amazon SageMaker對於容器內目錄結構的要求，具體如下圖所示，訓練所需代碼放到/opt/ml/code目錄下，訓練所需數據放到/opt/ml/input/data目錄下，訓練輸出的模型放到/opt/ml/model目錄下，訓練結果文件或者日誌文件放到/opt/ml/output目錄下，訓練超參數文件是由Amazon SageMaker自動生成的，在/opt/ml/input/config目錄下。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/029edcc1141247d9a3bf74cadd8473ad><p class=pgc-img-caption></p></div><p></p><p>2.2 創建訓練的啟動腳本</p><p>Amazon SageMaker在訓練時默認的啟動腳本是train，您可以將自己代碼中的啟動腳本命名為train，但我們更建議您使用我們提供的啟動腳本train，該腳本是基於Python的，可以幫助您解析傳入的超參數，並調用您代碼中的實際啟動腳本。</p><p>2.3 創建鏡像並上傳到Amazon ECR</p><p>在準備好Dockerfile和啟動腳本後，我們可以使用build_and_push.sh這個腳本創建鏡像並上傳到Amazon ECR。注意這個過程可能需要進行很多次，因為我們不可避免地要修改Dockerfile或者TensorFlow程序以使得它們可以正常工作。如果尚未調試完成，我們可以暫時不執行該腳本的最後一句docker push ${fullname}，以避免頻繁上傳鏡像到Amazon ECR。</p><p>2.4 本地測試</p><p>在創建鏡像完成後，我們可以使用Amazon SageMaker的本地模式進行本地測試：第一步，執行utils/setup.sh來初始化本地模式。第二步，指定執行的角色，這裡我們假設您是在Amazon SageMaker Notebook上執行的，如果是其他環境，您可能需要手動指定角色的ARN。第三步，設定超參數，這裡需要對應到您程序中所需的超參數。第四步，設定訓練機型為local或者local_gpu（支持GPU）。第五步，創建Estimator，這裡需要傳入之前獲得的角色、訓練機型、機器數量、鏡像名稱、超參數等。第六步，啟動訓練，這裡需要傳入訓練數據的位置，在本地模式下，訓練數據的位置可以設置成本地路徑。</p><pre><code>role = get_execution_role()hyperparameters = {'task_name': 'ner', 'do_train': 'true', 'do_eval': 'true',  'data_dir': '/opt/ml/input/data/training', 'output_dir': '/opt/ml/model',                    'vocab_file': './albert_config/vocab.txt', 'bert_config_file': './albert_base_zh/albert_config_base.json', _seq_length': 128, 'train_batch_size': 64, 'learning_rate': 2e-5, 'num_train_epochs': 1}instance_type = 'local'if subprocess.call('nvidia-smi') == 0:    instance_type = 'local_gpu'    estimator = Estimator(role=role,                      train_instance_count=1,                      train_instance_type=instance_type,                      image_name='sagemaker-tf-albert-chinese-ner:latest',                      hyperparameters=hyperparameters)estimator.fit('file:///home/ec2-user/SageMaker/albert-chinese-ner/data/')</code></pre><p>訓練啟動後，我們可以看到訓練的日誌輸出，以及監控本機的GPU、CPU、內存等的使用率等情況，以確認程序可以正常工作。</p><p>如果在此過程中需要進入正在運行的容器內調試，我們可以使用docker ps命令獲取當前正在運行的容器ID，並使用docker exec -it &lt;CONTAINER ID> /bin/bash進入容器內進行調試。</p><p>2.5 Amazon SageMaker測試</p><p>在本地測試和上傳鏡像到Amazon ECR完成後，我們可以使用Amazon SageMaker進行測試：第一步，上傳數據到Amazon S3，獲取鏡像在Amazon ECR的地址。第二步，指定執行的角色，這裡我們假設您是在Amazon SageMaker Notebook上執行的，如果是其他環境，您可能需要手動指定角色的ARN。第三步，設定超參數，這裡需要對應到您程序中所需的超參數。第四步，設定訓練機型為ml.p2.xlarge（支持GPU）。第五步，創建Estimator，這裡需要傳入之前獲得的角色、訓練機型、機器數量、鏡像地址、超參數等。第六步，啟動訓練，這裡需要傳入訓練數據的位置，在Amazon SageMaker模式下，訓練數據的位置需要設置成Amazon S3路徑。</p><pre><code>prefix = 'DEMO-tensorflow-albert-chinese-ner'sess = sage.Session()WORK_DIRECTORY = '/home/ec2-user/SageMaker/albert-chinese-ner/data'data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)client = boto3.client('sts')account = client.get_caller_identity()['Account']my_session = boto3.session.Session()region = my_session.region_namealgorithm_name = 'sagemaker-tf-albert-chinese-ner'ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)hyperparameters = {'task_name': 'ner', 'do_train': 'true', 'do_eval': 'true', 'data_dir': '/opt/ml/input/data/training', 'output_dir': '/opt/ml/model', 'vocab_file': './albert_config/vocab.txt', 'bert_config_file': './albert_base_zh/albert_config_base.json', 'max_seq_length': 128, 'train_batch_size': 64, 'learning_rate': 2e-5, 'num_train_epochs': 3}instance_type = 'ml.p2.xlarge'estimator = Estimator(role=role,                      train_instance_count=1,                      train_instance_type=instance_type,                      image_name=ecr_image,                      hyperparameters=hyperparameters)estimator.fit(data_location)</code></pre><p></p><p>訓練啟動後，我們可以在Amazon SageMaker控制檯看到這個訓練任務，點進詳情可以看到訓練的詳情，日誌輸出，以及監控機器的GPU、CPU、內存等的使用率等情況，以確認程序可以正常工作。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/952dd49836cb4bfcb082216aed9703cd><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/29c8f49e297a40e0bf7e08047d837203><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/c96b466644834aeb8c6d32bd478c28a4><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/c3feee2ce548429ba668d48dc107a6ac><p class=pgc-img-caption></p></div><p></p><p>在此過程中我們無法進入正在運行的容器內調試，您可以將盡量多的日誌打印出來，或者輸出到/opt/ml/output路徑下，該路徑下的所有文件在訓練完成後會被自動打包成output.tar.gz放到設定好的位於Amazon S3的輸出路徑下。</p><p>2.6 訓練結果</p><p>本文所示程序使用了MSRA公開的中文實體識別數據集進行訓練，在訓練3輪之後，最優的F1值就可以達到0.948345，屬於比較領先的結果。</p><pre><code>***** Eval results albert_base_ner_checkpoints/model.ckpt-0 *****eval_f = 0.01672106eval_precision = 0.010008455eval_recall = 0.10698523global_step = 0loss = 2367.2935***** Eval results albert_base_ner_checkpoints/model.ckpt-1000 *****eval_f = 0.9256434eval_precision = 0.95667034eval_recall = 0.8976247global_step = 1000loss = 17.80814***** Eval results albert_base_ner_checkpoints/model.ckpt-2000 *****eval_f = 0.9444123eval_precision = 0.94401eval_recall = 0.9452899global_step = 2000loss = 10.842231***** Eval results albert_base_ner_checkpoints/model.ckpt-2374 *****eval_f = 0.948345eval_precision = 0.9542561eval_recall = 0.94261235global_step = 2374loss = 10.520088</code></pre><h3 class=pgc-h-arrow-right>3. 自定義腳本（BYOS）</h3><p>使用BYOS的方法和BYOC的不同之處在於：BYOC是使用用戶自己創建的鏡像來運行程序，更適用於用戶對鏡像自定義程度較高的使用情景；而BYOS是使用預先構建好的鏡像，只是傳入用戶自己的代碼來運行程序，不需要用戶自己調試鏡像，更適用於比較簡單的使用情景。</p><p>由於不需要編譯自定義鏡像，我們可以直接進行本地測試和Amazon SageMaker測試，完整流程見tensorflow_script_mode_quickstart.ipynb。</p><p>3.1 本地測試</p><p>我們可以使用Amazon SageMaker的本地模式進行本地測試：第一步，執行utils/setup.sh來初始化本地模式。第二步，指定執行的角色，這裡我們假設您是在Amazon SageMaker Notebook上執行的，如果是其他環境，您可能需要手動指定角色的ARN。第三步，設定超參數，這裡需要對應到您程序中所需的超參數。第四步，設定訓練機型為local或者local_gpu（支持GPU）。第五步，創建一個名為TensorFlow的Estimator，這裡需要傳入訓練入口腳本（entry_point）、源代碼路徑（source_dir）、之前獲得的角色、訓練機型、機器數量、TensorFlow版本、Python版本、超參數等。第六步，啟動訓練，這裡需要傳入訓練數據的位置，在本地模式下，訓練數據的位置可以設置成本地路徑。</p><pre><code>role = get_execution_role()hyperparameters = {'task_name': 'ner', 'do_train': 'true', 'do_eval': 'true', _dir': '/opt/ml/input/data/training', 'output_dir': '/opt/ml/model', 'vocab_file': './albert_config/vocab.txt', 'bert_config_file': './albert_base_zh/albert_config_base.json', _seq_length': 128, 'train_batch_size': 64, 'learning_rate': 2e-5, 'num_train_epochs': 1}train_instance_type='local'if subprocess.call('nvidia-smi') == 0:    train_instance_type = 'local_gpu'estimator = TensorFlow(entry_point='albert_ner.py',                       source_dir='.',                       train_instance_type=train_instance_type,                       train_instance_count=1,                       hyperparameters=hyperparameters,                       role=role,                       framework_version='1.15.2',                       py_version='py3',                       script_mode=True)inputs = {'training': f'file:///home/ec2-user/SageMaker/albert-chinese-ner/data/'}estimator.fit(inputs)</code></pre><p></p><p>這裡我們可以注意到estimator.fit()傳入的參數與BYOC略有不同，這兩個寫法其實是等價的，事實上，這裡的寫法更規範一些，按照Amazon SageMaker的文檔，輸入數據可以有多個通道（Channel），默認的通道是training，在本文的代碼中，訓練、驗證等過程其實都是從training通道中讀取的數據，所以更規範的做法是，我們應該額外增加一個通道validation，用來存放驗證數據。</p><p>訓練啟動後，我們可以看到訓練的日誌輸出，以及監控本機的GPU、CPU、內存等的使用率等情況，以確認程序可以正常工作。</p><p>如果在此過程中需要進入正在運行的容器內調試，我們可以使用docker ps命令獲取當前正在運行的容器ID，並使用docker exec -it &lt;CONTAINER ID> /bin/bash進入容器內進行調試。另外，我們使用docker images命令可以看到Amazon SageMaker自動下載了一個名為763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:1.15.2-gpu-py3的鏡像，該鏡像是由Amazon SageMaker預編譯的。</p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/4956502f431b4d748dcfe8e3c1f15a5b><p class=pgc-img-caption></p></div><p></p><p>3.2 Amazon SageMaker測試</p><p>在本地測試完成後，我們可以使用Amazon SageMaker進行測試：第一步，上傳數據到Amazon S3。第二步，指定執行的角色，這裡我們假設您是在Amazon SageMaker Notebook上執行的，如果是其他環境，您可能需要手動指定角色的ARN。第三步，設定超參數，這裡需要對應到您程序中所需的超參數。第四步，設定訓練機型為ml.p2.xlarge（支持GPU）。第五步，創建一個名為TensorFlow的Estimator，這裡需要傳入訓練入口腳本（entry_point）、源代碼路徑（source_dir）、之前獲得的角色、訓練機型、機器數量、TensorFlow版本、Python版本、超參數等。第六步，啟動訓練，這裡需要傳入訓練數據的位置，在Amazon SageMaker模式下，訓練數據的位置需要設置成Amazon S3路徑。</p><pre><code>inputs = sagemaker.Session().upload_data(path='/home/ec2-user/SageMaker/albert-chinese-ner/data', key_prefix='DEMO-tensorflow-albert-chinese-ner')estimator = TensorFlow(entry_point='albert_ner.py',                       source_dir='.',                       train_instance_type='ml.p2.xlarge',                       train_instance_count=1,                       hyperparameters=hyperparameters,                       role=role,                       framework_version='1.15.2',                       py_version='py3',                       script_mode=True)             estimator.fit({'training': inputs})</code></pre><p></p><p>訓練啟動後，我們可以在Amazon SageMaker控制檯看到這個訓練任務，點進詳情可以看到訓練的詳情，日誌輸出，以及監控機器的GPU、CPU、內存等的使用率等情況，以確認程序可以正常工作。</p><p></p><p>在這裡，source_dir我們設置的是本地代碼路徑，Amazon SageMaker會自動將該路徑下的所有代碼和數據拷貝進容器中。此外，BYOS模式還支持git路徑作為代碼路徑，使用方法如下：</p><pre><code>git_config = {'repo': 'https://github.com/whn09/albert-chinese-ner.git', 'branch': 'master'}estimator = TensorFlow(entry_point='albert_ner.py',                       source_dir='.',                       git_config=git_config,                       train_instance_type='ml.p2.xlarge',                       train_instance_count=1,                       hyperparameters=hyperparameters,                       role=role,                       framework_version='1.15.2',                       py_version='py3',                       script_mode=True)estimator.fit({'training': inputs})</code></pre><p>但是，由於本文所用代碼需要ALBERT預訓練數據，而該數據不包含在git內，所以我們需要對代碼進行改造，以使得在代碼內下載並解壓數據，才能夠正常訓練。這裡我們不再展示如何操作，感興趣的讀者可以自行嘗試。</p><p>四、結論</p><p>本文講解了如何使用Amazon SageMaker運行基於TensorFlow的中文命名實體識別，其中算法部分是使用預訓練語言模型ALBERT做中文命名實體識別。</p><p>本文展示瞭如何把一個已有項目快速運行到Amazon SageMaker上，如果您想使用到Amazon SageMaker的更多高級用法，需要對已有項目進行改造，比如支持實時推理、批量推理、斷點重新訓練等，具體可以查看Amazon SageMaker的文檔。</p><p>本文所演示的使用方法是基於單機單卡的，Amazon SageMaker 提供基於 Docker 的簡化分佈式 TensorFlow 訓練平臺，如果要將程序擴展到多機多卡進行訓練，可以參考其他相關博客。</p><p><strong>本篇作者</strong></p><div class=pgc-img><img alt="使用 Amazon SageMaker 運行基於 TensorFlow 的中文命名實體識別" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/786dd0a3c9714e72a3efb0558eb77004><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Amazon</a></li><li><a>SageMaker</a></li><li><a>運行基</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/f8c270d.html alt="黑客新手法，專找配置錯誤的Amazon S3儲存貯體植入惡意程序" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/f1e3ca7a6dae4d139a8832c295cc7839 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f8c270d.html title="黑客新手法，專找配置錯誤的Amazon S3儲存貯體植入惡意程序">黑客新手法，專找配置錯誤的Amazon S3儲存貯體植入惡意程序</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>