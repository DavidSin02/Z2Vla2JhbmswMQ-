<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ | 极客快訊</title><meta property="og:title" content="同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/061d642903b64e2381535ca2be379ae7"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e929204.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/e929204.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/e929204.html><meta property="article:published_time" content="2020-10-29T21:04:30+08:00"><meta property="article:modified_time" content="2020-10-29T21:04:30+08:00"><meta name=Keywords content><meta name=description content="同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/e929204.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>​</p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/061d642903b64e2381535ca2be379ae7><p class=pgc-img-caption></p></div><p>同程藝龍的機票、火車票、汽車票、酒店相關業務已經接入了RocketMQ，用於流量高峰時候的削峰，以減少後端的壓力。同時，對常規的系統進行解耦，將一些同步處理改成異步處理，每天處理的數據達1500億條。</p><p>在近期的Apache RockeMQ Meetup上，同程藝龍機票事業部架構師查江，分享了同程藝龍的消息系統如何應對每天1500億條的數據處理，通過此文，您將瞭解到：</p><p>o 同程藝龍在消息方面的使用情況；</p><p>o 消息在同程藝龍的應用場景；</p><p>o 技術上踩過哪些坑；</p><p>o 基於RocketMQ，做了哪些改進；</p><p>1 同程藝龍在消息方面的使用情況</p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/11ea7a759c364882bbac667d17e78ee5><p class=pgc-img-caption></p></div><p class=ql-align-justify>RocketMQ集群分為 Name Server 和Broker兩部分，Name Server用的是雙主模式，一個是考慮性能，另一個是考慮安全性。 在純數據的Broker分成很多組，每個組裡面分為Master和Slave。目前，我們的機票、火車票、汽車票、酒店相關業務已經接入了RocketMQ，用於流量高峰時候的削峰，以減少後端的壓力。 同時，對常規的系統進行解耦，將一些同步處理改成異步處理，每天處理的數據多達1500億條。</p><p>選擇RocketMQ的原因是：</p><p>o 接入簡單，引入的Java包比較少；</p><p>o 純Java開發，設計邏輯比較清晰；</p><p>o 整體性能穩定，在Topic數量大的情況下，可以保持性能；</p><p>2 消息在同程藝龍的應用場景</p><p><strong>退訂系統</strong></p><p><strong>圖中是我們退訂系統中的一個應用場景。</strong>用戶點擊前端的退訂按鈕，系統首先會調用退訂接口，再去調用供應商的退訂接口，從而完成一個退訂功能。</p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/abd51a9cad6743829e15dad8168d4566><p class=pgc-img-caption></p></div><p class=ql-align-justify>如果供應商的系統接口不可靠，會導致用戶退訂失敗;如果系統設置為同步操作，則會導致用戶需要再次點擊。所以，我們引入了RocketMQ，將同步改為異步。當前端用戶發出退訂需求時，退訂系統接收到請求，記錄到退訂系統的數據庫裡面，表示這個用戶正在退訂。同時，通過消息引擎把這條退訂消息發送到與供應商對接的系統，以調用供應商的接口。</p><p>如果接口調用成功，數據庫進行標識，則表示已經退訂成功。同時，­­­加了一個補償的腳本，去數據庫撈那些未退訂成功的消息，進行重新退訂，以此避免消息丟失引起的退訂失敗。</p><p><strong>房倉系統</strong></p><p><strong>第二個應用場景是我們的房倉系統。</strong>這是一個比較常規的消息使用場景，我們先從供應商處採集一些酒店的基本信息數據和詳情數據，然後接入到消息系統，由後端的分銷系統、最小价系統和庫存系統來進行計算。同時，當供應商出現變價的情況，變價事件也會通過消息系統傳遞給我們的後端業務系統，以此保證數據的實時性和準確性。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b8bff203b656490da4c965108ab9fae6><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>供應庫的訂閱系統</strong></p><p class=ql-align-justify><strong>數據庫的訂閱系統也用到了消息的應用。</strong>一般情況下做數據庫同步，都是通過binlog去讀裡面的數據，然後搬運到數據庫。在搬運的過程中，我們最關注的是數據的順序性，因此在數據庫row模式的基礎上，新增了一個功能，以確保每一個Queue裡面的順序是唯一的。</p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/28802a027dcc408c959b17bbffa77d30><p class=pgc-img-caption></p></div><p class=ql-align-justify>雖然，Queue裡面的順序天然都是唯一的，但我們在使用上有一個特點，就是把相同ID的消息都是放在同一個Queue裡面的。例如，圖中右上角id1的消息，數據庫主字段是id1，統一放在Queue1裡面，而且是順序的。在Queue2裡，兩個id3之間被兩個順序的id2間隔開來了，但實際消費讀出來的時候，也會是順序的，由此，可以用多隊列的順序來提高整體的併發度。</p><p>3 我們踩過哪些坑</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/f86e556afb86422dbaa2503bb58e2c4a><p class=pgc-img-caption></p></div><p><strong>供應商系統的場景</strong></p><p>上圖中，一個MQ對應有兩個消費者，他們是在同一個Group1中，起初大家都只有Topic1，這時候是正常消費的。但如果在第一個消費者裡面加入一個Topic2，這時候是無法消費的或者說是消費不正常了。這是RocketMQ本身的機制引起的問題，需要在第二個消費者裡面加入Topic2才能正常消費。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/b4a78f443b0f421b95eecee4893460a7><p class=pgc-img-caption></p></div><p class=ql-align-justify><strong>支付交易系統的場景</strong></p><p class=ql-align-justify>另外一個是支付交易系統，這個場景下也是有兩個應用，他們都是在同一Group和同一Topic下，一個是消費Tag1的數據，另一個是消費Tag2的數據。在正常情況下，啟動應該是沒問題的，但是有一天我們發現其中一個應用無法啟動。而另外一個應用只消費Tag2的數據，由於RocketMQ的機制會把Tag1的數據拿過來，拿過來之後會把Tag1的數據丟棄，這將導致用戶在支付的過程中出現支付失敗的情況。</p><p class=ql-align-justify><strong>對此，我們把Tag2放到Group2裡面，兩個Group就不會消費相同的消息了。個人建議RocketMQ能夠實現一個機制，即只接受自己的Tag消息，不接受非相關的Tag。</strong></p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/22e14b67d25342b795f62f71bea55032><p class=pgc-img-caption></p></div><p class=ql-align-center><br></p><p class=ql-align-justify><br></p><p><strong>大量老數據讀取的場景</strong></p><p>在火車票消費的場景中，我們發現有200億條老數據沒有被消費。當我們消費啟動的時候，RocketMQ會默認從第0個數據開始讀，這時候磁盤IO飆升到100%，從而影響到其他消費端數據的讀取，但這些老數據被加載後後，並沒有實際作用。因此，對於大量老數據讀取的改進方式是：</p><p><strong>對於新消費組，默認從LAST_OFFSET消費；</strong></p><p><strong>Broker中單Topic堆積超過1000萬時，禁止消費，需聯繫管理員開啟消費；</strong></p><p><strong>監控要到位，磁盤IO飆升時，能立刻聯繫到消費方處理；</strong></p><p><strong>服務端的場景</strong></p><p>CentOS 6.6中 Futex Kernel bug, 導致Name Server, Broker進程經常掛起，無法正常工作；</p><p><strong>- > 升級到6.7</strong></p><p>服務端2個線程會創建相同CommitLog放入List，導致計算消息offset錯誤，解析消息失敗，無法消費，重啟沒法解決問題。</p><p><strong>- > 線程安全問題，改為單線程</strong></p><p>Pull模式下重置消費進度，導致服務端填充大量數據到Map中，broker cpu使用率飆升100%。</p><p><strong>- > Map局部變量場景用不到，刪除</strong></p><p>Master建議客戶端到Slave消費時，若數據還沒同步到Slave, 會重置pullOffset, 導致大量重複消費。</p><p><strong>- ></strong> <strong>不重置offset</strong></p><p>同步沒有MagicCode，安全組掃描同步端口時，Master解析錯誤，導致一些問題。</p><p><strong>- > 同步時添加magicCode校驗</strong></p><p>4 基於RocketMQ，我們做了哪些改進</p><p><strong>新增客戶端</strong></p><p>新增.net客戶端，基於Java源代碼原生開發；</p><p>新增HTTP客戶端，實現部分功能，並通過Netty Server連接RocketMQ；</p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/06491bb8e2d541709910c3f17b6c4600><p class=pgc-img-caption></p></div><p><strong>新增消息限流功能</strong></p><p>如果客戶端代碼寫錯產生死循環，會產生大量的重複數據，這時會把生產線程打滿，導致隊列溢出，嚴重影響我們MQ集群的穩定性，從而影響其他業務。</p><p class=ql-align-center><br></p><div class=pgc-img><img alt=同程藝龍：如何基於RocketMQ打造日均容量1500億的消息引擎？ onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c22bfde667db43cfbdca7f2dd43e7266><p class=pgc-img-caption></p></div><p class=ql-align-justify>上圖是限流的模型圖。我們把限流功能加在Topic之前，通過限流功能可以設置rate limit和size limit等。其中rate limit是通過令牌桶算法來實現的，即每秒往桶裡放多少個令牌，每秒就消費多少速度，或者是往Topic裡寫多少數據。以上的兩個配置是支持動態修改的。</p><p><strong>後臺監控</strong></p><p>我們還做了一個監控後臺，用於監控消息的全鏈路過程，包括</p><p>o 消息全鏈路追蹤，覆蓋消息產生、消費、過期整個生命週期；</p><p>o 消息生產、消費曲線；</p><p>o 消息生產異常報警；</p><p>o 消息堆積報警，通知哪個IP消費過慢；</p><p><strong>其他功能</strong></p><p>o HTTP方式生產，消費消息；</p><p>o Topic消費權限設置，Topic只能被指定Group消費，防止線上錯亂訂閱；</p><p>o 支持新消費組從最新位置消費 (默認是從第一條開始消費)；</p><p>o 廣播模式消費進度同步 (服務端顯示進度)；</p><p class=ql-align-center><br></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>同程</a></li><li><a>藝龍</a></li><li><a>RocketMQ</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/15b0178.html alt=一定能看懂的RocketMQ事務消息源碼介紹(乾貨) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9893da5524c1439f8a11cb24322c57a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/15b0178.html title=一定能看懂的RocketMQ事務消息源碼介紹(乾貨)>一定能看懂的RocketMQ事務消息源碼介紹(乾貨)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dffb53c.html alt="消息隊列之事務消息，RocketMQ 和 Kafka是如何做的？" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/S2XWraJF1wHo8F style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dffb53c.html title="消息隊列之事務消息，RocketMQ 和 Kafka是如何做的？">消息隊列之事務消息，RocketMQ 和 Kafka是如何做的？</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/3ff1309.html alt="基於RocketMQ分佈式事務 - 完整示例" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=http://p1.pstatp.com/large/pgc-image/388a9665bf45413eb391e47c6d10ca12 style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/3ff1309.html title="基於RocketMQ分佈式事務 - 完整示例">基於RocketMQ分佈式事務 - 完整示例</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>