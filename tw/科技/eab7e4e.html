<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答 | 极客快訊</title><meta property="og:title" content="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p9.pstatp.com/large/pgc-image/89d6bb2700894ec79b76fdc99e8768e9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eab7e4e.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eab7e4e.html><meta property="article:published_time" content="2020-10-29T21:00:10+08:00"><meta property="article:modified_time" content="2020-10-29T21:00:10+08:00"><meta name=Keywords content><meta name=description content="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/eab7e4e.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><br></p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/89d6bb2700894ec79b76fdc99e8768e9><p class=pgc-img-caption></p></div><blockquote><p><em>作者: 北京大學碩士 易鴻偉</em><br><em>公眾號：<strong>將門創投</strong>(thejiangmen)</em></p></blockquote><p style=text-align:start><br></p><p style=text-align:start><strong>ECCV 2020系列文章專題 第·5·期</strong></p><p style=text-align:start>本文將分享<strong>北京大學碩士易鴻偉</strong>等在<strong>ECCV 2020</strong>上發表的兩篇關於<strong>多視圖立體幾何</strong>的工作：基於自適應視角選擇的金字塔多視角立體幾何神經網絡(PVA-MVSNet)及採用動態一致性檢測的密集混合式多視角立體幾何循環神經網絡(D2HC-RMVSNet(spotlight))。更多ECCV精彩內容，關注<strong>將門創投（</strong><em><strong>thejiangmen</strong></em><strong>）公眾號，</strong>後臺回覆“ECCV”即可查看！</p><p style=text-align:start>好消息，我“門”首次舉辦的頂會線上活動——<strong>將門「ECCV 2020鮮聲奪人云際會」</strong>火熱報名中，掃描下方二維碼，或複製 http://thejiangmen2222.mikecrm.com/OUKtdGm至瀏覽器，馬上報名，搶佔席位！</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cd08693bbbad4f6987233f17e20760c1><p class=pgc-img-caption>快來報名吧！</p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/aaa7c65e0fac475692beb44daa7fa5e5><p class=pgc-img-caption></p></div><p style=text-align:start>文章鏈接：https://arxiv.org/abs/1912.03001v2</p><p style=text-align:start>代碼鏈接：https://github.com/yhw-yhw/PVAMVSNet</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5484e2a300ba4beda63de519f40019bf><p class=pgc-img-caption></p></div><p style=text-align:start>文章鏈接：https://arxiv.org/pdf/2007.10872.pdf</p><p style=text-align:start>代碼鏈接：https://github.com/yhw-yhw/D2HC-RMVSNet</p><h1 class=pgc-h-arrow-right><strong>一、導讀</strong></h1><p style=text-align:start>從圖像中重建3D幾何是數十年來經典的計算機視覺問題，主要方法之一是<strong>Multi-view Stereo </strong>(MVS)，旨在給定兩個以上的較準圖片，使用立體對應作為主要信息恢復稠密3D場景表示。</p><p style=text-align:start>在針對普通消費者的領域，該技術可以用於用戶對自己喜歡的物體通過拍攝照片，進行實時或雲端的三維重建，從而獲得該物體的三維模型。在針對商業用戶的領域，該技術可以為商業用戶提供三維重建服務，在建築領域、測繪領域及遊戲領域均有重要的應用價值。</p><p style=text-align:start>基於深度學習的多視圖立體幾何方法，從訓練數據中學習知識可以推斷出從立體匹配算法中難以獲得的信息去解決匹配模糊性，但是這些方法並沒有使用如下非常重要的信息：<strong>多視角圖像的差別和多尺度信息</strong>。基於此兩點，我們提出一種<strong>基於自適應視角選擇的金字塔多視角立體幾何神經網絡模型(PVA-MVSNet)</strong>：</p><ol start=1><li>自適應視圖聚合模塊，考慮在不同視角圖像間多重匹配的不同重要性，將更好的匹配區域特徵得到增強，錯誤匹配的區域特徵得到抑制。</li><li>多尺度度量約束金字塔深度圖聚合，通過多尺度度量約束聚合由VA-MVSNet產生的金字塔深度圖為一張融合後的深度圖。</li></ol><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/a87c2c130b6f4c4486ddd31dd5e7becd><p class=pgc-img-caption></p></div><p style=text-align:start>除上述問題之外，首先，一些基於3D CNN的方法需要消耗大量內存，所以無法處理高分辨率的圖像；雖然基於RNN的方法試圖解決佔內存大的問題，但是犧牲了準確性。其次，大部分的基於神經網絡的方法都採用了非常大的降採樣模塊來完成特徵的提取，除了佔內存外，信息也在降採樣的過程中丟失了。最後，這些基於深度學習的多視角立體幾何方法都需要將每一張作為參考圖像計算出來的深度圖進行融合，在融合的時候採用固定的啟發式策略和參數，會過濾掉很多高精度的點雲。</p><p style=text-align:start>為了解決上述問題，我們提出<strong>採用動態一致性檢測的密集混合式多視角立體幾何網絡</strong>，該算法包括了一個新的神經網絡結構，和一個動態的後處理融合深度圖的方法。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/89e01ff8a4254d51a1d408ac78954524><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>二、算法細節</strong></h1><h1 class=pgc-h-arrow-right><strong>1、PVA-MVSNet</strong></h1><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2d3b82251d6a480992bfb074b1ed7c4c><p class=pgc-img-caption></p></div><ul><li><strong>自適應視角聚合</strong></li></ul><p style=text-align:start>為了處理任意N視圖圖像輸入以及不同圖像之間的差異來源，我們提出自適應視角度聚合，一種是<strong>像素級視角聚合</strong>(pixel-wise view aggregation)，另一種是<strong>體素級視角聚合</strong>(voxel-wise view aggregation)。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9da7a018e95f4505bad066c55ce64e53><p class=pgc-img-caption></p></div><p style=text-align:start>像素級視角聚合引入在高度和寬度維度自選擇帶權重的注意力圖，在深度採樣假設的維度共享權重，經過規範化的3D代價卷如下：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/efa5cd304c134bb381809b1e1b783c4f><p class=pgc-img-caption></p></div><p style=text-align:start><br></p><p style=text-align:start>其中</p><p style=text-align:start>Wh,w表示2D帶權重注意力圖，</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9abc8b870bf94ed49ead6d6db18f8d75><p class=pgc-img-caption>表示元素級乘法操作</p></div><p style=text-align:start>為了產生2D帶權重注意力圖，我們設計了weightnet網絡來學習W h,w，其中weightnet由幾層卷積層和一個ResNet塊組成：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/d831aa4102f6463f8f291580a99e470f><p class=pgc-img-caption></p></div><p style=text-align:start>體素級視角聚合考慮每一個圖像像素不同的深度假設都被視為不同，所以3D代價卷中每一個體素都學習它自身的重要性。基於此，我們設計了一個weightnet-3d網絡直接學習3D代價卷的3D注意力圖，規範化的3D代價卷如下：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/10bed8c860c54c00a2113bbfbf3b54a8><p class=pgc-img-caption></p></div><p style=text-align:start>我們的自適應視圖聚合模塊可以增強多視圖立體幾何網絡，從而生成更多具有較高置信度精確的深度估計。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3796b326529c4cbfbdfa617aeff1e1d2><p class=pgc-img-caption></p></div><ul><li><strong>多度量金字塔深度圖聚合</strong></li></ul><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/feb176d83b6b4e8db561725edb28feb9><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/14fc972da0b54d7589ca50b445cba23e><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/5b87e74356464b889617b1cdf7b9612e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>2、D2HC-RMVSNet</strong></h1><ul><li><strong>密集感受野擴張子網DRENet</strong></li></ul><p style=text-align:start>在這個子網絡中，我們引入了<strong>不同的擴張卷積層來產生多個尺度的背景信息，並且保持了分辨率</strong>，使得我們能夠輸出輸入圖像分辨率大小的深度圖。DRENet的網絡細節如下表所示。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/1ee229da8e194236a4f5192b77a36909><p class=pgc-img-caption></p></div><p style=text-align:start>Conv和Deconv表示2D卷積和2D反捲積。GR是組歸一化(Group Normalization)和ReLU的簡稱. MaxPooling表示了2維最大化池化層。ConvLSTMCell表示了有著2維卷積的LSTM循環神經元。N，H，W，D是輸入的多視角圖像的個數，圖像的長、寬，和深度假設的個數。</p><ul><li><strong>混合循環正則化HRU-LSTM</strong></li></ul><p style=text-align:start>之前的方法中有兩種不同的方法來正則代價卷，從而得到描述深度圖的概率圖。一種是<strong>MVSNet用的3DCNN U-Net</strong>，它利用了局部信息和多尺度背景信息，但是卻不能直接用於迴歸和輸入圖像大小一樣的深度圖，因為這種結構非常佔內存。另一種，是<strong>R-MVSNet用的堆疊起來的卷積RGU</strong>，它通過沿著深度方向依次處理3D代價捲來提升效率，但是卻沒有融合多尺度的背景信息。</p><p style=text-align:start>因此，我們吸收了這兩種方法的優點，提出了一種混合式的循環正則網絡結構，這種結構包含了比GRU更加有力的循環卷積神經元，我們稱之為<strong>LSTMConvCell</strong>。我們把LSTMConvCell作為每一層從而構建了一種新的2D U-Net結構，從而既考慮了多尺度背景信息，又能依次處理三維代價卷，從而減少內存消耗。這種結構相比於R-MVSnet直接減少了19.4%的內存消耗。細節結構見上表。LSTMConvCell用三個門map來控制信息流，並且可以集成不同尺度的背景信息。</p><ul><li><strong>動態一致性檢驗</strong></li></ul><p style=text-align:start>我們提出了動態的幾何一致性檢測策略，<strong>用一種整體的一致性度量替換之前方法所提固定視角閾值的方法，從而儘可能地保留那些更為準確的深度值</strong>，進而提高最終生成點雲的精度與召回率。對於參考圖像上的某個深度值而言，我們將其反投影到三維空間並投影到其相鄰的圖片上，再重複這一過程將其相鄰圖片上的對應像素重投影回原圖像，並計算出相應的重投影像素誤差與深度誤差：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6ba4d9bb4eeb4f3db61b19abf888b6e2><p class=pgc-img-caption></p></div><p style=text-align:start>為了定量地衡量這些誤差值的影響，我們將這兩個誤差整合為一個整體的一致性度量為：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ace75dbad9ac405a855dd3b899db40b0><p class=pgc-img-caption></p></div><p style=text-align:start>最後根據在每個相鄰視角的結果計算出全局幾何一致性度量之和衡量深度值的可靠性：</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/2c213bec78124ec6987c9bd2622bfb74><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>三、實驗結果</strong></h1><p style=text-align:start>我們均在DTU數據集上訓練PVA-MVSNet和D2HC-RMVSNet，並直接在Tanks andTemples或者BlendedMVS上進行測試。</p><h1 class=pgc-h-arrow-right><strong>1、PVA-MVSNet</strong></h1><ul><li><strong>DTU 測試集</strong></li></ul><p style=text-align:start>我們的VA-MVSNet和PVA-MVSNet（具有體素視圖聚合）的性能在完整性和整體質量方面相比其他方法都有顯著改善，並且能夠生成更加準確、連續和完整的深度圖。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/134becb2232347e385ff3a810e6a095b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/3b11b1811a524a4cafa7de8495f3c828><p class=pgc-img-caption></p></div><ul><li><strong>Tanks and Temples</strong></li></ul><p style=text-align:start>我們的算法在該榜單上也取得與P-MVSNet相當的結果，表明本文提出的算法具有較強的通用性。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e816c942db044455978e21998cc4fb8b><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/cb791e4e095d44379092aba5f1048947><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>2、D2HC-RMVSNet</strong></h1><ul><li><strong>DTU 測試集：</strong></li></ul><p style=text-align:start>D2HC-RMVSNet能夠提升其來源方法MVSNet和R-MVSNet對重建物體的準確性和完整度，從而能夠重建更加完整和準確的點雲。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/992670c4706846f2964a80a4c36ae15a><p class=pgc-img-caption></p></div><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/3c4445d21d2043b4ad59ace4aa5d32af><p class=pgc-img-caption></p></div><ul><li><strong>Tanks and Temples</strong></li></ul><p style=text-align:start>D2HC-RMVSNet在該榜單上排名第一，重建更加稠密和準確的點雲。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/af87a16095e2430096039394a6017b6c><p class=pgc-img-caption></p></div><ul><li><strong>BlendedMVS</strong></li></ul><p style=text-align:start>BlendedMVS是一個新的大規模MVS數據集，它是根據Altizure的3D重建模型合成的。我們的方法D2HC-RMVSNet可以很好地重建大型場景和小型汽車，而R-MVSNet卻失敗了。</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/497394c8f39c4edf8ae203fcfa061f2e><p class=pgc-img-caption></p></div><h1 class=pgc-h-arrow-right><strong>四、未來工作</strong></h1><p style=text-align:start>未來我們會考慮將法相或者平面先驗加入到多視圖立體幾何網絡中，並探索多視圖立體幾何在具有更多無紋理區域以及更多平面的室內場景中的應用。</p><h1 class=pgc-h-arrow-right><strong>作者介紹</strong></h1><p style=text-align:start><strong>易鴻偉 | 北京大學 碩士</strong></p><p style=text-align:start>易鴻偉，將於今年九月加入MPI-PS實驗室師從Michael J. Black教授攻讀博士學位，本科畢業於北京郵電大學，碩士畢業於北京大學。目前研究方向涉及人臉重建和多視圖立體幾何，即通過拍攝單張圖片重建人臉模型和通過多張環拍圖片重建稠密場景點雲。</p><h1 class=pgc-h-arrow-right><strong>ECCV 2020獨家攻略</strong></h1><p style=text-align:start><strong>//1</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6859166022080037389/?group_id=6859166022080037389" rel="noopener noreferrer" target=_blank>活動報名 | 「將門ECCV 2020鮮聲奪人云際會」踏浪而來</a></p><p style=text-align:start><strong>// 2</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6852505428085965324/?group_id=6852505428085965324" rel="noopener noreferrer" target=_blank>ECCV 2020 | 雲端參會攻略之Oral篇，前排佔位、強勢圍觀</a></p><p style=text-align:start><strong>// 3</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6853974407581270536/?group_id=6853974407581270536" rel="noopener noreferrer" target=_blank>ECCV 2020 | 精彩教程大揭祕，雲端參會也easy</a></p><p style=text-align:start><strong>// 4</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6857341929441460747/?group_id=6857341929441460747" rel="noopener noreferrer" target=_blank>ECCV 2020|Workshop第一彈：視覺研討會，最新研究成果一網打盡</a></p><h1 class=pgc-h-arrow-right>ECCV 2020論文精選</h1><p style=text-align:start><strong>// 1</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6855119185048142350/?group_id=6855119185048142350" rel="noopener noreferrer" target=_blank>ECCV 2020 Oral|當AI遇見三維時裝:來看現今最大的三維服裝數據集</a></p><p style=text-align:start><strong>// 2</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6855482358905176579/?group_id=6855482358905176579" rel="noopener noreferrer" target=_blank>ECCV 2020 | GRNet: 用於稠密點雲補全的網格化殘差網絡</a></p><p style=text-align:start><strong>// 3</strong> <a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6856932870309872142/?group_id=6856932870309872142" rel="noopener noreferrer" target=_blank>ECCV 2020 | 中科大&微軟提出挑圖神器：GIQA，一鍵挑出高質量圖像</a></p><p style=text-align:start><strong>// 4 </strong><a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6857685969777197581/?group_id=6857685969777197581" rel="noopener noreferrer" target=_blank>ECCV 2020 | 基於對抗路徑採樣的反事實視覺語言導航</a></p><p style=text-align:start><br></p><p style=text-align:start>最後，別忘了</p><p style=text-align:start><strong>將門「ECCV 2020鮮聲奪人云際會」</strong>火熱報名中~</p><p style=text-align:start>掃描下方二維碼</p><p style=text-align:start>或複製 http://thejiangmen2222.mikecrm.com/OUKtdGm至瀏覽器，</p><p style=text-align:start>馬上報名，搶佔席位！</p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7e8d0a62b6064f8ea38ad3d7932ccb04><p class=pgc-img-caption>快來報名吧~</p></div><h1 class=pgc-h-arrow-right>關於我“門”</h1><p style=text-align:start><strong>將門</strong>是一家以專注於<strong>發掘、加速及投資技術驅動型創業公司</strong>的新型<strong>創投機構</strong>，旗下涵蓋將門創新服務、將門技術社群以及將門創投基金。將門成立於2015年底，創始團隊由微軟創投在中國的創始團隊原班人馬構建而成，曾為微軟優選和深度孵化了126家創新的技術型創業公司。</p><p style=text-align:start><strong>將門創新服務</strong>專注於使創新的技術落地於真正的應用場景，激活和實現全新的商業價值，服務於行業領先企業和技術創新型創業公司。</p><p style=text-align:start><strong>將門技術社群</strong>專注於幫助技術創新型的創業公司提供來自產、學、研、創領域的核心技術專家的技術分享和學習內容，使創新成為持續的核心競爭力。</p><p style=text-align:start><strong>將門創投基金</strong>專注於投資通過技術創新激活商業場景，實現商業價值的初創企業，關注技術領域包括機器智能、物聯網、自然人機交互、企業計算。在近四年的時間裡，將門創投基金已經投資了包括量化派、碼隆科技、禾賽科技、寬拓科技、杉數科技、迪英加科技等數十傢俱有高成長潛力的技術型創業公司。</p><p style=text-align:start>如果您是技術領域的初創企業，不僅想獲得投資，還希望獲得一系列持續性、有價值的投後服務，歡迎發送或者推薦項目給我“門”: bp@thejiangmen.com</p><p style=text-align:start><br></p><div class=pgc-img><img alt="ECCV 2020|多視角圖像的差別和多尺度信息如何利用？兩篇論文解答" onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/88a48157d21744e8978e1ce71ad0cef4><p class=pgc-img-caption></p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ECCV</a></li><li><a>2020</a></li><li><a>多視</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E5%AD%B8/ec6c155.html alt="ECCV 2020附代碼論文合集(目標檢測）" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/31e617a451a4464484945f89ca231e68 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/ec6c155.html title="ECCV 2020附代碼論文合集(目標檢測）">ECCV 2020附代碼論文合集(目標檢測）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html alt="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9d1db0f2d2884c99b22fed2f8726ff26 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e4c213e9.html title="2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈">2020款勞斯萊斯庫裡南Black Badge版進店實拍 22英寸鑄造合金輪圈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html alt=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6090cec007b4477094c4dee77aa55cab style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2e5827c2.html title=2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》>2020變成“姐姐年”？有一檔新綜藝曝光，名為《不愧是姐姐》</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html alt=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/147a09b4453942c4b8f8f277957352b2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ae2d9a0e.html title=2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係>2020年河北省中考物理電學重點實驗-1——探究電流與電阻關係</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html alt=2020最新網頁設計，入門到精通教程+網頁素材，小白速領 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/b1791402c6954e31bde2d2e6686776ce style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/7d6c5722.html title=2020最新網頁設計，入門到精通教程+網頁素材，小白速領>2020最新網頁設計，入門到精通教程+網頁素材，小白速領</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html alt=2020年二級建築答案（部分僅供參考） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee5b14e3.html title=2020年二級建築答案（部分僅供參考）>2020年二級建築答案（部分僅供參考）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html alt="2020 一起感受前沿科學的魅力" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RoKukVcIMipJlM style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/495611a3.html title="2020 一起感受前沿科學的魅力">2020 一起感受前沿科學的魅力</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html alt=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3e29dad6969c439eb635b60d7b56ece8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0437348b.html title=2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念>2020武警/公安部隊院校考試化學--第1課物質分類之元素的基本概念</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html alt="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/e4d506eba5ab436ea0c06314cea9156a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a233d930.html title="一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實">一切以人民利益為中心 ——景德鎮2020年防汛抗洪搶險救災紀實</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html alt=2020年一級建造師每日一練習題及答案解析 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/57a9c8b4.html title=2020年一級建造師每日一練習題及答案解析>2020年一級建造師每日一練習題及答案解析</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html alt=2020焊工（中級）考試題及焊工（中級）複審模擬考試 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1e535667de7d4f2bb53fcc15449cf2cd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3c1e2d0.html title=2020焊工（中級）考試題及焊工（中級）複審模擬考試>2020焊工（中級）考試題及焊工（中級）複審模擬考試</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html alt=2020年建築焊工(建築特殊工種)證模擬考試題庫 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/da22da92ae304596ad940f56f54806eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/04fbee94.html title=2020年建築焊工(建築特殊工種)證模擬考試題庫>2020年建築焊工(建築特殊工種)證模擬考試題庫</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/df2816c1.html alt=2020年上半年國內丙烯供需平衡分析及三季度供需展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/df2816c1.html title=2020年上半年國內丙烯供需平衡分析及三季度供需展望>2020年上半年國內丙烯供需平衡分析及三季度供需展望</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0a47d7ff.html alt=「丙烯」2020年丙烯新產能投放進展 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6fb3fed02f5247a7af4ddaac5ef5595f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0a47d7ff.html title=「丙烯」2020年丙烯新產能投放進展>「丙烯」2020年丙烯新產能投放進展</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce532b9d.html alt=「丙烯」2020年中盤點與展望 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1b09f15c6a994a13a46b33cc10b2dce4 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce532b9d.html title=「丙烯」2020年中盤點與展望>「丙烯」2020年中盤點與展望</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>