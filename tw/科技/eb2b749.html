<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>機器不學習：FastText入門與實戰 | 极客快訊</title><meta property="og:title" content="機器不學習：FastText入門與實戰 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/153344935537075eee4d9a3"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/eb2b749.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/eb2b749.html><meta property="article:published_time" content="2020-10-29T21:07:51+08:00"><meta property="article:modified_time" content="2020-10-29T21:07:51+08:00"><meta name=Keywords content><meta name=description content="機器不學習：FastText入門與實戰"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/eb2b749.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>機器不學習：FastText入門與實戰</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><h1><strong>機器不學習 www.jqbxx.com : 深度聚合機器學習、深度學習算法及技術實戰</strong></h1><div class=pgc-img><img alt=機器不學習：FastText入門與實戰 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153344935537075eee4d9a3><p class=pgc-img-caption></p></div><p>本文主要介紹FastText的來龍去脈和原理分析，大概目錄如下：</p><ul><li>一、簡介</li><li>二、FastText原理</li><li>2.1 模型架構</li><li>2.2 層次SoftMax</li><li>2.3 N-gram特徵</li><li>三、 基於fastText實現文本分類</li><li>3.1 fastText有監督學習分類</li><li>3.2 fastText有監督學習分類</li><li>三、總結</li><li>3.1 fastText和word2vec的區別</li><li>3.2 小結</li></ul><h1><strong>一、簡介</strong></h1><p>fasttext是facebook開源的一個詞向量與文本分類工具，在2016年開源，典型應用場景是“帶監督的文本分類問題”。提供簡單而高效的文本分類和表徵學習的方法，性能比肩深度學習而且速度更快。</p><p>fastText結合了自然語言處理和機器學習中最成功的理念。這些包括了使用詞袋以及n-gram袋錶徵語句，還有使用子字(subword)信息，並通過隱藏表徵在類別間共享信息。我們另外採用了一個softmax層級(利用了類別不均衡分佈的優勢)來加速運算過程。</p><p>這些不同概念被用於兩個不同任務：</p><ul><li><strong>有效文本分類</strong> ：有監督學習</li><li><strong>學習詞向量表徵</strong>：無監督學習</li></ul><p>舉例來說：fastText能夠學會“男孩”、“女孩”、“男人”、“女人”指代的是特定的性別，並且能夠將這些數值存在相關文檔中。然後，當某個程序在提出一個用戶請求（假設是“我女友現在在兒？”），它能夠馬上在fastText生成的文檔中進行查找並且理解用戶想要問的是有關女性的問題。</p><h1><strong>二、FastText原理</strong></h1><p>fastText方法包含三部分，<strong>模型架構，層次SoftMax和N-gram特徵。</strong></p><p><strong>2.1 模型架構</strong></p><p>fastText的架構和word2vec中的CBOW的架構類似，因為它們的作者都是Facebook的科學家Tomas Mikolov，而且確實fastText也算是words2vec所衍生出來的。</p><p>Continuous Bog-Of-Words：</p><div class=pgc-img><img alt=機器不學習：FastText入門與實戰 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/153344953341462c4cdd065><p class=pgc-img-caption></p></div><p><strong>fastText</strong></p><div class=pgc-img><img alt=機器不學習：FastText入門與實戰 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/15334495564343533e51ef8><p class=pgc-img-caption></p></div><p>fastText 模型輸入一個詞的序列（一段文本或者一句話)，輸出這個詞序列屬於不同類別的概率。</p><p>序列中的詞和詞組組成特徵向量，特徵向量通過線性變換映射到中間層，中間層再映射到標籤。</p><p>fastText 在預測標籤時使用了非線性激活函數，但在中間層不使用非線性激活函數。fastText 模型架構和 Word2Vec 中的 CBOW 模型很類似。不同之處在於，fastText 預測標籤，而 CBOW 模型預測中間詞。</p><p><strong>2.2 層次SoftMax</strong></p><p>對於有大量類別的數據集，fastText使用了一個分層分類器（而非扁平式架構）。不同的類別被整合進樹形結構中（想象下二叉樹而非 list）。在某些文本分類任務中類別很多，計算線性分類器的複雜度高。為了改善運行時間，fastText 模型使用了層次 Softmax 技巧。層次 Softmax 技巧建立在哈弗曼編碼的基礎上，對標籤進行編碼，能夠極大地縮小模型預測目標的數量。</p><p>fastText 也利用了類別（class）不均衡這個事實（一些類別出現次數比其他的更多），通過使用 Huffman 算法建立用於表徵類別的樹形結構。因此，頻繁出現類別的樹形結構的深度要比不頻繁出現類別的樹形結構的深度要小，這也使得進一步的計算效率更高。</p><div class=pgc-img><img alt=機器不學習：FastText入門與實戰 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/15334496003899cec119d1f><p class=pgc-img-caption></p></div><p><strong>2.3 N-gram特徵</strong></p><p>fastText 可以用於文本分類和句子分類。不管是文本分類還是句子分類，我們常用的特徵是詞袋模型。但詞袋模型不能考慮詞之間的順序，因此 fastText 還加入了 N-gram 特徵。“我 愛 她” 這句話中的詞袋模型特徵是 “我”，“愛”, “她”。這些特徵和句子 “她 愛 我” 的特徵是一樣的。如果加入 2-Ngram，第一句話的特徵還有 “我-愛” 和 “愛-她”，這兩句話 “我 愛 她” 和 “她 愛 我” 就能區別開來了。當然啦，為了提高效率，我們需要過濾掉低頻的 N-gram。</p><h1><strong>三、 基於fastText實現文本分類</strong></h1><p><strong>3.1 fastText有監督學習分類</strong></p><p>fastText做文本分類要求文本是如下的存儲形式：</p><p>__label__2 , birchas chaim , yeshiva birchas chaim is a orthodox jewish mesivta high school in lakewood township new jersey . it was founded by rabbi shmuel zalmen stein in 2001 after his father rabbi chaim stein asked him to open a branch of telshe yeshiva in lakewood . as of the 2009-10 school year the school had an enrollment of 76 students and 6 . 6 classroom teachers ( on a fte basis ) for a student–teacher ratio of 11 . 5 1 .</p><p>__label__6 , motor torpedo boat pt-41 , motor torpedo boat pt-41 was a pt-20-class motor torpedo boat of the united states navy built by the electric launch company of bayonne new jersey . the boat was laid down as motor boat submarine chaser ptc-21 but was reclassified as pt-41 prior to its launch on 8 july 1941 and was completed on 23 july 1941 .</p><p>__label__11 , passiflora picturata , passiflora picturata is a species of passion flower in the passifloraceae family .</p><p>__label__13 , naya din nai raat , naya din nai raat is a 1974 bollywood drama film directed by a . bhimsingh . the film is famous as sanjeev kumar reprised the nine-role epic performance by sivaji ganesan in navarathri ( 1964 ) which was also previously reprised by akkineni nageswara rao in navarathri ( telugu 1966 ) . this film had enhanced his status and reputation as an actor in hindi cinema .</p><p>其中前面的<strong>label</strong>是前綴，也可以自己定義，<strong>label</strong>後接的為類別。</p><p>具體代碼：</p><p># -*- coding:utf-8 -*-</p><p>import pandas as pd</p><p>import random</p><p>import fasttext</p><p>import jieba</p><p>from sklearn.model_selection import train_test_split</p><p>cate_dic = {'technology': 1, 'car': 2, 'entertainment': 3, 'military': 4, 'sports': 5}</p><p>"""</p><p>函數說明：加載數據</p><p>"""</p><p>def loadData():</p><p>#利用pandas把數據讀進來</p><p>df_technology = pd.read_csv("./data/technology_news.csv",encoding ="utf-8")</p><p>df_technology=df_technology.dropna() #去空行處理</p><p>df_car = pd.read_csv("./data/car_news.csv",encoding ="utf-8")</p><p>df_car=df_car.dropna()</p><p>df_entertainment = pd.read_csv("./data/entertainment_news.csv",encoding ="utf-8")</p><p>df_entertainment=df_entertainment.dropna()</p><p>df_military = pd.read_csv("./data/military_news.csv",encoding ="utf-8")</p><p>df_military=df_military.dropna()</p><p>df_sports = pd.read_csv("./data/sports_news.csv",encoding ="utf-8")</p><p>df_sports=df_sports.dropna()</p><p>technology=df_technology.content.values.tolist()[1000:21000]</p><p>car=df_car.content.values.tolist()[1000:21000]</p><p>entertainment=df_entertainment.content.values.tolist()[:20000]</p><p>military=df_military.content.values.tolist()[:20000]</p><p>sports=df_sports.content.values.tolist()[:20000]</p><p>return technology,car,entertainment,military,sports</p><p>"""</p><p>函數說明：停用詞</p><p>參數說明：</p><p>datapath：停用詞路徑</p><p>返回值：</p><p>stopwords:停用詞</p><p>"""</p><p>def getStopWords(datapath):</p><p>stopwords=pd.read_csv(datapath,index_col=False,quoting=3,sep="\t",names=['stopword'], encoding='utf-8')</p><p>stopwords=stopwords["stopword"].values</p><p>return stopwords</p><p>"""</p><p>函數說明：去停用詞</p><p>參數：</p><p>content_line：文本數據</p><p>sentences：存儲的數據</p><p>category：文本類別</p><p>"""</p><p>def preprocess_text(content_line,sentences,category,stopwords):</p><p>for line in content_line:</p><p>try:</p><p>segs=jieba.lcut(line) #利用結巴分詞進行中文分詞</p><p>segs=filter(lambda x:len(x)>1,segs) #去掉長度小於1的詞</p><p>segs=filter(lambda x:x not in stopwords,segs) #去掉停用詞</p><p>sentences.append("__lable__"+str(category)+" , "+" ".join(segs)) #把當前的文本和對應的類別拼接起來，組合成fasttext的文本格式</p><p>except Exception as e:</p><p>print (line)</p><p>continue</p><p>"""</p><p>函數說明：把處理好的寫入到文件中，備用</p><p>參數說明：</p><p>"""</p><p>def writeData(sentences,fileName):</p><p>print("writing data to fasttext format...")</p><p>out=open(fileName,'w')</p><p>for sentence in sentences:</p><p>out.write(sentence.encode('utf8')+"\n")</p><p>print("done!")</p><p>"""</p><p>函數說明：數據處理</p><p>"""</p><p>def preprocessData(stopwords,saveDataFile):</p><p>technology,car,entertainment,military,sports=loadData()</p><p>#去停用詞，生成數據集</p><p>sentences=[]</p><p>preprocess_text(technology,sentences,cate_dic["technology"],stopwords)</p><p>preprocess_text(car,sentences,cate_dic["car"],stopwords)</p><p>preprocess_text(entertainment,sentences,cate_dic["entertainment"],stopwords)</p><p>preprocess_text(military,sentences,cate_dic["military"],stopwords)</p><p>preprocess_text(sports,sentences,cate_dic["sports"],stopwords)</p><p>random.shuffle(sentences) #做亂序處理，使得同類別的樣本不至於扎堆</p><p>writeData(sentences,saveDataFile)</p><p>if __name__=="__main__":</p><p>stopwordsFile=r"./data/stopwords.txt"</p><p>stopwords=getStopWords(stopwordsFile)</p><p>saveDataFile=r'train_data.txt'</p><p>preprocessData(stopwords,saveDataFile)</p><p>#fasttext.supervised():有監督的學習</p><p>classifier=fasttext.supervised(saveDataFile,'classifier.model',lable_prefix='__lable__')</p><p>result = classifier.test(saveDataFile)</p><p>print("P@1:",result.precision) #準確率</p><p>print("R@2:",result.recall) #召回率</p><p>print("Number of examples:",result.nexamples) #預測錯的例子</p><p>#實際預測</p><p>lable_to_cate={1:'technology'.1:'car',3:'entertainment',4:'military',5:'sports'}</p><p>texts=['中新網 日電 2018 預賽 亞洲區 強賽 中國隊 韓國隊 較量 比賽 上半場 分鐘 主場 作戰 中國隊 率先 打破 場上 僵局 利用 角球 機會 大寶 前點 攻門 得手 中國隊 領先']</p><p>lables=classifier.predict(texts)</p><p>print(lables)</p><p>print(lable_to_cate[int(lables[0][0])])</p><p>#還可以得到類別+概率</p><p>lables=classifier.predict_proba(texts)</p><p>print(lables)</p><p>#還可以得到前k個類別</p><p>lables=classifier.predict(texts，k=3)</p><p>print(lables)</p><p>#還可以得到前k個類別+概率</p><p>lables=classifier.predict_proba(texts，k=3)</p><p>print(lables)</p><p><strong>3.2 fastText有監督學習分類</strong></p><p># -*- coding:utf-8 -*-</p><p>import pandas as pd</p><p>import random</p><p>import fasttext</p><p>import jieba</p><p>from sklearn.model_selection import train_test_split</p><p>cate_dic = {'technology': 1, 'car': 2, 'entertainment': 3, 'military': 4, 'sports': 5}</p><p>"""</p><p>函數說明：加載數據</p><p>"""</p><p>def loadData():</p><p>#利用pandas把數據讀進來</p><p>df_technology = pd.read_csv("./data/technology_news.csv",encoding ="utf-8")</p><p>df_technology=df_technology.dropna() #去空行處理</p><p>df_car = pd.read_csv("./data/car_news.csv",encoding ="utf-8")</p><p>df_car=df_car.dropna()</p><p>df_entertainment = pd.read_csv("./data/entertainment_news.csv",encoding ="utf-8")</p><p>df_entertainment=df_entertainment.dropna()</p><p>df_military = pd.read_csv("./data/military_news.csv",encoding ="utf-8")</p><p>df_military=df_military.dropna()</p><p>df_sports = pd.read_csv("./data/sports_news.csv",encoding ="utf-8")</p><p>df_sports=df_sports.dropna()</p><p>technology=df_technology.content.values.tolist()[1000:21000]</p><p>car=df_car.content.values.tolist()[1000:21000]</p><p>entertainment=df_entertainment.content.values.tolist()[:20000]</p><p>military=df_military.content.values.tolist()[:20000]</p><p>sports=df_sports.content.values.tolist()[:20000]</p><p>return technology,car,entertainment,military,sports</p><p>"""</p><p>函數說明：停用詞</p><p>參數說明：</p><p>datapath：停用詞路徑</p><p>返回值：</p><p>stopwords:停用詞</p><p>"""</p><p>def getStopWords(datapath):</p><p>stopwords=pd.read_csv(datapath,index_col=False,quoting=3,sep="\t",names=['stopword'], encoding='utf-8')</p><p>stopwords=stopwords["stopword"].values</p><p>return stopwords</p><p>"""</p><p>函數說明：去停用詞</p><p>參數：</p><p>content_line：文本數據</p><p>sentences：存儲的數據</p><p>category：文本類別</p><p>"""</p><p>def preprocess_text(content_line,sentences,stopwords):</p><p>for line in content_line:</p><p>try:</p><p>segs=jieba.lcut(line) #利用結巴分詞進行中文分詞</p><p>segs=filter(lambda x:len(x)>1,segs) #去掉長度小於1的詞</p><p>segs=filter(lambda x:x not in stopwords,segs) #去掉停用詞</p><p>sentences.append(" ".join(segs))</p><p>except Exception as e:</p><p>print (line)</p><p>continue</p><p>"""</p><p>函數說明：把處理好的寫入到文件中，備用</p><p>參數說明：</p><p>"""</p><p>def writeData(sentences,fileName):</p><p>print("writing data to fasttext format...")</p><p>out=open(fileName,'w')</p><p>for sentence in sentences:</p><p>out.write(sentence.encode('utf8')+"\n")</p><p>print("done!")</p><p>"""</p><p>函數說明：數據處理</p><p>"""</p><p>def preprocessData(stopwords,saveDataFile):</p><p>technology,car,entertainment,military,sports=loadData()</p><p>#去停用詞，生成數據集</p><p>sentences=[]</p><p>preprocess_text(technology,sentences,stopwords)</p><p>preprocess_text(car,sentences,stopwords)</p><p>preprocess_text(entertainment,sentences,stopwords)</p><p>preprocess_text(military,sentences,stopwords)</p><p>preprocess_text(sports,sentences,stopwords)</p><p>random.shuffle(sentences) #做亂序處理，使得同類別的樣本不至於扎堆</p><p>writeData(sentences,saveDataFile)</p><p>if __name__=="__main__":</p><p>stopwordsFile=r"./data/stopwords.txt"</p><p>stopwords=getStopWords(stopwordsFile)</p><p>saveDataFile=r'unsupervised_train_data.txt'</p><p>preprocessData(stopwords,saveDataFile)</p><p>#fasttext.load_model:不管是有監督還是無監督的，都是載入一個模型</p><p>#fasttext.skipgram(),fasttext.cbow()都是無監督的，用來訓練詞向量的</p><p>model=fasttext.skipgram('unsupervised_train_data.txt','model')</p><p>print(model.words) #打印詞向量</p><p>#cbow model</p><p>model=fasttext.cbow('unsupervised_train_data.txt','model')</p><p>print(model.words) #打印詞向量</p><h1><strong>三、總結</strong></h1><p><strong>3.1 fastText和word2vec的區別</strong></p><p>相似處：</p><ol><li>圖模型結構很像，都是採用embedding向量的形式，得到word的隱向量表達。</li><li>都採用很多相似的優化方法，比如使用Hierarchical softmax優化訓練和預測中的打分速度。</li></ol><p>不同處：</p><ol><li>模型的輸出層：word2vec的輸出層，對應的是每一個term，計算某term的概率最大；而fasttext的輸出層對應的是 分類的label。不過不管輸出層對應的是什麼內容，起對應的vector都不會被保留和使用；</li><li>模型的輸入層：word2vec的輸出層，是 context window 內的term；而fasttext 對應的整個sentence的內容，包括term，也包括 n-gram的內容；</li></ol><p>兩者本質的不同，體現在 h-softmax的使用：</p><ul><li>Wordvec的目的是得到詞向量，該詞向量 最終是在輸入層得到，輸出層對應的 h-softmax</li><li>也會生成一系列的向量，但最終都被拋棄，不會使用。</li><li>fasttext則充分利用了h-softmax的分類功能，遍歷分類樹的所有葉節點，找到概率最大的label（一個或者N個）</li></ul><p><strong>3.2 小結</strong></p><p>總的來說，fastText的學習速度比較快，效果還不錯。fastText適用與分類類別非常大而且數據集足夠多的情況，當分類類別比較小或者數據集比較少的話，很容易過擬合。</p><p>可以完成無監督的詞向量的學習，可以學習出來詞向量，來保持住詞和詞之間，相關詞之間是一個距離比較近的情況；</p><p>也可以用於有監督學習的文本分類任務，（新聞文本分類，垃圾郵件分類、情感分析中文本情感分析，電商中用戶評論的褒貶分析）</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>機器</a></li><li><a>不學習</a></li><li><a>FastText</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html alt="機器不學習：NLP系列3 自然語言理解-意圖分類" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1534769000731dd06801b0b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/77565851.html title="機器不學習：NLP系列3 自然語言理解-意圖分類">機器不學習：NLP系列3 自然語言理解-意圖分類</a></li><hr><li><a href=../../tw/%E9%81%8A%E6%88%B2/28f56587.html alt=機器不學習：基於知識圖譜推理的關係推演 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15348478783789794734e6f style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/28f56587.html title=機器不學習：基於知識圖譜推理的關係推演>機器不學習：基於知識圖譜推理的關係推演</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/316bfb0b.html alt="機器不學習：深度學習訓練淫技2 L1正則化和L2正則化" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1535372399398ea02c0c526 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/316bfb0b.html title="機器不學習：深度學習訓練淫技2 L1正則化和L2正則化">機器不學習：深度學習訓練淫技2 L1正則化和L2正則化</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0631b3a.html alt=機器不學習：自然語言處理（NLP）知識結構總結 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0631b3a.html title=機器不學習：自然語言處理（NLP）知識結構總結>機器不學習：自然語言處理（NLP）知識結構總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html alt=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1530929302432561dc6cda6 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfb83fa2.html title=機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價>機器視覺｜晏磊：航空遙感平臺通用物理模型及可變基高比系統精度評價</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html alt=「火爐煉AI」機器學習048-Harris檢測圖像角點 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d756b20a1dbc4ab4b4f22d6b61be2043 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/098d4a35.html title=「火爐煉AI」機器學習048-Harris檢測圖像角點>「火爐煉AI」機器學習048-Harris檢測圖像角點</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html alt=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/13adbab9c7f94c7fa81d49a98861b051 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dc2af9c9.html title=機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式>機器學習筆記(七)——初識邏輯迴歸、不同方法推導梯度公式</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html alt=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1540372101455de0fb74774 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e214e6d7.html title=深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開>深度學習/機器學習入門數學知識整理（二）梯度與導數，泰勒展開</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html alt=講透機器學習中的梯度下降 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/5c80301e53424671bc22755be2e4ee33 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f3767255.html title=講透機器學習中的梯度下降>講透機器學習中的梯度下降</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bc93016e.html alt=人工智能時代，機器人真的能在對話中識別人的意圖嘛？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7804be8632614272aab014f77d8f40a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bc93016e.html title=人工智能時代，機器人真的能在對話中識別人的意圖嘛？>人工智能時代，機器人真的能在對話中識別人的意圖嘛？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html alt=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RfDgA10IBHJqK9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51723e35.html title=AI也有偏見：你在機器“眼裡”是好人還是壞蛋？>AI也有偏見：你在機器“眼裡”是好人還是壞蛋？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html alt=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/519b968bf69146fda9bf55f89779d373 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ee69f5ac.html title=基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質>基於機器視覺技術快速準確地確定收穫後幹大豆種子的品質</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html alt=如何減少焊接機器人出現焊接件變形的情況？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/3a62de9fde6c4a09ac0950d5f16dea0a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/dbe0144c.html title=如何減少焊接機器人出現焊接件變形的情況？>如何減少焊接機器人出現焊接件變形的情況？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html alt=機器學習時代的哈希算法，將如何更高效地索引數據 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525617261534ad07c6455c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce278cf4.html title=機器學習時代的哈希算法，將如何更高效地索引數據>機器學習時代的哈希算法，將如何更高效地索引數據</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html alt=淺談機器學習時代的哈希算法（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1525788510275af3193bcdc style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/346037ff.html title=淺談機器學習時代的哈希算法（一）>淺談機器學習時代的哈希算法（一）</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>