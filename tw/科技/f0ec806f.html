<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>用 Vision Transformer 進行圖像分類 | 极客快訊</title><meta property="og:title" content="用 Vision Transformer 進行圖像分類 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/9529b2f9517b48fdbc59f29c866a50c1"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f0ec806f.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f0ec806f.html><meta property="article:published_time" content="2020-11-14T21:04:07+08:00"><meta property="article:modified_time" content="2020-11-14T21:04:07+08:00"><meta name=Keywords content><meta name=description content="用 Vision Transformer 進行圖像分類"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/f0ec806f.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>用 Vision Transformer 進行圖像分類</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><blockquote class=pgc-blockquote-abstract><p style=text-align:start>Transformer 問世後被廣泛地用在 NLP 的各種任務中，但是卻很少出現在計算機視覺領域中。目前計算機視覺主流的模型依然是 CNN，各種 attention 操作也是在 CNN 結構上進行。本文介紹 Vision Transformer (ViT)，把圖片的區塊序列傳入 Transformer 進行預測。ViT 首先在大規模的圖片數據集上進行預訓練，然後再遷移到目標數據集上，得到的分類效果可以和當前最好的 CNN 模型相媲美，但是所需的計算資源大大減少。</p></blockquote><h1 class=pgc-h-arrow-right><strong>1.概述</strong></h1><p style=text-align:start>Transformer 是 2017 年提出的模型，主要基於 Self-Attention 結構，對 Transformer 不熟悉的童鞋可以參考一下之前的文章<a class=pgc-link data-content=mp data-source=innerLink href="https://www.toutiao.com/i6762351574296560136/?group_id=6762351574296560136" rel="noopener noreferrer" target=_blank>《Transformer 模型詳解》</a>。Transformer 具有較高的計算效率和很好的擴展性，可以支持訓練超過 100B 參數的模型。</p><p style=text-align:start>目前 Transformer 已成為 NLP 領域的主流，衍生出了 BERT、GPT 等模型，但是在計算機視覺領域，Transformer 的應用卻很少。本文介紹 Google 在 2020 年的一篇論文《An Image is Worth 16*16 Words: Transformers for Image Recognition at Scale》，論文中提出了 Vision Transformer (ViT)，能直接利用 Transformer 對圖像進行分類，而不需要卷積網絡。為了讓 ViT 模型可以處理圖片，首先要把圖片劃分為很多個區塊 (類似 NLP 中的 token)，然後把區塊序列傳入 ViT。</p><p style=text-align:start>論文地址：https://arxiv.org/pdf/2010.11929.pdf</p><p style=text-align:start>代碼地址：https://github.com/google-research/vision_transformer</p><p style=text-align:start>實驗發現，在中等大小的數據集 (如 ImageNet) 上訓練得到的 ViT 模型準確率比 SOTA 模型 ResNet (CNN 模型) 低了幾個百分點。論文作者認為這是因為 CNN 模型具有平移不變性和局部性等歸納偏好 (inductive biases)，而 Transformer 並沒有這種歸納偏好，因此在數據量不足的時候準確率不如 CNN 模型。但是如果在大規模的圖像數據集 (14M-300M 圖片) 上預訓練 ViT 再遷移到小規模數據，則 ViT 可以取得非常好的效果，甚至可以超過當前圖片識別的最好結果。</p><h1 class=pgc-h-arrow-right><strong>2.Vision Transformer</strong></h1><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/9529b2f9517b48fdbc59f29c866a50c1><p class=pgc-img-caption>ViT 模型結構圖</p></div><p><strong>2.1 ViT 模型</strong></p><p style=text-align:start>上圖是 ViT 的結構，傳統的 Transformer 輸入時一維的 token embedding 序列，為了處理二維的圖像，需要把圖像分為幾個區塊 (patch)。給定一個 H×W×C 的圖像以及區塊大小 P，可以把圖像劃分為 N 個 P×P×C 的區塊，N=H×W/(P×P)。得到區塊後要使用線性變換轉為 D 維特徵向量，再加上位置編碼向量即可。和 BERT 類似，ViT 在序列之前也加入了一個分類標誌位 [class]。ViT 輸入序列 <strong>z</strong> 如下面的公式所示，其中 <strong>x</strong> 表示一個圖像區塊。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/29d089ae1e084a2295d06aacb74bd254><p class=pgc-img-caption>輸入序列 z 計算公式</p></div><p style=text-align:start>ViT 模型和 Transformer 基本一樣，輸入序列傳入 ViT，然後利用 [class] 標誌位的最終輸出特徵進行分類。ViT 主要由 MSA (多頭自注意力) 和 MLP (兩層使用 GELU 激活函數的全連接網絡) 組成，在 MSA 和 MLP 之前加上 LayerNorm 和殘差連接。ViT 的公式如下：</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/776ae9ab1d104632bff6f077e11d8af9><p class=pgc-img-caption>ViT 公式</p></div><p><strong>2.2 ViT 和 CNN 混合結構</strong></p><p style=text-align:start>可以使用 CNN 輸出的 feature map 代替原始圖片的區塊序列，將 feature map 劃分為多個區塊，然後用線性映射矩陣 <strong>E</strong> 進行映射。甚至可以把 feature map 劃分為多個 1×1 的區塊，這相當於直接把 feature map 展開，然後再映射。</p><p><strong>2.3 微調和高分辨率</strong></p><p style=text-align:start>ViT 通常在大數據集上預訓練，然後再使用目標數據集微調。因為預訓練數據集和目標數據集類別個數不同，因此需要把最後一層預測層移除，換為初始值為 0 的 D×K 全連接層，K 是目標數據集的類別個數。</p><p style=text-align:start>在微調階段數據集分辨率比預訓練時高通常有比較好的效果。當微調時傳入高分辨率的圖片，需要保持區塊 (patch) 的大小不變，此時序列長度會變長，這會導致預訓練得到的 Position Embedding 失去意義。為了解決這個問題，作者採用了插值的方法，根據圖像的位置，在預訓練得到的 Position Embedding 中插值。插值過程如下圖所示。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/30f2862d335544e2b82589b94c2f5727><p class=pgc-img-caption>插值過程示意圖</p></div><h1 class=pgc-h-arrow-right>3.實驗效果</h1><p style=text-align:start>作者使用了三種規模的 ViT 模型，分別是 Base、Large、Huge，參數量如下表所示。用 ViT-L/16 表示 ViT Large 模型，圖片區塊 (patch) 大小時 16×16。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/e2cc0c38174d488092d7b9dfd0f934ef><p class=pgc-img-caption>三種規模的 ViT</p></div><p style=text-align:start>作者對比了 ViT 和 SOTA 模型 (ResNet) 的分類效果，結果如下表所示，表中 ViT-H/14 使用 JFT-300M 預訓練，ViT-L/16 使用 JFT-300M 和 ImageNet-21K 分別進行預訓練，ResNet 使用 JFT-300M 預訓練。可以看到用 JFT 預訓練的 ViT-L/16 在後續所有分類數據集上的性能都可以與 ResNet 媲美，有些甚至超越了 ResNet，並且 ViT-L 的計算效率遠遠高於 ResNet。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/89960519fd0944bb8ef1250a939f34ab><p class=pgc-img-caption>和 SOTA 模型比較實驗</p></div><p style=text-align:start>作者進行實驗測試預訓練數據量對 ViT 性能的影響，結果如下圖所示。使用了三種不同大小的數據集進行預訓練，數據集從小到大排列為 ImageNet、ImageNet-21k、JFT-300M。灰色的部分是不同規模的 BiT (ResNet) 模型所得到的性能區間。可以看到在預訓練數據集比較小的時候，BiT 比 ViT 更好，但是隨著預訓練數據集變大，ViT 模型會超過 BiT 模型。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/74168cfd5f7c4dd5961e71102233bf49><p class=pgc-img-caption>預訓練數據量對模型性能的影響</p></div><p style=text-align:start>作者還對比了預訓練計算量對遷移效果的影響，結果如下圖所示。Hybrid 指 ViT 和 ResNet 的混合模型。在算力和性能對比中發現 ViT 明顯優於 ResNet，可以用更少的算力得到媲美 ResNet 的性能。在算力較小時 Hybrid 模型優於 ViT，但是隨著算力增大，這一現象會消失。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7c264f2c92ca4a57a9292e379b4db9ba><p class=pgc-img-caption>預訓練計算量對遷移效果的影響</p></div><p style=text-align:start>查看 ViT 的 Attention，可以發現 ViT 能夠很好地關注與分類相關的區域，如下圖所示。</p><div class=pgc-img><img alt="用 Vision Transformer 進行圖像分類" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/7974f4f168be430c86341e6b56a5d620><p class=pgc-img-caption>ViT 模型的 Attention</p></div><h1 class=pgc-h-arrow-right>4.參考文獻</h1><p style=text-align:start>An Image is Worth 16*16 Words: Transformers for Image Recognition at Scale</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>Vision</a></li><li><a>Transformer</a></li><li><a>進行</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/72139afe.html alt=怎樣對臍橙樹進行扭枝（彎枝）促花？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/fe6ea8ad111f421c9673e3f61072fa1f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/72139afe.html title=怎樣對臍橙樹進行扭枝（彎枝）促花？>怎樣對臍橙樹進行扭枝（彎枝）促花？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e0c52137.html alt=作文裡面怎麼進行場面描寫？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/230976bf-ee1d-44c0-8ce9-4a4714b8ad40 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e0c52137.html title=作文裡面怎麼進行場面描寫？>作文裡面怎麼進行場面描寫？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cc683c38.html alt=怎樣進行場面描寫？中小學生高分作文技巧，作文快速提分 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7559326b0b254462970a98290ef15e9f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cc683c38.html title=怎樣進行場面描寫？中小學生高分作文技巧，作文快速提分>怎樣進行場面描寫？中小學生高分作文技巧，作文快速提分</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/862b0119.html alt=庭院景觀進行分類，分析其設計手法及景觀元素 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0b2a23998d02489a9f65c5ac190e0ab1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/862b0119.html title=庭院景觀進行分類，分析其設計手法及景觀元素>庭院景觀進行分類，分析其設計手法及景觀元素</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9aacad8d.html alt=四子王旗著陸場進行夜間返回器回收演練 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/SGCsDGZChiSE1J style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9aacad8d.html title=四子王旗著陸場進行夜間返回器回收演練>四子王旗著陸場進行夜間返回器回收演練</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d1051ab4.html alt=稅務機關是如何進行稅務檢查的？小白必看 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/5910228d-1631-4921-8a4e-08a892a227ca style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d1051ab4.html title=稅務機關是如何進行稅務檢查的？小白必看>稅務機關是如何進行稅務檢查的？小白必看</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/b24cd416.html alt="有勒索軟件冒充解密工具對用戶文件進行二次加密 真是壞透了" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/d2b5b02227754787880b9798bc0d8451 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/b24cd416.html title="有勒索軟件冒充解密工具對用戶文件進行二次加密 真是壞透了">有勒索軟件冒充解密工具對用戶文件進行二次加密 真是壞透了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1d30af34.html alt=脈動進行年輕化品牌升級，起用吳亦凡為品牌全球代言人 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/RxWrYnBCPI4mSB style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1d30af34.html title=脈動進行年輕化品牌升級，起用吳亦凡為品牌全球代言人>脈動進行年輕化品牌升級，起用吳亦凡為品牌全球代言人</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d160830e.html alt="基於 Oracle 的系統識別方法來進行 Control-CPS 軟件缺陷定位" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7f751bafd94a4c9a933109a7b3f275eb style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d160830e.html title="基於 Oracle 的系統識別方法來進行 Control-CPS 軟件缺陷定位">基於 Oracle 的系統識別方法來進行 Control-CPS 軟件缺陷定位</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/839128d9.html alt=如何利用MES系統進行生產防錯？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/1a9be6af1166482e9570cecda0f01f8c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/839128d9.html title=如何利用MES系統進行生產防錯？>如何利用MES系統進行生產防錯？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a3cbc9ea.html alt=進行百年的瀝青滴落實驗，如此大費干戈，究竟是為了證明什麼？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/9729abe48f9c47919432f44bf48e02e2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a3cbc9ea.html title=進行百年的瀝青滴落實驗，如此大費干戈，究竟是為了證明什麼？>進行百年的瀝青滴落實驗，如此大費干戈，究竟是為了證明什麼？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e9c9b225.html alt=9座市管隨路橋樑今起進行“體檢” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e9c9b225.html title=9座市管隨路橋樑今起進行“體檢”>9座市管隨路橋樑今起進行“體檢”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/2f8212b0.html alt=中交怒江連心橋進行荷載試驗 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c5de27c9149c45b29e1fb42cc5f16f9f style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/2f8212b0.html title=中交怒江連心橋進行荷載試驗>中交怒江連心橋進行荷載試驗</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/5465ffdc.html alt=利用等距通道進行價格行為交易的核心方法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/f7d9e5eb-8cdd-44e7-8ea2-a0b7057b8c45 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/5465ffdc.html title=利用等距通道進行價格行為交易的核心方法>利用等距通道進行價格行為交易的核心方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bafe1e0c.html alt=創想小知識：管道焊接需要進行的七個步驟 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9306fc55883d446e956d5918fa47082b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bafe1e0c.html title=創想小知識：管道焊接需要進行的七個步驟>創想小知識：管道焊接需要進行的七個步驟</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>