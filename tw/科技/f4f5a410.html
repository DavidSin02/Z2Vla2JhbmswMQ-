<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>從 ICLR 2019 一覽小樣本學習最新進展 | 极客快訊</title><meta property="og:title" content="從 ICLR 2019 一覽小樣本學習最新進展 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/RSsmrS1GwCcDsw"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f4f5a410.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f4f5a410.html><meta property="article:published_time" content="2020-11-14T21:01:58+08:00"><meta property="article:modified_time" content="2020-11-14T21:01:58+08:00"><meta name=Keywords content><meta name=description content="從 ICLR 2019 一覽小樣本學習最新進展"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/f4f5a410.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>從 ICLR 2019 一覽小樣本學習最新進展</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p><strong>雷鋒網 AI 科技評論按：</strong>通常而言，深度學習是典型的數據驅動型技術，面對數據有限的情況，傳統的深度學習技術的性能往往不盡如人意。在本屆 ICLR 上，許多研究者們利用元學習、遷移學習等技術對小樣本學習問題進行了探究，發表了多篇高質量論文，可謂百家爭鳴！深度學習工程師 Isaac Godfried 在 Medium 上發表了一篇文章，基於今年 ICLR 上關於小型數據集深度學習研究的論文，探討了目前小樣本學習的最新進展。雷鋒網 AI 科技評論編譯如下。</p><p>今年的國際表徵學習大會（ICLR）於 2019 年 5 月 6 日如期開幕。按照我此前的計劃，我會深入研究本屆會議發表的一些有趣的 ICLR 論文。其中大多數的論文都與我個人感興趣的研究領域相關（無監督學習、元學習、注意力機制、自然語言處理），但是我只會選出一些高質量的、並且在其各自的領域有所影響的精品論文進行分析，並更新系列博文。該系列博文的第一篇將介紹在小型數據集上的深度學習研究；第二篇將討論在自然語言處理和其它類型的序列化數據上取得突破性進展的論文；而第三篇則將分析各類其它的、我認為十分有趣的論文。</p><p></p><h3>遷移學習、元學習和無監督學習</h3><p>訓練數據有限的問題對各行各業都有著廣泛的影響，包括醫療衛生、農業、汽車、零售、娛樂，等等。在另外一些情況下，我們擁有大量的數據，但是它們卻未被標註。由於收集和標註數據的時間/成本很大，這個問題往往會成為將深度學習技術整合到目標任務中的障礙。</p><p><strong>《學習無監督學習規則》</strong></p><p>Learning unsupervised learning rules</p><p>論文下載地址：https://openreview.net/forum?id=HkNDsiC9KQ</p><p>該論文同時建立在元學習和無監督學習（這裡指 Metz 等人的工作）的概念之上。具體而言，該論文提出利用元學習以一種無監督學習的方式學習下游任務的有效表徵。該論文重點關注「半監督學習」分類問題，但是它之所以有趣是因為：至少在理論上，這種學習規則「可以被優化，從而為任意後續任務生成表徵」。這一點十分有用，因為在針對表徵的無監督學習的工作中，作者都定義了一個明確的訓練算法或損失函數。而這裡的模型會「學習創建由元目標確定的有用的表徵的算法」。這個自定義的規則往往需要經過大量的實驗以及領域知識才能得出，因此並不能很輕易地適用於新的領域。對自編碼器的使用就是其中的一個例子，它試著通過先進行編碼、再解碼出一個與原始數據相同的輸出來學習表徵。自編碼器往往需要一個明確指定的損失函數。</p><p>為了理解該方法究竟是如何工作的，我們不妨回想一下：在元學習中，我們通常有一個內層循環和外層循環。在內層循環中，模型會作用於一個具體的任務，例如：在圖像分類問題中，這樣的任務可能是識別出貓和狗。通常而言，內層循環會在一定數量 n（一般來說，n 在 1 到 10 之間）個示例上運行。然後，外層循環會使用某些內層循環得到的參數（權重本身、累計損失或其它參數）來執行一次「元更新」。這種「元更新」的具體情況隨著模型的變化而變化，但是它們通常會遵循如下所示的方法：</p><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RSsmrS1GwCcDsw><p>元學習過程一覽</p><p>考慮到這一點，他們的模型架構本質上是通過元學習學到某種在創建表徵之後更新內層模型的方法。在創建了某種表徵之後，該規則有效地在更新內層模型的過程中替代了隨機梯度下降方法。此外，不同於權重本身通過 MAML 方法或注意力模型的權重通過 SNAIL 更新的情況，這種無監督的更新規則是在循環的最後進行更新的。這意味著這種無監督學習規則不僅僅可以被應用於類似的任務，還可以被用於全新的任務、新的基礎模型，甚至是新模態的數據（例如從圖像數據到文本數據）。</p><p>首先，作者通過展現以前方法存在的問題來評價他們的模型的實驗結果。例如，一個變分自編碼器（VAE）會存在目標函數（即損失）不匹配的問題，隨著時間的推移，這會導致模型的性能不佳。儘管可以使用原型網絡遷移特徵，但如果不同任務的特徵維度不同，這種方法就會崩潰。相反，Metz 等人的方法學到了一種在「小樣本」分類任務中具備更好的泛化性能的更新規則。他們還展示了訓練時的元更新，即使該網絡僅僅在圖片分類任務上進行訓練，它仍然可以泛化到提升文本分類的性能（但同時他們也發現：如果元函數在圖片分類任務上訓練了太久，會產生明顯的性能下降，這是由於該元函數在圖片任務上發生了過擬合）。</p><p>總而言之，這是一篇非常棒的論文，也是在無監督技術上取得的巨大進步。即使它沒有取得任何目前最先進的實驗結果，但是它完全可以被應用於許多數據稀疏的領域。本論文官方版本的代碼可以通過該鏈接獲取：https://github.com/tensorflow/models/tree/master/research/learning_unsupervised_learning</p><p></p><h3><strong>通過元學習實現的無監督學習</strong></h3><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RSsmrSH5JWooYR><p>有趣的是，在今年的 ICLR 上發表了兩篇同時提出將元學習和無監督學習結合起來的論文（儘管兩篇文章實現的方法完全不同）。在本文中，作者使用無監督學習為元學習劃分數據及，而並非使用元學習來學會無監督學習的規則。</p><p>本文是我最喜愛的論文之一，因為它開啟了無需進行顯式任務描述的元學習的大門。元學習存在的某些問題在於：元學習往往需要定義得非常好的任務集合。這就將元學習的適用範疇限制在研究者擁有非常大的已標註元數據集（往往被劃分為不同的子數據集）的前提下。本文的方法提出自動地將數據集劃分為不同的子集。本文作者發現，即便使用簡單的無監督聚類算法（例如 K-means 算法），元學習器仍然能夠從這些任務中進行學習，並且在後續人為標記過的任務上比直接利用這些嵌入進行學習的方法（例如在無監督學習後，緊接著進行監督分類的情況）的性能更好。他們使用的兩種元學習技術為「ProtoNets」和「MAML」。本文介紹了一種有趣的半監督學習範式，在這裡，我們首先進行無監督的預訓練，然後進行監督學習。在本例中，「帶監督的」部分會進行「小樣本學習」（few-shot learning）。</p><p>作者在 4 個數據集上（MNIST，Omniglot，miniImageNet，以及 CelebA）將他們的方法和無監督學習方法進行了對比。最終，他們發現，他們的方法比所有其它的「無監督+監督學習」方法（包括聚類匹配，多層知機（MLP），線性分類，以及K最近鄰）的性能都要好得多。總而言之，本文朝著「讓元學習更容易被應用於各種不同類型的問題」的方向邁出了一大步，而不是讓元學習僅僅適用於那些被良好定義的任務切片。</p><p><strong>《帶有潛在嵌入優化（LEO） 的元學習》</strong></p><p>Meta-Learning with Latent Embedding Optimization (LEO)</p><p>論文下載地址：https://openreview.net/forum?id=BJgklhAcK7</p><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RSsmrSW6Q366wp><p>本文旨在將基於梯度的元學習和一個潛在的表徵網絡結合起來。LEO 的操作分為兩步：首先，它會學習一個模型參數的低維嵌入；接著它會在模型的低維嵌入空間上執行元學習。具體而言，首先將會為模型給出一個任務 T 以及會被傳給編碼器的輸入。編碼器會生成一個潛在編碼，該編碼隨後會被解碼成一組參數。該編碼器還帶有一個關係網絡，它有助於將編碼變得具有上下文依賴。接著，這些參數會在內層循環中被優化，而編碼器、解碼器和關係網絡則會在外層循環中被優化。作者指出，他們的工作的主要貢獻是說明了低維嵌入空間中的元學習會比在類似於 MAML 中使用的那樣的高維空間中的元學習的性能好得多。LEO 在「tieredImageNet」和「miniImageNet」數據集上都取得了很好的實驗結果（包括在 5 way 1-shot 對比基準測試上實現的準確率為 61%，令人印象深刻，同時還在 5 way 5-shot 任務上取得了77% 的準確率）。和許多其它的論文一樣，本文僅僅在圖像數據集上進行了測試，因此尚不清楚該模型在其它類型數據上的泛化能力。</p><p><strong>《跨程序的遷移學習》</strong></p><p>Transferring Learning Across Processes</p><p>論文下載地址：https://openreview.net/forum?id=HygBZnRctX</p><p>由於本文作者已經在 Medium 上發表了一篇詳細介紹其模型工作原理的博文（文章查看地址：https://medium.com/@flnr/transferring-knowledge-across-learning-processes-f6f63e9e6f46），我在這裡就不過多贅述技術層面的細節了。相較於其它大量關於元學習的論文，該論文有下面幾點值得強調的亮點：首先，本文的模型同時在小樣本學習（few-shot learning）和數據規模更大的場景下進行了測試評估。這一點是很重要的，因為元學習算法往往並沒有考慮在有更多的數據示例（但數據規模仍然太小，以致於無法從頭開始訓練模型）的情況下元優化的工作情況。本文還研究了一些尚未被探索的領域。具體而言，本文研究了往往未被探索的「遠程遷移」領域，即在明顯不同的任務之間實現具有積極效果的知識遷移。</p><p><strong>《學習深度多維聚類變分自編碼器中的潛在上層結構》</strong></p><p>Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering</p><p>論文下載地址：https://openreview.net/forum?id=SJgNwi09Km</p><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/RSsmrSkEguNPS9><p>本文討論了使用一種新型的用於更好地對高維數據進行聚類的變分自編碼器（VAE）。在無監督學習中，將數據項聚類到不同的中是一個重要的預處理步驟。本文作者指出，許多種類的數據可以基於其屬性的許多不同部分被進行聚類。作者指出「LTVAE 會生成多個數據劃分，每個劃分都會由一個上層的潛變量導出。」</p><p>「LT-VAE 不僅僅會學習每個聚類的位置來更好地表徵數據，它還會學習這些簇的編號和底層樹形架構的層次結構。這是通過一個三步的學習算法實現的：第一步，訓練一個傳統的『編碼器-解碼器』神經網絡，從而提升它們對數據的擬合效果。第二步，一種類似於最大期望算法（EM）的優化過程，從而更好地擬合學到的後驗概率的潛在先驗的參數。第三步，調整潛在先驗的結構從而提升其 BIC 得分[3]，這樣做在對潛在後驗的良好擬合以及潛在先驗的參數數量（即複雜度）之間取得了平衡。」</p><p>本文提出的方法的主要優點在於，它提高了聚類的可解釋性（即使從對數似然方面來說，它整體的效果並沒有那麼好）。此外，針對特定的因素進行聚類使其在許多真實世界的應用中變得十分具有吸引力。儘管本文與許多其它的文章有所不同，並且沒有顯式地研究小樣本學習問題，我認為將這種聚類方法與小樣本方法相結合可能會很有用。例如，它可能可以在「基於元學習環境的無監督學習」問題中被用於任務劃分。</p><p><strong>《基於元學習的深度在線學習》</strong></p><p>Deep online learning via meta-learning</p><p>論文下載地址：https://sites.google.com/berkeley.edu/onlineviameta</p><p>本文聚焦於使用元學習和一個「Chinese Restaurant Proces」，在強化學習模型在線運行時（即在生產過程中）快速地更新它們。該工作受啟發於這一事實：人類常常面臨之前從未（真正地）經歷過的新狀況；然而我們可以利用過去的經驗，並將其與我們從新的經歷中獲得的反饋相結合，從而迅速適應新的狀況。</p><p>本文提出的方法首次使用了 MAML 來初步訓練模型。在 MAML 給出有效的先驗後會使用在線學習算法。該在線學習算法使用了「中餐館程序」來生成新的帶有合適的初始化設置的新模型或選擇一個已經存在的模型。接著，作者會基於在線學習的結果，使用隨機梯度下降（SGD）算法更新模型參數。作者將本文提出的方法命名為「用於在線學習的元學習」（或簡稱 MoLE）。</p><p>作者在一些強化學習環境中測試評估了他們提出的方法。第一個環境是穿越不同難度的斜坡的仿真獵豹。第二個環境是一個腿部有殘缺的六足履帶機器人。實驗結果表明，MoLE 比基於模型的強化學習、使用元學習的k-shot 自適應技術、以及使用元學習的連續梯度步技術的性能要好（儘管有趣的是，它僅僅略微優於使用元學習的梯度步）。</p><p><strong>《學習通過最大化遷移和最小化干擾進行不會遺忘的學習》</strong></p><p>Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference</p><p>論文下載地址：https://arxiv.org/pdf/1810.11910.pdf</p><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RSsmrSy4nzasLJ><p>當神經網絡對一系列任務進行學習時，它往往會遭遇被稱作「災難性遺忘」的問題。由於災難性遺忘，神經網絡無法再在之前訓練的任務上取得好的性能。災難性遺忘可以被認為是存在明顯的消極負向遷移的遷移學習的特例。遷移學習（正如大多數人們所指的）以及元學習通常尋求最大化在最終的任務上的正向積極遷移，但是一般來說並不會關注它對於源任務的影響。本文試圖在仍然能夠實現積極遷移但不以災難性遺忘（干擾）為代價的情況下取得更大的平衡。</p><p>為了解決這個問題，Riemer 等人提出了一種被稱為元經驗回放（MER）的方法。MER 採用了標準的經驗回放，交叉存取過去的訓練示例與當前的訓練示例，從而防止發生災難性遺忘。作者假設過去的訓練示例學習率較低；其次，MER 採用流行的 REPTILE 元學習算法在新數據上進行訓練。不過，MER 也將內存緩存器中的過去的訓練示例與新的示例交錯在一起，輸入給由 REPTILE 驅動的內層訓練循環，從而防止災難性遺忘的發生。</p><p>我非常喜歡這篇論文，因為它同時探究了積極遷移和消極遷移的想法。本文的方法在 Omniglot 和強化學習環境中取得的實驗結果似乎相當不錯。然而，作者只在小型「玩具」數據集上進行了測試，尤其是在監督分類問題中。他們本應該也在 CIFAR-10 對比基準、CALTech-Birds 或 CORRE50 上進行測試。從這一點上說，由於還存在許多更加真實的 CL 數據集，他們沒有理由僅僅在稍微修改過的 MNIST 或 Omniglot 數據集上進行測試。此外，我發現由於作者「重複命名」了一些之前命名過的概念，文中的一些術語令人困惑。而且，在理想情況下，當我們連續進行學習時，我們不必再在任何之前的數據上重新進行訓練（重新訓練會帶來額外的計算開銷）。然而，所有的這一切都是朝著正確的方向邁進了，我希望有更多的論文同時關注正向和負向遷移。更多關於該論文的信息，請參閱 IBM 的博文：「Unifying Continual Learning and Meta-Learning with Meta-Experience Replay」（https://www.ibm.com/blogs/research/2019/05/meta-experience-replay/）；論文代碼地址：https://github.com/mattriemer/MER</p><p><strong>《文本轉語音的高效自適應採樣》</strong></p><p>Sample Efficient Adaptive Text-to-Speech</p><p>論文下載地址：https://openreview.net/forum?id=rkzjUoAcFX</p><img alt="從 ICLR 2019 一覽小樣本學習最新進展" onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/RSsmrg3BAGnr5l><p>這是一個將元學習運用到「序列到序列」建模任務中的有趣應用。在本例中，作者使用元學習來實現對說話者聲音的小樣本自適應。該應用十分重要，因為大多數情況下，你可能並不能獲取某個特定說話者持續 100 秒或 1000 秒的聲音。具體而言，作者拓展了 WaveNet 架構，從而引入了元學習技術。有趣的是，根據作者的說法，在他們初步的試驗中，MAML 並沒有生成有意義的先驗。因此，他們不得不開發他們自己的架構。</p><p>該架構的工作流程分為三步：（1）在一個包含多名說話者的「文本-語音」對的大型語料庫上訓練模型；（2）根據某個特定說話者的少量「文本-語音」對調整模型；（3）最終在純文本上進行推理，並將其轉化為合適的語音。作者研究了兩種小樣本學習場景：帶有一個嵌入編碼器（SEA-ENC）的參數化 few-soht 自適應，以及帶有調優過程的非參數化 few-shot 自適應（SEA-ALL）。在 SEA-ENC 的情況下，作者訓練一個輔助嵌入網絡，該網絡會在給定新數據的情況下預測出一個說話者的嵌入向量。相比之下，對於 SEA-ALL 來說，作者同時訓練網路和嵌入。在測試評估階段，SEA-ALL 似乎性能更好，儘管作者聲稱模型在 SEA-ALL 的情況下會發生過擬合。因此，他們推薦使用早停法（early stopping）防止過擬合。（他們的模型僅僅在 10 秒內的 Librispeech 任務上比早先的論文所提出的模型表現更好）。</p><p>本文是一個很好的範例，它將小樣本學習應用於典型的圖像分類領域之外的棘手問題，並對其進行必要的調整使其能夠真正有效。希望我們能夠在未來看到有更多的研究者嘗試將小樣本學習應用於通用模型。作者提供了一個網站，你可以在上面測試他們的 TTS（Text to speaking）模型的demo。然而，遺憾的是，他們似乎沒有公開他們的代碼。</p><p></p><h3>ICLR 其它相關論文概述</h3><p><strong>《K for the Price of 1：參數高效的多任務和遷移學習》</strong></p><p>K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning</p><p>論文下載地址：https://openreview.net/pdf?id=BJxvEh0cFQ</p><p>Mudrarkarta 等人提出了一個由少量可學習的參數組成的模型補丁包，這些參數專門針對各個任務。這種方法替代了對網絡的最後一層進行調優的通常做法。作者發現這種方法不僅可以減少參數的數量（從超過 100 萬減少到 3.5 萬），還可以在遷移學習和多任務學習的環境下提升調優的準確率。唯一的缺點是，該補丁包似乎針對的只是相當具體的架構。</p><p><strong>《用於距離度量學習的無監督域自適應方法》</strong></p><p>Unsupervised Domain Adaptation for Distance Metric Learning</p><p>論文下載地址：https://openreview.net/forum?id=BklhAj09K7</p><p>儘管本論文第一部分的標題為「無監督域自適應」，它實際上研究的是遷移學習問題。回想一下，通常目標域會通過域自適應獲得一組相同的標籤。然而，在本例中，作者假設了一個無標籤的目標域——正如一些審稿人提到的，本論文因此也變得有些令人困惑；不過，本文仍然有一些值得關注的地方：為了分離源域和目標域的調整空間，作者提出了一種特徵遷移網絡 FTN。並且，該作者在跨種族人臉識別任務上取得了目前最先進的性能。</p><p><strong>《學習用於語法引導的程序合成的元解算器》</strong></p><p>Learning a Meta-Solver for Syntax-Guided Program Synthesis</p><p>論文下載地址：https://openreview.net/forum?id=Syl8Sn0cK7&noteId=BJlUkwHxeV</p><p>本文討論如何將元學習應用到程序合成任務中。在本文中，作者構建了一個語法引導程序，它遵循一個邏輯公式和語法，然後生成一個程序。本文是一個將元學習用於典型的小樣本圖像數據集之外的應用中的很好的範例。</p><p><strong>《深度線性網絡中泛化動態和遷移學習的分析理論》</strong></p><p>An analytic theory of generalization dynamics and transfer learning in deep linear networks</p><p>論文下載地址：https://arxiv.org/abs/1809.10374</p><p>本文研究了學習和遷移學習的理論。作者聲稱「我們的理論解釋了知識遷移敏感但可計算依賴於『信噪比』和任務對的輸入特徵對齊」。總而言之，對於那些喜歡深入研究理論的人來說，這篇文章非常有趣。</p><p></p><h3>結語</h3><p>我希望本文很好地概述了本屆 ICLR 上有關小樣本學習的大多數論文（儘管我可能會漏掉一些）。如你所見，本屆 ICLR 上出現了各種各樣有趣的新技術，它們開啟了將深度學習用於數據有限的情況的大門。</p><p>via https://towardsdatascience.com/iclr-2019-overcoming-limited-data-382cd19db6d2雷鋒網</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>ICLR</a></li><li><a>2019</a></li><li><a>一覽小樣</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html alt=2019年土木畢業生要知道的那些事 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/21d2ba3e.html title=2019年土木畢業生要知道的那些事>2019年土木畢業生要知道的那些事</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html alt=2019年度《特種鑄造及有色合金》優秀論文結果公佈 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/137c70000b816835d80bf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/171b22b4.html title=2019年度《特種鑄造及有色合金》優秀論文結果公佈>2019年度《特種鑄造及有色合金》優秀論文結果公佈</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html alt=2019年度《特種鑄造及有色合金》網絡評選結果出爐 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/66c26cbe459a4361b1d501e4bbac6c88 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/817e1015.html title=2019年度《特種鑄造及有色合金》網絡評選結果出爐>2019年度《特種鑄造及有色合金》網絡評選結果出爐</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html alt=金川集團公司2019年全國合金鑄造行業商洽會舉行 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/df18bcc1.html title=金川集團公司2019年全國合金鑄造行業商洽會舉行>金川集團公司2019年全國合金鑄造行業商洽會舉行</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html alt="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3c5292d6.html title="2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班">2019年度數字孿生城市之無人機 航攝應用及真三維建模技術培訓班</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html alt=2019年最爆笑的120個名場面合集 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/dc6fcd05f35e499a9ef7a2d19ff9c66b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcd2a59f.html title=2019年最爆笑的120個名場面合集>2019年最爆笑的120個名場面合集</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html alt=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9a08cc2f25cb41c5be515de0d79879a9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/715eacc1.html title=《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝>《獅子王》2019：引入VR虛擬製作技術，顛覆動畫電影拍攝</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html alt="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/Rk8ZSn39iz0Be8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e342e11c.html title="2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法">2019掌上生活10元風暴怎麼玩攻略 快速獲取小招喵方法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html alt=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/f8d17716-f3b8-4c6d-8eb7-f482334ad491 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/67fef4c6.html title=2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！>2019年高考，怎樣設置院校梯度才合理？衝、穩、保、墊，很關鍵！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html alt=2019年正在流行的16個網頁設計趨勢 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/RPgQdSQEjBTN6Z style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e18c5b5e.html title=2019年正在流行的16個網頁設計趨勢>2019年正在流行的16個網頁設計趨勢</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d72ed228.html alt=2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fbcf9bc4d8224c309106305ad34adf9a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d72ed228.html title=2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一）>2019年中式烹調師（技師）安全生產模擬考試題庫及答案（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d4044e1f.html alt=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d4044e1f.html title=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一）>2019年中式烹調師（高級）安全生產模擬考試題庫及答案（一）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/f855d5ae.html alt=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9796cfd44f754f9ab22310d91088423e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/f855d5ae.html title=2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二）>2019年中式烹調師（高級）安全生產模擬考試題庫及答案（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/9adee5f1.html alt=2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/d6a75905fb9346ccb6e4c8a304a79e63 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/9adee5f1.html title=2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2>2019中式烹調師（技師）在線免費模擬考試系統及模擬題庫2</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/01e18262.html alt="2019級軍訓 | 蛻變中的成長，在西京學院我們一起經歷的軍訓" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/5e6d48b6fc5a49f480f9de7e22ab7958 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/01e18262.html title="2019級軍訓 | 蛻變中的成長，在西京學院我們一起經歷的軍訓">2019級軍訓 | 蛻變中的成長，在西京學院我們一起經歷的軍訓</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>