<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 | 极客快訊</title><meta property="og:title" content="萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/pgc-image/4b1546669f144ee4b07bce69320d4431"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f8112cb.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f8112cb.html><meta property="article:published_time" content="2020-10-29T20:50:28+08:00"><meta property="article:modified_time" content="2020-10-29T20:50:28+08:00"><meta name=Keywords content><meta name=description content="萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/f8112cb.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>作者：morganhuang，騰訊 IEG 後臺開發工程師</p><blockquote><p>說到 TCP 協議，相信大家都比較熟悉了，對於 TCP 協議總能說個一二三來，但是 TCP 協議又是一個非常複雜的協議，其中有不少細節點讓人頭疼點。本文就是來說說這些頭疼點的，淺談一些 TCP 的疑難雜症。那麼從哪說起呢？當然是從三次握手和四次揮手說起啦，可能大家都知道 TCP 是三次交互完成連接的建立，四次交互來斷開一個連接，那為什麼是三次握手和四次揮手呢？反過來不行嗎？</p></blockquote><h1><strong>疑症（1）TCP 的三次握手、四次揮手</strong></h1><p>下面兩圖大家再熟悉不過了，TCP 的三次握手和四次揮手見下面左邊的”TCP 建立連接”、”TCP 數據傳送”、”TCP 斷開連接”時序圖和右邊的”TCP 協議狀態機” 。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/4b1546669f144ee4b07bce69320d4431></div><p>TCP三次握手、四次揮手時序圖</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6d6ea92fc97444da9cceaf5299022c87></div><p>TCP協議狀態機</p><p>要弄清 TCP 建立連接需要幾次交互才行，我們需要弄清建立連接進行初始化的目標是什麼。TCP 進行握手初始化一個連接的目標是：分配資源、初始化序列號(通知 peer 對端我的初始序列號是多少)，知道初始化連接的目標，那麼要達成這個目標的過程就簡單了，握手過程可以簡化為下面的四次交互：</p><p>1）client 端首先發送一個 SYN 包告訴 Server 端我的初始序列號是 X；2）Server 端收到 SYN 包後回覆給 client 一個 ACK 確認包，告訴 client 說我收到了；3）接著 Server 端也需要告訴 client 端自己的初始序列號，於是 Server 也發送一個 SYN 包告訴 client 我的初始序列號是 Y；4）Client 收到後，回覆 Server 一個 ACK 確認包說我知道了。</p><p>整個過程 4 次交互即可完成初始化，但是，細心的同學會發現兩個問題：</p><ul><li>Server 發送 SYN 包是作為發起連接的 SYN 包，還是作為響應發起者的 SYN 包呢？怎麼區分？比較容易引起混淆</li><li>Server 的 ACK 確認包和接下來的 SYN 包可以合成一個 SYN ACK 包一起發送的，沒必要分別單獨發送，這樣省了一次交互同時也解決了問題[1].這樣 TCP 建立一個連接，三次握手在進行最少次交互的情況下完成了 Peer 兩端的資源分配和初始化序列號的交換。</li></ul><p>大部分情況下建立連接需要三次握手，也不一定都是三次，有可能出現四次握手來建立連接的。如下圖，當 Peer 兩端同時發起 SYN 來建立連接的時候，就出現了四次握手來建立連接(對於有些 TCP/IP 的實現，可能不支持這種同時打開的情況)。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/174e0899441a4218b635c9be3f640744></div><p>在三次握手過程中，細心的同學可能會有以下疑問：</p><ul><li>初始化序列號 X、Y 是可以是寫死固定的嗎，為什麼不能呢？</li><li>假如 Client 發送一個 SYN 包給 Server 後就掛了或是不管了，這個時候這個連接處於什麼狀態呢？會超時嗎？為什麼呢？</li></ul><p>TCP 進行斷開連接的目標是：回收資源、終止數據傳輸。由於 TCP 是全雙工的，需要 Peer 兩端分別各自拆除自己通向 Peer 對端的方向的通信信道。這樣需要四次揮手來分別拆除通信信道，就比較清晰明瞭了。</p><p>1）Client 發送一個 FIN 包來告訴 Server 我已經沒數據需要發給 Server 了；2）Server 收到後回覆一個 ACK 確認包說我知道了；3）然後 server 在自己也沒數據發送給 client 後，Server 也發送一個 FIN 包給 Client 告訴 Client 我也已經沒數據發給 client 了；4）Client 收到後，就會回覆一個 ACK 確認包說我知道了。</p><p>到此，四次揮手，這個 TCP 連接就可以完全拆除了。在四次揮手的過程中，細心的同學可能會有以下疑問：</p><ul><li>Client 和 Server 同時發起斷開連接的 FIN 包會怎麼樣呢，TCP 狀態是怎麼轉移的?</li><li>左側圖中的四次揮手過程中，Server 端的 ACK 確認包能不能和接下來的 FIN 包合併成一個包呢，這樣四次揮手就變成三次揮手了。</li><li>四次揮手過程中，首先斷開連接的一端，在回覆最後一個 ACK 後，為什麼要進行 TIME_WAIT 呢(超時設置是 2*MSL，RFC793 定義了 MSL 為 2 分鐘，Linux 設置成了 30s)，在 TIME_WAIT 的時候又不能釋放資源，白白讓資源佔用那麼長時間，能不能省了 TIME_WAIT 呢，為什麼？</li></ul><h1><strong>疑症（2）TCP 連接的初始化序列號能否固定</strong></h1><p>如果初始化序列號（縮寫為 ISN：Inital Sequence Number）可以固定，我們來看看會出現什麼問題。假設 ISN 固定是 1，Client 和 Server 建立好一條 TCP 連接後，Client 連續給 Server 發了 10 個包，這 10 個包不知怎麼被鏈路上的路由器緩存了(路由器會毫無先兆地緩存或者丟棄任何的數據包)，這個時候碰巧 Client 掛掉了，然後 Client 用同樣的端口號重新連上 Server，Client 又連續給 Server 發了幾個包，假設這個時候 Client 的序列號變成了 5。</p><p>接著，之前被路由器緩存的 10 個數據包全部被路由到 Server 端了，Server 給 Client 回覆確認號 10，這個時候，Client 整個都不好了，這是什麼情況？我的序列號才到 5，你怎麼給我的確認號是 10 了，整個都亂了。RFC793 中，建議 ISN 和一個假的時鐘綁在一起，這個時鐘會在每 4 微秒對 ISN 做加一操作，直到超過 2^32，又從 0 開始，這需要 4 小時才會產生 ISN 的迴繞問題，這幾乎可以保證每個新連接的 ISN 不會和舊的連接的 ISN 產生衝突。這種遞增方式的 ISN，很容易讓攻擊者猜測到 TCP 連接的 ISN，現在的實現大多是在一個基準值的基礎上進行隨機的。</p><h1><strong>疑症（3）初始化連接的 SYN 超時問題</strong></h1><p>Client 發送 SYN 包給 Server 後掛了，Server 回給 Client 的 SYN-ACK 一直沒收到 Client 的 ACK 確認，這個時候這個連接既沒建立起來，也不能算失敗。這就需要一個超時時間讓 Server 將這個連接斷開，否則這個連接就會一直佔用 Server 的 SYN 連接隊列中的一個位置，大量這樣的連接就會將 Server 的 SYN 連接隊列耗盡，讓正常的連接無法得到處理。目前，Linux 下默認會進行 5 次重發 SYN-ACK 包，重試的間隔時間從 1s 開始，下次的重試間隔時間是前一次的雙倍，5 次的重試時間間隔為 1s,2s, 4s, 8s,16s，總共 31s，第 5 次發出後還要等 32s 都知道第 5 次也超時了，所以，總共需要 1s + 2s +4s+ 8s+ 16s + 32s =63s，TCP 才會把斷開這個連接。</p><p>由於，SYN 超時需要 63 秒，那麼就給攻擊者一個攻擊服務器的機會，攻擊者在短時間內發送大量的 SYN 包給 Server(俗稱 SYN flood 攻擊)，用於耗盡 Server 的 SYN 隊列。對於應對 SYN 過多的問題，linux 提供了幾個 TCP 參數：tcp_syncookies、tcp_synack_retries、tcp_max_syn_backlog、tcp_abort_on_overflow 來調整應對。</p><h1><strong>疑症（4） TCP 的 Peer 兩端同時斷開連接</strong></h1><p>由上面的”TCP 協議狀態機“圖可以看出，TCP 的 Peer 端在收到對端的 FIN 包前發出了 FIN 包，那麼該 Peer 的狀態就變成了 FIN_WAIT1，Peer 在 FIN_WAIT1 狀態下收到對端 Peer 對自己 FIN 包的 ACK 包的話，那麼 Peer 狀態就變成 FIN_WAIT2，Peer 在 FIN_WAIT2 下收到對端 Peer 的 FIN 包，在確認已經收到了對端 Peer 全部的 Data 數據包後，就響應一個 ACK 給對端 Peer，然後自己進入 TIME_WAIT 狀態。</p><p>但是如果 Peer 在 FIN_WAIT1 狀態下首先收到對端 Peer 的 FIN 包的話，那麼該 Peer 在確認已經收到了對端 Peer 全部的 Data 數據包後，就響應一個 ACK 給對端 Peer，然後自己進入 CLOSEING 狀態，Peer 在 CLOSEING 狀態下收到自己的 FIN 包的 ACK 包的話，那麼就進入 TIME WAIT 狀態。於是，TCP 的 Peer 兩端同時發起 FIN 包進行斷開連接，那麼兩端 Peer 可能出現完全一樣的狀態轉移 FIN_WAIT1——>CLOSEING——->TIME_WAIT，也就會 Client 和 Server 最後同時進入 TIME_WAIT 狀態。同時關閉連接的狀態轉移如下圖所示：</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/1bbcd9975402416e87ed92680c2f3912></div><h1><strong>疑症（5）四次揮手能不能變成三次揮手呢？？</strong></h1><p>答案是可能的。TCP 是全雙工通信，Cliet 在自己已經不會在有新的數據要發送給 Server 後，可以發送 FIN 信號告知 Server，這邊已經終止 Client 到對端 Server 那邊的數據傳輸。但是，這個時候對端 Server 可以繼續往 Client 這邊發送數據包。於是，兩端數據傳輸的終止在時序上是獨立並且可能會相隔比較長的時間，這個時候就必須最少需要 2+2= 4 次揮手來完全終止這個連接。但是，如果 Server 在收到 Client 的 FIN 包後，在也沒數據需要發送給 Client 了，那麼對 Client 的 ACK 包和 Server 自己的 FIN 包就可以合併成為一個包發送過去，這樣四次揮手就可以變成三次了(似乎 linux 協議棧就是這樣實現的)</p><h1><strong>疑症（6） TCP 的頭號疼症 TIME_WAIT 狀態</strong></h1><p>要說明 TIME_WAIT 的問題，需要解答以下幾個問題</p><h1><strong>一、Peer 兩端，哪一端會進入 TIME_WAIT 呢？為什麼?</strong></h1><p>相信大家都知道，TCP 主動關閉連接的那一方會最後進入 TIME_WAIT。那麼怎麼界定主動關閉方呢？是否主動關閉是由 FIN 包的先後決定的，就是在自己沒收到對端 Peer 的 FIN 包之前自己發出了 FIN 包，那麼自己就是主動關閉連接的那一方。對於疑症（4）中描述的情況，那麼 Peer 兩邊都是主動關閉的一方，兩邊都會進入 TIME_WAIT。為什麼是主動關閉的一方進行 TIME_WAIT 呢，被動關閉的進入 TIME_WAIT 可以不呢？我們來看看 TCP 四次揮手可以簡單分為下面三個過程：</p><p>過程一.主動關閉方發送 FIN；過程二.被動關閉方收到主動關閉方的 FIN 後發送該 FIN 的 ACK，被動關閉方發送 FIN；過程三.主動關閉方收到被動關閉方的 FIN 後發送該 FIN 的 ACK，被動關閉方等待自己 FIN 的 ACK。</p><p>問題就在過程三中，據 TCP 協議規範，不對 ACK 進行 ACK，如果主動關閉方不進入 TIME_WAIT，那麼主動關閉方在發送完 ACK 就走了的話，如果最後發送的 ACK 在路由過程中丟掉了，最後沒能到被動關閉方，這個時候被動關閉方沒收到自己 FIN 的 ACK 就不能關閉連接，接著被動關閉方會超時重發 FIN 包，但是這個時候已經沒有對端會給該 FIN 回 ACK，被動關閉方就無法正常關閉連接了，所以主動關閉方需要進入 TIME_WAIT 以便能夠重發丟掉的被動關閉方 FIN 的 ACK。</p><h1><strong>二、TIME_WAIT 狀態是用來解決或避免什麼問題呢？</strong></h1><p>TIME_WAIT 主要是用來解決以下幾個問題：</p><p>1）上面解釋為什麼主動關閉方需要進入 TIME_WAIT 狀態中提到的：主動關閉方需要進入 TIME_WAIT 以便能夠重發丟掉的被動關閉方 FIN 包的 ACK。如果主動關閉方不進入 TIME_WAIT，那麼在主動關閉方對被動關閉方 FIN 包的 ACK 丟失了的時候，被動關閉方由於沒收到自己 FIN 的 ACK，會進行重傳 FIN 包，這個 FIN 包到主動關閉方後，由於這個連接已經不存在於主動關閉方了，這個時候主動關閉方無法識別這個 FIN 包，協議棧會認為對方瘋了，都還沒建立連接你給我來個 FIN 包？，於是回覆一個 RST 包給被動關閉方，被動關閉方就會收到一個錯誤(我們見的比較多的：connect reset by peer，這裡順便說下 Broken pipe，在收到 RST 包的時候，還往這個連接寫數據，就會收到 Broken pipe 錯誤了)，原本應該正常關閉的連接，給我來個錯誤，很難讓人接受。</p><p>2）防止已經斷開的連接 1 中在鏈路中殘留的 FIN 包終止掉新的連接 2(重用了連接 1 的所有的 5 元素(源 IP，目的 IP，TCP，源端口，目的端口)），這個概率比較低，因為涉及到一個匹配問題，遲到的 FIN 分段的序列號必須落在連接 2 的一方的期望序列號範圍之內，雖然概率低，但是確實可能發生，因為初始序列號都是隨機產生的，並且這個序列號是 32 位的，會迴繞。</p><p>3）防止鏈路上已經關閉的連接的殘餘數據包(a lost duplicate packet or a wandering duplicate packet) 干擾正常的數據包，造成數據流的不正常。這個問題和 2）類似。</p><h1><strong>三、TIME_WAIT 會帶來哪些問題呢？</strong></h1><p>TIME_WAIT 帶來的問題注意是源於：一個連接進入 TIME_WAIT 狀態後需要等待 2*MSL(一般是 1 到 4 分鐘)那麼長的時間才能斷開連接釋放連接佔用的資源，會造成以下問題：</p><ul><li>作為服務器，短時間內關閉了大量的 Client 連接，就會造成服務器上出現大量的 TIME_WAIT 連接，佔據大量的 tuple，嚴重消耗著服務器的資源。</li><li>作為客戶端，短時間內大量的短連接，會大量消耗的 Client 機器的端口，畢竟端口只有 65535 個，端口被耗盡了，後續就無法在發起新的連接了。</li></ul><p>由於上面兩個問題，作為客戶端需要連本機的一個服務的時候，首選 UNIX 域套接字而不是 TCP)。TIME_WAIT 很令人頭疼，很多問題是由 TIME_WAIT 造成的，但是 TIME_WAIT 又不是多餘的不能簡單將 TIME_WAIT 去掉，那麼怎麼來解決或緩解 TIME_WAIT 問題呢？可以進行 TIME_WAIT 的快速回收和重用來緩解 TIME_WAIT 的問題。有沒一些清掉 TIME_WAIT 的技巧呢？</p><h1><strong>四、TIME_WAIT 的快速回收和重用</strong></h1><p><strong>【1】TIME_WAIT 快速回收</strong>linux 下開啟 TIME_WAIT 快速回收需要同時打開 tcp_tw_recycle 和 tcp_timestamps(默認打開)兩選項。Linux 下快速回收的時間為 3.5* RTO（Retransmission Timeout），而一個 RTO 時間為 200ms 至 120s。開啟快速回收 TIME_WAIT，可能會帶來(問題一、)中說的三點危險，為了避免這些危險，要求同時滿足以下三種情況的新連接要被拒絕掉：</p><ul><li>來自同一個對端 Peer 的 TCP 包攜帶了時間戳；</li><li>之前同一臺 peer 機器(僅僅識別 IP 地址，因為連接被快速釋放了，沒了端口信息)的某個 TCP 數據在 MSL 秒之內到過本 Server；</li><li>Peer 機器新連接的時間戳小於 peer 機器上次 TCP 到來時的時間戳，且差值大於重放窗口戳(TCP_PAWS_WINDOW)。</li></ul><p>初看起來正常的數據包同時滿足下面 3 條幾乎不可能，因為機器的時間戳不可能倒流的，出現上述的 3 點均滿足時，一定是老的重複數據包又回來了，丟棄老的 SYN 包是正常的。到此，似乎啟用快速回收就能很大程度緩解 TIME_WAIT 帶來的問題。但是，這裡忽略了一個東西就是 NAT。</p><p>在一個 NAT 後面的所有 Peer 機器在 Server 看來都是一個機器，NAT 後面的那麼多 Peer 機器的系統時間戳很可能不一致，有些快，有些慢。這樣，在 Server 關閉了與系統時間戳快的 Client 的連接後，在這個連接進入快速回收的時候，同一 NAT 後面的系統時間戳慢的 Client 向 Server 發起連接，這就很有可能同時滿足上面的三種情況，造成該連接被 Server 拒絕掉。所以，在是否開啟 tcp_tw_recycle 需要慎重考慮了</p><p><strong>【2】TIME_WAIT 重用</strong></p><p>linux 上比較完美的實現了 TIME_WAIT 重用問題。只要滿足下面兩點中的一點，一個 TW 狀態的四元組(即一個 socket 連接)可以重新被新到來的 SYN 連接使用。</p><p>[1]. 新連接 SYN 告知的初始序列號比 TIME_WAIT 老連接的末序列號大；[2]. 如果開啟了 tcp_timestamps，並且新到來的連接的時間戳比老連接的時間戳大。</p><p>要同時開啟 tcp_tw_reuse 選項和 tcp_timestamps 選項才可以開啟 TIME_WAIT 重用，還有一個條件是：重用 TIME_WAIT 的條件是收到最後一個包後超過 1s。細心的同學可能發現 TIME_WAIT 重用對 Server 端來說並沒解決大量 TIME_WAIT 造成的資源消耗的問題，因為不管 TIME_WAIT 連接是否被重用，它依舊佔用著系統資源。即便如此，TIME_WAIT 重用還是有些用處的，它解決了整機範圍拒絕接入的問題，雖然一般一個單獨的 Client 是不可能在 MSL 內用同一個端口連接同一個服務的，但是如果 Client 做了 bind 端口那就是同個端口了。時間戳重用 TIME_WAIT 連接的機制的前提是 IP 地址唯一性，得出新請求發起自同一臺機器，但是如果是 NAT 環境下就不能這樣保證了，於是在 NAT 環境下，TIME_WAIT 重用還是有風險的。</p><p>有些同學可能會混淆 tcp_tw_reuse 和 SO_REUSEADDR 選項，認為是相關的一個東西，其實他們是兩個完全不同的東西，可以說兩個半毛錢關係都沒。tcp_tw_reuse 是內核選項，而 SO_REUSEADDR 用戶態的選項，使用 SO_REUSEADDR 是告訴內核，如果端口忙，但 TCP 狀態位於 TIME_WAIT，可以重用端口。如果端口忙，而 TCP 狀態位於其他狀態，重用端口時依舊得到一個錯誤信息，指明 Address already in use”。如果你的服務程序停止後想立即重啟，而新套接字依舊使用同一端口，此時 SO_REUSEADDR 選項非常有用。但是，使用這個選項就會有(問題二、)中說的三點危險，雖然發生的概率不大。</p><h1><strong>五、清掉 TIME_WAIT 的奇技怪巧</strong></h1><p>可以用下面兩種方式控制服務器的 TIME_WAIT 數量：</p><p><strong>【1】修改 tcp_max_tw_buckets</strong></p><p>tcp_max_tw_buckets 控制併發的 TIME_WAIT 的數量，默認值是 180000。如果超過默認值，內核會把多的 TIME_WAIT 連接清掉，然後在日誌裡打一個警告。官網文檔說這個選項只是為了阻止一些簡單的 DoS 攻擊，平常不要人為的降低它。</p><p><strong>【2】利用 RST 包從外部清掉 TIME_WAIT 鏈接</strong></p><p>根據 TCP 規範，收到任何的發送到未偵聽端口、已經關閉的連接的數據包、連接處於任何非同步狀態（LISTEN,SYS-SENT,SYN-RECEIVED）並且收到的包的 ACK 在窗口外，或者安全層不匹配，都要回執以 RST 響應(而收到滑動窗口外的序列號的數據包，都要丟棄這個數據包，並回復一個 ACK 包)，內核收到 RST 將會產生一個錯誤並終止該連接。我們可以利用 RST 包來終止掉處於 TIME_WAIT 狀態的連接，其實這就是所謂的 RST 攻擊了。</p><p>為了描述方便：假設 Client 和 Server 有個連接 Connect1，Server 主動關閉連接並進入了 TIME_WAIT 狀態，我們來描述一下怎麼從外部使得 Server 的處於 TIME_WAIT 狀態的連接 Connect1 提前終止掉。要實現這個 RST 攻擊，首先我們要知道 Client 在 Connect1 中的端口 port1(一般這個端口是隨機的，比較難猜到，這也是 RST 攻擊較難的一個點)，利用 IP_TRANSPARENT 這個 socket 選項，它可以 bind 不屬於本地的地址，因此可以從任意機器綁定 Client 地址以及端口 port1，然後向 Server 發起一個連接，Server 收到了窗口外的包於是響應一個 ACK，這個 ACK 包會路由到 Client 處。</p><p>這個時候 99%的可能 Client 已經釋放連接 connect1 了，這個時候 Client 收到這個 ACK 包，會發送一個 RST 包，server 收到 RST 包然後就釋放連接 connect1 提前終止 TIME_WAIT 狀態了。提前終止 TIME_WAIT 狀態是可能會帶來(問題二)中說的三點危害，具體的危害情況可以看下 RFC1337。RFC1337 中建議，不要用 RST 過早的結束 TIME_WAIT 狀態。</p><p>至此，上面的疑症都解析完畢，然而細心的同學會有下面的疑問：</p><ul><li>TCP 的可靠傳輸是確認號來實現的，那麼 TCP 的確認機制是怎樣的呢？是收到一個包就馬上確認，還是可以稍等一下在確認呢？</li><li>假如發送一個包，一直都沒收到確認呢？什麼時候重傳呢？超時機制的怎樣的？</li><li>TCP 兩端 Peer 的處理能力不對等的時候，比如發送方處理能力很強，接收方處理能力很弱，這樣發送方是否能夠不管接收方死活狂發數據呢？如果不能，流量控制機制的如何的？</li><li>TCP 是端到端的協議，也就是 TCP 對端 Peer 只看到對方，看不到網絡上的其他點，那麼 TCP 的兩端怎麼對網絡情況做出反映呢？發生擁塞的時候，擁塞控制機制是如何的？</li></ul><h1><strong>疑症（7）TCP 的延遲確認機制</strong></h1><p>按照 TCP 協議，確認機制是累積的，也就是確認號 X 的確認指示的是所有 X 之前但不包括 X 的數據已經收到了。確認號(ACK)本身就是不含數據的分段，因此大量的確認號消耗了大量的帶寬，雖然大多數情況下，ACK 還是可以和數據一起捎帶傳輸的，但是如果沒有捎帶傳輸，那麼就只能單獨回來一個 ACK，如果這樣的分段太多，網絡的利用率就會下降。為緩解這個問題，RFC 建議了一種延遲的 ACK，也就是說，ACK 在收到數據後並不馬上回復，而是延遲一段可以接受的時間，延遲一段時間的目的是看能不能和接收方要發給發送方的數據一起回去，因為 TCP 協議頭中總是包含確認號的，如果能的話，就將數據一起捎帶回去，這樣網絡利用率就提高了。</p><p>延遲 ACK 就算沒有數據捎帶，那麼如果收到了按序的兩個包，那麼只要對第二包做確認即可，這樣也能省去一個 ACK 消耗。由於 TCP 協議不對 ACK 進行 ACK 的，RFC 建議最多等待 2 個包的積累確認，這樣能夠及時通知對端 Peer，我這邊的接收情況。Linux 實現中，有延遲 ACK 和快速 ACK，並根據當前的包的收發情況來在這兩種 ACK 中切換。一般情況下，ACK 並不會對網絡性能有太大的影響，延遲 ACK 能減少發送的分段從而節省了帶寬，而快速 ACK 能及時通知發送方丟包，避免滑動窗口停等，提升吞吐率。</p><p>關於 ACK 分段，有個細節需要說明一下，ACK 的確認號，是確認按序收到的最後一個字節序，對於亂序到來的 TCP 分段，接收端會回覆相同的 ACK 分段，只確認按序到達的最後一個 TCP 分段。TCP 連接的延遲確認時間一般初始化為最小值 40ms，隨後根據連接的重傳超時時間（RTO）、上次收到數據包與本次接收數據包的時間間隔等參數進行不斷調整。</p><h1><strong>疑症（8）TCP 的重傳機制以及重傳的超時計算</strong></h1><h1><strong>【1】TCP 的重傳超時計算</strong></h1><p>TCP 交互過程中，如果發送的包一直沒收到 ACK 確認，是要一直等下去嗎？顯然不能一直等(如果發送的包在路由過程中丟失了，對端都沒收到又如何給你發送確認呢？)，這樣協議將不可用，既然不能一直等下去，那麼該等多久呢？等太長時間的話，數據包都丟了很久了才重發，沒有效率，性能差；等太短時間的話，可能 ACK 還在路上快到了，這時候卻重傳了，造成浪費，同時過多的重傳會造成網絡擁塞，進一步加劇數據的丟失。也是，我們不能去猜測一個重傳超時時間，應該是通過一個算法去計算，並且這個超時時間應該是隨著網絡的狀況在變化的。為了使我們的重傳機制更高效，如果我們能夠比較準確知道在當前網絡狀況下，一個數據包從發出去到回來的時間 RTT——Round Trip Time，那麼根據這個 RTT 我們就可以方便設置 TimeOut——RTO（Retransmission TimeOut）了。</p><p>為了計算這個 RTO，RFC793 中定義了一個經典算法，算法如下：</p><p>[1] 首先採樣計算RTT值</p><p>[2] 然後計算平滑的RTT，稱為Smoothed Round Trip Time (SRTT)，SRTT = ( ALPHA * SRTT ) + ((1-ALPHA) * RTT)</p><p>[3] RTO = min[UBOUND,max[LBOUND,(BETA*SRTT)]]</p><p>其中：UBOUND 是 RTO 值的上限；例如：可以定義為 1 分鐘，LBOUND 是 RTO 值的下限，例如，可以定義為 1 秒；ALPHA is a smoothing factor (e.g., .8 to .9), and BETA is a delay variance factor(e.g., 1.3 to 2.0).</p><p>然而這個算法有個缺點就是：在算 RTT 樣本的時候，是用第一次發數據的時間和 ack 回來的時間做 RTT 樣本值，還是用重傳的時間和 ACK 回來的時間做 RTT 樣本值？不管是怎麼選擇，總會造成會要麼把 RTT 算過長了，要麼把 RTT 算過短了。如下圖：(a)就計算過長了，而(b)就是計算過短了。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p9.pstatp.com/large/pgc-image/6c0b22aa01244b4bb6220ca23e3d2634></div><p>針對上面經典算法的缺陷，於是提出 Karn / Partridge Algorithm 對經典算法進行了改進(算法大特點是——忽略重傳，不把重傳的 RTT 做採樣)，但是這個算法有問題：如果在某一時間，網絡閃動，突然變慢了，產生了比較大的延時，這個延時導致要重轉所有的包（因為之前的 RTO 很小），於是，因為重轉的不算，所以，RTO 就不會被更新，這是一個災難。於是，為解決上面兩個算法的問題，又有人推出來了一個新的算法，這個算法叫 Jacobson / Karels Algorithm（參看 FC6289），這個算法的核心是：除了考慮每兩次測量值的偏差之外，其變化率也應該考慮在內，如果變化率過大，則通過以變化率為自變量的函數為主計算 RTT(如果陡然增大，則取值為比較大的正數，如果陡然減小，則取值為比較小的負數，然後和平均值加權求和)，反之如果變化率很小，則取測量平均值。</p><p>公式如下：（其中的 DevRTT 是 Deviation RTT 的意思）</p><p>SRTT = SRTT + α (RTT – SRTT) —— 計算平滑RTT</p><p>DevRTT = (1-β)*DevRTT + β*(|RTT-SRTT|) ——計算平滑RTT和真實的差距（加權移動平均）</p><p>RTO= µ * SRTT + ∂ *DevRTT —— 神一樣的公式</p><p>（其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——這就是算法中的“調得一手好參數”，nobody knows why, it just works…） 最後的這個算法在被用在今天的TCP協議中並工作非常好</p><p>最後的這個算法在被用在今天的 TCP 協議中並工作非常好。</p><p>知道超時怎麼計算後，很自然就想到定時器的設計問題。一個簡單直觀的方案就是為 TCP 中的每一個數據包維護一個定時器，在這個定時器到期前沒收到確認，則進行重傳。這種設計理論上是很合理的，但是實現上，這種方案將會有非常多的定時器，會帶來巨大內存開銷和調度開銷。既然不能每個包一個定時器，那麼多少個包一個定時器才好呢，這個似乎比較難確定。可以換個思路，不要以包量來確定定時器，以連接來確定定時器會不會比較合理呢？目前，採取每一個 TCP 連接單一超時定時器的設計則成了一個默認的選擇，並且 RFC2988 給出了每連接單一定時器的設計建議算法規則：</p><p>[1].每一次一個包含數據的包被髮送（包括重發），如果還沒開啟重傳定時器，則開啟它，使得它在 RTO 秒之後超時（按照當前的 RTO 值）。[2]. 當接收到一個 ACK 確認一個新的數據；如果所有的發出數據都被確認了，關閉重傳定時器；[3].當接收到一個 ACK 確認一個新的數據，還有數據在傳輸，也就是還有沒被確認的數據，重新啟動重傳定時器，使得它在 RTO 秒之後超時（按照當前的 RTO 值）。</p><p>當重傳定時器超時後，依次做下列 3 件事情：[4.1]. 重傳最早的尚未被 TCP 接收方 ACK 的數據包；[4.2]. 重新設置 RTO 為 RTO *2（“還原定時器”），但是新 RTO 不應該超過 RTO 的上限(RTO 有個上限值，這個上限值最少為 60s)；[4.3]. 重啟重傳定時器。</p><p>上面的建議算法體現了一個原則：沒被確認的包必須可以超時，並且超時的時間不能太長，同時也不要過早重傳。規則[1][3][4.3]共同說明了只要還有數據包沒被確認，那麼定時器一定會是開啟著的(這樣滿足沒被確認的包必須可以超時的原則)。規則[4.2]說明定時器的超時值是有上限的(滿足超時的時間不能太長)。</p><p>規則[3]說明，在一個 ACK 到來後重置定時器可以保護後發的數據不被過早重傳；因為一個 ACK 到來了，說明後續的 ACK 很可能會依次到來，也就是說丟失的可能性並不大。規則[4.2]也是在一定程度上避免過早重傳，因為，在出現定時器超時後，有可能是網絡出現擁塞了，這個時候應該延長定時器，避免出現大量的重傳進一步加劇網絡的擁塞。</p><h1><strong>【2】TCP 的重傳機制</strong></h1><p>通過上面我們可以知道，TCP 的重傳是由超時觸發的，這會引發一個重傳選擇問題，假設 TCP 發送端連續發了 1、2、3、4、5、6、7、8、9、10 共 10 包，其中 4、6、8 這 3 個包全丟失了，由於 TCP 的 ACK 是確認最後連續收到序號，這樣發送端只能收到 3 號包的 ACK，這樣在 TIME_OUT 的時候，發送端就面臨下面兩個重傳選擇：[1].僅重傳 4 號包 [2].重傳 3 號後面所有的包，也就是重傳 4~10 號包</p><p>對於，上面兩個選擇的優缺點都比較明顯。方案[1]，優點：按需重傳，能夠最大程度節省帶寬。缺點：重傳會比較慢，因為重傳 4 號包後，需要等下一個超時才會重傳 6 號包。方案[2]，優點：重傳較快，數據能夠較快交付給接收端。缺點：重傳了很多不必要重傳的包，浪費帶寬，在出現丟包的時候，一般是網絡擁塞，大量的重傳又可能進一步加劇擁塞。</p><p>上面的問題是由於單純以時間驅動來進行重傳的，都必須等待一個超時時間，不能快速對當前網絡狀況做出響應，如果加入以數據驅動呢？TCP 引入了一種叫 Fast Retransmit(快速重傳)的算法，就是在連續收到 3 次相同確認號的 ACK，那麼就進行重傳。這個算法基於這麼一個假設，連續收到 3 個相同的 ACK，那麼說明當前的網絡狀況變好了，可以重傳丟失的包了。</p><p>快速重傳解決了 timeout 的問題，但是沒解決重傳一個還是重傳多個的問題。出現難以決定是否重傳多個包問題的根源在於，發送端不知道那些非連續序號的包已經到達接收端了，但是接收端是知道的，如果接收端告訴一下發送端不就可以解決這個問題嗎？於是，RFC2018 提出了 Selective Acknowledgment(SACK，選擇確認)機制，SACK 是 TCP 的擴展選項，包括(1)SACK 允許選項（Kind=4,Length=2，選項只允許在有 SYN 標誌的 TCP 包中），(2)SACK 信息選項 Kind=5,Length）。一個 SACK 的例子如下圖，紅框說明：接收端收到了 0-5500，8000-8500，7000-7500，6000-6500 的數據了，這樣發送端就可以選擇重傳丟失的 5500-6000，6500-7000，7500-8000 的包。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/01e470ad861c48b996be8b0d709f24b7></div><p>SACK 依靠接收端的接收情況反饋，解決了重傳風暴問題，這樣夠了嗎？接收端能不能反饋更多的信息呢？顯然是可以的，於是，RFC2883 對對 SACK 進行了擴展，提出了 D-SACK，也就是利用第一塊 SACK 數據中描述重複接收的不連續數據塊的序列號參數，其他 SACK 數據則描述其他正常接收到的不連續數據。這樣發送方利用第一塊 SACK，可以發現數據段被網絡複製、錯誤重傳、ACK 丟失引起的重傳、重傳超時等異常的網絡狀況，使得發送端能更好調整自己的重傳策略。D-SACK，有幾個優點：</p><p>1）發送端可以判斷出，是發包丟失了，還是接收端的 ACK 丟失了。(發送方，重傳了一個包，發現並沒有 D-SACK 那個包，那麼就是發送的數據包丟了；否則就是接收端的 ACK 丟了，或者是發送的包延遲到達了)；2）發送端可以判斷自己的 RTO 是不是有點小了，導致過早重傳(如果收到比較多的 D-SACK 就該懷疑是 RTO 小了)；3）發送端可以判斷自己的數據包是不是被複制了。(如果明明沒有重傳該數據包，但是收到該數據包的 D-SACK)；4）發送端可以判斷目前網絡上是不是出現了有些包被 delay 了，也就是出現先發的包卻後到了。</p><h1><strong>疑症（9）TCP 的流量控制</strong></h1><p>我們知道 TCP 的窗口(window)是一個 16bit 位字段，它代表的是窗口的字節容量，也就是 TCP 的標準窗口最大為 2^16-1=65535 個字節。另外在 TCP 的選項字段中還包含了一個 TCP 窗口擴大因子，option-kind 為 3，option-length 為 3 個字節，option-data 取值範圍 0-14。窗口擴大因子用來擴大 TCP 窗口，可把原來 16bit 的窗口，擴大為 31bit。</p><p>這個窗口是接收端告訴發送端自己還有多少緩衝區可以接收數據。於是發送端就可以根據這個接收端的處理能力來發送數據，而不會導致接收端處理不過來。也就是，發送端是根據接收端通知的窗口大小來調整自己的發送速率的，以達到端到端的流量控制。儘管流量控制看起來簡單明瞭，就是發送端根據接收端的限制來控制自己的發送就好了，但是細心的同學還是會有些疑問的。</p><p>1）發送端是怎麼做到比較方便知道自己哪些包可以發，哪些包不能發呢？2）如果接收端通知一個零窗口給發送端，這個時候發送端還能不能發送數據呢？如果不發數據，那一直等接收端口通知一個非 0 窗口嗎，如果接收端一直不通知呢？3）如果接收端處理能力很慢，這樣接收端的窗口很快被填滿，然後接收處理完幾個字節，騰出幾個字節的窗口後，通知發送端，這個時候發送端馬上就發送幾個字節給接收端嗎？發送的話會不會太浪費了，就像一艘萬噸油輪只裝上幾斤的油就開去目的地一樣。對於發送端產生數據的能力很弱也一樣，如果發送端慢吞吞產生幾個字節的數據要發送，這個時候該不該立即發送呢？還是累積多點在發送？</p><h1><strong>疑問 1）的解決:</strong></h1><p>發送方要知道那些可以發，哪些不可以發，一個簡明的方案就是按照接收方的窗口通告，發送方維護一個一樣大小的發送窗口就可以了，在窗口內的可以發，窗口外的不可以發，窗口在發送序列上不斷後移，這就是 TCP 中的滑動窗口。如下圖所示，對於 TCP 發送端其發送緩存內的數據都可以分為 4 類：[1]-已經發送並得到接收端 ACK 的；[2]-已經發送但還未收到接收端 ACK 的；[3]-未發送但允許發送的(接收方還有空間)；[4]-未發送且不允許發送(接收方沒空間了)。</p><p>其中，[2]和[3]兩部分合起來稱之為發送窗口。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/7332ee8648c949c7a3db087fe6838aa2></div><p>下面兩圖演示的窗口的滑動情況，收到 36 的 ACK 後，窗口向後滑動 5 個 byte。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/6e1de9d67edf495c8de60f03f2c761f2></div><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ca0404ce676f417bbdb82f765628a4a3></div><h1><strong>疑問 2）的解決</strong></h1><p>由問題 1）我們知道，發送端的發送窗口是由接收端控制的。下圖，展示了一個發送端是怎麼受接收端控制的。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/6520e885ef584571b0fa8834798a28f5></div><p>由上圖我們知道，當接收端通知一個 zero 窗口的時候，發送端的發送窗口也變成了 0，也就是發送端不能發數據了。如果發送端一直等待，直到接收端通知一個非零窗口在發數據的話，這似乎太受限於接收端，如果接收端一直不通知新的窗口呢？顯然發送端不能幹等，起碼有一個主動探測的機制。為解決 0 窗口的問題，TCP 使用了 Zero Window Probe 技術，縮寫為 ZWP。發送端在窗口變成 0 後，會發 ZWP 的包給接收方，來探測目前接收端的窗口大小，一般這個值會設置成 3 次，每次大約 30-60 秒（不同的實現可能會不一樣）。</p><p>如果 3 次過後還是 0 的話，有的 TCP 實現就會發 RST 掉這個連接。正如有人的地方就會有商機，那麼有等待的地方就很有可能出現 DDoS 攻擊點。攻擊者可以在和 Server 建立好連接後，就向 Server 通告一個 0 窗口，然後 Server 端就只能等待進行 ZWP，於是攻擊者會併發大量的這樣的請求，把 Server 端的資源耗盡。</p><h1><strong>疑問點 3）的解決</strong></h1><p>疑點 3）本質就是一個避免發送大量小包的問題。造成這個問題原因有二：</p><p>1)接收端一直在通知一個小的窗口；2)發送端本身問題，一直在發送小包。這個問題，TCP 中有個術語叫 Silly Window Syndrome(糊塗窗口綜合症)。</p><p>解決這個問題的思路有兩種，1)接收端不通知小窗口，2)發送端積累一下數據在發送。</p><p>思路 1)是在接收端解決這個問題，David D Clark’s 方案，如果收到的數據導致 window size 小於某個值，就 ACK 一個 0 窗口，這就阻止發送端在發數據過來。等到接收端處理了一些數據後 windows size 大於等於了 MSS，或者 buffer 有一半為空，就可以通告一個非 0 窗口。</p><p>思路 2)是在發送端解決這個問題，有個著名的 Nagle’s algorithm。Nagle 算法的規則：[1]如果包長度達到 MSS ，則允許發送；[2]如果該包含有 FIN ，則允許發送；[3]設置了 TCP_NODELAY 選項，則允許發送；[4]設置 TCP_CORK 選項時，若所有發出去的小數據包（包長度小於 MSS）均被確認，則允許發送；[5]上述條件都未滿足，但發生了超時（一般為 200ms ），則立即發送。</p><p>規則[4]指出 TCP 連接上最多只能有一個未被確認的小數據包。從規則[4]可以看出 Nagle 算法並不禁止發送小的數據包(超時時間內)，而是避免發送大量小的數據包。由於 Nagle 算法是依賴 ACK 的，如果 ACK 很快的話，也會出現一直髮小包的情況，造成網絡利用率低。TCP_CORK 選項則是禁止發送小的數據包(超時時間內)，設置該選項後，TCP 會盡力把小數據包拼接成一個大的數據包（一個 MTU）再發送出去，當然也不會一直等，發生了超時（一般為 200ms），也立即發送。Nagle 算法和 CP_CORK 選項提高了網絡的利用率，但是增加是延時。從規則[3]可以看出，設置 TCP_NODELAY 選項，就是完全禁用 Nagle 算法了。</p><p>這裡要說一個小插曲，Nagle 算法和延遲確認(Delayed Acknoledgement)一起，當出現(write-write-read)的時候會引發一個 40ms 的延時問題，這個問題在 HTTP svr 中體現的比較明顯。場景如下：</p><p>客戶端在請求下載 HTTP svr 中的一個小文件，一般情況下，HTTP svr 都是先發送 HTTP 響應頭部，然後在發送 HTTP 響應 BODY(特別是比較多的實現在發送文件的實施採用的是 sendfile 系統調用，這就出現 write-write-read 模式了)。當發送頭部的時候，由於頭部較小，於是形成一個小的 TCP 包發送到客戶端，這個時候開始發送 body，由於 body 也較小，這樣還是形成一個小的 TCP 數據包，根據 Nagle 算法，HTTP svr 已經發送一個小的數據包了，在收到第一個小包的 ACK 後或等待 200ms 超時後才能在發小包，HTTP svr 不能發送這個 body 小 TCP 包。</p><p>客戶端收到 http 響應頭後，由於這是一個小的 TCP 包，於是客戶端開啟延遲確認，客戶端在等待 Svr 的第二個包來在一起確認或等待一個超時(一般是 40ms)在發送 ACK 包；這樣就出現了你等我、然而我也在等你的死鎖狀態，於是出現最多的情況是客戶端等待一個 40ms 的超時，然後發送 ACK 給 HTTP svr，HTTP svr 收到 ACK 包後再發送 body 部分。大家在測 HTTP svr 的時候就要留意這個問題了。</p><h1><strong>疑症（10）TCP 的擁塞控制</strong></h1><p>談到擁塞控制，就要先談談擁塞的因素和本質。本質上，網絡上擁塞的原因就是大家都想獨享整個網絡資源，對於 TCP，端到端的流量控制必然會導致網絡擁堵。這是因為 TCP 只看到對端的接收空間的大小，而無法知道鏈路上的容量，只要雙方的處理能力很強，那麼就可以以很大的速率發包，於是鏈路很快出現擁堵，進而引起大量的丟包，丟包又引發發送端的重傳風暴，進一步加劇鏈路的擁塞。</p><p>另外一個擁塞的因素是鏈路上的轉發節點，例如路由器，再好的路由器只要接入網絡，總是會拉低網絡的總帶寬，如果在路由器節點上出現處理瓶頸，那麼就很容易出現擁塞。由於 TCP 看不到網絡的狀況，那麼擁塞控制是必須的並且需要採用試探性的方式來控制擁塞，於是擁塞控制要完成兩個任務：[1]公平性；[2]擁塞過後的恢復。</p><p>TCP 發展到現在，擁塞控制方面的算法很多，其中 Reno 是目前應用最廣泛且較為成熟的算法，下面著重介紹一下 Reno 算法(RFC5681)。介紹該算法前，首先介紹一個概念 duplicate acknowledgment(冗餘 ACK、重複 ACK)一般情況下一個 ACK 被稱為冗餘 ACK，要同時滿足下面幾個條件(對於 SACK，那麼根據 SACK 的一些信息來進一步判斷)。</p><p>[1] 接收 ACK 的那端已經發出了一些還沒被 ACK 的數據包；[2] 該 ACK 沒有捎帶 data；[3] 該 ACK 的 SYN 和 FIN 位都是 off 的，也就是既不是 SYN 包的 ACK 也不是 FIN 包的 ACK；[4] 該 ACK 的確認號等於接收 ACK 那端已經收到的 ACK 的最大確認號；[5] 該 ACK 通知的窗口等接收該 ACK 的那端上一個收到的 ACK 的窗口。</p><p>Reno 算法包含 4 個部分：[1]慢熱啟動算法 – Slow Start；[2]擁塞避免算法 – Congestion Avoidance；[3]快速重傳 - Fast Retransimit；[4]快速恢復算法 – Fast Recovery。</p><p>TCP 的擁塞控制主要原理依賴於一個擁塞窗口(cwnd)來控制，根據前面的討論，我們知道有一個接收端通告的接收窗口(rwnd)用於流量控制；加上擁塞控制後，發送端真正的發送窗口=min(rwnd,cwnd)。關於 cwnd 的單位，在 TCP 中是以字節來做單位的，我們假設 TCP 每次傳輸都是按照 MSS 大小來發送數據，因此你可以認為 cwnd 按照數據包個數來做單位也可以理解，下面如果沒有特別說明是字節，那麼 cwnd 增加 1 也就是相當於字節數增加 1 個 MSS 大小。</p><h1><strong>【1】慢熱啟動算法 – Slow Start</strong></h1><p>慢啟動體現了一個試探的過程，剛接入網絡的時候先發包慢點，探測一下網絡情況，然後在慢慢提速。不要一上來就拼命發包，這樣很容易造成鏈路的擁堵，出現擁堵了在想到要降速來緩解擁堵這就有點成本高了，畢竟無數的先例告誡我們先汙染後治理的成本是很高的。慢啟動的算法如下(cwnd 全稱 Congestion Window)：1）連接建好的開始先初始化 cwnd = N，表明可以傳 N 個 MSS 大小的數據；2）每當收到一個 ACK，++cwnd; 呈線性上升；3）每當過了一個 RTT，cwnd = cwnd*2; 呈指數上升；4）還有一個慢啟動門限 ssthresh（slow start threshold），是一個上限，當 cwnd >= ssthresh 時，就會進入"擁塞避免算法 - Congestion Avoidance"。</p><p>根據 RFC5681，如果 MSS > 2190 bytes，則 N = 2;如果 MSS &lt; 1095 bytes，則 N =4;如果 2190 bytes >= MSS >= 1095 bytes，則 N = 3;一篇 Google 的論文《An Argument for Increasing TCP’s Initial Congestion Window》建議把 cwnd 初始化成了 10 個 MSS。Linux 3.0 後採用了這篇論文的建議。</p><h1><strong>【2】擁塞避免算法 – Congestion Avoidance</strong></h1><p>慢啟動的時候說過，cwnd 是指數快速增長的，但是增長是有個門限 ssthresh(一般來說大多數的實現 ssthresh 的值是 65535 字節)的，到達門限後進入擁塞避免階段。在進入擁塞避免階段後，cwnd 值變化算法如下：1）每收到一個 ACK，調整 cwnd 為 (cwnd + 1/cwnd) * MSS 個字節；2）每經過一個 RTT 的時長，cwnd 增加 1 個 MSS 大小。</p><p>TCP 是看不到網絡的整體狀況的，那麼 TCP 認為網絡擁塞的主要依據是它重傳了報文段。前面我們說過 TCP 的重傳分兩種情況：1）出現 RTO 超時，重傳數據包。這種情況下，TCP 就認為出現擁塞的可能性就很大，於是它反應非常'強烈' [1] 調整門限 ssthresh 的值為當前 cwnd 值的 1/2；[2] reset 自己的 cwnd 值為 1；[3] 然後重新進入慢啟動過程。</p><p>2）在 RTO 超時前，收到 3 個 duplicate ACK 進行重傳數據包。這種情況下，收到 3 個冗餘 ACK 後說明確實有中間的分段丟失，然而後面的分段確實到達了接收端，因為這樣才會發送冗餘 ACK，這一般是路由器故障或者輕度擁塞或者其它不太嚴重的原因引起的，因此此時擁塞窗口縮小的幅度就不能太大，此時進入快速重傳。</p><h1><strong>【3】快速重傳 - Fast Retransimit 做的事情有：</strong></h1><p>1） 調整門限 ssthresh 的值為當前 cwnd 值的 1/2；2） 將 cwnd 值設置為新的 ssthresh 的值；3） 重新進入擁塞避免階段。</p><p>在快速重傳的時候，一般網絡只是輕微擁堵，在進入擁塞避免後，cwnd 恢復的比較慢。針對這個，“快速恢復”算法被添加進來，當收到 3 個冗餘 ACK 時，TCP 最後的[3]步驟進入的不是擁塞避免階段，而是快速恢復階段。</p><h1><strong>【4】快速恢復算法 – Fast Recovery ：</strong></h1><p>快速恢復的思想是“數據包守恆”原則，即帶寬不變的情況下，在網絡同一時刻能容納數據包數量是恆定的。當“老”數據包離開了網絡後，就能向網絡中發送一個“新”的數據包。既然已經收到了 3 個冗餘 ACK，說明有三個數據分段已經到達了接收端，既然三個分段已經離開了網絡，那麼就是說可以在發送 3 個分段了。</p><p>於是只要發送方收到一個冗餘的 ACK，於是 cwnd 加 1 個 MSS。快速恢復步驟如下(在進入快速恢復前，cwnd 和 sshthresh 已被更新為：sshthresh = cwnd /2，cwnd = sshthresh)：1）把 cwnd 設置為 ssthresh 的值加 3，重傳 Duplicated ACKs 指定的數據包；2）如果再收到 duplicated Acks，那麼 cwnd = cwnd +1；3）如果收到新的 ACK，而非 duplicated Ack，那麼將 cwnd 重新設置為【3】中 1）的 sshthresh 的值。然後進入擁塞避免狀態。</p><p>細心的同學可能會發現快速恢復有個比較明顯的缺陷就是：它依賴於 3 個冗餘 ACK，並假定很多情況下，3 個冗餘的 ACK 只代表丟失一個包。但是 3 個冗餘 ACK 也很有可能是丟失了很多個包，快速恢復只是重傳了一個包，然後其他丟失的包就只能等待到 RTO 超時了。超時會導致 ssthresh 減半，並且退出了 Fast Recovery 階段，多個超時會導致 TCP 傳輸速率呈級數下降。出現這個問題的主要原因是過早退出了 Fast Recovery 階段。</p><p>為解決這個問題，提出了 New Reno 算法，該算法是在沒有 SACK 的支持下改進 Fast Recovery 算法(SACK 改變 TCP 的確認機制，把亂序等信息會全部告訴對方，SACK 本身攜帶的信息就可以使得發送方有足夠的信息來知道需要重傳哪些包，而不需要重傳哪些包)，具體改進如下：</p><p>1）發送端收到 3 個冗餘 ACK 後，重傳冗餘 ACK 指示可能丟失的那個包 segment1，如果 segment1 的 ACK 通告接收端已經收到發送端的全部已經發出的數據的話，那麼就是隻丟失一個包，如果沒有，那麼就是有多個包丟失了；2）發送端根據 segment1 的 ACK 判斷出有多個包丟失，那麼發送端繼續重傳窗口內未被 ACK 的第一個包，直到 sliding window 內發出去的包全被 ACK 了，才真正退出 Fast Recovery 階段。</p><p>我們可以看到，擁塞控制在擁塞避免階段，cwnd 是加性增加的，在判斷出現擁塞的時候採取的是指數遞減。為什麼要這樣做呢？這是出於公平性的原則，擁塞窗口的增加受惠的只是自己，而擁塞窗口減少受益的是大家。這種指數遞減的方式實現了公平性，一旦出現丟包，那麼立即減半退避，可以給其他新建的連接騰出足夠的帶寬空間，從而保證整個的公平性。</p><p>至此，TCP 的疑難雜症基本介紹完畢了，總的來說 TCP 是一個有連接的、可靠的、帶流量控制和擁塞控制的端到端的協議。TCP 的發送端能發多少數據，由發送端的發送窗口決定(當然發送窗口又被接收端的接收窗口、發送端的擁塞窗口限制)的，那麼一個 TCP 連接的傳輸穩定狀態應該體現在發送端的發送窗口的穩定狀態上，這樣的話，TCP 的發送窗口有哪些穩定狀態呢？TCP 的發送窗口穩定狀態主要有上面三種穩定狀態：</p><h1><strong>【1】接收端擁有大窗口的經典鋸齒狀</strong></h1><p>大多數情況下都是處於這樣的穩定狀態，這是因為，一般情況下機器的處理速度就是比較快，這樣 TCP 的接收端都是擁有較大的窗口，這時發送端的發送窗口就完全由其擁塞窗口 cwnd 決定了；網絡上擁有成千上萬的 TCP 連接，它們在相互爭用網絡帶寬，TCP 的流量控制使得它想要獨享整個網絡，而擁塞控制又限制其必要時做出犧牲來體現公平性。於是在傳輸穩定的時候 TCP 發送端呈現出下面過程的反覆：</p><p>[1]用慢啟動或者擁塞避免方式不斷增加其擁塞窗口，直到丟包的發生；[2]然後將發送窗口將下降到 1 或者下降一半，進入慢啟動或者擁塞避免階段(要看是由於超時丟包還是由於冗餘 ACK 丟包)；過程如下圖：</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/d951c8bb2f1e45eea8bd638803ecba53></div><h1><strong>【2】接收端擁有小窗口的直線狀態</strong></h1><p>這種情況下是接收端非常慢速，接收窗口一直很小，這樣發送窗口就完全有接收窗口決定了。由於發送窗口小，發送數據少，網絡就不會出現擁塞了，於是發送窗口就一直穩定的等於那個較小的接收窗口，呈直線狀態。</p><h1><strong>【3】兩個直連網絡端點間的滿載狀態下的直線狀態</strong></h1><p>這種情況下，Peer 兩端直連，並且只有位於一個 TCP 連接，那麼這個連接將獨享網絡帶寬，這裡不存在擁塞問題，在他們處理能力足夠的情況下，TCP 的流量控制使得他們能夠跑慢整個網絡帶寬。</p><p>通過上面我們知道，在 TCP 傳輸穩定的時候，各個 TCP 連接會均分網絡帶寬的。相信大家學生時代經常會發生這樣的場景，自己在看視頻的時候突然出現視頻卡頓，於是就大叫起來，哪個開了迅雷，趕緊給我停了。其實簡單的下載加速就是開啟多個 TCP 連接來分段下載就達到加速的效果，假設宿舍的帶寬是 1000K/s，一開始兩個在看視頻，每人平均網速是 500k/s，這速度看起視頻來那叫一個順溜。突然其中一個同學打打開迅雷開著 99 個 TCP 連接在下載愛情動作片，這個時候平均下來你能分到的帶寬就剩下 10k/s，這網速下你的視頻還不卡成幻燈片。</p><p>在通信鏈路帶寬固定(假設為 W)，多人公用一個網絡帶寬的情況下，利用 TCP 協議的擁塞控制的公平性，多開幾個 TCP 連接就能多分到一些帶寬(當然要忽略有些用 UDP 協議帶來的影響)，然而不管怎麼最多也就能把整個帶寬搶到，於是在佔滿整個帶寬的情況下，下載一個大小為 FS 的文件，那麼最快需要的時間是 FS/W，難道就沒辦法加速了嗎？</p><p>答案是有的，這樣因為網絡是網狀的，一個節點是要和很多幾點互聯的，這就存在多個帶寬為 W 的通信鏈路，如果我們能夠將要下載的文件，一半從 A 通信鏈路下載，另外一半從 B 通信鏈路下載，這樣整個下載時間就減半了為 FS/(2W)，這就是 p2p 加速。相信大家學生時代在下載愛情動作片的時候也遇到過這種情況，明明外網速度沒這麼快的，自己下載的愛情動作片的速度卻達到幾 M/s，那是因為，你的左後或右後的宿友在幫你加速中。我們都知道 P2P 模式下載會快，並且越多人下載就越快，那麼問題來了，P2P 下載加速理論上的加速比是多少呢？</p><h1><strong>11.附加題 1：P2P 理論上的加速比</strong></h1><p>傳統的 C/S 模式傳輸文件，在跑滿 Client 帶寬的情況下傳輸一個文件需要耗時 FS/BW，如果有 n 個客戶端需要下載文件，那麼總耗時是 n*(FS/BW)，當然啦，這並不一定是串行傳輸，可以並行來傳輸的，這樣總耗時也就是 FS/BW 了，但是這需要服務器的帶寬是 n 個 client 帶寬的總和 n*BW。C/S 模式一個明顯的缺點是服務要傳輸一個文件 n 次，這樣對服務器的性能和帶寬帶來比較大的壓力，我可以換下思路，服務器將文件傳給其中一個 Client 後，讓這些互聯的 Client 自己來交互那個文件，那服務器的壓力就減少很多了。這就是 P2P 網絡的好處，P2P 利用各個節點間的互聯，提倡“人人為我，我為人人”。</p><p>知道 P2P 傳輸的好處後，我們來談下理論上的最大加速比，為了簡化討論，一個簡單的網絡拓撲圖如下，有 4 個相互互聯的節點，並且每個節點間的網絡帶寬是 BW，傳輸一個大小為 FS 的文件最快的時間是多少呢？假設節點 N1 有個大小為 FS 的文件需要傳輸給 N2，N3，N4 節點，一種簡單的方式就是：節點 N1 同時將文件傳輸給節點 N2，N3，N4 耗時 FS/BW，這樣大家都擁有文件 FS 了。大家可以看出，整個過程只有節點 1 在發送文件，其他節點都是在接收，完全違反了 P2P 的“人人為我，我為人人”的宗旨。那怎麼才能讓大家都做出貢獻了呢？解決方案是切割文件。</p><p>[1]首先，節點 N1 文件分成 3 個片段 FS2,FS3,FS4，接著將 FS2 發送給 N2，FS3 發送給 N3，FS4 發送給 N4，耗時 FS/(3*BW)；[2]然後，N2,N3,N4 執行“人人為我，我為人人”的精神，將自己擁有的 F2,F3,F4 分別發給沒有的其他的節點，這樣耗時 FS/(3*BW)完成交換。</p><p>於是總耗時為 2FS/(3BW)完成了文件 FS 的傳輸，可以看出耗時減少為原來的 2/3 了，如果有 n 個節點，那麼時間就是原來的 2/(n-1)，也就是加速比是 2/(n-1)，這就是加速的理論上限了嗎？還沒發揮最多能量的，相信大家已經看到分割文件的好處了，上面的文件分割粒度還是有點大，以至於，在第二階段[2]傳輸過程中，節點 N1 無所事事。為了最大化發揮大家的作用，我們需要將 FS2,FS3,FS4 在進行分割，假設將它們都均分為 K 等份，這樣就有 FS21,FS22…FS2K、FS31,FS32…FS3K、FS41,FS42…FS4K，一共 3K 個分段。於是下面就開始進行加速分發：</p><p>[1]節點 N1 將分段 FS21，FS31，FS41 分別發送給 N2，N3，N4 節點。耗時，FS/(3K*BW) [2]節點 N1 將分段 FS22，FS32，FS42 分別發送給 N2，N3，N4 節點，同時節點 N2，N3，N4 將階段[1]收到的分段相互發給沒有的節點。耗時，FS/(3K*BW)。</p><p>[K]節點 N1 將分段 FS2K，FS3K，FS4K 分別發送給 N2，N3，N4 節點，同時節點 N2，N3，N4 將階段[K-1]收到的分段相互發給沒有的節點。耗時，FS/(3K*BW)。[K+1]節點 N2，N3，N4 將階段[K]收到的分段相互發給沒有的節點。耗時，FS/(3K*BW)。於是總的耗時為(K+1) (FS/(3KBW)) = FS/(3BW) +FS/(3KBW)，當 K 趨於無窮大的時候，文件進行無限細分的時候，耗時變成了 FS/(3*BW)，也就是當節點是 n+1 的時候，加速比是 n。這就是理論上的最大加速比了，最大加速比是 P2P 網絡節點個數減 1。</p><div class=pgc-img><img alt=萬字詳文徹底弄懂TCP協議：從三次握手和四次揮手說起 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/ebf9a0b757c34d058abc072195db10d2></div><h1><strong>12.附加題 2：系統調用 listen() 的 backlog 參數指的是什麼</strong></h1><p>要說明 backlog 參數的含義，首先需要說一下 Linux 的協議棧維護的 TCP 連接的兩個連接隊列：[1]SYN 半連接隊列；[2]accept 連接隊列。</p><p>[1]SYN 半連接隊列：Server 端收到 Client 的 SYN 包並回復 SYN,ACK 包後，該連接的信息就會被移到一個隊列，這個隊列就是 SYN 半連接隊列(此時 TCP 連接處於 非同步狀態 )</p><p>[2]accept 連接隊列：Server 端收到 SYN,ACK 包的 ACK 包後，就會將連接信息從[1]中的隊列移到另外一個隊列，這個隊列就是 accept 連接隊列(這個時候 TCP 連接已經建立，三次握手完成了)。</p><p>用戶進程調用 accept()系統調用後，該連接信息就會從[2]中的隊列中移走。相信不少同學就 backlog 的具體含義進行爭論過，有些認為 backlog 指的是[1]和[2]兩個隊列的和。而有些則認為是 backlog 指的是[2]的大小。其實，這兩個說法都對，在 linux kernel 2.2 之前 backlog 指的是[1]和[2]兩個隊列的和。而 2.2 以後，就指的是[2]的大小，那麼在 kernel 2.2 以後，[1]的大小怎麼確定的呢？兩個隊列的作用分別是什麼呢？</p><h1><strong>【1】SYN 半連接隊列的作用</strong></h1><p>對於 SYN 半連接隊列的大小是由（/proc/sys/net/ipv4/tcp_max_syn_backlog）這個內核參數控制的，有些內核似乎也受 listen 的 backlog 參數影響，取得是兩個值的最小值。當這個隊列滿了，Server 會丟棄新來的 SYN 包，而 Client 端在多次重發 SYN 包得不到響應而返回（connection time out）錯誤。但是，當 Server 端開啟了 syncookies，那麼 SYN 半連接隊列就沒有邏輯上的最大值了，並且/proc/sys/net/ipv4/tcp_max_syn_backlog 設置的值也會被忽略。</p><h1><strong>【2】accept 連接隊列</strong></h1><p>accept 連接隊列的大小是由 backlog 參數和（/proc/sys/net/core/somaxconn）內核參數共同決定，取值為兩個中的最小值。當 accept 連接隊列滿了，協議棧的行為根據（/proc/sys/net/ipv4/tcp_abort_on_overflow）內核參數而定。如果 tcp_abort_on_overflow=1，server 在收到 SYN_ACK 的 ACK 包後，協議棧會丟棄該連接並回復 RST 包給對端，這個是 Client 會出現(connection reset by peer)錯誤。如果 tcp_abort_on_overflow=0，server 在收到 SYN_ACK 的 ACK 包後，直接丟棄該 ACK 包。這個時候 Client 認為連接已經建立了，一直在等 Server 的數據，直到超時出現 read timeout 錯誤。</p><p><strong>參考資料</strong></p><p><strong>http://blog.csdn.net/dog250/article/details/6612496</strong></p><p>http://coolshell.cn/articles/11564.html</p><p><strong>http://coolshell.cn/articles/11609.html</strong></p><p><strong>http://www.tcpipguide.com/free/t_TCPMessageSegmentFormat.html</strong></p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>萬字</a></li><li><a>詳文</a></li><li><a>徹底</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/0cdba029.html alt=C++｜徹底弄清偽隨機數與隨機數 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0cdba029.html title=C++｜徹底弄清偽隨機數與隨機數>C++｜徹底弄清偽隨機數與隨機數</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2e1ceb0.html alt="縱橫談｜徹底清除基層治理中的'灰色手段'" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2e1ceb0.html title="縱橫談｜徹底清除基層治理中的'灰色手段'">縱橫談｜徹底清除基層治理中的'灰色手段'</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bd423c48.html alt=口罩產業鏈徹底亂了！丙烯週末瘋狂上漲，價格兩日翻倍，PP期價暴力拉昇；多廠家發緊急聲明…… class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/Rw0qyU6Ao0YcN0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bd423c48.html title=口罩產業鏈徹底亂了！丙烯週末瘋狂上漲，價格兩日翻倍，PP期價暴力拉昇；多廠家發緊急聲明……>口罩產業鏈徹底亂了！丙烯週末瘋狂上漲，價格兩日翻倍，PP期價暴力拉昇；多廠家發緊急聲明……</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/4a687640.html alt=寶興縣開展“徹底清理層層加碼、堅決真切為基層減負”專項行動 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/4a687640.html title=寶興縣開展“徹底清理層層加碼、堅決真切為基層減負”專項行動>寶興縣開展“徹底清理層層加碼、堅決真切為基層減負”專項行動</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d451ce4.html alt=熔斷14次！房多多徹底撕開房產平臺暗傷 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/0fa1fe78f52a407186f92787addf5ae3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d451ce4.html title=熔斷14次！房多多徹底撕開房產平臺暗傷>熔斷14次！房多多徹底撕開房產平臺暗傷</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c78b6d52.html alt=8分鐘看完，徹底掌握Java正則表達式的十大問題 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/14ae145d-0620-476a-8a82-7912b192e9b5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c78b6d52.html title=8分鐘看完，徹底掌握Java正則表達式的十大問題>8分鐘看完，徹底掌握Java正則表達式的十大問題</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/006333f2.html alt=一篇文讓你徹底瞭解java多線程併發 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/fbdb8be32a094b448c052c5058d1d2f2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/006333f2.html title=一篇文讓你徹底瞭解java多線程併發>一篇文讓你徹底瞭解java多線程併發</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6c172832.html alt=一文徹底掌握二叉查找樹，（多組動圖）史上最全總結 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/f9d23b4550d741b8b8c0a156d712f69d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6c172832.html title=一文徹底掌握二叉查找樹，（多組動圖）史上最全總結>一文徹底掌握二叉查找樹，（多組動圖）史上最全總結</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bedd02a9.html alt=Access徹底隱藏表顯示錶 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/3b0200038f286f1db52e style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bedd02a9.html title=Access徹底隱藏表顯示錶>Access徹底隱藏表顯示錶</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6c0c417f.html alt=粉絲徹底怒了，T1大樓被緊急關閉！你們不配擁有Faker class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/3522a4f2aeeb479bbc5a1b3a8580232a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6c0c417f.html title=粉絲徹底怒了，T1大樓被緊急關閉！你們不配擁有Faker>粉絲徹底怒了，T1大樓被緊急關閉！你們不配擁有Faker</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/c85ab63d.html alt=依靠立法徹底解決二手菸問題？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/02cea07b-7716-45f3-b9a5-efe0f9dd9498 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/c85ab63d.html title=依靠立法徹底解決二手菸問題？>依靠立法徹底解決二手菸問題？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d258b9eb.html alt="徹底凍結Android 應用後臺活動 讓他們不耗電、不聯網、不啟動" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/e4fd87bc-b2e5-40e2-841d-2e3dc5f9a2b9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d258b9eb.html title="徹底凍結Android 應用後臺活動 讓他們不耗電、不聯網、不啟動">徹底凍結Android 應用後臺活動 讓他們不耗電、不聯網、不啟動</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/46ff8566.html alt=輸入主題就能生成萬字文章？解密狗屁不通文章生成器！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/c2383ec46acf4ed5aec149441b42dea8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/46ff8566.html title=輸入主題就能生成萬字文章？解密狗屁不通文章生成器！>輸入主題就能生成萬字文章？解密狗屁不通文章生成器！</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/89977530.html alt=一鍵生成文章，徹底告別討厭的形式主義 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/191fe4c4beb143b3b81d5ee01a5d10d9 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/89977530.html title=一鍵生成文章，徹底告別討厭的形式主義>一鍵生成文章，徹底告別討厭的形式主義</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/37854077.html alt=文章自動生成器！徹底告別形式主義 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/827d0970b0af4527a6834c4e048a85d0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/37854077.html title=文章自動生成器！徹底告別形式主義>文章自動生成器！徹底告別形式主義</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>