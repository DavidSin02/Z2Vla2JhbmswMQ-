<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>深入理解GBDT多分類算法 | 极客快訊</title><meta property="og:title" content="深入理解GBDT多分類算法 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p1.pstatp.com/large/pgc-image/22b3a5a1b5784d34b3e60fbd556fbbe9"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/f969fea9.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/f969fea9.html><meta property="article:published_time" content="2020-10-29T21:12:41+08:00"><meta property="article:modified_time" content="2020-10-29T21:12:41+08:00"><meta name=Keywords content><meta name=description content="深入理解GBDT多分類算法"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/f969fea9.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>深入理解GBDT多分類算法</h1></header><date class="post-meta meta-date">2020-10-29</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><p>目錄：</p><ol start=1><li>GBDT多分類算法1.1 Softmax迴歸的對數損失函數1.2 GBDT多分類原理</li><li>GBDT多分類算法實例</li><li>手撕GBDT多分類算法3.1 用Python3實現GBDT多分類算法3.2 用sklearn實現GBDT多分類算法</li><li>總結</li><li>Reference</li></ol><h4 class=pgc-h-arrow-right>本文的主要內容概覽：</h4><div class=pgc-img><img alt=深入理解GBDT多分類算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/22b3a5a1b5784d34b3e60fbd556fbbe9><p class=pgc-img-caption></p></div><h2 class=pgc-h-arrow-right>1. GBDT多分類算法</h2><h2 class=pgc-h-arrow-right>1.1 Softmax迴歸的對數損失函數</h2><p>當使用邏輯迴歸處理多標籤的分類問題時，如果一個樣本只對應於一個標籤，我們可以假設每個樣本屬於不同標籤的概率服從於幾何分佈，使用多項邏輯迴歸（Softmax Regression）來進行分類：</p><p>其中，為模型的參數，而 可以看作是對概率的歸一化。一般來說，多項邏輯迴歸具有參數冗餘的特點，即將 同時加減一個向量後預測結果不變，因為 ，所以 。</p><p>假設從參數向量中減去向量 ，這時每一個都變成了。此時假設函數變成了以下公式：</p><p>從上式可以看出，從中減去 完全不影響假設函數的預測結果，這表明前面的迴歸模型中存在冗餘的參數。特別地，當類別數為時，</p><p>利用參數冗餘的特點，我們將所有的參數減去，上式變為：</p><p>其中。而整理後的式子與邏輯迴歸一致。因此，多項邏輯迴歸實際上是二分類邏輯迴歸在多標籤分類下的一種拓展。</p><p>當存在樣本可能屬於多個標籤的情況時，我們可以訓練個二分類的邏輯迴歸分類器。第 個分類器用以區分每個樣本是否可以歸為第 類，訓練該分類器時，需要把標籤重新整理為“第 類標籤”與“非第 類標籤”兩類。通過這樣的辦法，我們就解決了每個樣本可能擁有多個標籤的情況。</p><p>在二分類的邏輯迴歸中，對輸入樣本分類結果為類別和的概率可以寫成下列形式：</p><p>其中，是模型預測的概率值， 是樣本對應的類標籤。</p><p>將問題泛化為更一般的多分類情況：</p><p>由於連乘可能導致最終結果接近的問題，一般對似然函數取對數的負數，變成最小化對數似然函數。</p><p>補充：交叉熵</p><p>假設 和 是關於樣本集的兩個分佈，其中 是樣本集的真實分佈， 是樣本集的估計分佈，那麼按照真實分佈 來衡量識別一個樣本所需要編碼長度的期望（即，平均編碼長度）：</p><p>如果用估計分佈來表示真實分佈 的平均編碼長度，應為：</p><p>這是因為用來編碼的樣本來自於真實分佈 ，所以期望值 中的概率是 。而 就是交叉熵。</p><p>可以看出，在多分類問題中，通過最大似然估計得到的對數似然損失函數與通過交叉熵得到的交叉熵損失函數在形式上相同。</p><h2 class=pgc-h-arrow-right>1.2 GBDT多分類原理</h2><p>將GBDT應用於二分類問題需要考慮邏輯迴歸模型，同理，對於GBDT多分類問題則需要考慮以下Softmax模型：</p><p>其中是 個不同的CART迴歸樹集成。每一輪的訓練實際上是訓練了 棵樹去擬合softmax的每一個分支模型的負梯度。softmax模型的單樣本損失函數為：</p><p>這裡的是樣本在個類別上作one-hot編碼之後的取值，只有一維為，其餘都是。由以上表達式不難推導：</p><p>可見，這棵樹同樣是擬合了樣本的真實標籤與預測概率之差，與GBDT二分類的過程非常類似。下圖是Friedman在論文中對GBDT多分類給出的偽代碼：</p><div class=pgc-img><img alt=深入理解GBDT多分類算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/ba0f71ed73d647199330c8c81c817500><p class=pgc-img-caption></p></div><p>根據上面的偽代碼具體到多分類這個任務上面來，我們假設總體樣本共有類。來了一個樣本 ，我們需要使用GBDT來判斷 屬於樣本的哪一類。</p><p>第一步我們在訓練的時候，是針對樣本 每個可能的類都訓練一個分類迴歸樹。舉例說明，目前樣本有三類，也就是 ，樣本 屬於第二類。那麼針對該樣本的分類標籤，其實可以用一個三維向量 來表示。 表示樣本不屬於該類， 表示樣本屬於該類。由於樣本已經屬於第二類了，所以第二類對應的向量維度為 ，其它位置為 。</p><p>針對樣本有三類的情況，我們實質上在每輪訓練的時候是同時訓練三顆樹。第一顆樹針對樣本 的第一類，輸入為 。第二顆樹輸入針對樣本 的第二類，輸入為 。第三顆樹針對樣本 的第三類，輸入為 。這裡每顆樹的訓練過程其實就是CART樹的生成過程。在此我們參照CART生成樹的步驟即可解出三顆樹，以及三顆樹對 類別的預測值 , 那麼在此類訓練中，我們仿照多分類的邏輯迴歸 ，使用Softmax 來產生概率，則屬於類別 的概率為：</p><p>並且我們可以針對類別求出殘差 ；類別 求出殘差 ；類別 求出殘差。</p><p>然後開始第二輪訓練，針對第一類輸入為, 針對第二類輸入為 ，針對第三類輸入為 。繼續訓練出三顆樹。一直迭代M輪。每輪構建3顆樹。</p><p>當時，我們其實應該有三個式子：</p><p>當訓練完以後，新來一個樣本，我們要預測該樣本類別的時候，便可以有這三個式子產生三個值 。樣本屬於某個類別的概率為：</p><h2 class=pgc-h-arrow-right>2. GBDT多分類算法實例</h2><h2 class=pgc-h-arrow-right>（1）數據集</h2><h2 class=pgc-h-arrow-right>（2）模型訓練階段</h2><p>首先，由於我們需要轉化個二分類的問題，所以需要先做一步one-hot：</p><div class=pgc-img><img alt=深入理解GBDT多分類算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/56ab34eb35484bf494e44e04e555bf3c><p class=pgc-img-caption></p></div><p>參數設置：</p><ul><li>學習率：learning_rate = 1</li><li>樹的深度：max_depth = 2</li><li>迭代次數：n_trees = 5</li></ul><p>首先對所有的樣本，進行初始化，就是各類別在總樣本集中的佔比，結果如下表。</p><div class=pgc-img><img alt=深入理解GBDT多分類算法 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/pgc-image/a180ffea31e84ed7931f2a20132d73e3><p class=pgc-img-caption></p></div><p>注意：在Friedman論文裡全部初始化為，但在sklearn裡是初始化先驗概率（就是各類別的佔比），這裡我們用sklearn中的方法進行初始化。</p><h3 class=pgc-h-arrow-right>1）對第一個類別擬合第一顆樹 。</h3><p>首先，利用公式 計算概率。</p><p>其次，計算負梯度值，以 為例 ：</p><p>同樣地，計算其它樣本可以有下表：</p><p>接著，尋找回歸樹的最佳劃分節點。在GBDT的建樹中，可以採用如MSE、MAE等作為分裂準則來確定分裂點。本文采用的分裂準則是 MSE ，具體計算過程如下。遍歷所有特徵的取值，將每個特徵值依次作為分裂點，然後計算左子結點與右子結點上的MSE，尋找兩者加和最小的一個。</p><p>比如，選擇作為分裂點時 。</p><ul><li>左子結點上的集合的MSE為：</li></ul><ul><li>右子節點上的集合的MSE為：</li></ul><p>比如選擇作為分裂點時 。</p><p>對所有特徵計算完後可以發現，當選擇做為分裂點時，可以得到最小的， 。</p><p>下圖展示以為分裂點的 擬合一顆迴歸樹的示意圖：</p><div class=pgc-img><img alt=深入理解GBDT多分類算法 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/pgc-image/c9ebed8995d442928eb5767ce1f452d7><p class=pgc-img-caption></p></div><p>然後，我們的樹滿足了設置，還需要做一件事情，給這棵樹的每個葉子節點分別賦一個參數 （也就是我們文章提到的 ），來擬合殘差。</p><p>最後，更新可得下表：</p><p>至此第一個類別（類別）的第一顆樹擬合完畢，下面開始擬合第二個類別（類別）的第一顆樹。</p><h3 class=pgc-h-arrow-right>2）對第二個類別擬合第一顆樹 。</h3><p>首先，利用 計算概率。</p><p>其次，計算負梯度值，以 為例 ：</p><p>同樣地，計算其它樣本可以有下表：</p><p>然後，以 為分裂點的 擬合一顆迴歸樹，可計算得到葉子節點：</p><p>最後，更新 可得下表：</p><p>至此第二個類別（類別）的第一顆樹擬合完畢。然後再擬合第三個類別（類別）的第一顆樹，過程也是重複上述步驟，所以這裡就不再重複了。在擬合完所有類別的第一顆樹後就開始擬合第二顆樹。反覆進行，直到訓練了輪。</p><h2 class=pgc-h-arrow-right>3. 手撕GBDT多分類算法</h2><p>本篇文章所有數據集和代碼均在我的GitHub中，地址：https://github.com/Microstrong0305/WeChat-zhihu-csdnblog-code/tree/master/Ensemble%20Learning/GBDT_Multi-class</p><h2 class=pgc-h-arrow-right>3.1 用Python3實現GBDT多分類算法</h2><h4 class=pgc-h-arrow-right>需要的Python庫：</h4><pre><code>pandas、PIL、pydotplus、matplotlib</code></pre><p>其中 pydotplus 庫會自動調用 Graphviz ，所以需要去 Graphviz 官網下載 graphviz-2.38.msi 安裝，再將安裝目錄下的 bin 添加到系統環境變量，最後重啟計算機。</p><p>由於用 Python3 實現 GBDT 多分類算法代碼量比較多，我這裡就不列出詳細代碼了，感興趣的同學可以去我的 GitHub 中看一下，地址：https://github.com/Microstrong0305/WeChat-zhihu-csdnblog-code/tree/master/Ensemble%20Learning/GBDT_Multi-class/GBDT_GradientBoostingMultiClassifier</p><h2 class=pgc-h-arrow-right>3.2 用sklearn實現GBDT多分類算法</h2><pre><code>import numpy as npfrom sklearn.ensemble import GradientBoostingClassifier'''調參：loss：損失函數。有deviance和exponential兩種。deviance是採用對數似然，exponential是指數損失，後者相當於AdaBoost。n_estimators:最大弱學習器個數，默認是100，調參時要注意過擬合或欠擬合，一般和learning_rate一起考慮。learning_rate:步長，即每個弱學習器的權重縮減係數，默認為0.1，取值範圍0-1，當取值為1時，相當於權重不縮減。較小的learning_rate相當於更多的迭代次數。subsample:子採樣，默認為1，取值範圍(0,1]，當取值為1時，相當於沒有采樣。小於1時，即進行採樣，按比例採樣得到的樣本去構建弱學習器。這樣做可以防止過擬合，但是值不能太低，會造成高方差。init：初始化弱學習器。不使用的話就是第一輪迭代構建的弱學習器.如果沒有先驗的話就可以不用管由於GBDT使用CART迴歸決策樹。以下參數用於調優弱學習器，主要都是為了防止過擬合max_feature：樹分裂時考慮的最大特徵數，默認為None，也就是考慮所有特徵。可以取值有：log2,auto,sqrtmax_depth：CART最大深度，默認為Nonemin_sample_split：劃分節點時需要保留的樣本數。當某節點的樣本數小於某個值時，就當做葉子節點，不允許再分裂。默認是2min_sample_leaf：葉子節點最少樣本數。如果某個葉子節點數量少於某個值，會同它的兄弟節點一起被剪枝。默認是1min_weight_fraction_leaf：葉子節點最小的樣本權重和。如果小於某個值，會同它的兄弟節點一起被剪枝。一般用於權重變化的樣本。默認是0min_leaf_nodes：最大葉子節點數'''gbdt = GradientBoostingClassifier(loss='deviance', learning_rate=1, n_estimators=5, subsample=1                                  , min_samples_split=2, min_samples_leaf=1, max_depth=2                                  , init=None, random_state=None, max_features=None                                  , verbose=0, max_leaf_nodes=None, warm_start=False                                  )train_feat = np.array([[6],                       [12],                       [14],                       [18],                       [20],                       [65],                       [31],                       [40],                       [1],                       [2],                       [100],                       [101],                       [65],                       [54],                       ])train_label = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [2], [2], [2], [2]]).ravel()test_feat = np.array([[25]])test_label = np.array([[0]])print(train_feat.shape, train_label.shape, test_feat.shape, test_label.shape)gbdt.fit(train_feat, train_label)pred = gbdt.predict(test_feat)print(pred, test_label)</code></pre><p>用 sklearn 實現 GBDT 多分類算法的 GitHub 地址：https://github.com/Microstrong0305/WeChat-zhihu-csdnblog-code/blob/master/Ensemble%20Learning/GBDT_Multi-class/GBDT_multiclass_sklearn.py</p><h2 class=pgc-h-arrow-right>4. 總結</h2><p>在本文中，我們首先從Softmax迴歸引出GBDT的多分類算法原理；其次用實例來講解GBDT的多分類算法；然後不僅用Python3實現GBDT多分類算法，還用sklearn實現GBDT多分類算法；最後簡單的對本文做了一個總結。至此，GBDT用於解決迴歸任務、二分類任務和多分類任務就完整的深入理解了一遍。</p></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>GBDT</a></li><li><a>多分</a></li><li><a>算法</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E7%A7%91%E6%8A%80/ed4abe39.html alt=算法小專欄：散列表（二） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/a831970b0ccf4e4cbe591777ebd3f2a3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ed4abe39.html title=算法小專欄：散列表（二）>算法小專欄：散列表（二）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/38aea254.html alt=七大查找算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/15393515221731c57aa8da1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/38aea254.html title=七大查找算法>七大查找算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/51e4e55b.html alt=掌握算法-散列 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/7fe8d19cb78241e999d77102bee7e16c style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/51e4e55b.html title=掌握算法-散列>掌握算法-散列</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d2c8de48.html alt=C#算法系列（1）——二叉樹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d2c8de48.html title=C#算法系列（1）——二叉樹>C#算法系列（1）——二叉樹</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/d241e092.html alt=算法--二叉樹（平衡二叉樹、搜索二叉樹、完全二叉樹） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/9b2026e861ad49e88e1e124dc67edb32 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/d241e092.html title=算法--二叉樹（平衡二叉樹、搜索二叉樹、完全二叉樹）>算法--二叉樹（平衡二叉樹、搜索二叉樹、完全二叉樹）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bf5399b7.html alt=算法題—完全二叉樹 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/ef7d8ad6eaca4524a71e1e5d1277532b style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bf5399b7.html title=算法題—完全二叉樹>算法題—完全二叉樹</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1b7b6866.html alt=基於一致性算法的微網分佈式有功均衡控制 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/39fa00034e1eb30ffce3 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1b7b6866.html title=基於一致性算法的微網分佈式有功均衡控制>基於一致性算法的微網分佈式有功均衡控制</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/a61341cf.html alt=深入淺出排序算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/c898a3bab26542c2965d2bc5bebf9bd8 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/a61341cf.html title=深入淺出排序算法>深入淺出排序算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/8257f1b4.html alt=程序員那些必須掌握的排序算法(上) class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/c32d187d725f4bd59225a5d09a38cb37 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/8257f1b4.html title=程序員那些必須掌握的排序算法(上)>程序員那些必須掌握的排序算法(上)</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/500d3e1f.html alt="算法 － 七大排序算法詳細介紹" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/9275d53c0e5f432294fce6dd4cfef236 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/500d3e1f.html title="算法 － 七大排序算法詳細介紹">算法 － 七大排序算法詳細介紹</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/e9a28bf0.html alt=算法之旅｜冒泡排序法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/37e00004d03a88913f18 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/e9a28bf0.html title=算法之旅｜冒泡排序法>算法之旅｜冒泡排序法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/1ca491e3.html alt=算法之旅｜快速排序法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/3b0e0000a716d98c3cba style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/1ca491e3.html title=算法之旅｜快速排序法>算法之旅｜快速排序法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/0f03920a.html alt=算法入門篇：簡單的排序算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/6fbaa6f801434986af5ed9e339fd77f1 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/0f03920a.html title=算法入門篇：簡單的排序算法>算法入門篇：簡單的排序算法</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cb1c4077.html alt=算法設計之分治策略 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/15394979629303da8548ffa style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cb1c4077.html title=算法設計之分治策略>算法設計之分治策略</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d2b71b7.html alt=結構與算法：遞歸機制、排序規則、查找算法 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/b599d6f709aa44d7b77f190a4d81dcdd style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d2b71b7.html title=結構與算法：遞歸機制、排序規則、查找算法>結構與算法：遞歸機制、排序規則、查找算法</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>