<!doctype html><html lang=tw><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><link rel=dns-prefetch href=https://i.geekbank.cf/><title>乾貨｜如何在實戰中運用特徵工程與推薦系統 | 极客快訊</title><meta property="og:title" content="乾貨｜如何在實戰中運用特徵工程與推薦系統 - 极客快訊"><meta property="og:type" content="article"><meta property="og:locale" content="tw"><meta property="og:image" content="https://p3.pstatp.com/large/46f100002076c42a8d10"><link rel=alternate hreflang=x-default href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-tw href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-cn href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-hk href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-mo href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-my href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=alternate hreflang=zh-sg href=https://geekbank.cf/cn/%e7%a7%91%e6%8a%80/fdfcf961.html><link rel=canonical href=https://geekbank.cf/tw/%e7%a7%91%e6%8a%80/fdfcf961.html><meta property="article:published_time" content="2020-11-14T21:00:52+08:00"><meta property="article:modified_time" content="2020-11-14T21:00:52+08:00"><meta name=Keywords content><meta name=description content="乾貨｜如何在實戰中運用特徵工程與推薦系統"><meta name=author content="极客快訊"><meta property="og:url" content="/tw/%E7%A7%91%E6%8A%80/fdfcf961.html"><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffc40d"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=https://geekbank.cf/css/normalize.css><link rel=stylesheet href=https://geekbank.cf/css/style.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script type=text/javascript src=https://geekbank.cf/js/jqthumb.min.js></script><script data-ad-client=ca-pub-3525055026201463 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><h1><a id=logo href>🤓 极客快訊 Geek Bank</a></h1><p class=description>為你帶來最全的科技知識 🧡</p></div><div><nav id=nav-menu class=clearfix><a class=current href>猜你喜歡</a>
<a href=../../tw/categories/%E7%A7%91%E6%8A%80.html title=科技>科技</a>
<a href=../../tw/categories/%E9%81%8A%E6%88%B2.html title=遊戲>遊戲</a>
<a href=../../tw/categories/%E7%A7%91%E5%AD%B8.html title=科學>科學</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title>乾貨｜如何在實戰中運用特徵工程與推薦系統</h1></header><date class="post-meta meta-date">2020-11-14</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=tw/categories/%E7%A7%91%E6%8A%80.html>科技</a></span></div><div class=post-content><div><p>雲腦科技機器學習訓練營11月13日正式開始啦！量子位作為合作媒體獨家為大家分享課程乾貨內容。</p><h1>本期內容簡介</h1><p><strong>主題：</strong>億級用戶電商平臺推薦系統挑戰</p><p><strong>主講人：</strong>張本宇（雲腦科技創始人&CEO）</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/46f100002076c42a8d10></p><p>從事人工智能十八年的老兵，曾就職於微軟亞洲研究院、Google和Facebook，在AI方面手握了150項美國專利，在國際一流期刊及會議上發表的45篇論文已被引用超過6000次，創新工場最新研究《AI領域，中國人/華人有多牛？》中，張本宇位列<strong>“華人前10位大牛科學家”</strong>。</p><p><strong>內容要點：</strong></p><p>協同過濾 Collaborative Filtering</p><p>特徵工程 Feature Engineering</p><p>推薦系統實戰注意點</p><h1>分享內容實錄</h1><p>首先我們看一下<strong>機器學習的五大環節</strong>。</p><p>一是特徵工程。第二是算法定義和調參，就是你該選擇什麼樣的算法，用什麼樣的參數進行調節。第三是數據採集和清洗，接下來是實現這個算法並進行優化。‘I’代表和業務生產系統集成，所以我們就會簡稱為FaDAI這五大步驟。<strong>特徵工程是這五大環節最重要的一部分</strong>。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46f00000c063c4b73eb3></p><p>我們會<strong>簡單介紹一下特徵工程，以及一些常見的特徵工程的方法。</strong></p><p>引用一下吳恩達的話：“應用機器學習其實就是在做特徵工程，特徵工程是非常難、耗時、也是需要專業知識的一個工作。”我們理想中機器學習的情況：有很乾淨的Raw data，然後變成可學習的Dataset, 通過某些算法學出某些模型，然後解決一個問題，這是最理想的一個狀態。但現實中，我們會有各種各樣的數據，有的從數據庫來，有的從日誌來，有的從半結構結構化文檔來，有的從無結構的音頻、圖片中來。<strong>從中抽取什麼特徵，才能夠被我們機器學習所使用，從而能學習出模型解決出問題呢？</strong></p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/46ec00029e941a066d2a></p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46eb00029c78be4c6f2b></p><p>因此需要我們來做特徵工程，<strong>特徵工程本質是一種數據轉化的過程，原始數據通過特徵工程轉化為更好的、更可以學習的特徵，能夠表述模型內在關鍵因素。</strong></p><p>接下來我們看一下針對變量類型的特徵，這裡實際上有幾大類的變量類型。有分類型的特徵變量，也有數值型的特徵，還有兩個比較特殊的是時間和空間，接下來我們也會一一介紹。</p><p>對於離散型的特徵枚舉一些例子：你的操作系統是什麼類型？有可能是桌面，有可能是平板，有可能是手機。那你的user_id是什麼？有121545，或者別的一些id。 這種類型的特徵是最需要特徵工程的，因為它的取值空間非常巨大，經常會導致稀疏數據。所以說從效率和精度上來說，都是對模型一個巨大的挑戰。</p><p>那最簡單的一個特徵工程，叫做<strong>One-Hot encoding</strong>。舉例來說，platform這個維度有三個取值：desktop、mobile、tablet。 那我們可以轉換成三個特徵，如果平臺是在desktop上，那這個特徵就取1，如果在mobile上，那這個特徵就取1，如果在tablet上，那這個特徵就取1，這是一個非常稀疏的結構。舉例來說，如果有十萬個站點，那就十萬維，這是十萬維只有這一個維度上取1，其他都取0。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46f1000020da5b95f0c8></p><p><strong>一種比較常見的方法就是做Hash Encoding。</strong>舉例來說：有200多個國家，用Hash的方法把它轉化為100多列，但用剛才One-Hot的方法就有200多列，但用Hash方式表達，參數是可調的，所以它可以縮成100、50，甚至10。那它會有一定的代價，比如說巴西和智利被放在一列，但是這兩個國家可能有不同的特性，但他們必須share同樣的位置。這是它們潛在的一個問題，但稀疏性是可以控制的，也可以處理低頻和一些新的變量。這裡隱含的條件是有一個假設，這個假設是有些特徵可以share同一個位置。這個假設在深度學習中也會有使用。所以在實踐中發現很多時候並不會影響實際的結果，只要你的參數空間相對是足夠的，就是它有足夠的表達能力。這個也是相對比較常見的一個方法 像有些比較知名、開源的機器學習的工具都有這樣的一個功能。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/46ec00029f32dfab6c89></p><p>另外一個是<strong>計數型的Encoding，就是把它變成全局的count</strong>。比如廣告id:423654，他看了多少次，點擊了多少次，直接把它轉化成一個統計量，可以是觀看的次數，點擊的次數，廣告的CTR。就是用不同的id，每個id有不同的權重，變成浮點數上的一個特徵，共享一個權重。這裡有一個假設，它跟全局統計有某種線性關係，或者在某個轉化空間之後有線性關係。</p><p>還有一個是我們關心的<strong>異常值對整個統計的影響</strong>，那我們可能就從絕對值改為一個相對值，相對值就是它排序的一個次序，比如說按CTR排序，最好的CTR有什麼特徵。</p><p>最後是<strong>在神經網絡中常見的做法</strong>，就是把分類變量轉換為嵌入式變量，做Embedding。比如說你有十萬個不同sites，把它投影到64維或者128維的vector上面，相當於原來需要十萬個Free parameters，現在只需要64維或128維。之所以能這樣做，原來的十萬維空間是非常稀疏的，64維或者128維是更稠密的表達，所以還是有非常強的表達意義，好處就是內存需求會更少，相對來說精度也會更高。</p><p>有同學問<strong>Hash和Embedding的區別</strong>，Embedding本身是需要學習出來的，比如說id1它投影到怎樣的Embedding空間，通過學習來獲得。而哈希是通過預定義的哈希函數，直接投影過去，本身的哈希函數是不需要學習的。這裡它最基礎的邏輯是不一樣的，Hash Encoding也就是說你這兩維特徵可以share相同的weight。比如說巴西和智利放在同一列中，他們有相同的權重，而Embedding實際上是一種distributional的表達方式。它的意思是說巴西可能使用64維上不同取值來代表，智利也是同樣用這64維，所以這64維，每一列都參與表達不同的國家，每一個國家都由這64維來表達。它們兩個的基本思路上是有所區別的。</p><p><strong>我們現在進入到數值變量，數值變量主要有兩種，一種是浮點數和一種是定點數，定點數也就是整數。</strong>很多時候數值變量也可以當成模型的直接輸入來使用。但是基本上也都需要一定的特徵工程，因為實踐中它的取值範圍會很分散，實際上對模型的影響也比較大。</p><p><strong>首先我們看一下缺失數據</strong>，缺失數據一種最簡單的做法是轉化為空白，或者NaN，但實際上空白都會當成0來處理，這其實不是一種最好的表達。<strong>這時候其實更好的是使用平均值、中位值，或者模值，或者由其他模型來生成一些值。</strong>但常見來說平均值和中位值就足夠好了。那第二種情況可能會做一些rounding，就是忽略掉一些小數位上的變化，因為有時候小數位過高會是一種噪音。他本身的觀測實際上沒有這麼高的精度，所以很多時候精度是一些更低階的噪音帶來的。或說我們希望他在某些特徵上有一定的魯棒性。比如說這個例子，它在乘10取整後，實際上某種程度上可以當成分類、離散型的變量，比如說12345678910，當然它變成分類變量之後，實際上是產生了一個約束，10一定比9好，9一定比8好，它有個排序的次序和關係。所以這就是要看實際工作中，這樣一個約束是否成立。</p><p>然後<strong>還有一種情況是對取整的進一步拓展</strong>，二次化，0和1，超過0的就是1，因為很多時候我們需要關注它定性上的一些特性。再做一些擴展就是做Binning，就是做分塊，離散化，切到若干個bin裡面去，這個bin是等寬的，1到2，2到3，3到4 ，取值落到這裡面的個數是多少。另外還有一種分法是落入某個桶的分法平均，儘量的平均，這樣橫軸就是平均的。</p><p>還有的時候取值的範圍跨度太大或太小，這時候就採用某種非線性的變化，比如說log的transformation，讓它在兩個有extreme的value range上相對來說更smooth一些，更有區分力。這也是非線性的一種常用手段。雖然它非常簡單，但實際上的效果是不錯的。List還有取平方或者開方。</p><p><strong>最後一種是對數組做一定的normalization</strong>，有兩種方法：一種是minmax找到最小值最大值，把他們normalize到0到1之間，還有一種是做一個比較標準的正態化，就是減去mean 再除以var，但要對數據的分佈有個基本的瞭解。這裡有另一種方法，是對數值向量做歸一化，這也是為了防止數值上面一些outlier的點，主要還是為了數值上的穩定性。</p><p>這裡是一種特徵生成的方法，比如說原始特徵是X1,X2，通過兩兩交互能夠生成新的特徵，也帶來一定的非線性。後面要講的推薦系統FFM本質上就是使用這樣的方法。</p><p><strong>接下來是時間變量</strong>，本質上是一種連續值，但是實際上有一些特殊的處理，有時會忽略掉一些奇怪的問題，要注意一下。首先要注意一下時區的問題，是應該用local的時間還是同一時區，要根據具體問題來定，還有夏令時的問題。具體要根據場景來定。時間是連續值，很多時候也要進行分段，有時候會有一定語義的分法，比如早上，中午，晚上這樣的切分。實際上對切分本身來說也可以做成有重疊的， 比如說5點到9點是early morning，8點到11點是morning,這樣8點到9點就同時屬於兩個bin，這也是可以的。第二個就是對它的某些時間趨勢做一個特徵，就是它所消耗的時間，上週所消耗的時間，或者是相對消耗時間上的一個變化。</p><p>還有一些場景下我們關注一些特殊的時間，比如說節假日、雙十一。舉例來說這些做用電量的預測，那麼春節可能是一個非常強的特徵。春節大城市的用電量會急劇下降，世界盃前、發工資又要做一些特殊的推薦可能是實踐中需要考慮的東西。時間間隔：比如說上一次點擊廣告的時間，兩次點擊的間隔，因為會假設用戶的興趣會隨著時間變量發生變化。</p><p><strong>和時間相對應的是空間上的變量</strong>，有可能是GPS座標，也有可能是語義上的地址、郵編、城市、省，或是與特定位置的距離。很多時候地點是連續的特徵流，每一秒可能都有GPS 的座標，他可能需要進行異常的監測，因為GPS並不是那麼的精準可靠。也可以基於外部資源強增地點信息：包括這個區域的人口情況、收入情況等。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46ec00029e950ca2aca3></p><p><strong>接下來我們看一下自然語言處理的特徵工程。</strong>文本本質上也是一種分類變量，所以他會有一些傳統的做法，比如說:Bag of words ,TF-IDF，也有比較新的Embedding 或Topic models。</p><p><strong>Bag of words是One-Hot encoding的一種表達，TF-IDF是對Bag of words的一種簡單改進</strong>，它feature取值不僅僅取決於出現或不出現，它希望在這個feature的取值上能夠反映這個單詞對語義的相對重要性。Term Frequency 代表著一個詞如果在文檔中出現的次數越多，它可能的重要性越高。另外一方面，如果這個詞在出現的文章個數越少，說明這個詞更有區分性或者越具有代表性。 所以TF代表的是Term Frequency，IDF是words出現在document 的Frequency，兩者相乘是信息檢索領域對特徵取值進行re-weighting的一種常見的方法。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46f100002078212c6a04></p><p>有了兩個文檔的TF-IDF向量之後，就可以定義這個向量的相似性，可以用Cosine來定義，Cosine可以理解為一個normalize的內積，把兩個特徵進行L2的正則，它們之間的關係就是內積，或者說是兩個向量之間的夾角。</p><p>Textual Similarity 是簡單的進行一些定量的計算，比如說從一個文本轉換成另一個文本難易程度的一個計算。Word2vec實際上是Embedding的一種方法，需要定義某種損失函數來學習，最終是哪種損失函數滿足最終我們所期望的損失函數。Topic models本質上是進行某種矩陣的分解，目的是在高維的空間上進行低維的表達，能夠更完整的刻畫數據，這個在推薦系統上也會用到。</p><p><strong>推薦系統是一種非常廣泛的機器學習的領域，和廣告系統密切相關。區別是業務上的邏輯，本質上算法可以互相借鑑。</strong></p><p>協同過濾本質是用別的用戶來為這個用戶進行推薦和過濾，假設A和B在都看過的item非常相似，那麼A和B可能會share相似的list. 比如某些items 只有B看過，那麼A很可能和B會有相同的喜好。Item可能是廣告、電影、音樂等等。</p><p>舉例來說綠代表喜歡，紅色代表不喜歡，我們要看一下該用戶對電視機的喜好程度，什麼樣的用戶和他會比較像？我們會注意到第二個和第三個用戶，我們會借鑑第二、三個用戶的喜好來猜測它在電視機上的喜好，也意味著它喜歡第三個物品。</p><p><strong>協同過濾分為三個步驟：1用戶需要對某個物品表現出他的喜好性。2.用算法去找到和他比較相似的用戶。3．基於用戶做一個推薦。</strong></p><p><strong>這是基於user的推薦</strong>，接下來還會舉例基於item的推薦。</p><p>首先他需要確定一個度量方法，可以度量user之間的相似性，也可以度量item之間的相似性。假定這樣一個item都是使用一個特徵向量的表達，那麼它的相似性可以通過歐氏距離或皮爾遜相關係數來度量。歐氏距離實際上是最簡單的一種度量方式，但很多時候也是非常好用的方法。</p><p>假設兩個向量是n維空間的兩個點，那麼這兩個點的距離就是歐氏距離。距離我們需要轉化為相似性，有時候越小越好，有時候越大越好。所以我們會用圖中的一個變化。本質上是把無窮區間投影到0，1區間。皮爾遜係數本質上也是刻畫兩者之間的相似性。Cosine 也是基於內積的一個變化，如果在一個超球面上，它和歐氏距離有簡單的對應關係。有了這樣一個距離之後，我們可以找相似的label，有兩種找法：1.找最近的K個鄰居。2.找相似性小於或大於某種程度的一些鄰居。這兩種方法在實踐中都有使用。</p><p><strong>Item-item Filtering：</strong>現在有用戶ABC和物品ABC, 我們考慮是否要把物品C推薦給用戶C。我們看物品C和哪一個物品經常一起出現，發現是物品A。用戶C被推薦了物品A，因此把物品C推薦給他。User-item Filtering 考慮對用戶A進行推薦，先找到和A相似的可能是用戶C，看用戶C有說明額外的物品是用戶A不知道的，物品D是用戶A不知道的，那麼D就會推薦給A。這兩個可能是不同的維度，用哪種方法更好，也要看數據具體的特徵來定。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/46f10000207a8e00ef74></p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p1.pstatp.com/large/46ec00029e9605f43f70></p><p><strong>無論是哪種方法都會有一些缺點</strong>：1.複雜度是O(n^2)的，會隨著用戶數和物品數增高。無論是用Item-item Filtering還是User-item Filtering，本身feature vector的維度就很高，用來計算相似度或差異度的開銷就會更大，會有一個O(n)的增長。找相似的 item的做法有O（n）的複雜度；2.如何對新的用戶進行推薦。</p><p><strong>因式分解機試圖來解決帶來的一些問題，</strong>這個工作是10年Steffen提出的，他從另外一個角度來增強模型，同時也取得了很好的效果。他關注點在特徵間的協同作用，比如說將兩兩特徵組合起來。舉一個廣告的例子，他關心的是用戶是否有點擊這個廣告（1或者0），展示了用戶的一些特徵，國家、點擊的時間、還有廣告的類型，這是一個簡化的數據集，使用One-Hot encoding。</p><p><strong>最簡單的方法是把所有特徵進行One-Hot 表達，也不對日期等別的特徵進行哈希等別的方法的處理。</strong>把這樣一個矩陣放回到推薦的系統中，比如用戶和電影的推薦，每行代表用戶和電影的關係，用戶和電影都進行了One-Hot 表達，時間做了一個normalization，y是好與不好。推薦系統除了協同過濾，另一種方法是把它當成迴歸問題，那回歸問題X就是這些特徵，y就是rating，最簡單的一個模型就是線性迴歸。線性迴歸實際上是賦予每個特徵一個權重，然後相加，再加一個先驗。然後就得到一個預測值，我們希望預測值儘可能的接近真實的y。</p><p>當只使用原始特徵時可能表達能力不夠強。比如說在USA且今天是Thanksgiving，這是一個非常重要的信息，<strong>我們可能需要對這樣的特徵進行組合然後構造新的特徵。</strong>但這些組合空間可能會非常巨大，組合數是n方的關係。比如有200個國家，30個節日，再結合其他特徵如站點，相乘就會非常巨大。我們仔細觀察特徵組它們之間可能不是相互獨立的，有一些可以share的參數，這些share的參數是一些非常重要的概念，在Hash Encoding、CNN、RNN上都會用到。比如說美國和Thanksgiving的組合，它與中國和中國的新年的組合非常有關聯，所以它們倆之間可以用相同的latent factors進行刻畫。</p><p><strong>找 latent factor傳統的技術是做矩陣因式分解，</strong>比如說我們有非常大的矩陣是nm的，我們通過找到兩個nk和km的矩陣相乘可以重構出這樣一個nm的矩陣，就是SVD或者LSI，可能有不同的名詞但是有相同的做法。所以這個想法就被延展到了FFM上面，這裡最關鍵的想法是把wij定義成vi 乘以vj的內積，vi是k維上的一個元素，這樣的一個好處是把O(n^2)的複雜度降到O(n)的複雜度。所以wij就不是任意的一個參數，它是受限制的一個參數。所以FM可以被表達成下面這樣一個式子，它不在是O(n^2)的複雜度，而是O(nk)這樣一個問題，k是一個可選的參數，不會隨著數據量或特徵的增長而變化。計算量看起來更大了，但實際上有很多計算是重複的，通過簡單的變化可以變成O(nk)的複雜度。</p><p><img alt=乾貨｜如何在實戰中運用特徵工程與推薦系統 onerror=errorimg.call(this); src=https://p3.pstatp.com/large/46eb00029c7a675fd89b></p><p>總結一下它的優勢：FM model 可以線性時間來計算，它可以和任何實數型的特徵向量一起用，即使是在非常巨大的數據下它也可以進行一些參數估計，還可以做兩階的特徵組合。</p><p>— 完 —</p><p>誠摯招聘</p><p>量子位正在招募編輯/記者，工作地點在北京中關村。期待有才氣、有熱情的同學加入我們！相關細節，請在量子位公眾號(QbitAI)對話界面，回覆“招聘”兩個字。</p><p>量子位 QbitAI · 頭條號簽約作者</p><p>վ'ᴗ' ի 追蹤AI技術和產品新動態</p></div></div><div class="post-meta meta-tags"><ul class=clearfix><li><a>特徵</a></li><li><a>乾貨</a></li><li><a>實戰</a></li></ul></div></article></div></div><div id=secondary><section class=widget><form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=搜索>
<input type=hidden name=sitesearch value=geekbank.cf>
<button type=submit>🔍</button></form></section><section class=widget><h3 class=widget-title>最新文章 ⚡</h3><ul class=widget-list><li><a href=../../tw/%E9%81%8A%E6%88%B2/f35e56c1.html alt=纏論實戰乾貨-缺口的處理原則 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/3810fcf26af1481a9d1b2c3a1d7cea3b style=border-radius:25px></a>
<a href=../../tw/%E9%81%8A%E6%88%B2/f35e56c1.html title=纏論實戰乾貨-缺口的處理原則>纏論實戰乾貨-缺口的處理原則</a></li><hr><li><a href=../../tw/%E7%A7%91%E5%AD%B8/65e5268.html alt="乾貨分享 | 初中生物知識點：生物的基本特徵" class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/Rap732zEmXljR2 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E5%AD%B8/65e5268.html title="乾貨分享 | 初中生物知識點：生物的基本特徵">乾貨分享 | 初中生物知識點：生物的基本特徵</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/929d155d.html alt=耳模的基本特徵 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/929d155d.html title=耳模的基本特徵>耳模的基本特徵</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/efdb7210.html alt=乾貨丨光纖跳線類型、尾纖類型（附PPT全文） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/cb29513613c245eb85b248ac90e3b149 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/efdb7210.html title=乾貨丨光纖跳線類型、尾纖類型（附PPT全文）>乾貨丨光纖跳線類型、尾纖類型（附PPT全文）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/24b0e60e.html alt=乾貨|西大學長教你玩轉計算機07——圖像導數實戰 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/74830a84f854431294e917cf61f29fb7 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/24b0e60e.html title=乾貨|西大學長教你玩轉計算機07——圖像導數實戰>乾貨|西大學長教你玩轉計算機07——圖像導數實戰</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html alt=OpenCV項目實戰---人臉檢測 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/f267e46946554437b5ffe48234f3b78d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/cfc7290d.html title=OpenCV項目實戰---人臉檢測>OpenCV項目實戰---人臉檢測</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/02402c9e.html alt=「乾貨」藍牙耳機編碼（SBC、AAC、aptX）都有啥區別？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/feb0ab00-bb82-4c38-9e77-e3570f56137d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/02402c9e.html title=「乾貨」藍牙耳機編碼（SBC、AAC、aptX）都有啥區別？>「乾貨」藍牙耳機編碼（SBC、AAC、aptX）都有啥區別？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html alt=音頻編碼實戰 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/dfic-imagehandler/aacf5cab-b987-443f-815e-236f984fb2d0 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/fcc2ad9e.html title=音頻編碼實戰>音頻編碼實戰</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ce442e1f.html alt=【購房乾貨】層高和淨高的區別？ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/ba8f2c776647469baae689a0da1b401d style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ce442e1f.html title=【購房乾貨】層高和淨高的區別？>【購房乾貨】層高和淨高的區別？</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/6d98984a.html alt=重磅乾貨！柯春曉談“世界一流企業的創新生態與知識創新服務業” class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/2211f4f2f5c349ffa46e9937b47c9f39 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/6d98984a.html title=重磅乾貨！柯春曉談“世界一流企業的創新生態與知識創新服務業”>重磅乾貨！柯春曉談“世界一流企業的創新生態與知識創新服務業”</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/ac4494ba.html alt=乾貨｜機械行業面試題大整合，興許哪天就用上了 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p1.pstatp.com/large/pgc-image/4f9b97c36b5848f4af9c56ac14d665cf style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/ac4494ba.html title=乾貨｜機械行業面試題大整合，興許哪天就用上了>乾貨｜機械行業面試題大整合，興許哪天就用上了</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/652f4ceb.html alt=智慧電廠乾貨｜火電燃煤機組APS啟動步序設計管窺 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RsEtY3nI5h4LXq style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/652f4ceb.html title=智慧電廠乾貨｜火電燃煤機組APS啟動步序設計管窺>智慧電廠乾貨｜火電燃煤機組APS啟動步序設計管窺</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/bfcc99b0.html alt=智慧電廠乾貨｜火電燃煤機組APS邏輯步序設計管窺：停機步序設計點評 class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p9.pstatp.com/large/pgc-image/RsEtY3nI5h4LXq style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/bfcc99b0.html title=智慧電廠乾貨｜火電燃煤機組APS邏輯步序設計管窺：停機步序設計點評>智慧電廠乾貨｜火電燃煤機組APS邏輯步序設計管窺：停機步序設計點評</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/3e1ab8af.html alt=乾貨｜你知道像素和分辨率的關係嗎？（轉載） class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/pgc-image/1538281328795ef3472794a style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/3e1ab8af.html title=乾貨｜你知道像素和分辨率的關係嗎？（轉載）>乾貨｜你知道像素和分辨率的關係嗎？（轉載）</a></li><hr><li><a href=../../tw/%E7%A7%91%E6%8A%80/38ae079e.html alt=乾貨｜建築工程測量常見的錯誤分析，測量人一定要知道！ class="image featured" style=display:block;margin-left:auto;margin-right:auto;width:100%><img src=https://p3.pstatp.com/large/dfic-imagehandler/b2e4d031-2bd9-4ad0-83b1-b4efc2c7cdb5 style=border-radius:25px></a>
<a href=../../tw/%E7%A7%91%E6%8A%80/38ae079e.html title=乾貨｜建築工程測量常見的錯誤分析，測量人一定要知道！>乾貨｜建築工程測量常見的錯誤分析，測量人一定要知道！</a></li><hr></ul></section><section class=widget><h3 class=widget-title>其他</h3><ul class=widget-list><li><a href=TOS.html>使用條款</a></li><li><a href=CommentPolicy.html>留言政策</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>DMCA</a></li><li><a href=mailto:gdnews@tuta.io rel=nofollow>聯絡我們</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href>极客快訊</a></div></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:true}};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script><a id=rocket href=#top></a><script type=text/javascript src=https://kknews.cf/js/totop.js async></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e508ed9e4e698bb"></script></body></html>